<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.clpsych">
  <volume id="1" ingest-date="2024-03-04" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 9th Workshop on Computational Linguistics and Clinical Psychology (CLPsych 2024)</booktitle>
      <editor><first>Andrew</first><last>Yates</last></editor>
      <editor><first>Bart</first><last>Desmet</last></editor>
      <editor><first>Emily</first><last>Prud’hommeaux</last></editor>
      <editor><first>Ayah</first><last>Zirikly</last></editor>
      <editor><first>Steven</first><last>Bedrick</last></editor>
      <editor><first>Sean</first><last>MacAvaney</last></editor>
      <editor><first>Kfir</first><last>Bar</last></editor>
      <editor><first>Molly</first><last>Ireland</last></editor>
      <editor><first>Yaakov</first><last>Ophir</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>St. Julians, Malta</address>
      <month>March</month>
      <year>2024</year>
      <url hash="ad406089">2024.clpsych-1</url>
      <venue>clpsych</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="2ef53363">2024.clpsych-1.0</url>
      <bibkey>clpsych-2024-linguistics</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Assessing Motivational Interviewing Sessions with <fixed-case>AI</fixed-case>-Generated Patient Simulations</title>
      <author><first>Stav</first><last>Yosef</last><affiliation>RUNI</affiliation></author>
      <author><first>Moreah</first><last>Zisquit</last><affiliation>RUNI</affiliation></author>
      <author><first>Ben</first><last>Cohen</last><affiliation>RUNI</affiliation></author>
      <author><first>Anat</first><last>Klomek Brunstein</last><affiliation>RUNI</affiliation></author>
      <author><first>Kfir</first><last>Bar</last><affiliation>Reichman University</affiliation></author>
      <author><first>Doron</first><last>Friedman</last><affiliation>Reichman University</affiliation></author>
      <pages>1-11</pages>
      <abstract>There is growing interest in utilizing large language models (LLMs) in the field of mental health, and this goes as far as suggesting automated LLM-based therapists. Evaluating such generative models in therapy sessions is essential, yet remains an ongoing and complex challenge. We suggest a novel approach: an LLMbased digital patient platform which generates digital patients that can engage in a text-based conversation with either automated or human therapists. Moreover, we show that LLMs can be used to rate the quality of such sessions by completing questionnaires originally designed for human patients. We demonstrate that the ratings are both statistically reliable and valid, indicating that they are consistent and capable of distinguishing among three levels of therapist expertise. In the present study, we focus on motivational interviewing, but we suggest that this platform can be adapted to facilitate other types of therapies. We plan to publish the digital patient platform and make it available to the research community, with the hope of contributing to the standardization of evaluating automated therapists.</abstract>
      <url hash="abb4491d">2024.clpsych-1.1</url>
      <bibkey>yosef-etal-2024-assessing</bibkey>
    </paper>
    <paper id="2">
      <title>Delving into the Depths: Evaluating Depression Severity through <fixed-case>BDI</fixed-case>-biased Summaries</title>
      <author><first>Mario</first><last>Aragon</last><affiliation>Universidade de Santiago de Compostela</affiliation></author>
      <author><first>Javier</first><last>Parapar</last><affiliation>Universidad de A Coruña</affiliation></author>
      <author><first>David E</first><last>Losada</last><affiliation>Universidad de Satiago de Compostela</affiliation></author>
      <pages>12-22</pages>
      <abstract>Depression is a global concern suffered by millions of people, significantly impacting their thoughts and behavior. Over the years, heightened awareness, spurred by health campaigns and other initiatives, has driven the study of this disorder using data collected from social media platforms. In our research, we aim to gauge the severity of symptoms related to depression among social media users. The ultimate goal is to estimate the user’s responses to a well-known standardized psychological questionnaire, the Beck Depression Inventory-II (BDI). This is a 21-question multiple-choice self-report inventory that covers multiple topics about how the subject has been feeling. Mining users’ social media interactions and understanding psychological states represents a challenging goal. To that end, we present here an approach based on search and summarization that extracts multiple BDI-biased summaries from the thread of users’ publications. We also leverage a robust large language model to estimate the potential answer for each BDI item. Our method involves several steps. First, we employ a search strategy based on sentence similarity to obtain pertinent extracts related to each topic in the BDI questionnaire. Next, we compile summaries of the content of these groups of extracts. Last, we exploit chatGPT to respond to the 21 BDI questions, using the summaries as contextual information in the prompt. Our model has undergone rigorous evaluation across various depression datasets, yielding encouraging results. The experimental report includes a comparison against an assessment done by expert humans and competes favorably with state-of-the-art methods.</abstract>
      <url hash="714a6aae">2024.clpsych-1.2</url>
      <bibkey>aragon-etal-2024-delving</bibkey>
    </paper>
    <paper id="3">
      <title>How Can Client Motivational Language Inform Psychotherapy Agents?</title>
      <author><first>Van</first><last>Hoang</last><affiliation>Technical University Dublin</affiliation></author>
      <author><first>Eoin</first><last>Rogers</last><affiliation>TU Dublin</affiliation></author>
      <author><first>Robert</first><last>Ross</last><affiliation>Technological University Dublin</affiliation></author>
      <pages>23-40</pages>
      <abstract>Within Motivational Interviewing (MI), client utterances are coded as for or against a certain behaviour change, along with commitment strength; this is essential to ensure therapists soften rather than persisting goal-related actions in the face of resistance. Prior works in MI agents have been scripted or semi-scripted, limiting users’ natural language expressions. With the aim of automating the MI interactions, we propose and explore the task of automated identification of client motivational language. Employing Large Language Models (LLMs), we compare in-context learning (ICL) and instruction fine-tuning (IFT) with varying training sizes for this identification task. Our experiments show that both approaches can learn under low-resourced settings. Our results demonstrate that IFT, though cheaper, is more stable to prompt choice, and yields better performance with more data. Given the detected motivation, we further present an approach to the analysis of therapists’ strategies for balancing building rapport with clients with advancing the treatment plan. A framework of MI agents is developed using insights from the data and the psychotherapy literature.</abstract>
      <url hash="8d169458">2024.clpsych-1.3</url>
      <bibkey>hoang-etal-2024-client</bibkey>
    </paper>
    <paper id="4">
      <title>Linguistic markers of schizophrenia: a case study of <fixed-case>R</fixed-case>obert <fixed-case>W</fixed-case>alser</title>
      <author><first>Ivan</first><last>Nenchev</last><affiliation>Charité Universitätsmedizin Berlin</affiliation></author>
      <author><first>Tatjana</first><last>Scheffler</last><affiliation>Ruhr Universität Bochum</affiliation></author>
      <author><first>Marie</first><last>de la Fuente</last><affiliation>Universität Potsdam</affiliation></author>
      <author><first>Heiner</first><last>Stuke</last><affiliation>Charité Universitätsmedizin Berlin</affiliation></author>
      <author><first>Benjamin</first><last>Wilck</last><affiliation>Hebrew University of Jerusalem</affiliation></author>
      <author><first>Sandra Anna</first><last>Just</last><affiliation>Charité Universitätsmedizin Berlin</affiliation></author>
      <author><first>Christiane</first><last>Montag</last><affiliation>Charité Universitätsmedizin Berlin</affiliation></author>
      <pages>41-60</pages>
      <abstract>We present a study of the linguistic output of the German-speaking writer Robert Walser using NLP. We curated a corpus comprising texts written by Walser during periods of sound health, and writings from the year before his hospitalization, and writings from the first year of his stay in a psychiatric clinic, all likely at- tributed to schizophrenia. Within this corpus, we identified and analyzed a total of 20 lin- guistic markers encompassing established met- rics for lexical diversity, semantic similarity, and syntactic complexity. Additionally, we ex- plored lesser-known markers such as lexical innovation, concreteness, and imageability. No- tably, we introduced two additional markers for phonological similarity for the first time within this context. Our findings reveal sig- nificant temporal dynamics in these markers closely associated with Walser’s contempora- neous diagnosis of schizophrenia. Furthermore, we investigated the relationship between these markers, leveraging them for classification of the schizophrenic episode.</abstract>
      <url hash="2f3e97a3">2024.clpsych-1.4</url>
      <bibkey>nenchev-etal-2024-linguistic</bibkey>
    </paper>
    <paper id="5">
      <title>Therapist Self-Disclosure as a Natural Language Processing Task</title>
      <author><first>Natalie</first><last>Shapira</last><affiliation>None</affiliation></author>
      <author><first>Tal</first><last>Alfi-Yogev</last><affiliation>None</affiliation></author>
      <pages>61-73</pages>
      <abstract>Therapist Self-Disclosure (TSD) within the context of psychotherapy entails the revelation of personal information by the therapist. The ongoing scholarly discourse surrounding the utility of TSD, spanning from the inception of psychotherapy to the present day, has underscored the need for greater specificity in conceptualizing TSD. This inquiry has yielded more refined classifications within the TSD domain, with a consensus emerging on the distinction between immediate and non-immediate TSD, each of which plays a distinct role in the therapeutic process. Despite this progress in the field of psychotherapy, the Natural Language Processing (NLP) domain currently lacks methodological solutions or explorations for such scenarios. This lacuna can be partly due to the difficulty of attaining publicly available clinical data. To address this gap, this paper presents an innovative NLP-based approach that formalizes TSD as an NLP task. The proposed methodology involves the creation of publicly available, expert-annotated test sets designed to simulate therapist utterances, and the employment of NLP techniques for evaluation purposes. By integrating insights from psychotherapy research with NLP methodologies, this study aims to catalyze advancements in both NLP and psychotherapy research.</abstract>
      <url hash="2485fe70">2024.clpsych-1.5</url>
      <bibkey>shapira-alfi-yogev-2024-therapist</bibkey>
    </paper>
    <paper id="6">
      <title>Ethical thematic and topic modelling analysis of sleep concerns in a social media derived suicidality dataset</title>
      <author><first>Martin</first><last>Orr</last><affiliation>Auckland University Technology</affiliation></author>
      <author><first>Kirsten</first><last>Van Kessel</last><affiliation>Auckland University of Technology New Zealand</affiliation></author>
      <author><first>David</first><last>Parry</last><affiliation>Murdoch University Australia</affiliation></author>
      <pages>74-91</pages>
      <abstract>Objective: A thematic and topic modelling analysis of sleep concerns in a social media derived, privacy-preserving, suicidality dataset. This forms the basis for an exploration of sleep as a potential computational linguistic signal in suicide prevention. Background: Suicidal ideation is a limited signal for suicide. Developments in computational linguistics and mental health datasets afford an opportunity to investigate additional signals and to consider the broader clinical ethical design implications. Methodology: A clinician-led integration of reflexive thematic analysis, with machine learning topic modelling (Bertopic), and the purposeful sampling of the University of Maryland Suicidality Dataset. Results: Sleep as a place of refuge and escape, revitalisation for exhaustion, and risk and vulnerability were generated as core themes in an initial thematic analysis of 546 posts. Bertopic analysing 21,876 sleep references in 16791 posts facilitated the production of 40 topics that were clinically interpretable, relevant, and thematically aligned to a level that exceeded original expectations. Privacy and synthetic representative data, reproducibility, validity and stochastic variability of results, and a multi-signal formulation perspective, are highlighted as key research and clinical issues.</abstract>
      <url hash="046e1c52">2024.clpsych-1.6</url>
      <bibkey>orr-etal-2024-ethical</bibkey>
    </paper>
    <paper id="7">
      <title>Automatic Annotation of Dream Report’s Emotional Content with Large Language Models</title>
      <author><first>Lorenzo</first><last>Bertolini</last><affiliation>European Commission JRC</affiliation></author>
      <author><first>Valentina</first><last>Elce</last><affiliation>IMT School for Advanced Studies</affiliation></author>
      <author><first>Adriana</first><last>Michalak</last><affiliation>IMT School for Advanced Studies</affiliation></author>
      <author><first>Hanna-Sophia</first><last>Widhoezl</last><affiliation>Institute of Interdisciplinary Studies, University of Amsterdam</affiliation></author>
      <author><first>Giulio</first><last>Bernardi</last><affiliation>IMT School for Advanced Studies</affiliation></author>
      <author><first>Julie</first><last>Weeds</last><affiliation>University of Sussex</affiliation></author>
      <pages>92-107</pages>
      <abstract>In the field of dream research, the study of dream content typically relies on the analysis of verbal reports provided by dreamers upon awakening from their sleep. This task is classically performed through manual scoring provided by trained annotators, at a great time expense. While a consistent body of work suggests that natural language processing (NLP) tools can support the automatic analysis of dream reports, proposed methods lacked the ability to reason over a report’s full context and required extensive data pre-processing. Furthermore, in most cases, these methods were not validated against standard manual scoring approaches. In this work, we address these limitations by adopting large language models (LLMs) to study and replicate the manual annotation of dream reports, using a mixture of off-the-shelf and bespoke approaches, with a focus on references to reports’ emotions. Our results show that the off-the-shelf method achieves a low performance probably in light of inherent linguistic differences between reports collected in different (groups of) individuals. On the other hand, the proposed bespoke text classification method achieves a high performance, which is robust against potential biases. Overall, these observations indicate that our approach could find application in the analysis of large dream datasets and may favour reproducibility and comparability of results across studies.</abstract>
      <url hash="5e4d4df7">2024.clpsych-1.7</url>
      <bibkey>bertolini-etal-2024-automatic</bibkey>
    </paper>
    <paper id="8">
      <title>Explainable Depression Detection Using Large Language Models on Social Media Data</title>
      <author><first>Yuxi</first><last>Wang</last><affiliation>University of Ottawa</affiliation></author>
      <author><first>Diana</first><last>Inkpen</last><affiliation>University of Ottawa</affiliation></author>
      <author><first>Prasadith</first><last>Kirinde Gamaarachchige</last><affiliation>University of Ottawa</affiliation></author>
      <pages>108-126</pages>
      <abstract>Due to the rapid growth of user interaction on different social media platforms, publicly available social media data has increased substantially. The sheer amount of data and level of personal information being shared on such platforms has made analyzing textual information to predict mental disorders such as depression a reliable preliminary step when it comes to psychometrics. In this study, we first proposed a system to search for texts that are related to depression symptoms from the Beck’s Depression Inventory (BDI) questionnaire, and providing a ranking for further investigation in a second step. Then, in this second step, we address the even more challenging task of automatic depression level detection, using writings and voluntary answers provided by users on Reddit. Several Large Language Models (LLMs) were applied in experiments. Our proposed system based on LLMs can generate both predictions and explanations for each question. By combining two LLMs for different questions, we achieved better performance on three of four metrics compared to the state-of-the-art and remained competitive on the one remaining metric. In addition, our system is explainable on two levels: first, knowing the answers to the BDI questions provides clues about the possible symptoms that could lead to a clinical diagnosis of depression; second, our system can explain the predicted answer for each question.</abstract>
      <url hash="b013668d">2024.clpsych-1.8</url>
      <bibkey>wang-etal-2024-explainable</bibkey>
    </paper>
    <paper id="9">
      <title>Analysing relevance of Discourse Structure for Improved Mental Health Estimation</title>
      <author><first>Navneet</first><last>Agarwal</last><affiliation>Normandie University, UNICAEN, ENSICAEN, CNRS, GREYC</affiliation></author>
      <author><first>Gaël</first><last>Dias</last><affiliation>Normandie Univ, UNICAEN, ENSICAEN, CNRS, GREYC</affiliation></author>
      <author><first>Sonia</first><last>Dollfus</last><affiliation>CHU de Caen, Service de Psychiatrie; Normandie Univ, UNICAEN, ISTS, GIP Cyceron; Normandie Univ, UNICAEN, UFR de Médecine</affiliation></author>
      <pages>127-132</pages>
      <abstract>Automated depression estimation has received significant research attention in recent years as a result of its growing impact on the global community. Within the context of studies based on patient-therapist interview transcripts, most researchers treat the dyadic discourse as a sequence of unstructured sentences, thus ignoring the discourse structure within the learning process. In this paper we propose Multi-view architectures that divide the input transcript into patient and therapist views based on sentence type in an attempt to utilize symmetric discourse structure for improved model performance. Experiments on DAIC-WOZ dataset for binary classification task within depression estimation show advantages of Multi-view architecture over sequential input representations. Our model also outperforms the current state-of-the-art results and provide new SOTA performance on test set of DAIC-WOZ dataset.</abstract>
      <url hash="8b0e31e0">2024.clpsych-1.9</url>
      <bibkey>agarwal-etal-2024-analysing</bibkey>
    </paper>
    <paper id="10">
      <title>Using Daily Language to Understand Drinking: Multi-Level Longitudinal Differential Language Analysis</title>
      <author><first>Matthew</first><last>Matero</last><affiliation>Stony Brook University</affiliation></author>
      <author><first>Huy</first><last>Vu</last><affiliation>Stony Brook University</affiliation></author>
      <author><first>August</first><last>Nilsson</last><affiliation>OsloMet</affiliation></author>
      <author><first>Syeda</first><last>Mahwish</last><affiliation>Stony Brook University</affiliation></author>
      <author><first>Young Min</first><last>Cho</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>James</first><last>McKay</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Johannes</first><last>Eichstaedt</last><affiliation>Stanford University</affiliation></author>
      <author><first>Richard</first><last>Rosenthal</last><affiliation>Stony Brook University</affiliation></author>
      <author><first>Lyle</first><last>Ungar</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>H. Andrew</first><last>Schwartz</last><affiliation>Stony Brook University</affiliation></author>
      <pages>133-144</pages>
      <abstract>Analyses for linking language with psychological factors or behaviors predominately treat linguistic features as a static set, working with a single document per person or aggregating across multiple posts (e.g. on social media) into a single set of features. This limits language to mostly shed light on between-person differences rather than changes in behavior within-person. Here, we collected a novel dataset of daily surveys where participants were asked to describe their experienced well-being and report the number of alcoholic beverages they had within the past 24 hours. Through this data, we first build a multi-level forecasting model that is able to capture within-person change and leverage both the psychological features of the person and daily well-being responses. Then, we propose a longitudinal version of differential language analysis that finds patterns associated with drinking more (e.g. social events) and less (e.g. task-oriented), as well as distinguishing patterns of heavy drinks versus light drinkers.</abstract>
      <url hash="2579df42">2024.clpsych-1.10</url>
      <bibkey>matero-etal-2024-using</bibkey>
    </paper>
    <paper id="11">
      <title>Prevalent Frequency of Emotional and Physical Symptoms in Social Anxiety using Zero Shot Classification: An Observational Study</title>
      <author><first>Muhammad</first><last>Rizwan</last><affiliation>Department of Information Technology, Khwaja Fareed University of Engineering and Information Technology, RYKhan, Pakistan</affiliation></author>
      <author><first>Jure</first><last>Demšar</last><affiliation>Faculty of Computer and Information Science, University of Ljubljana, Slovenia</affiliation></author>
      <pages>145-152</pages>
      <abstract>Social anxiety represents a prevalent challenge in modern society, affecting individuals across personal and professional spheres. Left unaddressed, this condition can yield substantial negative consequences, impacting social interactions and performance. Further understanding its diverse physical and emotional symptoms becomes pivotal for comprehensive diagnosis and tailored therapeutic interventions. This study analyze prev lance and frequency of social anxiety symptoms taken from Mayo Clinic, exploring diverse human experiences from utilizing a large Reddit dataset dedicated to this issue. Leveraging these platforms, the research aims to extract insights and examine a spectrum of physical and emotional symptoms linked to social anxiety disorder. Upholding ethical considerations, the study maintains strict user anonymity within the dataset. By employing a novel approach, the research utilizes BART-based multi-label zero-shot classification to identify and measure symptom prevalence and significance in the form of probability score for each symptom under consideration. Results uncover distinctive patterns: “Trembling” emerges as a prevalent physical symptom, while emotional symptoms like “Fear of being judged negatively” exhibit high frequencies. These findings offer insights into the multifaceted nature of social anxiety, aiding clinical practices and interventions tailored to its diverse expressions.</abstract>
      <url hash="657bed2b">2024.clpsych-1.11</url>
      <bibkey>rizwan-demsar-2024-prevalent</bibkey>
    </paper>
    <paper id="12">
      <title>Comparing panic and anxiety on a dataset collected from social media</title>
      <author><first>Sandra</first><last>Mitrović</last><affiliation>IDSIA - USI/SUPSI</affiliation></author>
      <author><first>Oscar William</first><last>Lithgow-Serrano</last><affiliation>IDSIA - USI/SUPSI</affiliation></author>
      <author><first>Carlo</first><last>Schillaci</last><affiliation>SUPSI</affiliation></author>
      <pages>153-165</pages>
      <abstract>The recognition of mental health’s crucial significance has led to a growing interest in utilizing social media text data in current research trends. However, there remains a significant gap in the study of panic and anxiety on these platforms, despite their high prevalence and severe impact. In this paper, we address this gap by presenting a dataset consisting of 1,930 user posts from Quora and Reddit specifically focusing on panic and anxiety. Through a combination of lexical analysis, emotion detection, and writer attitude assessment, we explore the unique characteristics of each condition. To gain deeper insights, we employ a mental health-specific transformer model and a large language model for qualitative analysis. Our findings not only contribute to the understanding digital discourse on anxiety and panic but also provide valuable resources for the broader research community. We make our dataset, methodologies, and code available to advance understanding and facilitate future studies.</abstract>
      <url hash="cb568f10">2024.clpsych-1.12</url>
      <bibkey>mitrovic-etal-2024-comparing</bibkey>
    </paper>
    <paper id="13">
      <title>Your Model Is Not Predicting Depression Well And That Is Why: A Case Study of <fixed-case>PRIMATE</fixed-case> Dataset</title>
      <author><first>Kirill</first><last>Milintsevich</last><affiliation>University of Caen Normandy</affiliation></author>
      <author><first>Kairit</first><last>Sirts</last><affiliation>University of Tartu</affiliation></author>
      <author><first>Gaël</first><last>Dias</last><affiliation>Normandie Univ, UNICAEN, ENSICAEN, CNRS, GREYC</affiliation></author>
      <pages>166-171</pages>
      <abstract>This paper addresses the quality of annotations in mental health datasets used for NLP-based depression level estimation from social media texts. While previous research relies on social media-based datasets annotated with binary categories, i.e. depressed or non-depressed, recent datasets such as D2S and PRIMATE aim for nuanced annotations using PHQ-9 symptoms. However, most of these datasets rely on crowd workers without the domain knowledge for annotation. Focusing on the PRIMATE dataset, our study reveals concerns regarding annotation validity, particularly for the lack of interest or pleasure symptom. Through reannotation by a mental health professional, we introduce finer labels and textual spans as evidence, identifying a notable number of false positives. Our refined annotations, to be released under a Data Use Agreement, offer a higher-quality test set for anhedonia detection. This study underscores the necessity of addressing annotation quality issues in mental health datasets, advocating for improved methodologies to enhance NLP model reliability in mental health assessments.</abstract>
      <url hash="e743e05f">2024.clpsych-1.13</url>
      <bibkey>milintsevich-etal-2024-model</bibkey>
    </paper>
    <paper id="14">
      <title>Detecting a Proxy for Potential Comorbid <fixed-case>ADHD</fixed-case> in People Reporting Anxiety Symptoms from Social Media Data</title>
      <author><first>Claire</first><last>Lee</last><affiliation>Start-up</affiliation></author>
      <author><first>Noelle</first><last>Lim</last><affiliation>LinkedIn</affiliation></author>
      <author><first>Michael</first><last>Guerzhoy</last><affiliation>University of Toronto</affiliation></author>
      <pages>172-176</pages>
      <abstract>We present a novel task that can elucidate the connection between anxiety and ADHD; use Transformers to make progress toward solving a task that is not solvable by keyword-based classifiers; and discuss a method for visualization of our classifier illuminating the connection between anxiety and ADHD presentations. Up to approximately 50% of adults with ADHD may also have an anxiety disorder and approximately 30% of adults with anxiety may also have ADHD. Patients presenting with anxiety may be treated for anxiety without ADHD ever being considered, possibly affecting treatment. We show how data that bears on ADHD that is comorbid with anxiety can be obtained from social media data, and show that Transformers can be used to detect a proxy for possible comorbid ADHD in people with anxiety symptoms. We collected data from anxiety and ADHD online forums (subreddits). We identified posters who first started posting in the Anxiety subreddit and later started posting in the ADHD subreddit as well. We use this subset of the posters as a proxy for people who presented with anxiety symptoms and then became aware that they might have ADHD. We fine-tune a Transformer architecture-based classifier to classify people who started posting in the Anxiety subreddit and then started posting in the ADHD subreddit vs. people who posted in the Anxiety subreddit without later posting in the ADHD subreddit. We show that a Transformer architecture is capable of achieving reasonable results (76% correct for RoBERTa vs. under 60% correct for the best keyword-based model, both with 50% base rate).</abstract>
      <url hash="090fc9b5">2024.clpsych-1.14</url>
      <bibkey>lee-etal-2024-detecting</bibkey>
    </paper>
    <paper id="15">
      <title>Overview of the <fixed-case>CLP</fixed-case>sych 2024 Shared Task: Leveraging Large Language Models to Identify Evidence of Suicidality Risk in Online Posts</title>
      <author><first>Jenny</first><last>Chim</last><affiliation>Queen Mary University of London and The Alan Turing Institute</affiliation></author>
      <author><first>Adam</first><last>Tsakalidis</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Dimitris</first><last>Gkoumas</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Dana</first><last>Atzil-Slonim</last><affiliation>Bar Ilan University</affiliation></author>
      <author><first>Yaakov</first><last>Ophir</last><affiliation>Ariel University and University of Cambridge</affiliation></author>
      <author><first>Ayah</first><last>Zirikly</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Philip</first><last>Resnik</last><affiliation>University of Maryland</affiliation></author>
      <author><first>Maria</first><last>Liakata</last><affiliation>Queen Mary University of London and The Alan Turing Institute</affiliation></author>
      <pages>177-190</pages>
      <abstract>We present the overview of the CLPsych 2024 Shared Task, focusing on leveraging open source Large Language Models (LLMs) for identifying textual evidence that supports the suicidal risk level of individuals on Reddit. In particular, given a Reddit user, their pre- determined suicide risk level (‘Low’, ‘Mod- erate’ or ‘High’) and all of their posts in the r/SuicideWatch subreddit, we frame the task of identifying relevant pieces of text in their posts supporting their suicidal classification in two ways: (a) on the basis of evidence highlighting (extracting sub-phrases of the posts) and (b) on the basis of generating a summary of such evidence. We annotate a sample of 125 users and introduce evaluation metrics based on (a) BERTScore and (b) natural language inference for the two sub-tasks, respectively. Finally, we provide an overview of the system submissions and summarise the key findings.</abstract>
      <url hash="841f1f96">2024.clpsych-1.15</url>
      <bibkey>chim-etal-2024-overview</bibkey>
    </paper>
    <paper id="16">
      <title>Team <fixed-case>ISM</fixed-case> at <fixed-case>CLP</fixed-case>sych 2024: Extracting Evidence of Suicide Risk from <fixed-case>R</fixed-case>eddit Posts with Knowledge Self-Generation and Output Refinement using A Large Language Model</title>
      <author><first>Vu</first><last>Tran</last><affiliation>The Institute of Statistical Mathematics</affiliation></author>
      <author><first>Tomoko</first><last>Matsui</last><affiliation>The Institute of Statistical Mathematics</affiliation></author>
      <pages>191-196</pages>
      <abstract>This paper presents our approach to the CLPsych 2024 shared task: utilizing large language models (LLMs) for finding supporting evidence about an individual’s suicide risk level in Reddit posts. Our framework is constructed around an LLM with knowledge self-generation and output refinement. The knowledge self-generation process produces task-related knowledge which is generated by the LLM and leads to accurate risk predictions. The output refinement process, later, with the selected best set of LLM-generated knowledge, refines the outputs by prompting the LLM repeatedly with different knowledge instances interchangeably. We achieved highly competitive results comparing to the top-performance participants with our official recall of 93.5%, recall–precision harmonic-mean of 92.3%, and mean consistency of 96.1%.</abstract>
      <url hash="fc15c94f">2024.clpsych-1.16</url>
      <bibkey>tran-matsui-2024-team</bibkey>
    </paper>
    <paper id="17">
      <title>Exploring Instructive Prompts for Large Language Models in the Extraction of Evidence for Supporting Assigned Suicidal Risk Levels</title>
      <author><first>Jiyu</first><last>Chen</last><affiliation>CSIRO</affiliation></author>
      <author><first>Vincent</first><last>Nguyen</last><affiliation>CSIRO</affiliation></author>
      <author><first>Xiang</first><last>Dai</last><affiliation>CSIRO</affiliation></author>
      <author><first>Diego</first><last>Molla-Aliod</last><affiliation>Macquarie University</affiliation></author>
      <author><first>Cecile</first><last>Paris</last><affiliation>CSIRO</affiliation></author>
      <author><first>Sarvnaz</first><last>Karimi</last><affiliation>CSIRO</affiliation></author>
      <pages>197-202</pages>
      <abstract>Monitoring and predicting the expression of suicidal risk in individuals’ social media posts is a central focus in clinical NLP. Yet, existing approaches frequently lack a crucial explainability component necessary for extracting evidence related to an individual’s mental health state. We describe the CSIRO Data61 team’s evidence extraction system submitted to the CLPsych 2024 shared task. The task aims to investigate the zero-shot capabilities of open-source LLM in extracting evidence regarding an individual’s assigned suicide risk level from social media discourse. The results are assessed against ground truth evidence annotated by psychological experts, with an achieved recall-oriented BERTScore of 0.919. Our findings suggest that LLMs showcase strong feasibility in the extraction of information supporting the evaluation of suicidal risk in social media discourse. Opportunities for refinement exist, notably in crafting concise and effective instructions to guide the extraction process.</abstract>
      <url hash="0d25df1a">2024.clpsych-1.17</url>
      <bibkey>chen-etal-2024-exploring</bibkey>
    </paper>
    <paper id="18">
      <title>Psychological Assessments with Large Language Models: A Privacy-Focused and Cost-Effective Approach</title>
      <author><first>Sergi</first><last>Blanco-Cuaresma</last><affiliation>Harvard-Smithsonian Center for Astrophysics</affiliation></author>
      <pages>203-210</pages>
      <abstract>This study explores the use of Large Language Models (LLMs) to analyze text comments from Reddit users, aiming to achieve two primary objectives: firstly, to pinpoint critical excerpts that support a predefined psychological assessment of suicidal risk; and secondly, to summarize the material to substantiate the preassigned suicidal risk level. The work is circumscribed to the use of “open-source” LLMs that can be run locally, thereby enhancing data privacy. Furthermore, it prioritizes models with low computational requirements, making it accessible to both individuals and institutions operating on limited computing budgets. The implemented strategy only relies on a carefully crafted prompt and a grammar to guide the LLM’s text completion. Despite its simplicity, the evaluation metrics show outstanding results, making it a valuable privacy-focused and cost-effective approach. This work is part of the Computational Linguistics and Clinical Psychology (CLPsych) 2024 shared task.</abstract>
      <url hash="0423b5e6">2024.clpsych-1.18</url>
      <bibkey>blanco-cuaresma-2024-psychological</bibkey>
    </paper>
    <paper id="19">
      <title>Incorporating Word Count Information into Depression Risk Summary Generation: <fixed-case>INF</fixed-case>@<fixed-case>U</fixed-case>o<fixed-case>S</fixed-case> <fixed-case>CLP</fixed-case>sych 2024 Submission</title>
      <author><first>Judita</first><last>Preiss</last><affiliation>University of Sheffield</affiliation></author>
      <author><first>Zenan</first><last>Chen</last><affiliation>University of Sheffield</affiliation></author>
      <pages>211-217</pages>
      <abstract>Large language model classifiers do not directly offer transparency: it is not clear why one class is chosen over another. In this work, summaries explaining the suicide risk level assigned using a fine-tuned mental-roberta-base model are generated from key phrases extracted using SHAP explainability using Mistral-7B. The training data for the classifier consists of all Reddit posts of a user in the University of Maryland Reddit Suicidality Dataset, Version 2, with their suicide risk labels along with selected features extracted from each post by the Linguistic Inquiry and Word Count (LIWC-22) tool. The resulting model is used to make predictions regarding risk on each post of the users in the evaluation set of the CLPsych 2024 shared task, with a SHAP explainer used to identify the phrases contributing to the top scoring, correct and severe risk categories. Some basic stoplisting is applied to the extracted phrases, along with length based filtering, and a locally run version of Mistral-7B-Instruct-v0.1 is used to create summaries from the highest value (based on SHAP) phrases.</abstract>
      <url hash="4388c862">2024.clpsych-1.19</url>
      <bibkey>preiss-chen-2024-incorporating</bibkey>
    </paper>
    <paper id="20">
      <title>Extracting and Summarizing Evidence of Suicidal Ideation in Social Media Contents Using Large Language Models</title>
      <author><first>Loitongbam</first><last>Gyanendro Singh</last><affiliation>University of Southampton</affiliation></author>
      <author><first>Junyu</first><last>Mao</last><affiliation>University of Southampton</affiliation></author>
      <author><first>Rudra</first><last>Mutalik</last><affiliation>University of Southampton</affiliation></author>
      <author><first>Stuart</first><last>Middleton</last><affiliation>University of Southampton</affiliation></author>
      <pages>218-226</pages>
      <abstract>This paper explores the use of Large Language Models (LLMs) in analyzing social media content for mental health monitoring, specifically focusing on detecting and summarizing evidence of suicidal ideation. We utilized LLMs Mixtral7bx8 and Tulu-2-DPO-70B, applying diverse prompting strategies for effective content extraction and summarization. Our methodology included detailed analysis through Few-shot and Zero-shot learning, evaluating the ability of Chain-of-Thought and Direct prompting strategies. The study achieved notable success in the CLPsych 2024 shared task (ranked top for the evidence extraction task and second for the summarization task), demonstrating the potential of LLMs in mental health interventions and setting a precedent for future research in digital mental health monitoring.</abstract>
      <url hash="890c4a2e">2024.clpsych-1.20</url>
      <bibkey>gyanendro-singh-etal-2024-extracting</bibkey>
    </paper>
    <paper id="21">
      <title>Detecting Suicide Risk Patterns using Hierarchical Attention Networks with Large Language Models</title>
      <author><first>Koushik</first><last>L</last><affiliation>Student, NITK</affiliation></author>
      <author><first>Vishruth</first><last>M</last><affiliation>National Institute of Technology Karnataka</affiliation></author>
      <author><first>Anand Kumar</first><last>M</last><affiliation>National Institute of Technology Karnataka</affiliation></author>
      <pages>227-231</pages>
      <abstract>Suicide has become a major public health and social concern in the world . This Paper looks into a method through use of LLMs (Large Lan- guage Model) to extract the likely reason for a person to attempt suicide , through analysis of their social media text posts detailing about the event , using this data we can extract the rea- son for the cause such mental state which can provide support for suicide prevention. This submission presents our approach for CLPsych Shared Task 2024. Our model uses Hierarchi- cal Attention Networks (HAN) and Llama2 for finding supporting evidence about an individ- ual’s suicide risk level.</abstract>
      <url hash="326e0638">2024.clpsych-1.21</url>
      <bibkey>l-etal-2024-detecting</bibkey>
    </paper>
    <paper id="22">
      <title>Using Large Language Models (<fixed-case>LLM</fixed-case>s) to Extract Evidence from Pre-Annotated Social Media Data</title>
      <author><first>Falwah</first><last>Alhamed</last><affiliation>Imperial College London</affiliation></author>
      <author><first>Julia</first><last>Ive</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Lucia</first><last>Specia</last><affiliation>Imperial College London</affiliation></author>
      <pages>232-237</pages>
      <abstract>For numerous years, researchers have employed social media data to gain insights into users’ mental health. Nevertheless, the majority of investigations concentrate on categorizing users into those experiencing depression and those considered healthy, or on detection of suicidal thoughts. In this paper, we aim to extract evidence of a pre-assigned gold label. We used a suicidality dataset containing Reddit posts labeled with the suicide risk level. The task is to use Large Language Models (LLMs) to extract evidence from the post that justifies the given label. We used Meta Llama 7b and lexicons for solving the task and we achieved a precision of 0.96.</abstract>
      <url hash="fe5d1841">2024.clpsych-1.22</url>
      <bibkey>alhamed-etal-2024-using</bibkey>
    </paper>
    <paper id="23">
      <title><fixed-case>X</fixed-case>in<fixed-case>H</fixed-case>ai@<fixed-case>CLP</fixed-case>sych 2024 Shared Task: Prompting Healthcare-oriented <fixed-case>LLM</fixed-case>s for Evidence Highlighting in Posts with Suicide Risk</title>
      <author><first>Jingwei</first><last>Zhu</last><affiliation>University of Science and Technology of China</affiliation></author>
      <author><first>Ancheng</first><last>Xu</last><affiliation>Shenzhen Institutes of Advanced Technology</affiliation></author>
      <author><first>Minghuan</first><last>Tan</last><affiliation>Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences</affiliation></author>
      <author><first>Min</first><last>Yang</last><affiliation>Chinese Academy of Sciences</affiliation></author>
      <pages>238-246</pages>
      <abstract>In this article, we introduce a new method for analyzing and summarizing posts from r/SuicideWatch on Reddit, overcoming the limitations of current techniques in processing complex mental health discussions online. Existing methods often struggle to accurately identify and contextualize subtle expressions of mental health problems, leading to inadequate support and intervention strategies. Our approach combines the open-source Large Language Model (LLM), fine-tuned with health-oriented knowledge, to effectively process Reddit posts. We also design prompts that focus on suicide-related statements, extracting key statements, and generating concise summaries that capture the core aspects of the discussions. The preliminary results indicate that our method improves the understanding of online suicide-related posts compared to existing methodologies.</abstract>
      <url hash="fd9388ac">2024.clpsych-1.23</url>
      <bibkey>zhu-etal-2024-xinhai</bibkey>
    </paper>
    <paper id="24">
      <title>A Dual-Prompting for Interpretable Mental Health Language Models</title>
      <author><first>Hyolim</first><last>Jeon</last><affiliation>Sungkyunkwan University</affiliation></author>
      <author><first>Dongje</first><last>Yoo</last><affiliation>Chung-Ang University</affiliation></author>
      <author><first>Daeun</first><last>Lee</last><affiliation>sungkyunkwan university</affiliation></author>
      <author><first>Sejung</first><last>Son</last><affiliation>Sungkyunkwan University</affiliation></author>
      <author><first>Seungbae</first><last>Kim</last><affiliation>University of South Florida</affiliation></author>
      <author><first>Jinyoung</first><last>Han</last><affiliation>Sungkyunkwan University</affiliation></author>
      <pages>247-255</pages>
      <abstract>Despite the increasing demand for AI-based mental health monitoring tools, their practical utility for clinicians is limited by the lack of interpretability. The CLPsych 2024 Shared Task (Chim et al., 2024) aims to enhance the interpretability of Large Language Models (LLMs), particularly in mental health analysis, by providing evidence of suicidality through linguistic content. We propose a dual-prompting approach: (i) Knowledge-aware evidence extraction by leveraging the expert identity and a suicide dictionary with a mental health-specific LLM; and (ii) Evidence summarization by employing an LLM-based consistency evaluator. Comprehensive experiments demonstrate the effectiveness of combining domain-specific information, revealing performance improvements and the approach’s potential to aid clinicians in assessing mental state progression.</abstract>
      <url hash="ed86b2b5">2024.clpsych-1.24</url>
      <bibkey>jeon-etal-2024-dual</bibkey>
    </paper>
    <paper id="25">
      <title>Cheap Ways of Extracting Clinical Markers from Texts</title>
      <author><first>Anastasia</first><last>Sandu</last><affiliation>University of Bucharest</affiliation></author>
      <author><first>Teodor</first><last>Mihailescu</last><affiliation>University of Bucharest</affiliation></author>
      <author><first>Sergiu</first><last>Nisioi</last><affiliation>Human Language Technologies Research Center, University of Bucharest</affiliation></author>
      <pages>256-263</pages>
      <abstract>This paper describes the Unibuc Archaeology team work for CLPsych’s 2024 Shared Task that involved finding evidence within the text supporting the assigned suicide risk level. Two types of evidence were required: highlights (extracting relevant spans within the text) and summaries (aggregating evidence into a synthesis). Our work focuses on evaluating Large Language Models (LLM) as opposed to an alternative method that is much more memory and resource efficient. The first approach employs an LLM that is used for generating the summaries and is guided to provide sequences of text indicating suicidal tendencies through a processing chain for highlights. The second approach involves implementing a good old-fashioned machine learning tf-idf with a logistic regression classifier, whose representative features we use to extract relevant highlights.</abstract>
      <url hash="233c541e">2024.clpsych-1.25</url>
      <bibkey>sandu-etal-2024-cheap</bibkey>
    </paper>
    <paper id="26">
      <title>Utilizing Large Language Models to Identify Evidence of Suicidality Risk through Analysis of Emotionally Charged Posts</title>
      <author><first>Ahmet Yavuz</first><last>Uluslu</last><affiliation>University of Zurich</affiliation></author>
      <author><first>Andrianos</first><last>Michail</last><affiliation>University of Zurich</affiliation></author>
      <author><first>Simon</first><last>Clematide</last><affiliation>University of Zurich</affiliation></author>
      <pages>264-269</pages>
      <abstract>This paper presents our contribution to the CLPsych 2024 shared task, focusing on the use of open-source large language models (LLMs) for suicide risk assessment through the analysis of social media posts. We achieved first place (out of 15 participating teams) in the task of providing summarized evidence of a user’s suicide risk. Our approach is based on Retrieval Augmented Generation (RAG), where we retrieve the top-k (k=5) posts with the highest emotional charge and provide the level of three different negative emotions (sadness, fear, anger) for each post during the generation phase.</abstract>
      <url hash="c333966f">2024.clpsych-1.26</url>
      <bibkey>uluslu-etal-2024-utilizing</bibkey>
    </paper>
    <paper id="27">
      <title>Integrating Supervised Extractive and Generative Language Models for Suicide Risk Evidence Summarization</title>
      <author><first>Rika</first><last>Tanaka</last><affiliation>Sophia University Graduate School</affiliation></author>
      <author><first>Yusuke</first><last>Fukazawa</last><affiliation>Sophia University Graduate School</affiliation></author>
      <pages>270-277</pages>
      <abstract>We propose a method that integrates supervised extractive and generative language models for providing supporting evidence of suicide risk in the CLPsych 2024 shared task. Our approach comprises three steps. Initially, we construct a BERT-based model for estimating sentence-level suicide risk and negative sentiment. Next, we precisely identify high suicide risk sentences by emphasizing elevated probabilities of both suicide risk and negative sentiment. Finally, we integrate generative summaries using the MentaLLaMa framework and extractive summaries from identified high suicide risk sentences and a specialized dictionary of suicidal risk words. SophiaADS, our team, achieved 1st place for highlight extraction and ranked 10th for summary generation, both based on recall and consistency metrics, respectively.</abstract>
      <url hash="e7f6935e">2024.clpsych-1.27</url>
      <bibkey>tanaka-fukazawa-2024-integrating</bibkey>
    </paper>
    <paper id="28">
      <title>Archetypes and Entropy: Theory-Driven Extraction of Evidence for Suicide Risk</title>
      <author><first>Vasudha</first><last>Varadarajan</last><affiliation>Stony Brook University</affiliation></author>
      <author><first>Allison</first><last>Lahnala</last><affiliation>University of Bonn</affiliation></author>
      <author><first>Adithya</first><last>V Ganesan</last><affiliation>Stony Brook University</affiliation></author>
      <author><first>Gourab</first><last>Dey</last><affiliation>Stony Brook University, New York</affiliation></author>
      <author><first>Siddharth</first><last>Mangalik</last><affiliation>Stony Brook University</affiliation></author>
      <author><first>Ana-Maria</first><last>Bucur</last><affiliation>Interdisciplinary School of Doctoral Studies</affiliation></author>
      <author><first>Nikita</first><last>Soni</last><affiliation>Stony Brook University</affiliation></author>
      <author><first>Rajath</first><last>Rao</last><affiliation>Stony Brook University</affiliation></author>
      <author><first>Kevin</first><last>Lanning</last><affiliation>Wilkes Honors College, Florida Atlantic University</affiliation></author>
      <author><first>Isabella</first><last>Vallejo</last><affiliation>Wilkes Honors College, Florida Atlantic University</affiliation></author>
      <author><first>Lucie</first><last>Flek</last><affiliation>CAISA Lab, University of Bonn</affiliation></author>
      <author><first>H. Andrew</first><last>Schwartz</last><affiliation>Stony Brook University</affiliation></author>
      <author><first>Charles</first><last>Welch</last><affiliation>University of Bonn</affiliation></author>
      <author><first>Ryan</first><last>Boyd</last><affiliation>Stony Brook University</affiliation></author>
      <pages>278-291</pages>
      <abstract>Research on psychological risk factors for suicide has developed for decades. However, combining explainable theory with modern data-driven language model approaches is non-trivial. In this study, we propose and evaluate methods for identifying language patterns aligned with theories of suicide risk by combining theory-driven suicidal archetypes with language model-based and relative entropy-based approaches. Archetypes are based on prototypical statements that evince risk of suicidality while relative entropy considers the ratio of how unusual both a risk-familiar and unfamiliar model find the statements. While both approaches independently performed similarly, we find that combining the two significantly improved the performance in the shared task evaluations, yielding our combined system submission with a BERTScore Recall of 0.906. Consistent with the literature, we find that titles are highly informative as suicide risk evidence, despite the brevity. We conclude that a combination of theory- and data-driven methods are needed in the mental health space and can outperform more modern prompt-based methods.</abstract>
      <url hash="fc1d5614">2024.clpsych-1.28</url>
      <bibkey>varadarajan-etal-2024-archetypes</bibkey>
    </paper>
  </volume>
</collection>
