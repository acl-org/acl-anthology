<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.finnlp">
  <volume id="1" ingest-date="2024-08-02" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Joint Workshop of the 7th Financial Technology and Natural Language Processing, the 5th Knowledge Discovery from Unstructured Data in Financial Services, and the 4th Workshop on Economics and Natural Language Processing</booktitle>
      <editor><first>Chung-Chi</first><last>Chen</last></editor>
      <editor><first>Xiaomo</first><last>Liu</last></editor>
      <editor><first>Udo</first><last>Hahn</last></editor>
      <editor><first>Armineh</first><last>Nourbakhsh</last></editor>
      <editor><first>Zhiqiang</first><last>Ma</last></editor>
      <editor><first>Charese</first><last>Smiley</last></editor>
      <editor><first>Veronique</first><last>Hoste</last></editor>
      <editor><first>Sanjiv Ranjan</first><last>Das</last></editor>
      <editor><first>Manling</first><last>Li</last></editor>
      <editor><first>Mohammad</first><last>Ghassemi</last></editor>
      <editor><first>Hen-Hsen</first><last>Huang</last></editor>
      <editor><first>Hiroya</first><last>Takamura</last></editor>
      <editor><first>Hsin-Hsi</first><last>Chen</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Torino, Italia</address>
      <month>May</month>
      <year>2024</year>
      <url hash="7c3ac348">2024.finnlp-1</url>
      <venue>finnlp</venue>
    </meta>
    <frontmatter>
      <url hash="cf58cc77">2024.finnlp-1.0</url>
      <bibkey>finnlp-2024-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Construction of a <fixed-case>J</fixed-case>apanese Financial Benchmark for Large Language Models</title>
      <author><first>Masanori</first><last>Hirano</last></author>
      <pages>1–9</pages>
      <abstract>With the recent development of large language models (LLMs), models that focus on certain domains and languages have been discussed for their necessity. There is also a growing need for benchmarks to evaluate the performance of current LLMs in each domain. Therefore, in this study, we constructed a benchmark comprising multiple tasks specific to the Japanese and financial domains and performed benchmark measurements on some models. Consequently , we confirmed that GPT-4 is currently outstanding, and that the constructed benchmarks function effectively. According to our analysis, our benchmark can differentiate benchmark scores among models in all performance ranges by combining tasks with different difficulties.</abstract>
      <url hash="028ada0a">2024.finnlp-1.1</url>
      <bibkey>hirano-2024-construction</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>KRX</fixed-case> Bench: Automating Financial Benchmark Creation via Large Language Models</title>
      <author><first>Guijin</first><last>Son</last></author>
      <author><first>Hyunjun</first><last>Jeon</last></author>
      <author><first>Chami</first><last>Hwang</last></author>
      <author><first>Hanearl</first><last>Jung</last></author>
      <pages>10–20</pages>
      <abstract>In this work, we introduce KRX-Bench, an automated pipeline for creating financial benchmarks via GPT-4. To demonstrate the effectiveness of the pipeline, we create KRX-Bench-POC, a benchmark assessing the knowledge of LLMs in real-world companies. This dataset comprises 1,002 questions, each focusing on companies across the U.S., Japanese, and Korean stock markets. We make our pipeline and dataset publicly available and integrate the evaluation code into EleutherAI’s Language Model Evaluation Harness.</abstract>
      <url hash="30b6578b">2024.finnlp-1.2</url>
      <bibkey>son-etal-2024-krx</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>BLU</fixed-case>-<fixed-case>S</fixed-case>yn<fixed-case>T</fixed-case>ra: Distinguish Synergies and Trade-offs between Sustainable Development Goals Using Small Language Models</title>
      <author><first>Loris</first><last>Bergeron</last></author>
      <author><first>Jerome</first><last>Francois</last></author>
      <author><first>Radu</first><last>State</last></author>
      <author><first>Jean</first><last>Hilger</last></author>
      <pages>21–33</pages>
      <abstract>Since the United Nations defined the Sustainable Development Goals, studies have shown that these goals are interlinked in different ways. The concept of SDG interlinkages refers to the complex network of interactions existing within and between the SDGs themselves. These interactions are referred to as synergies and trade-offs. Synergies represent positive interactions where the progress of one SDG contributes positively to the progress of another. On the other hand, trade-offs are negative interactions where the progress of one SDG has a negative impact on another. However, evaluating such interlinkages is a complex task, not only because of the multidimensional nature of SDGs, but also because it is highly exposed to personal interpretation bias and technical limitations. Recent studies are mainly based on expert judgements, literature reviews, sentiment or data analysis. To remedy these limitations we propose the use of Small Language Models in addition of an advanced Retrieval Augmented Generation to distinguish synergies and trade-offs between SDGs. In order to validate our results, we have drawn on the study carried out by the European Commission’s Joint Research Centre which provides a database of interlinkages labelled according to the presence of synergies or trade-offs.</abstract>
      <url hash="831c5a4b">2024.finnlp-1.3</url>
      <bibkey>bergeron-etal-2024-blu</bibkey>
    </paper>
    <paper id="4">
      <title>Assessing the Impact of <fixed-case>ESG</fixed-case>-Related News on Stock Trading in the <fixed-case>I</fixed-case>ndonesian Market: A Text Similarity Framework Approach</title>
      <author><first>Okiriza</first><last>Wibisono</last></author>
      <author><first>Ali Akbar</first><last>Septiandri</last></author>
      <author><first>Reinhard Denis</first><last>Najogie</last></author>
      <pages>34–39</pages>
      <abstract>Environmental, Social, and Governance (ESG) perspectives have become integral to corporate decision-making and investment, with global regulatory mandates for ESG disclosure. The reliability of ESG ratings, crucial for assessing corporate sustainability practices, is compromised by inconsistencies and discrepancies across and within rating agencies, casting doubt on their effectiveness in reflecting true ESG performance and impact on firm valuations. While there have been studies using ESG-related news articles to measure their effect on stock trading, none have studied the Indonesian stock market. To address this gap, we developed a text similarity framework to identify ESG-related news articles based on Sustainability Accounting Standards Board (SASB) Standards without the need for manual annotations. Using news articles from one of the prominent business media outlets in Indonesia and an event study method, we found that 17.9% out of 18,431 environment-related news are followed by increased stock trading on the firms mentioned in the news, compared to 16.0% on random-dates datasets of the same size and firm composition. This approach is intended as a simpler alternative to building an ESG-specific news labeling model or using third-party data providers, although further analyses may be required to evaluate its robustness.</abstract>
      <url hash="47a7f649">2024.finnlp-1.4</url>
      <bibkey>wibisono-etal-2024-assessing</bibkey>
    </paper>
    <paper id="5">
      <title>Development and Evaluation of a <fixed-case>G</fixed-case>erman Language Model for the Financial Domain</title>
      <author><first>Nata</first><last>Kozaeva</last></author>
      <author><first>Serhii</first><last>Hamotskyi</last></author>
      <author><first>Christian</first><last>Hanig</last></author>
      <pages>40–49</pages>
      <abstract>Recent advancements in self-supervised pre-training of Language Models (LMs) have significantly improved their performance across a wide range of Natural Language Processing (NLP) tasks. Yet, the adaptation of these models to specialized domains remains a critical endeavor, as it enables the models to grasp domain-specific nuances, terminology, and patterns more effectively, thereby enhancing their utility in specialized contexts. This paper presents an in-depth investigation into the training and fine-tuning of German language models specifically for the financial sector. We construct various datasets for training and fine-tuning to examine the impact of different data construction strategies on the models’ performance. Our study provides detailed insights into essential pre-processing steps, including text extraction from PDF documents and language identification, to evaluate their influence on the performance of the language models. Addressing the scarcity of resources in the German financial domain, we also introduce a German Text Classification benchmark dataset, aimed at fostering further research and development in this area. The performance of the trained models is evaluated on two domain-specific tasks, demonstrating that fine-tuning with domain-specific data improves model outcomes, even with limited amounts of domain-specific data.</abstract>
      <url hash="b75553c0">2024.finnlp-1.5</url>
      <bibkey>kozaeva-etal-2024-development</bibkey>
    </paper>
    <paper id="6">
      <title>Evaluating Multilingual Language Models for Cross-Lingual <fixed-case>ESG</fixed-case> Issue Identification</title>
      <author><first>Wing Yan</first><last>Li</last></author>
      <author><first>Emmanuele</first><last>Chersoni</last></author>
      <author><first>Cindy Sing Bik</first><last>Ngai</last></author>
      <pages>50–58</pages>
      <abstract>The automation of information extraction from ESG reports has recently become a topic of increasing interest in the Natural Language Processing community. While such information is highly relevant for socially responsible investments, identifying the specific issues discussed in a corporate social responsibility report is one of the first steps in an information extraction pipeline. In this paper, we evaluate methods for tackling the Multilingual Environmental, Social and Governance (ESG) Issue Identification Task. Our experiments use existing datasets in English, French and Chinese with a unified label set. Leveraging multilingual language models, we compare two approaches that are commonly adopted for the given task: off-the-shelf and fine-tuning. We show that fine-tuning models end-to-end is more robust than off-the-shelf methods. Additionally, translating text into the same language has negligible performance benefits.</abstract>
      <url hash="696607ea">2024.finnlp-1.6</url>
      <bibkey>li-etal-2024-evaluating-multilingual</bibkey>
    </paper>
    <paper id="7">
      <title>Modal-adaptive Knowledge-enhanced Graph-based Financial Prediction from Monetary Policy Conference Calls with <fixed-case>LLM</fixed-case></title>
      <author><first>Kun</first><last>Ouyang</last></author>
      <author><first>Yi</first><last>Liu</last></author>
      <author><first>Shicheng</first><last>Li</last></author>
      <author><first>Ruihan</first><last>Bao</last></author>
      <author><first>Keiko</first><last>Harimoto</last></author>
      <author><first>Xu</first><last>Sun</last></author>
      <pages>59–69</pages>
      <abstract>Financial prediction from Monetary Policy Conference (MPC) calls is a new yet challenging task, which targets at predicting the price movement and volatility for specific financial assets by analyzing multimodal information including text, video, and audio. Although the existing work has achieved great success using cross-modal transformer blocks, it overlooks the potential external financial knowledge, the varying contributions of different modalities to financial prediction, as well as the innate relations among different financial assets. To tackle these limitations, we propose a novel Modal-Adaptive kNowledge-enhAnced Graph-basEd financial pRediction scheme, named MANAGER. Specifically, MANAGER resorts to FinDKG to obtain the external related knowledge for the input text. Meanwhile, MANAGER adopts BEiT-3 and Hidden-unit BERT (HuBERT) to extract the video and audio features, respectively. Thereafter, MANAGER introduces a novel knowledge-enhanced cross-modal graph that fully characterizes the semantic relations among text, external knowledge, video and audio, to adaptively utilize the information in different modalities, with ChatGLM2 as the backbone. Extensive experiments on a publicly available dataset Monopoly verify the superiority of our model over cutting-edge methods.</abstract>
      <url hash="4e9e5732">2024.finnlp-1.7</url>
      <bibkey>ouyang-etal-2024-modal</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>N</fixed-case>et<fixed-case>Z</fixed-case>ero<fixed-case>F</fixed-case>acts: Two-Stage Emission Information Extraction from Company Reports</title>
      <author><first>Marco</first><last>Wrzalik</last></author>
      <author><first>Florian</first><last>Faust</last></author>
      <author><first>Simon</first><last>Sieber</last></author>
      <author><first>Adrian</first><last>Ulges</last></author>
      <pages>70–84</pages>
      <abstract>We address the challenge of efficiently extracting structured emission information, specifically emission goals, from company reports. Leveraging the potential of Large Language Models (LLMs), we propose a two-stage pipeline that first filters and retrieves potentially relevant passages and then extracts structured information from them using a generative model. We contribute an annotated dataset covering over 14.000 text passages, from which we extracted 739 expert annotated facts. On this dataset, we investigate the accuracy, efficiency and limitations of LLM-based emission information extraction, evaluate different retrieval techniques, and assess efficiency gains for human analysts by using the proposed pipeline. Our research demonstrates the promise of LLM technology in addressing the intricate task of sustainable emission data extraction from company reports.</abstract>
      <url hash="d09bd80b">2024.finnlp-1.8</url>
      <bibkey>wrzalik-etal-2024-netzerofacts</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>FB</fixed-case>-<fixed-case>GAN</fixed-case>: A Novel Neural Sentiment-Enhanced Model for Stock Price Prediction</title>
      <author><first>Jainendra Kumar</first><last>Jain</last></author>
      <author><first>Ruchit</first><last>Agrawal</last></author>
      <pages>85–93</pages>
      <abstract>Predicting stock prices remains a significant challenge in financial markets. This study explores existing stock price prediction systems, identifies their strengths and weaknesses, and proposes a novel method for stock price prediction that leverages a state-of-the-art neural network framework, combining the BERT language model for sentiment analysis on news articles and the GAN model for stock price prediction. We introduce the FB-GAN model, an ensemble model that leverages stock price history and market sentiment score for more accurate stock price prediction and propose effective strategies to capture the market sentiment. We conduct experiments on stock price prediction for five major equities (Amazon, Apple, Microsoft, Nvidia, and Adobe), and compare the performance obtained by our proposed model against the existing state-of-the-art baseline model. The results demonstrate that our proposed model outperforms existing models across the five major equities. We demonstrate that the strategic incorporation of market sentiment using both headlines as well summaries of news articles significantly enhances the accuracy and robustness of stock price prediction.</abstract>
      <url hash="ac277864">2024.finnlp-1.9</url>
      <bibkey>jain-agrawal-2024-fb</bibkey>
    </paper>
    <paper id="10">
      <title>Unveiling Currency Market Dynamics: Leveraging Federal Reserve Communications for Strategic Investment Insights</title>
      <author><first>Martina</first><last>Menzio</last></author>
      <author><first>Davide</first><last>Paris</last></author>
      <author><first>Elisabetta</first><last>Fersini</last></author>
      <pages>94–102</pages>
      <abstract>The purpose of this paper is to extract market signals for the major currencies (EUR, USD, GBP, JPY, CNY) analyzing the Federal Reserve System (FED) minutes and speeches, and, consequently, making suggestions about going long/short or remaining neutral to investors thanks to the causal relationships between FED sentiment and currency exchange rates. To this purpose, we aim to verify the hypothesis that the currency market dynamics follow a trend that is subject to the sentiment of FED minutes and speeches related to specific relevant currencies. The proposed paper has highlighted two main findings: (1) the sentiment expressed in the FED minutes has a strong influence on financial market predictability on major currencies trend and (2) the sentiment over time Granger-causes the exchange rate of currencies not only immediately but also at increasing lags according to a monotonically decreasing impact.</abstract>
      <url hash="861e735e">2024.finnlp-1.10</url>
      <bibkey>menzio-etal-2024-unveiling</bibkey>
    </paper>
    <paper id="11">
      <title>Analysis of Material Facts on Financial Assets: A Generative <fixed-case>AI</fixed-case> Approach</title>
      <author><first>Gabriel</first><last>Assis</last></author>
      <author><first>Daniela</first><last>Vianna</last></author>
      <author><first>Gisele L.</first><last>Pappa</last></author>
      <author><first>Alexandre</first><last>Plastino</last></author>
      <author><first>Wagner</first><last>Meira Jr</last></author>
      <author><first>Altigran Soares</first><last>da Silva</last></author>
      <author><first>Aline</first><last>Paes</last></author>
      <pages>103–118</pages>
      <abstract>Material facts (MF) are crucial and obligatory disclosures that can significantly influence asset values. Following their release, financial analysts embark on the meticulous and highly specialized task of crafting analyses to shed light on their impact on company assets, a challenge elevated by the daily amount of MFs released. Generative AI, with its demonstrated power of crafting coherent text, emerges as a promising solution to this task. However, while these analyses must incorporate the MF, they must also transcend it, enhancing it with vital background information, valuable and grounded recommendations, prospects, potential risks, and their underlying reasoning. In this paper, we approach this task as an instance of controllable text generation, aiming to ensure adherence to the MF and other pivotal attributes as control elements. We first explore language models’ capacity to manage this task by embedding those elements into prompts and engaging popular chatbots. A bilingual proof of concept underscores both the potential and the challenges of applying generative AI techniques to this task.</abstract>
      <url hash="a4a125f5">2024.finnlp-1.11</url>
      <bibkey>assis-etal-2024-analysis</bibkey>
    </paper>
    <paper id="12">
      <title>Exploring Large Language Models in Financial Argument Relation Identification</title>
      <author><first>Yasser</first><last>Otiefy</last></author>
      <author><first>Alaa</first><last>Alhamzeh</last></author>
      <pages>119–129</pages>
      <abstract>In the dynamic landscape of financial analytics, the argumentation within Earnings Conference Calls (ECCs) provides valuable insights for investors and market participants. This paper delves into the automatic relation identification between argument components in this type of data, a poorly studied task in the literature. To tackle this challenge, we empirically examined and analysed a wide range of open-source models, as well as the Generative Pre-trained Transformer GPT-4. On the one hand, our experiments in open-source models spanned general-purpose models, debate-fine-tuned models, and financial-fine-tuned models. On the other hand, we assessed the performance of GPT-4 zero-shot learning on a financial argumentation dataset (FinArg). Our findings show that a smaller open-source model, fine-tuned on relevant data, can perform as a huger general-purpose one, showing the value of enriching the local embeddings with the semantic context of data. However, GPT-4 demonstrated superior performance with F1-score of 0.81, even with no given samples or shots. In this paper, we detail our data, models and experimental setup. We also provide further performance analysis from different aspects.</abstract>
      <url hash="92881cac">2024.finnlp-1.12</url>
      <bibkey>otiefy-alhamzeh-2024-exploring</bibkey>
    </paper>
    <paper id="13">
      <title>Keyword-based Annotation of Visually-Rich Document Content for Trend and Risk Analysis Using Large Language Models</title>
      <author><first>Giuseppe</first><last>Gallipoli</last></author>
      <author><first>Simone</first><last>Papicchio</last></author>
      <author><first>Lorenzo</first><last>Vaiani</last></author>
      <author><first>Luca</first><last>Cagliero</last></author>
      <author><first>Arianna</first><last>Miola</last></author>
      <author><first>Daniele</first><last>Borghi</last></author>
      <pages>130–136</pages>
      <abstract>In the banking and finance sectors, members of the business units focused on Trend and Risk Analysis daily process internal and external visually-rich documents including text, images, and tables. Given a facet (i.e., topic) of interest, they are particularly interested in retrieving the top trending keywords related to it and then use them to annotate the most relevant document elements (e.g., text paragraphs, images or tables). In this paper, we explore the use of both open-source and proprietary Large Language Models to automatically generate lists of facet-relevant keywords, automatically produce free-text descriptions of both keywords and multimedia document content, and then annotate documents by leveraging textual similarity approaches. The preliminary results, achieved on English and Italian documents, show that OpenAI GPT-4 achieves superior performance in keyword description generation and multimedia content annotation, while the open-source Meta AI Llama2 model turns out to be highly competitive in generating additional keywords.</abstract>
      <url hash="148ec301">2024.finnlp-1.13</url>
      <bibkey>gallipoli-etal-2024-keyword</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>ESG</fixed-case>-<fixed-case>FTSE</fixed-case>: A Corpus of News Articles with <fixed-case>ESG</fixed-case> Relevance Labels and Use Cases</title>
      <author><first>Mariya</first><last>Pavlova</last></author>
      <author><first>Bernard</first><last>Casey</last></author>
      <author><first>Miaosen</first><last>Wang</last></author>
      <pages>137–149</pages>
      <abstract>We present ESG-FTSE, the first corpus comprised of news articles with Environmental, Social and Governance (ESG) relevance annotations. In recent years, investors and regulators have pushed ESG investing to the mainstream due to the urgency of climate change. This has led to the rise of ESG scores to evaluate an investment’s credentials as socially responsible. While demand for ESG scores is high, their quality varies wildly. Quantitative techniques can be applied to improve ESG scores, thus, responsible investing. To contribute to resource building for ESG and financial text mining, we pioneer the ESG-FTSE corpus. We further present the first of its kind ESG annotation schema. It has three levels: a binary classification (relevant versus irrelevant news articles), ESG classification (ESG-related news articles), and target company. Both supervised and unsupervised learning experiments for ESG relevance detection were conducted to demonstrate that the corpus can be used in different settings to derive accurate ESG predictions.</abstract>
      <url hash="22309961">2024.finnlp-1.14</url>
      <attachment type="OptionalSupplementaryMaterial" hash="196544a8">2024.finnlp-1.14.OptionalSupplementaryMaterial.zip</attachment>
      <bibkey>pavlova-etal-2024-esg</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>BBRC</fixed-case>: <fixed-case>B</fixed-case>razilian Banking Regulation Corpora</title>
      <author><first>Rafael</first><last>Faria de Azevedo</last></author>
      <author><first>Thiago Henrique</first><last>Eduardo Muniz</last></author>
      <author><first>Claudio</first><last>Pimentel</last></author>
      <author><first>Guilherme</first><last>Jose de Assis Foureaux</last></author>
      <author><first>Barbara</first><last>Caldeira Macedo</last></author>
      <author><first>Daniel de Lima</first><last>Vasconcelos</last></author>
      <pages>150–166</pages>
      <abstract>We present BBRC, a collection of 25 corpus of banking regulatory risk from different departments of Banco do Brasil (BB). These are individual corpus about investments, insurance, human resources, security, technology, treasury, loans, accounting, fraud, credit cards, payment methods, agribusiness, risks, etc. They were annotated in binary form by experts indicating whether each regulatory document contains regulatory risk that may require changes to products, processes, services, and channels of a bank department or not. The corpora in Portuguese contain documents from 26 Brazilian regulatory authorities in the financial sector. In total, there are 61,650 annotated documents, mostly between half and three pages long. The corpora belong to a Natural Language Processing (NLP) application that has been in production since 2020. In this work, we also performed binary classification benchmarks with some of the corpus. Experiments were carried out with different sampling techniques and in one of them we sought to solve an intraclass imbalance problem present in each corpus of the corpora. For the benchmarks, we used the following classifiers: Multinomial Naive Bayes, Random Forest, SVM, XGBoost, and BERTimbau (a version of BERT for Portuguese). The BBRC can be downloaded through a link in the article.</abstract>
      <url hash="8b16a55b">2024.finnlp-1.15</url>
      <bibkey>faria-de-azevedo-etal-2024-bbrc</bibkey>
    </paper>
    <paper id="16">
      <title>Stock Price Prediction with Sentiment Analysis for <fixed-case>C</fixed-case>hinese Market</title>
      <author><first>Yuchen</first><last>Luan</last></author>
      <author><first>Haiyang</first><last>Zhang</last></author>
      <author><first>Chenlei</first><last>Zhang</last></author>
      <author><first>Yida</first><last>Mu</last></author>
      <author><first>Wei</first><last>Wang</last></author>
      <pages>167–177</pages>
      <abstract>Accurate prediction of stock prices is considered as a significant practical challenge and has been a longstanding topic of debate within the economic domain. In recent years, sentiment analysis on social media comments has been considered an important data source for stock prediction. However, most of these works focus on exploring stocks with high market values or from specific industries. The extent to which sentiments affect a broader range of stocks and their overall performance remains uncertain. In this paper, we study the influence of sentiment analysis on stock price prediction with respect to (1) different market value groups and (2) different Book-to-Market ratio groups in the Chinese stock market. To this end, we create a new dataset that consists of 24 stocks across different market value groups and Book-to-Market ratio categories, along with 12,000 associated comments that have been collected and manually annotated. We then utilized this dataset to train a variety of sentiment classifiers, which were subsequently integrated into sequential neural-based models for stock price prediction. Experimental findings indicate that while sentiment integration generally improve the predictive performance for price prediction, it may not consistently lead to better results for individual stocks. Moreover, these outcomes are notably influenced by varying market values and Book-to-Market ratios, with stocks of higher market values and B/M ratios often exhibiting more accurate predictions. Among all the models tested, the Bi-LSTM model incorporated with the sentiment analysis, achieves the best prediction performance.</abstract>
      <url hash="c3a9ba67">2024.finnlp-1.16</url>
      <bibkey>luan-etal-2024-stock</bibkey>
    </paper>
    <paper id="17">
      <title>Topic Taxonomy Construction from <fixed-case>ESG</fixed-case> Reports</title>
      <author><first>Saif Majdi</first><last>AlNajjar</last></author>
      <author><first>Xinyu</first><last>Wang</last></author>
      <author><first>Yulan</first><last>He</last></author>
      <pages>178–187</pages>
      <abstract>The surge in Environmental, Societal, and Governance (ESG) reports, essential for corporate transparency and modern investments, presents a challenge for investors due to their varying lengths and sheer volume. We present a novel methodology, called MultiTaxoGen, for creating topic taxonomies designed specifically for analysing the ESG reports. Topic taxonomies serve to illustrate topics covered in a corpus of ESG reports while also highlighting the hierarchical relationships between them. Unfortunately, current state-of-the-art approaches for constructing topic taxonomies are designed for more general datasets, resulting in ambiguous topics and the omission of many latent topics presented in ESG-focused corpora. This makes them unsuitable for the specificity required by investors. Our method instead adapts topic modelling techniques by employing them recursively on each topic’s local neighbourhood, the subcorpus of documents assigned to that topic. This iterative approach allows us to identify the children topics and offers a better understanding of topic hierarchies in a fine-grained paradigm. Our findings reveal that our method captures more latent topics in our ESG report corpus than the leading method and provides more coherent topics with comparable relational accuracy.</abstract>
      <url hash="8ed8caa5">2024.finnlp-1.17</url>
      <bibkey>alnajjar-etal-2024-topic</bibkey>
    </paper>
    <paper id="18">
      <title>Duration Dynamics: Fin-Turbo’s Rapid Route to <fixed-case>ESG</fixed-case> Impact Insight</title>
      <author><first>Weijie</first><last>Yang</last></author>
      <author><first>Xinyun</first><last>Rong</last></author>
      <pages>188–196</pages>
      <abstract>This study introduces “Duration Dynamics: Fin-Turbo’s Rapid Route to ESG Impact Insight”, an innovative approach employing advanced Natural Language Processing (NLP) techniques to assess the impact duration of ESG events on corporations. Leveraging a unique dataset comprising multilingual news articles, the research explores the utility of machine translation for language uniformity, text segmentation for contextual understanding, data augmentation for dataset balance, and an ensemble learning method integrating models like ESG-BERT, RoBERTa, DeBERTa, and Flan-T5 for nuanced analysis. Yielding excellent results, our research showcases the potential of using language models to improve ESG-oriented decision-making, contributing valuable insights to the FinNLP community.</abstract>
      <url hash="2fd6571d">2024.finnlp-1.18</url>
      <bibkey>yang-rong-2024-duration</bibkey>
    </paper>
    <paper id="19">
      <title>Multilingual <fixed-case>ESG</fixed-case> News Impact Identification Using an Augmented Ensemble Approach</title>
      <author><first>Harika</first><last>Abburi</last></author>
      <author><first>Ajay</first><last>Kumar</last></author>
      <author><first>Edward</first><last>Bowen</last></author>
      <author><first>Balaji</first><last>Veeramani</last></author>
      <pages>197–202</pages>
      <abstract>Determining the duration and length of a news event’s impact on a company’s performance remains elusive for financial analysts. The complexity arises from the fact that the effects of these news articles are influenced by various extraneous factors and can change over time. As a result, in this work, we investigate our ability to predict 1) the duration (length) of a news event’s impact, and 2) level of impact on companies. The datasets used in this study are provided as part of the Multi-Lingual ESG Impact Duration Inference (ML-ESG-3) shared task. To handle the data scarcity, we explored data augmentation techniques to augment our training data. To address each of the research objectives stated above, we employ an ensemble approach combining transformer model, a variant of Convolutional Neural Networks (CNNs), specifically the KimCNN model and contextual embeddings. The model’s performance is assessed across a multilingual dataset encompassing English, French, Japanese, and Korean news articles. For the first task of determining impact duration, our model ranked in first, fifth, seventh, and eight place for Japanese, French, Korean and English texts respectively (with respective macro F1 scores of 0.256, 0.458, 0.552, 0.441). For the second task of assessing impact level, our model ranked in sixth, and eight place for French and English texts, respectively (with respective macro F1 scores of 0.488 and 0.550).</abstract>
      <url hash="19e07c42">2024.finnlp-1.19</url>
      <bibkey>abburi-etal-2024-multilingual</bibkey>
    </paper>
    <paper id="20">
      <title>Cheap Talk: Topic Analysis of <fixed-case>CSR</fixed-case> Themes on Corporate <fixed-case>T</fixed-case>witter</title>
      <author><first>Nile</first><last>Phillips</last></author>
      <author><first>Sathvika</first><last>Anand</last></author>
      <author><first>Michelle</first><last>Lum</last></author>
      <author><first>Manisha</first><last>Goel</last></author>
      <author><first>Michelle</first><last>Zemel</last></author>
      <author><first>Alexandra</first><last>Schofield</last></author>
      <pages>203–211</pages>
      <abstract>Numerous firms advertise action around corporate social responsibility (CSR) on social media. Using a Twitter corpus from S&amp;P 500 companies and topic modeling, we investigate how companies talk about their social and sustainability efforts and whether CSR-related speech predicts Environmental, Social, and Governance (ESG) risk scores. As part of our work in progress, we present early findings suggesting a possible distinction in language between authentic discussion of positive practices and corporate posturing.</abstract>
      <url hash="061d5648">2024.finnlp-1.20</url>
      <bibkey>phillips-etal-2024-cheap</bibkey>
    </paper>
    <paper id="21">
      <title><fixed-case>LL</fixed-case>a<fixed-case>MA</fixed-case>-2-Econ: Enhancing Title Generation, Abstract Classification, and Academic <fixed-case>Q</fixed-case>&amp;<fixed-case>A</fixed-case> in Economic Research</title>
      <author><first>Onur</first><last>Keles</last></author>
      <author><first>Omer Turan</first><last>Bayraklı</last></author>
      <pages>212–218</pages>
      <abstract>Using Quantized Low Rank Adaptation and Parameter Efficient Fine Tuning, we fine-tuned Meta AI’s LLaMA-2-7B large language model as a research assistant in the field of economics for three different types of tasks: title generation, abstract classification, and question and answer. The model was fine-tuned on economics paper abstracts and syntheticically created question-answer dialogues based on the abstracts. For the title generation, the results of the experiment demonstrated that LLaMA-2-Econ (the fine-tuned model) surpassed the base model (7B and 13B) with few shot learning, and comparable models of similar size like Mistral-7B and Bloom-7B in the BLEU and ROUGE metrics. For abstract categorization, LLaMA-2-Econ outperformed different machine and deep learning algorithms in addition to state-of-the-art models like GPT 3.5 and GPT 4 with both single and representative few shot learning. We tested the fine-tuned Q&amp;A model by comparing its output with the base LLaMA-2-7B-chat with a Retrieval Augmented Generation (RAG) pipeline with semantic search and dense vector indexing, and found that LLaMA-2 performed on a par with the base model with RAG.</abstract>
      <url hash="90e04a4e">2024.finnlp-1.21</url>
      <bibkey>keles-bayrakli-2024-llama</bibkey>
    </paper>
    <paper id="22">
      <title>Multi-Lingual <fixed-case>ESG</fixed-case> Impact Duration Inference</title>
      <author><first>Chung-Chi</first><last>Chen</last></author>
      <author><first>Yu-Min</first><last>Tseng</last></author>
      <author><first>Juyeon</first><last>Kang</last></author>
      <author><first>Anais</first><last>Lhuissier</last></author>
      <author><first>Yohei</first><last>Seki</last></author>
      <author><first>Hanwool</first><last>Lee</last></author>
      <author><first>Min-Yuh</first><last>Day</last></author>
      <author><first>Teng-Tsai</first><last>Tu</last></author>
      <author><first>Hsin-Hsi</first><last>Chen</last></author>
      <pages>219–227</pages>
      <abstract>To accurately assess the dynamic impact of a company’s activities on its Environmental, Social, and Governance (ESG) scores, we have initiated a series of shared tasks, named ML-ESG. These tasks adhere to the MSCI guidelines for annotating news articles across various languages. This paper details the third iteration of our series, ML-ESG-3, with a focus on impact duration inference—a task that poses significant challenges in estimating the enduring influence of events, even for human analysts. In ML-ESG-3, we provide datasets in five languages (Chinese, English, French, Korean, and Japanese) and share insights from our experience in compiling such subjective datasets. Additionally, this paper reviews the methodologies proposed by ML-ESG-3 participants and offers a comparative analysis of the models’ performances. Concluding the paper, we introduce the concept for the forthcoming series of shared tasks, namely multi-lingual ESG promise verification, and discuss its potential contributions to the field.</abstract>
      <url hash="6e6be300">2024.finnlp-1.22</url>
      <bibkey>chen-etal-2024-multi</bibkey>
    </paper>
    <paper id="23">
      <title><fixed-case>IMNTPU</fixed-case> at <fixed-case>ML</fixed-case>-<fixed-case>ESG</fixed-case>-3: Transformer Language Models for Multi-Lingual <fixed-case>ESG</fixed-case> Impact Type and Duration Classification</title>
      <author><first>Yu Han</first><last>Kao</last></author>
      <author><first>Vidhya</first><last>Nataraj</last></author>
      <author><first>Ting-Chi</first><last>Wang</last></author>
      <author><first>Yu-Jyun</first><last>Zheng</last></author>
      <author><first>Hsiao-Chuan</first><last>Liu</last></author>
      <author><first>Wen-Hsuan</first><last>Liao</last></author>
      <author><first>Chia-Tung</first><last>Tsai</last></author>
      <author><first>Min-Yuh</first><last>Day</last></author>
      <pages>228–233</pages>
      <abstract>Our team participated in the multi-lingual Environmental, Social, and Governance (ESG) classification task, focusing on datasets in three languages: English, French, and Japanese. This study leverages Pre-trained Language Models (PLMs), with a particular emphasis on the Bidirectional Encoder Representations from Transformers (BERT) framework, to analyze sentence and document structures across these varied linguistic datasets. The team’s experimentation with diverse PLM-based network designs facilitated a nuanced comparative analysis within this multi-lingual context. For each language-specific dataset, different BERT-based transformer models were trained and evaluated. Notably, in the experimental results, the RoBERTa-Base model emerged as the most effective in official evaluation, particularly in the English dataset, achieving a micro-F1 score of 58.82 %, thereby demonstrating superior performance in classifying ESG impact levels. This research highlights the adaptability and effectiveness of PLMs in tackling the complexities of multi-lingual ESG classification tasks, underscoring the exceptional performance of the Roberta Base model in processing English-language data.</abstract>
      <url hash="deabbd4e">2024.finnlp-1.23</url>
      <bibkey>kao-etal-2024-imntpu</bibkey>
    </paper>
    <paper id="24">
      <title><fixed-case>DICE</fixed-case> @ <fixed-case>ML</fixed-case>-<fixed-case>ESG</fixed-case>-3: <fixed-case>ESG</fixed-case> Impact Level and Duration Inference Using <fixed-case>LLM</fixed-case>s for Augmentation and Contrastive Learning</title>
      <author><first>Konstantinos</first><last>Bougiatiotis</last></author>
      <author><first>Andreas</first><last>Sideras</last></author>
      <author><first>Elias</first><last>Zavitsanos</last></author>
      <author><first>Georgios</first><last>Paliouras</last></author>
      <pages>234–243</pages>
      <abstract>We present the submission of team DICE for ML-ESG-3, the 3rd Shared Task on Multilingual ESG impact duration inference in the context of the joint FinNLP-KDF workshop series. The task provides news articles and seeks to determine the impact and duration of an event in the news article may have on a company. We experiment with various baselines and discuss the results of our best-performing submissions based on contrastive pre-training and a stacked model based on the bag-of-words assumption and sentence embeddings. We also explored the label correlations among events stemming from the same news article and the correlations between impact level and impact length. Our analysis shows that even simple classifiers trained in this task can achieve comparable performance with more complex models, under certain conditions.</abstract>
      <url hash="ac24bed3">2024.finnlp-1.24</url>
      <bibkey>bougiatiotis-etal-2024-dice</bibkey>
    </paper>
    <paper id="25">
      <title>Fine-tuning Language Models for Predicting the Impact of Events Associated to Financial News Articles</title>
      <author><first>Neelabha</first><last>Banerjee</last></author>
      <author><first>Anubhav</first><last>Sarkar</last></author>
      <author><first>Swagata</first><last>Chakraborty</last></author>
      <author><first>Sohom</first><last>Ghosh</last></author>
      <author><first>Sudip Kumar</first><last>Naskar</last></author>
      <pages>244–247</pages>
      <abstract>Investors and other stakeholders like consumers and employees, increasingly consider ESG factors when making decisions about investments or engaging with companies. Taking into account the importance of ESG today, FinNLP-KDF introduced the <i>ML-ESG-3</i> shared task, which seeks to determine the duration of the impact of financial news articles in four languages - English, French, Korean, and Japanese. This paper describes our team, LIPI’s approach towards solving the above-mentioned task. Our final systems consist of translation, paraphrasing and fine-tuning language models like BERT, Fin-BERT and RoBERTa for classification. We ranked first in the impact duration prediction subtask for French language.</abstract>
      <url hash="9266c72f">2024.finnlp-1.25</url>
      <bibkey>banerjee-etal-2024-fine</bibkey>
    </paper>
    <paper id="26">
      <title><fixed-case>C</fixed-case>ritical<fixed-case>M</fixed-case>inds: Enhancing <fixed-case>ML</fixed-case> Models for <fixed-case>ESG</fixed-case> Impact Analysis Categorisation Using Linguistic Resources and Aspect-Based Sentiment Analysis</title>
      <author><first>Iana</first><last>Atanassova</last></author>
      <author><first>Marine</first><last>Potier</last></author>
      <author><first>Maya</first><last>Mathie</last></author>
      <author><first>Marc</first><last>Bertin</last></author>
      <author><first>Panggih Kusuma</first><last>Ningrum</last></author>
      <pages>248–253</pages>
      <abstract>This paper presents our method and findings for the ML-ESG-3 shared task for categorising Environmental, Social, and Governance (ESG) impact level and duration. We introduce a comprehensive machine learning framework incorporating linguistic and semantic features to predict ESG impact levels and durations in English and French. Our methodology uses features that are derived from FastText embeddings, TF-IDF vectors, manually crafted linguistic resources, the ESG taxonomy, and aspect-based sentiment analysis (ABSA). We detail our approach, feature engineering process, model selection via grid search, and results. The best performance for this task was achieved by the Random Forest and XGBoost classifiers, with micro-F1 scores of 47.06 % and 65.44 % for English Impact level and Impact length, and 39.04 % and 54.79 % for French Impact level and Impact length respectively.</abstract>
      <url hash="8e69602b">2024.finnlp-1.26</url>
      <bibkey>atanassova-etal-2024-criticalminds</bibkey>
    </paper>
    <paper id="27">
      <title>Jetsons at <fixed-case>F</fixed-case>in<fixed-case>NLP</fixed-case> 2024: Towards Understanding the <fixed-case>ESG</fixed-case> Impact of a News Article Using Transformer-based Models</title>
      <author><first>Parag Pravin</first><last>Dakle</last></author>
      <author><first>Alolika</first><last>Gon</last></author>
      <author><first>Sihan</first><last>Zha</last></author>
      <author><first>Liang</first><last>Wang</last></author>
      <author><first>Sai Krishna</first><last>Rallabandi</last></author>
      <author><first>Preethi</first><last>Raghavan</last></author>
      <pages>254–260</pages>
      <abstract>In this paper, we describe the different approaches explored by the Jetsons team for the Multi-Lingual ESG Impact Duration Inference (ML-ESG-3) shared task. The shared task focuses on predicting the duration and type of the ESG impact of a news article. The shared task dataset consists of 2,059 news titles and articles in English, French, Korean, and Japanese languages. For the impact duration classification task, we fine-tuned XLM-RoBERTa with a custom fine-tuning strategy and using self-training and DeBERTa-v3 using only English translations. These models individually ranked first on the leaderboard for Korean and Japanese and in an ensemble for the English language, respectively. For the impact type classification task, our XLM-RoBERTa model fine-tuned using a custom fine-tuning strategy ranked first for the English language.</abstract>
      <url hash="4b0fd35f">2024.finnlp-1.27</url>
      <bibkey>dakle-etal-2024-jetsons</bibkey>
    </paper>
    <paper id="28">
      <title><fixed-case>ESG</fixed-case> Classification by Implicit Rule Learning via <fixed-case>GPT</fixed-case>-4</title>
      <author><first>Yun</first><last>Hyojeong</last></author>
      <author><first>Kim</first><last>Chanyoung</last></author>
      <author><first>Moonjeong</first><last>Hahm</last></author>
      <author><first>Kyuri</first><last>Kim</last></author>
      <author><first>Guijin</first><last>Son</last></author>
      <pages>261–268</pages>
      <abstract>In this work, we adopt multiple prompting, chain-of-thought reasoning, and in-context learning strategies to guide GPT-4 in solving ESG classification tasks. We rank second in the Korean subset for Shared Task ML-ESG-3 in Impact Type prediction. Furthermore, we adopt open models to explain their calibration and robustness to different prompting strategies. The longer general pre-training correlates with enhanced performance in financial downstream tasks.</abstract>
      <url hash="fa757566">2024.finnlp-1.28</url>
      <bibkey>hyojeong-etal-2024-esg</bibkey>
    </paper>
    <paper id="29">
      <title>Leveraging Semi-Supervised Learning on a Financial-Specialized Pre-trained Language Model for Multilingual <fixed-case>ESG</fixed-case> Impact Duration and Type Classification</title>
      <author><first>Jungdae</first><last>Kim</last></author>
      <author><first>Eunkwang</first><last>Jeon</last></author>
      <author><first>Jeon</first><last>Sang Hyun</last></author>
      <pages>269–273</pages>
      <abstract>This paper presents the results of our participation in the Multilingual ESG Impact Duration Inference (ML-ESG-3) shared task organized by FinNLP-KDF@LREC-COLING-2024. The objective of this challenge is to leverage natural language processing (NLP) techniques to identify the impact duration or impact type of events that may affect a company based on news articles written in various languages. Our approach employs semi-supervised learning methods on a finance-specialized pre-trained language model. Our methodology demonstrates strong performance, achieving 1st place in the Korean - Impact Type subtask and 2nd place in the Korean - Impact Duration subtask. These results showcase the efficacy of our approach in detecting ESG-related issues from news articles. Our research shows the potential to improve existing ESG ratings by quickly reflecting the latest events of companies.</abstract>
      <url hash="ee2a48c5">2024.finnlp-1.29</url>
      <bibkey>kim-etal-2024-leveraging</bibkey>
    </paper>
    <paper id="30">
      <title>Adapting <fixed-case>LLM</fixed-case> to Multi-lingual <fixed-case>ESG</fixed-case> Impact and Length Prediction Using In-context Learning and Fine-Tuning with Rationale</title>
      <author><first>Pawan Kumar</first><last>Rajpoot</last></author>
      <author><first>Ashvini</first><last>Jindal</last></author>
      <author><first>Ankur</first><last>Parikh</last></author>
      <pages>274–278</pages>
      <abstract>The prediction of Environmental, Social, and Governance (ESG) impact and duration (length) of impact from company events, as reported in news articles, hold immense significance for investors, policymakers, and various stakeholders. In this paper, we describe solutions from our team “Upaya” to ESG impact and length prediction tasks on one such dataset ML-ESG-3. ML-ESG-3 dataset was released along with shared task as a part of the Fifth Workshop on Knowledge Discovery from Unstructured Data in Financial Services, co-located with LREC-COLING 2024. We employed two different paradigms to adapt Large Language Models (LLMs) to predict both the ESG impact and length of events. In the first approach, we leverage GPT-4 within the In-context learning (ICL) framework. A learning-free dense retriever identifies top K-relevant In-context learning examples from the training data for a given test example. The second approach involves instruction-tuning Mistral (7B) LLM to predict impact and duration, supplemented with rationale generated using GPT-4. Our models secured second place in French tasks and achieved reasonable results (fifth and ninth rank) in English tasks. These results demonstrate the potential of different LLM-based paradigms for delivering valuable insights within the ESG investing landscape.</abstract>
      <url hash="8c356f58">2024.finnlp-1.30</url>
      <bibkey>rajpoot-etal-2024-adapting</bibkey>
    </paper>
    <paper id="31">
      <title><fixed-case>ESG</fixed-case>-<fixed-case>GPT</fixed-case>:<fixed-case>GPT</fixed-case>4-Based Few-Shot Prompt Learning for Multi-lingual <fixed-case>ESG</fixed-case> News Text Classification</title>
      <author><first>Ke</first><last>Tian</last></author>
      <author><first>Hua</first><last>Chen</last></author>
      <pages>279–282</pages>
      <abstract>Environmental, Social, and Governance (ESG) factors for company assessment have gained great attention from finance investors to identify companies’ risks and growth opportunities. ESG Text data regarding the company like sustainable reports, media news text, and social media text are important data sources for ESG analysis like ESG factors classification. Recently, FinNLP has proposed several ESG-related tasks. One of the tasks is Multi-Lingual ESG Issue Identification 3(ML-ESG-3) which is to determine the duration or impact level of the impact of an event in the news article regarding the company. In this paper, we mainly discussed our team: KaKa’s solution to this ML-ESG-3 task. We proposed the GPT4 model based on few-shot prompt learning to predict the impact level or duration of the impact of multi-lingual ESG news for the company. The experiment result demonstrates that GPT4-based few-shot prompt learning achieved good performance in leaderboard quantitative evaluations of ML-ESG-3 tasks across different languages.</abstract>
      <url hash="b5a407f3">2024.finnlp-1.31</url>
      <bibkey>tian-chen-2024-esg</bibkey>
    </paper>
    <paper id="32">
      <title>Shared Task for Cross-lingual Classification of Corporate Social Responsibility (<fixed-case>CSR</fixed-case>) Themes and Topics</title>
      <author><first>Yola</first><last>Nayekoo</last></author>
      <author><first>Sophia</first><last>Katrenko</last></author>
      <author><first>Veronique</first><last>Hoste</last></author>
      <author><first>Aaron</first><last>Maladry</last></author>
      <author><first>Els</first><last>Lefever</last></author>
      <pages>283–291</pages>
      <abstract>This paper provides an overview of the Shared Task for Cross-lingual Classification of CSR Themes and Topics. We framed the task as two separate sub-tasks: one cross-lingual multi-class CSR theme recognition task for English, French and simplified Chinese and one multi-label fine-grained classification task of CSR topics for Environment (ENV) and Labor and Human Rights (LAB) themes in English. The participants were provided with URLs and annotations for both tasks. Several teams downloaded the data, of which two teams submitted a system for both sub-tasks. In this overview paper, we discuss the set-up of the task and our main findings.</abstract>
      <url hash="0283ce20">2024.finnlp-1.32</url>
      <bibkey>nayekoo-etal-2024-shared</bibkey>
    </paper>
    <paper id="33">
      <title>Advancing <fixed-case>CSR</fixed-case> Theme and Topic Classification: <fixed-case>LLM</fixed-case>s and Training Enhancement Insights</title>
      <author><first>Jens</first><last>Van Nooten</last></author>
      <author><first>Andriy</first><last>Kosar</last></author>
      <pages>292–305</pages>
      <abstract>In this paper, we present our results of the classification of Corporate Social Responsibility (CSR) Themes and Topics shared task, which encompasses cross-lingual multi-class classification and monolingual multi-label classification. We examine the performance of multiple machine learning (ML) models, ranging from classical models to pre-trained large language models (LLMs), and assess the effectiveness of Data Augmentation (DA), Data Translation (DT), and Contrastive Learning (CL). We find that state-of-the-art generative LLMs in a zero-shot setup still fall behind on more complex classification tasks compared to fine-tuning local models with enhanced datasets and additional training objectives. Our work provides a wide array of comparisons and highlights the relevance of utilizing smaller language models for more complex classification tasks.</abstract>
      <url hash="c439fac2">2024.finnlp-1.33</url>
      <bibkey>van-nooten-kosar-2024-advancing</bibkey>
    </paper>
    <paper id="34">
      <title>Improving Cross-Lingual <fixed-case>CSR</fixed-case> Classification Using Pretrained Transformers with Variable Selection Networks and Data Augmentation</title>
      <author><first>Shubham</first><last>Sharma</last></author>
      <author><first>Himanshu</first><last>Janbandhu</last></author>
      <author><first>Ankush</first><last>Chopra</last></author>
      <pages>306–318</pages>
      <abstract>This paper describes our submission to the Cross-Lingual Classification of Corporate Social Responsibility (CSR) Themes and Topics shared task, aiming to identify themes and fine-grained topics present in news articles. Classifying news articles poses several challenges, including limited training data, noisy articles, and longer context length. In this paper, we explore the potential of using pretrained transformer models to classify news articles into CSR themes and fine-grained topics. We propose two different approaches for these tasks. For multi-class classification of CSR themes, we suggest using a pretrained multi-lingual encoder-based model like microsoft/mDeBERTa-v3-base, along with a variable selection network to classify the article into CSR themes. To identify all fine-grained topics in each article, we propose using a pretrained encoder-based model like Longformer, which offers a higher context length. We employ chunking-based inference to avoid information loss in inference and experimented with using different parts and manifestation of original article for training and inference.</abstract>
      <url hash="cd2978a0">2024.finnlp-1.34</url>
      <bibkey>sharma-etal-2024-improving</bibkey>
    </paper>
  </volume>
  <volume id="2" ingest-date="2024-08-02" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Eighth Financial Technology and Natural Language Processing and the 1st Agent AI for Scenario Planning</booktitle>
      <editor><first>Chung-Chi</first><last>Chen</last></editor>
      <editor><first>Tatsuya</first><last>Ishigaki</last></editor>
      <editor><first>Hiroya</first><last>Takamura</last></editor>
      <editor><first>Akihiko</first><last>Murai</last></editor>
      <editor><first>Suzuko</first><last>Nishino</last></editor>
      <editor><first>Hen-Hsen</first><last>Huang</last></editor>
      <editor><first>Hsin-Hsi</first><last>Chen</last></editor>
      <publisher>-</publisher>
      <address>Jeju, South Korea</address>
      <month>3 August</month>
      <year>2024</year>
      <url hash="a6ade360">2024.finnlp-2</url>
      <venue>finnlp</venue>
    </meta>
    <frontmatter>
      <url hash="5c440232">2024.finnlp-2.0</url>
      <bibkey>finnlp-2024-2</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Using Pre-trained Language Model for Accurate <fixed-case>ESG</fixed-case> Prediction</title>
      <author><first>Lei</first><last>Xia</last></author>
      <author><first>Mingming</first><last>Yang</last></author>
      <author><first>Qi</first><last>Liu</last></author>
      <pages>1–22</pages>
      <url hash="359b94b0">2024.finnlp-2.1</url>
      <bibkey>xia-etal-2024-using</bibkey>
    </paper>
    <paper id="2">
      <title>Can <fixed-case>GPT</fixed-case> models be Financial Analysts? An Evaluation of <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> and <fixed-case>GPT</fixed-case>-4 on mock <fixed-case>CFA</fixed-case> Exams</title>
      <author><first>Ethan</first><last>Callanan</last></author>
      <author><first>Amarachi</first><last>Mbakwe</last></author>
      <author><first>Antony</first><last>Papadimitriou</last></author>
      <author><first>Yulong</first><last>Pei</last></author>
      <author><first>Mathieu</first><last>Sibue</last></author>
      <author><first>Xiaodan</first><last>Zhu</last></author>
      <author><first>Zhiqiang</first><last>Ma</last></author>
      <author><first>Xiaomo</first><last>Liu</last></author>
      <author><first>Sameena</first><last>Shah</last></author>
      <pages>23–32</pages>
      <url hash="05704db3">2024.finnlp-2.2</url>
      <bibkey>callanan-etal-2024-gpt</bibkey>
    </paper>
    <paper id="3">
      <title>Examining the Effect of News Context on Algorithmic Trading</title>
      <author><first>Surupendu</first><last>Gangopadhyay</last></author>
      <author><first>Prasenjit</first><last>Majumder</last></author>
      <pages>33–41</pages>
      <url hash="f4b77bd5">2024.finnlp-2.3</url>
      <bibkey>gangopadhyay-majumder-2024-examining</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>GPT</fixed-case>-Signal: Generative <fixed-case>AI</fixed-case> for Semi-automated Feature Engineering in the Alpha Research Process</title>
      <author><first>Yining</first><last>Wang</last></author>
      <author><first>Jinman</first><last>Zhao</last></author>
      <author><first>Yuri</first><last>Lawryshyn</last></author>
      <pages>42–53</pages>
      <url hash="5e32052a">2024.finnlp-2.4</url>
      <bibkey>wang-etal-2024-gpt</bibkey>
    </paper>
    <paper id="5">
      <title><fixed-case>RACCOON</fixed-case>: Real-world Advanced financ<fixed-case>C</fixed-case>ial analysis through <fixed-case>CO</fixed-case>mprehensive Natural language dataset</title>
      <author><first>Seonghyun</first><last>Kim</last></author>
      <author><first>Kanghee</first><last>Lee</last></author>
      <author><first>Minsu</first><last>Jeong</last></author>
      <author><first>Junghan</first><last>Yoon</last></author>
      <pages>54–62</pages>
      <url hash="9947a1e2">2024.finnlp-2.5</url>
      <bibkey>kim-etal-2024-raccoon</bibkey>
    </paper>
    <paper id="6">
      <title><fixed-case>T</fixed-case>opo<fixed-case>L</fixed-case>edger<fixed-case>BERT</fixed-case>: Topological Learning of Ledger Description Embeddings using <fixed-case>S</fixed-case>iamese <fixed-case>BERT</fixed-case>-Networks.</title>
      <author><first>Sander</first><last>Noels</last></author>
      <author><first>Sébastien</first><last>Viaene</last></author>
      <author><first>Tijl De</first><last>Bie</last></author>
      <pages>63–72</pages>
      <url hash="22b52ad6">2024.finnlp-2.6</url>
      <bibkey>noels-etal-2024-topoledgerbert</bibkey>
    </paper>
    <paper id="7">
      <title>Probing Numerical Concepts in Financial Text with <fixed-case>BERT</fixed-case> Models</title>
      <author><first>Shanyue</first><last>Guo</last></author>
      <author><first>Le</first><last>Qiu</last></author>
      <author><first>Emmanuele</first><last>Chersoni</last></author>
      <pages>73–78</pages>
      <url hash="4e6c058a">2024.finnlp-2.7</url>
      <bibkey>guo-etal-2024-probing</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>GENWISE</fixed-case>: Thematic Discovery from Textual Data</title>
      <author><first>Minnie</first><last>Kabra</last></author>
      <author><first>Abhinav</first><last>Nagpal</last></author>
      <author><first>Aayush</first><last>Sacheti</last></author>
      <author><first>Mohit</first><last>Kumar</last></author>
      <author><first>Salil</first><last>Joshi</last></author>
      <pages>79–88</pages>
      <url hash="b9d55528">2024.finnlp-2.8</url>
      <bibkey>kabra-etal-2024-genwise</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>FINALE</fixed-case> : Finance Domain Instruction-Tuning Dataset with High-Quality Rationales via Chain-of-Thought Prompting</title>
      <author><first>Sangmin</first><last>Lee</last></author>
      <author><first>Suzie</first><last>Oh</last></author>
      <author><first>Saeran</first><last>Park</last></author>
      <author><first>Guijin</first><last>Son</last></author>
      <author><first>Pilsung</first><last>Kang</last></author>
      <pages>89–106</pages>
      <url hash="0681faab">2024.finnlp-2.9</url>
      <bibkey>lee-etal-2024-finale</bibkey>
    </paper>
    <paper id="10">
      <title>Capturing Analysts’ Questioning Strategies in Earnings Calls via a Question Cornering Score (<fixed-case>QCS</fixed-case>)</title>
      <author><first>Giulia</first><last>D’Agostino</last></author>
      <author><first>Andrea</first><last>Rocci</last></author>
      <author><first>Chris</first><last>Reed</last></author>
      <pages>107–118</pages>
      <url hash="96c2c33c">2024.finnlp-2.10</url>
      <bibkey>dagostino-etal-2024-capturing</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>F</fixed-case>in<fixed-case>NLP</fixed-case>-<fixed-case>A</fixed-case>gent<fixed-case>S</fixed-case>cen-2024 Shared Task: Financial Challenges in Large Language Models - <fixed-case>F</fixed-case>in<fixed-case>LLM</fixed-case>s</title>
      <author><first>Qianqian</first><last>Xie</last></author>
      <author><first>Jimin</first><last>Huang</last></author>
      <author><first>Dong</first><last>Li</last></author>
      <author><first>Zhengyu</first><last>Chen</last></author>
      <author><first>Ruoyu</first><last>Xiang</last></author>
      <author><first>Mengxi</first><last>Xiao</last></author>
      <author><first>Yangyang</first><last>Yu</last></author>
      <author><first>Vijayasai</first><last>Somasundaram</last></author>
      <author><first>Kailai</first><last>Yang</last></author>
      <author><first>Chenhan</first><last>Yuan</last></author>
      <author><first>Zheheng</first><last>Luo</last></author>
      <author><first>Zhiwei</first><last>Liu</last></author>
      <author><first>Yueru</first><last>He</last></author>
      <author><first>Yuechen</first><last>Jiang</last></author>
      <author><first>Haohang</first><last>Li</last></author>
      <author><first>Duanyu</first><last>Feng</last></author>
      <author><first>Xiao-Yang</first><last>Liu</last></author>
      <author><first>Benyou</first><last>Wang</last></author>
      <author><first>Hao</first><last>Wang</last></author>
      <author><first>Yanzhao</first><last>Lai</last></author>
      <author><first>Jordan</first><last>Suchow</last></author>
      <author><first>Alejandro</first><last>Lopez-Lira</last></author>
      <author><first>Min</first><last>Peng</last></author>
      <author><first>Sophia</first><last>Ananiadou</last></author>
      <pages>119–126</pages>
      <url hash="557a4cf4">2024.finnlp-2.11</url>
      <bibkey>xie-etal-2024-finnlp</bibkey>
    </paper>
    <paper id="12">
      <title>University of Glasgow at the <fixed-case>F</fixed-case>in<fixed-case>LLM</fixed-case> Challenge Task: Adapting Llama for Financial News Abstractive Summarization</title>
      <author><first>Lubingzhi</first><last>Guo</last></author>
      <author><first>Javier</first><last>Sanz-Cruzado</last></author>
      <author><first>Richard</first><last>McCreadie</last></author>
      <pages>127–132</pages>
      <url hash="6d64ffdb">2024.finnlp-2.12</url>
      <bibkey>guo-etal-2024-university</bibkey>
    </paper>
    <paper id="13">
      <title>Wealth Guide: A Sophisticated Language Model Solution for Financial Trading Decisions</title>
      <author><first>Sarmistha</first><last>Das</last></author>
      <author><first>R E Zera Marveen</first><last>Lyngkhoi</last></author>
      <author><first>Sriparna</first><last>Saha</last></author>
      <author><first>Alka</first><last>Maurya</last></author>
      <pages>133–140</pages>
      <url hash="5f51821e">2024.finnlp-2.13</url>
      <bibkey>das-etal-2024-wealth</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>L</fixed-case>3i<fixed-case>TC</fixed-case> at the <fixed-case>F</fixed-case>in<fixed-case>LLM</fixed-case> Challenge Task: Quantization for Financial Text Classification &amp; Summarization</title>
      <author><first>Elvys Linhares</first><last>Pontes</last></author>
      <author><first>Carlos-Emiliano</first><last>González-Gallardo</last></author>
      <author><first>Mohamed</first><last>Benjannet</last></author>
      <author><first>Caryn</first><last>Qu</last></author>
      <author><first>Antoine</first><last>Doucet</last></author>
      <pages>141–145</pages>
      <url hash="a34b43aa">2024.finnlp-2.14</url>
      <bibkey>pontes-etal-2024-l3itc</bibkey>
    </paper>
    <paper id="15">
      <title>Revelata at the <fixed-case>F</fixed-case>in<fixed-case>LLM</fixed-case> Challenge Task: Improving Financial Text Summarization by Restricted Prompt Engineering and Fine-tuning</title>
      <author><first>Ken</first><last>Kawamura</last></author>
      <author><first>Zeqian</first><last>Li</last></author>
      <author><first>Chit-Kwan</first><last>Lin</last></author>
      <author><first>Bradley</first><last>McDanel</last></author>
      <pages>146–152</pages>
      <url hash="284c4a6a">2024.finnlp-2.15</url>
      <bibkey>kawamura-etal-2024-revelata</bibkey>
    </paper>
    <paper id="16">
      <title>‘Finance Wizard’ at the <fixed-case>F</fixed-case>in<fixed-case>LLM</fixed-case> Challenge Task: Financial Text Summarization</title>
      <author><first>Meisin</first><last>Lee</last></author>
      <author><first>Lay-Ki</first><last>Soon</last></author>
      <pages>153–158</pages>
      <url hash="f84066cd">2024.finnlp-2.16</url>
      <bibkey>lee-soon-2024-finance</bibkey>
    </paper>
    <paper id="17">
      <title>Upaya at the <fixed-case>F</fixed-case>in<fixed-case>LLM</fixed-case> Challenge Task 1 and 2: <fixed-case>D</fixed-case>ist<fixed-case>F</fixed-case>in: Distillation based Fine-Tuning for Financial Tasks</title>
      <author><first>Ashvini Kumar</first><last>Jindal</last></author>
      <author><first>Pawan Kumar</first><last>Rajpoot</last></author>
      <author><first>Ankur</first><last>Parikh</last></author>
      <pages>159–164</pages>
      <url hash="28a0e4ac">2024.finnlp-2.17</url>
      <bibkey>jindal-etal-2024-upaya</bibkey>
    </paper>
    <paper id="18">
      <title><fixed-case>BAI</fixed-case>-Arg <fixed-case>LLM</fixed-case> at the <fixed-case>F</fixed-case>in<fixed-case>LLM</fixed-case> Challenge Task: Earn While You Argue - Financial Argument Identification</title>
      <author><first>Varad</first><last>Srivastava</last></author>
      <pages>165–173</pages>
      <url hash="8dab5da8">2024.finnlp-2.18</url>
      <bibkey>srivastava-2024-bai</bibkey>
    </paper>
    <paper id="19">
      <title><fixed-case>C</fixed-case>at<fixed-case>M</fixed-case>emo@<fixed-case>IJCAI</fixed-case> 2024 <fixed-case>F</fixed-case>in<fixed-case>LLM</fixed-case> Challenge: Fine-Tuning Large Language Models using Data Fusion in Financial Applications</title>
      <author><first>Yupeng</first><last>Cao</last></author>
      <author><first>Zhiyuan</first><last>Yao</last></author>
      <author><first>Zhi</first><last>Chen</last></author>
      <author><first>Zhiyang</first><last>Deng</last></author>
      <pages>174–178</pages>
      <url hash="17bd7973">2024.finnlp-2.19</url>
      <bibkey>cao-etal-2024-catmemo</bibkey>
    </paper>
  </volume>
</collection>
