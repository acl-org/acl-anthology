<?xml version='1.0' encoding='UTF-8'?>
<collection id="2022.alta">
  <volume id="1" ingest-date="2023-02-10" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 20th Annual Workshop of the Australasian Language Technology Association</booktitle>
      <editor><first>Pradeesh</first><last>Parameswaran</last></editor>
      <editor><first>Jennifer</first><last>Biggs</last></editor>
      <editor><first>David</first><last>Powers</last></editor>
      <publisher>Australasian Language Technology Association</publisher>
      <address>Adelaide, Australia</address>
      <month>December</month>
      <year>2022</year>
      <url hash="5662a931">2022.alta-1</url>
      <venue>alta</venue>
    </meta>
    <frontmatter>
      <url hash="867b0a2d">2022.alta-1.0</url>
      <bibkey>alta-2022-australasian</bibkey>
    </frontmatter>
    <paper id="1">
      <title>The Corpus of <fixed-case>A</fixed-case>ustralian and <fixed-case>N</fixed-case>ew <fixed-case>Z</fixed-case>ealand Spoken <fixed-case>E</fixed-case>nglish: A new resource of naturalistic speech transcripts</title>
      <author><first>Steven</first><last>Coats</last></author>
      <pages>1–5</pages>
      <url hash="685b580f">2022.alta-1.1</url>
      <bibkey>coats-2022-corpus</bibkey>
    </paper>
    <paper id="2">
      <title>Using public domain resources and off-the-shelf tools to produce high-quality multimedia texts</title>
      <author><first>Manny</first><last>Rayner</last></author>
      <author><first>Belinda</first><last>Chiera</last></author>
      <author><first>Cathy</first><last>Chua</last></author>
      <pages>6–15</pages>
      <url hash="5d3e6a0b">2022.alta-1.2</url>
      <bibkey>rayner-etal-2022-using</bibkey>
    </paper>
    <paper id="3">
      <title>The Role of Context in Vaccine Stance Prediction for <fixed-case>T</fixed-case>witter Users</title>
      <author><first>Aleney</first><last>Khoo</last></author>
      <author><first>Maciej</first><last>Rybinski</last></author>
      <author><first>Sarvnaz</first><last>Karimi</last></author>
      <author><first>Adam</first><last>Dunn</last></author>
      <pages>16–21</pages>
      <url hash="d77d5d5f">2022.alta-1.3</url>
      <bibkey>khoo-etal-2022-role</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>TCG</fixed-case>-Event: Effective Task Conditioning for Generation-based Event Extraction</title>
      <author><first>Fatemeh</first><last>Shiri</last></author>
      <author><first>Tongtong</first><last>Wu</last></author>
      <author><first>Yuanfang</first><last>Li</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>22–30</pages>
      <url hash="a650b4f6">2022.alta-1.4</url>
      <bibkey>shiri-etal-2022-tcg</bibkey>
    </paper>
    <paper id="5">
      <title>Complex Reading Comprehension Through Question Decomposition</title>
      <author><first>Xiao-Yu</first><last>Guo</last></author>
      <author><first>Yuan-Fang</first><last>Li</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>31–40</pages>
      <url hash="272ff661">2022.alta-1.5</url>
      <bibkey>guo-etal-2022-complex</bibkey>
    </paper>
    <paper id="6">
      <title>Using Aspect-Based Sentiment Analysis to Classify Attitude-bearing Words</title>
      <author><first>Pradeesh</first><last>Parameswaran</last></author>
      <author><first>Andrew</first><last>Trotman</last></author>
      <author><first>Veronica</first><last>Liesaputra</last></author>
      <author><first>David</first><last>Eyers</last></author>
      <pages>41–51</pages>
      <url hash="7bdf973b">2022.alta-1.6</url>
      <bibkey>parameswaran-etal-2022-using</bibkey>
    </paper>
    <paper id="7">
      <title>Fine-tuning a Subtle Parsing Distinction Using a Probabilistic Decision Tree: the Case of Postnominal “that” in Noun Complement Clauses vs. Relative Clauses</title>
      <author><first>Zineddine</first><last>Tighidet</last></author>
      <author><first>Nicolas</first><last>Ballier</last></author>
      <pages>52–61</pages>
      <url hash="76d953a9">2022.alta-1.7</url>
      <bibkey>tighidet-ballier-2022-fine</bibkey>
    </paper>
    <paper id="8">
      <title>Robustness of Hybrid Models in Cross-domain Readability Assessment</title>
      <author><first>Ho Hung</first><last>Lim</last></author>
      <author><first>Tianyuan</first><last>Cai</last></author>
      <author><first>John S. Y.</first><last>Lee</last></author>
      <author><first>Meichun</first><last>Liu</last></author>
      <pages>62–67</pages>
      <url hash="2baaa8f6">2022.alta-1.8</url>
      <bibkey>lim-etal-2022-robustness</bibkey>
    </paper>
    <paper id="9">
      <title>Specifying Optimisation Problems for Declarative Programs in Precise Natural Language</title>
      <author><first>Rolf</first><last>Schwitter</last></author>
      <pages>68–72</pages>
      <url hash="ad2a2dba">2022.alta-1.9</url>
      <bibkey>schwitter-2022-specifying</bibkey>
    </paper>
    <paper id="10">
      <title>Improving Text-based Early Prediction by Distillation from Privileged Time-Series Text</title>
      <author><first>Jinghui</first><last>Liu</last></author>
      <author><first>Daniel</first><last>Capurro</last></author>
      <author><first>Anthony</first><last>Nguyen</last></author>
      <author><first>Karin</first><last>Verspoor</last></author>
      <pages>73–83</pages>
      <url hash="e657ba85">2022.alta-1.10</url>
      <bibkey>liu-etal-2022-improving</bibkey>
    </paper>
    <paper id="11">
      <title>A <fixed-case>D</fixed-case>istil<fixed-case>BERT</fixed-case>opic Model for Short Text Documents</title>
      <author><first>Junaid</first><last>Rashid</last></author>
      <author><first>Jungeun</first><last>Kim</last></author>
      <author><first>Usman</first><last>Naseem</last></author>
      <author><first>Amir</first><last>Hussain</last></author>
      <pages>84–89</pages>
      <url hash="e7ca79c7">2022.alta-1.11</url>
      <bibkey>rashid-etal-2022-distilbertopic</bibkey>
    </paper>
    <paper id="12">
      <title>Generating Code-Switched Text from Monolingual Text with Dependency Tree</title>
      <author><first>Bryan</first><last>Gregorius</last></author>
      <author><first>Takeshi</first><last>Okadome</last></author>
      <pages>90–97</pages>
      <url hash="3fe8f3f8">2022.alta-1.12</url>
      <bibkey>gregorius-okadome-2022-generating</bibkey>
    </paper>
    <paper id="13">
      <title>Stability of Forensic Text Comparison System</title>
      <author><first>Susan</first><last>Brown</last></author>
      <author><first>Shunichi</first><last>Ishihara</last></author>
      <pages>98–106</pages>
      <url hash="14e23af6">2022.alta-1.13</url>
      <bibkey>brown-ishihara-2022-stability</bibkey>
    </paper>
    <paper id="14">
      <title>Academic Curriculum Generation using <fixed-case>W</fixed-case>ikipedia for External Knowledge</title>
      <author><first>Anurag Reddy</first><last>Muthyala</last></author>
      <author><first>Vikram</first><last>Pudi</last></author>
      <pages>107–114</pages>
      <url hash="17b91c72">2022.alta-1.14</url>
      <bibkey>muthyala-pudi-2022-academic</bibkey>
    </paper>
    <paper id="15">
      <title>Interactive Rationale Extraction for Text Classification</title>
      <author><first>Jiayi</first><last>Dai</last></author>
      <author><first>Mi-Young</first><last>Kim</last></author>
      <author><first>Randy</first><last>Goebel</last></author>
      <pages>115–121</pages>
      <url hash="f94f2b58">2022.alta-1.15</url>
      <bibkey>dai-etal-2022-interactive</bibkey>
    </paper>
    <paper id="16">
      <title>Automatic Explanation Generation For Climate Science Claims</title>
      <author><first>Rui</first><last>Xing</last></author>
      <author><first>Shraey</first><last>Bhatia</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Jey Han</first><last>Lau</last></author>
      <pages>122–129</pages>
      <abstract>Climate change is an existential threat to humanity, the proliferation of unsubstantiated claims relating to climate science is manipulating public perception, motivating the need for fact-checking in climate science. In this work, we draw on recent work that uses retrieval-augmented generation for veracity prediction and explanation generation, in framing explanation generation as a query-focused multi-document summarization task. We adapt PRIMERA to the climate science domain by adding additional global attention on claims. Through automatic evaluation and qualitative analysis, we demonstrate that our method is effective at generating explanations.</abstract>
      <url hash="cfb70c46">2022.alta-1.16</url>
      <bibkey>xing-etal-2022-automatic</bibkey>
    </paper>
    <paper id="17">
      <title>Zhangzhou Implosives and Their Variations</title>
      <author><first>Yishan</first><last>Huang</last></author>
      <author><first>Gwendolyn</first><last>Hyslop</last></author>
      <pages>122–129</pages>
      <abstract>Zhangzhou Southern Min employs the airstream mechanism of glottalic ingressive as a contrastive feature in its onset system. However, their realisations are highly diverse with eleven phonetic variants that can be derived from three implosive phonemes (/ɓ, ɗ, ɠ/). The allophonic variations are regressively motivated by three driving factors comprising the nasal [Ṽ], labial-velar [u, w], and palatal [i, j] characteristics of subsequent segments. Several processes that include labialisation, nasalisation, lenition, laminalisation, dentalisation and palatalisation have been found to trigger alternation on the airstream mechanism, manner of articulation, and place of articulation of related sounds, resulting in diverse phonetic outputs of the three implosives phonemes that can be captured using phonological rules.</abstract>
      <url hash="05129cbe">2022.alta-1.17</url>
      <bibkey>huang-hyslop-2022-zhangzhou</bibkey>
    </paper>
    <paper id="18">
      <title>Evaluating the Examiner: The Perils of <fixed-case>P</fixed-case>earson Correlation for Validating Text Similarity Metrics</title>
      <author><first>Gisela</first><last>Vallejo</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Lea</first><last>Frermann</last></author>
      <pages>130–138</pages>
      <abstract>In recent years, researchers have developed question-answering based approaches to automatically evaluate system summaries, reporting improved validity compared to word overlap-based metrics like ROUGE, in terms of correlation with human ratings of criteria including fluency and hallucination. In this paper, we take a closer look at one particular metric, QuestEval, and ask whether: (1) it can serve as a more general metric for long document similarity assessment; and (2) a single correlation score between metric scores and human ratings, as the currently standard approach, is sufficient for metric validation. We find that correlation scores can be misleading, and that score distributions and outliers should be taken into account. With these caveats in mind, QuestEval can be a promising candidate for long document similarity assessment.</abstract>
      <url hash="f06c637c">2022.alta-1.18</url>
      <bibkey>vallejo-etal-2022-evaluating</bibkey>
    </paper>
    <paper id="19">
      <title>Can Language Models Help in System Security? Investigating Log Anomaly Detection using <fixed-case>BERT</fixed-case></title>
      <author><first>Crispin</first><last>Almodovar</last></author>
      <author><first>Fariza</first><last>Sabrina</last></author>
      <author><first>Sarvnaz</first><last>Karimi</last></author>
      <author><first>Salahuddin</first><last>Azad</last></author>
      <pages>139–147</pages>
      <abstract>The log files generated by networked computer systems contain valuable information that can be used to monitor system security and stability. Recently, techniques based on Deep Learning and Natural Language Processing have been proven effective in detecting anomalous activities from system logs. The current approaches, however, have limited practical application because they rely on log templates which cannot handle variability in log content, or they require supervised training to be effective. In this paper, a novel log anomaly detection approach named LogFiT is proposed. The LogFiT model inherits the linguistic “knowledge” encoded within a pretrained BERT-based language model and fine-tunes it towards learning the linguistic structure of system logs. The LogFiT model is trained in a self-supervised manner using normal log data only. Using masked token prediction and centroid distance minimisation as training objectives, the LogFiT model learns to recognise the linguistic patterns associated with the normal log data. During inference, a discriminator function uses the LogFiT model’s top-k token prediction accuracy and computed centroid distance to determine if the input is normal or anomaly. Experiments show that LogFiT’s F1 score and specificity exceeds that of baseline models on the HDFS dataset and comparable on the BGL dataset.</abstract>
      <url hash="bcec6d6e">2022.alta-1.19</url>
      <bibkey>almodovar-etal-2022-language</bibkey>
    </paper>
    <paper id="20">
      <title>A Semantics of Spatial Expressions for interacting with unmanned aerial vehicles</title>
      <author><first>Lucas</first><last>Domingos</last></author>
      <author><first>Paulo</first><last>Santos</last></author>
      <pages>148–155</pages>
      <abstract>This paper describes an investigation of establishing communication between a quadro- tor and a human by means of qualitative spatial relations using speech recognition. It is based on a system capable to receive, interpret, process, act, transmit and execute the commands given. This system is composed of a quadrotor equipped with a GPS, IMU sensors and radio communication, and a computer acting as a ground station, that is capable of understanding and interpreting the received commands and correctly provide answers according to an underlying qualitative reasoning formalism. Tests were performed, whose results show that the error rate was less than five percent for vertical and radial dimensions, otherwise, in horizontal dimension, we had an error rate of almost ten percent.</abstract>
      <url hash="393f4a56">2022.alta-1.20</url>
      <bibkey>domingos-santos-2022-semantics</bibkey>
    </paper>
    <paper id="21">
      <title>Enhancing the <fixed-case>D</fixed-case>e<fixed-case>BERT</fixed-case>a Transformers Model for Classifying Sentences from Biomedical Abstracts</title>
      <author><first>Abdul</first><last>Aziz</last></author>
      <author><first>Md. Akram</first><last>Hossain</last></author>
      <author><first>Abu Nowshed</first><last>Chy</last></author>
      <pages>156–160</pages>
      <url hash="758c3d57">2022.alta-1.21</url>
      <bibkey>aziz-etal-2022-enhancing</bibkey>
    </paper>
    <paper id="22">
      <title>Textstar: a Fast and Lightweight Graph-Based Algorithm for Extractive Summarization and Keyphrase Extraction</title>
      <author><first>David</first><last>Brock</last></author>
      <author><first>Ali</first><last>Khan</last></author>
      <author><first>Tam</first><last>Doan</last></author>
      <author><first>Alicia</first><last>Lin</last></author>
      <author><first>Yifan</first><last>Guo</last></author>
      <author><first>Paul</first><last>Tarau</last></author>
      <pages>161–169</pages>
      <abstract>We introduce Textstar, a graph-based summarization and keyphrase extraction system that builds a document graph using only lemmatization and POS tagging. The document graph aggregates connections between lemma and sentence identifier nodes. Consecutive lemmas in each sentence, as well as consecutive sentences themselves, are connected in rings to form a ring of rings representing the document. We iteratively apply a centrality algorithm of our choice to the document graph and trim the lowest ranked nodes at each step. After the desired number of remaining sentences and lemmas is reached, we extract the sentences as the summary, and the remaining lemmas are aggregated into keyphrases using their context. Our algorithm is efficient enough to one-shot process large document graphs without any training, and empirical evaluation on several benchmarks indicates that our performance is higher than most other graph based algorithms.</abstract>
      <url hash="2b3cdb87">2022.alta-1.22</url>
      <bibkey>brock-etal-2022-textstar</bibkey>
    </paper>
    <paper id="23">
      <title>Contrastive Visual and Language Learning for Visual Relationship Detection</title>
      <author><first>Thanh</first><last>Tran</last></author>
      <author><first>Maelic</first><last>Neau</last></author>
      <author><first>Paulo</first><last>Santos</last></author>
      <author><first>David</first><last>Powers</last></author>
      <pages>170–177</pages>
      <abstract>Visual Relationship Detection aims to understand real-world objects’ interactions by grounding visual concepts to compositional visual relation triples, written in the form of (subject, predicate, object). Previous works have explored the use of contrastive learning to implicitly predict the predicates from the relevant image regions. However, these models often directly leverage in-distribution spatial and language co-occurrences biases during training, preventing the models from generalizing to out-of-distribution compositions. In this work, we examine whether contrastive vision and language models pre-trained on large-scale external image and text dataset can assist the detection of compositional visual relationships. To this end, we propose a semi-supervised contrastive fine-tuning approach for the visual relationship detection task. The results show that fine-tuned models that were pre-trained on larger datasets do not yield better performance when performing visual relationship detection, and larger models can yield lower performance when compared with their smaller counterparts.</abstract>
      <url hash="a0db5c15">2022.alta-1.23</url>
      <bibkey>tran-etal-2022-contrastive</bibkey>
    </paper>
    <paper id="24">
      <title>Overview of the 2022 <fixed-case>ALTA</fixed-case> Shared task: <fixed-case>PIBOSO</fixed-case> sentence classification, 10 years later</title>
      <author><first>Diego</first><last>Mollá</last></author>
      <pages>178–182</pages>
      <abstract>The 2022 ALTA shared task has been running annually since 2010. This year, the shared task is a re-visit of the 2012 ALTA shared task. The purpose of this task is to classify sentences of medical publications using the PIBOSO taxonomy. This is a multi-label classification task which can help medical researchers and practitioners conduct Evidence Based Medicine (EBM). In this paper we present the task, the evaluation criteria, and the results of the systems participating in the shared task.</abstract>
      <url hash="06051006">2022.alta-1.24</url>
      <bibkey>molla-2022-overview</bibkey>
    </paper>
    <paper id="25">
      <title>Estimating the Strength of Authorship Evidence with a Deep-Learning-Based Approach</title>
      <author><first>Shunichi</first><last>Ishihara</last></author>
      <author><first>Satoru</first><last>Tsuge</last></author>
      <author><first>Mitsuyuki</first><last>Inaba</last></author>
      <author><first>Wataru</first><last>Zaitsu</last></author>
      <pages>183–187</pages>
      <abstract>This study is the first likelihood ratio (LR)-based forensic text comparison study in which each text is mapped onto an embedding vector using RoBERTa as the pre-trained model. The scores obtained with Cosine distance and probabilistic linear discriminant analysis (PLDA) were calibrated to LRs with logistic regression; the quality of the LRs was assessed by log LR cost (Cllr). Although the documents in the experiments were very short (maximum 100 words), the systems reached the Cllr values of 0.55595 and 0.71591 for the Cosine and PLDA systems, respectively. The effectiveness of deep-learning-based text representation is discussed by comparing the results of the current study to those of the previous studies of systems based on conventional feature engineering tested with longer documents.</abstract>
      <url hash="ac6ab209">2022.alta-1.25</url>
      <bibkey>ishihara-etal-2022-estimating</bibkey>
    </paper>
    <paper id="26">
      <title>Automatic Classification of Evidence Based Medicine Using Transformers</title>
      <author><first>Necva</first><last>Bolucu</last></author>
      <author><first>Pinar Uskaner</first><last>Hepsag</last></author>
      <pages>188–192</pages>
      <url hash="430bd19a">2022.alta-1.26</url>
      <bibkey>bolucu-hepsag-2022-automatic</bibkey>
    </paper>
    <paper id="27">
      <title>Context-Aware Sentence Classification in Evidence-Based Medicine</title>
      <author><first>Biaoyan</first><last>Fang</last></author>
      <author><first>Fajri</first><last>Koto</last></author>
      <pages>193–198</pages>
      <url hash="333796a5">2022.alta-1.27</url>
      <bibkey>fang-koto-2022-context</bibkey>
    </paper>
  </volume>
</collection>
