<?xml version='1.0' encoding='UTF-8'?>
<collection id="2020.lt4gov">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on Language Technologies for Government and Public Administration (LT4Gov)</booktitle>
      <editor><first>Doaa</first><last>Samy</last></editor>
      <editor><first>David</first><last>Pérez-Fernández</last></editor>
      <editor><first>Jerónimo</first><last>Arenas-García</last></editor>
      <publisher>European Language Resources Association</publisher>
      <address>Marseille, France</address>
      <month>May</month>
      <year>2020</year>
      <isbn>979-10-95546-62-7</isbn>
    </meta>
    <frontmatter>
      <url hash="bb9b6675">2020.lt4gov-1.0</url>
    </frontmatter>
    <paper id="1">
      <title>Development of Natural Language Processing Tools to Support Determination of Federal Disability Benefits in the <fixed-case>U</fixed-case>.<fixed-case>S</fixed-case>.</title>
      <author><first>Bart</first><last>Desmet</last></author>
      <author><first>Julia</first><last>Porcino</last></author>
      <author><first>Ayah</first><last>Zirikly</last></author>
      <author><first>Denis</first><last>Newman-Griffis</last></author>
      <author><first>Guy</first><last>Divita</last></author>
      <author><first>Elizabeth</first><last>Rasch</last></author>
      <pages>1–6</pages>
      <abstract>The disability benefits programs administered by the US Social Security Administration (SSA) receive between 2 and 3 million new applications each year. Adjudicators manually review hundreds of evidence pages per case to determine eligibility based on financial, medical, and functional criteria. Natural Language Processing (NLP) technology is uniquely suited to support this adjudication work and is a critical component of an ongoing inter-agency collaboration between SSA and the National Institutes of Health. This NLP work provides resources and models for document ranking, named entity recognition, and terminology extraction in order to automatically identify documents and reports pertinent to a case, and to allow adjudicators to search for and locate desired information quickly. In this paper, we describe our vision for how NLP can impact SSA’s adjudication process, present the resources and models that have been developed, and discuss some of the benefits and challenges in working with large-scale government data, and its specific properties in the functional domain.</abstract>
      <url hash="01de5e78">2020.lt4gov-1.1</url>
      <language>eng</language>
    </paper>
    <paper id="2">
      <title><fixed-case>FRAQUE</fixed-case>: a <fixed-case>FRA</fixed-case>me-based <fixed-case>QUE</fixed-case>stion-answering system for the Public Administration domain</title>
      <author><first>Martina</first><last>Miliani</last></author>
      <author><first>Lucia C.</first><last>Passaro</last></author>
      <author><first>Alessandro</first><last>Lenci</last></author>
      <pages>7–14</pages>
      <abstract>In this paper, we propose FRAQUE, a question answering system for factoid questions in the Public administration domain. The system is based on semantic frames, here intended as collections of slots typed with their possible values. FRAQUE queries unstructured textual data and exploits the potential of different approaches: it extracts pattern elements from texts which are linguistically analyzed through statistical methods.FRAQUE allows Italian users to query vast document repositories related to the domain of Public Administration. Given the statistical nature of most of its components such as word embeddings, the system allows for a flexible domain and language adaptation process. FRAQUE’s goal is to associate questions with frames stored into a Knowledge Graph along with relevant document passages, which are returned as the answer.</abstract>
      <url hash="481e43aa">2020.lt4gov-1.2</url>
      <language>eng</language>
    </paper>
    <paper id="3">
      <title>Enhancing Job Searches in <fixed-case>M</fixed-case>exico City with Language Technologies</title>
      <author><first>Gerardo</first><last>Sierra Martínez</last></author>
      <author><first>Gemma</first><last>Bel-Enguix</last></author>
      <author><first>Helena</first><last>Gómez-Adorno</last></author>
      <author><first>Juan Manuel</first><last>Torres Moreno</last></author>
      <author><first>Tonatiuh</first><last>Hernández-García</last></author>
      <author><first>Julio V</first><last>Guadarrama-Olvera</last></author>
      <author><first>Jesús-Germán</first><last>Ortiz-Barajas</last></author>
      <author><first>Ángela María</first><last>Rojas</last></author>
      <author><first>Tomas</first><last>Damerau</last></author>
      <author><first>Soledad</first><last>Aragón Martínez</last></author>
      <pages>15–21</pages>
      <abstract>In this paper, we show the enhancing of the Demanded Skills Diagnosis (DiCoDe: Diagnóstico de Competencias Demandadas), a system developed by Mexico City’s Ministry of Labor and Employment Promotion (STyFE: Secretaría de Trabajo y Fomento del Empleo de la Ciudad de México) that seeks to reduce information asymmetries between job seekers and employers. The project uses webscraping techniques to retrieve job vacancies posted on private job portals on a daily basis and with the purpose of informing training and individual case management policies as well as labor market monitoring. For this purpose, a collaboration project between STyFE and the Language Engineering Group (GIL: Grupo de Ingeniería Lingüística) was established in order to enhance DiCoDe by applying NLP models and semantic analysis. By this collaboration, DiCoDe’s job vacancies system’s macro-structure and its geographic referencing at the city hall (municipality) level were improved. More specifically, dictionaries were created to identify demanded competencies, skills and abilities (CSA) and algorithms were developed for dynamic classifying of vacancies and identifying terms for searches on free text, in order to improve the results and processing time of queries.</abstract>
      <url hash="35fcebf1">2020.lt4gov-1.3</url>
      <language>eng</language>
    </paper>
    <paper id="4">
      <title>Research &amp; Innovation Activities’ Impact Assessment: The <fixed-case>D</fixed-case>ata4<fixed-case>I</fixed-case>mpact System</title>
      <author><first>Ioanna</first><last>Grypari</last></author>
      <author><first>Dimitris</first><last>Pappas</last></author>
      <author><first>Natalia</first><last>Manola</last></author>
      <author><first>Haris</first><last>Papageorgiou</last></author>
      <pages>22–27</pages>
      <abstract>Cat. 2 Show-case: We present the Data4Impact (D4I) platform, a novel end-to-end system for evidence-based, timely and accurate monitoring and evaluation of research and innovation (R&amp;I) activities. Using the latest technological advances in Human Language Technology (HLT) and our data-driven methodology, we build a novel set of indicators in order to track funded projects and their impact on science, the economy and the society as a whole, during and after the project life-cycle. We develop our methodology by targeting Health-related EC projects from 2007 to 2019 to produce solutions that meet the needs of stakeholders (mainly policy-makers and research funders). Various D4I text analytics workflows process datasets and their metadata, extract valuable insights and estimate intermediate results and metrics, culminating in a set of robust indicators that the users can interact with through our dashboard, the D4I Monitor (available at monitor.data4impact.eu). Therefore, our approach, which can be generalized to different contexts, is multidimensional (technology, tools, indicators, dashboard) and the resulting system can provide an innovative solution for public administrators in their policy-making needs related to RDI funding allocation.</abstract>
      <url hash="9c318a57">2020.lt4gov-1.4</url>
      <language>eng</language>
    </paper>
    <paper id="5">
      <title>The <fixed-case>A</fixed-case>ustrian Language Resource Portal for the Use and Provision of Language Resources in a Language Variety by Public Administration – a Showcase for Collaboration between Public Administration and a University</title>
      <author><first>Barbara</first><last>Heinisch</last></author>
      <author><first>Vesna</first><last>Lušicky</last></author>
      <pages>28–31</pages>
      <abstract>The Austrian Language Resource Portal (Sprachressourcenportal Österreichs) is Austria’s central platform for language resources in the area of public administration. It focuses on language resources in the Austrian variety of the German language. As a product of the cooperation between a public administration body and a university, the Portal contains various language resources (terminological resources in the public administration domain, a language guide, named entities based on open public data, translation memories, etc.). German is a pluricentric language that considerably varies in the domain of public administration due to different public administration systems. Therefore, the Austrian Language Resource Portal stresses the importance of language resources specific to a language variety, thus paving the way for the re-use of variety-specific language data for human language technology, such as machine translation training, for the Austrian standard variety.</abstract>
      <url hash="4af1bfd9">2020.lt4gov-1.5</url>
      <language>eng</language>
    </paper>
    <paper id="6">
      <title>Legal-<fixed-case>ES</fixed-case>: A Set of Large Scale Resources for <fixed-case>S</fixed-case>panish Legal Text Processing</title>
      <author><first>Doaa</first><last>Samy</last></author>
      <author><first>Jerónimo</first><last>Arenas-García</last></author>
      <author><first>David</first><last>Pérez-Fernández</last></author>
      <pages>32–36</pages>
      <abstract>Legal-ES is an open source resource kit for legal Spanish. It consists of a large scale Spanish corpus of open legal texts and different kinds of language models including word embeddings and topic models. The corpus includes over 1000 million words covering a collection of legislative and administrative open access documents in Spanish from different sources representing international, national and regional entities. The corpus is pre-processed and tokenized using Spacy. For the word embeddings, gensim was used on the collection of tokens, producing a representation space that is especially suited to reflect the inherent characteristics of the legal domain. We calculate also topic models to obtain a convenient tool to understand the main topics in the corpus and to navigate through the documents exploiting the semantic similarity among documents. We will analyse the time structure of a dynamic topic model to infer changes in the legal production of Spanish jurisdiction that have occurred over the analysed time framework.</abstract>
      <url hash="af935b42">2020.lt4gov-1.6</url>
      <language>eng</language>
    </paper>
  </volume>
</collection>
