<?xml version='1.0' encoding='UTF-8'?>
<collection id="2020.mwe">
  <volume id="1" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the Joint Workshop on Multiword Expressions and Electronic Lexicons</booktitle>
      <editor><first>Stella</first><last>Markantonatou</last></editor>
      <editor><first>John</first><last>McCrae</last></editor>
      <editor><first>Jelena</first><last>Mitrović</last></editor>
      <editor><first>Carole</first><last>Tiberius</last></editor>
      <editor><first>Carlos</first><last>Ramisch</last></editor>
      <editor><first>Ashwini</first><last>Vaidya</last></editor>
      <editor><first>Petya</first><last>Osenova</last></editor>
      <editor><first>Agata</first><last>Savary</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>online</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="fa57eb6a">2020.mwe-1.0</url>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>C</fixed-case>oll<fixed-case>F</fixed-case>r<fixed-case>E</fixed-case>n: Rich Bilingual <fixed-case>E</fixed-case>nglish–<fixed-case>F</fixed-case>rench Collocation Resource</title>
      <author><first>Beatriz</first><last>Fisas</last></author>
      <author><first>Joan</first><last>Codina-Filbá</last></author>
      <author><first>Luis</first><last>Espinosa Anke</last></author>
      <author><first>Leo</first><last>Wanner</last></author>
      <pages>1–12</pages>
      <abstract>Collocations in the sense of idiosyncratic lexical co-occurrences of two syntactically bound words traditionally pose a challenge to language learners and many Natural Language Processing (NLP) applications alike. Reliable ground truth (i.e., ideally manually compiled) resources are thus of high value. We present a manually compiled bilingual English–French collocation resource with 7,480 collocations in English and 6,733 in French. Each collocation is enriched with information that facilitates its downstream exploitation in NLP tasks such as machine translation, word sense disambiguation, natural language generation, relation classification, and so forth. Our proposed enrichment covers: the semantic category of the collocation (its lexical function), its vector space representation (for each individual word as well as their joint collocation embedding), a subcategorization pattern of both its elements, as well as their corresponding BabelNet id, and finally, indices of their occurrences in large scale reference corpora.</abstract>
      <url hash="e9869b4e">2020.mwe-1.1</url>
    </paper>
    <paper id="2">
      <title>Filling the ___-s in <fixed-case>F</fixed-case>innish <fixed-case>MWE</fixed-case> lexicons</title>
      <author><first>Frankie</first><last>Robertson</last></author>
      <pages>13–21</pages>
      <abstract>This paper describes the automatic construction of FinnMWE: a lexicon of Finnish Multi-Word Expressions (MWEs). In focus here are syntactic frames: verbal constructions with arguments in a particular morphological form. The verbal frames are automatically extracted from FinnWordNet and English Wiktionary. The resulting lexicon interoperates with dependency tree searching software so that instances can be quickly found within dependency treebanks. The extraction and enrichment process is explained in detail. The resulting resource is evaluated in terms of its coverage of different types of MWEs. It is also compared with and evaluated against Finnish PropBank.</abstract>
      <url hash="b6459bc7">2020.mwe-1.2</url>
    </paper>
    <paper id="3">
      <title>Hierarchy-aware Learning of Sequential Tool Usage via Semi-automatically Constructed Taxonomies</title>
      <author><first>Nima</first><last>Nabizadeh</last></author>
      <author><first>Martin</first><last>Heckmann</last></author>
      <author><first>Dorothea</first><last>Kolossa</last></author>
      <pages>22–26</pages>
      <abstract>When repairing a device, humans employ a series of tools that corresponds to the arrangement of the device components. Such sequences of tool usage can be learned from repair manuals, so that at each step, having observed the previously applied tools, a sequential model can predict the next required tool. In this paper, we improve the tool prediction performance of such methods by additionally taking the hierarchical relationships among the tools into account. To this aim, we build a taxonomy of tools with hyponymy and hypernymy relations from the data by decomposing all multi-word expressions of tool names. We then develop a sequential model that performs a binary prediction for each node in the taxonomy. The evaluation of the method on a dataset of repair manuals shows that encoding the tools with the constructed taxonomy and using a top-down beam search for decoding increases the prediction accuracy and yields an interpretable taxonomy as a potentially valuable byproduct.</abstract>
      <url hash="a47f13b7">2020.mwe-1.3</url>
    </paper>
    <paper id="4">
      <title>Scalar vs. mereological conceptualizations of the N-<fixed-case>BY</fixed-case>-N and <fixed-case>NUM</fixed-case>-<fixed-case>BY</fixed-case>-<fixed-case>NUM</fixed-case> adverbials</title>
      <author><first>Lucia</first><last>Vlášková</last></author>
      <author><first>Mojmír</first><last>Dočekal</last></author>
      <pages>27–31</pages>
      <abstract>The multiword adverbials N-BY-N and NUM-BY-NUM (as English “brick by brick” and “one by one”, respectively) are event modifiers which require temporal sequencing of the event they modify into a linearly ordered series of sub-events. Previous studies unified these two constructions under a single semantic analysis and adopted either a mereological or a scalar approach. However, based on a corpus study examining new Slavic language material and a binomial logistic regression modelling of the manually annotated data, we argue that two separate analyses are needed to account for these constructions, namely a scalar analysis for the N-BY-N construction and a mereological one for the NUM-BY-NUM construction.</abstract>
      <url hash="edbebb9a">2020.mwe-1.4</url>
    </paper>
    <paper id="5">
      <title><fixed-case>P</fixed-case>olish corpus of verbal multiword expressions</title>
      <author><first>Agata</first><last>Savary</last></author>
      <author><first>Jakub</first><last>Waszczuk</last></author>
      <pages>32–43</pages>
      <abstract>This paper describes a manually annotated corpus of verbal multi-word expressions in Polish. It is among the 4 biggest datasets in release 1.2 of the PARSEME multiligual corpus. We describe the data sources, as well as the annotation process and its outcomes. We also present interesting phenomena encountered during the annotation task and put forward enhancements for the PARSEME annotation guidelines.</abstract>
      <url hash="41e86711">2020.mwe-1.5</url>
    </paper>
    <paper id="6">
      <title><fixed-case>A</fixed-case>lpha<fixed-case>MWE</fixed-case>: Construction of Multilingual Parallel Corpora with <fixed-case>MWE</fixed-case> Annotations</title>
      <author><first>Lifeng</first><last>Han</last></author>
      <author><first>Gareth</first><last>Jones</last></author>
      <author><first>Alan</first><last>Smeaton</last></author>
      <pages>44–57</pages>
      <abstract>In this work, we present the construction of multilingual parallel corpora with annotation of multiword expressions (MWEs). MWEs include verbal MWEs (vMWEs) defined in the PARSEME shared task that have a verb as the head of the studied terms. The annotated vMWEs are also bilingually and multilingually aligned manually. The languages covered include English, Chinese, Polish, and German. Our original English corpus is taken from the PARSEME shared task in 2018. We performed machine translation of this source corpus followed by human post editing and annotation of target MWEs. Strict quality control was applied for error limitation, i.e., each MT output sentence received first manual post editing and annotation plus second manual quality rechecking. One of our findings during corpora preparation is that accurate translation of MWEs presents challenges to MT systems. To facilitate further MT research, we present a categorisation of the error types encountered by MT systems in performing MWE related translation. To acquire a broader view of MT issues, we selected four popular state-of-the-art MT models for comparisons namely: Microsoft Bing Translator, GoogleMT, Baidu Fanyi and DeepL MT. Because of the noise removal, translation post editing and MWE annotation by human professionals, we believe our AlphaMWE dataset will be an asset for cross-lingual and multilingual research, such as MT and information extraction. Our multilingual corpora are available as open access at github.com/poethan/AlphaMWE.</abstract>
      <url hash="16e295b9">2020.mwe-1.6</url>
    </paper>
    <paper id="7">
      <title>Annotating Verbal <fixed-case>MWE</fixed-case>s in <fixed-case>I</fixed-case>rish for the <fixed-case>PARSEME</fixed-case> Shared Task 1.2</title>
      <author><first>Abigail</first><last>Walsh</last></author>
      <author><first>Teresa</first><last>Lynn</last></author>
      <author><first>Jennifer</first><last>Foster</last></author>
      <pages>58–65</pages>
      <abstract>This paper describes the creation of two Irish corpora (labelled and unlabelled) for verbal MWEs for inclusion in the PARSEME Shared Task 1.2 on automatic identification of verbal MWEs, and the process of developing verbal MWE categories for Irish. A qualitative analysis on the two corpora is presented, along with discussion of Irish verbal MWEs.</abstract>
      <url hash="c78d9a40">2020.mwe-1.7</url>
    </paper>
    <paper id="8">
      <title><fixed-case>VMWE</fixed-case> discovery: a comparative analysis between Literature and <fixed-case>T</fixed-case>witter Corpora</title>
      <author><first>Vivian</first><last>Stamou</last></author>
      <author><first>Artemis</first><last>Xylogianni</last></author>
      <author><first>Marilena</first><last>Malli</last></author>
      <author><first>Penny</first><last>Takorou</last></author>
      <author><first>Stella</first><last>Markantonatou</last></author>
      <pages>66–72</pages>
      <abstract>We evaluate manually five lexical association measurements as regards the discovery of Modern Greek verb multiword expressions with two or more lexicalised components usingmwetoolkit3 (Ramisch et al., 2010). We use Twitter corpora and compare our findings with previous work on fiction corpora. The results of LL, MLE and T-score were found to overlap significantly in both the fiction and the Twitter corpora, while the results of PMI and Dice do not.We find that MWEs with two lexicalised components are more frequent in Twitter than in fiction corpora and that lean syntactic patterns help retrieve them more efficiently than richer ones.Our work (i) supports the enrichment of the lexicographical database for Modern Greek MWEs’ IDION’ (Markantonatou et al., 2019) and (ii) highlights aspects of the usage of five association measurements on specific text genres for best MWE discovery results.</abstract>
      <url hash="d1c2a98e">2020.mwe-1.8</url>
    </paper>
    <paper id="9">
      <title>Generationary or: “How We Went beyond Sense Inventories and Learnedto Gloss”</title>
      <author><first>Roberto</first><last>Navigli</last></author>
      <pages>73</pages>
      <abstract>In this talk I present Generationary, an approach that goes beyond the mainstream assumption that word senses can be represented as discrete items of a predefined inventory, and put forward a unified model which produces contextualized definitions for arbitrary lexical items, from words to phrases and even sentences. Generationary employs a novel span-based encoding scheme to fine-tune an English pre-trained Encoder-Decoder system and generate new definitions. Our model outperforms previous approaches in the generative task of Definition Modeling in many settings, but it also matches or surpasses the state of the art in discriminative tasks such as Word Sense Disambiguation and Word-in-Context. Finally, we show that Generationary benefits from training on definitions from multiple inventories, with strong gains across benchmarks, including a novel dataset of definitions for free adjective-noun phrases.</abstract>
      <url hash="11c576a8">2020.mwe-1.9</url>
    </paper>
    <paper id="10">
      <title>Multi-word Expressions for Abusive Speech Detection in <fixed-case>S</fixed-case>erbian</title>
      <author><first>Ranka</first><last>Stankovic</last></author>
      <author><first>Jelena</first><last>Mitrović</last></author>
      <author><first>Danka</first><last>Jokic</last></author>
      <author><first>Cvetana</first><last>Krstev</last></author>
      <pages>74–84</pages>
      <abstract>This paper presents our work on the refinement and improvement of the Serbian language part of Hurtlex, a multilingual lexicon of words to hurt. We pay special attention to adding Multi-word expressions that can be seen as abusive, as such lexical entries are very important in obtaining good results in a plethora of abusive language detection tasks. We use Serbian morphological dictionaries as a basis for data cleaning and MWE dictionary creation. A connection to other lexical and semantic resources in Serbian is outlined and building of abusive language detection systems based on that connection is foreseen.</abstract>
      <url hash="1a680f61">2020.mwe-1.10</url>
    </paper>
    <paper id="11">
      <title>Disambiguation of Potentially Idiomatic Expressions with Contextual Embeddings</title>
      <author><first>Murathan</first><last>Kurfalı</last></author>
      <author><first>Robert</first><last>Östling</last></author>
      <pages>85–94</pages>
      <abstract>The majority of multiword expressions can be interpreted as figuratively or literally in different contexts which pose challenges in a number of downstream tasks. Most previous work deals with this ambiguity following the observation that MWEs with different usages occur in distinctly different contexts. Following this insight, we explore the usefulness of contextual embeddings by means of both supervised and unsupervised classification. The results show that in the supervised setting, the state-of-the-art can be substantially improved for all expressions in the experiments. The unsupervised classification, similarly, yields very impressive results, comparing favorably to the supervised classifier for the majority of the expressions. We also show that multilingual contextual embeddings can also be employed for this task without leading to any significant loss in performance; hence, the proposed methodology has the potential to be extended to a number of languages.</abstract>
      <url hash="4fabe670">2020.mwe-1.11</url>
    </paper>
    <paper id="12">
      <title>Comparing word2vec and <fixed-case>G</fixed-case>lo<fixed-case>V</fixed-case>e for Automatic Measurement of <fixed-case>MWE</fixed-case> Compositionality</title>
      <author><first>Thomas</first><last>Pickard</last></author>
      <pages>95–100</pages>
      <abstract>This paper explores the use of word2vec and GloVe embeddings for unsupervised measurement of the semantic compositionality of MWE candidates. Through comparison with several human-annotated reference sets, we find word2vec to be substantively superior to GloVe for this task. We also find Simple English Wikipedia to be a poor-quality resource for compositionality assessment, but demonstrate that a sample of 10% of sentences in the English Wikipedia can provide a conveniently tractable corpus with only moderate reduction in the quality of outputs.</abstract>
      <url hash="a1809f27">2020.mwe-1.12</url>
    </paper>
    <paper id="13">
      <title>Automatic detection of unexpected/erroneous collocations in learner corpus</title>
      <author><first>Jen-Yu</first><last>Li</last></author>
      <author><first>Thomas</first><last>Gaillat</last></author>
      <pages>101–106</pages>
      <abstract>This research investigates the collocational errors made by English learners in a learner corpus. It focuses on the extraction of unexpected collocations. A system was proposed and implemented with open source toolkit. Firstly, the collocation extraction module was evaluated by a corpus with manually annotated collocations. Secondly, a standard collocation list was collected from a corpus of native speaker. Thirdly, a list of unexpected collocations was generated by extracting candidates from a learner corpus and discarding the standard collocations on the list. The overall performance was evaluated, and possible sources of error were pointed out for future improvement.</abstract>
      <url hash="eb8d9a5f">2020.mwe-1.13</url>
    </paper>
    <paper id="14">
      <title>Edition 1.2 of the <fixed-case>PARSEME</fixed-case> Shared Task on Semi-supervised Identification of Verbal Multiword Expressions</title>
      <author><first>Carlos</first><last>Ramisch</last></author>
      <author><first>Agata</first><last>Savary</last></author>
      <author><first>Bruno</first><last>Guillaume</last></author>
      <author><first>Jakub</first><last>Waszczuk</last></author>
      <author><first>Marie</first><last>Candito</last></author>
      <author><first>Ashwini</first><last>Vaidya</last></author>
      <author><first>Verginica</first><last>Barbu Mititelu</last></author>
      <author><first>Archna</first><last>Bhatia</last></author>
      <author><first>Uxoa</first><last>Iñurrieta</last></author>
      <author><first>Voula</first><last>Giouli</last></author>
      <author><first>Tunga</first><last>Gungor</last></author>
      <author><first>Menghan</first><last>Jiang</last></author>
      <author><first>Timm</first><last>Lichte</last></author>
      <author><first>Chaya</first><last>Liebeskind</last></author>
      <author><first>Johanna</first><last>Monti</last></author>
      <author><first>Renata</first><last>Ramisch</last></author>
      <author><first>Sara</first><last>Stymne</last></author>
      <author><first>Abigail</first><last>Walsh</last></author>
      <author><first>Hongzhi</first><last>Xu</last></author>
      <pages>107–118</pages>
      <abstract>We present edition 1.2 of the PARSEME shared task on identification of verbal multiword expressions (VMWEs). Lessons learned from previous editions indicate that VMWEs have low ambiguity, and that the major challenge lies in identifying test instances never seen in the training data. Therefore, this edition focuses on unseen VMWEs. We have split annotated corpora so that the test corpora contain around 300 unseen VMWEs, and we provide non-annotated raw corpora to be used by complementary discovery methods. We released annotated and raw corpora in 14 languages, and this semi-supervised challenge attracted 7 teams who submitted 9 system results. This paper describes the effort of corpus creation, the task design, and the results obtained by the participating systems, especially their performance on unseen expressions.</abstract>
      <url hash="27982d94">2020.mwe-1.14</url>
    </paper>
    <paper id="15">
      <title><fixed-case>HMS</fixed-case>id and <fixed-case>HMS</fixed-case>id2 at <fixed-case>PARSEME</fixed-case> Shared Task 2020: Computational Corpus Linguistics and unseen-in-training <fixed-case>MWE</fixed-case>s</title>
      <author><first>Jean-Pierre</first><last>Colson</last></author>
      <pages>119–123</pages>
      <abstract>This paper is a system description of HMSid, officially sent to the PARSEME Shared Task 2020 for one language (French), in the open track. It also describes HMSid2, sent to the organ-izers of the workshop after the deadline and using the same methodology but in the closed track. Both systems do not rely on machine learning, but on computational corpus linguistics. Their score for unseen MWEs is very promising, especially in the case of HMSid2, which would have received the best score for unseen MWEs in the French closed track.</abstract>
      <url hash="4a3b5c6b">2020.mwe-1.15</url>
    </paper>
    <paper id="16">
      <title><fixed-case>S</fixed-case>een2<fixed-case>U</fixed-case>nseen at <fixed-case>PARSEME</fixed-case> Shared Task 2020: All Roads do not Lead to Unseen Verb-Noun <fixed-case>VMWE</fixed-case>s</title>
      <author><first>Caroline</first><last>Pasquer</last></author>
      <author><first>Agata</first><last>Savary</last></author>
      <author><first>Carlos</first><last>Ramisch</last></author>
      <author><first>Jean-Yves</first><last>Antoine</last></author>
      <pages>124–129</pages>
      <abstract>We describe the Seen2Unseen system that participated in edition 1.2 of the PARSEME shared task on automatic identification of verbal multiword expressions (VMWEs). The identification of VMWEs that do not appear in the provided training corpora (called unseen VMWEs) – with a focus here on verb-noun VMWEs – is based on mutual information and lexical substitution or translation of seen VMWEs. We present the architecture of the system, report results for 14 languages, and propose an error analysis.</abstract>
      <url hash="45c13b33">2020.mwe-1.16</url>
    </paper>
    <paper id="17">
      <title><fixed-case>ERMI</fixed-case> at <fixed-case>PARSEME</fixed-case> Shared Task 2020: Embedding-Rich Multiword Expression Identification</title>
      <author><first>Zeynep</first><last>Yirmibeşoğlu</last></author>
      <author><first>Tunga</first><last>Gungor</last></author>
      <pages>130–135</pages>
      <abstract>This paper describes the ERMI system submitted to the closed track of the PARSEME shared task 2020 on automatic identification of verbal multiword expressions (VMWEs). ERMI is an embedding-rich bidirectional LSTM-CRF model, which takes into account the embeddings of the word, its POS tag, dependency relation, and its head word. The results are reported for 14 languages, where the system is ranked 1st in the general cross-lingual ranking of the closed track systems, according to the Unseen MWE-based F1.</abstract>
      <url hash="0ee06cf4">2020.mwe-1.17</url>
    </paper>
    <paper id="18">
      <title><fixed-case>TRAVIS</fixed-case> at <fixed-case>PARSEME</fixed-case> Shared Task 2020: How good is (m)<fixed-case>BERT</fixed-case> at seeing the unseen?</title>
      <author><first>Murathan</first><last>Kurfalı</last></author>
      <pages>136–141</pages>
      <abstract>This paper describes the TRAVIS system built for the PARSEME Shared Task 2020 on semi-supervised identification of verbal multiword expressions. TRAVIS is a fully feature-independent model, relying only on the contextual embeddings. We have participated with two variants of TRAVIS, TRAVIS-multi and TRAVIS-mono, where the former employs multilingual contextual embeddings and the latter uses monolingual ones. Our systems are ranked second and third among seven submissions in the open track, respectively. Despite the strong performance of multilingual contextual embeddings across all languages, the results show that language-specific contextual embeddings have better generalization capabilities.</abstract>
      <url hash="79c49226">2020.mwe-1.18</url>
    </paper>
    <paper id="19">
      <title><fixed-case>MTLB</fixed-case>-<fixed-case>STRUCT</fixed-case> @Parseme 2020: Capturing Unseen Multiword Expressions Using Multi-task Learning and Pre-trained Masked Language Models</title>
      <author><first>Shiva</first><last>Taslimipoor</last></author>
      <author><first>Sara</first><last>Bahaadini</last></author>
      <author><first>Ekaterina</first><last>Kochmar</last></author>
      <pages>142–148</pages>
      <abstract>This paper describes a semi-supervised system that jointly learns verbal multiword expressions (VMWEs) and dependency parse trees as an auxiliary task. The model benefits from pre-trained multilingual BERT. BERT hidden layers are shared among the two tasks and we introduce an additional linear layer to retrieve VMWE tags. The dependency parse tree prediction is modelled by a linear layer and a bilinear one plus a tree CRF architecture on top of the shared BERT. The system has participated in the open track of the PARSEME shared task 2020 and ranked first in terms of F1-score in identifying unseen VMWEs as well as VMWEs in general, averaged across all 14 languages.</abstract>
      <url hash="50a7c4a7">2020.mwe-1.19</url>
    </paper>
    <paper id="20">
      <title><fixed-case>M</fixed-case>ulti<fixed-case>V</fixed-case>itamin<fixed-case>B</fixed-case>ooster and <fixed-case>M</fixed-case>ulti<fixed-case>V</fixed-case>itamin<fixed-case>R</fixed-case>egressor at <fixed-case>PARSEME</fixed-case> Shared Task 2020: Combining Window- and Dependency-Based Features with Multilingual Contextualized Word Embeddings for Detecting Verbal Multiword Expressions</title>
      <author><first>Sebastian</first><last>Gombert</last></author>
      <author><first>Sabine</first><last>Bartsch</last></author>
      <pages>149–155</pages>
      <abstract>In this paper, we present MultiVitaminBooster, a system implemented for the PARSEME shared task on semi-supervised identification of verbal multiword expressions - edition 1.2. For our approach, we interpret detecting verbal multiword expressions as a token classification task aiming to decide whether a token is part of a verbal multiword expression or not. For this purpose, we train gradient boosting-based models. We encode tokens as feature vectors combining multilingual contextualized word embeddings provided by the XLM-RoBERTa language model with a more traditional linguistic feature set relying on context windows and dependency relations. Our system was ranked 7th in the official open track ranking of the shared task evaluations with an encoding-related bug distorting the results. For this reason we carry out further unofficial evaluations. Unofficial versions of our systems would have achieved higher ranks.</abstract>
      <url hash="40e930c0">2020.mwe-1.20</url>
    </paper>
  </volume>
</collection>
