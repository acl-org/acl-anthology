<?xml version='1.0' encoding='UTF-8'?>
<collection id="2021.cmcl">
  <volume id="1" ingest-date="2021-05-24">
    <meta>
      <booktitle>Proceedings of the Workshop on Cognitive Modeling and Computational Linguistics</booktitle>
      <editor><first>Emmanuele</first><last>Chersoni</last></editor>
      <editor><first>Nora</first><last>Hollenstein</last></editor>
      <editor><first>Cassandra</first><last>Jacobs</last></editor>
      <editor><first>Yohei</first><last>Oseki</last></editor>
      <editor><first>Laurent</first><last>Prévot</last></editor>
      <editor><first>Enrico</first><last>Santus</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>June</month>
      <year>2021</year>
      <url hash="85c83d62">2021.cmcl-1</url>
      <venue>cmcl</venue>
    </meta>
    <frontmatter>
      <url hash="494651d7">2021.cmcl-1.0</url>
      <bibkey>cmcl-2021-cognitive</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Non-Complementarity of Information in Word-Embedding and Brain Representations in Distinguishing between Concrete and Abstract Words</title>
      <author><first>Kalyan</first><last>Ramakrishnan</last></author>
      <author><first>Fatma</first><last>Deniz</last></author>
      <pages>1–11</pages>
      <abstract>Word concreteness and imageability have proven crucial in understanding how humans process and represent language in the brain. While word-embeddings do not explicitly incorporate the concreteness of words into their computations, they have been shown to accurately predict human judgments of concreteness and imageability. Inspired by the recent interest in using neural activity patterns to analyze distributed meaning representations, we first show that brain responses acquired while human subjects passively comprehend natural stories can significantly distinguish the concreteness levels of the words encountered. We then examine for the same task whether the additional perceptual information in the brain representations can complement the contextual information in the word-embeddings. However, the results of our predictive models and residual analyses indicate the contrary. We find that the relevant information in the brain representations is a subset of the relevant information in the contextualized word-embeddings, providing new insight into the existing state of natural language processing models.</abstract>
      <url hash="1cf27a4c">2021.cmcl-1.1</url>
      <attachment type="OptionalSupplementaryMaterial" hash="84fcb056">2021.cmcl-1.1.OptionalSupplementaryMaterial.zip</attachment>
      <doi>10.18653/v1/2021.cmcl-1.1</doi>
      <bibkey>ramakrishnan-deniz-2021-non</bibkey>
    </paper>
    <paper id="2">
      <title>Human Sentence Processing: Recurrence or Attention?</title>
      <author><first>Danny</first><last>Merkx</last></author>
      <author><first>Stefan L.</first><last>Frank</last></author>
      <pages>12–22</pages>
      <abstract>Recurrent neural networks (RNNs) have long been an architecture of interest for computational models of human sentence processing. The recently introduced Transformer architecture outperforms RNNs on many natural language processing tasks but little is known about its ability to model human language processing. We compare Transformer- and RNN-based language models’ ability to account for measures of human reading effort. Our analysis shows Transformers to outperform RNNs in explaining self-paced reading times and neural activity during reading English sentences, challenging the widely held idea that human sentence processing involves recurrent and immediate processing and provides evidence for cue-based retrieval.</abstract>
      <url hash="167e6770">2021.cmcl-1.2</url>
      <doi>10.18653/v1/2021.cmcl-1.2</doi>
      <bibkey>merkx-frank-2021-human</bibkey>
      <pwccode url="https://github.com/DannyMerkx/next_word_prediction" additional="false">DannyMerkx/next_word_prediction</pwccode>
    </paper>
    <paper id="3">
      <title>Modeling Incremental Language Comprehension in the Brain with <fixed-case>C</fixed-case>ombinatory <fixed-case>C</fixed-case>ategorial <fixed-case>G</fixed-case>rammar</title>
      <author><first>Miloš</first><last>Stanojević</last></author>
      <author><first>Shohini</first><last>Bhattasali</last></author>
      <author><first>Donald</first><last>Dunagan</last></author>
      <author><first>Luca</first><last>Campanelli</last></author>
      <author><first>Mark</first><last>Steedman</last></author>
      <author><first>Jonathan</first><last>Brennan</last></author>
      <author><first>John</first><last>Hale</last></author>
      <pages>23–38</pages>
      <abstract>Hierarchical sentence structure plays a role in word-by-word human sentence comprehension, but it remains unclear how best to characterize this structure and unknown how exactly it would be recognized in a step-by-step process model. With a view towards sharpening this picture, we model the time course of hemodynamic activity within the brain during an extended episode of naturalistic language comprehension using Combinatory Categorial Grammar (CCG). CCG has well-defined incremental parsing algorithms, surface compositional semantics, and can explain long-range dependencies as well as complicated cases of coordination. We find that CCG-derived predictors improve a regression model of fMRI time course in six language-relevant brain regions, over and above predictors derived from context-free phrase structure. Adding a special Revealing operator to CCG parsing, one designed to handle right-adjunction, improves the fit in three of these regions. This evidence for CCG from neuroimaging bolsters the more general case for mildly context-sensitive grammars in the cognitive science of language.</abstract>
      <url hash="d65b24ec">2021.cmcl-1.3</url>
      <doi>10.18653/v1/2021.cmcl-1.3</doi>
      <bibkey>stanojevic-etal-2021-modeling</bibkey>
    </paper>
    <paper id="4">
      <title>A Multinomial Processing Tree Model of <fixed-case>RC</fixed-case> Attachment</title>
      <author><first>Pavel</first><last>Logacev</last></author>
      <author><first>Noyan</first><last>Dokudan</last></author>
      <pages>39–47</pages>
      <abstract>In the field of sentence processing, speakers’ preferred interpretation of ambiguous sentences are often determined using a variant of a discrete choice task, in which participants are asked to indicate their preferred meaning of an ambiguous sentence. We discuss participants’ degree of attentiveness as a potential source of bias and variability in such tasks. We show that it may distort the estimates of the preference of a particular interpretation obtained in such experiments and may thus complicate the interpretation of the results as well as the comparison of the results of several experiments. We propose an analysis method based on multinomial processing tree models (Batchelder and Riefer, 1999) which can correct for this bias and allows for a separation of parameters of theoretical importance from nuisance parameters. We test two variants of the MPT-based model on experimental data from English and Turkish and demonstrate that our method can provide deeper insight into the processes underlying participants’ answering behavior and their interpretation preferences than an analysis based on raw percentages.</abstract>
      <url hash="7bf61ef2">2021.cmcl-1.4</url>
      <doi>10.18653/v1/2021.cmcl-1.4</doi>
      <bibkey>logacev-dokudan-2021-multinomial</bibkey>
    </paper>
    <paper id="5">
      <title>That Looks Hard: Characterizing Linguistic Complexity in Humans and Language Models</title>
      <author><first>Gabriele</first><last>Sarti</last></author>
      <author><first>Dominique</first><last>Brunato</last></author>
      <author><first>Felice</first><last>Dell’Orletta</last></author>
      <pages>48–60</pages>
      <abstract>This paper investigates the relationship between two complementary perspectives in the human assessment of sentence complexity and how they are modeled in a neural language model (NLM). The first perspective takes into account multiple online behavioral metrics obtained from eye-tracking recordings. The second one concerns the offline perception of complexity measured by explicit human judgments. Using a broad spectrum of linguistic features modeling lexical, morpho-syntactic, and syntactic properties of sentences, we perform a comprehensive analysis of linguistic phenomena associated with the two complexity viewpoints and report similarities and differences. We then show the effectiveness of linguistic features when explicitly leveraged by a regression model for predicting sentence complexity and compare its results with the ones obtained by a fine-tuned neural language model. We finally probe the NLM’s linguistic competence before and after fine-tuning, highlighting how linguistic information encoded in representations changes when the model learns to predict complexity.</abstract>
      <url hash="abaa89b4">2021.cmcl-1.5</url>
      <doi>10.18653/v1/2021.cmcl-1.5</doi>
      <bibkey>sarti-etal-2021-looks</bibkey>
      <pwccode url="https://github.com/gsarti/interpreting-complexity" additional="false">gsarti/interpreting-complexity</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="6">
      <title>Accounting for Agreement Phenomena in Sentence Comprehension with Transformer Language Models: Effects of Similarity-based Interference on Surprisal and Attention</title>
      <author><first>Soo Hyun</first><last>Ryu</last></author>
      <author><first>Richard</first><last>Lewis</last></author>
      <pages>61–71</pages>
      <abstract>We advance a novel explanation of similarity-based interference effects in subject-verb and reflexive pronoun agreement processing, grounded in surprisal values computed from a pretrained large-scale Transformer model, GPT-2. Specifically, we show that surprisal of the verb or reflexive pronoun predicts facilitatory interference effects in ungrammatical sentences, where a distractor noun that matches in number with the verb or pronouns leads to faster reading times, despite the distractor not participating in the agreement relation. We review the human empirical evidence for such effects, including recent meta-analyses and large-scale studies. We also show that attention patterns (indexed by entropy and other measures) in the Transformer show patterns of diffuse attention in the presence of similar distractors, consistent with cue-based retrieval models of parsing. But in contrast to these models, the attentional cues and memory representations are learned entirely from the simple self-supervised task of predicting the next word.</abstract>
      <url hash="951fe812">2021.cmcl-1.6</url>
      <doi>10.18653/v1/2021.cmcl-1.6</doi>
      <bibkey>ryu-lewis-2021-accounting</bibkey>
    </paper>
    <paper id="7">
      <title><fixed-case>CMCL</fixed-case> 2021 Shared Task on Eye-Tracking Prediction</title>
      <author><first>Nora</first><last>Hollenstein</last></author>
      <author><first>Emmanuele</first><last>Chersoni</last></author>
      <author><first>Cassandra L.</first><last>Jacobs</last></author>
      <author><first>Yohei</first><last>Oseki</last></author>
      <author><first>Laurent</first><last>Prévot</last></author>
      <author><first>Enrico</first><last>Santus</last></author>
      <pages>72–78</pages>
      <abstract>Eye-tracking data from reading represent an important resource for both linguistics and natural language processing. The ability to accurately model gaze features is crucial to advance our understanding of language processing. This paper describes the Shared Task on Eye-Tracking Data Prediction, jointly organized with the eleventh edition of the Work- shop on Cognitive Modeling and Computational Linguistics (CMCL 2021). The goal of the task is to predict 5 different token- level eye-tracking metrics of the Zurich Cognitive Language Processing Corpus (ZuCo). Eye-tracking data were recorded during natural reading of English sentences. In total, we received submissions from 13 registered teams, whose systems include boosting algorithms with handcrafted features, neural models leveraging transformer language models, or hybrid approaches. The winning system used a range of linguistic and psychometric features in a gradient boosting framework.</abstract>
      <url hash="c327c502">2021.cmcl-1.7</url>
      <doi>10.18653/v1/2021.cmcl-1.7</doi>
      <bibkey>hollenstein-etal-2021-cmcl</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>L</fixed-case>ang<fixed-case>R</fixed-case>esearch<fixed-case>L</fixed-case>ab_<fixed-case>NC</fixed-case> at <fixed-case>CMCL</fixed-case>2021 Shared Task: Predicting Gaze Behaviour Using Linguistic Features and Tree Regressors</title>
      <author><first>Raksha</first><last>Agarwal</last></author>
      <author><first>Niladri</first><last>Chatterjee</last></author>
      <pages>79–84</pages>
      <abstract>Analysis of gaze data behaviour has gained momentum in recent years for different NLP applications. The present paper aims at modelling gaze data behaviour of tokens in the context of a sentence. We have experimented with various Machine Learning Regression Algorithms on a feature space comprising the linguistic features of the target tokens for prediction of five Eye-Tracking features. CatBoost Regressor performed the best and achieved fourth position in terms of MAE based accuracy measurement for the ZuCo Dataset.</abstract>
      <url hash="5eb3e04f">2021.cmcl-1.8</url>
      <attachment type="OptionalSupplementaryData" hash="274b7c74">2021.cmcl-1.8.OptionalSupplementaryData.zip</attachment>
      <doi>10.18653/v1/2021.cmcl-1.8</doi>
      <bibkey>agarwal-chatterjee-2021-langresearchlab</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>T</fixed-case>oronto<fixed-case>CL</fixed-case> at <fixed-case>CMCL</fixed-case> 2021 Shared Task: <fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a with Multi-Stage Fine-Tuning for Eye-Tracking Prediction</title>
      <author><first>Bai</first><last>Li</last></author>
      <author><first>Frank</first><last>Rudzicz</last></author>
      <pages>85–89</pages>
      <abstract>Eye movement data during reading is a useful source of information for understanding language comprehension processes. In this paper, we describe our submission to the CMCL 2021 shared task on predicting human reading patterns. Our model uses RoBERTa with a regression layer to predict 5 eye-tracking features. We train the model in two stages: we first fine-tune on the Provo corpus (another eye-tracking dataset), then fine-tune on the task data. We compare different Transformer models and apply ensembling methods to improve the performance. Our final submission achieves a MAE score of 3.929, ranking 3rd place out of 13 teams that participated in this shared task.</abstract>
      <url hash="3ad3e8aa">2021.cmcl-1.9</url>
      <doi>10.18653/v1/2021.cmcl-1.9</doi>
      <bibkey>li-rudzicz-2021-torontocl</bibkey>
      <pwccode url="https://github.com/SPOClab-ca/cmcl-shared-task" additional="false">SPOClab-ca/cmcl-shared-task</pwccode>
    </paper>
    <paper id="10">
      <title><fixed-case>LAST</fixed-case> at <fixed-case>CMCL</fixed-case> 2021 Shared Task: Predicting Gaze Data During Reading with a Gradient Boosting Decision Tree Approach</title>
      <author><first>Yves</first><last>Bestgen</last></author>
      <pages>90–96</pages>
      <abstract>A LightGBM model fed with target word lexical characteristics and features obtained from word frequency lists, psychometric data and bigram association measures has been optimized for the 2021 CMCL Shared Task on Eye-Tracking Data Prediction. It obtained the best performance of all teams on two of the five eye-tracking measures to predict, allowing it to rank first on the official challenge criterion and to outperform all deep-learning based systems participating in the challenge.</abstract>
      <url hash="5d697c1e">2021.cmcl-1.10</url>
      <doi>10.18653/v1/2021.cmcl-1.10</doi>
      <bibkey>bestgen-2021-last</bibkey>
    </paper>
    <paper id="11">
      <title>Team <fixed-case>O</fixed-case>hio <fixed-case>S</fixed-case>tate at <fixed-case>CMCL</fixed-case> 2021 Shared Task: Fine-Tuned <fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a for Eye-Tracking Data Prediction</title>
      <author><first>Byung-Doh</first><last>Oh</last></author>
      <pages>97–101</pages>
      <abstract>This paper describes Team Ohio State’s approach to the CMCL 2021 Shared Task, the goal of which is to predict five eye-tracking features from naturalistic self-paced reading corpora. For this task, we fine-tune a pre-trained neural language model (RoBERTa; Liu et al., 2019) to predict each feature based on the contextualized representations. Moreover, motivated by previous eye-tracking studies, we include word length in characters and proportion of sentence processed as two additional input features. Our best model strongly outperforms the baseline and is also competitive with other systems submitted to the shared task. An ablation study shows that the word length feature contributes to making more accurate predictions, indicating the usefulness of features that are specific to the eye-tracking paradigm.</abstract>
      <url hash="3432ed72">2021.cmcl-1.11</url>
      <doi>10.18653/v1/2021.cmcl-1.11</doi>
      <bibkey>oh-2021-team</bibkey>
      <pwccode url="https://github.com/byungdoh/cmcl21_st" additional="false">byungdoh/cmcl21_st</pwccode>
    </paper>
    <paper id="12">
      <title><fixed-case>PIHK</fixed-case>ers at <fixed-case>CMCL</fixed-case> 2021 Shared Task: Cosine Similarity and Surprisal to Predict Human Reading Patterns.</title>
      <author><first>Lavinia</first><last>Salicchi</last></author>
      <author><first>Alessandro</first><last>Lenci</last></author>
      <pages>102–107</pages>
      <abstract>Eye-tracking psycholinguistic studies have revealed that context-word semantic coherence and predictability influence language processing. In this paper we show our approach to predict eye-tracking features from the ZuCo dataset for the shared task of the Cognitive Modeling and Computational Linguistics (CMCL2021) workshop. Using both cosine similarity and surprisal within a regression model, we significantly improved the baseline Mean Absolute Error computed among five eye-tracking features.</abstract>
      <url hash="f9ac134e">2021.cmcl-1.12</url>
      <doi>10.18653/v1/2021.cmcl-1.12</doi>
      <bibkey>salicchi-lenci-2021-pihkers</bibkey>
    </paper>
    <paper id="13">
      <title><fixed-case>TALEP</fixed-case> at <fixed-case>CMCL</fixed-case> 2021 Shared Task: Non Linear Combination of Low and High-Level Features for Predicting Eye-Tracking Data</title>
      <author><first>Franck</first><last>Dary</last></author>
      <author><first>Alexis</first><last>Nasr</last></author>
      <author><first>Abdellah</first><last>Fourtassi</last></author>
      <pages>108–113</pages>
      <abstract>In this paper we describe our contribution to the CMCL 2021 Shared Task, which consists in predicting 5 different eye tracking variables from English tokenized text. Our approach is based on a neural network that combines both raw textual features we extracted from the text and parser-based features that include linguistic predictions (e.g. part of speech) and complexity metrics (e.g., entropy of parsing). We found that both the features we considered as well as the architecture of the neural model that combined these features played a role in the overall performance. Our system achieved relatively high accuracy on the test data of the challenge and was ranked 2nd out of 13 competing teams and a total of 30 submissions.</abstract>
      <url hash="7f949156">2021.cmcl-1.13</url>
      <attachment type="OptionalSupplementaryMaterial" hash="4a0ab7ff">2021.cmcl-1.13.OptionalSupplementaryMaterial.zip</attachment>
      <doi>10.18653/v1/2021.cmcl-1.13</doi>
      <bibkey>dary-etal-2021-talep</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>MTL</fixed-case>782_<fixed-case>IITD</fixed-case> at <fixed-case>CMCL</fixed-case> 2021 Shared Task: Prediction of Eye-Tracking Features Using <fixed-case>BERT</fixed-case> Embeddings and Linguistic Features</title>
      <author><first>Shivani</first><last>Choudhary</last></author>
      <author><first>Kushagri</first><last>Tandon</last></author>
      <author><first>Raksha</first><last>Agarwal</last></author>
      <author><first>Niladri</first><last>Chatterjee</last></author>
      <pages>114–119</pages>
      <abstract>Reading and comprehension are quintessentially cognitive tasks. Eye movement acts as a surrogate to understand which part of a sentence is critical to the process of comprehension. The aim of the shared task is to predict five eye-tracking features for a given word of the input sentence. We experimented with several models based on LGBM (Light Gradient Boosting Machine) Regression, ANN (Artificial Neural Network), and CNN (Convolutional Neural Network), using BERT embeddings and some combination of linguistic features. Our submission using CNN achieved an average MAE of 4.0639 and ranked 7th in the shared task. The average MAE was further lowered to 3.994 in post-task evaluation.</abstract>
      <url hash="ab43c80f">2021.cmcl-1.14</url>
      <attachment type="OptionalSupplementaryData" hash="d6608c06">2021.cmcl-1.14.OptionalSupplementaryData.zip</attachment>
      <doi>10.18653/v1/2021.cmcl-1.14</doi>
      <bibkey>choudhary-etal-2021-mtl782</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>K</fixed-case>on<fixed-case>T</fixed-case>ra at <fixed-case>CMCL</fixed-case> 2021 Shared Task: Predicting Eye Movements by Combining <fixed-case>BERT</fixed-case> with Surface, Linguistic and Behavioral Information</title>
      <author><first>Qi</first><last>Yu</last></author>
      <author><first>Aikaterini-Lida</first><last>Kalouli</last></author>
      <author><first>Diego</first><last>Frassinelli</last></author>
      <pages>120–124</pages>
      <abstract>This paper describes the submission of the team KonTra to the CMCL 2021 Shared Task on eye-tracking prediction. Our system combines the embeddings extracted from a fine-tuned BERT model with surface, linguistic and behavioral features, resulting in an average mean absolute error of 4.22 across all 5 eye-tracking measures. We show that word length and features representing the expectedness of a word are consistently the strongest predictors across all 5 eye-tracking measures.</abstract>
      <url hash="9e51c491">2021.cmcl-1.15</url>
      <doi>10.18653/v1/2021.cmcl-1.15</doi>
      <bibkey>yu-etal-2021-kontra</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>C</fixed-case>og<fixed-case>NLP</fixed-case>-<fixed-case>S</fixed-case>heffield at <fixed-case>CMCL</fixed-case> 2021 Shared Task: Blending Cognitively Inspired Features with Transformer-based Language Models for Predicting Eye Tracking Patterns</title>
      <author><first>Peter</first><last>Vickers</last></author>
      <author><first>Rosa</first><last>Wainwright</last></author>
      <author><first>Harish</first><last>Tayyar Madabushi</last></author>
      <author><first>Aline</first><last>Villavicencio</last></author>
      <pages>125–133</pages>
      <abstract>The CogNLP-Sheffield submissions to the CMCL 2021 Shared Task examine the value of a variety of cognitively and linguistically inspired features for predicting eye tracking patterns, as both standalone model inputs and as supplements to contextual word embeddings (XLNet). Surprisingly, the smaller pre-trained model (XLNet-base) outperforms the larger (XLNet-large), and despite evidence that multi-word expressions (MWEs) provide cognitive processing advantages, MWE features provide little benefit to either model.</abstract>
      <url hash="862941e6">2021.cmcl-1.16</url>
      <doi>10.18653/v1/2021.cmcl-1.16</doi>
      <bibkey>vickers-etal-2021-cognlp</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wikitext-103">WikiText-103</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wikitext-2">WikiText-2</pwcdataset>
    </paper>
    <paper id="17">
      <title>Team <fixed-case>R</fixed-case>ead<fixed-case>M</fixed-case>e at <fixed-case>CMCL</fixed-case> 2021 Shared Task: Predicting Human Reading Patterns by Traditional Oculomotor Control Models and Machine Learning</title>
      <author><first>Alisan</first><last>Balkoca</last></author>
      <author><first>Abdullah</first><last>Algan</last></author>
      <author><first>Cengiz</first><last>Acarturk</last></author>
      <author><first>Çağrı</first><last>Çöltekin</last></author>
      <pages>134–140</pages>
      <abstract>This system description paper describes our participation in CMCL 2021 shared task on predicting human reading patterns. Our focus in this study is making use of well-known,traditional oculomotor control models and machine learning systems. We present experiments with a traditional oculomotor control model (the EZ Reader) and two machine learning models (a linear regression model and a re-current network model), as well as combining the two different models. In all experiments we test effects of features well-known in the literature for predicting reading patterns, such as frequency, word length and predictability.Our experiments support the earlier findings that such features are useful when combined.Furthermore, we show that although machine learning models perform better in comparison to traditional models, combination of both gives a consistent improvement for predicting multiple eye tracking variables during reading.</abstract>
      <url hash="8bd34cc8">2021.cmcl-1.17</url>
      <doi>10.18653/v1/2021.cmcl-1.17</doi>
      <bibkey>balkoca-etal-2021-team</bibkey>
    </paper>
    <paper id="18">
      <title>Enhancing Cognitive Models of Emotions with Representation Learning</title>
      <author><first>Yuting</first><last>Guo</last></author>
      <author><first>Jinho D.</first><last>Choi</last></author>
      <pages>141–148</pages>
      <abstract>We present a novel deep learning-based framework to generate embedding representations of fine-grained emotions that can be used to computationally describe psychological models of emotions. Our framework integrates a contextualized embedding encoder with a multi-head probing model that enables to interpret dynamically learned representations optimized for an emotion classification task. Our model is evaluated on the Empathetic Dialogue dataset and shows the state-of-the-art result for classifying 32 emotions. Our layer analysis can derive an emotion graph to depict hierarchical relations among the emotions. Our emotion representations can be used to generate an emotion wheel directly comparable to the one from Plutchik’s model, and also augment the values of missing emotions in the PAD emotional state model.</abstract>
      <url hash="388d240e">2021.cmcl-1.18</url>
      <doi>10.18653/v1/2021.cmcl-1.18</doi>
      <bibkey>guo-choi-2021-enhancing</bibkey>
      <pwccode url="https://github.com/emorynlp/CMCL-2021" additional="false">emorynlp/CMCL-2021</pwccode>
    </paper>
    <paper id="19">
      <title>Production vs Perception: The Role of Individuality in Usage-Based Grammar Induction</title>
      <author><first>Jonathan</first><last>Dunn</last></author>
      <author><first>Andrea</first><last>Nini</last></author>
      <pages>149–159</pages>
      <abstract>This paper asks whether a distinction between production-based and perception-based grammar induction influences either (i) the growth curve of grammars and lexicons or (ii) the similarity between representations learned from independent sub-sets of a corpus. A production-based model is trained on the usage of a single individual, thus simulating the grammatical knowledge of a single speaker. A perception-based model is trained on an aggregation of many individuals, thus simulating grammatical generalizations learned from exposure to many different speakers. To ensure robustness, the experiments are replicated across two registers of written English, with four additional registers reserved as a control. A set of three computational experiments shows that production-based grammars are significantly different from perception-based grammars across all conditions, with a steeper growth curve that can be explained by substantial inter-individual grammatical differences.</abstract>
      <url hash="ce663dd7">2021.cmcl-1.19</url>
      <doi>10.18653/v1/2021.cmcl-1.19</doi>
      <bibkey>dunn-nini-2021-production</bibkey>
    </paper>
    <paper id="20">
      <title>Clause Final Verb Prediction in <fixed-case>H</fixed-case>indi: Evidence for Noisy Channel Model of Communication</title>
      <author><first>Kartik</first><last>Sharma</last></author>
      <author><first>Niyati</first><last>Bafna</last></author>
      <author><first>Samar</first><last>Husain</last></author>
      <pages>160–170</pages>
      <abstract>Verbal prediction has been shown to be critical during online comprehension of Subject-Object-Verb (SOV) languages. In this work we present three computational models to predict clause final verbs in Hindi given its prior arguments. The models differ in their use of prior context during the prediction process – the context is either noisy or noise-free. Model predictions are compared with the sentence completion data obtained from Hindi native speakers. Results show that models that assume noisy context outperform the noise-free model. In particular, a lossy context model that assumes prior context to be affected by predictability and recency captures the distribution of the predicted verb class and error sources best. The success of the predictability-recency lossy context model is consistent with the noisy channel hypothesis for sentence comprehension and supports the idea that the reconstruction of the context during prediction is driven by prior linguistic exposure. These results also shed light on the nature of the noise that affects the reconstruction process. Overall the results pose a challenge to the adaptability hypothesis that assumes use of noise-free preverbal context for robust verbal prediction.</abstract>
      <url hash="c033e550">2021.cmcl-1.20</url>
      <attachment type="OptionalSupplementaryMaterial" hash="59a06c7b">2021.cmcl-1.20.OptionalSupplementaryMaterial.pdf</attachment>
      <attachment type="OptionalSupplementaryData" hash="59a06c7b">2021.cmcl-1.20.OptionalSupplementaryData.pdf</attachment>
      <doi>10.18653/v1/2021.cmcl-1.20</doi>
      <bibkey>sharma-etal-2021-clause</bibkey>
    </paper>
    <paper id="21">
      <title>Dependency Locality and Neural Surprisal as Predictors of Processing Difficulty: Evidence from Reading Times</title>
      <author><first>Neil</first><last>Rathi</last></author>
      <pages>171–176</pages>
      <abstract>This paper compares two influential theories of processing difficulty: Gibson (2000)’s Dependency Locality Theory (DLT) and Hale (2001)’s Surprisal Theory. While prior work has aimed to compare DLT and Surprisal Theory (see Demberg and Keller, 2008), they have not yet been compared using more modern and powerful methods for estimating surprisal and DLT integration cost. I compare estimated surprisal values from two models, an RNN and a Transformer neural network, as well as DLT integration cost from a hand-parsed treebank, to reading times from the Dundee Corpus. Our results for integration cost corroborate those of Demberg and Keller (2008), finding that it is a negative predictor of reading times overall and a strong positive predictor for nouns, but contrast with their observations for surprisal, finding strong evidence for lexicalized surprisal as a predictor of reading times. Ultimately, I conclude that a broad-coverage model must integrate both theories in order to most accurately predict processing difficulty.</abstract>
      <url hash="cbf821a4">2021.cmcl-1.21</url>
      <doi>10.18653/v1/2021.cmcl-1.21</doi>
      <bibkey>rathi-2021-dependency</bibkey>
    </paper>
    <paper id="22">
      <title>Modeling Sentence Comprehension Deficits in Aphasia: A Computational Evaluation of the Direct-access Model of Retrieval</title>
      <author><first>Paula</first><last>Lissón</last></author>
      <author><first>Dorothea</first><last>Pregla</last></author>
      <author><first>Dario</first><last>Paape</last></author>
      <author><first>Frank</first><last>Burchert</last></author>
      <author><first>Nicole</first><last>Stadie</last></author>
      <author><first>Shravan</first><last>Vasishth</last></author>
      <pages>177–185</pages>
      <abstract>Several researchers have argued that sentence comprehension is mediated via a content-addressable retrieval mechanism that allows fast and direct access to memory items. Initially failed retrievals can result in backtracking, which leads to correct retrieval. We present an augmented version of the direct-access model that allows backtracking to fail. Based on self-paced listening data from individuals with aphasia, we compare the augmented model to the base model without backtracking failures. The augmented model shows quantitatively similar performance to the base model, but only the augmented model can account for slow incorrect responses. We argue that the modified direct-access model is theoretically better suited to fit data from impaired populations.</abstract>
      <url hash="4ca69379">2021.cmcl-1.22</url>
      <attachment type="OptionalSupplementaryData" hash="ce454a9f">2021.cmcl-1.22.OptionalSupplementaryData.zip</attachment>
      <doi>10.18653/v1/2021.cmcl-1.22</doi>
      <bibkey>lisson-etal-2021-modeling</bibkey>
    </paper>
    <paper id="23">
      <title>Sentence Complexity in Context</title>
      <author><first>Benedetta</first><last>Iavarone</last></author>
      <author><first>Dominique</first><last>Brunato</last></author>
      <author><first>Felice</first><last>Dell’Orletta</last></author>
      <pages>186–199</pages>
      <abstract>We study the influence of context on how humans evaluate the complexity of a sentence in English. We collect a new dataset of sentences, where each sentence is rated for perceived complexity within different contextual windows. We carry out an in-depth analysis to detect which linguistic features correlate more with complexity judgments and with the degree of agreement among annotators. We train several regression models, using either explicit linguistic features or contextualized word embeddings, to predict the mean complexity values assigned to sentences in the different contextual windows, as well as their standard deviation. Results show that models leveraging explicit features capturing morphosyntactic and syntactic phenomena perform always better, especially when they have access to features extracted from all contextual sentences.</abstract>
      <url hash="f396e3b9">2021.cmcl-1.23</url>
      <attachment type="OptionalSupplementaryCode" hash="7d8ba351">2021.cmcl-1.23.OptionalSupplementaryCode.zip</attachment>
      <doi>10.18653/v1/2021.cmcl-1.23</doi>
      <bibkey>iavarone-etal-2021-sentence</bibkey>
    </paper>
    <paper id="24">
      <title>Evaluating the Acquisition of Semantic Knowledge from Cross-situational Learning in Artificial Neural Networks</title>
      <author><first>Mitja</first><last>Nikolaus</last></author>
      <author><first>Abdellah</first><last>Fourtassi</last></author>
      <pages>200–210</pages>
      <abstract>When learning their native language, children acquire the meanings of words and sentences from highly ambiguous input without much explicit supervision. One possible learning mechanism is cross-situational learning, which has been successfully tested in laboratory experiments with children. Here we use Artificial Neural Networks to test if this mechanism scales up to more natural language and visual scenes using a large dataset of crowd-sourced images with corresponding descriptions. We evaluate learning using a series of tasks inspired by methods commonly used in laboratory studies of language acquisition. We show that the model acquires rich semantic knowledge both at the word- and sentence-level, mirroring the patterns and trajectory of learning in early childhood. Our work highlights the usefulness of low-level co-occurrence statistics across modalities in facilitating the early acquisition of higher-level semantic knowledge.</abstract>
      <url hash="04190c1e">2021.cmcl-1.24</url>
      <doi>10.18653/v1/2021.cmcl-1.24</doi>
      <bibkey>nikolaus-fourtassi-2021-evaluating</bibkey>
      <pwccode url="https://github.com/mitjanikolaus/cross-situational-learning-abstract-scenes" additional="false">mitjanikolaus/cross-situational-learning-abstract-scenes</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">COCO</pwcdataset>
    </paper>
    <paper id="25">
      <title>Representation and Pre-Activation of Lexical-Semantic Knowledge in Neural Language Models</title>
      <author><first>Steven</first><last>Derby</last></author>
      <author><first>Paul</first><last>Miller</last></author>
      <author><first>Barry</first><last>Devereux</last></author>
      <pages>211–221</pages>
      <abstract>In this paper, we perform a systematic analysis of how closely the intermediate layers from LSTM and trans former language models correspond to human semantic knowledge. Furthermore, in order to make more meaningful comparisons with theories of human language comprehension in psycholinguistics, we focus on two key stages where the meaning of a particular target word may arise: immediately before the word’s presentation to the model (comparable to forward inferencing), and immediately after the word token has been input into the network. Our results indicate that the transformer models are better at capturing semantic knowledge relating to lexical concepts, both during word prediction and when retention is required.</abstract>
      <url hash="52821e1c">2021.cmcl-1.25</url>
      <doi>10.18653/v1/2021.cmcl-1.25</doi>
      <bibkey>derby-etal-2021-representation</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/billion-word-benchmark">Billion Word Benchmark</pwcdataset>
    </paper>
    <paper id="26">
      <title>Relation Classification with Cognitive Attention Supervision</title>
      <author><first>Erik</first><last>McGuire</last></author>
      <author><first>Noriko</first><last>Tomuro</last></author>
      <pages>222–232</pages>
      <abstract>Many current language models such as BERT utilize attention mechanisms to transform sequence representations. We ask whether we can influence BERT’s attention with human reading patterns by using eye-tracking and brain imaging data. We fine-tune BERT for relation extraction with auxiliary attention supervision in which BERT’s attention weights are supervised by cognitive data. Through a variety of metrics we find that this attention supervision can be used to increase similarity between model attention distributions over sequences and the cognitive data without significantly affecting classification performance while making unique errors from the baseline. In particular, models with cognitive attention supervision more often correctly classified samples misclassified by the baseline.</abstract>
      <url hash="9d8a84fe">2021.cmcl-1.26</url>
      <attachment type="OptionalSupplementaryMaterial" hash="8e5587ef">2021.cmcl-1.26.OptionalSupplementaryMaterial.zip</attachment>
      <doi>10.18653/v1/2021.cmcl-1.26</doi>
      <bibkey>mcguire-tomuro-2021-relation</bibkey>
    </paper>
    <paper id="27">
      <title>Graph-theoretic Properties of the Class of Phonological Neighbourhood Networks</title>
      <author><first>Rory</first><last>Turnbull</last></author>
      <pages>233–240</pages>
      <abstract>This paper concerns the structure of phonological neighbourhood networks, which are a graph-theoretic representation of the phonological lexicon. These networks represent each word as a node and links are placed between words which are phonological neighbours, usually defined as a string edit distance of one. Phonological neighbourhood networks have been used to study many aspects of the mental lexicon and psycholinguistic theories of speech production and perception. This paper offers preliminary graph-theoretic observations about phonological neighbourhood networks considered as a class. To aid this exploration, this paper introduces the concept of the hyperlexicon, the network consisting of all possible words for a given symbol set and their neighbourhood relations. The construction of the hyperlexicon is discussed, and basic properties are derived. This work is among the first to directly address the nature of phonological neighbourhood networks from an analytic perspective.</abstract>
      <url hash="2387f2ea">2021.cmcl-1.27</url>
      <doi>10.18653/v1/2021.cmcl-1.27</doi>
      <bibkey>turnbull-2021-graph</bibkey>
    </paper>
    <paper id="28">
      <title>Contributions of Propositional Content and Syntactic Category Information in Sentence Processing</title>
      <author><first>Byung-Doh</first><last>Oh</last></author>
      <author><first>William</first><last>Schuler</last></author>
      <pages>241–250</pages>
      <abstract>Expectation-based theories of sentence processing posit that processing difficulty is determined by predictability in context. While predictability quantified via surprisal has gained empirical support, this representation-agnostic measure leaves open the question of how to best approximate the human comprehender’s latent probability model. This work presents an incremental left-corner parser that incorporates information about both propositional content and syntactic categories into a single probability model. This parser can be trained to make parsing decisions conditioning on only one source of information, thus allowing a clean ablation of the relative contribution of propositional content and syntactic category information. Regression analyses show that surprisal estimates calculated from the full parser make a significant contribution to predicting self-paced reading times over those from the parser without syntactic category information, as well as a significant contribution to predicting eye-gaze durations over those from the parser without propositional content information. Taken together, these results suggest a role for propositional content and syntactic category information in incremental sentence processing.</abstract>
      <url hash="9166572b">2021.cmcl-1.28</url>
      <doi>10.18653/v1/2021.cmcl-1.28</doi>
      <bibkey>oh-schuler-2021-contributions</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/natural-stories">Natural Stories</pwcdataset>
    </paper>
  </volume>
</collection>
