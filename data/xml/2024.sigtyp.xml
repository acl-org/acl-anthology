<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.sigtyp">
  <volume id="1" ingest-date="2024-03-04" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 6th Workshop on Research in Computational Linguistic Typology and Multilingual NLP</booktitle>
      <editor><first>Michael</first><last>Hahn</last></editor>
      <editor><first>Alexey</first><last>Sorokin</last></editor>
      <editor><first>Ritesh</first><last>Kumar</last></editor>
      <editor><first>Andreas</first><last>Shcherbakov</last></editor>
      <editor><first>Yulia</first><last>Otmakhova</last></editor>
      <editor><first>Jinrui</first><last>Yang</last></editor>
      <editor><first>Oleg</first><last>Serikov</last></editor>
      <editor><first>Priya</first><last>Rani</last></editor>
      <editor><first>Edoardo M.</first><last>Ponti</last></editor>
      <editor><first>Saliha</first><last>Muradoğlu</last></editor>
      <editor><first>Rena</first><last>Gao</last></editor>
      <editor><first>Ryan</first><last>Cotterell</last></editor>
      <editor><first>Ekaterina</first><last>Vylomova</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>St. Julian's, Malta</address>
      <month>March</month>
      <year>2024</year>
      <url hash="39c34223">2024.sigtyp-1</url>
      <venue>sigtyp</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="c78e6cdf">2024.sigtyp-1.0</url>
      <bibkey>sigtyp-2024-research</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Syntactic dependency length shaped by strategic memory allocation</title>
      <author><first>Weijie</first><last>Xu</last></author>
      <author><first>Richard</first><last>Futrell</last><affiliation>University of California, Irvine</affiliation></author>
      <pages>1-9</pages>
      <abstract>Human processing of nonlocal syntactic dependencies requires engagement of limited working memory for encoding, maintenance, and retrieval. This process creates an evolutionary pressure for language to be structured in a way that keeps the subparts of a dependency closer to each other, an efficiency principle termed dependency locality. The current study proposes that such a dependency locality pressure can be modulated by the surprisal of the antecedent, defined as the first part of a dependency, due to strategic allocation of working memory. In particular, antecedents with novel and unpredictable information are prioritized for memory encoding, receiving more robust representation against memory interference and decay, and thus are more capable of handling longer dependency length. We examine this claim by examining dependency corpora of six languages (Danish, English, Italian, Mandarin, Russian, and Spanish), with word surprisal generated from GPT-3 language model. In support of our hypothesis, we find evidence for a positive correlation between dependency length and the antecedent surprisal in most of the languages in our analyses.</abstract>
      <url hash="74e339b6">2024.sigtyp-1.1</url>
      <bibkey>xu-futrell-2024-syntactic</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>GUIDE</fixed-case>: Creating Semantic Domain Dictionaries for Low-Resource Languages</title>
      <author><first>Jonathan</first><last>Janetzki</last></author>
      <author><first>Gerard</first><last>De Melo</last><affiliation>Hasso Plattner Institute and University of Potsdam</affiliation></author>
      <author><first>Joshua</first><last>Nemecek</last></author>
      <author><first>Daniel</first><last>Whitenack</last><affiliation>SIL International</affiliation></author>
      <pages>10-24</pages>
      <abstract>Over 7,000 of the world’s 7,168 living languages are still low-resourced. This paper aims to narrow the language documentation gap by creating multiparallel dictionaries, clustered by SIL’s semantic domains. This task is new for machine learning and has previously been done manually by native speakers. We propose GUIDE, a language-agnostic tool that uses a GNN to create and populate semantic domain dictionaries, using seed dictionaries and Bible translations as a parallel text corpus. Our work sets a new benchmark, achieving an exemplary average precision of 60% in eight zero-shot evaluation languages and predicting an average of 2,400 dictionary entries. We share the code, model, multilingual evaluation data, and new dictionaries with the research community: https://github.com/janetzki/GUIDE</abstract>
      <url hash="2efc4e41">2024.sigtyp-1.2</url>
      <bibkey>janetzki-etal-2024-guide</bibkey>
    </paper>
    <paper id="3">
      <title>A New Dataset for Tonal and Segmental Dialectometry from the <fixed-case>Y</fixed-case>ue- and Pinghua-Speaking Area</title>
      <author><first>Ho</first><last>Sung</last><affiliation>Leiden University</affiliation></author>
      <author><first>Jelena</first><last>Prokic</last><affiliation>Universiteit Leiden</affiliation></author>
      <author><first>Yiya</first><last>Chen</last><affiliation>Leiden University</affiliation></author>
      <pages>25-36</pages>
      <abstract>Traditional dialectology or dialect geography is the study of geographical variation of language. Originated in Europe and pioneered in Germany and France, this field has predominantly been focusing on sounds, more specifically, on segments. Similarly, quantitative approaches to language variation concerned with the phonetic level are in most cases focusing on segments as well. However, more than half of the world’s languages include lexical tones (Yip, 2002). Despite this, tones are still underexplored in quantitative language comparison, partly due to the low accessibility of the suitable data. This paper aims to introduce a newly digitised dataset which comes from the Yue- and Pinghua-speaking areas in Southern China, with over 100 dialects. This dataset consists of two parts: tones and segments. In this paper, we illustrate how we can computationaly model tones in order to explore linguistic variation. We have applied a tone distance metric on our data, and we have found that 1) dialects also form a continuum on the tonal level and 2) other than tonemic (inventory) and tonetic differences, dialects can also differ in the lexical distribution of tones. The availability of this dataset will hopefully enable further exploration of the role of tones in quantitative typology and NLP research.</abstract>
      <url hash="529d3082">2024.sigtyp-1.3</url>
      <bibkey>sung-etal-2024-new</bibkey>
    </paper>
    <paper id="4">
      <title>A Computational Model for the Assessment of Mutual Intelligibility Among Closely Related Languages</title>
      <author><first>Jessica</first><last>Nieder</last><affiliation>Universität Passau</affiliation></author>
      <author><first>Johann-Mattis</first><last>List</last><affiliation>Universität Passau and Max-Planck Institute</affiliation></author>
      <pages>37-43</pages>
      <abstract>Closely related languages show linguistic similarities that allow speakers of one language to understand speakers of another language without having actively learned it. Mutual intelligibility varies in degree and is typically tested in psycholinguistic experiments. To study mutual intelligibility computationally, we propose a computer-assisted method using the Linear Discriminative Learner, a computational model developed to approximate the cognitive processes by which humans learn languages, which we expand with multilingual semantic vectors and multilingual sound classes. We test the model on cognate data from German, Dutch, and English, three closely related Germanic languages. We find that our model’s comprehension accuracy depends on 1) the automatic trimming of inflections and 2) the language pair for which comprehension is tested. Our multilingual modelling approach does not only offer new methodological findings for automatic testing of mutual intelligibility across languages but also extends the use of Linear Discriminative Learning to multilingual settings.</abstract>
      <url hash="7f625753">2024.sigtyp-1.4</url>
      <bibkey>nieder-list-2024-computational</bibkey>
    </paper>
    <paper id="5">
      <title>Predicting <fixed-case>M</fixed-case>andarin and <fixed-case>C</fixed-case>antonese Adult Speakers’ Eye-Movement Patterns in Natural Reading</title>
      <author><first>Li</first><last>Junlin</last></author>
      <author><first>Yu-Yin</first><last>Hsu</last><affiliation>Hong Kong Polytechnic University</affiliation></author>
      <author><first>Emmanuele</first><last>Chersoni</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Bo</first><last>Peng</last></author>
      <pages>44-45</pages>
      <abstract>Please find the attached PDF file for the extended abstract of our study.</abstract>
      <url hash="3d11da57">2024.sigtyp-1.5</url>
      <bibkey>junlin-etal-2024-predicting</bibkey>
    </paper>
    <paper id="6">
      <title>The Typology of Ellipsis: A Corpus for Linguistic Analysis and Machine Learning Applications</title>
      <author><first>Damir</first><last>Cavar</last><affiliation>Indiana University</affiliation></author>
      <author><first>Ludovic</first><last>Mompelat</last></author>
      <author><first>Muhammad</first><last>Abdo</last></author>
      <pages>46-54</pages>
      <abstract>State-of-the-art (SotA) Natural Language Processing (NLP) technology faces significant challenges with constructions that contain ellipses. Although theoretically well-documented and understood, there needs to be more sufficient cross-linguistic language resources to document, study, and ultimately engineer NLP solutions that can adequately provide analyses for ellipsis constructions. This article describes the typological data set on ellipsis that we created for currently seventeen languages. We demonstrate how SotA parsers based on a variety of syntactic frameworks fail to parse sentences with ellipsis, and in fact, probabilistic, neural, and Large Language Models (LLM) do so, too. We demonstrate experiments that focus on detecting sentences with ellipsis, predicting the position of elided elements, and predicting elided surface forms in the appropriate positions. We show that cross-linguistic variation of ellipsis-related phenomena has different consequences for the architecture of NLP systems.</abstract>
      <url hash="7d7acbe8">2024.sigtyp-1.6</url>
      <bibkey>cavar-etal-2024-typology</bibkey>
    </paper>
    <paper id="7">
      <title>Language Atlas of <fixed-case>J</fixed-case>apanese and Ryukyuan (<fixed-case>LAJ</fixed-case>a<fixed-case>R</fixed-case>): A Linguistic Typology Database for Endangered <fixed-case>J</fixed-case>aponic Languages</title>
      <author><first>Kanji</first><last>Kato</last></author>
      <author><first>So</first><last>Miyagawa</last></author>
      <author><first>Natsuko</first><last>Nakagawa</last></author>
      <pages>55-57</pages>
      <abstract>LAJaR (Language Atlas of Japanese and Ryukyuan) is a linguistic typology database focusing on micro-variation of the Japonic (Japanese and Ryukyuan) languages. This paper aims to report the design and progress of this ongoing database project. Finally, we also show a case study utilizing its database on zero copulas among the Japonic languages.</abstract>
      <url hash="ab639a05">2024.sigtyp-1.7</url>
      <bibkey>kato-etal-2024-language</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>GTNC</fixed-case>: A Many-To-One Dataset of <fixed-case>G</fixed-case>oogle Translations from <fixed-case>N</fixed-case>ews<fixed-case>C</fixed-case>rawl</title>
      <author><first>Damiaan</first><last>Reijnaers</last><affiliation>University of Amsterdam and University of Amsterdam</affiliation></author>
      <author><first>Charlotte</first><last>Pouw</last></author>
      <pages>58-65</pages>
      <abstract>This paper lays the groundwork for initiating research into Source Language Identification; the task of identifying the original language of a machine-translated text. We contribute a dataset of translations from a typologically diverse spectrum of languages into English and use it to set initial baselines for this novel task.</abstract>
      <url hash="5ad46947">2024.sigtyp-1.8</url>
      <bibkey>reijnaers-pouw-2024-gtnc</bibkey>
    </paper>
    <paper id="9">
      <title>Sociolinguistically Informed Interpretability: A Case Study on <fixed-case>H</fixed-case>inglish Emotion Classification</title>
      <author><first>Kushal</first><last>Tatariya</last><affiliation>KU Leuven</affiliation></author>
      <author><first>Heather</first><last>Lent</last><affiliation>Aalborg University</affiliation></author>
      <author><first>Johannes</first><last>Bjerva</last><affiliation>Aalborg University</affiliation></author>
      <author><first>Miryam</first><last>De Lhoneux</last><affiliation>KU Leuven</affiliation></author>
      <pages>66-74</pages>
      <abstract>Emotion classification is a challenging task in NLP due to the inherent idiosyncratic and subjective nature of linguistic expression,especially with code-mixed data. Pre-trained language models (PLMs) have achieved high performance for many tasks and languages, but it remains to be seen whether these models learn and are robust to the differences in emotional expression across languages. Sociolinguistic studies have shown that Hinglish speakers switch to Hindi when expressing negative emotions and to English when expressing positive emotions. To understand if language models can learn these associations, we study the effect of language on emotion prediction across 3 PLMs on a Hinglish emotion classification dataset. Using LIME and token level language ID, we find that models do learn these associations between language choice and emotional expression. Moreover, having code-mixed data present in the pre-training can augment that learning when task-specific data is scarce. We also conclude from the misclassifications that the models may overgeneralise this heuristic to other infrequent examples where this sociolinguistic phenomenon does not apply.</abstract>
      <url hash="1d79f49f">2024.sigtyp-1.9</url>
      <bibkey>tatariya-etal-2024-sociolinguistically</bibkey>
    </paper>
    <paper id="10">
      <title>A Call for Consistency in Reporting Typological Diversity</title>
      <author><first>Wessel</first><last>Poelman</last><affiliation>KU Leuven</affiliation></author>
      <author><first>Esther</first><last>Ploeger</last></author>
      <author><first>Miryam</first><last>De Lhoneux</last><affiliation>KU Leuven</affiliation></author>
      <author><first>Johannes</first><last>Bjerva</last><affiliation>Aalborg University</affiliation></author>
      <pages>75-77</pages>
      <abstract>In order to draw generalizable conclusions about the performance of multilingual models across languages, it is important to evaluate on a set of languages that captures linguistic diversity.Linguistic typology is increasingly used to justify language selection, inspired by language sampling in linguistics.However, justifications for ‘typological diversity’ exhibit great variation, as there seems to be no set definition, methodology or consistent link to linguistic typology.In this work, we provide a systematic insight into how previous work in the ACL Anthology uses the term ‘typological diversity’.Our two main findings are: 1) what is meant by typologically diverse language selection is not consistent and 2) the actual typological diversity of the language sets in these papers varies greatly.We argue that, when making claims about ‘typological diversity’, an operationalization of this should be included.A systematic approach that quantifies this claim, also with respect to the number of languages used, would be even better.</abstract>
      <url hash="4ae14aa8">2024.sigtyp-1.10</url>
      <bibkey>poelman-etal-2024-call</bibkey>
    </paper>
    <paper id="11">
      <title>Are Sounds Sound for Phylogenetic Reconstruction?</title>
      <author><first>Luise</first><last>Häuser</last><affiliation>Heidelberg Institute for Theoretical Studies</affiliation></author>
      <author><first>Gerhard</first><last>Jäger</last><affiliation>Eberhard-Karls-Universität Tübingen</affiliation></author>
      <author><first>Johann-Mattis</first><last>List</last><affiliation>Universität Passau and Max-Planck Institute</affiliation></author>
      <author><first>Taraka</first><last>Rama</last></author>
      <author><first>Alexandros</first><last>Stamatakis</last></author>
      <pages>78-87</pages>
      <abstract>In traditional studies on language evolution, scholars often emphasize the importance of sound laws and sound correspondences for phylogenetic inference of language family trees. However, to date, computational approaches have typically not taken this potential into account. Most computational studies still rely on lexical cognates as major data source for phylogenetic reconstruction in linguistics, although there do exist a few studies in which authors praise the benefits of comparing words at the level of sound sequences. Building on (a) ten diverse datasets from different language families, and (b) state-of-the-art methods for automated cognate and sound correspondence detection, we test, for the first time, the performance of sound-based versus cognate-based approaches to phylogenetic reconstruction. Our results show that phylogenies reconstructed from lexical cognates are topologically closer, by approximately one third with respect to the generalized quartet distance on average, to the gold standard phylogenies than phylogenies reconstructed from sound correspondences.</abstract>
      <url hash="014d3a3f">2024.sigtyp-1.11</url>
      <bibkey>hauser-etal-2024-sounds</bibkey>
    </paper>
    <paper id="12">
      <title>Compounds in <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies: A Survey in Five <fixed-case>E</fixed-case>uropean Languages</title>
      <author><first>Emil</first><last>Svoboda</last></author>
      <author><first>Magda</first><last>Ševčíková</last><affiliation>Charles University</affiliation></author>
      <pages>88-99</pages>
      <abstract>In Universal Dependencies, compounds, which we understand as words containing two or more roots, are represented according to tokenization, which reflects the orthographic conventions of the language. A closed compound (e.g. <tex-math>\textit{waterfall}</tex-math>) corresponds to a single word in Universal Dependencies while a hyphenated compound (<tex-math>\textit{father-in-law}</tex-math>) and an open compound (<tex-math>\textit{apple pie}</tex-math>) to multiple words. The aim of this paper is to open a discussion on how to move towards a more consistent annotation of compounds.The solution we argue for is to represent the internal structure of all compound types analogously to syntactic phrases, which would not only increase the comparability of compounding within and across languages, but also allow comparisons of compounds and syntactic phrases.</abstract>
      <url hash="cdd2cea9">2024.sigtyp-1.12</url>
      <bibkey>svoboda-sevcikova-2024-compounds</bibkey>
    </paper>
    <paper id="13">
      <title>Predicting positive transfer for improved low-resource speech recognition using acoustic pseudo-tokens</title>
      <author><first>Nay</first><last>San</last></author>
      <author><first>Georgios</first><last>Paraskevopoulos</last><affiliation>Athena Research and Innovation Center</affiliation></author>
      <author><first>Aryaman</first><last>Arora</last></author>
      <author><first>Xiluo</first><last>He</last></author>
      <author><first>Prabhjot</first><last>Kaur</last></author>
      <author><first>Oliver</first><last>Adams</last></author>
      <author><first>Dan</first><last>Jurafsky</last><affiliation>Stanford University</affiliation></author>
      <pages>100-112</pages>
      <abstract>While massively multilingual speech models like wav2vec 2.0 XLSR-128 can be directly fine-tuned for automatic speech recognition (ASR), downstream performance can still be relatively poor on languages that are under-represented in the pre-training data. Continued pre-training on 70–200 hours of untranscribed speech in these languages can help — but what about languages without that much recorded data? For such cases, we show that supplementing the target language with data from a similar, higher-resource ‘donor’ language can help. For example, continued pretraining on only 10 hours of low-resource Punjabi supplemented with 60 hours of donor Hindi is almost as good as continued pretraining on 70 hours of Punjabi. By contrast, sourcing supplemental data from less similar donors like Bengali does not improve ASR performance. To inform donor language selection, we propose a novel similarity metric based on the sequence distribution of induced acoustic units: the Acoustic Token Distribution Similarity (ATDS). Across a set of typologically different target languages (Punjabi, Galician, Iban, Setswana), we show that the ATDS between the target language and its candidate donors precisely predicts target language ASR performance.</abstract>
      <url hash="fda5588c">2024.sigtyp-1.13</url>
      <bibkey>san-etal-2024-predicting</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>M</fixed-case>ode<fixed-case>L</fixed-case>ing: A Novel Dataset for Testing Linguistic Reasoning in Language Models</title>
      <author><first>Nathan</first><last>Chi</last><affiliation>Stanford University</affiliation></author>
      <author><first>Teodor</first><last>Malchev</last></author>
      <author><first>Riley</first><last>Kong</last></author>
      <author><first>Ryan</first><last>Chi</last></author>
      <author><first>Lucas</first><last>Huang</last></author>
      <author><first>Ethan</first><last>Chi</last></author>
      <author><first>R.</first><last>McCoy</last><affiliation>Yale University</affiliation></author>
      <author><first>Dragomir</first><last>Radev</last><affiliation>Yale University</affiliation></author>
      <pages>113-119</pages>
      <abstract>Large language models (LLMs) perform well on (at least) some evaluations of both few-shot multilingual adaptation and reasoning. However, evaluating the intersection of these two skills—multilingual few-shot reasoning—is difficult: even relatively low-resource languages can be found in large training corpora, raising the concern that when we intend to evaluate a model’s ability to generalize to a new language, that language may have in fact been present during the model’s training. If such language contamination has occurred, apparent cases of few-shot reasoning could actually be due to memorization. Towards understanding the capability of models to perform multilingual few-shot reasoning, we propose modeLing, a benchmark of Rosetta stone puzzles. This type of puzzle, originating from competitions called Linguistics Olympiads, contain a small number of sentences in a target language not previously known to the solver. Each sentence is translated to the solver’s language such that the provided sentence pairs uniquely specify a single most reasonable underlying set of rules; solving requires applying these rules to translate new expressions (Figure 1). modeLing languages are chosen to be extremely low-resource such that the risk of training data contamination is low, and unlike prior datasets, it consists entirely of problems written specifically for this work, as a further measure against data leakage. Empirically, we find evidence that popular LLMs do not have data leakage on our benchmark.</abstract>
      <url hash="08504410">2024.sigtyp-1.14</url>
      <bibkey>chi-etal-2024-modeling</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>T</fixed-case>artu<fixed-case>NLP</fixed-case> @ <fixed-case>SIGTYP</fixed-case> 2024 Shared Task: Adapting <fixed-case>XLM</fixed-case>-<fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a for Ancient and Historical Languages</title>
      <author><first>Aleksei</first><last>Dorkin</last><affiliation>University of Tartu</affiliation></author>
      <author><first>Kairit</first><last>Sirts</last><affiliation>University of Tartu</affiliation></author>
      <pages>120-130</pages>
      <abstract>We present our submission to the unconstrained subtask of the SIGTYP 2024 Shared Task on Word Embedding Evaluation for Ancient and Historical Languages for morphological annotation, POS-tagging, lemmatization, characterand word-level gap-filling. We developed a simple, uniform, and computationally lightweight approach based on the adapters framework using parameter-efficient fine-tuning. We applied the same adapter-based approach uniformly to all tasks and 16 languages by fine-tuning stacked language- and task-specific adapters. Our submission obtained an overall second place out of three submissions, with the first place in word-level gap-filling. Our results show the feasibility of adapting language models pre-trained on modern languages to historical and ancient languages via adapter training.</abstract>
      <url hash="24674b78">2024.sigtyp-1.15</url>
      <bibkey>dorkin-sirts-2024-tartunlp</bibkey>
    </paper>
    <paper id="16">
      <title>Heidelberg-Boston @ <fixed-case>SIGTYP</fixed-case> 2024 Shared Task: Enhancing Low-Resource Language Analysis With Character-Aware Hierarchical Transformers</title>
      <author><first>Frederick</first><last>Riemenschneider</last><affiliation>Heidelberg University, Germany</affiliation></author>
      <author><first>Kevin</first><last>Krahn</last><affiliation>Sattler College, USA</affiliation></author>
      <pages>131-141</pages>
      <abstract>Historical languages present unique challenges to the NLP community, with one prominent hurdle being the limited resources available in their closed corpora. This work describes our submission to the constrained subtask of the SIGTYP 2024 shared task, focusing on PoS tagging, morphological tagging, and lemmatization for 13 historical languages. For PoS and morphological tagging we adapt a hierarchical tokenization method from Sun et al. (2023) and combine it with the advantages of the DeBERTa-V3 architecture, enabling our models to efficiently learn from every character in the training data. We also demonstrate the effectiveness of characterlevel T5 models on the lemmatization task. Pre-trained from scratch with limited data, our models achieved first place in the constrained subtask, nearly reaching the performance levels of the unconstrained task’s winner. Our code is available at https://github.com/bowphs/ SIGTYP-2024-hierarchical-transformers</abstract>
      <url hash="30d2fdd3">2024.sigtyp-1.16</url>
      <bibkey>riemenschneider-krahn-2024-heidelberg</bibkey>
    </paper>
    <paper id="17">
      <title><fixed-case>UDP</fixed-case>arse @ <fixed-case>SIGTYP</fixed-case> 2024 Shared Task : Modern Language Models for Historical Languages</title>
      <author><first>Johannes</first><last>Heinecke</last><affiliation>Orange Innovation, France</affiliation></author>
      <pages>142-150</pages>
      <abstract>SIGTYP’s Shared Task on Word Embedding Evaluation for Ancient and Historical Languages was proposed in two variants, constrained or unconstrained. Whereas the constrained variant disallowed any other data to train embeddings or models than the data provided, the unconstrained variant did not have these limits. We participated in the five tasks of the unconstrained variant and came out first. The tasks were the prediction of part-of-speech, lemmas and morphological features and filling masked words and masked characters on 16 historical languages. We decided to use a dependency parser and train the data using an underlying pretrained transformer model to predict part-of-speech tags, lemmas, and morphological features. For predicting masked words, we used multilingual distilBERT (with rather bad results). In order to predict masked characters, our language model is extremely small: it is a model of 5-gram frequencies, obtained by reading the available training data.</abstract>
      <url hash="128752d0">2024.sigtyp-1.17</url>
      <bibkey>heinecke-2024-udparse</bibkey>
    </paper>
    <paper id="18">
      <title><fixed-case>A</fixed-case>llen Institute for <fixed-case>AI</fixed-case> @ <fixed-case>SIGTYP</fixed-case> 2024 Shared Task on Word Embedding Evaluation for Ancient and Historical Languages</title>
      <author><first>Lester James</first><last>Miranda</last><affiliation>Allen Institute for Artificial Intelligence</affiliation></author>
      <pages>151-159</pages>
      <abstract>In this paper, we describe Allen AI’s submission to the constrained track of the SIGTYP 2024 Shared Task. Using only the data provided by the organizers, we pretrained a transformer-based multilingual model, then finetuned it on the Universal Dependencies (UD) annotations of a given language for a downstream task. Our systems achieved decent performance on the test set, beating the baseline in most language-task pairs, yet struggles with subtoken tags in multiword expressions as seen in Coptic and Ancient Hebrew. On the validation set, we obtained ≥70% F1- score on most language-task pairs. In addition, we also explored the cross-lingual capability of our trained models. This paper highlights our pretraining and finetuning process, and our findings from our internal evaluations.</abstract>
      <url hash="bfbced08">2024.sigtyp-1.18</url>
      <bibkey>miranda-2024-allen</bibkey>
    </paper>
    <paper id="19">
      <title>Findings of the <fixed-case>SIGTYP</fixed-case> 2024 Shared Task on Word Embedding Evaluation for Ancient and Historical Languages</title>
      <author><first>Oksana</first><last>Dereza</last><affiliation>University of Galway</affiliation></author>
      <author><first>Adrian</first><last>Doyle</last><affiliation>University of Galway</affiliation></author>
      <author><first>Priya</first><last>Rani</last><affiliation>University of Galway</affiliation></author>
      <author><first>Atul Kr.</first><last>Ojha</last><affiliation>University of Galway</affiliation></author>
      <author><first>Pádraic</first><last>Moran</last><affiliation>University of Galway</affiliation></author>
      <author><first>John</first><last>McCrae</last><affiliation>University of Galway</affiliation></author>
      <pages>160-172</pages>
      <abstract>This paper discusses the organisation and findings of the SIGTYP 2024 Shared Task on Word Embedding Evaluation for Ancient and Historical Languages. The shared task was split into the constrained and unconstrained tracks and involved solving either 3 or 5 problems for either 13 or 16 ancient and historical languages belonging to 4 language families, and making use of 6 different scripts. There were 14 registrations in total, of which 3 teams submitted to each track. Out of these 6 submissions, 2 systems were successful in the constrained setting and another 2 in the uncon- strained setting, and 4 system description papers were submitted by different teams. The best average result for morphological feature prediction was about 96%, while the best average results for POS-tagging and lemmatisation were 96% and 94% respectively. At the word level, the winning team could not achieve a higher average accuracy across all 16 languages than 5.95%, which demonstrates the difficulty of this problem. At the character level, the best average result over 16 languages 55.62%</abstract>
      <url hash="c66b4f4d">2024.sigtyp-1.19</url>
      <bibkey>dereza-etal-2024-findings</bibkey>
    </paper>
  </volume>
</collection>
