<?xml version='1.0' encoding='UTF-8'?>
<collection id="2023.lchange">
  <volume id="1" ingest-date="2023-11-30" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 4th Workshop on Computational Approaches to Historical Language Change</booktitle>
      <editor><first>Nina</first><last>Tahmasebi</last></editor>
      <editor><first>Syrielle</first><last>Montariol</last></editor>
      <editor><first>Haim</first><last>Dubossarsky</last></editor>
      <editor><first>Andrey</first><last>Kutuzov</last></editor>
      <editor><first>Simon</first><last>Hengchen</last></editor>
      <editor><first>David</first><last>Alfter</last></editor>
      <editor><first>Francesco</first><last>Periti</last></editor>
      <editor><first>Pierluigi</first><last>Cassotti</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Singapore</address>
      <month>December</month>
      <year>2023</year>
      <url hash="6890f89e">2023.lchange-1</url>
      <venue>lchange</venue>
    </meta>
    <frontmatter>
      <url hash="69c977b5">2023.lchange-1.0</url>
      <bibkey>lchange-2023</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Literary Intertextual Semantic Change Detection: Application and Motivation for Evaluating Models on Small Corpora</title>
      <author><first>Jackson</first><last>Ehrenworth</last><affiliation>Williams College</affiliation></author>
      <author><first>Katherine</first><last>Keith</last><affiliation>Williams College</affiliation></author>
      <pages>1-14</pages>
      <abstract>Lexical semantic change detection is the study of how words change meaning between corpora. While Schlechtweg et al. (2020) standardized both datasets and evaluation metrics for this shared task, for those interested in applying semantic change detection models to small corpora—e.g., in the digital humanities—there is a need for evaluation involving much smaller datasets. We present a method and open-source code pipeline for downsampling the SemEval-2020 Task 1 corpora while preserving gold standard measures of semantic change. We then evaluate several state-of-the-art models trained on these downsampled corpora and find both dramatically decreased performance (average 67% decrease) and high variance. We also propose a novel application to the digital humanities and provide a case study demonstrating that semantic change detection can be used in an exploratory manner to produce insightful avenues of investigation for literary scholars.</abstract>
      <url hash="b076942b">2023.lchange-1.1</url>
      <bibkey>ehrenworth-keith-2023-literary-intertextual</bibkey>
      <doi>10.18653/v1/2023.lchange-1.1</doi>
    </paper>
    <paper id="2">
      <title>Domain-Adapting <fixed-case>BERT</fixed-case> for Attributing Manuscript, Century and Region in Pre-<fixed-case>M</fixed-case>odern <fixed-case>S</fixed-case>lavic Texts</title>
      <author><first>Piroska</first><last>Lendvai</last><affiliation>Bavarian Academy of Sciences and Humanities</affiliation></author>
      <author><first>Uwe</first><last>Reichel</last><affiliation>Hungarian Research Centre for Linguistics</affiliation></author>
      <author><first>Anna</first><last>Jouravel</last></author>
      <author><first>Achim</first><last>Rabus</last><affiliation>University of Freiburg</affiliation></author>
      <author><first>Elena</first><last>Renje</last><affiliation>University of Freiburg</affiliation></author>
      <pages>15-21</pages>
      <abstract>Our study presents a stratified dataset compiled from six different Slavic bodies of text, for cross-linguistic and diachronic analyses of Slavic Pre-Modern language variants. We demonstrate unsupervised domain adaptation and supervised finetuning of BERT on these low-resource, historical Slavic variants, for the purposes of provenance attribution in terms of three downstream tasks: manuscript, century and copying region classification.The data compilation aims to capture diachronic as well as regional language variation and change: the texts were written in the course of roughly a millennium, incorporating language variants from the High Middle Ages to the Early Modern Period, and originate from a variety of geographic regions. Mechanisms of language change in relatively small portions of such data have been inspected, analyzed and typologized by Slavists manually; our contribution aims to investigate the extent to which the BERT transformer architecture and pretrained models can benefit this process. Using these datasets for domain adaptation, we could attribute temporal, geographical and manuscript origin on the level of text snippets with high F-scores. We also conducted a qualitative analysis of the models’ misclassifications.</abstract>
      <url hash="0160e68d">2023.lchange-1.2</url>
      <bibkey>lendvai-etal-2023-domain-adapting</bibkey>
      <doi>10.18653/v1/2023.lchange-1.2</doi>
    </paper>
    <paper id="3">
      <title>Representing and Computing Uncertainty in Phonological Reconstruction</title>
      <author><first>Johann-Mattis</first><last>List</last><affiliation>Universität Passau and Max-Planck Institute</affiliation></author>
      <author><first>Nathan</first><last>Hill</last><affiliation>University of Dublin, Trinity College</affiliation></author>
      <author><first>Robert</first><last>Forkel</last><affiliation>Max-Planck Institute for Evolutionary Anthropology</affiliation></author>
      <author><first>Frederic</first><last>Blum</last><affiliation>Max-Planck Institute for Evolutionary Anthropology</affiliation></author>
      <pages>22-32</pages>
      <abstract>Despite the inherently fuzzy nature of reconstructions in historical linguistics, most scholars do not represent their uncertainty when proposing proto-forms. With the increasing success of recently proposed approaches to automating certain aspects of the traditional comparative method, the formal representation of proto-forms has also improved. This formalization makes it possible to address both the representation and the computation of uncertainty. Building on recent advances in supervised phonological reconstruction, during which an algorithm learns how to reconstruct words in a given proto-language relying on previously annotated data, and inspired by improved methods for automated word prediction from cognate sets, we present a new framework that allows for the representation of uncertainty in linguistic reconstruction and also includes a workflow for the computation of fuzzy reconstructions from linguistic data.</abstract>
      <url hash="6df67e3a">2023.lchange-1.3</url>
      <bibkey>list-etal-2023-representing-computing</bibkey>
      <doi>10.18653/v1/2023.lchange-1.3</doi>
    </paper>
    <paper id="4">
      <title><fixed-case>GH</fixed-case>is<fixed-case>BERT</fixed-case> – Training <fixed-case>BERT</fixed-case> from scratch for lexical semantic investigations across historical <fixed-case>G</fixed-case>erman language stages</title>
      <author><first>Christin</first><last>Beck</last><affiliation>Universität Konstanz</affiliation></author>
      <author><first>Marisa</first><last>Köllner</last><affiliation>University of Tübingen</affiliation></author>
      <pages>33-45</pages>
      <abstract>While static embeddings have dominated computational approaches to lexical semantic change for quite some time, recent approaches try to leverage the contextualized embeddings generated by the language model BERT for identifying semantic shifts in historical texts. However, despite their usability for detecting changes in the more recent past, it remains unclear how well language models scale to investigations going back further in time, where the language differs substantially from the training data underlying the models. In this paper, we present GHisBERT, a BERT-based language model trained from scratch on historical data covering all attested stages of German (going back to Old High German, c. 750 CE). Given a lack of ground truth data for investigating lexical semantic change across historical German language stages, we evaluate our model via a lexical similarity analysis of ten stable concepts. We show that, in comparison with an unmodified and a fine-tuned German BERT-base model, our model performs best in terms of assessing inter-concept similarity as well as intra-concept similarity over time. This in turn argues for the necessity of pre-training historical language models from scratch when working with historical linguistic data.</abstract>
      <url hash="9d264d4c">2023.lchange-1.4</url>
      <bibkey>beck-kollner-2023-ghisbert-training</bibkey>
      <doi>10.18653/v1/2023.lchange-1.4</doi>
    </paper>
    <paper id="5">
      <title>A longitudinal study about gradual changes in the <fixed-case>I</fixed-case>ranian Online Public Sphere pre and post of ‘Mahsa Moment’: Focusing on <fixed-case>T</fixed-case>witter</title>
      <author><first>Sadegh</first><last>Jafari</last><affiliation>Iran University of Science and Technology Tehran, University of Tehran</affiliation></author>
      <author><first>Amin</first><last>Fathi</last><affiliation>Iran University of Science and Technology Tehran, University of Tehran</affiliation></author>
      <author><first>Abolfazl</first><last>Hajizadegan</last><affiliation>University of Tehran, University of Tehran</affiliation></author>
      <author><first>Amirmohammad</first><last>Kazemeini</last><affiliation>Vector Institute</affiliation></author>
      <author><first>Sauleh</first><last>Eetemadi</last><affiliation>Iran University of Science and Technology</affiliation></author>
      <pages>46-52</pages>
      <abstract>Mahsa Amini’s death shocked Iranian society. The effects of this event and the subsequent tragedies in Iran not only in realspace but also in cyberspace, including Twitter, were tremendous and unimaginable. We explore how Twitter has changed after Mahsa Amini’s death by analyzing the sentiments of Iranian users in the 90 days after this event. Additionally, we track the change in word meaning and each word’s neighboring words. Finally, we use word clustering methods for topic modeling.</abstract>
      <url hash="4ee1dd3d">2023.lchange-1.5</url>
      <bibkey>jafari-etal-2023-longitudinal-study</bibkey>
      <doi>10.18653/v1/2023.lchange-1.5</doi>
      <video href="2023.lchange-1.5.mp4"/>
    </paper>
    <paper id="6">
      <title>Political dogwhistles and community divergence in semantic change</title>
      <author><first>Max</first><last>Boholm</last><affiliation>University of Gothenburg</affiliation></author>
      <author><first>Asad</first><last>Sayeed</last><affiliation>University of Gothenburg</affiliation></author>
      <pages>53-65</pages>
      <abstract>We test whether the development of political dogwhistles can be observed using language change measures; specifically, does the development of a “hidden” message in a dogwhistle show up as differences in semantic change between communities over time? We take Swedish-language dogwhistles related to the on-going immigration debate and measure differences over time in their rate of semantic change between two Swedish-language community forums, Flashback and Familjeliv, the former representing an in-group for understanding the “hidden” meaning of the dogwhistles. We find that multiple measures are sensitive enough to detect differences over time, in that the meaning changes in Flashback over the relevant time period but not in Familjeliv. We also examine the sensitivity of multiple modeling approaches to semantic change in the matter of community divergence.</abstract>
      <url hash="99496059">2023.lchange-1.6</url>
      <bibkey>boholm-sayeed-2023-political-dogwhistles</bibkey>
      <doi>10.18653/v1/2023.lchange-1.6</doi>
    </paper>
    <paper id="7">
      <title><fixed-case>E</fixed-case>vo<fixed-case>S</fixed-case>em: A database of polysemous cognate sets</title>
      <author><first>Mathieu</first><last>Dehouck</last><affiliation>CNRS</affiliation></author>
      <author><first>Alex</first><last>François</last><affiliation>CNRS</affiliation></author>
      <author><first>Siva</first><last>Kalyan</last><affiliation>University of Queensland and Australian National University</affiliation></author>
      <author><first>Martial</first><last>Pastor</last><affiliation>Radboud University Nijmegen</affiliation></author>
      <author><first>David</first><last>Kletz</last><affiliation>CNRS</affiliation></author>
      <pages>66-75</pages>
      <abstract>Polysemies, or “colexifications”, are of great interest in cognitive and historical linguistics, since meanings that are frequently expressed by the same lexeme are likely to be conceptually similar, and lie along a common pathway of semantic change. We argue that these types of inferences can be more reliably drawn from polysemies of cognate sets (which we call “dialexifications”) than from polysemies of lexemes. After giving a precise definition of dialexification, we introduce Evosem, a cross-linguistic database of etymologies scraped from several online sources. Based on this database, we measure for each pair of senses how many cognate sets include them both — i.e. how often this pair of senses is “dialexified”. This allows us to construct a weighted dialexification graph for any set of senses, indicating the conceptual and historical closeness of each pair. We also present an online interface for browsing our database, including graphs and interactive tables. We then discuss potential applications to NLP tasks and to linguistic research.</abstract>
      <url hash="ff4a3683">2023.lchange-1.7</url>
      <bibkey>dehouck-etal-2023-evosem-database</bibkey>
      <doi>10.18653/v1/2023.lchange-1.7</doi>
    </paper>
    <paper id="8">
      <title>Multi-lect automatic detection of <fixed-case>S</fixed-case>wadesh list items from raw corpus data in <fixed-case>E</fixed-case>ast <fixed-case>S</fixed-case>lavic languages</title>
      <author><first>Ilia</first><last>Afanasev</last><affiliation>Universität Vienna</affiliation></author>
      <pages>76-86</pages>
      <abstract>The article introduces a novel task of multi-lect automatic detection of Swadesh list items from raw corpora. The task aids the early stageof historical linguistics study by helping the researcher compile word lists for further analysis.In this paper, I test multi-lect automatic detection on the East Slavic lects’ data. The training data consists of Ukrainian, Belarusian, and Russian material. I introduce a new dataset for the Ukrainian language. I implement data augmentation techniques to give automatic tools a better understanding of the searched value. The test data consists of the Old East Slavic texts.I train HMM, CRF, and mBERT models, then test and evaluate them by harmonic F1 score. The baseline is a Random Forest classifier. I introduce two different subtasks: the search for new Swadesh list items, and the search for the known Swadesh list items in new lects of the well-established group. The first subtask, given the simultaneously diverse and vague nature of the Swadesh list, currently presents an almost unbeatable challenge for machine learning methods. The second subtask, on the other hand, is easier, and the mBERT model achieves a 0.57 F1 score. This is an impressive result, given how hard it is to formalise the token belonging to a very specific and thematically diverse set of concepts.</abstract>
      <url hash="093c0a88">2023.lchange-1.8</url>
      <bibkey>afanasev-2023-multi-lect</bibkey>
      <doi>10.18653/v1/2023.lchange-1.8</doi>
    </paper>
    <paper id="9">
      <title>Anchors in Embedding Space: A Simple Concept Tracking Approach to Support Conceptual History Research</title>
      <author><first>Jetske</first><last>Adams</last><affiliation>Radboud University</affiliation></author>
      <author><first>Martha</first><last>Larson</last><affiliation>Radboud University</affiliation></author>
      <author><first>Jaap</first><last>Verheul</last><affiliation>Utrecht University and Radboud University</affiliation></author>
      <author><first>Michael</first><last>Boyden</last><affiliation>Radboud University</affiliation></author>
      <pages>87-92</pages>
      <abstract>We introduce a simple concept tracking approach to support conceptual history research. Building on the existing practices of conceptual historians, we use dictionaries to identify “anchors”, which represent primary dimensions of meaning of a concept. Then, we create a plot showing how a key concept has evolved over time in a historical corpus in relation to these dimensions. We demonstrate the approach by plotting the change of several key concepts in the COHA corpus.</abstract>
      <url hash="6cb4faa6">2023.lchange-1.9</url>
      <bibkey>adams-etal-2023-anchors-embedding</bibkey>
      <doi>10.18653/v1/2023.lchange-1.9</doi>
    </paper>
    <paper id="10">
      <title><fixed-case>C</fixed-case>hi<fixed-case>WUG</fixed-case>: A Graph-based Evaluation Dataset for <fixed-case>C</fixed-case>hinese Lexical Semantic Change Detection</title>
      <author><first>Jing</first><last>Chen</last><affiliation>Hong Kong Polytechnic University</affiliation></author>
      <author><first>Emmanuele</first><last>Chersoni</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Dominik</first><last>Schlechtweg</last><affiliation>Institute for Natural Language Processing, University of Stuttgart</affiliation></author>
      <author><first>Jelena</first><last>Prokic</last><affiliation>Universiteit Leiden</affiliation></author>
      <author><first>Chu-Ren</first><last>Huang</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <pages>93-99</pages>
      <abstract>Recent studies suggested that language models are efficient tools for measuring lexical semantic change. In our paper, we present the compilation of the first graph-based evaluation dataset for lexical semantic change in the context of the Chinese language, specifically covering the periods of pre- and post- Reform and Opening Up. Exploiting the existing framework DURel, we collect over 61,000 human semantic relatedness judgments for 40 targets. The inferred word usage graphs and semantic change scores provide a basis for visualization and evaluation of semantic change.</abstract>
      <url hash="a59a7dbe">2023.lchange-1.10</url>
      <bibkey>chen-etal-2023-chiwug-graph</bibkey>
      <doi>10.18653/v1/2023.lchange-1.10</doi>
    </paper>
    <paper id="11">
      <title>Towards Detecting Lexical Change of Hate Speech in Historical Data</title>
      <author><first>Sanne</first><last>Hoeken</last><affiliation>Universität Bielefeld</affiliation></author>
      <author><first>Sophie</first><last>Spliethoff</last><affiliation>Universität Bielefeld</affiliation></author>
      <author><first>Silke</first><last>Schwandt</last><affiliation>Universität Bielefeld</affiliation></author>
      <author><first>Sina</first><last>Zarrieß</last><affiliation>Bielefeld University</affiliation></author>
      <author><first>Özge</first><last>Alacam</last><affiliation>Bielefeld University</affiliation></author>
      <pages>100-111</pages>
      <abstract>The investigation of lexical change has predominantly focused on generic language evolution, not suited for detecting shifts in a particular domain, such as hate speech. Our study introduces the task of identifying changes in lexical semantics related to hate speech within historical texts. We present an interdisciplinary approach that brings together NLP and History, yielding a pilot dataset comprising 16th-century Early Modern English religious writings during the Protestant Reformation. We provide annotations for both semantic shifts and hatefulness on this data and, thereby, combine the tasks of Lexical Semantic Change Detection and Hate Speech Detection. Our framework and resulting dataset facilitate the evaluation of our applied methods, advancing the analysis of hate speech evolution.</abstract>
      <url hash="dabfa85a">2023.lchange-1.11</url>
      <bibkey>hoeken-etal-2023-towards-detecting</bibkey>
      <doi>10.18653/v1/2023.lchange-1.11</doi>
    </paper>
    <paper id="12">
      <title>Changing usage of <fixed-case>L</fixed-case>ow <fixed-case>S</fixed-case>axon auxiliary and modal verbs</title>
      <author><first>Janine</first><last>Siewert</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Martijn</first><last>Wieling</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Yves</first><last>Scherrer</last><affiliation>University of Helsinki</affiliation></author>
      <pages>112-118</pages>
      <abstract>We investigate the usage of auxiliary and modal verbs in Low Saxon dialects from both Germany and the Netherlands based on word vectors, and compare developments in the modern language to Middle Low Saxon. Although most of these function words have not been affected by lexical replacement, changes in usage that likely at least partly result from contact with the state languages can still be observed.</abstract>
      <url hash="20982fc0">2023.lchange-1.12</url>
      <bibkey>siewert-etal-2023-changing-usage</bibkey>
      <doi>10.18653/v1/2023.lchange-1.12</doi>
    </paper>
    <paper id="13">
      <title>Semantic Shifts in Mental Health-Related Concepts</title>
      <author><first>Naomi</first><last>Baes</last><affiliation>The University of Melbourne</affiliation></author>
      <author><first>Nick</first><last>Haslam</last><affiliation>The University of Melbourne</affiliation></author>
      <author><first>Ekaterina</first><last>Vylomova</last><affiliation>The University of Melbourne</affiliation></author>
      <pages>119-128</pages>
      <abstract>The present study evaluates semantic shifts in mental health-related concepts in two diachronic corpora spanning 1970-2016, one academic and one general. It evaluates whether their meanings have broadened to encompass less severe phenomena and whether they have become more pathology related. It applies a recently proposed methodology (Baes et al., 2023) to examine whether words collocating with a sample of mental health concepts have become less emotionally intense and develops a new way to examine whether the concepts increasingly co-occur with pathology-related terms. In support of the first hypothesis, mental health-related concepts became associated with less emotionally intense language in the psychology corpus (addiction, anger, stress, worry) and in the general corpus (addiction, grief, stress, worry). In support of the second hypothesis, mental health-related concepts came to be more associated with pathology-related language in psychology (addiction, grief, stress, worry) and in the general corpus (grief, stress). Findings demonstrate that some mental health concepts have become normalized and/or pathologized, a conclusion with important social and cultural implications.</abstract>
      <url hash="26e638f2">2023.lchange-1.13</url>
      <bibkey>baes-etal-2023-semantic-shifts</bibkey>
      <doi>10.18653/v1/2023.lchange-1.13</doi>
    </paper>
    <paper id="14">
      <title>Automating Sound Change Prediction for Phylogenetic Inference: A Tukanoan Case Study</title>
      <author><first>Kalvin</first><last>Chang</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Nathaniel</first><last>Robinson</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Anna</first><last>Cai</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Ting</first><last>Chen</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Annie</first><last>Zhang</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>David</first><last>Mortensen</last><affiliation>Carnegie Mellon University</affiliation></author>
      <pages>129-142</pages>
      <abstract>We describe a set of new methods to partially automate linguistic phylogenetic inference given (1) cognate sets with their respective protoforms and sound laws, (2) a mapping from phones to their articulatory features and (3) a typological database of sound changes.We train a neural network on these sound change data to weight articulatory distances between phones and predict intermediate sound change steps between historical protoforms and their modern descendants, replacing a linguistic expert in part of a parsimony-based phylogenetic inference algorithm. In our best experiments on Tukanoan languages, this method produces trees with a Generalized Quartet Distance of 0.12 from a tree that used expert annotations, a significant improvement over other semi-automated baselines. We discuss potential benefits and drawbacks to our neural approach and parsimony-based tree prediction. We also experiment with a minimal generalization learner for automatic sound law induction, finding it less effective than sound laws from expert annotation. Our code is publicly available.</abstract>
      <url hash="6f89995b">2023.lchange-1.14</url>
      <bibkey>chang-etal-2023-automating-sound</bibkey>
      <doi>10.18653/v1/2023.lchange-1.14</doi>
    </paper>
    <paper id="15">
      <title>Scent and Sensibility: Perception Shifts in the Olfactory Domain</title>
      <author><first>Teresa</first><last>Paccosi</last><affiliation>Fondazione Bruno Kessler and University of Trento</affiliation></author>
      <author><first>Stefano</first><last>Menini</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Elisa</first><last>Leonardelli</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Ilaria</first><last>Barzon</last><affiliation>University of Pavia</affiliation></author>
      <author><first>Sara</first><last>Tonelli</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <pages>143-152</pages>
      <abstract>In this work, we investigate olfactory perception shifts, analysing how the description of the smells emitted by specific sources has changed over time. We first create a benchmark of selected smell sources, relying upon existing historical studies related to olfaction. We also collect an English text corpus by retrieving large collections of documents from freely available resources, spanning from 1500 to 2000 and covering different domains. We label such corpus using a system for olfactory information extraction inspired by frame semantics, where the semantic roles around the smell sources in the benchmark are marked. We then analyse how the roles describing Qualities of smell sources change over time and how they can contribute to characterise perception shifts, also in comparison with more standard statistical approaches.</abstract>
      <url hash="35dd7bd2">2023.lchange-1.15</url>
      <bibkey>paccosi-etal-2023-scent-sensibility</bibkey>
      <doi>10.18653/v1/2023.lchange-1.15</doi>
    </paper>
    <paper id="16">
      <title>From Diachronic to Contextual Lexical Semantic Change: Introducing Semantic Difference Keywords (<fixed-case>SDK</fixed-case>s) for Discourse Studies</title>
      <author><first>Isabelle</first><last>Gribomont</last><affiliation>UCLouvain</affiliation></author>
      <pages>153-160</pages>
      <abstract>This paper introduces the concept of Semantic Difference Keywords (SDKs). We define SDKs as keywords selected because of a comparatively high semantic difference between their use in two or more corpora. They are extracted by applying methods developed to identify diachronic Lexical Semantic Change. Like statistical keywords, most commonly used in quantitative discourse studies, SDKs capture the distinctiveness of a target corpus. However, they do not do so because they are used significantly more often or more consistently, but because they are used significantly differently. The case study presented in this paper shows that SDKs are successful in identifying concepts which are contested, i.e., sites of “semantic struggles” (CITATION). SDKs are therefore a useful contribution to (computational) discourse studies and text-based Digital Humanities more broadly.</abstract>
      <url hash="1dbbd29c">2023.lchange-1.16</url>
      <bibkey>gribomont-2023-diachronic-contextual</bibkey>
      <doi>10.18653/v1/2023.lchange-1.16</doi>
    </paper>
  </volume>
</collection>
