<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.nlpai4health">
  <volume id="main" ingest-date="2026-01-13" type="proceedings">
    <meta>
      <booktitle>NLP-AI4Health</booktitle>
      <editor><first>Arun</first><last>Zechariah</last></editor>
      <editor><first>Balu</first><last>Krishna S</last></editor>
      <editor><first>Dipti</first><last>Misra Sharma</last></editor>
      <editor><first>Hannah</first><last>Mary Thomas</last></editor>
      <editor><first>Joy</first><last>Mammen</last></editor>
      <editor id="parameswari-krishnamurthy"><first>Parameswari</first><last>Krishnamurthy</last></editor>
      <editor id="vandan-mujadia"><first>Vandan</first><last>Mujadia</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Mumbai, India</address>
      <month>December</month>
      <year>2025</year>
      <url hash="336a90eb">2025.nlpai4health-main</url>
      <venue>nlpai4health</venue>
      <venue>ws</venue>
      <isbn>979-8-89176-315-9</isbn>
    </meta>
    <frontmatter>
      <url hash="7f8b77ca">2025.nlpai4health-main.0</url>
      <bibkey>nlp-ai4health-ws-2025-main</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Enhancing Patient-Centric Healthcare Communication Through Multimodal Emotion Recognition: A Transformer-Based Framework for Clinical Decision Support</title>
      <author><first>Vineet</first><last>Channe</last></author>
      <pages>1-8</pages>
      <abstract>This paper presents a multimodal emotion analysis framework designed to enhance patient-centric healthcare communication and support clinical decision-making. Our system addresses automated patient emotion monitoring during consultations, telemedicine sessions, and mental health screenings by combining audio transcription, facial emotion analysis, and text processing. Using emotion patterns from the CREMA-D dataset as a foundation for healthcare-relevant emotional expressions, we introduce a novel emotion-annotated text format “[emotion] transcript [emotion]” integrating Whisper-based audio transcription with DeepFace facial emotion analysis. We systematically evaluate eight transformer architectures (BERT, RoBERTa, DeBERTa, XLNet, ALBERT, DistilBERT, ELECTRA, and BERT-base) for three-class clinical emotion classification: Distress/Negative (anxiety, fear), Stable/Neutral (baseline), and Engaged/Positive (comfort). Our multimodal fusion strategy achieves 86.8% accuracy with DeBERTa-v3-base, representing a 12.6% improvement over unimodal approaches and meeting clinical requirements for reliable patient emotion detection. Cross-modal attention analysis reveals facial expressions provide crucial disambiguation, with stronger attention to negative emotions (0.41 vs 0.28), aligning with clinical priorities for detecting patient distress. Our contributions include emotion-annotated text representation for healthcare contexts, systematic transformer evaluation for clinical deployment, and a framework enabling real-time patient emotion monitoring and emotionally-aware clinical decision support.</abstract>
      <url hash="e43cd8d8">2025.nlpai4health-main.1</url>
      <bibkey>channe-2025-enhancing</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>MOD</fixed-case>-<fixed-case>KG</fixed-case>: <fixed-case>M</fixed-case>ulti<fixed-case>O</fixed-case>rgan Diagnosis Knowledge Graph</title>
      <author orcid="0009-0004-7917-5328"><first>Anas Anwarul Haq</first><last>Khan</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last><affiliation>Indian Institute of Technology, Bombay, Dhirubhai Ambani Institute Of Information and Communication Technology</affiliation></author>
      <pages>9-15</pages>
      <abstract>The human body is highly interconnected, where a diagnosis in one organ can influence conditions in others. In medical research, graphs (such as Knowledge Graphs and Causal Graphs) have proven useful for capturing these relationships, but constructing them manually with expert input is both costly and time-intensive, especially given the continuous flow of new findings. To address this, we leverage the extraction capabilities of large language models (LLMs) to build the **MultiOrgan Diagnosis Knowledge Graph (MOD-KG)**. MOD-KG contains over **21,200 knowledge triples**, derived from both textbooks **(~13%)** and carefully selected research papers (with an average of **444** citations each). The graph focuses primarily on the *heart, lungs, kidneys, liver, pancreas, and brain*, which are central to much of today’s multimodal imaging research. The extraction quality of the LLM was benchmarked against baselines over **1000** samples, demonstrating reliability. We will make our dataset public upon acceptance.</abstract>
      <url hash="e455c5d8">2025.nlpai4health-main.2</url>
      <bibkey>khan-bhattacharyya-2025-mod</bibkey>
    </paper>
    <paper id="3">
      <title>Cross-Lingual Mental Health Ontologies for <fixed-case>I</fixed-case>ndian Languages: Bridging Patient Expression and Clinical Understanding through Explainable <fixed-case>AI</fixed-case> and Human-in-the-Loop Validation</title>
      <author><first>Ananth</first><last>Kandala</last></author>
      <author><first>Ratna</first><last>Kandala</last><affiliation>University of Kansas</affiliation></author>
      <author><first>Akshata Kishore</first><last>Moharir</last><affiliation>Microsoft</affiliation></author>
      <author><first>Niva</first><last>Manchanda</last></author>
      <author><first>Sunaina Singh</first><last>Rathod</last></author>
      <pages>16-24</pages>
      <abstract>Mental health communication in India is linguistically fragmented, culturally diverse, and often underrepresented in clinical NLP. Current health ontologies and mental health resources are dominated by English or Western-centric diagnostic frameworks, leaving a gap in representing patient distress expressions in Indian languages. We propose the Cross-Lingual Graphs of Patient Distress Expressions (CL-PDE), a framework for building cross-lingual mental health ontologies through graph-based methods that capture culturally embedded expressions of distress, align them across languages, and link them with clinical terminology. Our approach addresses critical gaps in healthcare communication by grounding AI systems in culturally valid representations, enabling more inclusive and patient-centric NLP tools for mental health care in multilingual contexts.</abstract>
      <url hash="9b6692d5">2025.nlpai4health-main.3</url>
      <bibkey>kandala-etal-2025-cross</bibkey>
    </paper>
    <paper id="4">
      <title>Automated Coding of Counsellor and Client Behaviours in Motivational Interviewing Transcripts: Validation and Application</title>
      <author><first>Armaity</first><last>Katki</last></author>
      <author><first>Nathan</first><last>Choi</last></author>
      <author><first>Son Sophak</first><last>Otra</last></author>
      <author><first>George</first><last>Flint</last></author>
      <author><first>Kevin</first><last>Zhu</last><affiliation>Algoverse AI Research</affiliation></author>
      <author><first>Sunishchal</first><last>Dev</last><affiliation>RAND Corporation and Algoverse Coding Academy LLC</affiliation></author>
      <pages>25-54</pages>
      <abstract>Protein language models (PLMs) are powerful tools for protein engineering, but remain difficult to steer toward specific biochemical properties, where small sequence changes can affect stability or function. We adapt two prominent unsupervised editing methods: task arithmetic (TA; specifically, Forgetting via Negation) in weight space and feature editing with a sparse autoencoder (SAE) in activation space. We evaluate their effects on six biochemical properties of generations from three PLMs (ESM3, ProGen2-Large, and ProLLaMA). Across models, we observe complementary efficacies: TA more effectively controls some properties while SAE more effectively controls others. Property response patterns show some consistence across models. We suggest that the response pattern of biochemical properties should be considered when steering PLMs.</abstract>
      <url hash="419e1abe">2025.nlpai4health-main.4</url>
      <bibkey>katki-etal-2025-automated</bibkey>
    </paper>
    <paper id="5">
      <title>Patient-Centric Question Answering- Overview of the Shared Task at the Second Workshop on <fixed-case>NLP</fixed-case> and <fixed-case>AI</fixed-case> for Multilingual and Healthcare Communication</title>
      <author><first>Arun</first><last>Zechariah</last></author>
      <author><first>Balu</first><last>Krishna</last></author>
      <author><first>Hannah</first><last>Mary Thomas</last></author>
      <author><first>Joy</first><last>Mammen</last></author>
      <author><first>Dipti</first><last>Misra Sharma</last></author>
      <author><first>Parameswari</first><last>Krishnamurthy</last></author>
      <author><first>Vandan</first><last>Mujadia</last></author>
      <author><first>Priyanka</first><last>Dasari</last></author>
      <author><first>Vishnuraj</first><last>Arjunaswamy</last></author>
      <pages>55-68</pages>
      <abstract>This paper presents an overview of the Shared Task on Patient-Centric Question Answering, organized as part of the NLP-AI4Health workshop at IJCNLP. The task aims to bridge the digital divide in healthcare by developing inclusive systems for two critical domains: Head and Neck Cancer (HNC) and Cystic Fibrosis (CF). We introduce the NLP4Health-2025 Dataset, a novel, large-scale multilingual corpus consisting of more than 45,000 validated multi-turn dialogues between patients and healthcare providers across 10 languages: Assamese, Bangla, Dogri, English, Gujarati, Hindi, Kannada, Marathi, Tamil, and Telugu. Participants were challenged to develop lightweight models (<tex-math>&lt;</tex-math> 3 billion parameters) to perform two core activities: (1) Clinical Summarization, encompassing both abstractive summaries and structured clinical extraction (SCE), and (2) Patient-Centric QA, generating empathetic, factually accurate answers in the dialogue native language. This paper details the hybrid human-agent dataset construction pipeline, task definitions, evaluation metrics, and analyzes the performance of 9 submissions from 6 teams. The results demonstrate the viability of small language models (SLMs) in low-resource medical settings when optimized via techniques like LoRA and RAG.</abstract>
      <url hash="2a501412">2025.nlpai4health-main.5</url>
      <bibkey>zechariah-etal-2025-patient</bibkey>
    </paper>
    <paper id="6">
      <title>Multilingual Clinical Dialogue Summarization and Information Extraction with Qwen-1.5<fixed-case>B</fixed-case> <fixed-case>L</fixed-case>o<fixed-case>RA</fixed-case></title>
      <author><first>Kunwar</first><last>Zaid</last><affiliation>Tata Consultancy Services Limited, India</affiliation></author>
      <author><first>Amit</first><last>Sangroya</last></author>
      <author><first>Jyotsana</first><last>Khatri</last></author>
      <pages>69-74</pages>
      <abstract>This paper describes our submission to theNLP-AI4Health 2025 Shared Task on multi-lingual clinical dialogue summarization andstructured information extraction. Our systemis based on Qwen-1.5B Instruct fine-tuned withLoRA adapters for parameter-efficient adapta-tion. The pipeline produces (i) concise Englishsummaries, (ii) schema-aligned JSON outputs,and (iii) multilingual Q&amp;A responses. TheQwen-based approach substantially improvessummary fluency, factual completeness, andJSON field coverage while maintaining effi-ciency within constrained GPU resources.</abstract>
      <url hash="11c2a55a">2025.nlpai4health-main.6</url>
      <bibkey>zaid-etal-2025-multilingual</bibkey>
    </paper>
    <paper id="7">
      <title>Patient-Centric Multilingual Question Answering and Summary Generation for Head and Neck Cancer and Blood Donation</title>
      <author><first>Amol</first><last>Shinde</last></author>
      <author><first>Saloni</first><last>Chitte</last><affiliation>Centre for Development of Advanced Computing, India</affiliation></author>
      <author><first>Prakash B.</first><last>Pimpale</last></author>
      <pages>75-79</pages>
      <abstract>This paper describes a production minded multilingual system built for the NLP-AI4Health shared task, designed to produce concise, medically accurate summaries and patient friendly answers for Head and Neck Cancer (HNC) and Blood Donation. We finetune Gemma2-2B under a strict model size constraint (&lt;3B parameters) using parameter efficient adaptation (LoRA) and practical engineering to handle long dialogues, code mixing, and multilingual scripts. The pipeline couples careful preprocessing, token aware chunking, and constrained decoding with lightweight retrieval and verification steps. We report per language quantitative metrics and provide an analysis of design choices and operational considerations for real world deployment.</abstract>
      <url hash="17901d05">2025.nlpai4health-main.7</url>
      <bibkey>shinde-etal-2025-patient</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>SAHA</fixed-case>: Samvad <fixed-case>AI</fixed-case> for Healthcare Assistance</title>
      <author orcid="0009-0008-1592-4675"><first>Aditya</first><last>Kumar</last></author>
      <author><first>Rakesh Kumar</first><last>Nayak</last><affiliation>Indian institute of information technology surat</affiliation></author>
      <author><first>Janhavi</first><last>Naik</last></author>
      <author><first>Ritesh</first><last>Kumar</last><affiliation>IIIT Surat</affiliation></author>
      <author><first>Dhiraj</first><last>Bhatia</last></author>
      <author orcid="0000-0001-8713-2679"><first>Shreya</first><last>Agarwal</last><affiliation>Indian Institute of Information Technology</affiliation></author>
      <pages>80-85</pages>
      <abstract>This paper deals with the dual task of developing a medical question answering (QA) system and generating concise summaries of medical dialogue data across nine languages (English and eight Indian languages). The medical dialogue data focuses on two critical health issues: Head and Neck Cancer (HNC) and Cystic Fibrosis (NLP AI4health shared task). The proposed framework utilises a dual approach: a fine-tuned small Multilingual Text-to-Text Transfer Transformer (mT5) model for the conversational summarisation component and a fine-tuned Retrieval Augmented Generation (RAG) system integrating the dense intfloat/e5-large language model for the language-independent QA component. The efficacy of the proposed approaches is demonstrated by achieving promising precision in the QA task. Our framework achieved the highest F1 scores in QA for the three Indian languages, with F1 score of 0.3995 in Marathi, 0.7803 in Bangla, and 0.74759 in Hindi, respectively. We achieved the highest cometscore of 0.5626 on the Gujarati QA test set. For the dialogue summarisation task, our model registered the highest ROUGE-2 and ROUGE-L precision across all eight Indian languages, with English being the sole exception. These results confirm our approach potential to improve e-health in dialogue data for low-resource Indian languages.</abstract>
      <url hash="1df80a1b">2025.nlpai4health-main.8</url>
      <bibkey>kumar-etal-2025-saha</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>M</fixed-case>ed<fixed-case>Q</fixed-case>wen-<fixed-case>PE</fixed-case>: Medical Qwen for Parameter-Efficient Multilingual Patient-Centric Summarization, Question Answering and Information Extraction</title>
      <author><first>Vinay Babu</first><last>Ulli</last><affiliation>Oogwai Analytics</affiliation></author>
      <author><first>Anindita</first><last>Mondal</last></author>
      <pages>86-92</pages>
      <abstract>This study addresses the Shared Task on Patient-Centric Multilingual Question Answering, which focuses on generating summaries and patient-oriented answers from multi-turn medical dialogues related to Head and Neck Cancer and Cystic Fibrosis across ten languages. The Qwen3-1.7B model is fine-tuned using QLoRA for three tasks—Summarization, Question Answering, and Information Extraction—while updating only approximately 1.6% of parameters through task-specific adapter layers. The resulting system demonstrates strong semantic fidelity, as evidenced by high BERTScore and COMET scores, particularly for Kannada, English, Telugu, and Tamil, with comparatively lower performance in Assamese, Bangla, Gujarati, and Marathi. The modular fine-tuning design enables efficient task adaptation while satisfying the constraints on model size and computational resources.</abstract>
      <url hash="4a8e6e29">2025.nlpai4health-main.9</url>
      <bibkey>ulli-mondal-2025-medqwen</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>NLP</fixed-case>4<fixed-case>H</fixed-case>ealth: Multilingual Clinical Dialogue Summarization and <fixed-case>QA</fixed-case> with m<fixed-case>T</fixed-case>5 and <fixed-case>L</fixed-case>o<fixed-case>RA</fixed-case></title>
      <author><first>Moutushi</first><last>Roy</last></author>
      <author orcid="0000-0002-8110-9344"><first>Dipankar</first><last>Das</last><affiliation>Jadavpur University</affiliation></author>
      <pages>93-97</pages>
      <abstract>In this work, we present NLP4Health, a unified and reproducible pipeline to accomplish the tasks of multilingual clinical dialogue summarization and question answering (QA). Our system fine-tunes the multilingual sequence-to-sequence model google/mt5-base along with parameter-efficient Low-Rank Adaptation (LoRA) modules to support ten Indian languages. For each clinical dialogue, the model produces (1) a free-text English summary, (2) an English structured key–value (KnV) JSON summary, and (3) QA responses in the dialogue’s original language. We conducted preprocessing, fine-tuning, and inference, and evaluated across QA, textual, and structured metrics, analyzing performance in low-resource settings. The adapter weights, tokenizer, and inference scripts are publicly released to promote transparency and reproducibility.</abstract>
      <url hash="06d6d4cb">2025.nlpai4health-main.10</url>
      <bibkey>roy-das-2025-nlp4health</bibkey>
    </paper>
  </volume>
</collection>
