<?xml version='1.0' encoding='UTF-8'?>
<collection id="2019.lilt">
  <volume id="17">
    <meta>
      <booktitle>Linguistic Issues in Language Technology, Volume 17, 2019</booktitle>
      <publisher>CSLI Publications</publisher>
      <year>2019</year>
    </meta>
    <paper id="1">
      <title>Syntactic composition and selectional preferences in <fixed-case>H</fixed-case>indi Light Verb Constructions</title>
      <author><first>Ashwini</first><last>Vaidya</last></author>
      <author><first>Martha</first><last>Palmer</last></author>
      <abstract>Previous work on light verb constructions (e.g. chorii kar ‘theft do; steal’) in Hindi describes their syntactic formation via co-predication (Ahmed et al., 2012, Butt, 2014). This implies that both noun and light verb contribute their arguments, and these overlapping argument structures must be composed in the syntax. In this paper, we present a co-predication analysis using Tree-Adjoining Grammar, which models syntactic composition and semantic selectional preferences without transformations (deletion or argument identification). The analysis has two key components (i) an underspecified category for the nominal and (ii) combinatorial constraints on the noun and light verb to specify selectional preferences. The former has the advantage of syntactic composition without argument identification and the latter prevents over-generalization, while recognizing the semantic contribution of both predicates. This work additionally accounts for the agreement facts for the Hindi LVC.</abstract>
      <issue>1</issue>
      <url hash="4165b47d">2019.lilt-17.1</url>
    </paper>
    <paper id="2">
      <title>Argument alternations in complex predicates: an <fixed-case>LFG</fixed-case>+glue perspective</title>
      <author><first>John J.</first><last>Lowe</last></author>
      <abstract>Vaidya et al. (2019) discuss argument alternations in Hindi complex predicates, and propose an analysis within an LTAG framework, comparing this with an LFG analysis of complex predicates. In this paper I clarify the inadequacies in existing LFG analyses of complex predicates, and show how the LFG+glue approach proposed by Lowe (2015) can both address these inadequacies and provide a relatively simple treatment of the phenomena discussed by Vaidya et al. (2019).</abstract>
      <issue>2</issue>
      <url hash="72b6155f">2019.lilt-17.2</url>
    </paper>
    <paper id="3">
      <title>Complex predicates: Structure, potential structure and underspecification</title>
      <author><first>Stephan</first><last>Müller</last></author>
      <abstract>This paper compares a recent TAG-based analysis of complex predicates in Hindi/Urdu with its HPSG analog. It points out that TAG combines actual structure while HPSG (and Categorial Grammar and other valence-based frameworks) specify valence of lexical items and hence potential structure. This makes it possible to have light verbs decide which arguments of embedded heads get realized, somthing that is not possible in TAG. TAG has to retreat to disjunctions instead. While this allows straight-forward analyses of active/passive alternations based on the light verb in valence-based frameworks, such an option does not exist for TAG and it has to be assumed that preverbs come with different sets of arguments.</abstract>
      <issue>3</issue>
      <url hash="c763c515">2019.lilt-17.3</url>
    </paper>
    <paper id="4">
      <title>Complex Predicates and Multidimensionality in Grammar</title>
      <author><first>Miriam</first><last>Butt</last></author>
      <abstract>This paper contributes to the on-going discussion of how best to analyze and handle complex predicate formations, commenting in particular on the properties of Hindi N-V complex predicates as set out by Vaidya et al. (2019). I highlight features of existing LFG analyses and focus in particular on the modular architecture of LFG, its attendant multidimensional lexicon and the analytic consequences which follow from this. I point out where the previously existing LFG proposals have been misunderstood as viewed from the lens of theories such as LTAG and HPSG, which assume a very different architectural set-up and provide a comparative discussion of the issues.</abstract>
      <issue>4</issue>
      <url hash="ebab151e">2019.lilt-17.4</url>
    </paper>
  </volume>
  <volume id="18">
    <meta>
      <booktitle>Linguistic Issues in Language Technology, Volume 18, 2019 - Exploiting Parsed Corpora: Applications in Research, Pedagogy, and Processing</booktitle>
      <publisher>CSLI Publications</publisher>
      <year>2019</year>
      <month>Jul</month>
    </meta>
    <paper id="1">
      <title>Exploiting Parsed Corpora: Applications in Research, Pedagogy, and Processing</title>
      <author><first>Prashant</first><last>Pardeshi</last></author>
      <author><first>Alistair</first><last>Butler</last></author>
      <author><first>Stephen</first><last>Horn</last></author>
      <author><first>Kei</first><last>Yoshimoto</last></author>
      <author><first>Iku</first><last>Nagasaki</last></author>
      <issue>0</issue>
      <url hash="f58f1f11">2019.lilt-18.1</url>
    </paper>
    <paper id="2">
      <title>Building a <fixed-case>C</fixed-case>hinese <fixed-case>AMR</fixed-case> Bank with Concept and Relation Alignments</title>
      <author><first>Bin</first><last>Li</last></author>
      <author><first>Yuan</first><last>Wen</last></author>
      <author><first>Li</first><last>Song</last></author>
      <author><first>Weiguang</first><last>Qu</last></author>
      <author><first>Nianwen</first><last>Xue</last></author>
      <abstract>Abstract Meaning Representation (AMR) is a meaning representation framework in which the meaning of a full sentence is represented as a single-rooted, acyclic, directed graph. In this article, we describe an on-going project to build a Chinese AMR (CAMR) corpus, which currently includes 10,149 sentences from the newsgroup and weblog portion of the Chinese TreeBank (CTB). We describe the annotation specifications for the CAMR corpus, which follow the annotation principles of English AMR but make adaptations where needed to accommodate the linguistic facts of Chinese. The CAMR specifications also include a systematic treatment of sentence-internal discourse relations. One significant change we have made to the AMR annotation methodology is the inclusion of the alignment between word tokens in the sentence and the concepts/relations in the CAMR annotation to make it easier for automatic parsers to model the correspondence between a sentence and its meaning representation. We develop an annotation tool for CAMR, and the inter-agreement as measured by the Smatch score between the two annotators is 0.83, indicating reliable annotation. We also present some quantitative analysis of the CAMR corpus. 46.71% of the AMRs of the sentences are non-tree graphs. Moreover, the AMR of 88.95% of the sentences has concepts inferred from the context of the sentence but do not correspond to a specific word.</abstract>
      <issue>1</issue>
      <url hash="e48846f0">2019.lilt-18.2</url>
    </paper>
    <paper id="3">
      <title>Parsed Corpus as a Source for Testing Generalizations in <fixed-case>J</fixed-case>apanese Syntax</title>
      <author><first>Hideki</first><last>Kishimoto</last></author>
      <author><first>Prashant</first><last>Pardeshi</last></author>
      <abstract>In this paper, we discuss constituent ordering generalizations in Japanese. Japanese has SOV as its basic order, but a significant range of argument order variations brought about by ‘scrambling’ is permitted. Although scrambling does not induce much in the way of semantic effects, it is conceivable that marked orders are derived from the unmarked order under some pragmatic or other motivations. The difference in the effect of basic and derived order is not reflected in native speaker’s grammaticality judgments, but we suggest that the intuition about the ordering of arguments may be attested in corpus data. By using the Keyaki treebank (a proper subset of which is NINJAL Parsed Corpus of Modern Japanese (NPCMJ)), it is shown that the naturallyoccurring corpus data confirm that marked orderings of arguments are less frequent than their unmarked ordering counterparts. We suggest some possible motivations lying behind the argument order variations.</abstract>
      <issue>2</issue>
      <url hash="abfe9208">2019.lilt-18.3</url>
    </paper>
    <paper id="4">
      <title>Probing the nature of an island constraint with a parsed corpus</title>
      <author><first>Yusuke</first><last>Kubota</last></author>
      <author><first>Ai</first><last>Kubota</last></author>
      <abstract>This paper presents a case study of the use of the NINJAL Parsed Corpus of Modern Japanese (NPCMJ) for syntactic research. NPCMJ is the first phrase structure-based treebank for Japanese that is specifically designed for application in linguistic (in addition to NLP) research. After discussing some basic methodological issues pertaining to the use of treebanks for theoretical linguistics research, we introduce our case study on the status of the Coordinate Structure Constraint (CSC) in Japanese, showing that NPCMJ enables us to easily retrieve examples that support one of the key claims of Kubota and Lee (2015): that the CSC should be viewed as a pragmatic, rather than a syntactic constraint. The corpus-based study we conducted moreover revealed a previously unnoticed tendency that was highly relevant for further clarifying the principles governing the empirical data in question. We conclude the paper by briefly discussing some further methodological issues brought up by our case study pertaining to the relationship between linguistic research and corpus development.</abstract>
      <issue>3</issue>
      <url hash="e8eee2a0">2019.lilt-18.4</url>
    </paper>
    <paper id="5">
      <title>Adding linguistic information to parsed corpora</title>
      <author><first>Susan</first><last>Pintzuk</last></author>
      <abstract>No matter how comprehensively corpus builders design their annotation schemes, users frequently find that information is missing that they need for their research. In this methodological paper I describe and illustrate five methods of adding linguistic information to corpora that have been morphosyntactically annotated (=parsed) in the style of Penn treebanks. Some of these methods involve manual operations; some are executed by CorpusSearch functions; some require a combination of manual and automated procedures. Which method is used depends almost entirely on the type of information to be added and the goals of the user. Of course, the main goal, regardless of method, is to record within the corpus additional information that can be used for analysis and also retained through further searches and data processing.</abstract>
      <issue>4</issue>
      <url hash="d784a4a7">2019.lilt-18.5</url>
    </paper>
    <paper id="6">
      <title>Exploiting parsed corpora in grammar teaching</title>
      <author><first>Sean</first><last>Wallis</last></author>
      <author><first>Ian</first><last>Cushing</last></author>
      <author><first>Bas</first><last>Aarts</last></author>
      <abstract>The principal barrier to the uptake of technologies in schools is not technological, but social and political. Teachers must be convinced of the pedagogical benefits of a particular curriculum before they will agree to learn the means to teach it. The teaching of formal grammar to first language students in schools is no exception to this rule. Over the last three decades, most schools in England have been legally required to teach grammatical subject knowledge, i.e. linguistic knowledge of grammar terms and structure, to children age five and upwards as part of the national curriculum in English. A mandatory set of curriculum specifications for England and Wales was published in 2014, and elsewhere similar requirements were imposed. However, few current English school teachers were taught grammar themselves, and the dominant view has long been in favour of ‘real books’ rather than the teaching of a formal grammar. English grammar teaching thus faces multiple challenges: to convince teachers of the value of grammar in their own teaching, to teach the teachers the knowledge they need, and to develop relevant resources to use in the classroom. Alongside subject knowledge, teachers need pedagogical knowledge – how to teach grammar effectively and how to integrate this teaching into other kinds of language learning. The paper introduces the Englicious1 web platform for schools, and summarises its development and impact since publication. Englicious draws data from the fully-parsed British Component of the International Corpus of English, ICE-GB. The corpus offers plentiful examples of genuine natural language, speech and writing, with context and potentially audio playback. However, corpus examples may be ageinappropriate or over-complex, and without grammar training, teachers are insufficiently equipped to use them. In the absence of grammatical knowledge among teachers, it is insufficient simply to give teachers and children access to a corpus. Whereas so-called ‘classroom concordancing’ approaches offer access to tools and encourage bottom-up learning, Englicious approaches the question of grammar teaching in a concept-driven, top-down way. It contains a modular series of professional development resources, lessons and exercises focused on each concept in turn, in which corpus examples are used extensively. Teachers must be able to discuss with a class why, for instance, work is a noun in a particular sentence, rather than merely report that it is. The paper describes the development of Englicious from secondary to primary, and outlines some of the practical challenges facing the design of this type of teaching resource. A key question, the ‘selection problem’, concerns how tools parameterise the selection of relevant examples for teaching purposes. Finally we discuss curricula for teaching teachers and the evaluation of the effectiveness of the intervention.</abstract>
      <issue>5</issue>
      <url hash="a862d877">2019.lilt-18.6</url>
    </paper>
  </volume>
</collection>
