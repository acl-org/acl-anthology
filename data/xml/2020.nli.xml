<?xml version='1.0' encoding='UTF-8'?>
<collection id="2020.nli">
  <volume id="1" ingest-date="2020-06-21">
    <meta>
      <booktitle>Proceedings of the First Workshop on Natural Language Interfaces</booktitle>
      <editor><first>Ahmed Hassan</first><last>Awadallah</last></editor>
      <editor><first>Yu</first><last>Su</last></editor>
      <editor><first>Huan</first><last>Sun</last></editor>
      <editor><first>Scott Wen-tau</first><last>Yih</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>July</month>
      <year>2020</year>
      <url hash="fed11dde">2020.nli-1</url>
    </meta>
    <frontmatter>
      <url hash="175d8ef8">2020.nli-1.0</url>
    </frontmatter>
    <paper id="1">
      <title>Answering Complex Questions by Combining Information from Curated and Extracted Knowledge Bases</title>
      <author><first>Nikita</first><last>Bhutani</last></author>
      <author><first>Xinyi</first><last>Zheng</last></author>
      <author><first>Kun</first><last>Qian</last></author>
      <author><first>Yunyao</first><last>Li</last></author>
      <author><first>H.</first><last>Jagadish</last></author>
      <pages>1–10</pages>
      <abstract>Knowledge-based question answering (KB_QA) has long focused on simple questions that can be answered from a single knowledge source, a manually curated or an automatically extracted KB. In this work, we look at answering complex questions which often require combining information from multiple sources. We present a novel KB-QA system, Multique, which can map a complex question to a complex query pattern using a sequence of simple queries each targeted at a specific KB. It finds simple queries using a neural-network based model capable of collective inference over textual relations in extracted KB and ontological relations in curated KB. Experiments show that our proposed system outperforms previous KB-QA systems on benchmark datasets, ComplexWebQuestions and WebQuestionsSP.</abstract>
      <url hash="0a910fed">2020.nli-1.1</url>
      <doi>10.18653/v1/2020.nli-1.1</doi>
      <video tag="video" href="http://slideslive.com/38929797"/>
    </paper>
    <paper id="2">
      <title>Towards Reversal-Based Textual Data Augmentation for <fixed-case>NLI</fixed-case> Problems with Opposable Classes</title>
      <author><first>Alexey</first><last>Tarasov</last></author>
      <pages>11–19</pages>
      <abstract>Data augmentation methods are commonly used in computer vision and speech. However, in domains dealing with textual data, such techniques are not that common. Most of the existing methods rely on rephrasing, i.e. new sentences are generated by changing a source sentence, preserving its meaning. We argue that in tasks with opposable classes (such as Positive and Negative in sentiment analysis), it might be beneficial to also invert the source sentence, reversing its meaning, to generate examples of the opposing class. Methods that use somewhat similar intuition exist in the space of adversarial learning, but are not always applicable to text classification (in our experiments, some of them were even detrimental to the resulting classifier accuracy). We propose and evaluate two reversal-based methods on an NLI task of recognising a type of a simple logical expression from its description in plain-text form. After gathering a dataset on MTurk, we show that a simple heuristic using a notion of negating the main verb has a potential not only on its own, but that it can also boost existing state-of-the-art rephrasing-based approaches.</abstract>
      <url hash="888880c6">2020.nli-1.2</url>
      <doi>10.18653/v1/2020.nli-1.2</doi>
      <video tag="video" href="http://slideslive.com/38929795"/>
    </paper>
    <paper id="3">
      <title>Examination and Extension of Strategies for Improving Personalized Language Modeling via Interpolation</title>
      <author><first>Liqun</first><last>Shao</last></author>
      <author><first>Sahitya</first><last>Mantravadi</last></author>
      <author><first>Tom</first><last>Manzini</last></author>
      <author><first>Alejandro</first><last>Buendia</last></author>
      <author><first>Manon</first><last>Knoertzer</last></author>
      <author><first>Soundar</first><last>Srinivasan</last></author>
      <author><first>Chris</first><last>Quirk</last></author>
      <pages>20–26</pages>
      <abstract>In this paper, we detail novel strategies for interpolating personalized language models and methods to handle out-of-vocabulary (OOV) tokens to improve personalized language models. Using publicly available data from Reddit, we demonstrate improvements in offline metrics at the user level by interpolating a global LSTM-based authoring model with a user-personalized n-gram model. By optimizing this approach with a back-off to uniform OOV penalty and the interpolation coefficient, we observe that over 80% of users receive a lift in perplexity, with an average of 5.4% in perplexity lift per user. In doing this research we extend previous work in building NLIs and improve the robustness of metrics for downstream tasks.</abstract>
      <url hash="7e3b5a81">2020.nli-1.3</url>
      <doi>10.18653/v1/2020.nli-1.3</doi>
      <video tag="video" href="http://slideslive.com/38929800"/>
    </paper>
    <paper id="4">
      <title>Efficient Deployment of Conversational Natural Language Interfaces over Databases</title>
      <author><first>Anthony</first><last>Colas</last></author>
      <author><first>Trung</first><last>Bui</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Moumita</first><last>Sinha</last></author>
      <author><first>Doo Soon</first><last>Kim</last></author>
      <pages>27–36</pages>
      <abstract>Many users communicate with chatbots and AI assistants in order to help them with various tasks. A key component of the assistant is the ability to understand and answer a user’s natural language questions for question-answering (QA). Because data can be usually stored in a structured manner, an essential step involves turning a natural language question into its corresponding query language. However, in order to train most natural language-to-query-language state-of-the-art models, a large amount of training data is needed first. In most domains, this data is not available and collecting such datasets for various domains can be tedious and time-consuming. In this work, we propose a novel method for accelerating the training dataset collection for developing the natural language-to-query-language machine learning models. Our system allows one to generate conversational multi-term data, where multiple turns define a dialogue session, enabling one to better utilize chatbot interfaces. We train two current state-of-the-art NL-to-QL models, on both an SQL and SPARQL-based datasets in order to showcase the adaptability and efficacy of our created data.</abstract>
      <url hash="756825dc">2020.nli-1.4</url>
      <doi>10.18653/v1/2020.nli-1.4</doi>
      <video tag="video" href="http://slideslive.com/38929798"/>
    </paper>
    <paper id="5">
      <title>Neural Multi-task Text Normalization and Sanitization with Pointer-Generator</title>
      <author><first>Hoang</first><last>Nguyen</last></author>
      <author><first>Sandro</first><last>Cavallari</last></author>
      <pages>37–47</pages>
      <abstract>Text normalization and sanitization are intrinsic components of Natural Language Inferences. In Information Retrieval or Dialogue Generation, normalization of user queries or utterances enhances linguistic understanding by translating non-canonical text to its canonical form, on which many state-of-the-art language models are trained. On the other hand, text sanitization removes sensitive information to guarantee user privacy and anonymity. Existing approaches to normalization and sanitization mainly rely on hand-crafted heuristics and syntactic features of individual tokens while disregarding the linguistic context. Moreover, such context-unaware solutions cannot dynamically determine whether out-of-vocab tokens are misspelt or are entity names. In this work, we formulate text normalization and sanitization as a multi-task text generation approach and propose a neural hybrid pointer-generator network based on multi-head attention. Its generator effectively captures linguistic context during normalization and sanitization while its pointer dynamically preserves the entities that are generally missing in the vocabulary. Experiments show that our generation approach outperforms both token-based text normalization and sanitization, while the hybrid pointer-generator improves the generator-only baseline in terms of BLEU4 score, and classical attentional pointer networks in terms of pointing accuracy.</abstract>
      <url hash="6d2763c3">2020.nli-1.5</url>
      <doi>10.18653/v1/2020.nli-1.5</doi>
      <video tag="video" href="http://slideslive.com/38929796"/>
    </paper>
  </volume>
</collection>
