<?xml version='1.0' encoding='UTF-8'?>
<collection id="2020.nlpmc">
  <volume id="1" ingest-date="2020-06-21">
    <meta>
      <booktitle>Proceedings of the First Workshop on Natural Language Processing for Medical Conversations</booktitle>
      <editor><first>Parminder</first><last>Bhatia</last></editor>
      <editor><first>Steven</first><last>Lin</last></editor>
      <editor><first>Rashmi</first><last>Gangadharaiah</last></editor>
      <editor><first>Byron</first><last>Wallace</last></editor>
      <editor><first>Izhak</first><last>Shafran</last></editor>
      <editor><first>Chaitanya</first><last>Shivade</last></editor>
      <editor><first>Nan</first><last>Du</last></editor>
      <editor><first>Mona</first><last>Diab</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>July</month>
      <year>2020</year>
      <url hash="915e7714">2020.nlpmc-1</url>
      <venue>nlpmc</venue>
    </meta>
    <frontmatter>
      <url hash="6f84e28c">2020.nlpmc-1.0</url>
      <bibkey>nlpmc-2020-natural</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Methods for Extracting Information from Messages from Primary Care Providers to Specialists</title>
      <author><first>Xiyu</first><last>Ding</last></author>
      <author><first>Michael</first><last>Barnett</last></author>
      <author><first>Ateev</first><last>Mehrotra</last></author>
      <author><first>Timothy</first><last>Miller</last></author>
      <pages>1–6</pages>
      <abstract>Electronic consult (eConsult) systems allow specialists more flexibility to respond to referrals more efficiently, thereby increasing access in under-resourced healthcare settings like safety net systems. Understanding the usage patterns of eConsult system is an important part of improving specialist efficiency. In this work, we develop and apply classifiers to a dataset of eConsult questions from primary care providers to specialists, classifying the messages for how they were triaged by the specialist office, and the underlying type of clinical question posed by the primary care provider. We show that pre-trained transformer models are strong baselines, with improving performance from domain-specific training and shared representations.</abstract>
      <url hash="187aa064">2020.nlpmc-1.1</url>
      <doi>10.18653/v1/2020.nlpmc-1.1</doi>
      <video href="http://slideslive.com/38929890"/>
      <bibkey>ding-etal-2020-methods</bibkey>
    </paper>
    <paper id="2">
      <title>Towards Understanding <fixed-case>ASR</fixed-case> Error Correction for Medical Conversations</title>
      <author><first>Anirudh</first><last>Mani</last></author>
      <author><first>Shruti</first><last>Palaskar</last></author>
      <author><first>Sandeep</first><last>Konam</last></author>
      <pages>7–11</pages>
      <abstract>Domain Adaptation for Automatic Speech Recognition (ASR) error correction via machine translation is a useful technique for improving out-of-domain outputs of pre-trained ASR systems to obtain optimal results for specific in-domain tasks. We use this technique on our dataset of Doctor-Patient conversations using two off-the-shelf ASR systems: Google ASR (commercial) and the ASPIRE model (open-source). We train a Sequence-to-Sequence Machine Translation model and evaluate it on seven specific UMLS Semantic types, including Pharmacological Substance, Sign or Symptom, and Diagnostic Procedure to name a few. Lastly, we breakdown, analyze and discuss the 7% overall improvement in word error rate in view of each Semantic type.</abstract>
      <url hash="276bfafc">2020.nlpmc-1.2</url>
      <doi>10.18653/v1/2020.nlpmc-1.2</doi>
      <video href="http://slideslive.com/38929893"/>
      <bibkey>mani-etal-2020-towards</bibkey>
    </paper>
    <paper id="3">
      <title>Studying Challenges in Medical Conversation with Structured Annotation</title>
      <author><first>Nan</first><last>Wang</last></author>
      <author><first>Yan</first><last>Song</last></author>
      <author><first>Fei</first><last>Xia</last></author>
      <pages>12–21</pages>
      <abstract>Medical conversation is a central part of medical care. Yet, the current state and quality of medical conversation is far from perfect. Therefore, a substantial amount of research has been done to obtain a better understanding of medical conversation and to address its practical challenges and dilemmas. In line with this stream of research, we have developed a multi-layer structure annotation scheme to analyze medical conversation, and are using the scheme to construct a corpus of naturally occurring medical conversation in Chinese pediatric primary care setting. Some of the preliminary findings are reported regarding 1) how a medical conversation starts, 2) where communication problems tend to occur, and 3) how physicians close a conversation. Challenges and opportunities for research on medical conversation with NLP techniques will be discussed.</abstract>
      <url hash="2e89eaa2">2020.nlpmc-1.3</url>
      <doi>10.18653/v1/2020.nlpmc-1.3</doi>
      <video href="http://slideslive.com/38929889"/>
      <bibkey>wang-etal-2020-studying</bibkey>
    </paper>
    <paper id="4">
      <title>Generating Medical Reports from Patient-Doctor Conversations Using Sequence-to-Sequence Models</title>
      <author><first>Seppo</first><last>Enarvi</last></author>
      <author><first>Marilisa</first><last>Amoia</last></author>
      <author><first>Miguel</first><last>Del-Agua Teba</last></author>
      <author><first>Brian</first><last>Delaney</last></author>
      <author><first>Frank</first><last>Diehl</last></author>
      <author><first>Stefan</first><last>Hahn</last></author>
      <author><first>Kristina</first><last>Harris</last></author>
      <author><first>Liam</first><last>McGrath</last></author>
      <author><first>Yue</first><last>Pan</last></author>
      <author><first>Joel</first><last>Pinto</last></author>
      <author><first>Luca</first><last>Rubini</last></author>
      <author><first>Miguel</first><last>Ruiz</last></author>
      <author><first>Gagandeep</first><last>Singh</last></author>
      <author><first>Fabian</first><last>Stemmer</last></author>
      <author><first>Weiyi</first><last>Sun</last></author>
      <author><first>Paul</first><last>Vozila</last></author>
      <author><first>Thomas</first><last>Lin</last></author>
      <author><first>Ranjani</first><last>Ramamurthy</last></author>
      <pages>22–30</pages>
      <abstract>We discuss automatic creation of medical reports from ASR-generated patient-doctor conversational transcripts using an end-to-end neural summarization approach. We explore both recurrent neural network (RNN) and Transformer-based sequence-to-sequence architectures for summarizing medical conversations. We have incorporated enhancements to these architectures, such as the pointer-generator network that facilitates copying parts of the conversations to the reports, and a hierarchical RNN encoder that makes RNN training three times faster with long inputs. A comparison of the relative improvements from the different model architectures over an oracle extractive baseline is provided on a dataset of 800k orthopedic encounters. Consistent with observations in literature for machine translation and related tasks, we find the Transformer models outperform RNN in accuracy, while taking less than half the time to train. Significantly large wins over a strong oracle baseline indicate that sequence-to-sequence modeling is a promising approach for automatic generation of medical reports, in the presence of data at scale.</abstract>
      <url hash="fda1778f">2020.nlpmc-1.4</url>
      <doi>10.18653/v1/2020.nlpmc-1.4</doi>
      <video href="http://slideslive.com/38929888"/>
      <bibkey>enarvi-etal-2020-generating</bibkey>
    </paper>
    <paper id="5">
      <title>Towards an Ontology-based Medication Conversational Agent for <fixed-case>P</fixed-case>r<fixed-case>EP</fixed-case> and <fixed-case>PEP</fixed-case></title>
      <author><first>Muhammad</first><last>Amith</last></author>
      <author><first>Licong</first><last>Cui</last></author>
      <author><first>Kirk</first><last>Roberts</last></author>
      <author><first>Cui</first><last>Tao</last></author>
      <pages>31–40</pages>
      <abstract>ABSTRACT: HIV (human immunodeficiency virus) can damage a human’s immune system and cause Acquired Immunodeficiency Syndrome (AIDS) which could lead to severe outcomes, including death. While HIV infections have decreased over the last decade, there is still a significant population where the infection permeates. PrEP and PEP are two proven preventive measures introduced that involve periodic dosage to stop the onset of HIV infection. However, the adherence rates for this medication is low in part due to the lack of information about the medication. There exist several communication barriers that prevent patient-provider communication from happening. In this work, we present our ontology-based method for automating the communication of this medication that can be deployed for live conversational agents for PrEP and PEP. This method facilitates a model of automated conversation between the machine and user can also answer relevant questions.</abstract>
      <url hash="274e5036">2020.nlpmc-1.5</url>
      <doi>10.18653/v1/2020.nlpmc-1.5</doi>
      <video href="http://slideslive.com/38929887"/>
      <bibkey>amith-etal-2020-towards</bibkey>
    </paper>
    <paper id="6">
      <title>Heart Failure Education of <fixed-case>A</fixed-case>frican <fixed-case>A</fixed-case>merican and <fixed-case>H</fixed-case>ispanic/<fixed-case>L</fixed-case>atino Patients: Data Collection and Analysis</title>
      <author><first>Itika</first><last>Gupta</last></author>
      <author><first>Barbara</first><last>Di Eugenio</last></author>
      <author><first>Devika</first><last>Salunke</last></author>
      <author><first>Andrew</first><last>Boyd</last></author>
      <author><first>Paula</first><last>Allen-Meares</last></author>
      <author><first>Carolyn</first><last>Dickens</last></author>
      <author><first>Olga</first><last>Garcia</last></author>
      <pages>41–46</pages>
      <abstract>Heart failure is a global epidemic with debilitating effects. People with heart failure need to actively participate in home self-care regimens to maintain good health. However, these regimens are not as effective as they could be and are influenced by a variety of factors. Patients from minority communities like African American (AA) and Hispanic/Latino (H/L), often have poor outcomes compared to the average Caucasian population. In this paper, we lay the groundwork to develop an interactive dialogue agent that can assist AA and H/L patients in a culturally sensitive and linguistically accurate manner with their heart health care needs. This will be achieved by extracting relevant educational concepts from the interactions between health educators and patients. Thus far we have recorded and transcribed 20 such interactions. In this paper, we describe our data collection process, thematic and initiative analysis of the interactions, and outline our future steps.</abstract>
      <url hash="0c5ed0ec">2020.nlpmc-1.6</url>
      <doi>10.18653/v1/2020.nlpmc-1.6</doi>
      <video href="http://slideslive.com/38929886"/>
      <bibkey>gupta-etal-2020-heart</bibkey>
    </paper>
    <paper id="7">
      <title>On the Utility of Audiovisual Dialog Technologies and Signal Analytics for Real-time Remote Monitoring of Depression Biomarkers</title>
      <author><first>Michael</first><last>Neumann</last></author>
      <author><first>Oliver</first><last>Roessler</last></author>
      <author><first>David</first><last>Suendermann-Oeft</last></author>
      <author><first>Vikram</first><last>Ramanarayanan</last></author>
      <pages>47–52</pages>
      <abstract>We investigate the utility of audiovisual dialog systems combined with speech and video analytics for real-time remote monitoring of depression at scale in uncontrolled environment settings. We collected audiovisual conversational data from participants who interacted with a cloud-based multimodal dialog system, and automatically extracted a large set of speech and vision metrics based on the rich existing literature of laboratory studies. We report on the efficacy of various audio and video metrics in differentiating people with mild, moderate and severe depression, and discuss the implications of these results for the deployment of such technologies in real-world neurological diagnosis and monitoring applications.</abstract>
      <url hash="6486a7ab">2020.nlpmc-1.7</url>
      <doi>10.18653/v1/2020.nlpmc-1.7</doi>
      <video href="http://slideslive.com/38929892"/>
      <bibkey>neumann-etal-2020-utility</bibkey>
    </paper>
    <paper id="8">
      <title>Robust Prediction of Punctuation and Truecasing for Medical <fixed-case>ASR</fixed-case></title>
      <author><first>Monica</first><last>Sunkara</last></author>
      <author><first>Srikanth</first><last>Ronanki</last></author>
      <author><first>Kalpit</first><last>Dixit</last></author>
      <author><first>Sravan</first><last>Bodapati</last></author>
      <author><first>Katrin</first><last>Kirchhoff</last></author>
      <pages>53–62</pages>
      <abstract>Automatic speech recognition (ASR) systems in the medical domain that focus on transcribing clinical dictations and doctor-patient conversations often pose many challenges due to the complexity of the domain. ASR output typically undergoes automatic punctuation to enable users to speak naturally, without having to vocalize awkward and explicit punctuation commands, such as “period”, “add comma” or “exclamation point”, while truecasing enhances user readability and improves the performance of downstream NLP tasks. This paper proposes a conditional joint modeling framework for prediction of punctuation and truecasing using pretrained masked language models such as BERT, BioBERT and RoBERTa. We also present techniques for domain and task specific adaptation by fine-tuning masked language models with medical domain data. Finally, we improve the robustness of the model against common errors made in ASR by performing data augmentation. Experiments performed on dictation and conversational style corpora show that our proposed model achieves 5% absolute improvement on ground truth text and 10% improvement on ASR outputs over baseline models under F1 metric.</abstract>
      <url hash="6a9feedb">2020.nlpmc-1.8</url>
      <doi>10.18653/v1/2020.nlpmc-1.8</doi>
      <video href="http://slideslive.com/38929891"/>
      <bibkey>sunkara-etal-2020-robust</bibkey>
    </paper>
    <paper id="9">
      <title>Topic-Based Measures of Conversation for Detecting Mild <fixed-case>C</fixed-case>ognitive<fixed-case>I</fixed-case>mpairment</title>
      <author><first>Meysam</first><last>Asgari</last></author>
      <author><first>Liu</first><last>Chen</last></author>
      <author><first>Hiroko</first><last>Dodge</last></author>
      <pages>63–67</pages>
      <abstract>Conversation is a complex cognitive task that engages multiple aspects of cognitive functions to remember the discussed topics, monitor the semantic and linguistic elements, and recognize others’ emotions. In this paper, we propose a computational method based on the lexical coherence of consecutive utterances to quantify topical variations in semi-structured conversations of older adults with cognitive impairments. Extracting the lexical knowledge of conversational utterances, our method generate a set of novel conversational measures that indicate underlying cognitive deficits among subjects with mild cognitive impairment (MCI). Our preliminary results verifies the utility of the proposed conversation-based measures in distinguishing MCI from healthy controls.</abstract>
      <url hash="d7de4173">2020.nlpmc-1.9</url>
      <doi>10.18653/v1/2020.nlpmc-1.9</doi>
      <video href="http://slideslive.com/38929894"/>
      <bibkey>asgari-etal-2020-topic</bibkey>
    </paper>
  </volume>
</collection>
