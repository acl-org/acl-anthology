<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.gitt">
  <volume id="1" ingest-date="2024-09-16" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 2nd International Workshop on Gender-Inclusive Translation Technologies</booktitle>
      <editor><first>Beatrice</first><last>Savoldi</last></editor>
      <editor><first>Janiça</first><last>Hackenbuchner</last></editor>
      <editor><first>Luisa</first><last>Bentivogli</last></editor>
      <editor><first>Joke</first><last>Daems</last></editor>
      <editor><first>Eva</first><last>Vanmassenhove</last></editor>
      <editor><first>Jasmijn</first><last>Bastings</last></editor>
      <publisher>European Association for Machine Translation (EAMT)</publisher>
      <address>Sheffield, United Kingdom</address>
      <month>June</month>
      <year>2024</year>
      <url hash="3b54253c">2024.gitt-1</url>
      <venue>gitt</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="e9a5acc5">2024.gitt-1.0</url>
      <bibkey>gitt-2024-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Gender Bias Evaluation in Machine Translation for <fixed-case>A</fixed-case>mharic, <fixed-case>T</fixed-case>igrigna, and Afaan Oromoo</title>
      <author><first>Walelign</first><last>Sewunetie</last></author>
      <author><first>Atnafu</first><last>Tonja</last><affiliation>Mohamed bin Zayed University of Artificial Intelligence and Instituto Politécnico Nacional</affiliation></author>
      <author><first>Tadesse</first><last>Belay</last></author>
      <author><first>Hellina Hailu</first><last>Nigatu</last><affiliation>Electrical Engineering &amp; Computer Science Department, University of California, Berkeley</affiliation></author>
      <author><first>Gashaw</first><last>Gebremeskel</last></author>
      <author><first>Zewdie</first><last>Mossie</last></author>
      <author><first>Hussien</first><last>Seid</last></author>
      <author><first>Seid</first><last>Yimam</last><affiliation>Universität Hamburg</affiliation></author>
      <pages>1-11</pages>
      <abstract>While Machine Translation (MT) research has progressed over the years, translation systems still suffer from biases, including gender bias. While an active line of research studies the existence and mitigation strategies of gender bias in machine translation systems, there is limited research exploring this phenomenon for low-resource languages. The limited availability of linguistic and computational resources confounded with the lack of benchmark datasets makes studying bias for low-resourced languages that much more difficult. In this paper, we construct benchmark datasets to evaluate gender bias in machine translation for three low-resource languages: Afaan Oromoo (Orm), Amharic (Amh), and Tigrinya (Tir). Building on prior work, we collected 2400 gender-balanced sentences parallelly translated into the three languages. From human evaluations of the dataset we collected, we found that about 93% of Afaan Oromoo, 80% of Tigrinya, and 72% of Amharic sentences exhibited gender bias. In addition to providing benchmarks for improving gender bias mitigation research in the three languages, we hope the careful documentation of our work will help other low-resourced language researchers extend our approach to their languages.</abstract>
      <url hash="2d8e3c12">2024.gitt-1.1</url>
      <bibkey>sewunetie-etal-2024-gender</bibkey>
    </paper>
    <paper id="2">
      <title>Sparks of Fairness: Preliminary Evidence of Commercial Machine Translation as <fixed-case>E</fixed-case>nglish-to-<fixed-case>G</fixed-case>erman Gender-Fair Dictionaries</title>
      <author><first>Manuel</first><last>Lardelli</last></author>
      <author><first>Timm</first><last>Dill</last><affiliation>Universität Hamburg</affiliation></author>
      <author><first>Giuseppe</first><last>Attanasio</last><affiliation>Instituto de Telecomunicações</affiliation></author>
      <author><first>Anne</first><last>Lauscher</last><affiliation>Universität Hamburg</affiliation></author>
      <pages>12-21</pages>
      <abstract>Bilingual dictionaries are bedrock components for several language tasks, including translation. However, dictionaries are traditionally fixed in time, thus excluding those neologisms and neo-morphemes that challenge the language’s nominal morphology. The need for a more dynamic, mutable alternative makes machine translation (MT) systems become an extremely valuable avenue. This paper investigates whether commercial MT can be used as bilingual dictionaries for gender-neutral translation. We focus on the English-to-German pair, where notional gender in the source requires gender inflection in the target. We translated 115 person-referring terms using Google Translate, Microsoft Bing, and DeepL and discovered that while each system is heavily biased towards the masculine gender, DeepL often provides gender-fair alternatives to users, especially with plurals.</abstract>
      <url hash="52f58528">2024.gitt-1.2</url>
      <bibkey>lardelli-etal-2024-sparks</bibkey>
    </paper>
    <paper id="3">
      <title>Gender and bias in <fixed-case>A</fixed-case>mazon review translations: by humans, <fixed-case>MT</fixed-case> systems and <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case></title>
      <author><first>Maja</first><last>Popovic</last><affiliation>IU International University of Applied Sciences and Dublin City University</affiliation></author>
      <author><first>Ekaterina</first><last>Lapshinova-Koltunski</last><affiliation>Universität Hildesheim</affiliation></author>
      <pages>22-30</pages>
      <abstract>This paper presents an analysis of first-person gender in five different translation variants of Amazon product reviews:those produced by professional translators, by translation students, with different machine translation (MT) systems andwith ChatGPT. The analysis revealed that the majority of the reviews were translated into the masculine first-person gender, both by humans as well as by machines. Further inspection revealed that the choice of the gender in a translation is not related to the actual gender of the translator. Finally, the analysis of different products showed that there are certain bias tendencies, because the distribution of genders notably differ for different products.</abstract>
      <url hash="dd46be9f">2024.gitt-1.3</url>
      <bibkey>popovic-lapshinova-koltunski-2024-gender</bibkey>
    </paper>
    <paper id="4">
      <title>You Shall Know a Word’s Gender by the Company it Keeps: Comparing the Role of Context in Human Gender Assumptions with <fixed-case>MT</fixed-case></title>
      <author><first>Janiça</first><last>Hackenbuchner</last></author>
      <author><first>Joke</first><last>Daems</last><affiliation>Universiteit Gent</affiliation></author>
      <author><first>Arda</first><last>Tezcan</last><affiliation>Universiteit Gent</affiliation></author>
      <author><first>Aaron</first><last>Maladry</last></author>
      <pages>31-41</pages>
      <abstract>In this paper, we analyse to what extent machine translation (MT) systems and humans base their gender translations and associations on role names and on stereotypicality in the absence of (generic) grammatical gender cues in language. We compare an MT system’s choice of gender for a certain word when translating from a notional gender language, English, into a grammatical gender language, German, with thegender associations of humans. We outline a comparative case study of gender translation and annotation of words in isolation, out-of-context, and words in sentence contexts. The analysis reveals patterns of gender (bias) by MT and gender associations by humans for certain (1) out-of-context words and (2) words in-context. Our findings reveal the impact of context on gender choice and translation and show that word-level analyses fall short in such studies.</abstract>
      <url hash="4e869747">2024.gitt-1.4</url>
      <bibkey>hackenbuchner-etal-2024-shall</bibkey>
    </paper>
    <paper id="5">
      <title>Lost in Translation? Approaches to Gender Representation in Multilingual Archives</title>
      <author><first>Mrinalini</first><last>Luthra</last><affiliation>Huygens Institute</affiliation></author>
      <author><first>Brecht</first><last>Nijman</last><affiliation>Huygens Institute (KNAW)</affiliation></author>
      <pages>42-55</pages>
      <abstract>The GLOBALISE project’s digitalisation of the Dutch East India Company (VOC) archives raises questions about representing gender and marginalised identities. This paper outlines the challenges of accurately conveying gender information in the archives, highlighting issues such as the lack of self-identified gender descriptions, low representation of marginalised groups, colonial context, and multilingualism in the collection. Machine learning (ML) and machine translation (MT) used in the digitalisation process may amplify existing biases and under-representation. To address these issues, the paper proposes a gender policy for GLOBALISE, offering guidelines and methodologies for handling gender information and increasing the visibility of marginalised identities. The policy contributes to discussions about representing gender and diversity in digital historical research, ML, and MT.</abstract>
      <url hash="e924c77e">2024.gitt-1.5</url>
      <bibkey>luthra-nijman-2024-lost</bibkey>
    </paper>
    <paper id="6">
      <title>Pilot testing gender-inclusive translations and machine translations for <fixed-case>G</fixed-case>erman quadball referee certification test takers</title>
      <author><first>Joke</first><last>Daems</last><affiliation>Universiteit Gent</affiliation></author>
      <pages>56-57</pages>
      <abstract>Gender-inclusive translations are the default at the International Quadball Association, yet translators make different choices for the (timed) referee certification tests to improve readability. However, the actual impact of a strategy on readability and performance has not been tested. This pilot study explores the impact of translation strategy (masculine generic, gender-inclusive, and machine translation) on the speed, performance and perceptions of quadball referee test takers in German. It shows promise for inclusive over masculine strategies, and suggests limited usefulness of MT in this context.</abstract>
      <url hash="a35ab783">2024.gitt-1.6</url>
      <bibkey>daems-2024-pilot</bibkey>
    </paper>
  </volume>
</collection>
