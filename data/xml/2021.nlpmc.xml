<?xml version='1.0' encoding='UTF-8'?>
<collection id="2021.nlpmc">
  <volume id="1" ingest-date="2021-05-24" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Natural Language Processing for Medical Conversations</booktitle>
      <editor><first>Chaitanya</first><last>Shivade</last></editor>
      <editor><first>Rashmi</first><last>Gangadharaiah</last></editor>
      <editor><first>Spandana</first><last>Gella</last></editor>
      <editor><first>Sandeep</first><last>Konam</last></editor>
      <editor><first>Shaoqing</first><last>Yuan</last></editor>
      <editor><first>Yi</first><last>Zhang</last></editor>
      <editor><first>Parminder</first><last>Bhatia</last></editor>
      <editor><first>Byron</first><last>Wallace</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>June</month>
      <year>2021</year>
      <url hash="85c83d62">2021.nlpmc-1</url>
      <venue>nlpmc</venue>
    </meta>
    <frontmatter>
      <url hash="4d53d183">2021.nlpmc-1.0</url>
      <bibkey>nlpmc-2021-natural</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Would you like to tell me more? Generating a corpus of psychotherapy dialogues</title>
      <author><first>Seyed Mahed</first><last>Mousavi</last></author>
      <author><first>Alessandra</first><last>Cervone</last></author>
      <author><first>Morena</first><last>Danieli</last></author>
      <author><first>Giuseppe</first><last>Riccardi</last></author>
      <pages>1–9</pages>
      <abstract>The acquisition of a dialogue corpus is a key step in the process of training a dialogue model. In this context, corpora acquisitions have been designed either for open-domain information retrieval or slot-filling (e.g. restaurant booking) tasks. However, there has been scarce research in the problem of collecting personal conversations with users over a long period of time. In this paper we focus on the types of dialogues that are required for mental health applications. One of these types is the follow-up dialogue that a psychotherapist would initiate in reviewing the progress of a Cognitive Behavioral Therapy (CBT) intervention. The elicitation of the dialogues is achieved through textual stimuli presented to dialogue writers. We propose an automatic algorithm that generates textual stimuli from personal narratives collected during psychotherapy interventions. The automatically generated stimuli are presented as a seed to dialogue writers following principled guidelines. We analyze the linguistic quality of the collected corpus and compare the performances of psychotherapists and non-expert dialogue writers. Moreover, we report the human evaluation of a corpus-based response-selection model.</abstract>
      <url hash="a06b3a15">2021.nlpmc-1.1</url>
      <doi>10.18653/v1/2021.nlpmc-1.1</doi>
      <bibkey>mousavi-etal-2021-like</bibkey>
    </paper>
    <paper id="2">
      <title>Towards Automating Medical Scribing : Clinic Visit <fixed-case>D</fixed-case>ialogue2<fixed-case>N</fixed-case>ote Sentence Alignment and Snippet Summarization</title>
      <author><first>Wen-wai</first><last>Yim</last></author>
      <author><first>Meliha</first><last>Yetisgen</last></author>
      <pages>10–20</pages>
      <abstract>Medical conversations from patient visits are routinely summarized into clinical notes for documentation of clinical care. The automatic creation of clinical note is particularly challenging given that it requires summarization over spoken language and multiple speaker turns; as well, clinical notes include highly technical semi-structured text. In this paper, we describe our corpus creation method and baseline systems for two NLP tasks, clinical dialogue2note sentence alignment and clinical dialogue2note snippet summarization. These two systems, as well as other models created from such a corpus, may be incorporated as parts of an overall end-to-end clinical note generation system.</abstract>
      <url hash="7073d125">2021.nlpmc-1.2</url>
      <doi>10.18653/v1/2021.nlpmc-1.2</doi>
      <bibkey>yim-yetisgen-2021-towards</bibkey>
    </paper>
    <paper id="3">
      <title>Gathering Information and Engaging the User <fixed-case>C</fixed-case>om<fixed-case>B</fixed-case>ot: A Task-Based, Serendipitous Dialog Model for Patient-Doctor Interactions</title>
      <author><first>Anna</first><last>Liednikova</last></author>
      <author><first>Philippe</first><last>Jolivet</last></author>
      <author><first>Alexandre</first><last>Durand-Salmon</last></author>
      <author><first>Claire</first><last>Gardent</last></author>
      <pages>21–29</pages>
      <abstract>We focus on dialog models in the context of clinical studies where the goal is to help gather, in addition to the close information collected based on a questionnaire, serendipitous information that is medically relevant. To promote user engagement and address this dual goal (collecting both a predefined set of data points and more informal information about the state of the patients), we introduce an ensemble model made of three bots: a task-based, a follow-up and a social bot. We introduce a generic method for developing follow-up bots. We compare different ensemble configurations and we show that the combination of the three bots (i) provides a better basis for collecting information than just the information seeking bot and (ii) collects information in a more user-friendly, more efficient manner that an ensemble model combining the information seeking and the social bot.</abstract>
      <url hash="692ca7e3">2021.nlpmc-1.3</url>
      <doi>10.18653/v1/2021.nlpmc-1.3</doi>
      <bibkey>liednikova-etal-2021-gathering</bibkey>
      <video href="2021.nlpmc-1.3.mp4"/>
    </paper>
    <paper id="4">
      <title>Automatic Speech-Based Checklist for Medical Simulations</title>
      <author><first>Sapir</first><last>Gershov</last></author>
      <author><first>Yaniv</first><last>Ringel</last></author>
      <author><first>Erez</first><last>Dvir</last></author>
      <author><first>Tzvia</first><last>Tsirilman</last></author>
      <author><first>Elad</first><last>Ben Zvi</last></author>
      <author><first>Sandra</first><last>Braun</last></author>
      <author><first>Aeyal</first><last>Raz</last></author>
      <author><first>Shlomi</first><last>Laufer</last></author>
      <pages>30–34</pages>
      <abstract>Medical simulators provide a controlled environment for training and assessing clinical skills. However, as an assessment platform, it requires the presence of an experienced examiner to provide performance feedback, commonly preformed using a task specific checklist. This makes the assessment process inefficient and expensive. Furthermore, this evaluation method does not provide medical practitioners the opportunity for independent training. Ideally, the process of filling the checklist should be done by a fully-aware objective system, capable of recognizing and monitoring the clinical performance. To this end, we have developed an autonomous and a fully automatic speech-based checklist system, capable of objectively identifying and validating anesthesia residents’ actions in a simulation environment. Based on the analyzed results, our system is capable of recognizing most of the tasks in the checklist: F1 score of 0.77 for all of the tasks, and F1 score of 0.79 for the verbal tasks. Developing an audio-based system will improve the experience of a wide range of simulation platforms. Furthermore, in the future, this approach may be implemented in the operation room and emergency room. This could facilitate the development of automatic assistive technologies for these domains.</abstract>
      <url hash="6cc95d32">2021.nlpmc-1.4</url>
      <doi>10.18653/v1/2021.nlpmc-1.4</doi>
      <bibkey>gershov-etal-2021-automatic</bibkey>
    </paper>
    <paper id="5">
      <title>Assertion Detection in Clinical Notes: Medical Language Models to the Rescue?</title>
      <author><first>Betty</first><last>van Aken</last></author>
      <author><first>Ivana</first><last>Trajanovska</last></author>
      <author><first>Amy</first><last>Siu</last></author>
      <author><first>Manuel</first><last>Mayrdorfer</last></author>
      <author><first>Klemens</first><last>Budde</last></author>
      <author><first>Alexander</first><last>Loeser</last></author>
      <pages>35–40</pages>
      <abstract>In order to provide high-quality care, health professionals must efficiently identify the presence, possibility, or absence of symptoms, treatments and other relevant entities in free-text clinical notes. Such is the task of assertion detection - to identify the assertion class (present, possible, absent) of an entity based on textual cues in unstructured text. We evaluate state-of-the-art medical language models on the task and show that they outperform the baselines in all three classes. As transferability is especially important in the medical domain we further study how the best performing model behaves on unseen data from two other medical datasets. For this purpose we introduce a newly annotated set of 5,000 assertions for the publicly available MIMIC-III dataset. We conclude with an error analysis that reveals situations in which the models still go wrong and points towards future research directions.</abstract>
      <url hash="28737d50">2021.nlpmc-1.5</url>
      <doi>10.18653/v1/2021.nlpmc-1.5</doi>
      <bibkey>van-aken-etal-2021-assertion</bibkey>
      <video href="2021.nlpmc-1.5.mp4"/>
      <pwccode url="https://github.com/bvanaken/clinical-assertion-data" additional="false">bvanaken/clinical-assertion-data</pwccode>
    </paper>
    <paper id="6">
      <title>Extracting Appointment Spans from Medical Conversations</title>
      <author><first>Nimshi Venkat</first><last>Meripo</last></author>
      <author><first>Sandeep</first><last>Konam</last></author>
      <pages>41–46</pages>
      <abstract>Extracting structured information from medical conversations can reduce the documentation burden for doctors and help patients follow through with their care plan. In this paper, we introduce a novel task of extracting appointment spans from medical conversations. We frame this task as a sequence tagging problem and focus on extracting spans for appointment reason and time. However, annotating medical conversations is expensive, time-consuming, and requires considerable domain expertise. Hence, we propose to leverage weak supervision approaches, namely incomplete supervision, inaccurate supervision, and a hybrid supervision approach and evaluate both generic and domain-specific, ELMo, and BERT embeddings using sequence tagging models. The best performing model is the domain-specific BERT variant using weak hybrid supervision and obtains an F1 score of 79.32.</abstract>
      <url hash="5fb37af3">2021.nlpmc-1.6</url>
      <doi>10.18653/v1/2021.nlpmc-1.6</doi>
      <bibkey>meripo-konam-2021-extracting</bibkey>
    </paper>
    <paper id="7">
      <title>Building blocks of a task-oriented dialogue system in the healthcare domain</title>
      <author><first>Heereen</first><last>Shim</last></author>
      <author><first>Dietwig</first><last>Lowet</last></author>
      <author><first>Stijn</first><last>Luca</last></author>
      <author><first>Bart</first><last>Vanrumste</last></author>
      <pages>47–57</pages>
      <abstract>There has been significant progress in dialogue systems research. However, dialogue systems research in the healthcare domain is still in its infancy. In this paper, we analyse recent studies and outline three building blocks of a task-oriented dialogue system in the healthcare domain: i) privacy-preserving data collection; ii) medical knowledge-grounded dialogue management; and iii) human-centric evaluations. To this end, we propose a framework for developing a dialogue system and show preliminary results of simulated dialogue data generation by utilising expert knowledge and crowd-sourcing.</abstract>
      <url hash="4e387204">2021.nlpmc-1.7</url>
      <doi>10.18653/v1/2021.nlpmc-1.7</doi>
      <bibkey>shim-etal-2021-building</bibkey>
    </paper>
    <paper id="8">
      <title>Joint Summarization-Entailment Optimization for Consumer Health Question Understanding</title>
      <author><first>Khalil</first><last>Mrini</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Walter</first><last>Chang</last></author>
      <author><first>Emilia</first><last>Farcas</last></author>
      <author><first>Ndapa</first><last>Nakashole</last></author>
      <pages>58–65</pages>
      <abstract>Understanding the intent of medical questions asked by patients, or Consumer Health Questions, is an essential skill for medical Conversational AI systems. We propose a novel data-augmented and simple joint learning approach combining question summarization and Recognizing Question Entailment (RQE) in the medical domain. Our data augmentation approach enables to use just one dataset for joint learning. We show improvements on both tasks across four biomedical datasets in accuracy (+8%), ROUGE-1 (+2.5%) and human evaluation scores. Human evaluation shows joint learning generates faithful and informative summaries. Finally, we release our code, the two question summarization datasets extracted from a large-scale medical dialogue dataset, as well as our augmented datasets.</abstract>
      <url hash="e652a3a3">2021.nlpmc-1.8</url>
      <doi>10.18653/v1/2021.nlpmc-1.8</doi>
      <bibkey>mrini-etal-2021-joint</bibkey>
      <pwccode url="https://github.com/khalilmrini/medical-question-understanding" additional="false">khalilmrini/medical-question-understanding</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/meqsum">MeQSum</pwcdataset>
    </paper>
    <paper id="9">
      <title>Medically Aware <fixed-case>GPT</fixed-case>-3 as a Data Generator for Medical Dialogue Summarization</title>
      <author><first>Bharath</first><last>Chintagunta</last></author>
      <author><first>Namit</first><last>Katariya</last></author>
      <author><first>Xavier</first><last>Amatriain</last></author>
      <author><first>Anitha</first><last>Kannan</last></author>
      <pages>66–76</pages>
      <abstract>In medical dialogue summarization, summaries must be coherent and must capture all the medically relevant information in the dialogue. However, learning effective models for summarization require large amounts of labeled data which is especially hard to obtain. We present an algorithm to create synthetic training data with an explicit focus on capturing medically relevant information. We utilize GPT-3 as the backbone of our algorithm and scale 210 human labeled examples to yield results comparable to using 6400 human labeled examples (~30x) leveraging low-shot learning and an ensemble method. In detailed experiments, we show that this approach produces high quality training data that can further be combined with human labeled data to get summaries that are strongly preferable to those produced by models trained on human data alone both in terms of medical accuracy and coherency.</abstract>
      <url hash="63e1e106">2021.nlpmc-1.9</url>
      <doi>10.18653/v1/2021.nlpmc-1.9</doi>
      <bibkey>chintagunta-etal-2021-medically</bibkey>
      <video href="2021.nlpmc-1.9.mp4"/>
      <pwcdataset url="https://paperswithcode.com/dataset/cnn-daily-mail-1">CNN/Daily Mail</pwcdataset>
    </paper>
  </volume>
</collection>
