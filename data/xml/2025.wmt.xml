<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.wmt">
  <volume id="1" ingest-date="2025-10-29" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Tenth Conference on Machine Translation</booktitle>
      <editor><first>Barry</first><last>Haddow</last></editor>
      <editor><first>Tom</first><last>Kocmi</last></editor>
      <editor><first>Philipp</first><last>Koehn</last></editor>
      <editor><first>Christof</first><last>Monz</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Suzhou, China</address>
      <month>November</month>
      <year>2025</year>
      <url hash="9a2b3554">2025.wmt-1</url>
      <venue>wmt</venue>
      <isbn>979-8-89176-341-8</isbn>
      <doi>10.18653/v1/2025.wmt-1</doi>
    </meta>
    <frontmatter>
      <url hash="06c771b5">2025.wmt-1.0</url>
      <bibkey>wmt-2025-1</bibkey>
      <doi>10.18653/v1/2025.wmt-1.0</doi>
    </frontmatter>
    <paper id="1">
      <title>An Empirical Analysis of Machine Translation for Expanding Multilingual Benchmarks</title>
      <author><first>Sara</first><last>Rajaee</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Rochelle</first><last>Choenni</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Ekaterina</first><last>Shutova</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Christof</first><last>Monz</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>1-30</pages>
      <abstract>The rapid advancement of large language models (LLMs) has introduced new challenges in their evaluation, particularly for multilingual settings. The limited evaluation data are more pronounced in low-resource languages due to the scarcity of professional annotators, hindering fair progress across languages. In this work, we systematically investigate the viability of using machine translation (MT) as a proxy for evaluation in scenarios where human-annotated test sets are unavailable. Leveraging a state-of-the-art translation model, we translate datasets from four tasks into 198 languages and employ these translations to assess the quality and robustness of MT-based multilingual evaluation under different setups. We analyze task-specific error patterns, identifying when MT-based evaluation is reliable and when it produces misleading results. Our translated benchmark reveals that current language selections in multilingual datasets tend to overestimate LLM performance on low-resource languages. We conclude that although machine translation is not yet a fully reliable method for evaluating multilingual models, overlooking its potential means missing a valuable opportunity to track progress in non-English languages.</abstract>
      <url hash="336d4004">2025.wmt-1.1</url>
      <bibkey>rajaee-etal-2025-empirical</bibkey>
      <doi>10.18653/v1/2025.wmt-1.1</doi>
    </paper>
    <paper id="2">
      <title>Cross-lingual Human-Preference Alignment for Neural Machine Translation with Direct Quality Optimization</title>
      <author><first>Kaden</first><last>Uhlig</last><affiliation>LILT</affiliation></author>
      <author><first>Joern</first><last>Wuebker</last><affiliation>Lilt, Inc.</affiliation></author>
      <author><first>Raphael</first><last>Reinauer</last><affiliation>Lilt</affiliation></author>
      <author><first>John</first><last>Denero</last><affiliation>UC Berkeley</affiliation></author>
      <pages>31-51</pages>
      <abstract>Reinforcement Learning from Human Feedback (RLHF) and derivative techniques like Direct Preference Optimization (DPO) are task-alignment algorithms used to repurpose general, foundational models for specific tasks. We show that applying task-alignment to neural machine translation (NMT) addresses an existing task–data mismatch in NMT, leading to improvements across all languages of a multilingual model, even when task-alignment is only applied to a subset of those languages. We do so by introducing Direct Quality Optimization (DQO), a variant of DPO leveraging a pre-trained translation quality estimation model as a proxy for human preferences, and verify the improvements with both automatic metrics and through human evaluation.</abstract>
      <url hash="431f451c">2025.wmt-1.2</url>
      <bibkey>uhlig-etal-2025-cross</bibkey>
      <doi>10.18653/v1/2025.wmt-1.2</doi>
    </paper>
    <paper id="3">
      <title>Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality</title>
      <author><first>Sami</first><last>Haq</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Sheila</first><last>Castilho</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Yvette</first><last>Graham</last><affiliation>ADAPT, Trinity College Dublin</affiliation></author>
      <pages>52-63</pages>
      <abstract>Machine Translation (MT) has achieved remarkable performance, with growing interest in speech translation and multimodal approaches. However, despite these advancements, MT quality assessment remains largely text-centric, typically relying on human experts who read and compare texts. Since many real-world MT applications (e.g., Google Translate Voice Mode, iFLYTEK Translator) involve translation being spoken rather printed or read, a more natural way to assess translation quality would be through speech as opposed text-only evaluations. This study compares text-only and audio-based evaluations of 10 MT systems from the WMT General MT Shared Task, using crowd-sourced judgments collected via Amazon Mechanical Turk. We additionally, performed statistical significance testing and self-replication experiments to test reliability and consistency of audio-based approach. Crowd-sourced assessments based on audio yield rankings largely consistent with text-only evaluations but, in some cases, identify significant differences between translation systems. We attribute this to speech’s richer, more natural modality and propose incorporating speech-based assessments into future MT evaluation frameworks.</abstract>
      <url hash="eb9af8ef">2025.wmt-1.3</url>
      <bibkey>haq-etal-2025-audio</bibkey>
      <doi>10.18653/v1/2025.wmt-1.3</doi>
    </paper>
    <paper id="4">
      <title>Meaningful Pose-Based Sign Language Evaluation</title>
      <author><first>Zifan</first><last>Jiang</last><affiliation>University of Zurich</affiliation></author>
      <author><first>Colin</first><last>Leong</last><affiliation>University of Dayton</affiliation></author>
      <author><first>Amit</first><last>Moryossef</last><affiliation>Bar-Ilan university, University of Zurich</affiliation></author>
      <author><first>Oliver</first><last>Cory</last><affiliation>University of Surrey</affiliation></author>
      <author><first>Maksym</first><last>Ivashechkin</last><affiliation>University of Surrey</affiliation></author>
      <author><first>Neha</first><last>Tarigopula</last><affiliation>Idiap Research Institute</affiliation></author>
      <author><first>Biao</first><last>Zhang</last><affiliation>Google</affiliation></author>
      <author id="anne-gohring"><first>Anne</first><last>Göhring</last><affiliation>University of Zurich</affiliation></author>
      <author id="annette-rios-gonzales"><first>Annette</first><last>Rios</last><affiliation>University of Zurich</affiliation></author>
      <author><first>Rico</first><last>Sennrich</last><affiliation>University of Zurich</affiliation></author>
      <author><first>Sarah</first><last>Ebling</last><affiliation>University of Zurich</affiliation></author>
      <pages>64-80</pages>
      <abstract>We present a comprehensive study on meaningfully evaluating sign language utterances in the form of human skeletal poses. The study covers keypoint distance-based, embedding-based, and back-translation-based metrics. We show tradeoffs between different metrics in different scenarios through (1) automatic meta-evaluation of sign-level retrieval, and (2) a human correlation study of text-to-pose translation across different sign languages. Our findings, along with the open-source pose-evaluation toolkit, provide a practical and reproducible approach for developing and evaluating sign language translation or generation systems.</abstract>
      <url hash="fca7a84b">2025.wmt-1.4</url>
      <bibkey>jiang-etal-2025-meaningful</bibkey>
      <doi>10.18653/v1/2025.wmt-1.4</doi>
    </paper>
    <paper id="5">
      <title>Context Is Ubiquitous, but Rarely Changes Judgments: Revisiting Document-Level <fixed-case>MT</fixed-case> Evaluation</title>
      <author><first>Ahrii</first><last>Kim</last><affiliation>None</affiliation></author>
      <pages>81-97</pages>
      <abstract>As sentence-level performance in modern Machine Translation (MT) has plateaued, reliable document-level evaluation is increasingly needed. While the recent FALCON framework with pragmatic features offers a promising direction, its reliability and reproducibility are unclear. We address this gap through human evaluation, analyzing sources of low inter-annotator agreement and identifying key factors. Based on these findings, we introduce H-FALCON, a Human-centered refinement of FALCON. Our experiments show that, even with limited annotator consensus, FALCON achieves correlations comparable to or better than standard sentence-level protocols.Furthermore, we find that contextual information is inherent in all sentences, challenging the view that only some require it. This suggests that prior estimates such as “n% of sentences require context” may stem from methodological artifacts. At the same time, we show that while context is pervasive, not all of it directly influences human judgment.</abstract>
      <url hash="afff6aab">2025.wmt-1.5</url>
      <bibkey>kim-2025-context</bibkey>
      <doi>10.18653/v1/2025.wmt-1.5</doi>
    </paper>
    <paper id="6">
      <title><fixed-case>GIIFT</fixed-case>: Graph-guided Inductive Image-free Multimodal Machine Translation</title>
      <author><first>Jiafeng</first><last>Xiong</last><affiliation>University of Manchester</affiliation></author>
      <author><first>Yuting</first><last>Zhao</last><affiliation>Kyushu University</affiliation></author>
      <pages>98-112</pages>
      <abstract>Multimodal Machine Translation (MMT) has demonstrated the significant help of visual information in machine translation. However, existing MMT methods face challenges in leveraging the modality gap by enforcing rigid visual-linguistic alignment whilst being confined to inference within their trained multimodal domains. In this work, we construct novel multimodal scene graphs to preserve and integrate modality-specific information and introduce GIIFT, a two-stage Graph-guided Inductive Image-Free MMT framework that uses a cross-modal Graph Attention Network adapter to learn multimodal knowledge in a unified fused space and inductively generalize it to broader image-free translation domains. Experimental results on the Multi30K dataset of English-to-French and English-to-German tasks demonstrate that our GIIFT surpasses existing approaches and achieves the state-of-the-art, even without images during inference. Results on the WMT benchmark show significant improvements over the image-free translation baselines, demonstrating the strength of GIIFT towards inductive image-free inference.</abstract>
      <url hash="40224d81">2025.wmt-1.6</url>
      <bibkey>xiong-zhao-2025-giift</bibkey>
      <doi>10.18653/v1/2025.wmt-1.6</doi>
    </paper>
    <paper id="7">
      <title>Specification-Aware Machine Translation and Evaluation for Purpose Alignment</title>
      <author><first>Yoko</first><last>Kayano</last><affiliation>The Graduate University for Advanced Studies</affiliation></author>
      <author><first>Saku</first><last>Sugawara</last><affiliation>National Institute of Informatics</affiliation></author>
      <pages>113-141</pages>
      <abstract>In professional settings, translation is guided by communicative goals and client needs, often formalized as specifications.While existing evaluation frameworks acknowledge the importance of such specifications, these specifications are often treated only implicitly in machine translation (MT) research.Drawing on translation studies, we provide a theoretical rationale for why specifications matter in professional translation, as well as a practical guide to implementing specification-aware MT and evaluation.Building on this foundation, we apply our framework to the translation of investor relations texts from 33 publicly listed companies.In our experiment, we compare five translation types, including official human translations and prompt-based outputs from large language models (LLMs), using expert error analysis, user preference rankings, and an automatic metric. The results show that LLM translations guided by specifications consistently outperformed official human translations in human evaluations, highlighting a gap between perceived and expected quality.These findings demonstrate that integrating specifications into MT workflows, with human oversight, can improve translation quality in ways aligned with professional practice.</abstract>
      <url hash="b4f7d37c">2025.wmt-1.7</url>
      <bibkey>kayano-sugawara-2025-specification</bibkey>
      <doi>10.18653/v1/2025.wmt-1.7</doi>
    </paper>
    <paper id="8">
      <title><fixed-case>O</fixed-case>pen<fixed-case>WHO</fixed-case>: A Document-Level Parallel Corpus for Health Translation in Low-Resource Languages</title>
      <author><first>Raphael</first><last>Merx</last><affiliation>University of Melbourne</affiliation></author>
      <author><first>Hanna</first><last>Suominen</last><affiliation>The Australian National University and University of Turku</affiliation></author>
      <author id="trevor-cohn"><first>Trevor</first><last>Cohn</last><affiliation>University of Melbourne</affiliation></author>
      <author><first>Ekaterina</first><last>Vylomova</last><affiliation>University of Melbourne</affiliation></author>
      <pages>142-160</pages>
      <abstract>Health machine translation (MT) is a high-stakes domain characterised by widespread deployment and domain-specific vocabulary. However, there is a lack of MT evaluation datasets for low-resource languages in the health domain. To address this gap, we introduce OpenWHO, a document-level parallel corpus of 2,978 documents and 26,824 sentences from the World Health Organization’s e-learning platform. Sourced from expert-authored, professionally translated materials shielded from web-crawling, OpenWHO spans a diverse range of over 20 languages, of which nine are low-resource. Leveraging this new resource, we evaluate modern large language models (LLMs) against traditional MT models. Our findings reveal that LLMs consistently outperform traditional MT models, with Gemini 2.5 Flash achieving a +4.79 ChrF point improvement over NLLB-54B on our low-resource test set. Further, we investigate how LLM context utilisation affects accuracy, finding that the benefits of document-level translation are most pronounced in specialised domains like health. We release the OpenWHO corpus to encourage further research into low-resource MT in the health domain.</abstract>
      <url hash="9e5c6810">2025.wmt-1.8</url>
      <bibkey>merx-etal-2025-openwho</bibkey>
      <doi>10.18653/v1/2025.wmt-1.8</doi>
    </paper>
    <paper id="9">
      <title>Factors Affecting Translation Quality in In-context Learning for Multilingual Medical Domain</title>
      <author><first>Jonathan</first><last>Mutal</last><affiliation>Unige</affiliation></author>
      <author id="raphael-rubino"><first>Raphael</first><last>Rubino</last><affiliation>UNIGE</affiliation></author>
      <author id="pierrette-bouillon"><first>Pierrette</first><last>Bouillon</last><affiliation>UNIGE FTI</affiliation></author>
      <pages>161-179</pages>
      <abstract>Multilingual machine translation in the medical domain presents critical challenges due to limited parallel data, domain-specific terminology, and the high stakes associated with translation accuracy. In this paper, we explore the potential of in-context learning (ICL) with general-purpose large language models (LLMs) as an alternative to fine-tuning. Focusing on the medical domain and low-resource languages, we evaluate an instruction-tuned LLM on a translation task across 16 languages. We address four research questions centered on prompt design, examining the impact of the number of examples, the domain and register of examples, and the example selection strategy. Our results show that prompting with one to three examples from the same register and domain as the test input leads to the largest improvements in translation quality, as measured by automatic metrics, while translation quality gains plateau with an increased number of examples. Furthermore, we find that example selection methods - lexical and embedding based - do not yield significant benefits over random selection if the register of selected examples does not match that of the test input.</abstract>
      <url hash="792754ba">2025.wmt-1.9</url>
      <bibkey>mutal-etal-2025-factors</bibkey>
      <doi>10.18653/v1/2025.wmt-1.9</doi>
    </paper>
    <paper id="10">
      <title>Character-Aware <fixed-case>E</fixed-case>nglish-to-<fixed-case>J</fixed-case>apanese Translation of Fictional Dialogue Using Speaker Embeddings and Back-Translation</title>
      <author><first>Ayuna</first><last>Nagato</last><affiliation>Tokyo University of Science</affiliation></author>
      <author><first>Takuya</first><last>Matsuzaki</last><affiliation>Tokyo University of Science</affiliation></author>
      <pages>180-190</pages>
      <abstract>In Japanese, the form of utterances often reflect speaker-specific character traits, such as gender and personality, through the choise of linguistic elements including personal pronouns and sentence-final particles. However, such elements are not always available in English and a character’s traits are often not directly expressed in English utterances, which can lead to character-inconsistent translations of English novels into Japanese. To address this, we propose a character-aware translation framework that incorporates speaker embeddings. We first train a speaker embedding model by masking the expressions in Japanese utterances that manifest the speaker’s traits and learning to predict them. The resulting embeddings are then injected into a machine translation model. Experimental results show that our proposed method outperforms conventional fine-tuning in preserving speaker-specific character traits in translations.</abstract>
      <url hash="f16d8828">2025.wmt-1.10</url>
      <bibkey>nagato-matsuzaki-2025-character</bibkey>
      <doi>10.18653/v1/2025.wmt-1.10</doi>
    </paper>
    <paper id="11">
      <title><fixed-case>DTW</fixed-case>-Align: Bridging the Modality Gap in End-to-End Speech Translation with Dynamic Time Warping Alignment</title>
      <author><first>Abderrahmane</first><last>Issam</last><affiliation>University of Maastricht</affiliation></author>
      <author><first>Yusuf Can</first><last>Semerci</last><affiliation>Maastricht University</affiliation></author>
      <author><first>Jan</first><last>Scholtes</last><affiliation>Professor at Maastricht University</affiliation></author>
      <author><first>Gerasimos</first><last>Spanakis</last><affiliation>Maastricht University</affiliation></author>
      <pages>191-199</pages>
      <abstract>End-to-End Speech Translation (E2E-ST) is the task of translating source speech directly into target text bypassing the intermediate transcription step. The representation discrepancy between the speech and text modalities has motivated research on what is known as bridging the modality gap. State-of-the-art methods addressed this by aligning speech and text representations on the word or token level. Unfortunately, this requires an alignment tool that is not available for all languages. Although this issue has been addressed by aligning speech and text embeddings using nearest-neighbor similarity search, it does not lead to accurate alignments. In this work, we adapt Dynamic Time Warping (DTW) for aligning speech and text embeddings during training. Our experiments demonstrate the effectiveness of our method in bridging the modality gap in E2E-ST. Compared to previous work, our method produces more accurate alignments and achieves comparable E2E-ST results while being significantly faster. Furthermore, our method outperforms previous work in low resource settings on 5 out of 6 language directions.</abstract>
      <url hash="5c9b947b">2025.wmt-1.11</url>
      <bibkey>issam-etal-2025-dtw</bibkey>
      <doi>10.18653/v1/2025.wmt-1.11</doi>
    </paper>
    <paper id="12">
      <title>Targeted Source Text Editing for Machine Translation: Exploiting Quality Estimators and Large Language Models</title>
      <author><first>Hyuga</first><last>Koretaka</last><affiliation>EhimeUniversity</affiliation></author>
      <author><first>Atsushi</first><last>Fujita</last><affiliation>National Institute of Information and Communications Technology</affiliation></author>
      <author><first>Tomoyuki</first><last>Kajiwara</last><affiliation>Ehime University / The University of Osaka</affiliation></author>
      <pages>200-219</pages>
      <abstract>To improve the translation quality of “black-box” machine translation (MT) systems,we focus on the automatic editing of source texts to be translated.In addition to the use of a large language model (LLM) to implement robust and accurate editing,we investigate the usefulness of targeted editing, i.e., instructing the LLM with a text span to be edited.Our method determines such source text spans using a span-level quality estimator, which identifies actual translation errors caused by the MT system of interest, and a word aligner, which identifies alignments between the tokens in the source text and translation hypothesis.Our empirical experiments with eight MT systems and ten test datasets for four translation directionsconfirmed the efficacy of our method in improving translation quality.Through analyses, we identified several characteristics of our method andthat the segment-level quality estimator is a vital component of our method.</abstract>
      <url hash="15cb0bc1">2025.wmt-1.12</url>
      <bibkey>koretaka-etal-2025-targeted</bibkey>
      <doi>10.18653/v1/2025.wmt-1.12</doi>
    </paper>
    <paper id="13">
      <title>Self-Retrieval from Distant Contexts for Document-Level Machine Translation</title>
      <author><first>Ziqian</first><last>Peng</last><affiliation>Sorbonne Université, CNRS/ISIR, Inria</affiliation></author>
      <author><first>Rachel</first><last>Bawden</last><affiliation>Inria</affiliation></author>
      <author><first>François</first><last>Yvon</last><affiliation>ISIR CNRS &amp; Sorbonne Université</affiliation></author>
      <pages>220-240</pages>
      <abstract>Document-level machine translation is a challenging task, as it requires modeling both short-range and long-range dependencies to maintain the coherence and cohesion of the generated translation. However, these dependencies are sparse, and most context-augmented translation systems resort to two equally unsatisfactory options: either to include maximally long contexts, hoping that the useful dependencies are not lost in the noise; or to use limited local contexts, at the risk of missing relevant information. In this work, we study a self-retrieval-augmented machine translation framework (Self-RAMT), aimed at informing translation decisions with informative local and global contexts dynamically extracted from the source and target texts. We examine the effectiveness of this method using three large language models, considering three criteria for context selection. We carry out experiments on TED talks as well as parallel scientific articles, considering three translation directions. Our results show that integrating distant contexts with Self-RAMT improves translation quality as measured by reference-based scores and consistency metrics.</abstract>
      <url hash="8cb4c032">2025.wmt-1.13</url>
      <bibkey>peng-etal-2025-self</bibkey>
      <doi>10.18653/v1/2025.wmt-1.13</doi>
    </paper>
    <paper id="14">
      <title>Using Encipherment to Isolate Conditions for the Successful Fine-tuning of Massively Multilingual Translation Models</title>
      <author><first>Carter</first><last>Louchheim</last><affiliation>Williams College</affiliation></author>
      <author><first>Denis</first><last>Sotnichenko</last><affiliation>Williams College</affiliation></author>
      <author><first>Yukina</first><last>Yamaguchi</last><affiliation>Williams College</affiliation></author>
      <author><first>Mark</first><last>Hopkins</last><affiliation>Williams College</affiliation></author>
      <pages>241-252</pages>
      <abstract>When fine-tuning massively multilingual translation models for low-resource languages, practitioners often include auxiliary languages to improve performance, but factors determining successful auxiliary language selection remain unclear. This paper investigates whether syntactic similarity or lexical overlap is more important for effective multilingual fine-tuning. We use encipherment to create controlled experimental conditions that disentangle these confounded factors, generating novel languages with identical syntax but no lexical overlap, and conversely, languages that preserve lexical overlap. Through extensive NLLB-200 fine-tuning experiments across Europarl and AmericasNLP datasets, we demonstrate that lexical overlap is the dominant factor. Syntactically identical auxiliary languages provide negligible benefits ( 1.0 ChrF), while languages with significant lexical overlap provide substantial improvements ( 5.0 ChrF), with effectiveness strongly correlated to KL-divergence between token distributions (r = -0.47, p .001). Our findings provide clear guidance: when selecting auxiliary languages for multilingual fine-tuning, prioritize lexical overlap over syntactic similarity.</abstract>
      <url hash="10a08237">2025.wmt-1.14</url>
      <bibkey>louchheim-etal-2025-using</bibkey>
      <doi>10.18653/v1/2025.wmt-1.14</doi>
    </paper>
    <paper id="15">
      <title>Translate, Then Detect: Leveraging Machine Translation for Cross-Lingual Toxicity Classification</title>
      <author><first>Samuel</first><last>Bell</last><affiliation>Meta</affiliation></author>
      <author><first>Eduardo</first><last>Sánchez</last><affiliation>Meta/UCL</affiliation></author>
      <author><first>David</first><last>Dale</last><affiliation>Meta AI</affiliation></author>
      <author><first>Pontus</first><last>Stenetorp</last><affiliation>University College London</affiliation></author>
      <author><first>Mikel</first><last>Artetxe</last><affiliation>Reka AI</affiliation></author>
      <author id="marta-r-costa-jussa"><first>Marta R.</first><last>Costa-Jussà</last><affiliation>Meta AI</affiliation></author>
      <pages>253-268</pages>
      <abstract>Multilingual toxicity detection remains a significant challenge due to the scarcity of training data and resources for many languages. While prior work has leveraged the translate-test paradigm to support cross-lingual transfer across a range of classification tasks, the utility of translation in supporting toxicity detection at scale remains unclear.In this work, we conduct a comprehensive comparison of translation-based and language-specific/multilingual classification pipelines.We find that translation-based pipelines consistently outperform out-of-distribution classifiers in 81.3% of cases (13 of 16 languages), with translation benefits strongly correlated with both the resource level of the target language and the quality of the machine translation (MT) system.Our analysis reveals that traditional classifiers continue to outperform LLM-based judgment methods, with this advantage being particularly pronounced for low-resource languages, where translate-classify methods dominate translate-judge approaches in 6 out of 7 cases.We show that MT-specific fine-tuning on LLMs yields lower refusal rates compared to standard instruction-tuned models, but it can negatively impact toxicity detection accuracy for low-resource languages.These findings offer actionable guidance for practitioners developing scalable multilingual content moderation systems.</abstract>
      <url hash="39903f83">2025.wmt-1.15</url>
      <bibkey>bell-etal-2025-translate</bibkey>
      <doi>10.18653/v1/2025.wmt-1.15</doi>
    </paper>
    <paper id="16">
      <title>Feeding Two Birds or Favoring One? Adequacy–Fluency Tradeoffs in Evaluation and Meta-Evaluation of Machine Translation</title>
      <author><first>Behzad</first><last>Shayegh</last><affiliation>University of Alberta</affiliation></author>
      <author><first>Jan-Thorsten</first><last>Peter</last><affiliation>Google</affiliation></author>
      <author><first>David</first><last>Vilar</last><affiliation>Google</affiliation></author>
      <author><first>Tobias</first><last>Domhan</last><affiliation>Google</affiliation></author>
      <author><first>Juraj</first><last>Juraska</last><affiliation>Google</affiliation></author>
      <author><first>Markus</first><last>Freitag</last><affiliation>Google Research</affiliation></author>
      <author><first>Lili</first><last>Mou</last><affiliation>University of Alberta</affiliation></author>
      <pages>269-285</pages>
      <abstract>We investigate the tradeoff between adequacy and fluency in machine translation. We show the severity of this tradeoff at the evaluation level and analyze where popular metrics fall within it. Essentially, current metrics generally lean toward adequacy, meaning that their scores correlate more strongly with the adequacy of translations than with fluency. More importantly, we find that this tradeoff also persists at the meta-evaluation level, and that the standard WMT meta-evaluation favors adequacy-oriented metrics over fluency-oriented ones. We show that this bias is partially attributed to the composition of the systems included in the meta-evaluation datasets. To control this bias, we propose a method that synthesizes translation systems in meta-evaluation. Our findings highlight the importance of understanding this tradeoff in meta-evaluation and its impact on metric rankings.</abstract>
      <url hash="76085c91">2025.wmt-1.16</url>
      <bibkey>shayegh-etal-2025-feeding</bibkey>
      <doi>10.18653/v1/2025.wmt-1.16</doi>
    </paper>
    <paper id="17">
      <title><fixed-case>D</fixed-case>oc<fixed-case>HPLT</fixed-case>: A Massively Multilingual Document-Level Translation Dataset</title>
      <author><first>Dayyán</first><last>O’Brien</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Bhavitvya</first><last>Malik</last><affiliation>University of Edinburgh</affiliation></author>
      <author id="ona-de-gibert"><first>Ona</first><last>de Gibert</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Pinzhen</first><last>Chen</last><affiliation>University of Edinburgh and Aveni</affiliation></author>
      <author><first>Barry</first><last>Haddow</last><affiliation>University of Edinburgh and Aveni</affiliation></author>
      <author id="jorg-tiedemann"><first>Jörg</first><last>Tiedemann</last><affiliation>University of Helsinki</affiliation></author>
      <pages>286-300</pages>
      <abstract>Existing document-level machine translation resources are only available for a handful of languages, mostly high-resourced ones. To facilitate the training and evaluation of document-level translation and, more broadly, long-context modeling for global communities, we create DocHPLT, the largest publicly available document-level translation dataset to date. It contains 124 million aligned document pairs across 50 languages paired with English, comprising 4.26 billion sentences. By adding pivoted alignments, practitioners can obtain 2500 additional pairs not involving English. Unlike previous reconstruction-based approaches that piece together documents from sentence-level data, we modify an existing web extraction pipeline to preserve complete document integrity from the source, retaining all content, including unaligned portions. After our preliminary experiments identify the optimal training context strategy for document-level translation, we demonstrate that LLMs fine-tuned on DocHPLT substantially outperform off-the-shelf instruction-tuned baselines, with particularly dramatic improvements for under-resourced languages. We open-source the dataset under a permissive license, providing essential infrastructure for advancing multilingual document-level translation.</abstract>
      <url hash="4d4f220a">2025.wmt-1.17</url>
      <bibkey>obrien-etal-2025-dochplt</bibkey>
      <doi>10.18653/v1/2025.wmt-1.17</doi>
    </paper>
    <paper id="18">
      <title><fixed-case>SONAR</fixed-case>-<fixed-case>SLT</fixed-case>: Multilingual Sign Language Translation via Language-Agnostic Sentence Embedding Supervision</title>
      <author><first>Yasser</first><last>Hamidullah</last><affiliation>DFKI</affiliation></author>
      <author><first>Shakib</first><last>Yazdani</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Cennet</first><last>Oguz</last><affiliation>German Research Center for Artificial Intelligence (DFKI), Saarland Informatics Campus</affiliation></author>
      <author id="josef-van-genabith"><first>Josef</first><last>Van Genabith</last><affiliation>DFKI</affiliation></author>
      <author><first>Cristina</first><last>España-Bonet</last><affiliation>DFKI GmbH</affiliation></author>
      <pages>301-313</pages>
      <abstract>Sign language translation (SLT) is typically trained with text in a single spoken language, which limits scalability and cross-language generalization. Earlier approaches have replaced gloss supervision with text-based sentence embeddings, but up to now, these remain tied to a specific language and modality. In contrast, here we employ language-agnostic, multimodal embeddings trained on text and speech from multiple languages to supervise SLT, enabling direct multilingual translation. To address data scarcity, we propose a coupled augmentation method that combines multilingual target augmentations (i.e. translations into many languages) with video-level perturbations, improving model robustness. Experiments show consistent BLEURT gains over text-only sentence embedding supervision, with larger improvements in low-resource settings. Our results demonstrate that language-agnostic embedding supervision, combined with coupled augmentation, provides a scalable and semantically robust alternative to traditional SLT training.</abstract>
      <url hash="596dd957">2025.wmt-1.18</url>
      <bibkey>hamidullah-etal-2025-sonar</bibkey>
      <doi>10.18653/v1/2025.wmt-1.18</doi>
    </paper>
    <paper id="19">
      <title><fixed-case>GAMBIT</fixed-case>+: A Challenge Set for Evaluating Gender Bias in Machine Translation Quality Estimation Metrics</title>
      <author><first>George</first><last>Filandrianos</last><affiliation>National Technical University of Athens</affiliation></author>
      <author><first>Orfeas</first><last>Menis Mastromichalakis</last><affiliation>National Technical University of Athens</affiliation></author>
      <author><first>Wafaa</first><last>Mohammed</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Giuseppe</first><last>Attanasio</last><affiliation>Instituto de Telecomunicacoes</affiliation></author>
      <author><first>Chrysoula</first><last>Zerva</last><affiliation>Instituto de Instituto de Telecomunicações, Instituto Superior Técnico, University of Lisbon</affiliation></author>
      <pages>314-326</pages>
      <abstract>Gender bias in machine translation (MT) systems has been extensively documented, but bias in automatic quality estimation (QE) metrics remains comparatively underexplored. Existing studies suggest that QE metrics can also exhibit gender bias, yet most analyses are limited by small datasets, narrow occupational coverage, and restricted language variety. To address this gap, we introduce a large-scale challenge set specifically designed to probe the behavior of QE metrics when evaluating translations containing gender-ambiguous occupational terms. Building on the GAMBIT corpus of English texts with gender-ambiguous occupations, we extend coverage to three source languages that are genderless or natural-gendered, and eleven target languages with grammatical gender, resulting in 33 source–target language pairs. Each source text is paired with two target versions differing only in the grammatical gender of the occupational term(s) (masculine vs. feminine), with all dependent grammatical elements adjusted accordingly. An unbiased QE metric should assign equal or near-equal scores to both versions. The dataset’s scale, breadth, and fully parallel design, where the same set of texts is aligned across all languages, enables fine-grained bias analysis by occupation and systematic comparisons across languages.</abstract>
      <url hash="4f93c7fc">2025.wmt-1.19</url>
      <bibkey>filandrianos-etal-2025-gambit</bibkey>
      <doi>10.18653/v1/2025.wmt-1.19</doi>
    </paper>
    <paper id="20">
      <title>Implementing and Evaluating Multi-source Retrieval-Augmented Translation</title>
      <author><first>Tommi</first><last>Nieminen</last><affiliation>University of Helsinki</affiliation></author>
      <author id="jorg-tiedemann"><first>Jörg</first><last>Tiedemann</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Sami</first><last>Virpioja</last><affiliation>University of Helsinki</affiliation></author>
      <pages>327-339</pages>
      <abstract>In recent years, neural machine translation (NMT) systems have been integrated with external databases with the aim of improving machine translation (MT) quality and enforcing domain-specific terminology and other conventions in the MT output. Most of the work in incorporating external knowledge with NMT has concentrated on integrating a single source of information, usually either a terminology database or a translation memory. However, in real-life translation scenarios, all relevant knowledge sources should be used in parallel. In this article, we evaluate different methods of integrating external knowledge from multiple sources in a single NMT system. In addition to training single models trained to utilize multiple kinds of information, we also ensemble models that have been trained to utilize a single type of information. We evaluate our models against state-of-the-art LLMs using an extensive purpose-built English to Finnish test suite.</abstract>
      <url hash="dd7af748">2025.wmt-1.20</url>
      <bibkey>nieminen-etal-2025-implementing</bibkey>
      <doi>10.18653/v1/2025.wmt-1.20</doi>
    </paper>
    <paper id="21">
      <title>A Cross-Lingual Perspective on Neural Machine Translation Difficulty</title>
      <author><first>Esther</first><last>Ploeger</last><affiliation>Aalborg University</affiliation></author>
      <author><first>Johannes</first><last>Bjerva</last><affiliation>Department of Computer Science, Aalborg University</affiliation></author>
      <author id="jorg-tiedemann"><first>Jörg</first><last>Tiedemann</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Robert</first><last>Östling</last><affiliation>Department of Linguistics, Stockholm University</affiliation></author>
      <pages>340-354</pages>
      <abstract>Intuitively, machine translation (MT) between closely related languages, such as Swedish and Danish, is easier than MT between more distant pairs, such as Finnish and Danish. Yet, the notions of ‘closely related’ languages and ‘easier’ translation have so far remained underspecified. Moreover, in the context of neural MT, this assumption was almost exclusively evaluated in scenarios where English was either the source or target language, leaving a broader cross-lingual view unexplored. In this work, we present a controlled study of language similarity and neural MT difficulty for 56 European translation directions. We test a range of language similarity metrics, some of which are reasonable predictors of MT difficulty. On a text-level, we reassess previously introduced indicators of MT difficulty, and find that they are not well-suited to our domain, or neural MT more generally. Ultimately, we hope that this work inspires further cross-lingual investigations of neural MT difficulty</abstract>
      <url hash="136e0875">2025.wmt-1.21</url>
      <bibkey>ploeger-etal-2025-cross</bibkey>
      <doi>10.18653/v1/2025.wmt-1.21</doi>
    </paper>
    <paper id="22">
      <title>Findings of the <fixed-case>WMT</fixed-case>25 General Machine Translation Shared Task: Time to Stop Evaluating on Easy Test Sets</title>
      <author><first>Tom</first><last>Kocmi</last><affiliation>Cohere</affiliation></author>
      <author><first>Ekaterina</first><last>Artemova</last><affiliation>Toloka.AI</affiliation></author>
      <author><first>Eleftherios</first><last>Avramidis</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Rachel</first><last>Bawden</last><affiliation>Inria</affiliation></author>
      <author id="ondrej-bojar"><first>Ondřej</first><last>Bojar</last><affiliation>Charles University, MFF UFAL</affiliation></author>
      <author><first>Konstantin</first><last>Dranch</last><affiliation>Custom.MT</affiliation></author>
      <author><first>Anton</first><last>Dvorkovich</last><affiliation>Yandex</affiliation></author>
      <author><first>Sergey</first><last>Dukanov</last><affiliation>Dubformer</affiliation></author>
      <author><first>Mark</first><last>Fishel</last><affiliation>University of Tartu</affiliation></author>
      <author><first>Markus</first><last>Freitag</last><affiliation>Google Research</affiliation></author>
      <author><first>Thamme</first><last>Gowda</last><affiliation>Microsoft</affiliation></author>
      <author><first>Roman</first><last>Grundkiewicz</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Barry</first><last>Haddow</last><affiliation>University of Edinburgh and Aveni</affiliation></author>
      <author><first>Marzena</first><last>Karpinska</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <author><first>Philipp</first><last>Koehn</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Howard</first><last>Lakougna</last><affiliation>Gates Foundation</affiliation></author>
      <author><first>Jessica</first><last>Lundin</last><affiliation>Gates Foundation</affiliation></author>
      <author><first>Christof</first><last>Monz</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Kenton</first><last>Murray</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Masaaki</first><last>Nagata</last><affiliation>NTT Inc.</affiliation></author>
      <author><first>Stefano</first><last>Perrella</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Lorenzo</first><last>Proietti</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Martin</first><last>Popel</last><affiliation>Charles University, Faculty of Mathematics and Physics, UFAL</affiliation></author>
      <author id="maja-popovic"><first>Maja</first><last>Popović</last><affiliation>IU University</affiliation></author>
      <author><first>Parker</first><last>Riley</last><affiliation>Google</affiliation></author>
      <author><first>Mariya</first><last>Shmatova</last><affiliation>Toloka AI</affiliation></author>
      <author><first>Steinthór</first><last>Steingrímsson</last><affiliation>The Árni Magnússon Institute for Icelandic Studies</affiliation></author>
      <author><first>Lisa</first><last>Yankovskaya</last><affiliation>University of Tartu</affiliation></author>
      <author><first>Vilém</first><last>Zouhar</last><affiliation>ETH Zurich, Charles University</affiliation></author>
      <pages>355-413</pages>
      <abstract>This paper presents the results of the General Machine Translation Task organized as part of the 2025 Conference on Machine Translation (WMT). Participants were invited to build systems for any of 30 language pairs. For half of these pairs, we conducted a human evaluation on test sets spanning four to five different domains.We evaluated 60 systems in total: 36 submitted by participants and 24 for which we collected translations from large language models (LLMs) and popular online translation providers.This year, we focused on creating challenging test sets by developing a difficulty sampling technique and using more complex source data. We evaluated system outputs with professional annotators using the Error Span Annotation (ESA) protocol, except for two language pairs, for which we used Multidimensional Quality Metrics (MQM) instead.We continued the trend of increasingly moving towards document-level translation, providing the source texts as whole documents containing multiple paragraphs.</abstract>
      <url hash="bc79f068">2025.wmt-1.22</url>
      <bibkey>kocmi-etal-2025-findings</bibkey>
      <doi>10.18653/v1/2025.wmt-1.22</doi>
    </paper>
    <paper id="23">
      <title>Findings of the <fixed-case>WMT</fixed-case>25 Multilingual Instruction Shared Task: Persistent Hurdles in Reasoning, Generation, and Evaluation</title>
      <author><first>Tom</first><last>Kocmi</last><affiliation>Cohere</affiliation></author>
      <author><first>Sweta</first><last>Agrawal</last><affiliation>Instituto de Telecomunicações</affiliation></author>
      <author><first>Ekaterina</first><last>Artemova</last><affiliation>Toloka.AI</affiliation></author>
      <author><first>Eleftherios</first><last>Avramidis</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Eleftheria</first><last>Briakou</last><affiliation>Google</affiliation></author>
      <author><first>Pinzhen</first><last>Chen</last><affiliation>University of Edinburgh and Aveni</affiliation></author>
      <author><first>Marzieh</first><last>Fadaee</last><affiliation>Cohere for AI</affiliation></author>
      <author><first>Markus</first><last>Freitag</last><affiliation>Google Research</affiliation></author>
      <author><first>Roman</first><last>Grundkiewicz</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Yupeng</first><last>Hou</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Philipp</first><last>Koehn</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Julia</first><last>Kreutzer</last><affiliation>Google</affiliation></author>
      <author><first>Saab</first><last>Mansour</last><affiliation>Amazon</affiliation></author>
      <author><first>Stefano</first><last>Perrella</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Lorenzo</first><last>Proietti</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Parker</first><last>Riley</last><affiliation>Google</affiliation></author>
      <author><first>Eduardo</first><last>Sánchez</last><affiliation>Meta/UCL</affiliation></author>
      <author><first>Patricia</first><last>Schmidtova</last><affiliation>Charles University</affiliation></author>
      <author><first>Mariya</first><last>Shmatova</last><affiliation>Toloka AI</affiliation></author>
      <author><first>Vilém</first><last>Zouhar</last><affiliation>ETH Zurich, Charles University</affiliation></author>
      <pages>414-435</pages>
      <abstract>The WMT25 Multilingual Instruction Shared Task (MIST) introduces a benchmark to evaluate large language models (LLMs) across 30 languages. The benchmark covers five types of problems: machine translation, linguistic reasoning, open-ended generation, cross-lingual summarization, and LLM-as-a-judge.We provide automatic evaluation and collect human annotations, which highlight the limitations of automatic evaluation and allow further research into metric meta-evaluation. We run on our benchmark a diverse set of open- and closed-weight LLMs, providing a broad assessment of the multilingual capabilities of current LLMs. Results highlight substantial variation across sub-tasks and languages, revealing persistent challenges in reasoning, cross-lingual generation, and evaluation reliability. This work establishes a standardized framework for measuring future progress in multilingual LLM development.</abstract>
      <url hash="54894776">2025.wmt-1.23</url>
      <bibkey>kocmi-etal-2025-findings-wmt25</bibkey>
      <doi>10.18653/v1/2025.wmt-1.23</doi>
    </paper>
    <paper id="24">
      <title>Findings of the <fixed-case>WMT</fixed-case>25 Shared Task on Automated Translation Evaluation Systems: Linguistic Diversity is Challenging and References Still Help</title>
      <author id="alon-lavie"><first>Alon</first><last>Lavie</last><affiliation>Unbabel/Carnegie Mellon University</affiliation></author>
      <author><first>Greg</first><last>Hanneman</last><affiliation>currently none</affiliation></author>
      <author><first>Sweta</first><last>Agrawal</last><affiliation>Instituto de Telecomunicações</affiliation></author>
      <author><first>Diptesh</first><last>Kanojia</last><affiliation>University of Surrey</affiliation></author>
      <author><first>Chi-Kiu</first><last>Lo</last><affiliation>National Research Council of Canada</affiliation></author>
      <author><first>Vilém</first><last>Zouhar</last><affiliation>ETH Zurich, Charles University</affiliation></author>
      <author id="frederic-blain"><first>Frederic</first><last>Blain</last><affiliation>Tilburg University</affiliation></author>
      <author><first>Chrysoula</first><last>Zerva</last><affiliation>Instituto de Instituto de Telecomunicações, Instituto Superior Técnico, University of Lisbon</affiliation></author>
      <author><first>Eleftherios</first><last>Avramidis</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Sourabh</first><last>Deoghare</last><affiliation>IIT Bombay</affiliation></author>
      <author><first>Archchana</first><last>Sindhujan</last><affiliation>PhD student</affiliation></author>
      <author><first>Jiayi</first><last>Wang</last><affiliation>University College London</affiliation></author>
      <author id="david-ifeoluwa-adelani"><first>David Ifeoluwa</first><last>Adelani</last><affiliation>McGill University / MILA</affiliation></author>
      <author><first>Brian</first><last>Thompson</last><affiliation>Amazon</affiliation></author>
      <author><first>Tom</first><last>Kocmi</last><affiliation>Cohere</affiliation></author>
      <author><first>Markus</first><last>Freitag</last><affiliation>Google Research</affiliation></author>
      <author><first>Daniel</first><last>Deutsch</last><affiliation>Google</affiliation></author>
      <pages>436-483</pages>
      <abstract>The WMT25 Shared Task on Automated Translation Evaluation Systems evaluates metrics and quality estimation systems that assess the quality of language translation systems. This task unifies and consolidates the separate WMT shared tasks on Machine Translation Evaluation Metrics and Quality Estimation from previous years. Our primary goal is to encourage the development and assessment of new state-of-the-art translation quality evaluation systems. The shared task this year consisted of three subtasks: (1) segment-level quality score prediction, (2) span-level translation error annotation, and (3) quality-informed segment-level error correction. The evaluation data for the shared task were provided by the General MT shared task and were complemented by “challenge sets” from both the organizers and participants. Task 1 results indicate the strong performance of large LLMs at the system level, whilereference-based baseline metrics outperform LLMs at the segment level. Task 2 results indicate that accurate error detection and balancing precision and recall are persistent challenges. Task 3 results show that minimal editing is challenging even when informed by quality indicators. Robustness across the broad diversity of languages remains a major challenge across all three subtasks.</abstract>
      <url hash="9e8008c4">2025.wmt-1.24</url>
      <bibkey>lavie-etal-2025-findings</bibkey>
      <doi>10.18653/v1/2025.wmt-1.24</doi>
    </paper>
    <paper id="25">
      <title>Findings of the <fixed-case>WMT</fixed-case> 2025 Shared Task on Model Compression: Early Insights on Compressing <fixed-case>LLM</fixed-case>s for Machine Translation</title>
      <author><first>Marco</first><last>Gaido</last><affiliation>Fondazione Bruno Kessler, University of Trento</affiliation></author>
      <author><first>Roman</first><last>Grundkiewicz</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Thamme</first><last>Gowda</last><affiliation>Microsoft</affiliation></author>
      <author id="matteo-negri"><first>Matteo</first><last>Negri</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <pages>484-494</pages>
      <abstract>We present the results of the first edition of the Model Compression shared task, organized as part of the 10th Conference on Machine Translation (WMT25). The task challenged participants to compress Large Language Models (LLMs) toward enabling practical deployment in resource-constrained scenarios, while minimizing loss in translation performance. In this edition, participants could choose to compete in either a constrained track, which required compressing a specific model (Aya Expanse 8B) evaluated on a limited set of language pairs (Czech→German, Japanese→Chinese, and English→Arabic), or an unconstrained track, which placed no restrictions on the model and allowed submissions for any of the 15 language directions covered by the General MT task (GenMT). We received 12 submissions from three teams, all in the constrained track. They proposed different compression solutions and covered various language combinations: all targeted Czech→German, while one covered all the language pairs. Evaluation was conducted separately for each language, measuring translation quality using COMET and MetricX, model size, and inference speed on an Nvidia A100 GPU.</abstract>
      <url hash="9ea702e0">2025.wmt-1.25</url>
      <bibkey>gaido-etal-2025-findings</bibkey>
      <doi>10.18653/v1/2025.wmt-1.25</doi>
    </paper>
    <paper id="26">
      <title>Findings of the <fixed-case>WMT</fixed-case> 2025 Shared Task of the Open Language Data Initiative</title>
      <author><first>David</first><last>Dale</last><affiliation>Meta AI</affiliation></author>
      <author><first>Laurie</first><last>Burchell</last><affiliation>Common Crawl Foundation</affiliation></author>
      <author><first>Jean</first><last>Maillard</last><affiliation>Meta AI</affiliation></author>
      <author><first>Idris</first><last>Abdulmumin</last><affiliation>University of Pretoria</affiliation></author>
      <author><first>Antonios</first><last>Anastasopoulos</last><affiliation>George Mason University</affiliation></author>
      <author><first>Isaac</first><last>Caswell</last><affiliation>Google Research</affiliation></author>
      <author><first>Philipp</first><last>Koehn</last><affiliation>Johns Hopkins University</affiliation></author>
      <pages>495-502</pages>
      <abstract>We present the results of the WMT 2025 shared task of the Open Language Data Initiative. Participants were invited to contribute to the massively multilingual open datasets (FLORES+, MT Seed, WMT24++) or create new such resources. We accepted 8 submissions, including 7 extensions or revisions of the existing datasets and one submission with a new parallel training dataset, SMOL.</abstract>
      <url hash="7f4ccdbd">2025.wmt-1.26</url>
      <bibkey>dale-etal-2025-findings</bibkey>
      <doi>10.18653/v1/2025.wmt-1.26</doi>
    </paper>
    <paper id="27">
      <title>Findings of the <fixed-case>WMT</fixed-case> 2025 Shared Task <fixed-case>LLM</fixed-case>s with Limited Resources for <fixed-case>S</fixed-case>lavic Languages: <fixed-case>MT</fixed-case> and <fixed-case>QA</fixed-case></title>
      <author><first>Shu</first><last>Okabe</last><affiliation>TUM Heilbronn</affiliation></author>
      <author><first>Daryna</first><last>Dementieva</last><affiliation>Technical University of Munich</affiliation></author>
      <author id="marion-weller-di-marco"><first>Marion</first><last>Di Marco</last><affiliation>TUM</affiliation></author>
      <author><first>Lukas</first><last>Edman</last><affiliation>TU Munich</affiliation></author>
      <author><first>Katharina</first><last>Haemmerl</last><affiliation>Technical University of Munich</affiliation></author>
      <author><first>Marko</first><last>Měškank</last><affiliation>WITAJ-Sprachzentrum</affiliation></author>
      <author><first>Anita</first><last>Hendrichowa</last><affiliation>WITAJ-Sprachzentrum</affiliation></author>
      <author id="alexander-fraser"><first>Alexander</first><last>Fraser</last><affiliation>Ludwig-Maximilians-Universität München</affiliation></author>
      <pages>503-519</pages>
      <abstract>We present the findings of the WMT 2025 Shared Task LLMs with Limited Resources for Slavic Languages. This shared task focuses on training LLMs using limited data and compute resources for three Slavic languages: Upper Sorbian (hsb), Lower Sorbian (dsb), and Ukrainian (uk), with the objective to develop and improve LLMs for these languages. We consider two tasks which are to be evaluated jointly: Machine Translation (MT) and Multiple-Choice Question Answering (QA). In total, three teams participated in this shared task, with submissions from all three teams for the Sorbian languages and one submission for Ukrainian. All submissions led to an improvement compared to the baseline Qwen2.5-3B model through varying fine-tuning strategies. We note, however, that training purely on MT degrades original QA capabilities. We also report further analyses on the submissions, including MT evaluation using advanced neural metrics for Ukrainian, as well as manual annotation and comparison to the current Sorbian machine translator.</abstract>
      <url hash="745507d1">2025.wmt-1.27</url>
      <bibkey>okabe-etal-2025-findings</bibkey>
      <doi>10.18653/v1/2025.wmt-1.27</doi>
    </paper>
    <paper id="28">
      <title>Findings of the First Shared Task for Creole Language Machine Translation at <fixed-case>WMT</fixed-case>25</title>
      <author><first>Nathaniel</first><last>Robinson</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Claire</first><last>Bizon Monroc</last><affiliation>Inria, Paris, France</affiliation></author>
      <author><first>Rasul</first><last>Dent</last><affiliation>Inria</affiliation></author>
      <author><first>Stefan</first><last>Watson</last><affiliation>University of the West Indies at Mona</affiliation></author>
      <author><first>Kenton</first><last>Murray</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Raj</first><last>Dabre</last><affiliation>NICT</affiliation></author>
      <author><first>Andre</first><last>Coy</last><affiliation>University of the West Indies</affiliation></author>
      <author><first>Heather</first><last>Lent</last><affiliation>Aalborg University</affiliation></author>
      <pages>520-531</pages>
      <abstract>Efforts towards better machine translation (MT) for Creole languages have historically been isolated, due to Creole languages’ geographic and linguistic diversity. However, most speakers of Creole languages stand to benefit from improved MT for low-resource languages. To galvanize collaboration for Creole MT across the NLP community, we introduce the First Shared Task for Creole Language Machine Translation at WMT25. This Shared Task consists of two systems tracks and one data track, for which we received submissions from five participating teams. Participants experimented with a wide variety of systems development techniques. Our evaluation campaign gave rise to improvements in MT performance in several languages, and particularly large improvements in new testing genres, though some participants found that reusing subsets of pretraining data for specialized post-training did not yield significant improvements. Our campaign also yielded new test sets for Mauritian Creole and a vast expansion of public training data for two Creole languages of Latin America.</abstract>
      <url hash="70a863fd">2025.wmt-1.28</url>
      <bibkey>robinson-etal-2025-findings</bibkey>
      <doi>10.18653/v1/2025.wmt-1.28</doi>
    </paper>
    <paper id="29">
      <title>Findings of <fixed-case>WMT</fixed-case> 2025 Shared Task on Low-resource <fixed-case>I</fixed-case>ndic Languages Translation</title>
      <author><first>Partha</first><last>Pakray</last><affiliation>National Institute of Technology Silchar</affiliation></author>
      <author><first>Reddi</first><last>Krishna</last><affiliation>NIT Silchar</affiliation></author>
      <author><first>Santanu</first><last>Pal</last><affiliation>Wipro</affiliation></author>
      <author><first>Advaitha</first><last>Vetagiri</last><affiliation>National Institute of Technology Silchar</affiliation></author>
      <author><first>Sandeep</first><last>Dash</last><affiliation>Assistant Professor</affiliation></author>
      <author><first>Arnab Kumar</first><last>Maji</last><affiliation>North-Eastern Hill University</affiliation></author>
      <author><first>Saralin A.</first><last>Lyngdoh</last><affiliation>North-Eastern Hill University</affiliation></author>
      <author><first>Lenin</first><last>Laitonjam</last><affiliation>NIT Mizoram</affiliation></author>
      <author><first>Anupam</first><last>Jamatia</last><affiliation>National Institute of Technology, Agartala</affiliation></author>
      <author><first>Koj</first><last>Sambyo</last><affiliation>NIT Arunachal Pradesh</affiliation></author>
      <author><first>Ajit</first><last>Das</last><affiliation>Bodoland University</affiliation></author>
      <author><first>Riyanka</first><last>Manna</last><affiliation>Amrita Vishwa Vidyapeetham Amaravati</affiliation></author>
      <pages>532-553</pages>
      <abstract>This study proposes the results of the lowresource Indic language translation task organized in collaboration with the Tenth Conference on Machine Translation (WMT) 2025. In this workshop, participants were required to build and develop machine translation models for the seven language pairs, which were categorized into two categories. Category 1 is moderate training data available in languages i.e English–Assamese, English–Mizo, English-Khasi, English–Manipuri and English– Nyishi. Category 2 has very limited training data available in languages, i.e English–Bodo and English–Kokborok. This task leverages the enriched IndicNE-corp1.0 dataset, which consists of an extensive collection of parallel and monilingual corpora for north eastern Indic languages. The participant results were evaluated using automatic machine translation metrics, including BLEU, TER, ROUGE-L, ChrF, and METEOR. Along with those metrics, this year’s work also includes Cosine similarity for evaluation, which captures the semantic representation of the sentence to measure the performance and accuracy of the models. This work aims to promote innovation and advancements in low-resource Indic languages.</abstract>
      <url hash="e8b66814">2025.wmt-1.29</url>
      <bibkey>pakray-etal-2025-findings</bibkey>
      <doi>10.18653/v1/2025.wmt-1.29</doi>
    </paper>
    <paper id="30">
      <title>Findings of the <fixed-case>WMT</fixed-case>25 Terminology Translation Task: Terminology is Useful Especially for Good <fixed-case>MT</fixed-case>s</title>
      <author><first>Kirill</first><last>Semenov</last><affiliation>University of Zurich</affiliation></author>
      <author><first>Xu</first><last>Huang</last><affiliation>Nanjing University</affiliation></author>
      <author><first>Vilém</first><last>Zouhar</last><affiliation>ETH Zurich, Charles University</affiliation></author>
      <author><first>Nathaniel</first><last>Berger</last><affiliation>Heidelberg University</affiliation></author>
      <author><first>Dawei</first><last>Zhu</last><affiliation>Saarland Univeristy</affiliation></author>
      <author id="arturo-oncevay"><first>Arturo</first><last>Oncevay</last><affiliation>JPMorgan</affiliation></author>
      <author><first>Pinzhen</first><last>Chen</last><affiliation>University of Edinburgh and Aveni</affiliation></author>
      <pages>554-576</pages>
      <abstract>The WMT25 Terminology Translation Task releases new resources in high-stakes domains and investigates the capabilities of translation systems to accurately and consistently translate specialized terms. This year, we feature new domain and language coverage over previous editions, introducing two distinct tracks: (1) sentence-level translation in the information technology domain for English→German, English→Russian, and English→Spanish, and (2) document-level translation in the finance domain for English↔Traditional Chinese with a document-level one-to-many dictionary. Participants are challenged to translate texts under three modes: no terminology, proper terminology, and random terminology, allowing for a causal analysis of terminology utility. Evaluation combines overall quality, terminology accuracy, and terminology consistency. This shared task attracted broad participation, with 13 teams submitting 20 systems in Track 1 and 4 teams participating in Track 2. The results show that providing proper terminology consistently boosts both overall translation quality and term accuracy, whereas reliance on random terminology yields smaller gains. Despite the near-saturation of sentence-level benchmarks, document-level finance translation still fallsshort, indicating an urgent need for long-form evaluation and more robust metrics tailored to professional domains.</abstract>
      <url hash="acf21e1d">2025.wmt-1.30</url>
      <bibkey>semenov-etal-2025-findings</bibkey>
      <doi>10.18653/v1/2025.wmt-1.30</doi>
    </paper>
    <paper id="31">
      <title>Midheind at <fixed-case>WMT</fixed-case>25 General Machine Translation Task</title>
      <author><first>Svanhvít Lilja</first><last>Ingólfsdóttir</last><affiliation>Midheind</affiliation></author>
      <author><first>Haukur</first><last>Jónsson</last><affiliation>Midheind</affiliation></author>
      <author><first>Kári Steinn</first><last>Adhalsteinsson</last><affiliation>Midheind</affiliation></author>
      <author><first>Róbert Fjölnir</first><last>Birkisson</last><affiliation>Midheind</affiliation></author>
      <author><first>Sveinbjörn</first><last>Thórdharson</last><affiliation>Midheind</affiliation></author>
      <author><first>Thorvaldur Páll</first><last>Helgason</last><affiliation>Midheind</affiliation></author>
      <pages>577-582</pages>
      <abstract>We present Midheind’s system contribution to two tasks at WMT25 – Tenth Conference on Machine Translation: The General Machine Translation Task and the WMT25 Terminology Shared Task. Erlendur is a multilingual LLM-based translation system that employs a multi-stage pipeline approach, with enhancements especially for translations from English to Icelandic. We address translation quality and grammatical accuracy challenges in current LLMs through a hybrid prompt-based approach that can benefit lower-resource language pairs. In a preparatory step, the LLM analyzes the source text and extracts key terms for lookup in an English-Icelandic dictionary. The findings of the analysis and the retrieved dictionary results are then incorporated into the translation prompt. When provided with a custom glossary, the system identifies relevant terms from the glossary and incorporates them into the translation, to ensure consistency in terminology. For longer inputs, the system maintains translation consistency by providing contextual information from preceding text chunks. Lastly, Icelandic target texts are passed through our custom-developed seq2seq language correction model (Ingólfsdóttir et al., 2023), where grammatical errors are corrected. Using this hybrid method, Erlendur delivers high-quality translations, without fine-tuning. Erlendur ranked 3rd-4th overall in the General Machine Translation Task for English-Icelandic translations, achieving the highest rank amongst all systems submitted by WMT25 participants (Kocmi et al., 2025a). Notably, in the WMT25 Terminology Shared Task, Erlendur placed 3rd in Track 1 and took first place in the more demanding Track 2 (Semenov et al., 2025).</abstract>
      <url hash="3d5e8a93">2025.wmt-1.31</url>
      <bibkey>ingolfsdottir-etal-2025-midheind</bibkey>
      <doi>10.18653/v1/2025.wmt-1.31</doi>
    </paper>
    <paper id="32">
      <title>A Preliminary Study of <fixed-case>AI</fixed-case> Agent Model in Machine Translation</title>
      <author><first>Ahrii</first><last>Kim</last><affiliation>None</affiliation></author>
      <pages>583-586</pages>
      <abstract>We present IR_Multi-agentMT, our submission to the WMT25 General Shared Task. The system adopts an AI-agent paradigm implemented through a multi-agent workflow, Prompt Chaining, in combination with RUBRIC-MQM, an automatic MQM-based error annotation metric. Our primary configuration follows the Translate–Postedit–Proofread paradigm, where each stage progressively enhances translation quality. We conduct a preliminary study to investigate (i) the impact of initial translation quality and (ii) the effect of enforcing explicit responses from the Postedit Agent. Our findings highlight the importance of both factors in shaping the overall performance of multi-agent translation systems.</abstract>
      <url hash="6926d194">2025.wmt-1.32</url>
      <bibkey>kim-2025-preliminary</bibkey>
      <doi>10.18653/v1/2025.wmt-1.32</doi>
    </paper>
    <paper id="33">
      <title>Marco Large Translation Model at <fixed-case>WMT</fixed-case>2025: Transforming Translation Capability in <fixed-case>LLM</fixed-case>s via Quality-Aware Training and Decoding</title>
      <author><first>Hao</first><last>Wang</last><affiliation>Alibaba-AIDC-AI Business</affiliation></author>
      <author><first>Linlong</first><last>Xu</last><affiliation>Alibaba-AIDC-AI Business</affiliation></author>
      <author><first>Heng</first><last>Liu</last><affiliation>Alibaba-AIDC-AI Business</affiliation></author>
      <author><first>Yangyang</first><last>Liu</last><affiliation>Alibaba-AIDC-AI Business</affiliation></author>
      <author><first>Xiaohu</first><last>Zhao</last><affiliation>Alibaba-AIDC-AI Business</affiliation></author>
      <author><first>Bo</first><last>Zeng</last><affiliation>Alibaba-AIDC-AI Business</affiliation></author>
      <author><first>Longyue</first><last>Wang</last><affiliation>Alibaba-AIDC-AI Business</affiliation></author>
      <author><first>Weihua</first><last>Luo</last><affiliation>Alibaba-AIDC-AI Business</affiliation></author>
      <author><first>Kaifu</first><last>Zhang</last><affiliation>Alibaba-AIDC-AI Business</affiliation></author>
      <pages>587-593</pages>
      <abstract>This paper presents the Marco-MT-Algharb system, our submission to the WMT2025 General Machine Translation Shared Task from Alibaba International Digital Commerce (AIDC). Built on a large language model (LLM) foundation, the system’s strong performance stems from novel quality-aware training and decoding techniques: (1) a two-step supervised fine-tuning (SFT) process incorporating data distillation, (2) a two-step reinforcement learning (RL) framework for preference alignment, and (3) a hybrid decoding strategy that integrates word alignment with Minimum Bayes Risk (MBR) re-ranking to improve faithfulness. These approaches jointly ensure high accuracy and robustness across diverse languages and domains. In the official human evaluation, our system secured five first‐place finishes, one second, and four third‐place results in the constrained category across the 13 directions we participated in. Notably, for the English-Chinese, our results surpassed all open/closed‐source systems.</abstract>
      <url hash="090ff5bc">2025.wmt-1.33</url>
      <bibkey>wang-etal-2025-marco</bibkey>
      <doi>10.18653/v1/2025.wmt-1.33</doi>
    </paper>
    <paper id="34">
      <title>Evaluation of <fixed-case>QWEN</fixed-case>-3 for <fixed-case>E</fixed-case>nglish to <fixed-case>U</fixed-case>krainian Translation</title>
      <author><first>Cristian</first><last>Grozea</last><affiliation>Fraunhofer Institut Fokus</affiliation></author>
      <author><first>Oleg</first><last>Verbitsky</last><affiliation>Pidstryhach Institute for Applied Problems of Mechanics and Mathematics Ukrainian Academy of Sciences</affiliation></author>
      <pages>594-598</pages>
      <abstract>We report the results of evaluating Qwen3 for the English-to-Ukrainian language pair of the general MT task of WMT 2025.In addition to the quantitative evaluation, we performed a qualitative evaluation, in collaboration with a native Ukrainian speaker - therefore we present an example-heavy analysis of the typical failures the LLMs still do when translating natural language, particularly into Ukrainian.We report also on the practicalities of using LLMs, such as on the difficulties of making them follow instructions, on ways to exploit the increased “smartness” of the reasoning models while simultaneously avoiding the reasoning part improperly interfering with the chain in which the LLM is just one element.</abstract>
      <url hash="ad58a391">2025.wmt-1.34</url>
      <bibkey>grozea-verbitsky-2025-evaluation</bibkey>
      <doi>10.18653/v1/2025.wmt-1.34</doi>
    </paper>
    <paper id="35">
      <title><fixed-case>SYSTRAN</fixed-case> @ <fixed-case>WMT</fixed-case> 2025 General Translation Task</title>
      <author><first>Dakun</first><last>Zhang</last><affiliation>CHAPSVISION</affiliation></author>
      <author><first>Yara</first><last>Khater</last><affiliation>CHAPSVISION</affiliation></author>
      <author><first>Ramzi</first><last>Rahli</last><affiliation>CHAPSVISION</affiliation></author>
      <author><first>Anna</first><last>Rebollo</last><affiliation>CHAPSVISION</affiliation></author>
      <author id="josep-m-crego"><first>Josep</first><last>Crego</last><affiliation>CHAPSVISION</affiliation></author>
      <pages>599-606</pages>
      <abstract>We present an English-to-Japanese translationsystem built upon the EuroLLM-9B (Martinset al., 2025) model. The training process involvestwo main stages: continue pretraining(CPT) and supervised fine-tuning (SFT). Afterboth stages, we further tuned the model using adevelopment set to optimize performance. Fortraining data, we employed both basic filteringtechniques and high-quality filtering strategiesto ensure data cleanness. Additionally, we classifyboth the training data and development datainto four different domains and we train andfine-tune with domain specific prompts duringsystem training. Finally, we applied MinimumBayes Risk (MBR) decoding and paragraph-levelreranking for post-processing to enhancetranslation quality.</abstract>
      <url hash="5b262c9c">2025.wmt-1.35</url>
      <bibkey>zhang-etal-2025-systran</bibkey>
      <doi>10.18653/v1/2025.wmt-1.35</doi>
    </paper>
    <paper id="36">
      <title>Shy-hunyuan-<fixed-case>MT</fixed-case> at <fixed-case>WMT</fixed-case>25 General Machine Translation Shared Task</title>
      <author><first>Mao</first><last>Zheng</last><affiliation>Tencent</affiliation></author>
      <author><first>Zheng</first><last>Li</last><affiliation>Tencent</affiliation></author>
      <author><first>Yang</first><last>Du</last><affiliation>Tencent</affiliation></author>
      <author><first>Bingxin</first><last>Qu</last><affiliation>Tencent</affiliation></author>
      <author><first>Mingyang</first><last>Song</last><affiliation>Tencent</affiliation></author>
      <pages>607-613</pages>
      <abstract>In this paper, we present our submission to the WMT25 shared task on machine translation, for which we propose Synergy-enhanced policy optimization framework, named <i>Shy</i>. This novel two-phase training framework synergistically combines knowledge distillation and fusion via reinforcement learning.In the first phase, we introduce a multi-stage training framework that harnesses the complementary strengths of multiple state-of-the-art large language models to generate diverse, high-quality translation candidates. These candidates serve as pseudo-references to guide the supervised fine-tuning of our model, Hunyuan-7B, effectively distilling the collective knowledge of multiple expert systems into a single efficient model.In the second phase, we further refine the distilled model through Group Relative Policy Optimization, a reinforcement learning technique that employs a composite reward function. By calculating reward from multiple perspectives, our model ensures better alignment with human preferences and evaluation metrics.Extensive experiments across multiple language pairs demonstrate that our model Shy-hunyuan-MT yields substantial improvements in translation quality compared to baseline approaches. Notably, our framework achieves competitive performance comparable to that of state-of-the-art systems while maintaining computational efficiency through knowledge distillation and strategic ensemble.</abstract>
      <url hash="0071ccd5">2025.wmt-1.36</url>
      <bibkey>zheng-etal-2025-shy</bibkey>
      <doi>10.18653/v1/2025.wmt-1.36</doi>
    </paper>
    <paper id="37">
      <title>From <fixed-case>SALAMANDRA</fixed-case> to <fixed-case>SALAMANDRATA</fixed-case>: <fixed-case>BSC</fixed-case> Submission for <fixed-case>WMT</fixed-case>25 General Machine Translation Shared Task</title>
      <author><first>Javier</first><last>Garcia Gilabert</last><affiliation>Barcelona Super Computing Center</affiliation></author>
      <author><first>Xixian</first><last>Liao</last><affiliation>Barcelona Supercomputing Center</affiliation></author>
      <author><first>Severino</first><last>Da Dalt</last><affiliation>Barcelona Supercomputing Center (BSC)</affiliation></author>
      <author><first>Ella</first><last>Bohman</last><affiliation>Barcelona Supercomputing Center</affiliation></author>
      <author><first>Audrey</first><last>Mash</last><affiliation>BSC</affiliation></author>
      <author><first>Francesca</first><last>De Luca Fornaciari</last><affiliation>BSC Barcelona Supercomputing Center</affiliation></author>
      <author><first>Irene</first><last>Baucells</last><affiliation>Barcelona Supercomputing Centre</affiliation></author>
      <author><first>Joan</first><last>Llop</last><affiliation>Barcelona Supercomputing Center</affiliation></author>
      <author><first>Miguel</first><last>Claramunt</last><affiliation>Barcelona Supercomputing Center</affiliation></author>
      <author><first>Carlos</first><last>Escolano</last><affiliation>Universitat Politecnica de Catalunya, Barcelona Supercomputing Center</affiliation></author>
      <author><first>Maite</first><last>Melero</last><affiliation>Barcelona Supercomputing Center</affiliation></author>
      <pages>614-637</pages>
      <abstract>In this paper, we present the SalamandraTA family of models, an improved iteration of Salamandra LLMs (Gonzalez-Agirre et al., 2025) specifically trained to achieve strong performance in translation-related tasks for 38 European languages. SalamandraTA comes in two scales: 2B and 7B parameters. For both versions, we applied the same training recipe with a first step of continual pre-training on parallel data, and a second step of supervised fine-tuning on high-quality instructions.The BSC submission to the WMT25 General Machine Translation shared task is based on the 7B variant of SalamandraTA. We first extended the model vocabulary to support the additional non-European languages included in the task. This was followed by a second phase of continual pretraining and supervised fine-tuning, carefully designed to optimize performance across all translation directions for this year’s shared task. For decoding, we employed two quality-aware strategies: Minimum Bayes Risk Decoding and Translation Reranking using Comet and Comet-kiwi.We publicly release both the 2B and 7B versions of SalamandraTA, along with the newer SalamandraTA-v2 model, on Hugging Face.</abstract>
      <url hash="35c41221">2025.wmt-1.37</url>
      <bibkey>garcia-gilabert-etal-2025-salamandra</bibkey>
      <doi>10.18653/v1/2025.wmt-1.37</doi>
    </paper>
    <paper id="38">
      <title>Instruction-Tuned <fixed-case>E</fixed-case>nglish to <fixed-case>B</fixed-case>hojpuri Neural Machine Translation Using Contrastive Preference Optimization</title>
      <author><first>Kshetrimayum Boynao</first><last>Singh</last><affiliation>National Institute of Technology Silchar</affiliation></author>
      <author><first>Deepak</first><last>Kumar</last><affiliation>IIT PATNA</affiliation></author>
      <author><first>Asif</first><last>Ekbal</last><affiliation>IIT Patna</affiliation></author>
      <pages>638-643</pages>
      <abstract>This paper presents an English to Bhojpuri machine translation (MT) system developed for the WMT25 General MT Shared Task. Given the low-resource nature of Bhojpuri, we adopt a two-stage training pipeline: unsupervised pretraining followed by supervised fine-tuning. During pretraining, we use a 300,000-sentence corpus comprising 70% Bhojpuri monolingual data and 30% English data to establish language grounding. The fine-tuning stage utilizes 29,749 bilingual English to Bhojpuri sentence pairs (including training, validation, and test sets). To adapt the system to instruction-following scenarios, we apply a novel optimization strategy: Contrastive Preference Optimization (CPO). This technique enables the model to capture fine-grained translation preferences and maintain semantic fidelity in instruction-tuned settings. We evaluate our system across multiple metrics, demonstrating moderate performance in low-resource MT tasks, particularly in diverse domains such as literary, news, social, and speech.</abstract>
      <url hash="327a0f1a">2025.wmt-1.38</url>
      <bibkey>singh-etal-2025-instruction</bibkey>
      <doi>10.18653/v1/2025.wmt-1.38</doi>
    </paper>
    <paper id="39">
      <title><fixed-case>SH</fixed-case> at <fixed-case>WMT</fixed-case>25 General Machine Translation Task</title>
      <author><first>Hayate</first><last>Shiroma</last><affiliation>University of the Ryukyus</affiliation></author>
      <pages>644-650</pages>
      <abstract>I participated in the unconstrained track of the English-to-Japanese translation task at the WMT 2025 General Machine Translation Task.My submission leverages several large language models, all of which are trained with supervised fine-tuning, and some further optimized via preference learning.To enhance translation quality, I introduce an automatic post-editing model and perform automatic post-editing.In addition, I select the best translation from multiple candidates using Minimum Bayes Risk (MBR) decoding.For MBR decoding, I use COMET-22 and LaBSE-based cosine similarity as evaluation metrics.</abstract>
      <url hash="60c4b054">2025.wmt-1.39</url>
      <bibkey>shiroma-2025-sh</bibkey>
      <doi>10.18653/v1/2025.wmt-1.39</doi>
    </paper>
    <paper id="40">
      <title>Simple Test Time Scaling for Machine Translation: Kaze-<fixed-case>MT</fixed-case> at the <fixed-case>WMT</fixed-case>25 General Translation Task</title>
      <author><first>Shaomu</first><last>Tan</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>651-656</pages>
      <abstract>This paper describes the Kaze-MT submission to the WMT25 General Machine Translation task (Japanese–Chinese). Our system deliberately adopts a minimalist Test-Time Scaling (TTS) pipeline with three stages—Sampling, Scoring, and Selection—while avoiding any task-specific fine-tuning, in-context exemplars, or bespoke decoding heuristics. In the sampling stage, we use the zero-shot Qwen2.5-72B-Instruct model to generate 512 candidate translations under a fixed temperature schedule designed to encourage lexical and syntactic diversity without sacrificing fluency. In the scoring stage, each candidate is evaluated by multiple reference-free quality estimation (QE) models—KIWI-22, MetricX-24 Hybrid-XXL, and Remedy-24-9B. The selection stage aggregates metric-specific rankings and chooses the candidate with the lowest mean rank, which we found more stable than averaging raw scores across heterogeneous ranges. We submit to both constrained and unconstrained tracks with minimal configuration changes. According to official preliminary results, our submissions are competitive on automatic metrics; in human evaluation, Kaze-MT falls within the 8–13 cluster, delivering performance comparable to CommandA-WMT and DeepSeek-V3 and outperforming other large LLM baselines such as Mistral-Medium and other extensively tuned MT systems.</abstract>
      <url hash="f809a808">2025.wmt-1.40</url>
      <bibkey>tan-2025-simple</bibkey>
      <doi>10.18653/v1/2025.wmt-1.40</doi>
    </paper>
    <paper id="41">
      <title><fixed-case>NTTSU</fixed-case> at <fixed-case>WMT</fixed-case>2025 General Translation Task</title>
      <author><first>Zhang</first><last>Yin</last><affiliation>Tsukuba University</affiliation></author>
      <author><first>Hiroyuki</first><last>Deguchi</last><affiliation>NTT, Inc.</affiliation></author>
      <author><first>Haruto</first><last>Azami</last><affiliation>University of Tsukuba</affiliation></author>
      <author><first>Guanyu</first><last>Ouyang</last><affiliation>University of Tsukuba</affiliation></author>
      <author><first>Kosei</first><last>Buma</last><affiliation>University of Tsukuba</affiliation></author>
      <author><first>Yingyi</first><last>Fu</last><affiliation>University of Tsukuba</affiliation></author>
      <author><first>Katsuki</first><last>Chousa</last><affiliation>NTT</affiliation></author>
      <author><first>Takehito</first><last>Utsuro</last><affiliation>University of Tsukuba</affiliation></author>
      <pages>657-665</pages>
      <abstract>This paper presents the submission of NTTSU for the constrained track of the English–Japanese and Japanese–Chinese at the WMT2025 general translation task.For each translation direction, we build translation models from a large language model by combining continual pretraining, supervised fine-tuning, and preference optimization based on the translation quality and adequacy.We finally generate translations via context-aware MBR decoding to maximize translation quality and document-level consistency.</abstract>
      <url hash="44720827">2025.wmt-1.41</url>
      <bibkey>yin-etal-2025-nttsu</bibkey>
      <doi>10.18653/v1/2025.wmt-1.41</doi>
    </paper>
    <paper id="42">
      <title>A* Decoding for Machine Translation in <fixed-case>LLM</fixed-case>s - <fixed-case>SRPOL</fixed-case> Participation in <fixed-case>WMT</fixed-case>2025</title>
      <author><first>Adam</first><last>Dobrowolski</last><affiliation>Samsung R&amp;D Institute Poland</affiliation></author>
      <author><first>Paweł</first><last>Przewłocki</last><affiliation>Samsung R&amp;D Institute Poland</affiliation></author>
      <author><first>Paweł</first><last>Przybysz</last><affiliation>Samsung R&amp;D Institute Poland</affiliation></author>
      <author><first>Marcin</first><last>Szymański</last><affiliation>SRPOL</affiliation></author>
      <author><first>Dawid</first><last>Siwicki</last><affiliation>Samsung R&amp;D Institute Poland</affiliation></author>
      <pages>666-670</pages>
      <abstract>SRPOL team submission to WMT2025 introduces innovative approach using A* (A-star) algorithm of decoding in EuroLLM which gives diverse set of translation hypotheses. Subsequent reranking by Comet-QE and NLLB chooses the best of the diversed hypotheses which gives significant improvement of translation quality. The A* algorithm can be applied to decoding in any LLMs or other translation models. The experiment shows that by using free, openly accessible MT models you can achieve translation quality of the best online translators and LLMs using just a PC under your desk.</abstract>
      <url hash="b33cecae">2025.wmt-1.42</url>
      <bibkey>dobrowolski-etal-2025-decoding</bibkey>
      <doi>10.18653/v1/2025.wmt-1.42</doi>
    </paper>
    <paper id="43">
      <title><fixed-case>I</fixed-case>n2<fixed-case>X</fixed-case> at <fixed-case>WMT</fixed-case>25 Translation Task</title>
      <author><first>Lei</first><last>Pang</last><affiliation>Duxiaoman</affiliation></author>
      <author><first>Hanyi</first><last>Mao</last><affiliation>University of Chicago</affiliation></author>
      <author><first>Quanjia</first><last>Xiao</last><affiliation>Peking University</affiliation></author>
      <author><first>Chen</first><last>Ruihan</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Jingjun</first><last>Zhang</last><affiliation>Duxiaoman</affiliation></author>
      <author><first>Haixiao</first><last>Liu</last><affiliation>Duxiaoman</affiliation></author>
      <author><first>Xiangyi</first><last>Li</last><affiliation>Duxiaoman</affiliation></author>
      <pages>671-679</pages>
      <abstract>This paper presents the open-system submission by the In2x research team for the WMT25 General Machine Translation Shared Task. Our submission focuses on Japanese-related translation tasks, aiming to explore a generalizable paradigm for extending large language models (LLMs) to other languages. This paradigm encompasses aspects such as data construction methods and reward model design. The ultimate goal is to enable large language model systems to achieve exceptional performance in low-resource or less commonly spoken languages.</abstract>
      <url hash="5acebe5e">2025.wmt-1.43</url>
      <bibkey>pang-etal-2025-in2x</bibkey>
      <doi>10.18653/v1/2025.wmt-1.43</doi>
    </paper>
    <paper id="44">
      <title><fixed-case>CUNI</fixed-case> at <fixed-case>WMT</fixed-case>25 General Translation Task</title>
      <author><first>Miroslav</first><last>Hrabal</last><affiliation>Charles University</affiliation></author>
      <author><first>Josef</first><last>Jon</last><affiliation>Charles University</affiliation></author>
      <author><first>Martin</first><last>Popel</last><affiliation>Charles University, Faculty of Mathematics and Physics, UFAL</affiliation></author>
      <author id="ondrej-bojar"><first>Ondřej</first><last>Bojar</last><affiliation>Charles University, MFF UFAL</affiliation></author>
      <pages>680-687</pages>
      <abstract>This paper describes the CUNI submissions to the WMT25 General Translation task, namely for the English to Czech, English to Serbian, Czech to German and Czech to Ukrainian language pairs. We worked in multiple teams, each with a different approach, spanning from traditional, smaller Transformer NMT models trained on both sentence and document level, to fine-tuning LLMs using LoRA and CPO. We show that these methods are effective in improving automatic MT evaluation scores compared to the base pretrained models.</abstract>
      <url hash="d86f26e3">2025.wmt-1.44</url>
      <bibkey>jon-etal-2025-cuni</bibkey>
      <doi>10.18653/v1/2025.wmt-1.44</doi>
    </paper>
    <paper id="45">
      <title><fixed-case>U</fixed-case>v<fixed-case>A</fixed-case>-<fixed-case>MT</fixed-case>’s Participation in the <fixed-case>WMT</fixed-case>25 General Translation Shared Task</title>
      <author><first>Di</first><last>Wu</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Yan</first><last>Meng</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Maya Konstantinovna</first><last>Nachesa</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Seth</first><last>Aycock</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Christof</first><last>Monz</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>688-694</pages>
      <abstract>This paper presents UvA-MT’s submission to the WMT 2025 shared task on general machine translation, competing in the unconstrained track across all 16 translation directions. Unusually, this year we use only WMT25’s blind test set (source sentences only) to generate synthetic data for LLM training, and translations are produced using pure beam search for submission. Overall, our approach can be seen as a special variant of data distillation, motivated by two key considerations: (1) perfect domain alignment, where the training and test domains are distributionally identical; and (2) the strong teacher model, GPT-4o-mini, offers high-quality outputs as both a reliable reference and a fallback in case of mere memorization.Interestingly, the outputs of the resulting model, trained on Gemma3-12B using Best-of-N (BoN) outputs from GPT-4o-mini, outperform both original BoN outputs from GPT-4o-mini and Gemma3-12B in some high-resource languages across various metrics. We attribute this to a successful model ensemble, where the student model (Gemma3-12B) retains the strengths of the teacher (GPT-4o-mini) while implicitly avoiding their flaws.</abstract>
      <url hash="ad51b605">2025.wmt-1.45</url>
      <bibkey>wu-etal-2025-uva</bibkey>
      <doi>10.18653/v1/2025.wmt-1.45</doi>
    </paper>
    <paper id="46">
      <title><fixed-case>AMI</fixed-case> at <fixed-case>WMT</fixed-case>25 General Translation Task: How Low Can We Go? Finetuning Lightweight Llama Models for Low Resource Machine Translation</title>
      <author><first>Atli</first><last>Jasonarson</last><affiliation>The Árni Magnússon Institute</affiliation></author>
      <author><first>Steinthor</first><last>Steingrimsson</last><affiliation>The Arni Magnusson Institute for Icelandic Studies</affiliation></author>
      <pages>695-704</pages>
      <abstract>We present the submission of the Árni Magnússon Institute’s team for the WMT25 General translation task. We focus on the English-Icelandic translation direction. We pre-train Llama 3.2 3B on 10B tokens of English and Icelandic texts and fine-tune on parallel corpora. Multiple translation hypotheses are produced first by the fine-tuned model, and then more hypotheses are added by that same model further tuned using contrastive preference optimization. The hypotheses are then post-processed using a grammar correction model and post-processing rules before the final translation is selected using minimum Bayes risk decoding. We found that while it is possible to generate translations of decent quality based on a lightweight model with simple approaches such as the ones we apply, our models are quite far behind the best participating systems and it would probably take somewhat larger models to reach competitive levels.</abstract>
      <url hash="dbabdb86">2025.wmt-1.46</url>
      <bibkey>jasonarson-steingrimsson-2025-ami</bibkey>
      <doi>10.18653/v1/2025.wmt-1.46</doi>
    </paper>
    <paper id="47">
      <title><fixed-case>KIKIS</fixed-case> at <fixed-case>WMT</fixed-case> 2025 General Translation Task</title>
      <author><first>Koichi</first><last>Iwakawa</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Keito</first><last>Kudo</last><affiliation>Tohoku University / RIKEN Center for AIP</affiliation></author>
      <author><first>Subaru</first><last>Kimura</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Takumi</first><last>Ito</last><affiliation>Langsmith Inc. / Tohoku University</affiliation></author>
      <author><first>Jun</first><last>Suzuki</last><affiliation>Tohoku University / RIKEN Center for AIP</affiliation></author>
      <pages>705-722</pages>
      <abstract>We participated in the constrained English–Japanese track of the WMT 2025 General Machine Translation Task.Our system collected the outputs produced by multiple subsystems, each of which consisted of LLM-based translation and reranking models configured differently (e.g., prompting strategies and context sizes), and reranked those outputs.Each subsystem generated multiple segment-level candidates and iteratively selected the most probable one to construct the document translation.We then reranked the document-level outputs from all subsystems to obtain the final translation.For reranking, we adopted a text-based LLM reranking approach with a reasoning model to take long contexts into account.Additionally, we built a bilingual dictionary on the fly from parallel corpora to make the system more robust to rare words.</abstract>
      <url hash="699bded1">2025.wmt-1.47</url>
      <bibkey>iwakawa-etal-2025-kikis</bibkey>
      <doi>10.18653/v1/2025.wmt-1.47</doi>
    </paper>
    <paper id="48">
      <title><fixed-case>G</fixed-case>oogle <fixed-case>T</fixed-case>ranslate’s Research Submission to <fixed-case>WMT</fixed-case>2025</title>
      <author><first>Mara</first><last>Finkelstein</last><affiliation>Google</affiliation></author>
      <author><first>Geza</first><last>Kovacs</last><affiliation>Google</affiliation></author>
      <author><first>Isaac</first><last>Caswell</last><affiliation>Google Research</affiliation></author>
      <author><first>Tobias</first><last>Domhan</last><affiliation>Google</affiliation></author>
      <author><first>Jan-Thorsten</first><last>Peter</last><affiliation>Google</affiliation></author>
      <author><first>Juraj</first><last>Juraska</last><affiliation>Google</affiliation></author>
      <author><first>Markus</first><last>Freitag</last><affiliation>Google Research</affiliation></author>
      <author><first>David</first><last>Vilar</last><affiliation>Google</affiliation></author>
      <pages>723-731</pages>
      <abstract>Large Language Models have shown impressive multilingual capabilities, where translation is one among many tasks. Google Translate’s submission to the 2025 WMT evaluation tries to research how these models behave when pushing their translation performance to the limit. Starting with the strong Gemma 3 model, we carry out supervised fine tuning on high quality, synthetically generated parallel data. Afterwards we perform an additional reinforcement learning step, with reward models based on translation metrics to push the translation capabilities even further. Controlling the combination of reward models, including reference-based and quality estimation metrics, we found that the behaviour of the model could be tailored towards a more literal or more creative translation style. Our two submissions correspond to those two models. We chose the more creative system as our primary submission, targetting a human preference for better sounding, more naturally flowing text, although at the risk of losing on the accuracy of the translation. It is an open question to find the sweet spot between these two dimensions, which certainly will depend on the specific domain to handle and user preferences.</abstract>
      <url hash="a08f887a">2025.wmt-1.48</url>
      <bibkey>finkelstein-etal-2025-google</bibkey>
      <doi>10.18653/v1/2025.wmt-1.48</doi>
    </paper>
    <paper id="49">
      <title><fixed-case>DLUT</fixed-case> and <fixed-case>GTCOM</fixed-case>’s Large Language Model Based Translation System for <fixed-case>WMT</fixed-case>25</title>
      <author><first>Hao</first><last>Zong</last><affiliation>DLUT</affiliation></author>
      <author><first>Chao</first><last>Bei</last><affiliation>GTCOM</affiliation></author>
      <author><first>Wentao</first><last>Chen</last><affiliation>GTCOM</affiliation></author>
      <author><first>Conghu</first><last>Yuan</last><affiliation>GTCOM</affiliation></author>
      <author><first>Huan</first><last>Liu</last><affiliation>GTCOM</affiliation></author>
      <author id="degen-huang"><first>Degen</first><last>Huang</last><affiliation>DLUT</affiliation></author>
      <pages>732-739</pages>
      <abstract>This paper presents the submission from Dalian University of Technology (DLUT) and Global Tone Communication Technology Co., Ltd. (GTCOM) to the WMT25 General Machine Translation Task. Amidst the paradigm shift from specialized encoder-decoder models to general-purpose Large Language Models (LLMs), this work conducts a systematic comparison of both approaches across five language pairs. For traditional Neural Machine Translation (NMT), we build strong baselines using deep Transformer architectures enhanced with data augmentation. For the LLM paradigm, we explore zero-shot performance and two distinct supervised fine-tuning (SFT) strategies: direct translation and translation refinement. Our key findings reveal a significant discrepancy between lexical and semantic evaluation metrics: while strong NMT systems remain competitive in BLEU scores, fine-tuned LLMs demonstrate marked superiority in semantic fidelity as measured by COMET. Furthermore, we find that fine-tuning LLMs for direct translation is more effective than for refinement, suggesting that teaching the core task directly is preferable to correcting baseline outputs.</abstract>
      <url hash="14690a74">2025.wmt-1.49</url>
      <bibkey>zong-etal-2025-dlut</bibkey>
      <doi>10.18653/v1/2025.wmt-1.49</doi>
    </paper>
    <paper id="50">
      <title><fixed-case>Y</fixed-case>andex Submission to the <fixed-case>WMT</fixed-case>25 General Machine Translation Task</title>
      <author><first>Nikolay</first><last>Karpachev</last><affiliation>Yandex</affiliation></author>
      <author><first>Ekaterina</first><last>Enikeeva</last><affiliation>Yandex</affiliation></author>
      <author><first>Dmitry</first><last>Popov</last><affiliation>Yandex</affiliation></author>
      <author><first>Arsenii</first><last>Bulgakov</last><affiliation>Yandex</affiliation></author>
      <author><first>Daniil</first><last>Panteleev</last><affiliation>Yandex</affiliation></author>
      <author><first>Dmitrii</first><last>Ulianov</last><affiliation>Yandex</affiliation></author>
      <author><first>Artem</first><last>Kryukov</last><affiliation>Yandex</affiliation></author>
      <author><first>Artem</first><last>Mekhraliev</last><affiliation>Yandex</affiliation></author>
      <pages>740-752</pages>
      <abstract>This paper describes Yandex submission to the WMT25 General Machine Translation task. We participate in English-to-Russian translation direction and propose a purely LLM-based translation model. Our training procedure comprises a training pipeline of several stages built upon YandexGPT, an in-house general-purpose LLM. In particular, firstly, we employ continual pretraining (post-pretrain) for MT task for initial adaptation to multilinguality and translation. Subsequently, we use SFT on parallel document-level corpus in the form of P-Tuning. Following SFT, we propose a novel alignment scheme of two stages, the first one being a curriculum learning with difficulty schedule and a second one - training the model for tag preservation and error correction with human post-edits as training samples. Our model achieves results comparable to human reference translations on multiple domains.</abstract>
      <url hash="d92b4cbc">2025.wmt-1.50</url>
      <bibkey>karpachev-etal-2025-yandex</bibkey>
      <doi>10.18653/v1/2025.wmt-1.50</doi>
    </paper>
    <paper id="51">
      <title><fixed-case>IRB</fixed-case>-<fixed-case>MT</fixed-case> at <fixed-case>WMT</fixed-case>25 Translation Task: A Simple Agentic System Using an Off-the-Shelf <fixed-case>LLM</fixed-case></title>
      <author><first>Ivan</first><last>Grubišić</last><affiliation>Ruđer Bošković Institute</affiliation></author>
      <author><first>Damir</first><last>Korencic</last><affiliation>Ruđer Bošković Institute</affiliation></author>
      <pages>753-764</pages>
      <abstract>Large Language Models (LLMs) have been demonstrated to achieve state-of-art results on machine translation. LLM-based translation systems usually rely on model adaptation and fine-tuning, requiring datasets and compute. The goal of our team’s participation in the “General Machine Translation” and “Multilingual” tasks of WMT25 was to evaluate the translation effectiveness of a resource-efficient solution consisting of a smaller off-the-shelf LLM coupled with a self-refine agentic workflow. Our approach requires a high-quality multilingual LLM capable of instruction following. We select Gemma3-12B among several candidates using the pretrained translation metric MetricX-24 and a small development dataset. WMT25 automatic evaluations place our solution in the mid tier of all WMT25 systems, and also demonstrate that it can perform competitively for approximately 16% of language pairs.</abstract>
      <url hash="3c162141">2025.wmt-1.51</url>
      <bibkey>grubisic-korencic-2025-irb</bibkey>
      <doi>10.18653/v1/2025.wmt-1.51</doi>
    </paper>
    <paper id="52">
      <title>Improving Low-Resource <fixed-case>J</fixed-case>apanese Translation with Fine-Tuning and Backtranslation for the <fixed-case>WMT</fixed-case> 25 General Translation Task</title>
      <author><first>Felipe</first><last>Fujita</last><affiliation>Ritsumeikan University</affiliation></author>
      <author><first>Hideyuki</first><last>Takada</last><affiliation>Ritsumeikan University</affiliation></author>
      <pages>765-768</pages>
      <abstract>In this paper, we explore the effectiveness of combining fine-tuning and backtranslation on a small Japanese corpus for neural machine translation. Starting from a baseline English→Japanese model (COMET = 0.460), we first apply backtranslation (BT) using synthetic data generated from monolingual Japanese corpora, yielding a modest increase (COMET = 0.468). Next, we fine-tune (FT) the model on a genuine small parallel dataset drawn from diverse Japanese news and literary corpora, achieving a substantial jump to COMET = 0.589 when using Mistral 7B. Finally, we integrate both backtranslation and fine-tuning—first augmenting the small dataset with BT generated examples, then adapting via FT—which further boosts performance to COMET = 0.597. These results demonstrate that, even with limited training data, the synergistic use of backtranslation and targeted fine-tuning on Japanese corpora can significantly enhance translation quality, outperforming each technique in isolation. This approach offers a lightweight yet powerful strategy for improving low-resource language pairs.</abstract>
      <url hash="264a32bf">2025.wmt-1.52</url>
      <bibkey>fujita-takada-2025-improving</bibkey>
      <doi>10.18653/v1/2025.wmt-1.52</doi>
    </paper>
    <paper id="53">
      <title>Multi-agent<fixed-case>MT</fixed-case>: Deploying <fixed-case>AI</fixed-case> Agent in the <fixed-case>WMT</fixed-case>25 Shared Task</title>
      <author><first>Ahrii</first><last>Kim</last><affiliation>None</affiliation></author>
      <pages>769-777</pages>
      <abstract>We present Multi-agentMT, our system for the WMT25 General Shared Task. The model adopts Prompt Chaining, a multi-agent workflow combined with Rubric-MQM, an automatic MQM-based error annotation metric. Our primary submission follows a Translate–Postedit–Proofread pipeline, in which error positions are explicitly marked and iteratively refined. Results suggest that a semi-autonomous agent scheme for machine translation is feasible with a smaller, earlier-generation model in low-resource settings, achieving comparable quality at roughly half the cost of larger systems.</abstract>
      <url hash="486c9560">2025.wmt-1.53</url>
      <bibkey>kim-2025-multi</bibkey>
      <doi>10.18653/v1/2025.wmt-1.53</doi>
    </paper>
    <paper id="54">
      <title>Laniqo at <fixed-case>WMT</fixed-case>25 General Translation Task: Self-Improved and Retrieval-Augmented Translation</title>
      <author><first>Kamil</first><last>Guttmann</last><affiliation>Laniqo, Adam Mickiewicz University in Poznań</affiliation></author>
      <author><first>Zofia</first><last>Rostek</last><affiliation>Laniqo</affiliation></author>
      <author><first>Adrian</first><last>Charkiewicz</last><affiliation>Laniqo, Adam Mickiewicz University in Poznań</affiliation></author>
      <author><first>Antoni</first><last>Solarski</last><affiliation>Laniqo</affiliation></author>
      <author><first>Mikołaj</first><last>Pokrywka</last><affiliation>Laniqo, Allegro, Adam Mickiewicz University</affiliation></author>
      <author><first>Artur</first><last>Nowakowski</last><affiliation>Laniqo / Adam Mickiewicz University</affiliation></author>
      <pages>778-788</pages>
      <abstract>This work describes Laniqo’s submission to the constrained track of the WMT25 General MT Task. We participated in 11 translation directions. Our approach combines several techniques: fine-tuning the EuroLLM-9B-Instruct model using Contrastive Preference Optimization on a synthetic dataset, applying Retrieval-Augmented Translation with human-translated data, implementing Quality-Aware Decoding, and performing postprocessing of translations with a rule-based algorithm. We analyze the contribution of each method and report improvements at every stage of our pipeline.</abstract>
      <url hash="f3f94ebf">2025.wmt-1.54</url>
      <bibkey>guttmann-etal-2025-laniqo</bibkey>
      <doi>10.18653/v1/2025.wmt-1.54</doi>
    </paper>
    <paper id="55">
      <title>Command-A-Translate: Raising the Bar of Machine Translation with Difficulty Filtering</title>
      <author><first>Tom</first><last>Kocmi</last><affiliation>Cohere</affiliation></author>
      <author><first>Arkady</first><last>Arkhangorodsky</last><affiliation>DiDi Labs</affiliation></author>
      <author><first>Alexandre</first><last>Berard</last><affiliation>Naver Labs Europe</affiliation></author>
      <author id="phil-blunsom"><first>Phil</first><last>Blunsom</last><affiliation>University of Oxford</affiliation></author>
      <author><first>Samuel</first><last>Cahyawijaya</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Théo</first><last>Dehaze</last><affiliation>Cohere</affiliation></author>
      <author><first>Marzieh</first><last>Fadaee</last><affiliation>Cohere for AI</affiliation></author>
      <author><first>Nicholas</first><last>Frosst</last><affiliation>Cohere</affiliation></author>
      <author><first>Matthias</first><last>Galle</last><affiliation>Cohere</affiliation></author>
      <author><first>Aidan</first><last>Gomez</last><affiliation>University of Oxford</affiliation></author>
      <author><first>Nithya</first><last>Govindarajan</last><affiliation>Cohere</affiliation></author>
      <author><first>Wei-Yin</first><last>Ko</last><affiliation>Cohere</affiliation></author>
      <author><first>Julia</first><last>Kreutzer</last><affiliation>Google</affiliation></author>
      <author><first>Kelly</first><last>Marchisio</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Ahmet</first><last>Üstün</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Sebastian</first><last>Vincent</last><affiliation>Cohere</affiliation></author>
      <author><first>Ivan</first><last>Zhang</last><affiliation>Cohere</affiliation></author>
      <pages>789-799</pages>
      <abstract>We present Command A Translate, an LLMbased machine translation model built off Cohere’s Command A. It reaches state-of-the-art machine translation quality via direct preference optimization. Our meticulously designed data preparation pipeline emphasizes robust quality control and a novel difficulty filtering – a key innovation that distinguishes Command A Translate. Furthermore, we extend our model and participate at WMT with a system (CommandA-WMT) that uses two models and post-editing steps of step-by-step reasoning and limited Minimum Bayes Risk decoding.</abstract>
      <url hash="59df9ef5">2025.wmt-1.55</url>
      <bibkey>kocmi-etal-2025-command</bibkey>
      <doi>10.18653/v1/2025.wmt-1.55</doi>
    </paper>
    <paper id="56">
      <title><fixed-case>GENDER</fixed-case>1<fixed-case>PERSON</fixed-case>: Test Suite for Estimating Gender Bias of First-person Singular Forms</title>
      <author id="maja-popovic"><first>Maja</first><last>Popović</last><affiliation>IU University</affiliation></author>
      <author><first>Ekaterina</first><last>Lapshinova-Koltunski</last><affiliation>University of Hildesheim</affiliation></author>
      <pages>800-822</pages>
      <abstract>The gender1person test suite is designed to measure gender bias in translating singular first-person forms from English into two Slavic languages, Russian and Serbian. The test suite consists of 1,000 Amazon product reviews, uniformly distributed over 10 different product categories. Bias is measured through a gender score ranging from -100 (all reviews are feminine) to 100 (all reviews are masculine). The test suite shows that the majority of the systems participating in the WMT-2025 task for these two target languages prefer the masculine writer’s gender. There is no single system which is biased towards the feminine variant. Furthermore, for each language pair, there are seven systems that are considered balanced, having the gender scores between -10 and 10.Finally, the analysis of different products showed that the choice of the writer’s gender depends to a large extent on the product. Moreover, it is demonstrated that even the systems with overall balanced scores are actually biased, but in different ways for different product categories.</abstract>
      <url hash="4acb5316">2025.wmt-1.56</url>
      <bibkey>popovic-lapshinova-koltunski-2025-gender1person</bibkey>
      <doi>10.18653/v1/2025.wmt-1.56</doi>
    </paper>
    <paper id="57">
      <title>Evaluation of <fixed-case>LLM</fixed-case> for <fixed-case>E</fixed-case>nglish to <fixed-case>H</fixed-case>indi Legal Domain Machine Translation Systems</title>
      <author><first>Kshetrimayum Boynao</first><last>Singh</last><affiliation>National Institute of Technology Silchar</affiliation></author>
      <author><first>Deepak</first><last>Kumar</last><affiliation>IIT PATNA</affiliation></author>
      <author><first>Asif</first><last>Ekbal</last><affiliation>IIT Patna</affiliation></author>
      <pages>823-833</pages>
      <abstract>The study critically examines various Machine Translation systems, particularly focusing on Large Language Models, using the WMT25 Legal Domain Test Suite for translating English into Hindi. It utilizes a dataset of 5,000 sentences designed to capture the complexity of legal texts, based on word frequency ranges from 5 to 54. Each frequency range contains 100 sentences, collectively forming a corpus that spans from simple legal terms to intricate legal provisions. Six metrics were used to evaluate the performance of the system: BLEU, METEOR, TER, CHRF++, BERTScore and COMET. The findings reveal diverse capabilities and limitations of LLM architectures in handling complex legal texts. Notably, Gemini-2.5-Pro, Claude-4 and ONLINE-B topped the performance charts in terms fo human evaluation, showcasing the potential of LLMs for nuanced trans- lation. Despite these advances, the study identified areas for further research, especially in improving robustness, reliability, and explainability for use in critical legal contexts. The study also supports the WMT25 subtask focused on evaluating weaknesses of large language models (LLMs). The dataset and related resources are publicly available at https://github.com/helloboyn/WMT25-TS.</abstract>
      <url hash="32a4ff37">2025.wmt-1.57</url>
      <bibkey>singh-etal-2025-evaluation</bibkey>
      <doi>10.18653/v1/2025.wmt-1.57</doi>
    </paper>
    <paper id="58">
      <title><fixed-case>R</fixed-case>o<fixed-case>CS</fixed-case>-<fixed-case>MT</fixed-case> v2 at <fixed-case>WMT</fixed-case> 2025: Robust Challenge Set for Machine Translation</title>
      <author><first>Rachel</first><last>Bawden</last><affiliation>Inria</affiliation></author>
      <author id="benoit-sagot"><first>Benoît</first><last>Sagot</last><affiliation>Inria</affiliation></author>
      <pages>834-849</pages>
      <abstract>RoCS-MT (Robust Challenge Set for Machine Translation) was initially proposed at the test suites track of WMT 2023. Designed to challenge MT systems’ translation performance on user-generated content (UGC), it contains examples sourced from English Reddit, with manually normalised versions, aligned labelled annotation spans and reference translations in five languages. In this article, we describe version 2 of RoCS-MT in the context of the 2025 WMT test suites track. This new version contains several improvements on the initial version including (i) minor corrections of normalisation, (ii) corrections to reference translations and addition of alternative references to accommodate for different possible genders (e.g. of speakers) and (iii) a redesign and re-annotation of normalisation spans for further analysis of different non-standard UGC phenomena. We describe these changes and provide results and preliminary analysis of the MT submissions to the 2025 general translation task.</abstract>
      <url hash="b1f46819">2025.wmt-1.58</url>
      <bibkey>bawden-sagot-2025-rocs</bibkey>
      <doi>10.18653/v1/2025.wmt-1.58</doi>
    </paper>
    <paper id="59">
      <title>Automated Evaluation for Terminology Translation Related to the <fixed-case>EEA</fixed-case> Agreement</title>
      <author><first>Selma Dis</first><last>Hauksdottir</last><affiliation>University of Iceland</affiliation></author>
      <author><first>Steinthor</first><last>Steingrimsson</last><affiliation>The Arni Magnusson Institute for Icelandic Studies</affiliation></author>
      <pages>850-855</pages>
      <abstract>This paper presents a submission to the WMT25 test suite subtask, focusing on terminology in official documents related to the EEA Agreement. The test suite evaluates the accuracy of MT systems in translating terminology for the English-Icelandic translation direction when applied to the EEA documents. We focus on the use of terminology in four domains of the agreement; science, technology, economics, and society. We find that the manual evaluation confirms that our test suite can be helpful in selecting the best MT system for working with these domains. Surprisingly, an online system that does not achieve very high scores on the general translation task, according to preliminary results, is most adept at translating the terminology our test suite evaluates.</abstract>
      <url hash="4530535a">2025.wmt-1.59</url>
      <bibkey>hauksdottir-steingrimsson-2025-automated</bibkey>
      <doi>10.18653/v1/2025.wmt-1.59</doi>
    </paper>
    <paper id="60">
      <title>Up to Par? <fixed-case>MT</fixed-case> Systems Take a Shot at Sports Terminology</title>
      <author><first>Einar</first><last>Sigurdsson</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Magnús</first><last>Magnússon</last><affiliation>The Árni Magnússon Institute for Icelandic Studies</affiliation></author>
      <author><first>Atli</first><last>Jasonarson</last><affiliation>The Árni Magnússon Institute</affiliation></author>
      <author><first>Steinthor</first><last>Steingrimsson</last><affiliation>The Arni Magnusson Institute for Icelandic Studies</affiliation></author>
      <pages>856-865</pages>
      <abstract>We present a submission to the WMT25 test suite subtask, focusing on the capabilities of MT systems to translate sports-related language. Although many sports attract extensive media attention and feature a rich, polysemous language, often shaped by active neologism and community-driven translations, the sports domain has received relatively little focus in MT research. In English-Icelandic automatic translations, sports-specific vocabulary often appears to be mistranslated. Our test suite is designed to test whether this observation holds merit. We evaluate 34 systems, both automatically and manually, and find that sports language poses challenges to a varying degree for all the systems.</abstract>
      <url hash="f015a9c0">2025.wmt-1.60</url>
      <bibkey>sigurdsson-etal-2025-par</bibkey>
      <doi>10.18653/v1/2025.wmt-1.60</doi>
    </paper>
    <paper id="61">
      <title>Fine-Grained Evaluation of <fixed-case>E</fixed-case>nglish-<fixed-case>R</fixed-case>ussian <fixed-case>MT</fixed-case> in 2025: Linguistic Challenges Mirroring Human Translator Training</title>
      <author><first>Shushen</first><last>Manakhimova</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Maria</first><last>Kunilovskaya</last><affiliation>Saarland University</affiliation></author>
      <author><first>Ekaterina</first><last>Lapshinova-Koltunski</last><affiliation>University of Hildesheim</affiliation></author>
      <author><first>Eleftherios</first><last>Avramidis</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <pages>866-877</pages>
      <abstract>We analyze how English–Russian machine translation (MT) systems submitted to WMT25 perform on linguistically challenging translation tasks, similar to problems used in university professional translator training. We assessed the ten top-performing systems using a fine-grained test suite containing 465 manually devised test items, which cover 55 lexical, grammatical, and discourse phenomena, in 13 categories. By applying pass/fail rules with human adjudication and micro/macro aggregates, we observe three performance tiers. Compared with the official WMT25 ranking, our ranking broadly aligns but reveals notable shifts.Our findings show that in 2025, even top-performing MT systems still struggle with translation problems that require deep understanding and rephrasing, much like human novices do. The best systems exhibit creativity and can be very good at handling such challenges, often producing more natural translations rather than producing word-for-word renditions. However, persistent structural and lexical problems remain: literal word order carry-overs, misused verb forms, and rigid phrase translations were common, mirroring errors typically seen in beginner translator assignments.</abstract>
      <url hash="58adf868">2025.wmt-1.61</url>
      <bibkey>manakhimova-etal-2025-fine</bibkey>
      <doi>10.18653/v1/2025.wmt-1.61</doi>
    </paper>
    <paper id="62">
      <title>Tagged Span Annotation for Detecting Translation Errors in Reasoning <fixed-case>LLM</fixed-case>s</title>
      <author><first>Taemin</first><last>Yeom</last><affiliation>Sungkyunkwan University</affiliation></author>
      <author><first>Yonghyun</first><last>Ryu</last><affiliation>Samsung Electronics</affiliation></author>
      <author><first>Yoonjung</first><last>Choi</last><affiliation>Samsung Research</affiliation></author>
      <author><first>Jinyeong</first><last>Bak</last><affiliation>Sungkyunkwan University</affiliation></author>
      <pages>878-886</pages>
      <abstract>We present the AIP team’s submission to the WMT 2025 Unified MT Evaluation SharedTask, focusing on the span-level error detection subtask. Our system emphasizes response format design to better harness the capabilities of OpenAI’s o3, the state-of-the-art reasoning LLM. To this end, we introduce Tagged SpanAnnotation (TSA), an annotation scheme designed to more accurately extract span-level information from the LLM. On our refined version of WMT24 ESA dataset, our reference-free method achieves an F1 score of approximately 27 for character-level label prediction, outperforming the reference-based XCOMET-XXL at approximately 17.</abstract>
      <url hash="cb5c6efd">2025.wmt-1.62</url>
      <bibkey>yeom-etal-2025-tagged</bibkey>
      <doi>10.18653/v1/2025.wmt-1.62</doi>
    </paper>
    <paper id="63">
      <title><fixed-case>COMET</fixed-case>-poly: Machine Translation Metric Grounded in Other Candidates</title>
      <author><first>Maike</first><last>Züfle</last><affiliation>Karlsruhe Institute of Technology</affiliation></author>
      <author><first>Vilém</first><last>Zouhar</last><affiliation>ETH Zurich, Charles University</affiliation></author>
      <author><first>Tu Anh</first><last>Dinh</last><affiliation>Karlsruhe Institute of Technology</affiliation></author>
      <author><first>Felipe</first><last>Maia Polo</last><affiliation>University of Michigan</affiliation></author>
      <author><first>Jan</first><last>Niehues</last><affiliation>Karlsruhe Institut of Technology</affiliation></author>
      <author><first>Mrinmaya</first><last>Sachan</last><affiliation>ETH Zurich</affiliation></author>
      <pages>887-904</pages>
      <abstract>Automated metrics for machine translation attempt to replicate human judgment. Unlike humans, who often assess a translation in the context of multiple alternatives, these metrics typically consider only the source sentence and a single translation. This discrepancy in the evaluation setup may negatively impact the performance of automated metrics. We propose two automated metrics that incorporate additional information beyond the single translation. COMET-polycand uses alternative translations of the same source sentence to compare and contrast with the translation at hand, thereby providing a more informed assessment of its quality. COMET-polyic, inspired by retrieval-based in-context learning, takes in translations of similar source texts along with their human-labeled quality scores to guide the evaluation. We find that including a single additional translation in COMET-polycand improves the segment-level metric performance (0.079 to 0.118 Kendall’s tau-b correlation), with further gains when more translations are added. Incorporating retrieved examples in COMET-polyic yields similar improvements (0.079 to 0.116 Kendall’s tau-b correlation). We release our models publicly.</abstract>
      <url hash="11785ecc">2025.wmt-1.63</url>
      <bibkey>zufle-etal-2025-comet</bibkey>
      <doi>10.18653/v1/2025.wmt-1.63</doi>
    </paper>
    <paper id="64">
      <title>Long-context Reference-based <fixed-case>MT</fixed-case> Quality Estimation</title>
      <author><first>Sami</first><last>Haq</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Chinonso</first><last>Osuji</last><affiliation>ADAPT Research Centre, Dublin City University</affiliation></author>
      <author><first>Sheila</first><last>Castilho</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Brian</first><last>Davis</last><affiliation>Dublin City University</affiliation></author>
      <author id="thiago-castro-ferreira"><first>Thiago</first><last>Castro Ferreira</last><affiliation>Federal University of Minas Gerais</affiliation></author>
      <pages>905-912</pages>
      <abstract>In this paper, we present our submission to the Tenth Conference on Machine Translation (WMT25) Shared Task on Automated Translation Quality Evaluation. Our systems are built upon the COMET framework and trained to predict segment-level ESA scores using augmented long-context data. To construct long-context training examples, we concatenate multiple in-domain sentences and compute a weighted average of their scores. We further integrate human judgment datasets MQM, SQM, and DA) through score normalisation and train multilingual models on the source, hypothesis, and reference translations. Experimental results demonstrate that incorporating long-context information yields higher correlations with human judgments compared to models trained exclusively on short segments.</abstract>
      <url hash="707eb72c">2025.wmt-1.64</url>
      <bibkey>haq-etal-2025-long</bibkey>
      <doi>10.18653/v1/2025.wmt-1.64</doi>
    </paper>
    <paper id="65">
      <title>Evaluating <fixed-case>WMT</fixed-case> 2025 Metrics Shared Task Submissions on the <fixed-case>SSA</fixed-case>-<fixed-case>MTE</fixed-case> <fixed-case>A</fixed-case>frican Challenge Set</title>
      <author><first>Senyu</first><last>Li</last><affiliation>University of Alberta</affiliation></author>
      <author><first>Felermino Dario Mario</first><last>Ali</last><affiliation>Lurio University</affiliation></author>
      <author><first>Jiayi</first><last>Wang</last><affiliation>University College London</affiliation></author>
      <author><first>Rui</first><last>Sousa-Silva</last><affiliation>University of Porto - Faculty of Arts and Humanities</affiliation></author>
      <author><first>Henrique</first><last>Lopes Cardoso</last><affiliation>University of Porto</affiliation></author>
      <author><first>Pontus</first><last>Stenetorp</last><affiliation>University College London</affiliation></author>
      <author><first>Colin</first><last>Cherry</last><affiliation>Google</affiliation></author>
      <author id="david-ifeoluwa-adelani"><first>David Ifeoluwa</first><last>Adelani</last><affiliation>McGill University / MILA</affiliation></author>
      <pages>913-919</pages>
      <abstract>This paper presents the evaluation of submissions to the WMT 2025 Metrics Shared Task on the SSA-MTE challenge set, a large-scale benchmark for machine translation evaluation (MTE) in Sub-Saharan African languages. The SSA-MTE test sets contains over 12,768 human-annotated adequacy scores across 11 language pairs sourced from English, French, and Portuguese, spanning 6 commercial and open-source MT systems. Results show that correlations with human judgments remain generally low, with most systems falling below the 0.4 Spearman threshold for medium-level agreement. Performance varies widely across language pairs, with most correlations under 0.4; in some extremely low-resource cases, such as Portuguese–Emakhuwa, correlations drop to around 0.1, underscoring the difficulty of evaluating MT for very low-resource African languages. These findings highlight the urgent need for more research on robust, generalizable MT evaluation methods tailored for African languages.</abstract>
      <url hash="277afc3b">2025.wmt-1.65</url>
      <bibkey>li-etal-2025-evaluating-wmt</bibkey>
      <doi>10.18653/v1/2025.wmt-1.65</doi>
    </paper>
    <paper id="66">
      <title>Nvidia-Nemo’s <fixed-case>WMT</fixed-case> 2025 Metrics Shared Task Submission</title>
      <author><first>Brian</first><last>Yan</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Shuoyang</first><last>Ding</last><affiliation>NVIDIA</affiliation></author>
      <author><first>Kuang-Da</first><last>Wang</last><affiliation>NYCU</affiliation></author>
      <author><first>Siqi</first><last>Ouyang</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Oleksii</first><last>Hrinchuk</last><affiliation>NVIDIA</affiliation></author>
      <author><first>Vitaly</first><last>Lavrukhin</last><affiliation>NVIDIA</affiliation></author>
      <author><first>Boris</first><last>Ginsburg</last><affiliation>NVIDIA</affiliation></author>
      <pages>920-925</pages>
      <abstract>This paper describes Nvidia-Nemo’s WMT 2025 Metrics Shared Task submission. We investigated two strategies for extending Machine Translation (MT) evaluation to unsegmented documents: 1) first segmenting into sentences and then applying regression-based metrics and 2) directly utilizing the long-context capabilities of LLMs. The base comparison of the segmentation-based and LLM-based metrics on the WMT 2023-24 evaluation sets indicated that the former performs more robustly across language pairs.Thus we sought to improve the LLM-based approach by incorporating relative evaluation - this setting jointly evaluates all candidate translations at once and relative to each other, rather than evaluating each separately. Our experiments using the open-source Qwen3 LLM show that relative evaluation improves score correlations with human judgment, but only if the task is structured as a 2-stage evaluate-then-refine problem.</abstract>
      <url hash="7adc4baa">2025.wmt-1.66</url>
      <bibkey>yan-etal-2025-nvidia</bibkey>
      <doi>10.18653/v1/2025.wmt-1.66</doi>
    </paper>
    <paper id="67">
      <title><fixed-case>GEMBA</fixed-case> V2: Ten Judgments Are Better Than One</title>
      <author><first>Marcin</first><last>Junczys-Dowmunt</last><affiliation>Microsoft</affiliation></author>
      <pages>926-933</pages>
      <abstract>We introduce GEMBA-MQM V2, an MQM-inspired, reference-free LLM evaluation metric for the WMT25 Metrics Shared Task (Subtask 1). Building on GEMBA/GEMBA-MQM, we prompt GPT-4.1-mini to produce structured MQM error annotations per segment. We map annotations to scores with 25/5/1 severity weights (minor punctuation = 0.1). To reduce stochastic variance, each segment is scored ten times and aggregated with a reciprocal-rank weighted average (RRWA) after removing outliers beyond <tex-math>2\sigma</tex-math>. On the WMT24 MQM test sets, GEMBA-MQM V2 ranks first by average correlation, with strong results across languages and evaluation levels; WMT23 results show comparable performance.</abstract>
      <url hash="3617e47e">2025.wmt-1.67</url>
      <bibkey>junczys-dowmunt-2025-gemba</bibkey>
      <doi>10.18653/v1/2025.wmt-1.67</doi>
    </paper>
    <paper id="68">
      <title><fixed-case>CUNI</fixed-case> and Phrase at <fixed-case>WMT</fixed-case>25 <fixed-case>MT</fixed-case> Evaluation Task</title>
      <author><first>Miroslav</first><last>Hrabal</last><affiliation>Charles University</affiliation></author>
      <author><first>Ondrej</first><last>Glembek</last><affiliation>Phrase a.s.</affiliation></author>
      <author><first>Aleš</first><last>Tamchyna</last><affiliation>Memsource</affiliation></author>
      <author id="almut-silja-hildebrand"><first>Almut Silja</first><last>Hildebrand</last><affiliation>Amazon</affiliation></author>
      <author><first>Alan</first><last>Eckhard</last><affiliation>Phrase a.s.</affiliation></author>
      <author><first>Miroslav</first><last>Štola</last><affiliation>Phrase a.s.</affiliation></author>
      <author><first>Sergio</first><last>Penkale</last><affiliation>Phrase a.s.</affiliation></author>
      <author><first>Zuzana</first><last>Šimečková</last><affiliation>Phrase a.s.</affiliation></author>
      <author id="ondrej-bojar"><first>Ondřej</first><last>Bojar</last><affiliation>Charles University, MFF UFAL</affiliation></author>
      <author id="alon-lavie"><first>Alon</first><last>Lavie</last><affiliation>Phrase a.s.</affiliation></author>
      <author><first>Craig</first><last>Stewart</last><affiliation>Phrase a.s.</affiliation></author>
      <pages>934-944</pages>
      <abstract>This paper describes the joint effort of Phrase a.s. and Charles University’sInstitute of Formal and Applied Linguistics (CUNI/UFAL) on the WMT25Automated Translation Quality Evaluation Systems Shared Task. Both teamsparticipated both in a collaborative and competitive manner, i.e. they eachsubmitted a system of their own as well as a contrastive joint system ensemble.In Task~1, we show that such an ensembling—if chosen in a clever way—canlead to a performance boost. We present the analysis of various kinds ofsystems comprising both “traditional” NN-based approach, as well as differentflavours of LLMs—off-the-shelf commercial models, their fine-tuned versions,but also in-house, custom-trained alternative models. In Tasks~2 and~3 we showPhrase’s approach to tackling the tasks via various GPT models: Error SpanAnnotation via the complete MQM solution using non-reasoning models (includingfine-tuned versions) in Task~2, and using reasoning models in Task~3.</abstract>
      <url hash="46559661">2025.wmt-1.68</url>
      <bibkey>hrabal-etal-2025-cuni</bibkey>
      <doi>10.18653/v1/2025.wmt-1.68</doi>
    </paper>
    <paper id="69">
      <title><fixed-case>MSLC</fixed-case>25: Metric Performance on Low-Quality Machine Translation, Empty Strings, and Language Variants</title>
      <author><first>Rebecca</first><last>Knowles</last><affiliation>National Research Council Canada</affiliation></author>
      <author><first>Samuel</first><last>Larkin</last><affiliation>National Research Council Canada</affiliation></author>
      <author><first>Chi-Kiu</first><last>Lo</last><affiliation>National Research Council of Canada</affiliation></author>
      <pages>945-956</pages>
      <abstract>In this challenge set, we examine how automatic metrics for machine translation perform on a wide variety of machine translation output, covering a wider range of quality than the WMT submissions. We also explore metric results on specific types of corner cases, such as empty strings, wrong- or mixed-language text, and more. We primarily focus on Japanese–Chinese data, with some work on English and Czech.</abstract>
      <url hash="ad672f5e">2025.wmt-1.69</url>
      <bibkey>knowles-etal-2025-mslc25</bibkey>
      <doi>10.18653/v1/2025.wmt-1.69</doi>
    </paper>
    <paper id="70">
      <title><fixed-case>M</fixed-case>etric<fixed-case>X</fixed-case>-25 and <fixed-case>G</fixed-case>em<fixed-case>S</fixed-case>pan<fixed-case>E</fixed-case>val: <fixed-case>G</fixed-case>oogle <fixed-case>T</fixed-case>ranslate Submissions to the <fixed-case>WMT</fixed-case>25 Evaluation Shared Task</title>
      <author><first>Juraj</first><last>Juraska</last><affiliation>Google</affiliation></author>
      <author><first>Tobias</first><last>Domhan</last><affiliation>Google</affiliation></author>
      <author><first>Mara</first><last>Finkelstein</last><affiliation>Google</affiliation></author>
      <author><first>Tetsuji</first><last>Nakagawa</last><affiliation>Google LLC</affiliation></author>
      <author><first>Geza</first><last>Kovacs</last><affiliation>Google</affiliation></author>
      <author><first>Daniel</first><last>Deutsch</last><affiliation>Google</affiliation></author>
      <author><first>Pidong</first><last>Wang</last><affiliation>Google</affiliation></author>
      <author><first>Markus</first><last>Freitag</last><affiliation>Google Research</affiliation></author>
      <pages>957-968</pages>
      <abstract>In this paper, we present our submissions to the unified WMT25 Translation Evaluation Shared Task. For the Quality Score Prediction subtask, we create a new generation of MetricX with improvements in the input format and the training protocol, while for the Error Span Detection subtask we develop a new model, GemSpanEval, trained to predict error spans along with their severities and categories. Both systems are based on the state-of-the-art multilingual open-weights model Gemma 3, fine-tuned on publicly available WMT data. We demonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture with a regression head on top, can be trained to effectively predict both MQM and ESA quality scores, and significantly outperforms its predecessor. Our decoder-only GemSpanEval model, on the other hand, we show to be competitive in error span detection with xCOMET, a strong encoder-only sequence-tagging baseline. With error span detection formulated as a generative task, we instruct the model to also output the context for each predicted error span, thus ensuring that error spans are identified unambiguously.</abstract>
      <url hash="a477da4d">2025.wmt-1.70</url>
      <bibkey>juraska-etal-2025-metricx</bibkey>
      <doi>10.18653/v1/2025.wmt-1.70</doi>
    </paper>
    <paper id="71">
      <title><fixed-case>HW</fixed-case>-<fixed-case>TSC</fixed-case>’s Submissions to the <fixed-case>WMT</fixed-case> 2025 Segment-level Quality Score Prediction Task</title>
      <author><first>Yuanchang</first><last>Luo</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Jiaxin</first><last>Guo</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Daimeng</first><last>Wei</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Hengchao</first><last>Shang</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Zongyao</first><last>Li</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Zhiqiang</first><last>Rao</last><affiliation>Huawei Translation Service Center, Beijing, China</affiliation></author>
      <author><first>Jinlong</first><last>Yang</last><affiliation>Huawei Technologies Co., Ltd</affiliation></author>
      <author><first>Zhanglin</first><last>Wu</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Xiaoyu</first><last>Chen</last><affiliation>Huawei Translation Service Center, Beijing, China</affiliation></author>
      <author><first>Hao</first><last>Yang</last><affiliation>Huawei Co. Ltd</affiliation></author>
      <pages>969-973</pages>
      <abstract>This paper presents the submissions of Huawei Translate Services Center (HW-TSC) to the WMT 2025 Segment-level quality score prediction Task. We participate in 16 language pairs. For the prediction of translation quality scores for long multi-sentence text units, we propose an automatic evaluation framework based on alignment algorithms. Our approach integrates sentence segmentation tools and dynamic programming to construct sentence-level alignments between source and translated texts, then adapts sentence-level evaluation models to document-level assessment via sliding-window aggregation. Our submissions achieved competitive results in the final evaluations of all language pairs we participated in.</abstract>
      <url hash="bfe30c7f">2025.wmt-1.71</url>
      <bibkey>luo-etal-2025-hw</bibkey>
      <doi>10.18653/v1/2025.wmt-1.71</doi>
    </paper>
    <paper id="72">
      <title><fixed-case>U</fixed-case>v<fixed-case>A</fixed-case>-<fixed-case>MT</fixed-case> at <fixed-case>WMT</fixed-case>25 Evaluation Task: <fixed-case>LLM</fixed-case> Uncertainty as a Proxy for Translation Quality</title>
      <author><first>Di</first><last>Wu</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Christof</first><last>Monz</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>974-983</pages>
      <abstract>This year, we focus exclusively on using the uncertainty quantification as a proxy for translation quality. While this has traditionally been regarded as a form of unsupervised quality estimation, such signals have been overlooked in the design of the current metric models—we show their value in the context of LLMs. More specifically, in contrast to conventional unsupervised QE methods, we apply recent calibration technology to adjust translation likelihoods to better align with quality signals, and we use the single resulting model to participate in both the general translation and QE tracks at WMT25.Our offline experiments show some advantages: 1) uncertainty signals extracted from LLMs, like Tower or Gemma-3, provide accurate quality predictions; and 2) calibration technology further improves this QE performance, sometimes even surpassing certain metric models that were trained with human annotations, such as CometKiwi. We therefore argue that uncertainty quantification (confidence), especially from LLMs, can serve as a strong and complementary signal for the metric design, particularly when human-annotated data are lacking. However, we also identify limitations, such as its tendency to assign disproportionately higher scores to hypotheses generated by the model itself.</abstract>
      <url hash="4a5402fb">2025.wmt-1.72</url>
      <bibkey>wu-monz-2025-uva</bibkey>
      <doi>10.18653/v1/2025.wmt-1.72</doi>
    </paper>
    <paper id="73">
      <title>Submission for <fixed-case>WMT</fixed-case>25 Task 3</title>
      <author><first>Govardhan</first><last>Padmanabhan</last><affiliation>None</affiliation></author>
      <pages>984-993</pages>
      <abstract>The paper presents two approaches submitted to the WMT 2025 Automated Translation Quality Evaluation Systems Task 3 - Quality Estimation (QE)-informed Segment-level Error Correction. While jointly training QE systems with Automatic Post-Editing (APE) has shown improved performance for both tasks, APE systems are still known to overcorrect the output of Machine Translation (MT), leading to a degradation in performance. We investigate a simple training-free approach - QE-informed Retranslation, and compare it with another within the same training-free paradigm. Our winning approach selects the highest-quality translation from multiple candidates generated by different LLMs. The second approach, more akin to APE, instructs an LLM to replace error substrings as specified in the provided QE explanation(s). A conditional heuristic was employed to minimise the number of edits, with the aim of maximising the Gain-to-Edit ratio. The two proposed approaches achieved a ∆COMET scoreof 0.0201 and −0.0108, respectively, leading the first approach to achieve the winning position on the subtask leaderboard.</abstract>
      <url hash="2a55dcb8">2025.wmt-1.73</url>
      <bibkey>padmanabhan-2025-submission</bibkey>
      <doi>10.18653/v1/2025.wmt-1.73</doi>
    </paper>
    <paper id="74">
      <title><fixed-case>R</fixed-case>anked<fixed-case>COMET</fixed-case>: Elevating a 2022 Baseline to a Top-5 Finish in the <fixed-case>WMT</fixed-case> 2025 <fixed-case>QE</fixed-case> Task</title>
      <author><first>Sujal</first><last>Maharjan</last><affiliation>IIMS College</affiliation></author>
      <author><first>Astha</first><last>Shrestha</last><affiliation>IIMS college</affiliation></author>
      <pages>994-998</pages>
      <abstract>This paper presents rankedCOMET, a lightweight per-language-pair calibration applied to the publicly available Unbabel/wmt22-comet-da model that yields a competitive Quality Estimation (QE) system for the WMT 2025 shared task. This approach transforms raw model outputs into per-language average ranks and min–max normalizes those ranks to [0,1], maintaining intra-language ordering while generating consistent numeric ranges across language pairs. Applied to 742,740 test segments and submitted to Codabench, this unsupervised post-processing enhanced the aggregated Pearson correlation on the preliminary snapshot and led to a 5th-place finish. We provide detailed pseudocode, ablations (including a negative ensemble attempt), and a reproducible analysis pipeline providing Pearson, Spearman, and Kendall correlations with bootstrap confidence intervals.</abstract>
      <url hash="67068851">2025.wmt-1.74</url>
      <bibkey>maharjan-shrestha-2025-rankedcomet</bibkey>
      <doi>10.18653/v1/2025.wmt-1.74</doi>
    </paper>
    <paper id="75">
      <title>Quality-Informed Segment-Level Error Correction Using Natural Language Explanations from x<fixed-case>T</fixed-case>ower and Large Language Models</title>
      <author><first>Prashant</first><last>Sharma</last><affiliation>University Of Surrey</affiliation></author>
      <pages>999-1003</pages>
      <abstract>This paper describes our submission to the WMT25 Automated Translation Quality Evaluation Systems Task 3 - QE-informed Segment-level Error Correction. We propose a two-step approach for Automatic Post-Editing (APE) that leverages natural language explanations of translation errors. Our method first utilises the xTower model to generate a descriptive explanation of the errors present in a machine-translated segment, given the source text, the machine translation, and quality estimation annotations. This explanation is then provided as a prompt to a powerful Large Language Model, Gemini 1.5 Pro, which generates the final, corrected translation. This approach is inspired by recent work in edit-based APE and aims to improve the interpretability and performance of APE systems. We Evaluated across six language pairs (EN→ZH, EN→CS, EN→IS, EN→JA, EN→RU, EN→UK), our approach demonstrates promising results, especially in cases requiring fine-grained edits.</abstract>
      <url hash="98de3eef">2025.wmt-1.75</url>
      <bibkey>sharma-2025-quality</bibkey>
      <doi>10.18653/v1/2025.wmt-1.75</doi>
    </paper>
    <paper id="76">
      <title><fixed-case>TASER</fixed-case>: Translation Assessment via Systematic Evaluation and Reasoning</title>
      <author><first>Monishwaran</first><last>Maheswaran</last><affiliation>UC Berkeley</affiliation></author>
      <author><first>Marco</first><last>Carini</last><affiliation>Apple Inc.</affiliation></author>
      <author><first>Christian</first><last>Federmann</last><affiliation>Apple Inc.</affiliation></author>
      <author><first>Tony</first><last>Diaz</last><affiliation>Apple Inc.</affiliation></author>
      <pages>1004-1010</pages>
      <abstract>We introduce TASER (Translation Assessment via Systematic Evaluation and Reasoning), a metric that uses Large Reasoning Models (LRMs) for automated translation quality assessment. TASER harnesses the explicit reasoning capabilities of LRMs to conduct systematic, step-by-step evaluation of translation quality. We evaluate TASER on the WMT24 Metrics Shared Task across both reference-based and reference-free scenarios, demonstrating state-of-the-art performance. In system-level evaluation, TASER achieves the highest soft pairwise accuracy in both reference-based and reference-free settings, outperforming all existing metrics. At the segment level, TASER maintains competitive performance with our reference-free variant ranking as the top-performing metric among all reference-free approaches. Our experiments reveal that structured prompting templates yield superior results with LRMs compared to the open-ended approaches that proved optimal for traditional LLMs. We evaluate o3, a large reasoning model from OpenAI, with varying reasoning efforts, providing insights into the relationship between reasoning depth and evaluation quality. The explicit reasoning process in LRMs offers interpretability and visibility, addressing a key limitation of existing automated metrics. Our results demonstrate that Large Reasoning Models show a measurable advancement in translation quality assessment, combining improved accuracy with transparent evaluation across diverse language pairs.</abstract>
      <url hash="ca6ce6b9">2025.wmt-1.76</url>
      <bibkey>maheswaran-etal-2025-taser</bibkey>
      <doi>10.18653/v1/2025.wmt-1.76</doi>
    </paper>
    <paper id="77">
      <title>Vicomtech@<fixed-case>WMT</fixed-case> 2025: Evolutionary Model Compression for Machine Translation</title>
      <author><first>David</first><last>Ponce</last><affiliation>Vicomtech</affiliation></author>
      <author><first>Harritxu</first><last>Gete</last><affiliation>Vicomtech</affiliation></author>
      <author><first>Thierry</first><last>Etchegoyhen</last><affiliation>Vicomtech</affiliation></author>
      <pages>1011-1021</pages>
      <abstract>We describe Vicomtech’s participation in the WMT 2025 Shared Task on Model Compression. We addressed all three language pairs of the constrained task, namely Czech to German, English to Arabic and Japanese to Chinese, using the Aya Expanse 8B model as our base model. Our approach centers on GeLaCo, an evolutionary method for LLM compression via layer collapse operations, which efficiently explores the compression solution space through population-based search and a module-wise similarity fitness function that captures attention, feed-forward, and hidden state representations. We systematically evaluated compression at three different ratios (0.25, 0.50, and 0.75) and applied targeted post-training techniques to recover performance through fine-tuning and knowledge distillation over translation instructions. Additionally, we explored quantization techniques to achieve further model size reduction. Our experimental results demonstrate that the combination of evolutionary layer compression, targeted post-training, and quantization can achieve substantial model size reduction while maintaining competitive translation quality across all language pairs.</abstract>
      <url hash="ed9bf5e9">2025.wmt-1.77</url>
      <bibkey>ponce-etal-2025-vicomtech</bibkey>
      <doi>10.18653/v1/2025.wmt-1.77</doi>
    </paper>
    <paper id="78">
      <title>Iterative Layer Pruning for Efficient Translation Inference</title>
      <author><first>Yasmin</first><last>Moslem</last><affiliation>ADAPT Centre, Trinity College Dublin</affiliation></author>
      <author><first>Muhammad Hazim</first><last>Al Farouq</last><affiliation>Kreasof AI</affiliation></author>
      <author id="john-kelleher"><first>John</first><last>Kelleher</last><affiliation>ADAPT Centre, Trinity College Dublin</affiliation></author>
      <pages>1022-1027</pages>
      <abstract>Large language models (LLMs) have transformed many areas of natural language processing, including machine translation. However, efficient deployment of LLMs remains challenging due to their intensive computational requirements. In this paper, we address this challenge and present our submissions to the Model Compression track at the Conference on Machine Translation (WMT 2025). In our experiments, we investigate iterative layer pruning guided by layer importance analysis. We evaluate this method using the Aya-Expanse-8B model for translation from Czech to German, and from English to Egyptian Arabic. Our approach achieves substantial reductions in model size and inference time, while maintaining the translation quality of the baseline models.</abstract>
      <url hash="735d422b">2025.wmt-1.78</url>
      <bibkey>moslem-etal-2025-iterative</bibkey>
      <doi>10.18653/v1/2025.wmt-1.78</doi>
    </paper>
    <paper id="79">
      <title>Expanding the <fixed-case>WMT</fixed-case>24++ Benchmark with Rumantsch Grischun, Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader</title>
      <author><first>Jannis</first><last>Vamvas</last><affiliation>Department of Computational Linguistics, University of Zurich</affiliation></author>
      <author><first>Ignacio</first><last>Pérez Prat</last><affiliation>Lia Rumantscha</affiliation></author>
      <author><first>Not</first><last>Soliva</last><affiliation>University of Zurich</affiliation></author>
      <author><first>Sandra</first><last>Baltermia-Guetg</last><affiliation>Lia Rumantscha</affiliation></author>
      <author><first>Andrina</first><last>Beeli</last><affiliation>Lia Rumantscha</affiliation></author>
      <author><first>Simona</first><last>Beeli</last><affiliation>Lia Rumantscha</affiliation></author>
      <author><first>Madlaina</first><last>Capeder</last><affiliation>Lia Rumantscha</affiliation></author>
      <author><first>Laura</first><last>Decurtins</last><affiliation>Lia Rumantscha</affiliation></author>
      <author><first>Gian Peder</first><last>Gregori</last><affiliation>Lia Rumantscha</affiliation></author>
      <author><first>Flavia</first><last>Hobi</last><affiliation>Lia Rumantscha</affiliation></author>
      <author><first>Gabriela</first><last>Holderegger</last><affiliation>Lia Rumantscha</affiliation></author>
      <author><first>Arina</first><last>Lazzarini</last><affiliation>Lia Rumantscha</affiliation></author>
      <author><first>Viviana</first><last>Lazzarini</last><affiliation>Lia Rumantscha</affiliation></author>
      <author><first>Walter</first><last>Rosselli</last><affiliation>Lia Rumantscha</affiliation></author>
      <author><first>Bettina</first><last>Vital</last><affiliation>Lia Rumantscha</affiliation></author>
      <author><first>Anna</first><last>Rutkiewicz</last><affiliation>University of Zurich</affiliation></author>
      <author><first>Rico</first><last>Sennrich</last><affiliation>University of Zurich</affiliation></author>
      <pages>1028-1047</pages>
      <abstract>The Romansh language, spoken in Switzerland, has limited resources for machine translation evaluation. In this paper, we present a benchmark for six varieties of Romansh: Rumantsch Grischun, a supra-regional variety, and five regional varieties: Sursilvan, Sutsilvan, Surmiran, Puter, and Vallader. Our reference translations were created by human translators based on the WMT24++ benchmark, which ensures parallelism with more than 55 other languages. An automatic evaluation of existing MT systems and LLMs shows that translation out of Romansh into German is handled relatively well for all the varieties, but translation into Romansh is still challenging.</abstract>
      <url hash="8a9cef44">2025.wmt-1.79</url>
      <bibkey>vamvas-etal-2025-expanding</bibkey>
      <doi>10.18653/v1/2025.wmt-1.79</doi>
    </paper>
    <paper id="80">
      <title>A <fixed-case>F</fixed-case>rench Version of the <fixed-case>OLDI</fixed-case> Seed Corpus</title>
      <author><first>Malik</first><last>Marmonier</last><affiliation>Inria</affiliation></author>
      <author id="benoit-sagot"><first>Benoît</first><last>Sagot</last><affiliation>Inria</affiliation></author>
      <author><first>Rachel</first><last>Bawden</last><affiliation>Inria</affiliation></author>
      <pages>1048-1060</pages>
      <abstract>We present the first French partition of the OLDI Seed Corpus, our submission to the WMT 2025 Open Language Data Initiative (OLDI) shared task. We detail its creation process, which involved using multiple machine translation systems and a custom-built interface for post-editing by qualified native speakers. We also highlight the unique translation challenges presented by the source data, which combines highly technical, encyclopedic terminology with the stylistic irregularities characteristic of user-generated content taken from Wikipedia. This French corpus is not an end in itself, but is intended as a crucial pivot resource to facilitate the collection of parallel corpora for the under-resourced regional languages of France.</abstract>
      <url hash="f1cabd27">2025.wmt-1.80</url>
      <bibkey>marmonier-etal-2025-french</bibkey>
      <doi>10.18653/v1/2025.wmt-1.80</doi>
    </paper>
    <paper id="81">
      <title>Bringing <fixed-case>L</fixed-case>adin to <fixed-case>FLORES</fixed-case>+</title>
      <author><first>Samuel</first><last>Frontull</last><affiliation>University of Innsbruck</affiliation></author>
      <author><first>Thomas</first><last>Ströhle</last><affiliation>University of Innsbruck</affiliation></author>
      <author><first>Carlo</first><last>Zoli</last><affiliation>Free University of Bozen-Bolzano</affiliation></author>
      <author><first>Werner</first><last>Pescosta</last><affiliation>Ladin Cultural Institute “Micurá de Rü”</affiliation></author>
      <author><first>Ulrike</first><last>Frenademez</last><affiliation>Ladin Cultural Institute “Micurá de Rü”</affiliation></author>
      <author><first>Matteo</first><last>Ruggeri</last><affiliation>Ladin Cultural Institute “Micurá de Rü”</affiliation></author>
      <author><first>Daria</first><last>Valentin</last><affiliation>Ladin Cultural Institute “Micurá de Rü”</affiliation></author>
      <author><first>Karin</first><last>Comploj</last><affiliation>Ladin Cultural Institute “Micurá de Rü”</affiliation></author>
      <author><first>Gabriel</first><last>Perathoner</last><affiliation>Ladin Cultural Institute “Micurá de Rü”</affiliation></author>
      <author><first>Silvia</first><last>Liotto</last><affiliation>Ladin Cultural Institute “Micurá de Rü”</affiliation></author>
      <author><first>Paolo</first><last>Anvidalfarei</last><affiliation>Ladin Cultural Institute “Micurá de Rü”</affiliation></author>
      <pages>1061-1071</pages>
      <abstract>Recent advances in neural machine translation (NMT) have opened new possibilities for developing translation systems also for smaller, so-called low-resource, languages. The rise of large language models (LLMs) has further revolutionized machine translation by enabling more flexible and context-aware generation. However, many challenges remain for low-resource languages, and the availability of high-quality, validated test data is essential to support meaningful development, evaluation, and comparison of translation systems. In this work, we present an extension of the FLORES+ dataset for two Ladin variants, Val Badia and Gherdëina, as a submission to the Open Language Data Initiative Shared Task 2025. To complement existing resources, we additionally release two parallel datasets for Gherdëina–Val Badia and Gherdëina–Italian. We validate these datasets by evaluating state-of-the-art LLMs and NMT systems on this test data, both with and without leveraging the newly released parallel data for fine-tuning and prompting. The results highlight the considerable potential for improving translation quality in Ladin, while also underscoring the need for further research and resource development, for which this contribution provides a basis.</abstract>
      <url hash="abfd3cdd">2025.wmt-1.81</url>
      <bibkey>frontull-etal-2025-bringing</bibkey>
      <doi>10.18653/v1/2025.wmt-1.81</doi>
    </paper>
    <paper id="82">
      <title>Correcting the Tamazight Portions of <fixed-case>FLORES</fixed-case>+ and <fixed-case>OLDI</fixed-case> Seed Datasets</title>
      <author><first>Alp</first><last>Oktem</last><affiliation>CLEAR Global</affiliation></author>
      <author><first>Mohamed Aymane</first><last>Farhi</last><affiliation>Tamazight NLP</affiliation></author>
      <author><first>Brahim</first><last>Essaidi</last><affiliation>Freelance Translator</affiliation></author>
      <author><first>Naceur</first><last>Jabouja</last><affiliation>Freelance Translator</affiliation></author>
      <author><first>Farida</first><last>Boudichat</last><affiliation>Awal Team</affiliation></author>
      <pages>1072-1080</pages>
      <abstract>We present the manual correction of the Tamazight portions of the FLORES+ and OLDI Seed datasets to improve the quality of open machine translation resources for the language. These widely used reference corpora contained numerous issues, including mistranslations, orthographic inconsistencies, overuse of loanwords, and non-standard transliterations. Overall, 36% of FLORES+ and 40% of Seed sentences were corrected by expert linguists, with average token divergence of 19% and 25% among changed items. Evaluation of multiple MT systems, including NLLB models and commercial LLM services, showed consistent gains in automated evaluation metrics when using the corrected data. Fine-tuning NLLB-600M on the revised Seed corpus yielded improvements of +6.05 chrF (en→zgh) and +2.32 (zgh→en), outperforming larger parameter models and LLM providers in en→zgh direction.</abstract>
      <url hash="da0b0bd1">2025.wmt-1.82</url>
      <bibkey>oktem-etal-2025-correcting</bibkey>
      <doi>10.18653/v1/2025.wmt-1.82</doi>
    </paper>
    <paper id="83">
      <title>Filling the Gap for <fixed-case>U</fixed-case>zbek: Creating Translation Resources for <fixed-case>S</fixed-case>outhern <fixed-case>U</fixed-case>zbek</title>
      <author><first>Mukhammadsaid</first><last>Mamasaidov</last><affiliation>Tahrirchi</affiliation></author>
      <author><first>Azizullah</first><last>Aral</last><affiliation>Academy of Sciences of Afghanistan</affiliation></author>
      <author><first>Abror</first><last>Shopulatov</last><affiliation>Tahrirchi, MBZUAI</affiliation></author>
      <author><first>Mironshoh</first><last>Inomjonov</last><affiliation>Tahrirchi</affiliation></author>
      <pages>1081-1087</pages>
      <abstract>Southern Uzbek (uzs) is a Turkic language variety spoken by around 5 million people in Afghanistan and differs significantly from Northern Uzbek (uzn) in phonology, lexicon, and orthography. Despite the large number of speakers, Southern Uzbek is underrepresented in natural language processing. We present new resources for Southern Uzbek machine translation, including a 997-sentence FLORES+ dev set, 39,994 parallel sentences from dictionary, literary, and web sources, and a fine-tuned NLLB-200 model (lutfiy). We also propose a post-processing method for restoring Arabic-script half-space characters, which improves handling of morphological boundaries. All datasets, models, and tools are released publicly to support future work on Southern Uzbek and other low-resource languages.</abstract>
      <url hash="28323c2b">2025.wmt-1.83</url>
      <bibkey>mamasaidov-etal-2025-filling</bibkey>
      <doi>10.18653/v1/2025.wmt-1.83</doi>
    </paper>
    <paper id="84">
      <title>The <fixed-case>K</fixed-case>yrgyz Seed Dataset Submission to the <fixed-case>WMT</fixed-case>25 Open Language Data Initiative Shared Task</title>
      <author><first>Murat</first><last>Jumashev</last><affiliation>Independent researcher</affiliation></author>
      <author><first>Alina</first><last>Tillabaeva</last><affiliation>Independent researcher</affiliation></author>
      <author><first>Aida</first><last>Kasieva</last><affiliation>Kyrgyz-Turkish Manas University</affiliation></author>
      <author><first>Turgunbek</first><last>Omurkanov</last><affiliation>Independent researcher</affiliation></author>
      <author><first>Akylai</first><last>Musaeva</last><affiliation>Kyrgyz-Turkish Manas University</affiliation></author>
      <author><first>Meerim</first><last>Emil Kyzy</last><affiliation>Independent researcher</affiliation></author>
      <author><first>Gulaiym</first><last>Chagataeva</last><affiliation>Independent researcher</affiliation></author>
      <author id="jonathan-washington"><first>Jonathan</first><last>Washington</last><affiliation>Swarthmore College</affiliation></author>
      <pages>1088-1102</pages>
      <abstract>We present a Kyrgyz language seed dataset as part of our contribution to the WMT25 Open Language Data Initiative (OLDI) shared task. This paper details the process of collecting and curating English–Kyrgyz translations, highlighting the main challenges encountered in translating into a morphologically rich, low-resource language. We demonstrate the quality of the dataset through fine-tuning experiments, showing consistent improvements in machine translation performance across multiple models. Comparisons with bilingual and MNMT Kyrgyz-English baselines reveal that, for some models, our dataset enables performance surpassing pretrained baselines in both English–Kyrgyz and Kyrgyz–English translation directions. These results validate the dataset’s utility and suggest that it can serve as a valuable resource for the Kyrgyz MT community and other related low-resource languages.</abstract>
      <url hash="1d7a401e">2025.wmt-1.84</url>
      <bibkey>jumashev-etal-2025-kyrgyz</bibkey>
      <doi>10.18653/v1/2025.wmt-1.84</doi>
    </paper>
    <paper id="85">
      <title><fixed-case>SMOL</fixed-case>: Professionally Translated Parallel Data for 115 Under-represented Languages</title>
      <author><first>Isaac</first><last>Caswell</last><affiliation>Google Research</affiliation></author>
      <author><first>Elizabeth</first><last>Nielsen</last><affiliation>Google</affiliation></author>
      <author><first>Jiaming</first><last>Luo</last><affiliation>Google</affiliation></author>
      <author><first>Colin</first><last>Cherry</last><affiliation>Google</affiliation></author>
      <author><first>Geza</first><last>Kovacs</last><affiliation>Google</affiliation></author>
      <author><first>Hadar</first><last>Shemtov</last><affiliation>Google Deepmind</affiliation></author>
      <author id="partha-talukdar"><first>Partha</first><last>Talukdar</last><affiliation>Google Research and IISc</affiliation></author>
      <author><first>Dinesh</first><last>Tewari</last><affiliation>Google</affiliation></author>
      <author><first>Baba Mamadi</first><last>Diane</last><affiliation>NKO USA INC</affiliation></author>
      <author><first>Djibrila</first><last>Diane</last><affiliation>NKO USA INC</affiliation></author>
      <author><first>Solo Farabado</first><last>Cissé</last><affiliation>NKO USA INC</affiliation></author>
      <author><first>Koulako Moussa</first><last>Doumbouya</last><affiliation>Stanford University</affiliation></author>
      <author><first>Edoardo</first><last>Ferrante</last><affiliation>Conseggio pe-o patrimonio linguistico ligure</affiliation></author>
      <author><first>Alessandro</first><last>Guasoni</last><affiliation>Conseggio pe-o patrimonio linguistico ligure</affiliation></author>
      <author><first>Christopher</first><last>Homan</last></author>
      <author><first>Mamadou K.</first><last>Keita</last><affiliation>Paair Institute</affiliation></author>
      <author><first>Sudhamoy</first><last>DebBarma</last><affiliation>NIT, Arunachal Pradesh</affiliation></author>
      <author><first>Ali</first><last>Kuzhuget</last><affiliation>tyvan.ru</affiliation></author>
      <author><first>David</first><last>Anugraha</last><affiliation>Stanford University</affiliation></author>
      <author><first>Muhammad Ravi</first><last>Shulthan Habibi</last><affiliation>Universitas Indonesia</affiliation></author>
      <author><first>Sina</first><last>Ahmadi</last><affiliation>University of Zurich</affiliation></author>
      <author><first>Anthony</first><last>Munthali</last></author>
      <author><first>Jonathan Mingfei</first><last>Liu</last><affiliation>Google</affiliation></author>
      <author><first>Jonathan</first><last>Eng</last><affiliation>Google</affiliation></author>
      <pages>1103-1123</pages>
      <abstract>We open-source SMOL (Set of Maximal Over-all Leverage), a suite of training data to un-lock machine translation for low-resource languages (LRLs). SMOL has been translated into123 under-resourced languages (125 language pairs), including many for which there exist no previous public resources, for a total of 6.1M translated tokens. SMOL comprises two sub-datasets, each carefully chosen for maximum impact given its size: SMOLSENT, a set of sentences chosen for broad unique token coverage, and SMOLDOC, a document-level source focusing on a broad topic coverage. They join the already released GATITOS for a trifecta of paragraph, sentence, and token-level content. We demonstrate that using SMOL to prompt or fine-tune Large Language Models yields robust chrF improvements. In addition to translation, we provide factuality ratings and rationales for all documents in SMOLDOC, yielding the first factuality datasets for most of these languages.</abstract>
      <url hash="b069adea">2025.wmt-1.85</url>
      <bibkey>caswell-etal-2025-smol</bibkey>
      <doi>10.18653/v1/2025.wmt-1.85</doi>
    </paper>
    <paper id="86">
      <title>Improved <fixed-case>N</fixed-case>orwegian <fixed-case>B</fixed-case>okmål Translations for <fixed-case>FLORES</fixed-case></title>
      <author><first>Petter</first><last>Mæhlum</last><affiliation>University of Oslo</affiliation></author>
      <author><first>Anders</first><last>Næss Evensen</last><affiliation>Disputas AS</affiliation></author>
      <author><first>Yves</first><last>Scherrer</last><affiliation>University of Oslo</affiliation></author>
      <pages>1124-1132</pages>
      <abstract>FLORES+ is a collection of parallel datasets obtained by translation from originally English source texts. FLORES+ contains Norwegian translations for the two official written variants of Norwegian: Norwegian Bokmål and Norwegian Nynorsk. However, the earliest Bokmål version contained non-native-like mistakes, and even after a later revision, the dataset contained grammatical and lexical errors. This paper aims at correcting unambiguous mistakes, and thus creating a new version of the Bokmål dataset. At the same time, we provide a translation into Radical Bokmål, a sub-variety of Norwegian which is closer to Nynorsk in some aspects, while still being within the official norms for Bokmål. We discuss existing errors and differences in the various translations and the corrections that we provide.</abstract>
      <url hash="5a589130">2025.wmt-1.86</url>
      <bibkey>maehlum-etal-2025-improved</bibkey>
      <doi>10.18653/v1/2025.wmt-1.86</doi>
    </paper>
    <paper id="87">
      <title><fixed-case>NRC</fixed-case> Systems for the <fixed-case>WMT</fixed-case>2025-<fixed-case>LRSL</fixed-case> Shared Task</title>
      <author><first>Samuel</first><last>Larkin</last><affiliation>National Research Council Canada</affiliation></author>
      <author><first>Chi-Kiu</first><last>Lo</last><affiliation>National Research Council of Canada</affiliation></author>
      <author><first>Rebecca</first><last>Knowles</last><affiliation>National Research Council Canada</affiliation></author>
      <pages>1133-1142</pages>
      <abstract>We describe the NRC team systems for the WMT25 Shared Tasks on Large Language Models (LLMs) with Limited Resources for Slavic Languages. We participate in the Lower Sorbian and Upper Sorbian Machine Translation and Question Answering tasks. On the machine translation tasks, our primary focus, our systems rank first according to the automatic MT evaluation metric (chrF). Our systems underperform on the QA tasks.</abstract>
      <url hash="ef372a9a">2025.wmt-1.87</url>
      <bibkey>larkin-etal-2025-nrc</bibkey>
      <doi>10.18653/v1/2025.wmt-1.87</doi>
    </paper>
    <paper id="88">
      <title><fixed-case>T</fixed-case>artu<fixed-case>NLP</fixed-case> at <fixed-case>WMT</fixed-case>25 <fixed-case>LLM</fixed-case>s with Limited Resources for <fixed-case>S</fixed-case>lavic Languages Shared Task</title>
      <author><first>Taido</first><last>Purason</last><affiliation>University of Tartu</affiliation></author>
      <author><first>Mark</first><last>Fishel</last><affiliation>University of Tartu</affiliation></author>
      <pages>1143-1150</pages>
      <abstract>This paper describes the TartuNLP submission to the Upper Sorbian (hsb) and Lower Sorbian (dsb) tracks of the WMT25 LLMs with Limited Resources for Slavic Languages shared task, which jointly targets machine translation (MT) and question answering (QA). We develop a single multilingual model based on Qwen2.5-3B-Instruct by continuing pretraining on Sorbian monolingual and parallel data together with general instruction datasets, combining language acquisition and instruction-following in a single step. The resulting model delivers substantial improvements over the baseline Qwen2.5-3B-Instruct model and also achieves the highest ranking for both tasks in the hsb and dsb shared task tracks.</abstract>
      <url hash="ed2d3fa9">2025.wmt-1.88</url>
      <bibkey>purason-fishel-2025-tartunlp</bibkey>
      <doi>10.18653/v1/2025.wmt-1.88</doi>
    </paper>
    <paper id="89">
      <title><fixed-case>JGU</fixed-case> Mainz’s Submission to the <fixed-case>WMT</fixed-case>25 Shared Task on <fixed-case>LLM</fixed-case>s with Limited Resources for <fixed-case>S</fixed-case>lavic Languages: <fixed-case>MT</fixed-case> and <fixed-case>QA</fixed-case></title>
      <author><first>Hossain Shaikh</first><last>Saadi</last><affiliation>Johannes Gutenberg University Mainz</affiliation></author>
      <author><first>Minh Duc</first><last>Bui</last><affiliation>University of Mainz</affiliation></author>
      <author><first>Mario</first><last>Sanz-Guerrero</last><affiliation>Johannes Gutenberg University Mainz</affiliation></author>
      <author><first>Katharina</first><last>Von Der Wense</last><affiliation>University of Colorado Boulder</affiliation></author>
      <pages>1151-1157</pages>
      <abstract>This paper presents the JGU Mainz submission to the WMT25 Shared Task on LLMs with Limited Resources for Slavic Languages: Machine Translation and Question Answering, focusing on Ukrainian, Upper Sorbian, and Lower Sorbian. For each language, we jointly fine-tune a Qwen2.5-3B-Instruct model for both tasks with parameter-efficient finetuning. Our pipeline integrates additional translation and multiple-choice question answering (QA) data. For Ukrainian QA, we further use retrieval-augmented generation. We also apply ensembling for QA in Upper and Lower Sorbian. Experiments show that our models outperform the baseline on both tasks.</abstract>
      <url hash="004e1d0d">2025.wmt-1.89</url>
      <bibkey>saadi-etal-2025-jgu</bibkey>
      <doi>10.18653/v1/2025.wmt-1.89</doi>
    </paper>
    <paper id="90">
      <title>Krey-All <fixed-case>WMT</fixed-case> 2025 <fixed-case>C</fixed-case>reole<fixed-case>MT</fixed-case> System Description: Language Agnostic Strategies for Low-Resource Translation</title>
      <author><first>Ananya</first><last>Ayasi</last><affiliation>Carnegie Mellon University</affiliation></author>
      <pages>1158-1165</pages>
      <abstract>The paper is a submission to the WMT 2025 Creole MT Task, aimed at improving translation between Seychellois Creole and English by using data from other closely related Creole languages. The approach treats all Creoles as variations of the same language, allowing the model to share knowledge across them. This strategy led to better translation quality than using separate language settings. The work highlights that related languages can effectively support each other in low-resource settings, while also noting challenges such as data imbalance, differences in language domains, and the absence of human evaluation.</abstract>
      <url hash="65967822">2025.wmt-1.90</url>
      <bibkey>ayasi-2025-krey</bibkey>
      <doi>10.18653/v1/2025.wmt-1.90</doi>
    </paper>
    <paper id="91">
      <title><fixed-case>E</fixed-case>din<fixed-case>H</fixed-case>els<fixed-case>OW</fixed-case> <fixed-case>WMT</fixed-case> 2025 <fixed-case>C</fixed-case>reole<fixed-case>MT</fixed-case> System Description: Improving Lusophone Creole Translation through Data Augmentation, Model Merging and <fixed-case>LLM</fixed-case> Post-editing</title>
      <author><first>Jacqueline</first><last>Rowe</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Ona</first><last>De Gibert</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Mateusz</first><last>Klimaszewski</last><affiliation>Warsaw University of Technology</affiliation></author>
      <author><first>Coleman</first><last>Haley</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Alexandra</first><last>Birch</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Yves</first><last>Scherrer</last><affiliation>University of Oslo</affiliation></author>
      <pages>1166-1182</pages>
      <abstract>In this work, we present our submissions to the unconstrained track of the System subtask of the WMT 2025 Creole Language Translation Shared Task. Of the 52 Creole languages included in the task, we focus on translation between English and seven Lusophone Creoles. Our approach leverages known strategies for low-resource machine translation, including back-translation and distillation of data, fine-tuning pre-trained multilingual models, and post-editing with large language models and lexicons. We also demonstrate that adding high-quality parallel Portuguese data in training, initialising Creole embeddings with Portuguese embedding weights, and strategically merging best checkpoints of different fine-tuned models all produce considerable gains in performance in certain translation directions. Our best models outperform the baselines on the Task test set for eight out of fourteen translation directions. When evaluated on a more diverse test set, they surpass the baselines in all but one direction.</abstract>
      <url hash="3d2184c8">2025.wmt-1.91</url>
      <bibkey>rowe-etal-2025-edinhelsow</bibkey>
      <doi>10.18653/v1/2025.wmt-1.91</doi>
    </paper>
    <paper id="92">
      <title><fixed-case>K</fixed-case>oz<fixed-case>K</fixed-case>reol<fixed-case>MRU</fixed-case> <fixed-case>WMT</fixed-case> 2025 <fixed-case>C</fixed-case>reole<fixed-case>MT</fixed-case> System Description: Koz Kreol: Multi-Stage Training for <fixed-case>E</fixed-case>nglish–Mauritian Creole <fixed-case>MT</fixed-case></title>
      <author><first>Yush</first><last>Rajcoomar</last><affiliation>None</affiliation></author>
      <pages>1183-1190</pages>
      <abstract>Mauritian Creole (Kreol Morisyen), spoken by approximately 1.5 million people worldwide, faces significant challenges in digital language technology due to limited computational resources. This paper presents “Koz Kreol”, a comprehensive approach to English–Mauritian Creole machine translation using a three-stage training methodology: monolingual pretraining, parallel data training, and LoRA fine-tuning. We achieve state-of-the-art results with a 28.82 BLEU score for EN→MFE translation, representing a 74% improvement over ChatGPT-4o. Our work addresses critical data scarcity through the use of existing datasets, synthetic data generation, and community-sourced translations. The methodology provides a replicable framework for other low-resource Creole languages while supporting digital inclusion and cultural preservation for the Mauritian community. This paper consists of both a systems and data subtask submission as part of a Creole MT Shared Task.</abstract>
      <url hash="e8ba7d45">2025.wmt-1.92</url>
      <bibkey>rajcoomar-2025-kozkreolmru</bibkey>
      <doi>10.18653/v1/2025.wmt-1.92</doi>
    </paper>
    <paper id="93">
      <title><fixed-case>JHU</fixed-case> <fixed-case>WMT</fixed-case> 2025 <fixed-case>C</fixed-case>reole<fixed-case>MT</fixed-case> System Description: Data for Belizean <fixed-case>K</fixed-case>riol and <fixed-case>F</fixed-case>rench Guianese Creole <fixed-case>MT</fixed-case></title>
      <author><first>Nathaniel</first><last>Robinson</last><affiliation>Johns Hopkins University</affiliation></author>
      <pages>1191-1197</pages>
      <abstract>This document details the Johns Hopkins University’s submission to the 2025 WMT Shared Task for Creole Language Translation. We submitted exclusively to the data subtask, contributing machine translation bitext corpora for Belizean Kriol with English translations, and French Guianese Creole with French translations. These datasets contain 5,530 and 1,671 parallel lines of text, respectively, thus amounting to an 2,300% increase in publicly available lines of bitext for Belizean Creole with English, and an 370% such increase for French Guianese Creole with French. Experiments demonstrate genre-dependent improvements on our proposed test sets when the relevant state-of-the-art model is fine-tuned on our proposed train sets, with improvements across genres of up to 33.3 chrF++.</abstract>
      <url hash="e1aa587e">2025.wmt-1.93</url>
      <bibkey>robinson-2025-jhu</bibkey>
      <doi>10.18653/v1/2025.wmt-1.93</doi>
    </paper>
    <paper id="94">
      <title><fixed-case>WMT</fixed-case> 2025 <fixed-case>C</fixed-case>reole<fixed-case>MT</fixed-case> Systems Description : Martinican Creole and <fixed-case>F</fixed-case>rench</title>
      <author><first>Ludovic</first><last>Mompelat</last><affiliation>Indiana University</affiliation></author>
      <pages>1198-1200</pages>
      <abstract>This paper describes our submissions to the constrained subtask of the WMT25 Creole Machine Translation shared task. We participated with a bidirectional Martinican Creole – French system. Our work explores training-time strategies tailored for low-resource MT, including LoRA fine-tuning, curriculum sampling, gradual unfreezing, and multitask learning. We report competitive results against the baseline on both translation directions.</abstract>
      <url hash="3f3b3bd9">2025.wmt-1.94</url>
      <bibkey>mompelat-2025-wmt</bibkey>
      <doi>10.18653/v1/2025.wmt-1.94</doi>
    </paper>
    <paper id="95">
      <title><fixed-case>JU</fixed-case>-<fixed-case>NLP</fixed-case>: Improving Low-Resource <fixed-case>I</fixed-case>ndic Translation System with Efficient <fixed-case>L</fixed-case>o<fixed-case>RA</fixed-case>-Based Adaptation</title>
      <author><first>Priyobroto</first><last>Acharya</last><affiliation>Jadavpur University</affiliation></author>
      <author><first>Haranath</first><last>Mondal</last><affiliation>Jadavpur University</affiliation></author>
      <author><first>Dipanjan</first><last>Saha</last><affiliation>Jadavpur University</affiliation></author>
      <author><first>Dipankar</first><last>Das</last><affiliation>Jadavpur University</affiliation></author>
      <author id="sivaji-bandyopadhyay"><first>Sivaji</first><last>Bandyopadhyay</last><affiliation>JADAVPUR UNIVERSITY</affiliation></author>
      <pages>1201-1209</pages>
      <abstract>Low-resource Indic languages such as Assamese, Manipuri, Mizo, and Bodo face persistent challenges in NMT due to limited parallel data, diverse scripts, and complex morphology. We address these issues in the WMT $2025$ shared task by introducing a unified multilingual NMT framework that combines rigorous language-specific preprocessing with parameter-efficient adaptation of large-scale models. Our pipeline integrates the NLLB-$200$ and IndicTrans$2$ architectures, fine-tuned using LoRA and DoRA, reducing trainable parameters by over 90% without degrading translation quality. A comprehensive preprocessing suite, including Unicode normalization, semantic filtering, transliteration, and noise reduction, ensures high-quality inputs, while script-aware post-processing mitigates evaluation bias from orthographic mismatches. Experiments across English-Indic directions demonstrate that NLLB-$200$ achieves superior results for Assamese, Manipuri, and Mizo, whereas IndicTrans$2$ excels in English-Bodo. Evaluated using BLEU, chrF, METEOR, ROUGE-L, and TER, our approach yields consistent improvements over baselines, underscoring the effectiveness of combining efficient fine-tuning with linguistically informed preprocessing for low-resource Indic MT.</abstract>
      <url hash="5858a8cc">2025.wmt-1.95</url>
      <bibkey>acharya-etal-2025-ju</bibkey>
      <doi>10.18653/v1/2025.wmt-1.95</doi>
    </paper>
    <paper id="96">
      <title>An Attention-Based Neural Translation System for <fixed-case>E</fixed-case>nglish to <fixed-case>B</fixed-case>odo</title>
      <author><first>Subhash</first><last>Wary</last><affiliation>Central Institute of Technology Kokrajhar</affiliation></author>
      <author><first>Birhang</first><last>Borgoyary</last><affiliation>Central Institute of Technology Kokrajhar</affiliation></author>
      <author><first>Akher</first><last>Ahmed</last><affiliation>Central Institute of Technology Kokrajhar</affiliation></author>
      <author><first>Mohanji</first><last>Sah</last><affiliation>Central Institute of Technology Kokrajhar</affiliation></author>
      <author><first>Apurbalal</first><last>Senapati</last><affiliation>Central Institute of Technology Kokrajhar</affiliation></author>
      <pages>1210-1214</pages>
      <abstract>Bodo is a resource scarce, the indigenous language belongs to the Tibeto-Burman family. It is mainly spoken in the north-east region of India. It has both linguistic and cultural significance in the region. Only a limited number of resources and tools are available in this language. This paper presents a study of neural machine translation for the English-Bodo language pair. The system is developed on a relatively small parallel corpus provided by the Low-Resource Indic Language Translation as a part of WMT-2025. The system is evaluated by the WMT-2025 organizers with the evaluation matrices like BLUE, METEOR, ROUGE-L, chrF and TER. The result is not promising but it will help for the further improvement. The result is not encouraging, but it provides a foundation for further improvement.</abstract>
      <url hash="e9d69cc7">2025.wmt-1.96</url>
      <bibkey>wary-etal-2025-attention</bibkey>
      <doi>10.18653/v1/2025.wmt-1.96</doi>
    </paper>
    <paper id="97">
      <title>Tackling Low-Resource <fixed-case>NMT</fixed-case> with Instruction-Tuned <fixed-case>LL</fixed-case>a<fixed-case>MA</fixed-case>: A Study on Kokborok and <fixed-case>B</fixed-case>odo</title>
      <author><first>Deepak</first><last>Kumar</last><affiliation>IIT PATNA</affiliation></author>
      <author><first>Kshetrimayum Boynao</first><last>Singh</last><affiliation>National Institute of Technology Silchar</affiliation></author>
      <author><first>Asif</first><last>Ekbal</last><affiliation>IIT Patna</affiliation></author>
      <pages>1215-1221</pages>
      <abstract>This paper presents a new neural machine translation (NMT) system aimed at low-resource language pairs: English to Kokborok and English to Bodo. The framework leverages the LLaMA3-8B-Instruct model along with LoRA-based parameter-efficient fine-tuning. For translating into Kokborok, the model undergoes an initial continued pre-training phase on a dataset containing 75,000 Kokborok and 25,000 English monolingual sentences, followed by instruction-tuning. This tuning uses a reformulated version of WMT25 dataset, adapted to the Alpaca format to support instructional goals. In the Bodo translation, the model is pre-trained on a more extensive dataset of 350,000 Bodo and 125,000 English sentences, using a similar instruction-tuning approach. LoRA adapters are used to modify the large LLaMA3 model for these low-resource settings. Testing with the WMT25 test dataset reveals modest translation results, highlighting the difficulties in translating for low-resource languages. Translating English to Bodo, the model achieved a BLEU score of 4.38, a TER of 92.5, and a chrF score of 35.4. For English to Kokborok, it yielded scores of 5.59 in chrF, 105.4 in TER, and 0.17 in BLEU. These results underscore the intricacies of the task and highlight the critical need for further data collection, domain-specific adaptations, and improvements in model design to better support underrepresented languages.</abstract>
      <url hash="6ec32206">2025.wmt-1.97</url>
      <bibkey>kumar-etal-2025-tackling</bibkey>
      <doi>10.18653/v1/2025.wmt-1.97</doi>
    </paper>
    <paper id="98">
      <title><fixed-case>DELAB</fixed-case>-<fixed-case>IIITM</fixed-case> <fixed-case>WMT</fixed-case>25: Enhancing Low-Resource Machine Translation for <fixed-case>M</fixed-case>anipuri and <fixed-case>A</fixed-case>ssamese</title>
      <author><first>Dingku</first><last>Oinam</last><affiliation>Indian Institute of Information Technology, Senapati, Manipur</affiliation></author>
      <author><first>Navanath</first><last>Saharia</last><affiliation>Indian Institute of Information Technology, Senapati, Manipur</affiliation></author>
      <pages>1222-1226</pages>
      <abstract>This paper describe DELAB-IIITM’s submission system for the WMT25 machine translation shared task. We participated in two sub-task of the Indic Translation Task, en↔as and en↔mn i.e. Assamese (Indo Aryan language) and Manipuri (Tibeto Burman language) with a total of six translation directions, including mn→en, mn←en, en→as, en←as, mn→as, mn←as. Our fine tuning process aims to leverages the pretrained multilingual NLLB-200 model, a machine translation model developed by Meta AI as part of the No Language Left Behind (NLLB) project, through two main development, Synthetic parallel corpus creation and Strategic Fine-tuning. The Fine-tuning process involves strict data cleaning protocols, Adafactor optimizer with low learning rate(2e-5), 2 training epochs, train-test data splits to prevent overfitting, and Seq2SeqTrainer framework. The official test data was used to generate the target language with our fine-tuned model. Experimental results show that our method improves the BLEU scores for translation of these two language pairs. These findings confirm that back-translation remains challenging, largely due to morphological complexity and limited data availability.</abstract>
      <url hash="669d929d">2025.wmt-1.98</url>
      <bibkey>oinam-saharia-2025-delab</bibkey>
      <doi>10.18653/v1/2025.wmt-1.98</doi>
    </paper>
    <paper id="99">
      <title>Transformers: Leveraging <fixed-case>O</fixed-case>pen<fixed-case>NMT</fixed-case> and Transfer Learning for Low-Resource <fixed-case>I</fixed-case>ndian Language Translation</title>
      <author><first>Bhagyashree</first><last>Wagh</last><affiliation>C-DAC</affiliation></author>
      <author><first>Harish</first><last>Bapat</last><affiliation>C-DAC</affiliation></author>
      <author><first>Neha</first><last>Gupta</last><affiliation>C-DAC</affiliation></author>
      <author><first>Saurabh</first><last>Salunkhe</last><affiliation>C-DAC</affiliation></author>
      <pages>1227-1232</pages>
      <abstract>This paper describes our submission to the WMT 2025 (Pakray et al, 2025) Shared Task on Low-Resource Machine Translation for Indic languages. This task is an extension of the efforts which was originally initiated in WMT 2023 (Pal et al., 2023), and further continued to WMT 2024 (Pakray et al, 2024), received significant participation from the global community. We address English ↔ {Assamese, Bodo, Manipuri} translation, leveraging Hindi and Bengali as high-resource bridge languages. Our approach employs Transformer-based Neural Machine Translation (NMT) models, initialized through multilingual pre-training on high-resource Indic languages, followed by fine-tuning on limited parallel data for the target low-resource languages. The pre-training stage provides a strong multilingual representation space, while fine-tuning enables adaptation to specific linguistic characteristics of the target languages. We also apply consistent preprocessing, including tokenization, true casing, and subword segmentation (Sennrich et al., 2016) with Byte-Pair Encoding (BPE), to handle the morphological complexity of Indic languages. Evaluation on the shared task test sets demonstrates that pre-training followed by fine-tuning yields notable improvements over models trained solely on the target language data.</abstract>
      <url hash="20cb9b43">2025.wmt-1.99</url>
      <bibkey>wagh-etal-2025-transformers</bibkey>
      <doi>10.18653/v1/2025.wmt-1.99</doi>
    </paper>
    <paper id="100">
      <title><fixed-case>RBG</fixed-case>-<fixed-case>AI</fixed-case>: Benefits of Multilingual Language Models for Low-Resource Languages</title>
      <author><first>Barathi Ganesh</first><last>Hb</last><affiliation>Resilience Business Grids LLP</affiliation></author>
      <author><first>Michal</first><last>Ptaszynski</last><affiliation>Kitami Institute of Technology</affiliation></author>
      <pages>1233-1239</pages>
      <abstract>This paper investigates how multilingual language models benefit low-resource languages through our submission to the WMT 2025 Low-Resource Indic Language Translation shared task. We explore whether languages from related families can effectively support translation for low-resource languages that were absent or underrepresented during model training. Using a quantized multilingual pretrained foundation model, we examine zero-shot translation capabilities and cross-lingual transfer effects across three language families: Tibeto-Burman, Indo-Aryan, and Austroasiatic. Our findings demonstrate that multilingual models failed to leverage linguistic similarities, particularly evidenced within the Tibeto-Burman family. The study provides insights into the practical feasibility of zero-shot translation for low-resource language settings and the role of language family relationships in multilingual model performance.</abstract>
      <url hash="fbe1e6dd">2025.wmt-1.100</url>
      <bibkey>hb-ptaszynski-2025-rbg</bibkey>
      <doi>10.18653/v1/2025.wmt-1.100</doi>
    </paper>
    <paper id="101">
      <title><fixed-case>ANVITA</fixed-case> : A Multi-pronged Approach for Enhancing Machine Translation of Extremely Low-Resource <fixed-case>I</fixed-case>ndian Languages</title>
      <author><first>Sivabhavani</first><last>J</last><affiliation>Centre for Artificial Intelligence and Robotics, CV Raman Nagar, Bangalore, India</affiliation></author>
      <author><first>Daneshwari</first><last>Kankanwadi</last><affiliation>Centre for Artificial Intelligence and Robotics,CV Raman Nagar, Bangalore, India</affiliation></author>
      <author><first>Abhinav</first><last>Mishra</last><affiliation>Centre for Artificial Intelligence and Robotics,CV Raman Nagar, Bangalore, India</affiliation></author>
      <author><first>Biswajit</first><last>Paul</last><affiliation>CAIR</affiliation></author>
      <pages>1240-1247</pages>
      <abstract>India has a rich diverse linguistic landscape including 22 official languages and 122 major languages. Most of these 122 languages fall into low, extremely low resource categories and pose significant challenges in building robust machine translation system. This paper presents ANVITA Indic LR machine translation system submitted to WMT 2025 shared task on Low-Resource Indic Language Translation covering three extremely low-resource Indian languages Nyshi, Khasi, and Kokborok. A transfer learning based strategy is adopted and selected suitable public pretrained models (NLLB, ByT5), considering aspects such as language, script, tokenization and fine-tuned with the organizer provided dataset. Further, to tackle low-resource language menace better, the pretrained models are enriched with new vocabulary for improved representation of these three languages and selectively augmented data with related-language corpora, supplied by the organizer. The contrastive submissions however made use of supplementary corpora sourced from the web, generated synthetically, and drawn from proprietary data. On the WMT 2025 official test set, ANVITA achieved BLEU score of 2.41-11.59 with 2.2K to 60K corpora and 6.99-19.43 BLUE scores with augmented corpora. Overall ANVITA ranked first for {Nyishi, Kokborok}↔English and second for Khasi↔English across evaluation metrics including BLUE, METEOR, ROUGE-L, chrF and TER.</abstract>
      <url hash="58ac4f33">2025.wmt-1.101</url>
      <bibkey>j-etal-2025-anvita</bibkey>
      <doi>10.18653/v1/2025.wmt-1.101</doi>
    </paper>
    <paper id="102">
      <title><fixed-case>D</fixed-case>o<fixed-case>DS</fixed-case>-<fixed-case>IITPKD</fixed-case>:Submissions to the <fixed-case>WMT</fixed-case>25 Low-Resource <fixed-case>I</fixed-case>ndic Language Translation Task</title>
      <author><first>Ontiwell</first><last>Khongthaw</last><affiliation>Indian Institute of Technology Palakkad</affiliation></author>
      <author><first>G.l.</first><last>Salvin</last><affiliation>Department of Data Science, Indian Institute of Technology (IIT) Palakkad</affiliation></author>
      <author><first>Shrikant</first><last>Budde</last><affiliation>Department of Data Science, Indian Institute of Technology (IIT) Palakkad</affiliation></author>
      <author><first>Abigairl</first><last>Chigwededza</last><affiliation>Department of Data Science, Indian Institute of Technology (IIT) Palakkad</affiliation></author>
      <author><first>Dhruvadeep</first><last>Malkar</last><affiliation>Department of Data Science, Indian Institute of Technology (IIT) Palakkad</affiliation></author>
      <author><first>Swapnil</first><last>Hingmire</last><affiliation>Department of Data Science, Indian Institute of Technology (IIT) Palakkad</affiliation></author>
      <pages>1248-1252</pages>
      <abstract>Low-resource translation for Indic languages poses significant challenges due to limited parallel corpora and linguistic diversity. In this work, we describe our participation in the WMT 2025 shared task for four Indic languages-Khasi, Mizo, Assamese, which is categorized into Category 1 and Bodo in Cate- gory 2. For our PRIMARY submission, we fine- tuned the distilled NLLB-200 model on bidi- rectional English↔Khasi and English↔Mizo data, and employed the IndicTrans2 model family for Assamese and Bodo translation. Our CONTRASTIVE submission augments training with external corpora from PMIN- DIA and Google SMOL to further enrich low- resource data coverage. Both systems lever- age Low-Rank Adaptation (LoRA) within a parameter-efficient fine-tuning framework, en- abling lightweight adapter training atop frozen pretrained weights. The translation pipeline was developed using the Hugging Face Trans- formers and PEFT libraries, augmented with bespoke preprocessing modules that append both language and domain identifiers to each instance. We evaluated our approach on par- allel corpora spanning multiple domains- ar- ticle based, newswire, scientific, and biblical texts as provided by the WMT25 dataset, under conditions of severe data scarcity. Fine-tuning lightweight LoRA adapters on targeted parallel corpora yields marked improvements in evalua- tion metrics, confirming their effectiveness for cross-domain adaptation in low-resource Indic languages.</abstract>
      <url hash="12b48440">2025.wmt-1.102</url>
      <bibkey>khongthaw-etal-2025-dods</bibkey>
      <doi>10.18653/v1/2025.wmt-1.102</doi>
    </paper>
    <paper id="103">
      <title>A Preliminary Exploration of Phrase-Based <fixed-case>SMT</fixed-case> and Multi-<fixed-case>BPE</fixed-case> Segmentations through Concatenated Tokenised Corpora for Low-Resource <fixed-case>I</fixed-case>ndian Languages</title>
      <author><first>Saumitra</first><last>Yadav</last><affiliation>International Institute of Information Technology, Hyderabad</affiliation></author>
      <author id="manish-shrivastava"><first>Manish</first><last>Shrivastava</last><affiliation>International Institute of Information Technology Hyderabad</affiliation></author>
      <pages>1253-1258</pages>
      <abstract>This paper describes our methodology and findings in building Machine Translation (MT) systems for submission to the WMT 2025 Shared Task on Low-Resource Indic Language Translation. Our primary aim was to evaluate the effectiveness of a phrase-based Statistical Machine Translation (SMT) system combined with a less common subword segmentation strategy for languages with very limited parallel data. We applied multiple Byte Pair Encoding (BPE) merge operations to the parallel corpora and concatenated the outputs to improve vocabulary coverage. We built systems for the English–Nyishi, English–Khasi, and English–Assamese language pairs. Although the approach showed potential as a data augmentation method, its performance in BLEU scores was not competitive with other shared task systems. This paper outlines our system architecture, data processing pipeline, and evaluation results, and provides an analysis of the challenges, positioning our work as an exploratory benchmark for future research in this area.</abstract>
      <url hash="3b27016c">2025.wmt-1.103</url>
      <bibkey>yadav-shrivastava-2025-preliminary</bibkey>
      <doi>10.18653/v1/2025.wmt-1.103</doi>
    </paper>
    <paper id="104">
      <title><fixed-case>A</fixed-case>kiba<fixed-case>NLP</fixed-case>-<fixed-case>TUT</fixed-case>: Injecting Language-Specific Word-Level Noise for Low-Resource Language Translation</title>
      <author><first>Shoki</first><last>Hamada</last><affiliation>Toyohashi University of Technology</affiliation></author>
      <author><first>Tomoyosi</first><last>Akiba</last><affiliation>Toyohashi University of Technology</affiliation></author>
      <author><first>Hajime</first><last>Tsukada</last><affiliation>Aichi Sangyo University</affiliation></author>
      <pages>1259-1264</pages>
      <abstract>In this paper, we describes our system for the WMT 2025 Low-Resource Indic Language Translation Shared Task.The language directions addressed are Assamese↔English and Manipuri→English.We propose a method to improve translation performance from low-resource languages (LRLs) to English by injecting Language-specific word-level noise into the parallel corpus of a closely related high-resource language (HRL).In the proposed method, word replacements are performed based on edit distance, using vocabulary and frequency information extracted from an LRL monolingual corpus.Experiments conducted on Assamese and Manipuri show that, in the absence of LRL parallel data, the proposed method outperforms both the w/o noise setting and existing approaches. Furthermore, we confirmed that increasing the size of the monolingual corpus used for noise injection leads to improved translation performance.</abstract>
      <url hash="2440e46f">2025.wmt-1.104</url>
      <bibkey>hamada-etal-2025-akibanlp</bibkey>
      <doi>10.18653/v1/2025.wmt-1.104</doi>
    </paper>
    <paper id="105">
      <title><fixed-case>BVSLP</fixed-case>: Machine Translation Using Linguistic Embellishments for <fixed-case>I</fixed-case>ndic<fixed-case>MT</fixed-case> Shared Task 2025</title>
      <author><first>Nisheeth</first><last>Joshi</last><affiliation>Banasthali Vidyapith</affiliation></author>
      <author><first>Palak</first><last>Arora</last><affiliation>DIT University</affiliation></author>
      <author><first>Anju</first><last>Krishnia</last><affiliation>Banasthali Vidyapith</affiliation></author>
      <author><first>Riya</first><last>Lonchenpa</last><affiliation>Banasthali Vidyapith</affiliation></author>
      <author><first>Mhasilenuo</first><last>Vizo</last><affiliation>Banasthali Vidyapith</affiliation></author>
      <pages>1265-1270</pages>
      <abstract>This paper describes our submission to the Indic MT 2025 shared task, where we trained machine translation systems for five low-resource language pairs: English–Manipuri, Manipuri–English, English–Bodo, English–Assamese, and Assamese–English. To address the challenge of out-of-vocabulary errors, we introduced a Named Entity Translation module that automatically identified named entities and either translated or transliterated them into the target language. The augmented corpus produced by this module was used to fine-tune a Transformer-based neural machine translation system. Our approach, termed HEMANT (Highly Efficient Machine-Assisted Natural Translation), demonstrated consistent improvements, particularly in reducing named entity errors and improving fluency for Assamese–English and Manipuri–English. Official shared task evaluation results show that the system achieved competitive performance across all five language pairs, underscoring the effectiveness of linguistically informed preprocessing for low-resource Indic MT.</abstract>
      <url hash="aadd678c">2025.wmt-1.105</url>
      <bibkey>joshi-etal-2025-bvslp</bibkey>
      <doi>10.18653/v1/2025.wmt-1.105</doi>
    </paper>
    <paper id="106">
      <title><fixed-case>T</fixed-case>ranssion<fixed-case>MT</fixed-case>’s Submission to the <fixed-case>I</fixed-case>ndic <fixed-case>MT</fixed-case> Shared Task in <fixed-case>WMT</fixed-case> 2025</title>
      <author><first>Zebiao</first><last>Zhou</last><affiliation>Transsion</affiliation></author>
      <author><first>Hui</first><last>Li</last><affiliation>Transsion</affiliation></author>
      <author><first>Xiangxun</first><last>Zhu</last><affiliation>Transsion</affiliation></author>
      <author><first>Kangzhen</first><last>Liu</last><affiliation>Transsion</affiliation></author>
      <pages>1271-1275</pages>
      <abstract>This study addresses the low-resource Indian lan- 002guage translation task (English Assamese, English Ma- 003nipuri) at WMT 2025, proposing a cross-iterative back- 004translation and data augmentation approach based on 005dual pre-trained models to enhance translation perfor- 006mance in low-resource scenarios. The research method- 007ology primarily encompasses four aspects: (1) Utilizing 008open-source pre-trained models IndicTrans2_1B and 009NLLB_3.3B, fine-tuning them on official bilingual data, 010followed by alternating back-translation and incremen- 011tal training to generate high-quality pseudo-parallel cor- 012pora and optimize model parameters through multiple 013iterations; (2) Employing the open-source semantic sim- 014ilarity model (all-mpnet-base-v2) to filter monolingual 015sentences with low semantic similarity to the test set 016from open-source corpora such as NLLB and BPCC, 017thereby improving the relevance of monolingual data 018to the task; (3) Cleaning the training data, including 019removing URL and HTML format content, eliminating 020untranslated sentences in back-translation, standardiz- 021ing symbol formats, and normalizing capitalization of 022the first letter; (4) During the model inference phase, 023combining the outputs generated by the fine-tuned In- 024dicTrans2_1B and NLLB3.3B</abstract>
      <url hash="872fa029">2025.wmt-1.106</url>
      <bibkey>zhou-etal-2025-transsionmts</bibkey>
      <doi>10.18653/v1/2025.wmt-1.106</doi>
    </paper>
    <paper id="107">
      <title>Laniqo at <fixed-case>WMT</fixed-case>25 Terminology Translation Task: A Multi-Objective Reranking Strategy for Terminology-Aware Translation via <fixed-case>P</fixed-case>areto-Optimal Decoding</title>
      <author><first>Kamil</first><last>Guttmann</last><affiliation>Laniqo, Adam Mickiewicz University in Poznań</affiliation></author>
      <author><first>Adrian</first><last>Charkiewicz</last><affiliation>Laniqo, Adam Mickiewicz University in Poznań</affiliation></author>
      <author><first>Zofia</first><last>Rostek</last><affiliation>Laniqo</affiliation></author>
      <author><first>Mikołaj</first><last>Pokrywka</last><affiliation>Laniqo, Allegro, Adam Mickiewicz University</affiliation></author>
      <author><first>Artur</first><last>Nowakowski</last><affiliation>Laniqo / Adam Mickiewicz University</affiliation></author>
      <pages>1276-1283</pages>
      <abstract>This paper describes the Laniqo system submitted to the WMT25 Terminology Translation Task. Our approach uses a Large Language Model fine-tuned on parallel data augmented with source-side terminology constraints. To select the final translation from a set of generated candidates, we introduce Pareto-Optimal Decoding - a multi-objective reranking strategy. This method balances translation quality with term accuracy by leveraging several quality estimation metrics alongside Term Success Rate (TSR). Our system achieves TSR greater than 0.99 across all language pairs on the Shared Task testset, demonstrating the effectiveness of the proposed approach.</abstract>
      <url hash="30a7c847">2025.wmt-1.107</url>
      <bibkey>guttmann-etal-2025-laniqo-wmt25</bibkey>
      <doi>10.18653/v1/2025.wmt-1.107</doi>
    </paper>
    <paper id="108">
      <title>Fine-tuning <fixed-case>NMT</fixed-case> Models and <fixed-case>LLM</fixed-case>s for Specialised <fixed-case>EN</fixed-case>-<fixed-case>ES</fixed-case> Translation Using Aligned Corpora, Glossaries, and Synthetic Data: <fixed-case>MULTITAN</fixed-case> at <fixed-case>WMT</fixed-case>25 Terminology Shared Task</title>
      <author><first>Lichao</first><last>Zhu</last><affiliation>Paris CitÃ© University</affiliation></author>
      <author><first>Maria</first><last>Zimina-Poirot</last><affiliation>ALTAE, UniversitÃ© Paris CitÃ©</affiliation></author>
      <author><first>Cristian</first><last>Valdez</last><affiliation>Université Paris Cité</affiliation></author>
      <author><first>Stephane</first><last>Patin</last><affiliation>University Paris Cité</affiliation></author>
      <pages>1284-1291</pages>
      <abstract>This paper describes our participation in the WMT25 Terminology Shared Task, specifically Track 1 (Spanish to English) focused on translation within the Information Technology (IT) domain. The shared task challenges participants to improve machine translation systems by effectively incorporating terminology constraints to ensure accurate and consistent translation of specialised technical terms. We experimented with several approaches to tackle terminology and lexical constraints with both NMT systems and LLMs with a small amount of training data and a glossary. Experimental results demonstrate that systems behave differently with and without glossary. The NMT system seems rather limited in adapting to special lexicon and resizing embeddings, which is the opposite of the case with LLMs preferring structured instructions. Through this participation, our objective is to improve terminology accuracy and overall translation quality, highlight the potential of specialised terminology-aware translation models for technical domains, and explore possibilities of fine-tuning of LLMs and NMT models with domain and lexical constraints.</abstract>
      <url hash="deac1ba1">2025.wmt-1.108</url>
      <bibkey>zhu-etal-2025-fine</bibkey>
      <doi>10.18653/v1/2025.wmt-1.108</doi>
    </paper>
    <paper id="109">
      <title>Contextual Selection of Pseudo-terminology Constraints for Terminology-aware Neural Machine Translation in the <fixed-case>IT</fixed-case> Domain</title>
      <author><first>Benjamin</first><last>Pong</last><affiliation>University of Washington</affiliation></author>
      <pages>1292-1301</pages>
      <abstract>This system paper describes the development of a Neural Machine Translation system that is adapted to the Information Technology (IT) domain, and is able to translate specialized IT-related terminologies. Despite the popularity of incorporating terminology constraints at training time to develop terminology-aware Neural Machine Translation engines, one of the main issues is: In the absence of terminology references for training, and with the proliferation of source-target alignments, how does one select word alignments as pseudo-terminology constraints? The system in this work uses the encoder’s final hidden states as proxies for terminologies, and selects word alignments with the highest norm as pseudo-terminology constraints for inline annotation at run-time. It compares this context-based approach against a conventional statistical approach, where terminology-constraints are selected based on a low-frequency threshold. The systems were evaluated for general translation quality and Terminology Success Rates, with results that validate the effectiveness of the contextual approach.</abstract>
      <url hash="77dd7e57">2025.wmt-1.109</url>
      <bibkey>pong-2025-contextual</bibkey>
      <doi>10.18653/v1/2025.wmt-1.109</doi>
    </paper>
    <paper id="110">
      <title><fixed-case>IRB</fixed-case>-<fixed-case>MT</fixed-case> at <fixed-case>WMT</fixed-case>25 Terminology Translation Task: Metric-guided Multi-agent Approach</title>
      <author><first>Ivan</first><last>Grubišić</last><affiliation>Ruđer Bošković Institute</affiliation></author>
      <author><first>Damir</first><last>Korencic</last><affiliation>Ruđer Bošković Institute</affiliation></author>
      <pages>1302-1334</pages>
      <abstract>Terminology-aware machine translation (MT) is needed in case of specialized domains such as science and law. Large Language Models (LLMs) have raised the level of state-of-art performance on the task of MT, but the problem is not completely solved, especially for use-cases requiring precise terminology translations. We participate in the WMT25 Terminology Translation Task with an LLM-based multi-agent system coupled with a custom terminology-aware translation quality metric for the selection of the final translation. We use a number of smaller open-weights LLMs embedded in an agentic “translation revision” workflow, and we do not rely on data- and compute-intensive fine-tuning of models. Our evaluations show that the system achieves very good results in terms of both MetricX-24 and a custom TSR metric designed to measure the adherence to predefined term mappings.</abstract>
      <url hash="f5f7bf03">2025.wmt-1.110</url>
      <bibkey>grubisic-korencic-2025-irb-mt</bibkey>
      <doi>10.18653/v1/2025.wmt-1.110</doi>
    </paper>
    <paper id="111">
      <title>Terminology-Constrained Translation from Monolingual Data Using <fixed-case>GRPO</fixed-case></title>
      <author><first>Javier</first><last>Garcia Gilabert</last><affiliation>Barcelona Super Computing Center</affiliation></author>
      <author><first>Carlos</first><last>Escolano</last><affiliation>Universitat PolitÃ ̈cnica de Catalunya, Barcelona Supercomputing Center</affiliation></author>
      <author><first>Xixian</first><last>Liao</last><affiliation>Barcelona Supercomputing Center</affiliation></author>
      <author><first>Maite</first><last>Melero</last><affiliation>BSC</affiliation></author>
      <pages>1335-1343</pages>
      <abstract>Terminology consistency is essential for high-quality machine translation, especially in domain-specific and professional contexts, where accurate term translation directly impacts usability. This paper presents the submission from the BSC team to the WMT25 Terminology-Aware Translation Task. We propose the use of GRPO (Group Relative Policy Optimization) to adapt translation models using monolingual data only, without requiring parallel corpora. Our reward function jointly optimizes for terminology adherence and overall translation quality, leveraging quality-estimation metrics. Experimental results demonstrate that our method consistently improves terminology translation across three language directions—English to Spanish, German, and Russian—by up to +0.36 Tₚ points across all evaluated models.</abstract>
      <url hash="88e89ec9">2025.wmt-1.111</url>
      <bibkey>garcia-gilabert-etal-2025-terminology</bibkey>
      <doi>10.18653/v1/2025.wmt-1.111</doi>
    </paper>
    <paper id="112">
      <title>It Takes Two: A Dual Stage Approach for Terminology-Aware Translation</title>
      <author><first>Akshat</first><last>Jaswal</last><affiliation>PES University</affiliation></author>
      <pages>1344-1350</pages>
      <abstract>This paper introduces DuTerm, a novel two-stage architecture for terminology-constrained machine translation. Our system combines a terminology-aware NMT model, adapted via fine-tuning on large-scale synthetic data, with a prompt-based LLM for post-editing. The LLM stage refines NMT output and enforces terminology adherence. We evaluate DuTerm on English-to German, English-to-Spanish, and English-to-Russian for the WMT 2025 Terminology Shared Task. We demonstrate that flexible, context-driven terminology handling by the LLM consistently yields higher quality translations than strict constraint enforcement. Our results highlight a critical trade-off, revealing that an LLM’s intrinsic knowledge often provides a stronger basis for high-quality translation than rigid, externally imposed constraints.</abstract>
      <url hash="32b76dfc">2025.wmt-1.112</url>
      <bibkey>jaswal-2025-takes</bibkey>
      <doi>10.18653/v1/2025.wmt-1.112</doi>
    </paper>
  </volume>
</collection>
