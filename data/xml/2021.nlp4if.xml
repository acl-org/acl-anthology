<?xml version='1.0' encoding='UTF-8'?>
<collection id="2021.nlp4if">
  <volume id="1" ingest-date="2021-05-24">
    <meta>
      <booktitle>Proceedings of the Fourth Workshop on NLP for Internet Freedom: Censorship, Disinformation, and Propaganda</booktitle>
      <editor><first>Anna</first><last>Feldman</last></editor>
      <editor><first>Giovanni</first><last>Da San Martino</last></editor>
      <editor><first>Chris</first><last>Leberknight</last></editor>
      <editor><first>Preslav</first><last>Nakov</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>June</month>
      <year>2021</year>
      <url hash="85c83d62">2021.nlp4if-1</url>
      <venue>nlp4if</venue>
    </meta>
    <frontmatter>
      <url hash="604d9ccc">2021.nlp4if-1.0</url>
      <bibkey>nlp4if-2021-nlp</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Identifying Automatically Generated Headlines using Transformers</title>
      <author><first>Antonis</first><last>Maronikolakis</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <author><first>Mark</first><last>Stevenson</last></author>
      <pages>1–6</pages>
      <abstract>False information spread via the internet and social media influences public opinion and user activity, while generative models enable fake content to be generated faster and more cheaply than had previously been possible. In the not so distant future, identifying fake content generated by deep learning models will play a key role in protecting users from misinformation. To this end, a dataset containing human and computer-generated headlines was created and a user study indicated that humans were only able to identify the fake headlines in 47.8% of the cases. However, the most accurate automatic approach, transformers, achieved an overall accuracy of 85.7%, indicating that content generated from language models can be filtered out accurately.</abstract>
      <url hash="76895ad7">2021.nlp4if-1.1</url>
      <doi>10.18653/v1/2021.nlp4if-1.1</doi>
      <bibkey>maronikolakis-etal-2021-identifying</bibkey>
    </paper>
    <paper id="2">
      <title>Improving Hate Speech Type and Target Detection with Hateful Metaphor Features</title>
      <author><first>Jens</first><last>Lemmens</last></author>
      <author><first>Ilia</first><last>Markov</last></author>
      <author><first>Walter</first><last>Daelemans</last></author>
      <pages>7–16</pages>
      <abstract>We study the usefulness of hateful metaphorsas features for the identification of the type and target of hate speech in Dutch Facebook comments. For this purpose, all hateful metaphors in the Dutch LiLaH corpus were annotated and interpreted in line with Conceptual Metaphor Theory and Critical Metaphor Analysis. We provide SVM and BERT/RoBERTa results, and investigate the effect of different metaphor information encoding methods on hate speech type and target detection accuracy. The results of the conducted experiments show that hateful metaphor features improve model performance for the both tasks. To our knowledge, it is the first time that the effectiveness of hateful metaphors as an information source for hatespeech classification is investigated.</abstract>
      <url hash="f5dee837">2021.nlp4if-1.2</url>
      <doi>10.18653/v1/2021.nlp4if-1.2</doi>
      <bibkey>lemmens-etal-2021-improving</bibkey>
    </paper>
    <paper id="3">
      <title>Improving Cross-Domain Hate Speech Detection by Reducing the False Positive Rate</title>
      <author><first>Ilia</first><last>Markov</last></author>
      <author><first>Walter</first><last>Daelemans</last></author>
      <pages>17–22</pages>
      <abstract>Hate speech detection is an actively growing field of research with a variety of recently proposed approaches that allowed to push the state-of-the-art results. One of the challenges of such automated approaches – namely recent deep learning models – is a risk of false positives (i.e., false accusations), which may lead to over-blocking or removal of harmless social media content in applications with little moderator intervention. We evaluate deep learning models both under in-domain and cross-domain hate speech detection conditions, and introduce an SVM approach that allows to significantly improve the state-of-the-art results when combined with the deep learning models through a simple majority-voting ensemble. The improvement is mainly due to a reduction of the false positive rate.</abstract>
      <url hash="b454930c">2021.nlp4if-1.3</url>
      <doi>10.18653/v1/2021.nlp4if-1.3</doi>
      <bibkey>markov-daelemans-2021-improving</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hate-speech">Hate Speech</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/olid">OLID</pwcdataset>
    </paper>
    <paper id="4">
      <title>Understanding the Impact of Evidence-Aware Sentence Selection for Fact Checking</title>
      <author><first>Giannis</first><last>Bekoulis</last></author>
      <author><first>Christina</first><last>Papagiannopoulou</last></author>
      <author><first>Nikos</first><last>Deligiannis</last></author>
      <pages>23–28</pages>
      <abstract>Fact Extraction and VERification (FEVER) is a recently introduced task that consists of the following subtasks (i) document retrieval, (ii) sentence retrieval, and (iii) claim verification. In this work, we focus on the subtask of sentence retrieval. Specifically, we propose an evidence-aware transformer-based model that outperforms all other models in terms of FEVER score by using a subset of training instances. In addition, we conduct a large experimental study to get a better understanding of the problem, while we summarize our findings by presenting future research challenges.</abstract>
      <url hash="41bb36dc">2021.nlp4if-1.4</url>
      <doi>10.18653/v1/2021.nlp4if-1.4</doi>
      <bibkey>bekoulis-etal-2021-understanding</bibkey>
      <revision id="1" href="2021.nlp4if-1.4v1" hash="d7251738"/>
      <revision id="2" href="2021.nlp4if-1.4v2" hash="41bb36dc" date="2021-06-28">Corrected a citation</revision>
      <pwccode url="https://github.com/bekou/evidence_aware_nlp4if" additional="false">bekou/evidence_aware_nlp4if</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/fever">FEVER</pwcdataset>
    </paper>
    <paper id="5">
      <title>Leveraging Community and Author Context to Explain the Performance and Bias of Text-Based Deception Detection Models</title>
      <author><first>Galen</first><last>Weld</last></author>
      <author><first>Ellyn</first><last>Ayton</last></author>
      <author><first>Tim</first><last>Althoff</last></author>
      <author><first>Maria</first><last>Glenski</last></author>
      <pages>29–38</pages>
      <abstract>Deceptive news posts shared in online communities can be detected with NLP models, and much recent research has focused on the development of such models. In this work, we use characteristics of online communities and authors — the context of how and where content is posted — to explain the performance of a neural network deception detection model and identify sub-populations who are disproportionately affected by model accuracy or failure. We examine who is posting the content, and where the content is posted to. We find that while author characteristics are better predictors of deceptive content than community characteristics, both characteristics are strongly correlated with model performance. Traditional performance metrics such as F1 score may fail to capture poor model performance on isolated sub-populations such as specific authors, and as such, more nuanced evaluation of deception detection models is critical.</abstract>
      <url hash="688ba3ac">2021.nlp4if-1.5</url>
      <doi>10.18653/v1/2021.nlp4if-1.5</doi>
      <bibkey>weld-etal-2021-leveraging</bibkey>
    </paper>
    <paper id="6">
      <title>Never guess what <fixed-case>I</fixed-case> heard... Rumor Detection in <fixed-case>F</fixed-case>innish News: a Dataset and a Baseline</title>
      <author><first>Mika</first><last>Hämäläinen</last></author>
      <author><first>Khalid</first><last>Alnajjar</last></author>
      <author><first>Niko</first><last>Partanen</last></author>
      <author><first>Jack</first><last>Rueter</last></author>
      <pages>39–44</pages>
      <abstract>This study presents a new dataset on rumor detection in Finnish language news headlines. We have evaluated two different LSTM based models and two different BERT models, and have found very significant differences in the results. A fine-tuned FinBERT reaches the best overall accuracy of 94.3% and rumor label accuracy of 96.0% of the time. However, a model fine-tuned on Multilingual BERT reaches the best factual label accuracy of 97.2%. Our results suggest that the performance difference is due to a difference in the original training data. Furthermore, we find that a regular LSTM model works better than one trained with a pretrained word2vec model. These findings suggest that more work needs to be done for pretrained models in Finnish language as they have been trained on small and biased corpora.</abstract>
      <url hash="5c7cef8d">2021.nlp4if-1.6</url>
      <doi>10.18653/v1/2021.nlp4if-1.6</doi>
      <bibkey>hamalainen-etal-2021-never</bibkey>
    </paper>
    <paper id="7">
      <title>Extractive and Abstractive Explanations for Fact-Checking and Evaluation of News</title>
      <author><first>Ashkan</first><last>Kazemi</last></author>
      <author><first>Zehua</first><last>Li</last></author>
      <author><first>Verónica</first><last>Pérez-Rosas</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <pages>45–50</pages>
      <abstract>In this paper, we explore the construction of natural language explanations for news claims, with the goal of assisting fact-checking and news evaluation applications. We experiment with two methods: (1) an extractive method based on Biased TextRank – a resource-effective unsupervised graph-based algorithm for content extraction; and (2) an abstractive method based on the GPT-2 language model. We perform comparative evaluations on two misinformation datasets in the political and health news domains, and find that the extractive method shows the most promise.</abstract>
      <url hash="d1838b6b">2021.nlp4if-1.7</url>
      <doi>10.18653/v1/2021.nlp4if-1.7</doi>
      <bibkey>kazemi-etal-2021-extractive</bibkey>
    </paper>
    <paper id="8">
      <title>Generalisability of Topic Models in Cross-corpora Abusive Language Detection</title>
      <author><first>Tulika</first><last>Bose</last></author>
      <author><first>Irina</first><last>Illina</last></author>
      <author><first>Dominique</first><last>Fohr</last></author>
      <pages>51–56</pages>
      <abstract>Rapidly changing social media content calls for robust and generalisable abuse detection models. However, the state-of-the-art supervised models display degraded performance when they are evaluated on abusive comments that differ from the training corpus. We investigate if the performance of supervised models for cross-corpora abuse detection can be improved by incorporating additional information from topic models, as the latter can infer the latent topic mixtures from unseen samples. In particular, we combine topical information with representations from a model tuned for classifying abusive comments. Our performance analysis reveals that topic models are able to capture abuse-related topics that can transfer across corpora, and result in improved generalisability.</abstract>
      <url hash="dcdf838e">2021.nlp4if-1.8</url>
      <doi>10.18653/v1/2021.nlp4if-1.8</doi>
      <bibkey>bose-etal-2021-generalisability</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>A</fixed-case>ra<fixed-case>S</fixed-case>tance: A Multi-Country and Multi-Domain Dataset of <fixed-case>A</fixed-case>rabic Stance Detection for Fact Checking</title>
      <author><first>Tariq</first><last>Alhindi</last></author>
      <author><first>Amal</first><last>Alabdulkarim</last></author>
      <author><first>Ali</first><last>Alshehri</last></author>
      <author><first>Muhammad</first><last>Abdul-Mageed</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <pages>57–65</pages>
      <abstract>With the continuing spread of misinformation and disinformation online, it is of increasing importance to develop combating mechanisms at scale in the form of automated systems that support multiple languages. One task of interest is claim veracity prediction, which can be addressed using stance detection with respect to relevant documents retrieved online. To this end, we present our new Arabic Stance Detection dataset (AraStance) of 4,063 claim–article pairs from a diverse set of sources comprising three fact-checking websites and one news website. AraStance covers false and true claims from multiple domains (e.g., politics, sports, health) and several Arab countries, and it is well-balanced between related and unrelated documents with respect to the claims. We benchmark AraStance, along with two other stance detection datasets, using a number of BERT-based models. Our best model achieves an accuracy of 85% and a macro F1 score of 78%, which leaves room for improvement and reflects the challenging nature of AraStance and the task of stance detection in general.</abstract>
      <url hash="cb441297">2021.nlp4if-1.9</url>
      <doi>10.18653/v1/2021.nlp4if-1.9</doi>
      <bibkey>alhindi-etal-2021-arastance</bibkey>
      <pwccode url="https://github.com/Tariq60/arastance" additional="false">Tariq60/arastance</pwccode>
    </paper>
    <paper id="10">
      <title><fixed-case>MEAN</fixed-case>: Multi-head Entity Aware Attention Networkfor Political Perspective Detection in News Media</title>
      <author><first>Chang</first><last>Li</last></author>
      <author><first>Dan</first><last>Goldwasser</last></author>
      <pages>66–75</pages>
      <abstract>The way information is generated and disseminated has changed dramatically over the last decade. Identifying the political perspective shaping the way events are discussed in the media becomes more important due to the sharp increase in the number of news outlets and articles. Previous approaches usually only leverage linguistic information. However, news articles attempt to maintain credibility and seem impartial. Therefore, bias is introduced in subtle ways, usually by emphasizing different aspects of the story. In this paper, we propose a novel framework that considers entities mentioned in news articles and external knowledge about them, capturing the bias with respect to those entities. We explore different ways to inject entity information into the text model. Experiments show that our proposed framework achieves significant improvements over the standard text models, and is capable of identifying the difference in news narratives with different perspectives.</abstract>
      <url hash="fa3b0f9f">2021.nlp4if-1.10</url>
      <doi>10.18653/v1/2021.nlp4if-1.10</doi>
      <bibkey>li-goldwasser-2021-mean</bibkey>
    </paper>
    <paper id="11">
      <title>An Empirical Assessment of the Qualitative Aspects of Misinformation in Health News</title>
      <author><first>Chaoyuan</first><last>Zuo</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Ritwik</first><last>Banerjee</last></author>
      <pages>76–81</pages>
      <abstract>The explosion of online health news articles runs the risk of the proliferation of low-quality information. Within the existing work on fact-checking, however, relatively little attention has been paid to medical news. We present a health news classification task to determine whether medical news articles satisfy a set of review criteria deemed important by medical experts and health care journalists. We present a dataset of 1,119 health news paired with systematic reviews. The review criteria consist of six elements that are essential to the accuracy of medical news. We then present experiments comparing the classical token-based approach with the more recent transformer-based models. Our results show that detecting qualitative lapses is a challenging task with direct ramifications in misinformation, but is an important direction to pursue beyond assigning True or False labels to short claims.</abstract>
      <url hash="96aac390">2021.nlp4if-1.11</url>
      <doi>10.18653/v1/2021.nlp4if-1.11</doi>
      <bibkey>zuo-etal-2021-empirical</bibkey>
    </paper>
    <paper id="12">
      <title>Findings of the <fixed-case>NLP</fixed-case>4<fixed-case>IF</fixed-case>-2021 Shared Tasks on Fighting the <fixed-case>COVID</fixed-case>-19 Infodemic and Censorship Detection</title>
      <author><first>Shaden</first><last>Shaar</last></author>
      <author><first>Firoj</first><last>Alam</last></author>
      <author><first>Giovanni</first><last>Da San Martino</last></author>
      <author><first>Alex</first><last>Nikolov</last></author>
      <author><first>Wajdi</first><last>Zaghouani</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <author><first>Anna</first><last>Feldman</last></author>
      <pages>82–92</pages>
      <abstract>We present the results and the main findings of the NLP4IF-2021 shared tasks. Task 1 focused on fighting the COVID-19 infodemic in social media, and it was offered in Arabic, Bulgarian, and English. Given a tweet, it asked to predict whether that tweet contains a verifiable claim, and if so, whether it is likely to be false, is of general interest, is likely to be harmful, and is worthy of manual fact-checking; also, whether it is harmful to society, and whether it requires the attention of policy makers. Task 2 focused on censorship detection, and was offered in Chinese. A total of ten teams submitted systems for task 1, and one team participated in task 2; nine teams also submitted a system description paper. Here, we present the tasks, analyze the results, and discuss the system submissions and the methods they used. Most submissions achieved sizable improvements over several baselines, and the best systems used pre-trained Transformers and ensembles. The data, the scorers and the leaderboards for the tasks are available at http://gitlab.com/NLP4IF/nlp4if-2021.</abstract>
      <url hash="c6020fc1">2021.nlp4if-1.12</url>
      <doi>10.18653/v1/2021.nlp4if-1.12</doi>
      <bibkey>shaar-etal-2021-findings</bibkey>
    </paper>
    <paper id="13">
      <title><fixed-case>D</fixed-case>amascus<fixed-case>T</fixed-case>eam at <fixed-case>NLP</fixed-case>4<fixed-case>IF</fixed-case>2021: Fighting the <fixed-case>A</fixed-case>rabic <fixed-case>COVID</fixed-case>-19 Infodemic on <fixed-case>T</fixed-case>witter Using <fixed-case>A</fixed-case>ra<fixed-case>BERT</fixed-case></title>
      <author><first>Ahmad</first><last>Hussein</last></author>
      <author><first>Nada</first><last>Ghneim</last></author>
      <author><first>Ammar</first><last>Joukhadar</last></author>
      <pages>93–98</pages>
      <abstract>The objective of this work was the introduction of an effective approach based on the AraBERT language model for fighting Tweets COVID-19 Infodemic. It was arranged in the form of a two-step pipeline, where the first step involved a series of pre-processing procedures to transform Twitter jargon, including emojis and emoticons, into plain text, and the second step exploited a version of AraBERT, which was pre-trained on plain text, to fine-tune and classify the tweets with respect to their Label. The use of language models pre-trained on plain texts rather than on tweets was motivated by the necessity to address two critical issues shown by the scientific literature, namely (1) pre-trained language models are widely available in many languages, avoiding the time-consuming and resource-intensive model training directly on tweets from scratch, allowing to focus only on their fine-tuning; (2) available plain text corpora are larger than tweet-only ones, allowing for better performance.</abstract>
      <url hash="3246b805">2021.nlp4if-1.13</url>
      <doi>10.18653/v1/2021.nlp4if-1.13</doi>
      <bibkey>hussein-etal-2021-damascusteam</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>NARNIA</fixed-case> at <fixed-case>NLP</fixed-case>4<fixed-case>IF</fixed-case>-2021: Identification of Misinformation in <fixed-case>COVID</fixed-case>-19 Tweets Using <fixed-case>BERT</fixed-case>weet</title>
      <author><first>Ankit</first><last>Kumar</last></author>
      <author><first>Naman</first><last>Jhunjhunwala</last></author>
      <author><first>Raksha</first><last>Agarwal</last></author>
      <author><first>Niladri</first><last>Chatterjee</last></author>
      <pages>99–103</pages>
      <abstract>The spread of COVID-19 has been accompanied with widespread misinformation on social media. In particular, Twitterverse has seen a huge increase in dissemination of distorted facts and figures. The present work aims at identifying tweets regarding COVID-19 which contains harmful and false information. We have experimented with a number of Deep Learning-based models, including different word embeddings, such as Glove, ELMo, among others. BERTweet model achieved the best overall F1-score of 0.881 and secured the third rank on the above task.</abstract>
      <url hash="e434f5cf">2021.nlp4if-1.14</url>
      <doi>10.18653/v1/2021.nlp4if-1.14</doi>
      <bibkey>kumar-etal-2021-narnia</bibkey>
    </paper>
    <paper id="15">
      <title>R00 at <fixed-case>NLP</fixed-case>4<fixed-case>IF</fixed-case>-2021 Fighting <fixed-case>COVID</fixed-case>-19 Infodemic with Transformers and More Transformers</title>
      <author><first>Ahmed</first><last>Qarqaz</last></author>
      <author><first>Dia</first><last>Abujaber</last></author>
      <author><first>Malak</first><last>Abdullah</last></author>
      <pages>104–109</pages>
      <abstract>This paper describes the winning model in the Arabic NLP4IF shared task for fighting the COVID-19 infodemic. The goal of the shared task is to check disinformation about COVID-19 in Arabic tweets. Our proposed model has been ranked 1st with an F1-Score of 0.780 and an Accuracy score of 0.762. A variety of transformer-based pre-trained language models have been experimented with through this study. The best-scored model is an ensemble of AraBERT-Base, Asafya-BERT, and ARBERT models. One of the study’s key findings is showing the effect the pre-processing can have on every model’s score. In addition to describing the winning model, the current study shows the error analysis.</abstract>
      <url hash="d853434c">2021.nlp4if-1.15</url>
      <doi>10.18653/v1/2021.nlp4if-1.15</doi>
      <bibkey>qarqaz-etal-2021-r00</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/arcov-19">ArCOV-19</pwcdataset>
    </paper>
    <paper id="16">
      <title>Multi Output Learning using Task Wise Attention for Predicting Binary Properties of Tweets : Shared-Task-On-Fighting the <fixed-case>COVID</fixed-case>-19 Infodemic</title>
      <author><first>Ayush</first><last>Suhane</last></author>
      <author><first>Shreyas</first><last>Kowshik</last></author>
      <pages>110–114</pages>
      <abstract>In this paper, we describe our system for the shared task on Fighting the COVID-19 Infodemic in the English Language. Our proposed architecture consists of a multi-output classification model for the seven tasks, with a task-wise multi-head attention layer for inter-task information aggregation. This was built on top of the Bidirectional Encoder Representations obtained from the RoBERTa Transformer. We were able to achieve a mean F1 score of 0.891 on the test data, leading us to the second position on the test-set leaderboard.</abstract>
      <url hash="7aac8619">2021.nlp4if-1.16</url>
      <doi>10.18653/v1/2021.nlp4if-1.16</doi>
      <bibkey>suhane-kowshik-2021-multi</bibkey>
    </paper>
    <paper id="17">
      <title>i<fixed-case>C</fixed-case>ompass at <fixed-case>NLP</fixed-case>4<fixed-case>IF</fixed-case>-2021–Fighting the <fixed-case>COVID</fixed-case>-19 Infodemic</title>
      <author><first>Wassim</first><last>Henia</last></author>
      <author><first>Oumayma</first><last>Rjab</last></author>
      <author><first>Hatem</first><last>Haddad</last></author>
      <author><first>Chayma</first><last>Fourati</last></author>
      <pages>115–118</pages>
      <abstract>This paper provides a detailed overview of the system and its outcomes, which were produced as part of the NLP4IF Shared Task on Fighting the COVID-19 Infodemic at NAACL 2021. This task is accomplished using a variety of techniques. We used state-of-the-art contextualized text representation models that were fine-tuned for the downstream task in hand. ARBERT, MARBERT,AraBERT, Arabic ALBERT and BERT-base-arabic were used. According to the results, BERT-base-arabic had the highest 0.784 F1 score on the test set.</abstract>
      <url hash="a774c93d">2021.nlp4if-1.17</url>
      <doi>10.18653/v1/2021.nlp4if-1.17</doi>
      <bibkey>henia-etal-2021-icompass</bibkey>
    </paper>
    <paper id="18">
      <title>Fighting the <fixed-case>COVID</fixed-case>-19 Infodemic with a Holistic <fixed-case>BERT</fixed-case> Ensemble</title>
      <author><first>Georgios</first><last>Tziafas</last></author>
      <author><first>Konstantinos</first><last>Kogkalidis</last></author>
      <author><first>Tommaso</first><last>Caselli</last></author>
      <pages>119–124</pages>
      <abstract>This paper describes the TOKOFOU system, an ensemble model for misinformation detection tasks based on six different transformer-based pre-trained encoders, implemented in the context of the COVID-19 Infodemic Shared Task for English. We fine tune each model on each of the task’s questions and aggregate their prediction scores using a majority voting approach. TOKOFOU obtains an overall F1 score of 89.7%, ranking first.</abstract>
      <url hash="95717aab">2021.nlp4if-1.18</url>
      <doi>10.18653/v1/2021.nlp4if-1.18</doi>
      <bibkey>tziafas-etal-2021-fighting</bibkey>
      <pwccode url="https://github.com/gtziafas/nlp4ifchallenge" additional="false">gtziafas/nlp4ifchallenge</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/tweeteval">TweetEval</pwcdataset>
    </paper>
    <paper id="19">
      <title>Detecting Multilingual <fixed-case>COVID</fixed-case>-19 Misinformation on Social Media via Contextualized Embeddings</title>
      <author><first>Subhadarshi</first><last>Panda</last></author>
      <author><first>Sarah Ita</first><last>Levitan</last></author>
      <pages>125–129</pages>
      <abstract>We present machine learning classifiers to automatically identify COVID-19 misinformation on social media in three languages: English, Bulgarian, and Arabic. We compared 4 multitask learning models for this task and found that a model trained with English BERT achieves the best results for English, and multilingual BERT achieves the best results for Bulgarian and Arabic. We experimented with zero shot, few shot, and target-only conditions to evaluate the impact of target-language training data on classifier performance, and to understand the capabilities of different models to generalize across languages in detecting misinformation online. This work was performed as a submission to the shared task, NLP4IF 2021: Fighting the COVID-19 Infodemic. Our best models achieved the second best evaluation test results for Bulgarian and Arabic among all the participating teams and obtained competitive scores for English.</abstract>
      <url hash="ce030391">2021.nlp4if-1.19</url>
      <doi>10.18653/v1/2021.nlp4if-1.19</doi>
      <bibkey>panda-levitan-2021-detecting</bibkey>
      <pwccode url="https://github.com/subhadarship/nlp4if-2021" additional="false">subhadarship/nlp4if-2021</pwccode>
    </paper>
    <paper id="20">
      <title>Transformers to Fight the <fixed-case>COVID</fixed-case>-19 Infodemic</title>
      <author><first>Lasitha</first><last>Uyangodage</last></author>
      <author><first>Tharindu</first><last>Ranasinghe</last></author>
      <author><first>Hansi</first><last>Hettiarachchi</last></author>
      <pages>130–135</pages>
      <abstract>The massive spread of false information on social media has become a global risk especially in a global pandemic situation like COVID-19. False information detection has thus become a surging research topic in recent months. NLP4IF-2021 shared task on fighting the COVID-19 infodemic has been organised to strengthen the research in false information detection where the participants are asked to predict seven different binary labels regarding false information in a tweet. The shared task has been organised in three languages; Arabic, Bulgarian and English. In this paper, we present our approach to tackle the task objective using transformers. Overall, our approach achieves a 0.707 mean F1 score in Arabic, 0.578 mean F1 score in Bulgarian and 0.864 mean F1 score in English ranking 4<tex-math>^{th}</tex-math> place in all the languages.</abstract>
      <url hash="353ff402">2021.nlp4if-1.20</url>
      <doi>10.18653/v1/2021.nlp4if-1.20</doi>
      <bibkey>uyangodage-etal-2021-transformers</bibkey>
      <pwccode url="https://github.com/tharindudr/infominer" additional="false">tharindudr/infominer</pwccode>
    </paper>
    <paper id="21">
      <title>Classification of Censored Tweets in <fixed-case>C</fixed-case>hinese Language using <fixed-case>XLN</fixed-case>et</title>
      <author><first>Shaikh Sahil</first><last>Ahmed</last></author>
      <author><first>Anand</first><last>Kumar M.</last></author>
      <pages>136–139</pages>
      <abstract>In the growth of today’s world and advanced technology, social media networks play a significant role in impacting human lives. Censorship is the overthrowing of speech, public transmission, or other details that play a vast role in social media. The content may be considered harmful, sensitive, or inconvenient. Authorities like institutes, governments, and other organizations conduct Censorship. This paper has implemented a model that helps classify censored and uncensored tweets as a binary classification. The paper describes submission to the Censorship shared task of the NLP4IF 2021 workshop. We used various transformer-based pre-trained models, and XLNet outputs a better accuracy among all. We fine-tuned the model for better performance and achieved a reasonable accuracy, and calculated other performance metrics.</abstract>
      <url hash="dec47c4e">2021.nlp4if-1.21</url>
      <doi>10.18653/v1/2021.nlp4if-1.21</doi>
      <bibkey>ahmed-kumar-m-2021-classification</bibkey>
    </paper>
  </volume>
</collection>
