<?xml version='1.0' encoding='UTF-8'?>
<collection id="2022.nllp">
  <volume id="1" ingest-date="2022-12-14" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Natural Legal Language Processing Workshop 2022</booktitle>
      <editor><first>Nikolaos</first><last>Aletras</last></editor>
      <editor><first>Ilias</first><last>Chalkidis</last></editor>
      <editor><first>Leslie</first><last>Barrett</last></editor>
      <editor><first>Cătălina</first><last>Goanță</last></editor>
      <editor><first>Daniel</first><last>Preoțiuc-Pietro</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Abu Dhabi, United Arab Emirates (Hybrid)</address>
      <month>December</month>
      <year>2022</year>
      <url hash="6668dc24">2022.nllp-1</url>
      <venue>nllp</venue>
    </meta>
    <frontmatter>
      <url hash="de2393bc">2022.nllp-1.0</url>
      <bibkey>nllp-2022-natural</bibkey>
    </frontmatter>
    <paper id="1">
      <title>On Breadth Alone: Improving the Precision of Terminology Extraction Systems on Patent Corpora</title>
      <author><first>Sean</first><last>Nordquist</last><affiliation>New York University</affiliation></author>
      <author><first>Adam</first><last>Meyers</last><affiliation>New York University</affiliation></author>
      <pages>1-11</pages>
      <abstract>Automatic Terminology Extraction (ATE) methods are a class of linguistic, statistical, machine learning or hybrid techniques for identifying terminology in a set of documents. Most modern ATE methods use a statistical measure of how important or characteristic a potential term is to a foreground corpus by using a second background corpus as a baseline. While many variables with ATE methods have been carefully evaluated and tuned in the literature, the effects of choosing a particular background corpus over another are not obvious. In this paper, we propose a methodology that allows us to adjust the relative breadth of the foreground and background corpora in patent documents by taking advantage of the Cooperative Patent Classification (CPC) scheme. Our results show that for every foreground corpus, the broadest background corpus gave the worst performance, in the worst case that difference is 17%. Similarly, the least broad background corpus gave suboptimal performance in all three experiments. We also demonstrate qualitative differences between background corpora – narrower background corpora tend towards more technical output. We expect our results to generalize to terminology extraction for other legal and technical documents and, generally, to the foreground/background approach to ATE.</abstract>
      <url hash="b5def077">2022.nllp-1.1</url>
      <bibkey>nordquist-meyers-2022-breadth</bibkey>
      <doi>10.18653/v1/2022.nllp-1.1</doi>
    </paper>
    <paper id="2">
      <title>On What it Means to Pay Your Fair Share: Towards Automatically Mapping Different Conceptions of Tax Justice in Legal Research Literature</title>
      <author><first>Reto</first><last>Gubelmann</last><affiliation>University of St.Gallen</affiliation></author>
      <author><first>Peter</first><last>Hongler</last><affiliation>University of St.Gallen</affiliation></author>
      <author><first>Elina</first><last>Margadant</last><affiliation>University of St.Gallen</affiliation></author>
      <author><first>Siegfried</first><last>Handschuh</last><affiliation>University of St. Gallen</affiliation></author>
      <pages>12-30</pages>
      <abstract>In this article, we explore the potential and challenges of applying transformer-based pre-trained language models (PLMs) and statistical methods to a particularly challenging, yet highly important and largely uncharted domain: normative discussions in tax law research. On our conviction, the role of NLP in this essentially contested territory is to make explicit implicit normative assumptions, and to foster debates across ideological divides. To this goal, we propose the first steps towards a method that automatically labels normative statements in tax law research, and that suggests the normative background of these statements. Our results are encouraging, but it is clear that there is still room for improvement.</abstract>
      <url hash="ff8ced9a">2022.nllp-1.2</url>
      <bibkey>gubelmann-etal-2022-means</bibkey>
      <video href="2022.nllp-1.2.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.2</doi>
    </paper>
    <paper id="3">
      <title><fixed-case>C</fixed-case>lass<fixed-case>A</fixed-case>ction<fixed-case>P</fixed-case>rediction: A Challenging Benchmark for Legal Judgment Prediction of Class Action Cases in the <fixed-case>US</fixed-case></title>
      <author><first>Gil</first><last>Semo</last><affiliation>Darrow AI Ltd.</affiliation></author>
      <author><first>Dor</first><last>Bernsohn</last><affiliation>Darrow AI Ltd.</affiliation></author>
      <author><first>Ben</first><last>Hagag</last><affiliation>Darrow AI Ltd.</affiliation></author>
      <author><first>Gila</first><last>Hayat</last><affiliation>Darrow AI Ltd.</affiliation></author>
      <author><first>Joel</first><last>Niklaus</last><affiliation>University of Bern</affiliation></author>
      <pages>31-46</pages>
      <abstract>The research field of Legal Natural Language Processing (NLP) has been very active recently, with Legal Judgment Prediction (LJP) becoming one of the most extensively studied tasks. To date, most publicly released LJP datasets originate from countries with civil law. In this work, we release, for the first time, a challenging LJP dataset focused on class action cases in the US. It is the first dataset in the common law system that focuses on the harder and more realistic task involving the complaints as input instead of the often used facts summary written by the court. Additionally, we study the difficulty of the task by collecting expert human predictions, showing that even human experts can only reach 53% accuracy on this dataset. Our Longformer model clearly outperforms the human baseline (63%), despite only considering the first 2,048 tokens. Furthermore, we perform a detailed error analysis and find that the Longformer model is significantly better calibrated than the human experts. Finally, we publicly release the dataset and the code used for the experiments.</abstract>
      <url hash="b99d638a">2022.nllp-1.3</url>
      <bibkey>semo-etal-2022-classactionprediction</bibkey>
      <doi>10.18653/v1/2022.nllp-1.3</doi>
    </paper>
    <paper id="4">
      <title>Combining <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et and Word Embeddings in Data Augmentation for Legal Texts</title>
      <author><first>Sezen</first><last>Perçin</last><affiliation>Boğaziçi University</affiliation></author>
      <author><first>Andrea</first><last>Galassi</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Francesca</first><last>Lagioia</last><affiliation>Cirsfid Alma-AI and Law department, University of Bologna, and Law Department, European University Institute</affiliation></author>
      <author><first>Federico</first><last>Ruggeri</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Piera</first><last>Santin</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Giovanni</first><last>Sartor</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Paolo</first><last>Torroni</last><affiliation>Alma Mater - Università di Bologna</affiliation></author>
      <pages>47-52</pages>
      <abstract>Creating balanced labeled textual corpora for complex tasks, like legal analysis, is a challenging and expensive process that often requires the collaboration of domain experts. To address this problem, we propose a data augmentation method based on the combination of GloVe word embeddings and the WordNet ontology. We present an example of application in the legal domain, specifically on decisions of the Court of Justice of the European Union.Our evaluation with human experts confirms that our method is more robust than the alternatives.</abstract>
      <url hash="cff4b88f">2022.nllp-1.4</url>
      <bibkey>percin-etal-2022-combining</bibkey>
      <doi>10.18653/v1/2022.nllp-1.4</doi>
    </paper>
    <paper id="5">
      <title>A Legal Approach to Hate Speech – Operationalizing the <fixed-case>EU</fixed-case>’s Legal Framework against the Expression of Hatred as an <fixed-case>NLP</fixed-case> Task</title>
      <author><first>Frederike</first><last>Zufall</last><affiliation>Max Planck Institute for Research on Collective Goods</affiliation></author>
      <author><first>Marius</first><last>Hamacher</last><affiliation>FernUniversität in Hagen</affiliation></author>
      <author><first>Katharina</first><last>Kloppenborg</last><affiliation>Center for Research and Interdisciplinarity</affiliation></author>
      <author><first>Torsten</first><last>Zesch</last><affiliation>Computational Linguistics, FernUniversität in Hagen</affiliation></author>
      <pages>53-64</pages>
      <abstract>We propose a ‘legal approach’ to hate speech detection by operationalization of the decision as to whether a post is subject to criminal law into an NLP task. Comparing existing regulatory regimes for hate speech, we base our investigation on the European Union’s framework as it provides a widely applicable legal minimum standard. Accurately deciding whether a post is punishable or not usually requires legal education. We show that, by breaking the legal assessment down into a series of simpler sub-decisions, even laypersons can annotate consistently. Based on a newly annotated dataset, our experiments show that directly learning an automated model of punishable content is challenging. However, learning the two sub-tasks of ‘target group’ and ‘targeting conduct’ instead of a holistic, end-to-end approach to the legal assessment yields better results. Overall, our method also provides decisions that are more transparent than those of end-to-end models, which is a crucial point in legal decision-making.</abstract>
      <url hash="fb7f8bec">2022.nllp-1.5</url>
      <bibkey>zufall-etal-2022-legal</bibkey>
      <doi>10.18653/v1/2022.nllp-1.5</doi>
    </paper>
    <paper id="6">
      <title>Privacy Pitfalls of Online Service Terms and Conditions: a Hybrid Approach for Classification and Summarization</title>
      <author><first>Emilia</first><last>Lukose</last><affiliation>University of Surrey</affiliation></author>
      <author><first>Suparna</first><last>De</last><affiliation>University of Surrey</affiliation></author>
      <author><first>Jon</first><last>Johnson</last><affiliation>University College London</affiliation></author>
      <pages>65-75</pages>
      <abstract>Verbose and complicated legal terminology in online service terms and conditions (T&amp;C) means that users typically don’t read these documents before accepting the terms of such unilateral service contracts. With such services becoming part of mainstream digital life, highlighting Terms of Service (ToS) clauses that impact on the collection and use of user data and privacy are important concerns. Advances in text summarization can help to create informative and concise summaries of the terms, but existing approaches geared towards news and microblogging corpora are not directly applicable to the ToS domain, which is hindered by a lack of T&amp;C-relevant resources for training and evaluation. This paper presents a ToS model, developing a hybrid extractive-classifier-abstractive pipeline that highlights the privacy and data collection/use-related sections in a ToS document and paraphrases these into concise and informative sentences. Relying on significantly less training data (4313 training pairs) than previous representative works (287,226 pairs), our model outperforms extractive baselines by at least 50% in ROUGE-1 score and 54% in METEOR score. The paper also contributes to existing community efforts by curating a dataset of online service T&amp;C, through a developed web scraping tool.</abstract>
      <url hash="3517cd2d">2022.nllp-1.6</url>
      <bibkey>lukose-etal-2022-privacy</bibkey>
      <video href="2022.nllp-1.6.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.6</doi>
    </paper>
    <paper id="7">
      <title>Abstractive Summarization of <fixed-case>D</fixed-case>utch Court Verdicts Using Sequence-to-sequence Models</title>
      <author><first>Marijn</first><last>Schraagen</last><affiliation>Utrecht University</affiliation></author>
      <author><first>Floris</first><last>Bex</last><affiliation>Utrecht University</affiliation></author>
      <author><first>Nick</first><last>Van De Luijtgaarden</last><affiliation>Utrecht University</affiliation></author>
      <author><first>Daniël</first><last>Prijs</last><affiliation>Utrecht University</affiliation></author>
      <pages>76-87</pages>
      <abstract>With the legal sector embracing digitization, the increasing availability of information has led to a need for systems that can automatically summarize legal documents. Most existing research on legal text summarization has so far focused on extractive models, which can result in awkward summaries, as sentences in legal documents can be very long and detailed. In this study, we apply two abstractive summarization models on a Dutch legal domain dataset. The results show that existing models transfer quite well across domains and languages: the ROUGE scores of our experiments are comparable to state-of-the-art studies on English news article texts. Examining one of the models showed the capability of rewriting long legal sentences to much shorter ones, using mostly vocabulary from the source document. Human evaluation shows that for both models hand-made summaries are still perceived as more relevant and readable, and automatic summaries do not always capture elements such as background, considerations and judgement. Still, generated summaries are valuable if only a keyword summary or no summary at all is present.</abstract>
      <url hash="ae0648b5">2022.nllp-1.7</url>
      <bibkey>schraagen-etal-2022-abstractive</bibkey>
      <video href="2022.nllp-1.7.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.7</doi>
    </paper>
    <paper id="8">
      <title>Legal-Tech Open Diaries: Lesson learned on how to develop and deploy light-weight models in the era of humongous Language Models</title>
      <author><first>Stelios</first><last>Maroudas</last><affiliation>Cognitiv+, Athens University of Economics and Business</affiliation></author>
      <author><first>Sotiris</first><last>Legkas</last><affiliation>Cognitiv+, Athens University of Economics and Business</affiliation></author>
      <author><first>Prodromos</first><last>Malakasiotis</last><affiliation>Workable Software Limited</affiliation></author>
      <author><first>Ilias</first><last>Chalkidis</last><affiliation>University of Copenhagen</affiliation></author>
      <pages>88-110</pages>
      <abstract>In the era of billion-parameter-sized Language Models (LMs), start-ups have to follow trends and adapt their technology accordingly. Nonetheless, there are open challenges since the development and deployment of large models comes with a need for high computational resources and has economical consequences. In this work, we follow the steps of the R&amp;D group of a modern legal-tech start-up and present important insights on model development and deployment. We start from ground zero by pre-training multiple domain-specific multi-lingual LMs which are a better fit to contractual and regulatory text compared to the available alternatives (XLM-R). We present benchmark results of such models in a half-public half-private legal benchmark comprising 5 downstream tasks showing the impact of larger model size. Lastly, we examine the impact of a full-scale pipeline for model compression which includes: a) Parameter Pruning, b) Knowledge Distillation, and c) Quantization: The resulting models are much more efficient without sacrificing performance at large.</abstract>
      <url hash="356889a8">2022.nllp-1.8</url>
      <bibkey>maroudas-etal-2022-legal</bibkey>
      <doi>10.18653/v1/2022.nllp-1.8</doi>
    </paper>
    <paper id="9">
      <title>Towards Cross-Domain Transferability of Text Generation Models for Legal Text</title>
      <author><first>Vinayshekhar</first><last>Bannihatti Kumar</last><affiliation>Aws Ai</affiliation></author>
      <author><first>Kasturi</first><last>Bhattacharjee</last><affiliation>AWS AI, Amazon</affiliation></author>
      <author><first>Rashmi</first><last>Gangadharaiah</last><affiliation>AWS AI, Amazon</affiliation></author>
      <pages>111-118</pages>
      <abstract>Legalese can often be filled with verbose domain-specific jargon which can make it challenging to understand and use for non-experts. Creating succinct summaries of legal documents often makes it easier for user comprehension. However, obtaining labeled data for every domain of legal text is challenging, which makes cross-domain transferability of text generation models for legal text, an important area of research. In this paper, we explore the ability of existing state-of-the-art T5 &amp; BART-based summarization models to transfer across legal domains. We leverage publicly available datasets across four domains for this task, one of which is a new resource for summarizing privacy policies, that we curate and release for academic research. Our experiments demonstrate the low cross-domain transferability of these models, while also highlighting the benefits of combining different domains. Further, we compare the effectiveness of standard metrics for this task and illustrate the vast differences in their performance.</abstract>
      <url hash="2e619422">2022.nllp-1.9</url>
      <bibkey>bannihatti-kumar-etal-2022-towards</bibkey>
      <video href="2022.nllp-1.9.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.9</doi>
    </paper>
    <paper id="10">
      <title>Parameter-Efficient Legal Domain Adaptation</title>
      <author><first>Jonathan</first><last>Li</last><affiliation>Queen’s University</affiliation></author>
      <author><first>Rohan</first><last>Bhambhoria</last><affiliation>Queen’s University</affiliation></author>
      <author><first>Xiaodan</first><last>Zhu</last><affiliation>Queen’s University</affiliation></author>
      <pages>119-129</pages>
      <abstract>Seeking legal advice is often expensive. Recent advancements in machine learning for solving complex problems can be leveraged to help make legal services more accessible to the public. However, real-life applications encounter significant challenges. State-of-the-art language models are growing increasingly large, making parameter-efficient learning increasingly important. Unfortunately, parameter-efficient methods perform poorly with small amounts of data, which are common in the legal domain (where data labelling costs are high). To address these challenges, we propose parameter-efficient legal domain adaptation, which uses vast unsupervised legal data from public legal forums to perform legal pre-training. This method exceeds or matches the fewshot performance of existing models such as LEGAL-BERT on various legal tasks while tuning only approximately 0.1% of model parameters. Additionally, we show that our method can achieve calibration comparable to existing methods across several tasks. To the best of our knowledge, this work is among the first to explore parameter-efficient methods of tuning language models in the legal domain.</abstract>
      <url hash="07eebd9b">2022.nllp-1.10</url>
      <bibkey>li-etal-2022-parameter</bibkey>
      <video href="2022.nllp-1.10.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.10</doi>
    </paper>
    <paper id="11">
      <title>Processing Long Legal Documents with Pre-trained Transformers: Modding <fixed-case>L</fixed-case>egal<fixed-case>BERT</fixed-case> and Longformer</title>
      <author><first>Dimitris</first><last>Mamakas</last><affiliation>Athens University of Economics and Business</affiliation></author>
      <author><first>Petros</first><last>Tsotsi</last><affiliation>Athens University of Economics and Business</affiliation></author>
      <author><first>Ion</first><last>Androutsopoulos</last><affiliation>Athens University of Economics and Business</affiliation></author>
      <author><first>Ilias</first><last>Chalkidis</last><affiliation>University of Copenhagen</affiliation></author>
      <pages>130-142</pages>
      <abstract>Pre-trained Transformers currently dominate most NLP tasks. They impose, however, limits on the maximum input length (512 sub-words in BERT), which are too restrictive in the legal domain. Even sparse-attention models, such as Longformer and BigBird, which increase the maximum input length to 4,096 sub-words, severely truncate texts in three of the six datasets of LexGLUE. Simpler linear classifiers with TF-IDF features can handle texts of any length, require far less resources to train and deploy, but are usually outperformed by pre-trained Transformers. We explore two directions to cope with long legal texts: (i) modifying a Longformer warm-started from LegalBERT to handle even longer texts (up to 8,192 sub-words), and (ii) modifying LegalBERT to use TF-IDF representations. The first approach is the best in terms of performance, surpassing a hierarchical version of LegalBERT, which was the previous state of the art in LexGLUE. The second approach leads to computationally more efficient models at the expense of lower performance, but the resulting models still outperform overall a linear SVM with TF-IDF features in long legal document classification.</abstract>
      <url hash="e3fb1db8">2022.nllp-1.11</url>
      <bibkey>mamakas-etal-2022-processing</bibkey>
      <doi>10.18653/v1/2022.nllp-1.11</doi>
    </paper>
    <paper id="12">
      <title>Data-efficient end-to-end Information Extraction for Statistical Legal Analysis</title>
      <author><first>Wonseok</first><last>Hwang</last><affiliation>LBox</affiliation></author>
      <author><first>Saehee</first><last>Eom</last><affiliation>LBox</affiliation></author>
      <author><first>Hanuhl</first><last>Lee</last><affiliation>LBox</affiliation></author>
      <author><first>Hai Jin</first><last>Park</last><affiliation>Hanyang Univ.</affiliation></author>
      <author><first>Minjoon</first><last>Seo</last><affiliation>Kaist</affiliation></author>
      <pages>143-152</pages>
      <abstract>Legal practitioners often face a vast amount of documents. Lawyers, for instance, search for appropriate precedents favorable to their clients, while the number of legal precedents is ever-growing. Although legal search engines can assist finding individual target documents and narrowing down the number of candidates, retrieved information is often presented as unstructured text and users have to examine each document thoroughly which could lead to information overloading. This also makes their statistical analysis challenging. Here, we present an end-to-end information extraction (IE) system for legal documents. By formulating IE as a generation task, our system can be easily applied to various tasks without domain-specific engineering effort. The experimental results of four IE tasks on Korean precedents shows that our IE system can achieve competent scores (-2.3 on average) compared to the rule-based baseline with as few as 50 training examples per task and higher score (+5.4 on average) with 200 examples. Finally, our statistical analysis on two case categories — drunk driving and fraud — with 35k precedents reveals the resulting structured information from our IE system faithfully reflects the macroscopic features of Korean legal system.</abstract>
      <url hash="78deab4a">2022.nllp-1.12</url>
      <bibkey>hwang-etal-2022-data</bibkey>
      <video href="2022.nllp-1.12.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.12</doi>
    </paper>
    <paper id="13">
      <title>Semantic Segmentation of Legal Documents via Rhetorical Roles</title>
      <author><first>Vijit</first><last>Malik</last><affiliation>Indian Institute of Technology Kanpur</affiliation></author>
      <author><first>Rishabh</first><last>Sanjay</last><affiliation>Indian Institute of Technology Kanpur</affiliation></author>
      <author><first>Shouvik Kumar</first><last>Guha</last><affiliation>Assistant Professor (Law), WBNUJS</affiliation></author>
      <author><first>Angshuman</first><last>Hazarika</last><affiliation>IIM Ranchi</affiliation></author>
      <author><first>Shubham</first><last>Nigam</last><affiliation>IIT Kanpur</affiliation></author>
      <author><first>Arnab</first><last>Bhattacharya</last><affiliation>Dept. of Computer Science and Engineering, IIT Kanpur</affiliation></author>
      <author><first>Ashutosh</first><last>Modi</last><affiliation>Indian Institute of Technology Kanpur</affiliation></author>
      <pages>153-171</pages>
      <abstract>Legal documents are unstructured, use legal jargon, and have considerable length, making them difficult to process automatically via conventional text processing techniques. A legal document processing system would benefit substantially if the documents could be segmented into coherent information units. This paper proposes a new corpus of legal documents annotated (with the help of legal experts) with a set of 13 semantically coherent units labels (referred to as Rhetorical Roles), e.g., facts, arguments, statute, issue, precedent, ruling, and ratio. We perform a thorough analysis of the corpus and the annotations. For automatically segmenting the legal documents, we experiment with the task of rhetorical role prediction: given a document, predict the text segments corresponding to various roles. Using the created corpus, we experiment extensively with various deep learning-based baseline models for the task. Further, we develop a multitask learning (MTL) based deep model with document rhetorical role label shift as an auxiliary task for segmenting a legal document. The proposed model shows superior performance over the existing models. We also experiment with model performance in the case of domain transfer and model distillation techniques to see the model performance in limited data conditions.</abstract>
      <url hash="36e1821f">2022.nllp-1.13</url>
      <bibkey>malik-etal-2022-semantic</bibkey>
      <doi>10.18653/v1/2022.nllp-1.13</doi>
    </paper>
    <paper id="14">
      <title>Privacy-Preserving Models for Legal Natural Language Processing</title>
      <author><first>Ying</first><last>Yin</last><affiliation>Technische Universitat Darmstadt</affiliation></author>
      <author><first>Ivan</first><last>Habernal</last><affiliation>Technische Universität Darmstadt</affiliation></author>
      <pages>172-183</pages>
      <abstract>Pre-training large transformer models with in-domain data improves domain adaptation and helps gain performance on the domain-specific downstream tasks. However, sharing models pre-trained on potentially sensitive data is prone to adversarial privacy attacks. In this paper, we asked to which extent we can guarantee privacy of pre-training data and, at the same time, achieve better downstream performance on legal tasks without the need of additional labeled data. We extensively experiment with scalable self-supervised learning of transformer models under the formal paradigm of differential privacy and show that under specific training configurations we can improve downstream performance without sacrifying privacy protection for the in-domain data. Our main contribution is utilizing differential privacy for large-scale pre-training of transformer language models in the legal NLP domain, which, to the best of our knowledge, has not been addressed before.</abstract>
      <url hash="4cdaf06b">2022.nllp-1.14</url>
      <bibkey>yin-habernal-2022-privacy</bibkey>
      <video href="2022.nllp-1.14.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.14</doi>
    </paper>
    <paper id="15">
      <title>Named Entity Recognition in <fixed-case>I</fixed-case>ndian court judgments</title>
      <author><first>Prathamesh</first><last>Kalamkar</last><affiliation>ThoughtWorks Technologies India Private Limited</affiliation></author>
      <author><first>Astha</first><last>Agarwal</last><affiliation>ThoughtWorks Technologies India Private Limited</affiliation></author>
      <author><first>Aman</first><last>Tiwari</last><affiliation>ThoughtWorks Technologies India Private Limited</affiliation></author>
      <author><first>Smita</first><last>Gupta</last><affiliation>Agami</affiliation></author>
      <author><first>Saurabh</first><last>Karn</last><affiliation>Agami</affiliation></author>
      <author><first>Vivek</first><last>Raghavan</last><affiliation>EkStep Foundation</affiliation></author>
      <pages>184-193</pages>
      <abstract>Identification of named entities from legal texts is an essential building block for developing other legal Artificial Intelligence applications. Named Entities in legal texts are slightly different and more fine-grained than commonly used named entities like Person, Organization, Location etc. In this paper, we introduce a new corpus of 46545 annotated legal named entities mapped to 14 legal entity types. The Baseline model for extracting legal named entities from judgment text is also developed.</abstract>
      <url hash="6ccc73c2">2022.nllp-1.15</url>
      <bibkey>kalamkar-etal-2022-named</bibkey>
      <video href="2022.nllp-1.15.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.15</doi>
    </paper>
    <paper id="17">
      <title>The Legal Argument Reasoning Task in Civil Procedure</title>
      <author><first>Leonard</first><last>Bongard</last><affiliation>Technical University of Darmstadt</affiliation></author>
      <author><first>Lena</first><last>Held</last><affiliation>Technical University of Darmstadt</affiliation></author>
      <author><first>Ivan</first><last>Habernal</last><affiliation>Technische Universität Darmstadt</affiliation></author>
      <pages>194-207</pages>
      <abstract>We present a new NLP task and dataset from the domain of the U.S. civil procedure. Each instance of the dataset consists of a general introduction to the case, a particular question, and a possible solution argument, accompanied by a detailed analysis of why the argument applies in that case. Since the dataset is based on a book aimed at law students, we believe that it represents a truly complex task for benchmarking modern legal language models. Our baseline evaluation shows that fine-tuning a legal transformer provides some advantage over random baseline models, but our analysis reveals that the actual ability to infer legal arguments remains a challenging open research question.</abstract>
      <url hash="608845f6">2022.nllp-1.17</url>
      <bibkey>bongard-etal-2022-legal</bibkey>
      <video href="2022.nllp-1.17.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.17</doi>
    </paper>
    <paper id="18">
      <title>Efficient Deep Learning-based Sentence Boundary Detection in Legal Text</title>
      <author><first>Reshma</first><last>Sheik</last><affiliation>National Institute of Technology, Trichy</affiliation></author>
      <author><first>Gokul</first><last>T</last><affiliation>National Institute of Technology, Trichy</affiliation></author>
      <author><first>S</first><last>Nirmala</last><affiliation>National Institute of Technology, Trichy</affiliation></author>
      <pages>208-217</pages>
      <url hash="f46b2ced">2022.nllp-1.18</url>
      <bibkey>sheik-etal-2022-efficient</bibkey>
      <abstract>A key component of the Natural Language Processing (NLP) pipeline is Sentence Boundary Detection (SBD). Erroneous SBD could affect other processing steps and reduce performance. A few criteria based on punctuation and capitalization are necessary to identify sentence borders in well-defined corpora. However, due to several grammatical ambiguities, the complex structure of legal data poses difficulties for SBD. In this paper, we have trained a neural network framework for identifying the end of the sentence in legal text. We used several state-of-the-art deep learning models, analyzed their performance, and identified that Convolutional Neural Network(CNN) outperformed other deep learning frameworks. We compared the results with rule-based, statistical, and transformer-based frameworks. The best neural network model outscored the popular rule-based framework with an improvement of 8% in the F1 score. Although domain-specific statistical models have slightly improved performance, the trained CNN is 80 times faster in run-time and doesn’t require much feature engineering. Furthermore, after extensive pretraining, the transformer models fall short in overall performance compared to the best deep learning model.</abstract>
      <video href="2022.nllp-1.18.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.18</doi>
    </paper>
    <paper id="19">
      <title>Tracking Semantic Shifts in <fixed-case>G</fixed-case>erman Court Decisions with Diachronic Word Embeddings</title>
      <author><first>Daniel</first><last>Braun</last><affiliation>University of Twente</affiliation></author>
      <pages>218-227</pages>
      <abstract>Language and its usage change over time. While legal language is arguably more stable than everyday language, it is still subject to change. Sometimes it changes gradually and slowly, sometimes almost instantaneously, for example through legislative changes. This paper presents an application of diachronic word embeddings to track changes in the usage of language by German courts triggered by changing legislation, based on a corpus of more than 200,000 documents. The results show the swift and lasting effect that changes in legislation can have on the usage of language by courts and suggest that using time-restricted word embedding models could be beneficial for downstream NLP tasks.</abstract>
      <url hash="a77be2c7">2022.nllp-1.19</url>
      <bibkey>braun-2022-tracking</bibkey>
      <doi>10.18653/v1/2022.nllp-1.19</doi>
    </paper>
    <paper id="20">
      <title>Should <fixed-case>I</fixed-case> disclose my dataset? Caveats between reproducibility and individual data rights</title>
      <author><first>Raysa M.</first><last>Benatti</last><affiliation>University of Campinas</affiliation></author>
      <author><first>Camila M. L.</first><last>Villarroel</last><affiliation>University of Sao Paulo</affiliation></author>
      <author><first>Sandra</first><last>Avila</last><affiliation>University of Campinas</affiliation></author>
      <author><first>Esther L.</first><last>Colombini</last><affiliation>University of Campinas</affiliation></author>
      <author><first>Fabiana</first><last>Severi</last><affiliation>University of Sao Paulo</affiliation></author>
      <pages>228-237</pages>
      <abstract>Natural language processing techniques have helped domain experts solve legal problems. Digital availability of court documents increases possibilities for researchers, who can access them as a source for building datasets — whose disclosure is aligned with good reproducibility practices in computational research. Large and digitized court systems, such as the Brazilian one, are prone to be explored in that sense. However, personal data protection laws impose restrictions on data exposure and state principles about which researchers should be mindful. Special caution must be taken in cases with human rights violations, such as gender discrimination, over which we elaborate as an example of interest. We present legal and ethical considerations on the issue, as well as guidelines for researchers dealing with this kind of data and deciding whether to disclose it.</abstract>
      <url hash="d0647d83">2022.nllp-1.20</url>
      <bibkey>m-benatti-etal-2022-disclose</bibkey>
      <video href="2022.nllp-1.20.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.20</doi>
    </paper>
    <paper id="21">
      <title>Attack on Unfair <fixed-case>T</fixed-case>o<fixed-case>S</fixed-case> Clause Detection: A Case Study using Universal Adversarial Triggers</title>
      <author><first>Shanshan</first><last>Xu</last><affiliation>Technical University of Munich</affiliation></author>
      <author><first>Irina</first><last>Broda</last><affiliation>Technical University of Munich</affiliation></author>
      <author><first>Rashid</first><last>Haddad</last><affiliation>Tum</affiliation></author>
      <author><first>Marco</first><last>Negrini</last><affiliation>Technical University of Munich</affiliation></author>
      <author><first>Matthias</first><last>Grabmair</last><affiliation>Technical University of Munich</affiliation></author>
      <pages>238-245</pages>
      <abstract>Recent work has demonstrated that natural language processing techniques can support consumer protection by automatically detecting unfair clauses in the Terms of Service (ToS) Agreement. This work demonstrates that transformer-based ToS analysis systems are vulnerable to adversarial attacks. We conduct experiments attacking an unfair-clause detector with universal adversarial triggers. Experiments show that a minor perturbation of the text can considerably reduce the detection performance. Moreover, to measure the detectability of the triggers, we conduct a detailed human evaluation study by collecting both answer accuracy and response time from the participants. The results show that the naturalness of the triggers remains key to tricking readers.</abstract>
      <url hash="18907fd1">2022.nllp-1.21</url>
      <bibkey>xu-etal-2022-attack</bibkey>
      <doi>10.18653/v1/2022.nllp-1.21</doi>
    </paper>
    <paper id="22">
      <title><fixed-case>E</fixed-case>-<fixed-case>NER</fixed-case> — An Annotated Named Entity Recognition Corpus of Legal Text</title>
      <author><first>Ting Wai Terence</first><last>Au</last><affiliation>University College London</affiliation></author>
      <author><first>Vasileios</first><last>Lampos</last><affiliation>University College London</affiliation></author>
      <author><first>Ingemar</first><last>Cox</last><affiliation>University College London, University of Copenhagen, Denmark</affiliation></author>
      <pages>246-255</pages>
      <abstract>Identifying named entities such as a person, location or organization, in documents can highlight key information to readers. Training Named Entity Recognition (NER) models requires an annotated data set, which can be a time-consuming labour-intensive task. Nevertheless, there are publicly available NER data sets for general English. Recently there has been interest in developing NER for legal text. However, prior work and experimental results reported here indicate that there is a significant degradation in performance when NER methods trained on a general English data set are applied to legal text. We describe a publicly available legal NER data set, called E-NER, based on legal company filings available from the US Securities and Exchange Commission’s EDGAR data set. Training a number of different NER algorithms on the general English CoNLL-2003 corpus but testing on our test collection confirmed significant degradations in accuracy, as measured by the F1-score, of between 29.4% and 60.4%, compared to training and testing on the E-NER collection.</abstract>
      <url hash="3ea7fdd2">2022.nllp-1.22</url>
      <bibkey>au-etal-2022-e</bibkey>
      <doi>10.18653/v1/2022.nllp-1.22</doi>
    </paper>
    <paper id="24">
      <title>Detecting Relevant Differences Between Similar Legal Texts</title>
      <author><first>Xiang</first><last>Li</last><affiliation>University of Ottawa</affiliation></author>
      <author><first>Jiaxun</first><last>Gao</last><affiliation>University of Ottawa</affiliation></author>
      <author><first>Diana</first><last>Inkpen</last><affiliation>University of Ottawa</affiliation></author>
      <author><first>Wolfgang</first><last>Alschner</last><affiliation>University of Ottawa</affiliation></author>
      <pages>256-264</pages>
      <abstract>Given two similar legal texts, is it useful to be able to focus only on the parts that contain relevant differences. However, because of variation in linguistic structure and terminology, it is not easy to identify true semantic differences. An accurate difference detection model between similar legal texts is therefore in demand, in order to increase the efficiency of legal research and document analysis. In this paper, we automatically label a training dataset of sentence pairs using an existing legal resource of international investment treaties that were already manually annotated with metadata. Then we propose models based on state-of-the-art deep learning techniques for the novel task of detecting relevant differences. In addition to providing solutions for this task, we include models for automatically producing metadata for the treaties that do not have it.</abstract>
      <url hash="020e6d6d">2022.nllp-1.24</url>
      <bibkey>li-etal-2022-detecting</bibkey>
      <doi>10.18653/v1/2022.nllp-1.24</doi>
    </paper>
    <paper id="25">
      <title>Legal and Political Stance Detection of <fixed-case>SCOTUS</fixed-case> Language</title>
      <author><first>Noah</first><last>Bergam</last><affiliation>Columbia University</affiliation></author>
      <author><first>Emily</first><last>Allaway</last><affiliation>Columbia University</affiliation></author>
      <author><first>Kathleen</first><last>Mckeown</last><affiliation>Columbia University and Amazon (Amazon Scholar)</affiliation></author>
      <pages>265-275</pages>
      <abstract>We analyze publicly available US Supreme Court documents using automated stance detection. In the first phase of our work, we investigate the extent to which the Court’s public-facing language is political. We propose and calculate two distinct ideology metrics of SCOTUS justices using oral argument transcripts. We then compare these language-based metrics to existing social scientific measures of the ideology of the Supreme Court and the public. Through this cross-disciplinary analysis, we find that justices who are more responsive to public opinion tend to express their ideology during oral arguments. This observation provides a new kind of evidence in favor of the attitudinal change hypothesis of Supreme Court justice behavior. As a natural extension of this political stance detection, we propose the more specialized task of legal stance detection with our new dataset SC-stance, which matches written opinions to legal questions. We find competitive performance on this dataset using language adapters trained on legal documents.</abstract>
      <url hash="f490b07a">2022.nllp-1.25</url>
      <bibkey>bergam-etal-2022-legal</bibkey>
      <doi>10.18653/v1/2022.nllp-1.25</doi>
    </paper>
    <paper id="26">
      <title>Graph-based Keyword Planning for Legal Clause Generation from Topics</title>
      <author><first>Sagar</first><last>Joshi</last><affiliation>International Institute of Information Technology, Hyderabad</affiliation></author>
      <author><first>Sumanth</first><last>Balaji</last><affiliation>IIIT-Hyderabad, India</affiliation></author>
      <author><first>Aparna</first><last>Garimella</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Vasudeva</first><last>Varma</last><affiliation>IIIT Hyderabad</affiliation></author>
      <pages>276-286</pages>
      <abstract>Generating domain-specific content such as legal clauses based on minimal user-provided information can be of significant benefit in automating legal contract generation. In this paper, we propose a controllable graph-based mechanism that can generate legal clauses using only the topic or type of the legal clauses. Our pipeline consists of two stages involving a graph-based planner followed by a clause generator. The planner outlines the content of a legal clause as a sequence of keywords in the order of generic to more specific clause information based on the input topic using a controllable graph-based mechanism. The generation stage takes in a given plan and generates a clause. The pipeline consists of a graph-based planner followed by text generation. We illustrate the effectiveness of our proposed two-stage approach on a broad set of clause topics in contracts.</abstract>
      <url hash="d15182c8">2022.nllp-1.26</url>
      <bibkey>joshi-etal-2022-graph</bibkey>
      <video href="2022.nllp-1.26.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.26</doi>
    </paper>
    <paper id="27">
      <title>Automatic Classification of Legal Violations in Cookie Banner Texts</title>
      <author><first>Marieke</first><last>Van Hofslot</last><affiliation>Utrecht University</affiliation></author>
      <author><first>Almila</first><last>Akdag Salah</last><affiliation>Utrecht University</affiliation></author>
      <author><first>Albert</first><last>Gatt</last><affiliation>Utrecht University</affiliation></author>
      <author><first>Cristiana</first><last>Santos</last><affiliation>Utrecht Universiy</affiliation></author>
      <pages>287-295</pages>
      <url hash="06152028">2022.nllp-1.27</url>
      <bibkey>van-hofslot-etal-2022-automatic</bibkey>
      <abstract>Cookie banners are designed to request consent from website visitors for their personal data. Recent research suggest that a high percentage of cookie banners violate legal regulations as defined by the General Data Protection Regulation (GDPR) and the ePrivacy Directive. In this paper, we focus on language used in these cookie banners, and whether these violations can be automatically detected, or not. We make use of a small cookie banner dataset that is annotated by five experts for legal violations and test it with state of the art classification models, namely BERT, LEGAL-BERT, BART in a zero-shot setting and BERT with LIWC embeddings. Our results show that none of the models outperform the others in all classes, but in general, BERT and LEGAL-BERT provide the highest accuracy results (70%-97%). However, they are influenced by the small size and the unbalanced distributions in the dataset.</abstract>
      <doi>10.18653/v1/2022.nllp-1.27</doi>
    </paper>
    <paper id="28">
      <title>Text Simplification for Legal Domain: {<fixed-case>I</fixed-case>}nsights and Challenges</title>
      <author><first>Aparna</first><last>Garimella</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Abhilasha</first><last>Sancheti</last><affiliation>University of Maryland</affiliation></author>
      <author><first>Vinay</first><last>Aggarwal</last><affiliation>Adobe</affiliation></author>
      <author><first>Ananya</first><last>Ganesh</last><affiliation>University of Colorado Boulder</affiliation></author>
      <author><first>Niyati</first><last>Chhaya</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Nandakishore</first><last>Kambhatla</last><affiliation>Adobe Research</affiliation></author>
      <pages>296-304</pages>
      <url hash="9d0e3193">2022.nllp-1.28</url>
      <bibkey>garimella-etal-2022-text</bibkey>
      <abstract>Legal documents such as contracts contain complex and domain-specific jargons, long and nested sentences, and often present with several details that may be difficult to understand for laypeople without domain expertise. In this paper, we explore the problem of text simplification (TS) in legal domain. The main challenge to this is the lack of availability of complex-simple parallel datasets for the legal domain. We investigate some of the existing datasets, methods, and metrics in the TS literature for simplifying legal texts, and perform human evaluation to analyze the gaps. We present some of the challenges involved, and outline a few open questions that need to be addressed for future research in this direction.</abstract>
      <video href="2022.nllp-1.28.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.28</doi>
    </paper>
    <paper id="29">
      <title>Legal Named Entity Recognition with Multi-Task Domain Adaptation</title>
      <author><first>Răzvan-Alexandru</first><last>Smădu</last><affiliation>University Politehnica of Bucharest</affiliation></author>
      <author><first>Ion-Robert</first><last>Dinică</last><affiliation>University Politehnica of Bucharest</affiliation></author>
      <author><first>Andrei-Marius</first><last>Avram</last><affiliation>Research Institute for Artificial Intelligence, Romanian Academy</affiliation></author>
      <author><first>Dumitru-Clementin</first><last>Cercel</last><affiliation>University Politehnica of Bucharest</affiliation></author>
      <author><first>Florin</first><last>Pop</last><affiliation>University Politehnica of Bucharest</affiliation></author>
      <author><first>Mihaela-Claudia</first><last>Cercel</last><affiliation>First District Court of Giurgiu</affiliation></author>
      <pages>305-321</pages>
      <abstract>Named Entity Recognition (NER) is a well-explored area from Information Retrieval and Natural Language Processing with an extensive research community. Despite that, few languages, such as English and German, are well-resourced, whereas many other languages, such as Romanian, have scarce resources, especially in domain-specific applications. In this work, we address the NER problem in the legal domain from both Romanian and German languages and evaluate the performance of our proposed method based on domain adaptation. We employ multi-task learning to jointly train a neural network on two legal and general domains and perform adaptation among them. The results show that domain adaptation increase performances by a small amount, under 1%, while considerable improvements are in the recall metric.</abstract>
      <url hash="11b7c1b0">2022.nllp-1.29</url>
      <bibkey>smadu-etal-2022-legal</bibkey>
      <video href="2022.nllp-1.29.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.29</doi>
    </paper>
    <paper id="30">
      <title>Computing and Exploiting Document Structure to Improve Unsupervised Extractive Summarization of Legal Case Decisions</title>
      <author><first>Yang</first><last>Zhong</last><affiliation>University of Pittsburgh</affiliation></author>
      <author><first>Diane</first><last>Litman</last><affiliation>University of Pittsburgh</affiliation></author>
      <pages>322-337</pages>
      <abstract>Though many algorithms can be used to automatically summarize legal case decisions, most fail to incorporate domain knowledge about how important sentences in a legal decision relate to a representation of its document structure. For example, analysis of a legal case sum- marization dataset demonstrates that sentences serving different types of argumentative roles in the decision appear in different sections of the document. In this work, we propose an unsupervised graph-based ranking model that uses a reweighting algorithm to exploit properties of the document structure of legal case decisions. We also explore the impact of using different methods to compute the document structure. Results on the Canadian Legal Case Law dataset show that our proposed method outperforms several strong baselines.</abstract>
      <url hash="59c098e2">2022.nllp-1.30</url>
      <bibkey>zhong-litman-2022-computing</bibkey>
      <video href="2022.nllp-1.30.mp4"/>
      <doi>10.18653/v1/2022.nllp-1.30</doi>
    </paper>
    <paper id="31">
      <title><fixed-case>A</fixed-case>ra<fixed-case>L</fixed-case>egal-<fixed-case>BERT</fixed-case>: A pretrained language model for <fixed-case>A</fixed-case>rabic Legal text</title>
      <author><first>Muhammad</first><last>Al-qurishi</last><affiliation>King Saud University</affiliation></author>
      <author><first>Sarah</first><last>Alqaseemi</last><affiliation>Elm Company</affiliation></author>
      <author><first>Riad</first><last>Souissi</last><affiliation>Elm Company</affiliation></author>
      <pages>338-344</pages>
      <abstract>The effectiveness of the bidirectional encoder representations from transformers (BERT) model for multiple linguistic tasks is well documented. However, its potential for a narrow and specific domain, such as legal, has not been fully explored. In this study, we examine the use of BERT in the Arabic legal domain and customize this language model for several downstream tasks using different domain-relevant training and test datasets to train BERT from scratch. We introduce AraLegal-BERT, a bidirectional encoder transformer-based model that has been thoroughly tested and carefully optimized with the goal of amplifying the impact of natural language processing-driven solutions on jurisprudence, legal documents, and legal practice. We fine-tuned AraLegal-BERT and evaluated it against three BERT variants for the Arabic language in three natural language understanding tasks. The results showed that the base version of AraLegal-BERT achieved better accuracy than the typical and original BERT model concerning legal texts.</abstract>
      <url hash="c52db937">2022.nllp-1.31</url>
      <bibkey>al-qurishi-etal-2022-aralegal</bibkey>
      <doi>10.18653/v1/2022.nllp-1.31</doi>
    </paper>
    <paper id="32">
      <title>An Efficient Active Learning Pipeline for Legal Text Classification</title>
      <author><first>Sepideh</first><last>Mamooler</last><affiliation>Swiss Federal Institute of Technology Lausanne (EPFL)</affiliation></author>
      <author><first>Rémi</first><last>Lebret</last><affiliation>Epfl</affiliation></author>
      <author><first>Stephane</first><last>Massonnet</last><affiliation>Epfl</affiliation></author>
      <author><first>Karl</first><last>Aberer</last><affiliation>Epfl</affiliation></author>
      <pages>345-358</pages>
      <url hash="493906ad">2022.nllp-1.32</url>
      <bibkey>mamooler-etal-2022-efficient</bibkey>
      <abstract>Active Learning (AL) is a powerful tool for learning with less labeled data, in particular, for specialized domains, like legal documents, where unlabeled data is abundant, but the annotation requires domain expertise and is thus expensive. Recent works have shown the effectiveness of AL strategies for pre-trained language models. However, most AL strategies require a set of labeled samples to start with, which is expensive to acquire. In addition, pre-trained language models have been shown unstable during fine-tuning with small datasets, and their embeddings are not semantically meaningful. In this work, we propose a pipeline for effectively using active learning with pre-trained language models in the legal domain. To this end, we leverage the available <i>unlabeled</i> data in three phases. First, we continue pre-training the model to adapt it to the downstream task. Second, we use knowledge distillation to guide the model’s embeddings to a semantically meaningful space. Finally, we propose a simple, yet effective, strategy to find the initial set of labeled samples with fewer actions compared to existing methods. Our experiments on Contract-NLI, adapted to the classification task, and LEDGAR benchmarks show that our approach outperforms standard AL strategies, and is more efficient. Furthermore, our pipeline reaches comparable results to the fully-supervised approach with a small performance gap, and dramatically reduced annotation cost. Code and the adapted data will be made available.</abstract>
      <doi>10.18653/v1/2022.nllp-1.32</doi>
    </paper>
  </volume>
</collection>
