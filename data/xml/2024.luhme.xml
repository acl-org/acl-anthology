<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.luhme">
  <volume id="1" ingest-date="2025-01-09" type="proceedings">
    <meta>
      <booktitle>Proceedings of the First LUHME Workshop</booktitle>
      <editor><first>Rui</first><last>Sousa-Silva</last></editor>
      <editor><first>Henrique</first><last>Lopes Cardoso</last></editor>
      <editor><first>Maarit</first><last>Koponen</last></editor>
      <editor><first>Antonio</first><last>Pareja Lora</last></editor>
      <editor><first>Márta</first><last>Seresi</last></editor>
      <publisher>CLUP, Centro de Linguística da Universidade do Porto FLUP - Faculdade de Letras da Universidade do Porto</publisher>
      <address>Santiago de Compostela, Spain</address>
      <month>October</month>
      <year>2024</year>
      <url hash="c9d4f6fc">2024.luhme-1</url>
      <venue>luhme</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="f063f8af">2024.luhme-1.0</url>
      <bibkey>luhme-2024-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Converso: Improving <fixed-case>LLM</fixed-case> Chatbot Interfaces and Task Execution via Conversational Form</title>
      <author><first>Gianfranco</first><last>Demarco</last></author>
      <author><first>Nicola</first><last>Fanelli</last></author>
      <author><first>Gennaro</first><last>Vessio</last></author>
      <author><first>Giovanna</first><last>Castellano</last></author>
      <pages>5–11</pages>
      <abstract>Recent advancements in large language models (LLMs) have enabled more autonomous conversational AI agents. However, challenges remain in developing effective chatbots, particularly in addressing LLMs’ lack of “statefulness”. This paper presents Converso, a novel chatbot framework that introduces a new conversation flow based on stateful conversational forms designed for natural data acquisition through dialogue. Converso leverages LLMs, LangChain, and a containerized architecture to provide an end-to-end chatbot system with Telegram as the user interface. The key innovation in Converso is its implementation of conversational forms, which guide users through form completion via a structured dialogue flow. Converso’s chatbots can be linked with multiple forms that are automatically triggered based on the user’s intent. Our forms are fully integrated into the LangChain ecosystem, allowing the LLM to use tools for form completion and dynamic validation. Evaluations show that this approach significantly improves task completion rates compared to LLMs alone. Converso demonstrates how specifically designed conversational flows can enhance the capabilities of LLM-based chatbots for practical data collection applications. Our implementation is available at: https://github.com/gianfrancodemarco/converso-chatbot.</abstract>
      <url hash="c2cd2b42">2024.luhme-1.1</url>
      <bibkey>demarco-etal-2024-converso</bibkey>
    </paper>
    <paper id="2">
      <title>A <fixed-case>G</fixed-case>rice-ful Examination of Offensive Language: Using <fixed-case>NLP</fixed-case> Methods to Assess the Co-operative Principle</title>
      <author><first>Katerina</first><last>Korre</last></author>
      <author><first>Federico</first><last>Ruggeri</last></author>
      <author><first>Alberto</first><last>Barrón-Cedeño</last></author>
      <pages>12–19</pages>
      <abstract>Natural Language Processing (NLP) can provide tools for analyzing specific intricate language phenomena, such as offensiveness in language. In this study, we employ methods from pragmatics, more specifically Gricean theory, as well as NLP techniques, to analyze instances of online offensive language. We present a comparative analysis between offensive and non-offensive instances with regard to the degree to which the 4 Gricean Maxims (Quality, Quantity, Manner, and Relevance) are flouted or violated. To facilitate our analysis, we employ NLP tools to filter the instances and proceed to a more thorough qualitative analysis. Our findings reveal that offensive and non-offensive speech do not differ significantly when we evaluate with metrics that correspond to the Gricean Maxims, apart from some aspects of the Maxim of Quality and the Maxim of Manner. Through this paper, we advocate for a turn towards mixed approaches to linguistic topics by also paving the way for a modernization of discourse analysis and natural language understanding that encompasses computational methods. Warning: This paper contains offensive language that might be triggering for some individuals.</abstract>
      <url hash="abda0f89">2024.luhme-1.2</url>
      <bibkey>korre-etal-2024-grice</bibkey>
    </paper>
    <paper id="3">
      <title>Mapping Sentiments: A Journey into Low-Resource <fixed-case>L</fixed-case>uxembourgish Analysis</title>
      <author><first>Nina</first><last>Hosseini-Kivanani</last></author>
      <author><first>Julien</first><last>Kühn</last></author>
      <author><first>Christoph</first><last>Schommer</last></author>
      <pages>20–27</pages>
      <abstract>Sentiment analysis (SA) plays a vital role in interpreting human opinions across different languages, especially in contexts like social media, product reviews, and other user-generated content. This study focuses on Luxembourgish, a low-resource language critical to Luxembourg’s identity, utilizing advanced deep learning models such as BERT, RoBERTa, LuxemBERTand LuxGPT-2. These models were enhanced with transfer learning, active learning strategies, and context-aware embeddings, enabling effective Luxembourgish processing. These models further improved with context-aware embeddings and were able to accurately detect sentiments, categorizing news comments into positive, negative, and neutral sentiments. Our approach highlights the significant role of human-in-the-loop (HITL) methodologies, which refine model accuracy by aligning automated analyses with human judgment. The findings indicate that LuxembBERT, especially when enhanced with the HITL method involving feedback from 500 and 1000 annotated sentences, outperforms other models in both binary (positive vs. negative) and multi-class (positive, neutral, and negative) classification tasks. The HITL approach not only refined model accuracy but also provided substantial improvements in understanding and processing sentiments and sarcasm, often challenging for automated systems. This study establishes the basis for future research to extend these methodologies to other underresourced languages, promising improvements in Natural Language Processing (NLP) applications across diverse linguistic landscapes.</abstract>
      <url hash="3eab5795">2024.luhme-1.3</url>
      <bibkey>hosseini-kivanani-etal-2024-mapping</bibkey>
    </paper>
    <paper id="4">
      <title>Navigating Opinion Space: A Study of Explicit and Implicit Opinion Generation in Language Models</title>
      <author><first>Chaya</first><last>Liebeskind</last></author>
      <author><first>Barbara</first><last>Lewandowska-Tomaszczyk</last></author>
      <pages>28–34</pages>
      <abstract>The paper focuses on testing the use of conversational Large Language Models (LLMs), in particular chatGPT and Google models, instructed to assume the role of linguistics experts to produce opinionated texts, which are defined as subjective statements about animates, things, events or properties, in contrast to knowledge/evidence-based objective factual statements. The taxonomy differentiates between Explicit (Direct or Indirect), and Implicit opinionated texts, further distinguishing between positive and negative, ambiguous, or balanced opinions. Examples of opinionated texts and instances of explicit opinion-marking discourse markers (words and phrases) we identified, as well as instances of opinion-marking mental verbs, evaluative and emotion phraseology, and expressive lexis, were provided in a series of prompts. The model demonstrated accurate identification of Direct and Indirect Explicit opinionated utterances, successfully classifying them according to language-specific properties, while less effective performance was observed for prompts requesting illustrations for Implicitly opinionated texts.To tackle this obstacle, the Chain-of-Thoughts methodology was used. Requested to convert the erroneously recognized opinion instances into factual knowledge sentences, LLMs effectively transformed texts containing explicit markers of opinion. However, the ability to transform Explicit Indirect, and Implicit opinionated texts into factual statements is lacking. This finding is interesting as, while the LLM is supposed to give a linguistic statement with factual information, it might be unaware of implicit opinionated content. Our experiment with the LLMs presents novel prospects for the field of linguistics.</abstract>
      <url hash="fa51ff31">2024.luhme-1.4</url>
      <bibkey>liebeskind-lewandowska-tomaszczyk-2024-navigating</bibkey>
    </paper>
  </volume>
</collection>
