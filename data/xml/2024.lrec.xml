<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.lrec">
  <volume id="tutorials" ingest-date="2024-05-10" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024): Tutorial Summaries</booktitle>
      <editor><first>Roman</first><last>Klinger</last></editor>
      <editor><first>Naozaki</first><last>Okazaki</last></editor>
      <editor><first>Nicoletta</first><last>Calzolari</last></editor>
      <editor><first>Min-Yen</first><last>Kan</last></editor>
      <publisher>ELRA and ICCL</publisher>
      <address>Torino, Italia</address>
      <month>May</month>
      <year>2024</year>
      <url hash="b712390f">2024.lrec-tutorials</url>
      <venue>lrec</venue>
      <venue>coling</venue>
    </meta>
    <frontmatter>
      <url hash="14adbb23">2024.lrec-tutorials.0</url>
      <bibkey>lrec-2024-2024</bibkey>
    </frontmatter>
    <paper id="1">
      <title>From Multimodal <fixed-case>LLM</fixed-case> to Human-level <fixed-case>AI</fixed-case>: Modality, Instruction, Reasoning, Efficiency and beyond</title>
      <author><first>Hao</first><last>Fei</last></author>
      <author><first>Yuan</first><last>Yao</last></author>
      <author><first>Zhuosheng</first><last>Zhang</last></author>
      <author><first>Fuxiao</first><last>Liu</last></author>
      <author><first>Ao</first><last>Zhang</last></author>
      <author><first>Tat-Seng</first><last>Chua</last></author>
      <pages>1–8</pages>
      <abstract>Artificial intelligence (AI) encompasses knowledge acquisition and real-world grounding across various modalities. As a multidisciplinary research field, multimodal large language models (MLLMs) have recently garnered growing interest in both academia and industry, showing an unprecedented trend to achieve human-level AI via MLLMs. These large models offer an effective vehicle for understanding, reasoning, and planning by integrating and modeling diverse information modalities, including language, visual, auditory, and sensory data. This tutorial aims to deliver a comprehensive review of cutting-edge research in MLLMs, focusing on four key areas: MLLM architecture design, instructional learning, multimodal reasoning, and the efficiency of MLLMs. We will explore technical advancements, synthesize key challenges, and discuss potential avenues for future research.</abstract>
      <url hash="d5a30633">2024.lrec-tutorials.1</url>
      <bibkey>fei-etal-2024-multimodal</bibkey>
    </paper>
    <paper id="2">
      <title>Geo-Cultural Representation and Inclusion in Language Technologies</title>
      <author><first>Sunipa</first><last>Dev</last></author>
      <author><first>Rida</first><last>Qadri</last></author>
      <pages>9–12</pages>
      <abstract>Training and evaluation of language models are increasingly relying on semi-structured data that is annotated by humans, along with techniques such as RLHF growing in usage across the board. As a result, both the data and the human perspectives involved in this process play a key role in what is taken as ground truth by our models. As annotation tasks are becoming increasingly more subjective and culturally complex, it is unclear how much of their socio-cultural identity annotators use to respond to tasks. We also currently do not have ways to integrate rich and diverse community perspectives into our language technologies. Accounting for such cross-cultural differences in interacting with technology is an increasingly crucial step for evaluating AI harms holistically. Without this, the state of the art of the AI models being deployed is at risk of causing unprecedented biases at a global scale. In this tutorial, we will take an interactive approach by utilizing some different types of annotation tasks to investigate together how our different socio-cultural perspectives and lived experiences influence what we consider as appropriate representations of global concepts.</abstract>
      <url hash="a6d87570">2024.lrec-tutorials.2</url>
      <bibkey>dev-qadri-2024-geo</bibkey>
    </paper>
    <paper id="3">
      <title>Meaning Representations for Natural Languages: Design, Models and Applications</title>
      <author><first>Julia</first><last>Bonn</last></author>
      <author><first>Jeffrey</first><last>Flanigan</last></author>
      <author><first>Jan</first><last>Hajič</last></author>
      <author><first>Ishan</first><last>Jindal</last></author>
      <author><first>Yunyao</first><last>Li</last></author>
      <author><first>Nianwen</first><last>Xue</last></author>
      <pages>13–18</pages>
      <abstract>This tutorial reviews the design of common meaning representations, SoTA models for predicting meaning representations, and the applications of meaning representations in a wide range of downstream NLP tasks and real-world applications. Reporting by a diverse team of NLP researchers from academia and industry with extensive experience in designing, building and using meaning representations, our tutorial has three components: (1) an introduction to common meaning representations, including basic concepts and design challenges; (2) a review of SoTA methods on building models for meaning representations; and (3) an overview of applications of meaning representations in downstream NLP tasks and real-world applications. We propose a cutting-edge, full-day tutorial for all stakeholders in the AI community, including NLP researchers, domain-specific practitioners, and students</abstract>
      <url hash="33d0656d">2024.lrec-tutorials.3</url>
      <bibkey>bonn-etal-2024-meaning</bibkey>
    </paper>
    <paper id="4">
      <title>Navigating the Modern Evaluation Landscape: Considerations in Benchmarks and Frameworks for Large Language Models (<fixed-case>LLM</fixed-case>s)</title>
      <author><first>Leshem</first><last>Choshen</last></author>
      <author><first>Ariel</first><last>Gera</last></author>
      <author><first>Yotam</first><last>Perlitz</last></author>
      <author><first>Michal</first><last>Shmueli-Scheuer</last></author>
      <author><first>Gabriel</first><last>Stanovsky</last></author>
      <pages>19–25</pages>
      <abstract>General-Purpose Language Models have changed the world of Natural Language Processing, if not the world itself. The evaluation of such versatile models, while supposedly similar to evaluation of generation models before them, in fact presents a host of new evaluation challenges and opportunities. In this Tutorial, we will start from the building blocks of evaluation. The tutorial welcomes people from diverse backgrounds and assumes little familiarity with metrics, datasets, prompts and benchmarks. It will lay the foundations and explain the basics and their importance, while touching on the major points and breakthroughs of the recent era of evaluation. It will also compare traditional evaluation methods – which are still widely used – to newly developed methods. We will contrast new to old approaches, from evaluating on many-task benchmarks rather than on dedicated datasets to efficiency constraints, and from testing stability and prompts on in-context learning to using the models themselves as evaluation metrics. Finally, the tutorial will cover practical issues, ranging from reviewing widely-used benchmarks and prompt banks to efficient evaluation.</abstract>
      <url hash="12099d66">2024.lrec-tutorials.4</url>
      <bibkey>choshen-etal-2024-navigating</bibkey>
    </paper>
    <paper id="5">
      <title>Mining, Assessing, and Improving Arguments in <fixed-case>NLP</fixed-case> and the Social Sciences</title>
      <author><first>Gabriella</first><last>Lapesa</last></author>
      <author><first>Eva Maria</first><last>Vecchi</last></author>
      <author><first>Serena</first><last>Villata</last></author>
      <author><first>Henning</first><last>Wachsmuth</last></author>
      <pages>26–32</pages>
      <abstract>Computational argumentation is an interdisciplinary research field, connecting Natural Language Processing (NLP) to other disciplines such as the social sciences. The focus of recent research has concentrated on <i>argument quality assessment</i>: what makes an argument good or bad? We present a tutorial which is an updated edition of the EACL 2023 tutorial presented by the same authors. As in the previous version, the tutorial will have a strong interdisciplinary and interactive nature, and will be structured along three main coordinates: (1) the notions of argument quality (AQ) across disciplines (how do we recognize good and bad arguments?), with a particular focus on the interface between Argument Mining (AM) and Deliberation Theory; (2) the modeling of subjectivity (who argues to whom; what are their beliefs?); and (3) the generation of improved arguments (what makes an argument better?). The tutorial will also touch upon a series of topics that are particularly relevant for the LREC-COLING audience (the issue of resource quality for the assessment of AQ; the interdisciplinary application of AM and AQ in a text-as-data approach to Political Science), in line with the developments in NLP (LLMs for AQ assessment), and relevant for the societal applications of AQ assessment (bias and debiasing). We will involve the participants in two annotation studies on the assessment and the improvement of quality.</abstract>
      <url hash="e12baa86">2024.lrec-tutorials.5</url>
      <bibkey>lapesa-etal-2024-mining</bibkey>
    </paper>
    <paper id="6">
      <title>Knowledge Editing for Large Language Models</title>
      <author><first>Ningyu</first><last>Zhang</last></author>
      <author><first>Yunzhi</first><last>Yao</last></author>
      <author><first>Shumin</first><last>Deng</last></author>
      <pages>33–41</pages>
      <abstract>Even with their impressive abilities, Large Language Models (LLMs) such as ChatGPT are not immune to issues of factual or logically consistent. Concretely, the key concern is how to seamlessly update those LLMs to correct mistakes without resorting to an exhaustive retraining or continuous training procedure, both of which can demand significant computational resources and time. Thus, the capability to edit LLMs offers an efficient solution to alter a model’s behavior, notably within a distinct area of interest, without negatively impacting its performance on other tasks. Through this tutorial, we strive to acquaint interested NLP researchers with recent and emerging techniques for editing LLMs. Specifically, we aim to present a systematic and current overview of cutting-edge methods, supplemented with practical tools, and unveil new research opportunities for our audiences. All the valuable resources can be accessed at https://github.com/zjunlp/KnowledgeEditingPapers.</abstract>
      <url hash="4cf4a23d">2024.lrec-tutorials.6</url>
      <bibkey>zhang-etal-2024-knowledge</bibkey>
    </paper>
    <paper id="7">
      <title>The <fixed-case>DB</fixed-case>pedia Databus Tutorial: Increase the Visibility and Usability of Your Data</title>
      <author><first>Milan</first><last>Dojchinovski</last></author>
      <pages>42–44</pages>
      <abstract>This tutorial introduces DBpedia Databus (https://databus.dbpedia.org), a FAIR data publishing platform, to address challenges faced by data producers and consumers. It covers data organization, publishing, and consumption on the DBpedia Databus, with an exclusive focus on Linguistic Knowledge Graphs. The tutorial offers practical insights for knowledge graph stakeholders, aiding data integration and accessibility in the Linked Open Data community. Designed for a diverse audience, it fosters hands-on learning to familiarize participants with the DBpedia Databus technology.</abstract>
      <url hash="c9c0dce3">2024.lrec-tutorials.7</url>
      <bibkey>dojchinovski-2024-dbpedia</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>NLP</fixed-case> for Chemistry – Introduction and Recent Advances</title>
      <author><first>Camilo</first><last>Thorne</last></author>
      <author><first>Saber</first><last>Akhondi</last></author>
      <pages>45–49</pages>
      <abstract>In this half-day tutorial we will be giving an introductory overview to a number of recent applications of natural language processing to a relatively underrepresented application domain: chemistry. Specifically, we will see how neural language models (transformers) can be applied (oftentimes with near-human performance) to chemical text mining, reaction extraction, or more importantly computational chemistry (forward and backward synthesis of chemical compounds). At the same time, a number of gold standards for experimentation have been made available to the research –academic and otherwise– community. Theoretical results will be, whenever possible, supported by system demonstrations in the form of Jupyter notebooks. This tutorial targets an audience interested in bioinformatics and biomedical applications, but pre-supposes no advanced knowledge of either.</abstract>
      <url hash="921ee182">2024.lrec-tutorials.8</url>
      <bibkey>thorne-akhondi-2024-nlp</bibkey>
    </paper>
    <paper id="9">
      <title>Formal Semantic Controls over Language Models</title>
      <author><first>Danilo</first><last>Silva de Carvalho</last></author>
      <author><first>Yingji</first><last>Zhang</last></author>
      <author><first>André</first><last>Freitas</last></author>
      <pages>50–55</pages>
      <abstract>Text embeddings provide a concise representation of the semantics of sentences and larger spans of text, rather than individual words, capturing a wide range of linguistic features. They have found increasing application to a variety of NLP tasks, including machine translation and natural language inference. While most recent breakthroughs in task performance are being achieved by large scale distributional models, there is a growing disconnection between their knowledge representation and traditional semantics, which hinders efforts to capture such knowledge in human interpretable form or explain model inference behaviour. In this tutorial, we examine from basics to the cutting edge research on the analysis and control of text representations, aiming to shorten the gap between deep latent semantics and formal symbolics. This includes the considerations on knowledge formalisation, the linguistic information that can be extracted and measured from distributional models, and intervention techniques that enable explainable reasoning and controllable text generation, covering methods from pooling to LLM-based.</abstract>
      <url hash="498a56d9">2024.lrec-tutorials.9</url>
      <bibkey>silva-de-carvalho-etal-2024-formal</bibkey>
    </paper>
    <paper id="10">
      <title>Towards a Human-Computer Collaborative Scientific Paper Lifecycle: A Pilot Study and Hands-On Tutorial</title>
      <author><first>Qingyun</first><last>Wang</last></author>
      <author><first>Carl</first><last>Edwards</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <author><first>Tom</first><last>Hope</last></author>
      <pages>56–67</pages>
      <abstract>Due to the rapid growth of publications varying in quality, there exists a pressing need to help scientists digest and evaluate relevant papers, thereby facilitating scientific discovery. This creates a number of urgent questions; however, computer-human collaboration in the scientific paper lifecycle is still in the exploratory stage and lacks a unified framework for analyzing the relevant tasks. Additionally, with the recent significant success of large language models (LLMs), they have increasingly played an important role in academic writing. In this cutting-edge tutorial, we aim to provide an all-encompassing overview of the paper lifecycle, detailing how machines can augment every stage of the research process for the scientist, including scientific literature understanding, experiment development, manuscript draft writing, and finally draft evaluation. This tutorial is devised for researchers interested in this rapidly-developing field of NLP-augmented paper writing. The tutorial will also feature a session of hands-on exercises during which participants can guide machines in generating ideas and automatically composing key paper elements. Furthermore, we will address current challenges, explore future directions, and discuss potential ethical issues. A toolkit designed for human-computer collaboration throughout the paper lifecycle will also be made publically available.</abstract>
      <url hash="7340dc19">2024.lrec-tutorials.10</url>
      <bibkey>wang-etal-2024-towards</bibkey>
    </paper>
    <paper id="11">
      <title>Tutorial Proposal: Hallucination in Large Language Models</title>
      <author><first>Vipula</first><last>Rawte</last></author>
      <author><first>Aman</first><last>Chadha</last></author>
      <author><first>Amit</first><last>Sheth</last></author>
      <author><first>Amitava</first><last>Das</last></author>
      <pages>68–72</pages>
      <abstract>In the fast-paced domain of Large Language Models (LLMs), the issue of hallucination is a prominent challenge. Despite continuous endeavors to address this concern, it remains a highly active area of research within the LLM landscape. Grasping the intricacies of this problem can be daunting, especially for those new to the field. This tutorial aims to bridge this knowledge gap by introducing the emerging realm of hallucination in LLMs. It will comprehensively explore the key aspects of hallucination, including benchmarking, detection, and mitigation techniques. Furthermore, we will delve into the specific constraints and shortcomings of current approaches, providing valuable insights to guide future research efforts for participants.</abstract>
      <url hash="988de175">2024.lrec-tutorials.11</url>
      <bibkey>rawte-etal-2024-tutorial</bibkey>
    </paper>
    <paper id="12">
      <title>Addressing Bias and Hallucination in Large Language Models</title>
      <author><first>Nihar Ranjan</first><last>Sahoo</last></author>
      <author><first>Ashita</first><last>Saxena</last></author>
      <author><first>Kishan</first><last>Maharaj</last></author>
      <author><first>Arif A.</first><last>Ahmad</last></author>
      <author><first>Abhijit</first><last>Mishra</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>73–79</pages>
      <abstract>In the landscape of natural language processing (NLP), addressing the challenges of bias and hallucination is paramount to ensuring the ethical and unbiased development of Large Language Models (LLMs). This tutorial delves into the intricate dimensions of LLMs, shedding light on the critical importance of understanding and mitigating the profound impacts of bias and hallucination. Divided into two parts, the first part delves deep into the complexity of bias propagation in LLM development, where we dissect its origins and far-reaching impacts. We then present innovative methodologies for mitigating diverse forms of bias, including dynamic word embeddings and robust benchmarking strategies. The second part of the tutorial discusses hallucination - a prevalent issue in generative AI systems such as LLMs. Through advanced data-driven techniques, we decode its intricate effects and complexities, followed factually-driven mitigation strategies. Furthermore, we shed light on the pivotal role of human cognitive behavior in the context of hallucination, drawing insights from cognitive data, including human eye-tracking data. Ultimately, this cutting-edge tutorial serves as a guiding light, equipping participants with indispensable tools and insights to navigate the ethical complexities of LLMs, thus paving the way for the development of unbiased and ethically robust NLP systems.</abstract>
      <url hash="ca710c70">2024.lrec-tutorials.12</url>
      <bibkey>sahoo-etal-2024-addressing</bibkey>
    </paper>
    <paper id="13">
      <title>Knowledge-enhanced Response Generation in Dialogue Systems: Current Advancements and Emerging Horizons</title>
      <author><first>Priyanshu</first><last>Priya</last></author>
      <author><first>Deeksha</first><last>Varshney</last></author>
      <author><first>Mauajama</first><last>Firdaus</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <pages>80–87</pages>
      <abstract>This tutorial provides an in-depth exploration of Knowledge-enhanced Dialogue Systems (KEDS), diving into their foundational aspects, methodologies, advantages, and practical applications. Topics include the distinction between internal and external knowledge integration, diverse methodologies employed in grounding dialogues, and innovative approaches to leveraging knowledge graphs for enhanced conversation quality. Furthermore, the tutorial touches upon the rise of biomedical text mining, the advent of domain-specific language models, and the challenges and strategies specific to medical dialogue generation. The primary objective is to give attendees a comprehensive understanding of KEDS. By delineating the nuances of these systems, the tutorial aims to elucidate their significance, highlight advancements made using deep learning, and pinpoint the current challenges. Special emphasis is placed on showcasing how KEDS can be fine-tuned for domain-specific requirements, with a spotlight on the healthcare sector. The tutorial is crafted for both beginners and intermediate researchers in the dialogue systems domain, with a focus on those keen on advancing research in KEDS. It will also be valuable for practitioners in sectors like healthcare, seeking to integrate advanced dialogue systems.</abstract>
      <url hash="34c8625a">2024.lrec-tutorials.13</url>
      <bibkey>priya-etal-2024-knowledge</bibkey>
    </paper>
  </volume>
  <event id="lrec-2024">
    <meta>
      <title>The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)</title>
      <location>Torino, Italia</location>
      <dates>May, 2024</dates>
    </meta>
    <links>
      <url type="website">https://lrec-coling-2024.org</url>
    </links>
    <colocated>
      <volume-id>2024.rapid-1</volume-id>
      <volume-id>2024.neusymbridge-1</volume-id>
    </colocated>
  </event>
</collection>
