<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.sighan">
  <volume id="1" ingest-date="2024-07-30" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 10th SIGHAN Workshop on Chinese Language Processing (SIGHAN-10)</booktitle>
      <editor><first>Kam-Fai</first><last>Wong</last></editor>
      <editor><first>Min</first><last>Zhang</last></editor>
      <editor><first>Ruifeng</first><last>Xu</last></editor>
      <editor><first>Jing</first><last>Li</last></editor>
      <editor><first>Zhongyu</first><last>Wei</last></editor>
      <editor><first>Lin</first><last>Gui</last></editor>
      <editor><first>Bin</first><last>Liang</last></editor>
      <editor><first>Runcong</first><last>Zhao</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Bangkok, Thailand</address>
      <month>August</month>
      <year>2024</year>
      <url hash="770bceb7">2024.sighan-1</url>
      <venue>sighan</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="f2a39885">2024.sighan-1.0</url>
      <bibkey>sighan-1-2024</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Automatic Quote Attribution in <fixed-case>C</fixed-case>hinese Literary Works</title>
      <author><first>Xingxing</first><last>Yang</last></author>
      <author><first>Yu</first><last>Wang</last></author>
      <pages>1-9</pages>
      <abstract>Quote attribution in fiction refers to the extraction of dialogues and speaker identification of dialogues, which can be divided into 2 steps: quotation annotation and speaker annotation. We use a pipeline for quote attribution, which involves classification, extractive QA, multi-choice QA, and coreference resolution. We also had an evaluation of our model performance by predicting explicit and implicit speakers using a combination of different models.</abstract>
      <url hash="1c4fd238">2024.sighan-1.1</url>
      <bibkey>yang-wang-2024-automatic</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>T</fixed-case>ele<fixed-case>C</fixed-case>hat: An Open-source Billingual Large Language Model</title>
      <author><first>Zihan</first><last>Wang</last></author>
      <author><first>Liuxz2@chinatelecom.cn</first><last>Liuxz2@chinatelecom.cn</last><affiliation>NA</affiliation></author>
      <author><first>Liusx14@chinatelecom.cn</first><last>Liusx14@chinatelecom.cn</last><affiliation>NA</affiliation></author>
      <author><first>Yitong</first><last>Yao</last><affiliation>中国电信数字智能科技分公司</affiliation></author>
      <author><first>Huangyy121@chinatelecom.cn</first><last>Huangyy121@chinatelecom.cn</last><affiliation>NA</affiliation></author>
      <author><first>Li</first><last>Mengxiang</last></author>
      <author><first>Zhongjiang</first><last>He</last></author>
      <author><first>Liyx25@chinatelecom.cn</first><last>Liyx25@chinatelecom.cn</last><affiliation>NA</affiliation></author>
      <author><first>Pulw@chinatelecom.cn</first><last>Pulw@chinatelecom.cn</last><affiliation>NA</affiliation></author>
      <author><first>Xuhn@chinatelecom.cn</first><last>Xuhn@chinatelecom.cn</last><affiliation>NA</affiliation></author>
      <author><first>Chao</first><last>Wang</last></author>
      <author><first>Shuangyong</first><last>Song</last></author>
      <pages>10-20</pages>
      <abstract>In this paper, we present <b>TeleChat</b>, a collection of large language models (LLMs) with parameters of 7 billion and 12 billion. TeleChat is initially pretrained on an extensive corpus containing a diverse collection of texts from both English and Chinese languages, encompassing trillions of tokens. Subsequently, the model undergoes fine-tuning to align with human preferences, following a detailed methodology that we describe. We evaluate the performance of TeleChat on various tasks, including general dialogue generation, language understanding, mathematics, reasoning, code generation, and knowledge-based question answering. Our findings indicate that TeleChat achieves state-of-the-art performance to other open-source models of similar size across a wide range of public benchmarks. To support future research and applications utilizing LLMs, we release the fine-tuned model checkpoints of TeleChat-7B and TeleChat-12B, along with code and a portion of our filtered high-quality pretraining data, to the public community.</abstract>
      <url hash="395235a3">2024.sighan-1.2</url>
      <bibkey>wang-etal-2024-telechat</bibkey>
    </paper>
    <paper id="3">
      <title>Few-shot Question Generation for Reading Comprehension</title>
      <author><first>Yin</first><last>Poon</last><affiliation>City University of Hong Kong</affiliation></author>
      <author><first>John Sie Yuen</first><last>Lee</last><affiliation>City University of Hong Kong</affiliation></author>
      <author><first>Yu Yan</first><last>Lam</last><affiliation>Hong Kong Metropolitan University</affiliation></author>
      <author><first>Wing Lam</first><last>Suen</last><affiliation>Hong Kong Metropolitan University</affiliation></author>
      <author><first>Elsie Li Chen</first><last>Ong</last><affiliation>Hong Kong Metropolitan University</affiliation></author>
      <author><first>Samuel Kai Wah</first><last>Chu</last><affiliation>Hong Kong Metropolitan University</affiliation></author>
      <pages>21-27</pages>
      <abstract>According to the internationally recognized PIRLS (Progress in International Reading Literacy Study) assessment standards, reading comprehension questions should require not only information retrieval, but also higher-order processes such as inferencing, interpreting and evaluation. However, these kinds of questions are often not available in large quantities for training question generation models. This paper investigates whether pre-trained Large Language Models (LLMs) can produce higher-order questions. Human assessment on a Chinese dataset shows that few-shot LLM prompting generates more usable and higher-order questions than two competitive neural baselines.</abstract>
      <url hash="5f10f2d4">2024.sighan-1.3</url>
      <bibkey>poon-etal-2024-shot</bibkey>
    </paper>
    <paper id="4">
      <title>Adversarial Learning for Multi-Lingual Entity Linking</title>
      <author><first>Bingbing</first><last>Wang</last></author>
      <author><first>Bin</first><last>Liang</last></author>
      <author><first>Zhixin</first><last>Bai</last></author>
      <author><first>Yongzhuo</first><last>Ma</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <pages>28-35</pages>
      <abstract>Entity linking aims to identify mentions from the text and link them to a knowledge base. Further, Multi-lingual Entity Linking (MEL) is a more challenging task, where the language-specific mentions need to be linked to a multi-lingual knowledge base. To tackle the MEL task, we propose a novel model that employs the merit of adversarial learning and few-shot learning to generalize the learning ability across languages. Specifically, we first randomly select a fraction of language-agnostic unlabeled data as the language signal to construct the language discriminator. Based on it, we devise a simple and effective adversarial learning framework with two characteristic branches, including an entity classifier and a language discriminator with adversarial training. Experimental results on two benchmark datasets indicate the excellent performance in few-shot learning and the effectiveness of the proposed adversarial learning framework.</abstract>
      <url hash="dce88c9e">2024.sighan-1.4</url>
      <bibkey>wang-etal-2024-adversarial</bibkey>
    </paper>
    <paper id="5">
      <title>Incremental pre-training from smaller language models</title>
      <author><first>Han</first><last>Zhang</last></author>
      <author><first>Hui</first><last>Wang</last></author>
      <author><first>Ruifeng</first><last>Xu</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>36-44</pages>
      <abstract>Large language models have recently become a new learning paradigm and led to state-of-the-art performance across a range of tasks. As explosive open-source pre-trained models are available, it is worth investigating how to better utilize existing models. We propose a simple yet effective method, Incr-Pretrain, for incrementally pre-training language models from smaller well-trained source models. Different layer-wise transfer strategies were introduced for model augmentation including parameter copying, initial value padding, and model distillation. Experiments on multiple zero-shot learning tasks demonstrate satisfying inference performance upon transferring and promising training efficiency during continuing pre-training. Compared to training from scratch, Incr-Pretrain can save up to half the training time to get a similar testing loss.</abstract>
      <url hash="654f71e6">2024.sighan-1.5</url>
      <bibkey>zhang-etal-2024-incremental</bibkey>
    </paper>
    <paper id="6">
      <title>Holistic Exploration on Universal Decompositional Semantic Parsing: Architecture, Data Augmentation, and <fixed-case>LLM</fixed-case> Paradigm</title>
      <author><first>Hexuan</first><last>Deng</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Xin</first><last>Zhang</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Meishan</first><last>Zhang</last><affiliation>Harbin Institute of Technology (Shenzhen), China and Tianjin University, China</affiliation></author>
      <author><first>Xuebo</first><last>Liu</last><affiliation>Harbin Institute of Technolgy, Shenzhen</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <pages>45-57</pages>
      <abstract>In this paper, we conduct a holistic exploration of Universal Decompositional Semantic (UDS) parsing, aiming to provide a more efficient and effective solution for semantic parsing and to envision the development prospects after the emergence of large language models (LLMs). To achieve this, we first introduce a cascade model for UDS parsing that decomposes the complex task into semantically appropriate subtasks. Our approach outperforms prior models while significantly reducing inference time. Furthermore, to further exploit the hierarchical and automated annotation process of UDS, we explore the use of syntactic information and pseudo-labels, both of which enhance UDS parsing. Lastly, we investigate ChatGPT’s efficacy in handling the UDS task, highlighting its proficiency in attribute parsing but struggles in relation parsing, revealing that small parsing models still hold research significance. Our code is available at https://github.com/hexuandeng/HExp4UDS.</abstract>
      <url hash="cbed24d4">2024.sighan-1.6</url>
      <bibkey>deng-etal-2024-holistic</bibkey>
    </paper>
    <paper id="7">
      <title>Who Responded to Whom: The Joint Effects of Latent Topics and Discourse in Conversation Structure</title>
      <author><first>Lu</first><last>Ji</last><affiliation>Fudan University</affiliation></author>
      <author><first>Lei</first><last>Chen</last></author>
      <author><first>Jing</first><last>Li</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Zhongyu</first><last>Wei</last><affiliation>Fudan University</affiliation></author>
      <author><first>Qi</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Xuanjing</first><last>Huang</last><affiliation>Fudan University</affiliation></author>
      <pages>58-68</pages>
      <abstract>Vast amount of online conversations are produced on a daily basis, resulting in a pressing need to automatic conversation understanding. As a basis to structure a discussion, we identify the responding relations in the conversation discourse, which link response utterances to their initiations. To figure out who responded to whom, here we explore how the consistency of topic contents and dependency of discourse roles indicate such interactions, whereas most prior work ignore the effects of latent factors underlying word occurrences. We propose a neural model to learn latent topics and discourse in word distributions, and predict pairwise initiation-response links via exploiting topic consistency and discourse dependency. Experimental results on both English and Chinese conversations show that our model significantly outperforms the previous state of the arts.</abstract>
      <url hash="c5bda00b">2024.sighan-1.7</url>
      <bibkey>ji-etal-2024-responded</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>C</fixed-case>antonese Natural Language Processing in the Transformers Era</title>
      <author><first>Rong</first><last>Xiang</last><affiliation>Hong Kong Polytechnic University</affiliation></author>
      <author><first>Ming</first><last>Liao</last></author>
      <author><first>Jing</first><last>Li</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <pages>69-79</pages>
      <abstract>Despite being spoken by a large population of speakers worldwide, Cantonese is under-resourced in terms of the data scale and diversity compared to other major languages. This limitation has excluded it from the current “pre-training and fine-tuning” paradigm that is dominated by Transformer architectures.In this paper, we provide a comprehensive review on the existing resources and methodologies for Cantonese Natural Language Processing, covering the recent progress in language understanding, text generation and development of language models.We finally discuss two aspects of the Cantonese language that could make it potentially challenging even for state-of-the-art architectures: <i>colloquialism</i> and <i>multilinguality</i>.</abstract>
      <url hash="957e96b5">2024.sighan-1.8</url>
      <bibkey>xiang-etal-2024-cantonese</bibkey>
    </paper>
    <paper id="9">
      <title>Auto-<fixed-case>ACE</fixed-case>: An Automatic Answer Correctness Evaluation Method for Conversational Question Answering</title>
      <author><first>Zhixin</first><last>Bai</last></author>
      <author><first>Bingbing</first><last>Wang</last></author>
      <author><first>Bin</first><last>Liang</last></author>
      <author><first>Ruifeng</first><last>Xu</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>80-87</pages>
      <abstract>Conversational question answering aims to respond to questions based on relevant contexts and previous question-answer history. Existing studies typically use ground-truth answers in history, leading to the inconsistency between the training and inference phases. However, in real-world scenarios, progress in question answering can only be made using predicted answers. Since not all predicted answers are correct, indiscriminately using all predicted answers for training introduces noise into the model. To tackle these challenges, we propose an automatic answer correctness evaluation method named **Auto-ACE**. Specifically, we first construct an Att-BERT model which employs attention weight to the BERT model, so as to bridge the relation between the current question and the question-answer pair in history. Furthermore, to reduce the interference of the irrelevant information in the predicted answer, A-Scorer, an answer scorer is designed to evaluate the confidence of the predicted answer. We conduct a series of experiments on QuAC and CoQA datasets, and the results demonstrate the effectiveness and practicality of our proposed Auto-ACE framework.</abstract>
      <url hash="872fbc93">2024.sighan-1.9</url>
      <bibkey>bai-etal-2024-auto</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>TMAK</fixed-case>-Plus at <fixed-case>SIGHAN</fixed-case>-2024 dim<fixed-case>ABSA</fixed-case> Task: Multi-Agent Collaboration for Transparent and Rational Sentiment Analysis</title>
      <author><first>Xin</first><last>Kang</last><affiliation>Tokushima University</affiliation></author>
      <author><first>Zhifei</first><last>Zhang</last><affiliation>Tongji University</affiliation></author>
      <author><first>周嘉政</first><last>周嘉政</last></author>
      <author><first>Raino.wu@dataarobotics.com</first><last>Raino.wu@dataarobotics.com</last><affiliation>NA</affiliation></author>
      <author><first>2020010107@mail.hfut.edu.cn</first><last>2020010107@mail.hfut.edu.cn</last><affiliation>NA</affiliation></author>
      <author><first>Kazuyuki</first><last>Matsumoto</last><affiliation>Tokushima University</affiliation></author>
      <pages>88-95</pages>
      <abstract>The TMAK-Plus team proposes a Multi-Agent Collaboration (MAC) model for the dimensional Aspect-Based Sentiment Analysis (dimABSA) task at SIGHAN-2024. The MAC model leverages Neuro-Symbolic AI to solve dimABSA transparently and rationally through symbolic message exchanges among generative AI agents. These agents collaborate on aspect detection, opinion detection, aspect classification, and intensity estimation. We created 8 sentiment intensity agents with distinct character traits to mimic diverse sentiment perceptions and average their outputs. The AI agents received clear instructions and 20 training examples to ensure task understanding. Our results suggest that the MAC model is effective in solving the dimABSA task and offers a transparent and rational approach to understanding the solution process.</abstract>
      <url hash="79e0d126">2024.sighan-1.10</url>
      <bibkey>kang-etal-2024-tmak</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>YNU</fixed-case>-<fixed-case>HPCC</fixed-case> at <fixed-case>SIGHAN</fixed-case>-2024 dim<fixed-case>ABSA</fixed-case> Task: Using <fixed-case>PLM</fixed-case>s with a Joint Learning Strategy for Dimensional Intensity Prediction</title>
      <author><first>Wangzehui@stu.ynu.edu.cn</first><last>Wangzehui@stu.ynu.edu.cn</last><affiliation>NA</affiliation></author>
      <author><first>You</first><last>Zhang</last></author>
      <author><first>Jin</first><last>Wang</last><affiliation>Yunnan University</affiliation></author>
      <author><first>Dan</first><last>Xu</last></author>
      <author><first>Xuejie</first><last>Zhang</last><affiliation>Yunnan University</affiliation></author>
      <pages>96-101</pages>
      <abstract>The dimensional approach can represent more fine-grained emotional information than discrete affective states. In this paper, a pretrained language model (PLM) with a joint learning strategy is proposed for the SIGHAN-2024 shared task on Chinese dimensional aspect-based sentiment analysis (dimABSA), which requires submitted models to provide fine-grained multi-dimensional (Valance and Arousal) intensity predictions for given aspects of a review. The proposed model consists of three parts: an input layer that concatenates both given aspect terms and input sentences; a Chinese PLM encoder that generates aspect-specific review representation; and separate linear predictors that jointly predict Valence and Arousal sentiment intensities. Moreover, we merge simplified and traditional Chinese training data for data augmentation. Our systems ranked 2nd place out of 5 participants in subtask 1-intensity prediction. The code is publicly available at https://github.com/WZH5127/2024_subtask1_intensity_prediction.</abstract>
      <url hash="0c2b0170">2024.sighan-1.11</url>
      <bibkey>wangzehui-stu-ynu-edu-cn-etal-2024-ynu</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>CCIIPL</fixed-case>ab at <fixed-case>SIGHAN</fixed-case>-2024 dim<fixed-case>ABSA</fixed-case> Task: Contrastive Learning-Enhanced Span-based Framework for <fixed-case>C</fixed-case>hinese Dimensional Aspect-Based Sentiment Analysis</title>
      <author><first>Zeliang</first><last>Tong</last></author>
      <author><first>Wei</first><last>Wei</last><affiliation>Huazhong University of Science and Technology</affiliation></author>
      <pages>102-111</pages>
      <abstract>This paper describes our system and findings for SIGHAN-2024 Shared Task Chinese Dimensional Aspect-Based Sentiment Analysis (dimABSA). Our team CCIIPLab proposes an Contrastive Learning-Enhanced Span-based (CL-Span) framework to boost the performance of extracting triplets/quadruples and predicting sentiment intensity. We first employ a span-based framework that integrates contextual representations and incorporates rotary position embedding. This approach fully considers the relational information of entire aspect and opinion terms, and enhancing the model’s understanding of the associations between tokens. Additionally, we utilize contrastive learning to predict sentiment intensities in the valence-arousal dimensions with greater precision. To improve the generalization ability of the model, additional datasets are used to assist training. Experiments have validated the effectiveness of our approach. In the official test results, our system ranked 2nd among the three subtasks.</abstract>
      <url hash="87d4a146">2024.sighan-1.12</url>
      <bibkey>tong-wei-2024-cciiplab</bibkey>
    </paper>
    <paper id="13">
      <title><fixed-case>ZZU</fixed-case>-<fixed-case>NLP</fixed-case> at <fixed-case>SIGHAN</fixed-case>-2024 dim<fixed-case>ABSA</fixed-case> Task: Aspect-Based Sentiment Analysis with Coarse-to-Fine In-context Learning</title>
      <author><first>Senbin</first><last>Zhu</last><affiliation>Zhengzhou University</affiliation></author>
      <author><first>Hanjie</first><last>Zhao</last></author>
      <author><first>Wxr</first><last>Wxr</last></author>
      <author><first>18437919080@163.com</first><last>18437919080@163.com</last><affiliation>NA</affiliation></author>
      <author><first>Yuxiang</first><last>Jia</last><affiliation>Zhengzhou University</affiliation></author>
      <author><first>Hongying</first><last>Zan</last><affiliation>Zhengzhou University</affiliation></author>
      <pages>112-120</pages>
      <abstract>The DimABSA task requires fine-grained sentiment intensity prediction for restaurant reviews, including scores for Valence and Arousal dimensions for each Aspect Term. In this study, we propose a Coarse-to-Fine In-context Learning(CFICL) method based on the Baichuan2-7B model for the DimABSA task in the SIGHAN 2024 workshop. Our method improves prediction accuracy through a two-stage optimization process. In the first stage, we use fixed in-context examples and prompt templates to enhance the model’s sentiment recognition capability and provide initial predictions for the test data. In the second stage, we encode the Opinion field using BERT and select the most similar training data as new in-context examples based on similarity. These examples include the Opinion field and its scores, as well as related opinion words and their average scores. By filtering for sentiment polarity, we ensure that the examples are consistent with the test data. Our method significantly improves prediction accuracy and consistency by effectively utilizing training data and optimizing in-context examples, as validated by experimental results.</abstract>
      <url hash="fba2907e">2024.sighan-1.13</url>
      <bibkey>zhu-etal-2024-zzu</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>JN</fixed-case>-<fixed-case>NLP</fixed-case> at <fixed-case>SIGHAN</fixed-case>-2024 dim<fixed-case>ABSA</fixed-case> Task: Extraction of Sentiment Intensity Quadruples Based on Paraphrase Generation</title>
      <author><first>Yunfan</first><last>Jiang</last></author>
      <author><first>Liutianci@stu.jiangnan.edu.cn</first><last>Liutianci@stu.jiangnan.edu.cn</last><affiliation>NA</affiliation></author>
      <author><first>Heng-yang</first><last>Lu</last><affiliation>Jiangnan University</affiliation></author>
      <pages>121-126</pages>
      <abstract>Aspect-based sentiment analysis(ABSA) is a fine-grained sentiment analysis task, which aims to extract multiple specific sentiment elements from text. The current aspect-based sentiment analysis task mainly involves four basic elements: aspect term, aspect category, opinion term, and sentiment polarity. With the development of ABSA, methods for predicting the four sentiment elements are gradually increasing. However, traditional ABSA usually only distinguishes between “positive”, “negative”, or “neutral”attitudes when judging sentiment polarity, and this simplified classification method makes it difficult to highlight the sentimentintensity of different reviews. SIGHAN 2024 provides a more challenging evaluation task, the Chinese dimensional ABSA shared task (dimABSA), which replaces the traditional sentiment polarity judgment task with a dataset in a multidimensional space with continuous sentiment intensity scores, including valence and arousal. Continuous sentiment intensity scores can obtain more detailed emotional information. In this task, we propose a new paraphrase generation paradigm that uses generative questioning in an end-to-end manner to predict sentiment intensity quadruples, which can fully utilize semantic information and reduce propagation errors in the pipeline approach.</abstract>
      <url hash="819a9389">2024.sighan-1.14</url>
      <bibkey>jiang-etal-2024-jn</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>DS</fixed-case>-Group at <fixed-case>SIGHAN</fixed-case>-2024 dim<fixed-case>ABSA</fixed-case> Task: Constructing In-context Learning Structure for Dimensional Aspect-Based Sentiment Analysis</title>
      <author><first>Ling-ang</first><last>Meng</last><affiliation>Beijing Institute of Technology</affiliation></author>
      <author><first>Tianyu</first><last>Zhao</last><affiliation>Beijing Institute of Technology</affiliation></author>
      <author><first>Dawei</first><last>Song</last><affiliation>Beijing Institute of Technology and Open University</affiliation></author>
      <pages>127-132</pages>
      <abstract>Aspect-Based Sentiment Analysis (ABSA) is an important subtask in Natural Language Processing (NLP). More recent research within ABSA have consistently focused on conducting more precise sentiment analysis on aspects, i.e., dimensional Aspect-Based Sentiment Analysis (dimABSA). However, previous approaches have not systematically explored the use of Large Language Models (LLMs) in dimABSA. To fill the gap, we propose a novel In-Context Learning (ICL) structure with a novel aspect-aware ICL example selection method, to enhance the performance of LLMs in dimABSA. Experiments show that our proposed ICL structure significantly improves the fine-grained sentiment analysis abilities of LLMs.</abstract>
      <url hash="dd2c5e62">2024.sighan-1.15</url>
      <bibkey>meng-etal-2024-ds</bibkey>
    </paper>
    <paper id="16">
      <title>Fine-tuning after Prompting: an Explainable Way for Classification</title>
      <author><first>Zezhong</first><last>Wang</last></author>
      <author><first>Luyao</first><last>Ye</last></author>
      <author><first>Hongru</first><last>Wang</last></author>
      <author><first>Boyang</first><last>Xue</last></author>
      <author><first>Yiming</first><last>Du</last></author>
      <author><first>Bin</first><last>Liang</last></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <pages>133-142</pages>
      <abstract>Prompting is an alternative approach for utilizing pre-trained language models (PLMs) in classification tasks. In contrast to fine-tuning, prompting is more understandable for humans because it utilizes natural language to interact with the PLM, but it often falls short in terms of accuracy. While current research primarily focuses on enhancing the performance of prompting methods to compete with fine-tuning, we believe that these two approaches are not mutually exclusive, each having its strengths and weaknesses. In our study, we depart from the competitive view of prompting versus fine-tuning and instead combine them, introducing a novel method called F&amp;P. This approach enables us to harness the advantages of <b>F</b>ine-tuning for accuracy and the explainability of <b>P</b>rompting simultaneously. Specifically, we reformulate the sample into a prompt and subsequently fine-tune a linear classifier on top of the PLM. Following this, we extract verbalizers according to the weight of this classifier. During the inference phase, we reformulate the sample in the same way and query the PLM. The PLM generates a word, which is then subject to a dictionary lookup by the verbalizer to obtain the prediction. Experiments show that keeping only 30 keywords for each class can achieve comparable performance as fine-tuning. On the other hand, both the prompt and verbalizers are constructed in natural language, making them fully understandable to humans. Hence, the F&amp;P method offers an effective and transparent way to employ a PLM for classification tasks.</abstract>
      <url hash="e0c6f323">2024.sighan-1.16</url>
      <bibkey>wang-etal-2024-fine</bibkey>
    </paper>
    <paper id="17">
      <title><fixed-case>C</fixed-case>ausal<fixed-case>B</fixed-case>ench: A Comprehensive Benchmark for Evaluating Causal Reasoning Capabilities of Large Language Models</title>
      <author><first>Zeyu</first><last>Wang</last><affiliation>University of California, San Diego, University of California, San Diego</affiliation></author>
      <pages>143-151</pages>
      <abstract>Causal reasoning, a core aspect of human cognition, is essential for advancing large language models (LLMs) towards artificial general intelligence (AGI) and reducing their propensity for generating hallucinations. However, existing datasets for evaluating causal reasoning in LLMs are limited by narrow domain coverage and a focus on cause-to-effect reasoning through textual problems, which does not comprehensively assess whether LLMs truly grasp causal relationships or merely guess correct answers. To address these shortcomings, we introduce a novel benchmark that spans textual, mathematical, and coding problem domains. Each problem is crafted to probe causal understanding from four perspectives: cause-to-effect, effect-to-cause, cause-to-effect with intervention, and effect-to-cause with intervention. This multi-dimensional evaluation method ensures that LLMs must exhibit a genuine understanding of causal structures by correctly answering questions across all four dimensions, mitigating the possibility of correct responses by chance. Furthermore, our benchmark explores the relationship between an LLM’s causal reasoning performance and its tendency to produce hallucinations. We present evaluations of state-of-the-art LLMs using our benchmark, providing valuable insights into their current causal reasoning capabilities across diverse domains. The dataset is publicly available for download at https://huggingface.co/datasets/CCLV/CausalBench</abstract>
      <url hash="478bf949">2024.sighan-1.17</url>
      <bibkey>wang-2024-causalbench</bibkey>
    </paper>
    <paper id="18">
      <title><fixed-case>P</fixed-case>er<fixed-case>LTQA</fixed-case>: A Personal Long-Term Memory Dataset for Memory Classification, Retrieval, and Fusion in Question Answering</title>
      <author><first>Yiming</first><last>Du</last></author>
      <author><first>Hongru</first><last>Wang</last></author>
      <author><first>Zhengyi</first><last>Zhao</last></author>
      <author><first>Bin</first><last>Liang</last></author>
      <author><first>Baojun</first><last>Wang</last></author>
      <author><first>Wanjun</first><last>Zhong</last></author>
      <author><first>Zezhong</first><last>Wang</last></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <pages>152-164</pages>
      <abstract>In conversational AI, effectively employing long-term memory improves personalized and consistent response generation. Existing work only concentrated on a single type of long-term memory, such as preferences, dialogue history, or social relationships, overlooking their interaction in real-world contexts. To this end, inspired by the concept of semantic memory and episodic memory from cognitive psychology, we create a new and more comprehensive Chinese dataset, coined as PerLTQA, in which world knowledge, profiles, social relationships, events, and dialogues are considered to leverage the interaction between different types of long-term memory for question answering (QA) in conversation. Further, based on PerLTQA, we propose a novel framework for memory integration in QA, consisting of three subtasks: <b>Memory Classification</b>, <b>Memory Retrieval</b>, and <b>Memory Fusion</b>, which provides a comprehensive paradigm for memory modeling, enabling consistent and personalized memory utilization. This essentially allows the exploitation of more accurate memory information for better responses in QA. We evaluate this framework using five LLMs and three retrievers. Experimental results demonstrate the importance of personal long-term memory in the QA task</abstract>
      <url hash="a67df734">2024.sighan-1.18</url>
      <bibkey>du-etal-2024-perltqa</bibkey>
    </paper>
    <paper id="19">
      <title>Overview of the <fixed-case>SIGHAN</fixed-case> 2024 shared task for <fixed-case>C</fixed-case>hinese dimensional aspect-based sentiment analysis</title>
      <author><first>Lung-Hao</first><last>Lee</last><affiliation>National Yang Ming Chiao Tung University</affiliation></author>
      <author><first>Liang-Chih</first><last>Yu</last><affiliation>Yuan Ze University</affiliation></author>
      <author><first>Suge</first><last>Wang</last></author>
      <author><first>Jian</first><last>Liao</last><affiliation>Shanxi University</affiliation></author>
      <pages>165-174</pages>
      <abstract>This paper describes the SIGHAN-2024 shared task for Chinese dimensional aspect-based sentiment analysis (ABSA), including task description, data preparation, performance metrics, and evaluation results. Compared to representing affective states as several discrete classes (i.e., sentiment polarity), the dimensional approach represents affective states as continuous numerical values (called sentiment intensity) in the valence-arousal space, providing more fine-grained affective states. Therefore, we organized a dimensional ABSA (shorted dimABSA) shared task, comprising three subtasks: 1) intensity prediction, 2) triplet extraction, and 3) quadruple extraction, receiving a total of 214 submissions from 61 registered participants during evaluation phase. A total of eleven teams provided selected submissions for each subtask and seven teams submitted technical reports for the subtasks. This shared task demonstrates current NLP techniques for dealing with Chinese dimensional ABSA. All data sets with gold standards and evaluation scripts used in this shared task are publicly available for future research.</abstract>
      <url hash="ec76cc7a">2024.sighan-1.19</url>
      <bibkey>lee-etal-2024-overview-sighan</bibkey>
    </paper>
    <paper id="20">
      <title><fixed-case>HITSZ</fixed-case>-<fixed-case>HLT</fixed-case> at <fixed-case>SIGHAN</fixed-case>-2024 dim<fixed-case>ABSA</fixed-case> Task: Integrating <fixed-case>BERT</fixed-case> and <fixed-case>LLM</fixed-case> for <fixed-case>C</fixed-case>hinese Dimensional Aspect-Based Sentiment Analysis</title>
      <author><first>Hongling</first><last>Xu</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Delong</first><last>Zhang</last></author>
      <author><first>Yice</first><last>Zhang</last></author>
      <author><first>Ruifeng</first><last>Xu</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>175-185</pages>
      <abstract>This paper presents the winning system participating in the ACL 2024 workshop SIGHAN-10 shared task: Chinese dimensional aspect-based sentiment analysis (dimABSA). This task aims to identify four sentiment elements in restaurant reviews: aspect, category, opinion, and sentiment intensity evaluated in valence-arousal dimensions, providing a concise yet fine-grained sentiment description for user opinions. To tackle this task, we introduce a system that integrates BERT and large language models (LLM) to leverage their strengths. First, we explore their performance in entity extraction, relation classification, and intensity prediction. Based on preliminary experiments, we develop an integrated approach to fully utilize their advantages in different scenarios. Our system achieves first place in all subtasks and obtains a 41.7% F1-score in quadruple extraction.</abstract>
      <url hash="a1f452de">2024.sighan-1.20</url>
      <bibkey>xu-etal-2024-hitsz</bibkey>
    </paper>
  </volume>
</collection>
