<?xml version='1.0' encoding='UTF-8'?>
<collection id="2016.amta">
  <volume id="researchers" ingest-date="2021-10-17" type="proceedings">
    <meta>
      <booktitle>Conferences of the Association for Machine Translation in the Americas: MT Researchers' Track</booktitle>
      <publisher>The Association for Machine Translation in the Americas</publisher>
      <address>Austin, TX, USA</address>
      <month>October 28 - November 1</month>
      <year>2016</year>
      <url hash="15e0d4ee">2016.amta-researchers</url>
      <editor><first>Spence</first><last>Green</last></editor>
      <editor><first>Lane</first><last>Schwartz</last></editor>
      <venue>amta</venue>
    </meta>
    <frontmatter>
      <url hash="95bac94f">2016.amta-researchers.0</url>
      <bibkey>amta-2016-conferences</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Instance Selection for Online Automatic Post-Editing in a multi-domain scenario</title>
      <author><first>Rajen</first><last>Chatterjee</last></author>
      <author><first>Mihael</first><last>Arcan</last></author>
      <author><first>Matteo</first><last>Negri</last></author>
      <author><first>Marco</first><last>Turchi</last></author>
      <pages>1-15</pages>
      <url hash="40615543">2016.amta-researchers.1</url>
      <abstract>In recent years, several end-to-end online translation systems have been proposed to successfully incorporate human post-editing feedback in the translation workflow. The performance of these systems in a multi-domain translation environment (involving different text genres, post-editing styles, machine translation systems) within the automatic post-editing (APE) task has not been thoroughly investigated yet. In this work, we show that when used in the APE framework the existing online systems are not robust towards domain changes in the incoming data stream. In particular, these systems lack in the capability to learn and use domain-specific post-editing rules from a pool of multi-domain data sets. To cope with this problem, we propose an online learning framework that generates more reliable translations with significantly better quality as compared with the existing online and batch systems. Our framework includes: i) an instance selection technique based on information retrieval that helps to build domain-specific APE systems, and ii) an optimization procedure to tune the feature weights of the log-linear model that allows the decoder to improve the post-editing quality.</abstract>
      <bibkey>chatterjee-etal-2016-instance</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/wmt-2016">WMT 2016</pwcdataset>
    </paper>
    <paper id="2">
      <title>Machine Translation Quality and Post-Editor Productivity</title>
      <author><first>Marina</first><last>Sanchez-Torron</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <pages>16-26</pages>
      <url hash="cda929df">2016.amta-researchers.2</url>
      <abstract>We assessed how different machine translation (MT) systems affect the post-editing (PE) process and product of professional English–Spanish translators. Our model found that for each 1-point increase in BLEU, there is a PE time decrease of 0.16 seconds per word, about 3-4%. The MT system with the lowest BLEU score produced the output that was post-edited to the lowest quality and with the highest PE effort, measured both in HTER and actual PE operations.</abstract>
      <bibkey>sanchez-torron-koehn-2016-machine</bibkey>
    </paper>
    <paper id="3">
      <title>Fuzzy-match repair using black-box machine translation systems: what can be expected?</title>
      <author><first>John</first><last>Ortega</last></author>
      <author><first>Felipe</first><last>Sánchez-Martínez</last></author>
      <author><first>Mikel</first><last>Forcada</last></author>
      <pages>27-39</pages>
      <url hash="86456ca6">2016.amta-researchers.3</url>
      <abstract>Computer-aided translation (CAT) tools often use a translation memory (TM) as the key resource to assist translators. A TM contains translation units (TU) which are made up of source and target language segments; translators use the target segments in the TU suggested by the CAT tool by converting them into the desired translation. Proposals from TMs could be made more useful by using techniques such as fuzzy-match repair (FMR) which modify words in the target segment corresponding to mismatches identified in the source segment. Modifications in the target segment are done by translating the mismatched source sub-segments using an external source of bilingual information (SBI) and applying the translations to the corresponding positions in the target segment. Several combinations of translated sub-segments can be applied to the target segment which can produce multiple repair candidates. We provide a formal algorithmic description of a method that is capable of using any SBI to generate all possible fuzzy-match repairs and perform an oracle evaluation on three different language pairs to ascertain the potential of the method to improve translation productivity. Using DGT-TM translation memories and the machine system Apertium as the single source to build repair operators in three different language pairs, we show that the best repaired fuzzy matches are consistently closer to reference translations than either machine-translated segments or unrepaired fuzzy matches.</abstract>
      <bibkey>ortega-etal-2016-fuzzy</bibkey>
    </paper>
    <paper id="4">
      <title>Fast, Scalable Phrase-Based <fixed-case>SMT</fixed-case> Decoding</title>
      <author><first>Hieu</first><last>Hoang</last></author>
      <author><first>Nikolay</first><last>Bogoychev</last></author>
      <author><first>Lane</first><last>Schwartz</last></author>
      <author><first>Marcin</first><last>Junczys-Dowmunt</last></author>
      <pages>40-52</pages>
      <url hash="19ef67ed">2016.amta-researchers.4</url>
      <abstract>The utilization of statistical machine translation (SMT) has grown enormously over the last decade, many using open-source software developed by the NLP community. As commercial use has increased, there is need for software that is optimized for commercial requirements, in particular, fast phrase-based decoding and more efficient utilization of modern multicore servers. In this paper we re-examine the major components of phrase-based decoding and decoder implementation with particular emphasis on speed and scalability on multicore machines. The result is a drop-in replacement for the Moses decoder which is up to fifteen times faster and scales monotonically with the number of cores.</abstract>
      <bibkey>hoang-etal-2016-fast</bibkey>
    </paper>
    <paper id="5">
      <title>An Effective Diverse Decoding Scheme for Robust Synonymous Sentence Translation</title>
      <author><first>Youngki</first><last>Park</last></author>
      <author><first>Hwidong</first><last>Na</last></author>
      <author><first>Hodong</first><last>Lee</last></author>
      <author><first>Jihyun</first><last>Lee</last></author>
      <author><first>Inchul</first><last>Song</last></author>
      <pages>53-64</pages>
      <url hash="687d25f8">2016.amta-researchers.5</url>
      <bibkey>park-etal-2016-effective</bibkey>
    </paper>
    <paper id="6">
      <title>Ranking suggestions for black-box interactive translation prediction systems with multilayer perceptrons</title>
      <author><first>Daniel</first><last>Torregrosa</last></author>
      <author><first>Juan Antonio</first><last>Pérez-Ortiz</last></author>
      <author><first>Mikel</first><last>Forcada</last></author>
      <pages>65-78</pages>
      <url hash="bd23a4e6">2016.amta-researchers.6</url>
      <abstract>The objective of interactive translation prediction (ITP), a paradigm of computer-aided translation, is to assist professional translators by offering context-based computer-generated suggestions as they type. While most state-of-the-art ITP systems are tightly coupled to a machine translation (MT) system (often created ad-hoc for this purpose), our proposal follows a resourceagnostic approach, one that does not need access to the inner workings of the bilingual resources (MT systems or any other bilingual resources) used to generate the suggestions, thus allowing to include new resources almost seamlessly. As we do not expect the user to tolerate more than a few proposals each time, the set of potential suggestions need to be filtered and ranked; the resource-agnostic approach has been evaluated before using a set of intuitive length-based and position-based heuristics designed to determine which suggestions to show, achieving promising results. In this paper, we propose a more principled suggestion ranking approach using a regressor (a multilayer perceptron) that achieves significantly better results.</abstract>
      <bibkey>torregrosa-etal-2016-ranking</bibkey>
    </paper>
    <paper id="7">
      <title>Multi-domain Adaptation for Statistical Machine Translation Based on Feature Augmentation</title>
      <author><first>Kenji</first><last>Imamura</last></author>
      <author><first>Eiichiro</first><last>Sumita</last></author>
      <pages>79-92</pages>
      <url hash="ef459463">2016.amta-researchers.7</url>
      <abstract>Domain adaptation is a major challenge when applying machine translation to practical tasks. In this paper, we present domain adaptation methods for machine translation that assume multiple domains. The proposed methods combine two model types: a corpus-concatenated model covering multiple domains and single-domain models that are accurate but sparse in specific domains. We combine the advantages of both models using feature augmentation for domain adaptation in machine learning. Our experimental results show that the BLEU scores of the proposed method clearly surpass those of single-domain models for low-resource domains. For high-resource domains, the scores of the proposed method were superior to those of both single-domain and corpusconcatenated models. Even in domains having a million bilingual sentences, the translation quality was at least preserved and even improved in some domains. These results demonstrate that state-of-the-art domain adaptation can be realized with appropriate settings, even when using standard log-linear models.</abstract>
      <bibkey>imamura-sumita-2016-multi</bibkey>
    </paper>
    <paper id="8">
      <title>Bilingual Methods for Adaptive Training Data Selection for Machine Translation</title>
      <author><first>Boxing</first><last>Chen</last></author>
      <author><first>Roland</first><last>Kuhn</last></author>
      <author><first>George</first><last>Foster</last></author>
      <author><first>Colin</first><last>Cherry</last></author>
      <author><first>Fei</first><last>Huang</last></author>
      <pages>93-106</pages>
      <url hash="072893b8">2016.amta-researchers.8</url>
      <abstract>In this paper, we propose a new data selection method which uses semi-supervised convolutional neural networks based on bitokens (Bi-SSCNNs) for training machine translation systems from a large bilingual corpus. In earlier work, we devised a data selection method based on semi-supervised convolutional neural networks (SSCNNs). The new method, Bi-SSCNN, is based on bitokens, which use bilingual information. When the new methods are tested on two translation tasks (Chinese-to-English and Arabic-to-English), they significantly outperform the other three data selection methods in the experiments. We also show that the BiSSCNN method is much more effective than other methods in preventing noisy sentence pairs from being chosen for training. More interestingly, this method only needs a tiny amount of in-domain data to train the selection model, which makes fine-grained topic-dependent translation adaptation possible. In the follow-up experiments, we find that neural machine translation (NMT) is more sensitive to noisy data than statistical machine translation (SMT). Therefore, Bi-SSCNN which can effectively screen out noisy sentence pairs, can benefit NMT much more than SMT.We observed a BLEU improvement over 3 points on an English-to-French WMT task when Bi-SSCNNs were used.</abstract>
      <bibkey>chen-etal-2016-bilingual</bibkey>
    </paper>
    <paper id="9">
      <title>Neural Interactive Translation Prediction</title>
      <author><first>Rebecca</first><last>Knowles</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <pages>107-120</pages>
      <url hash="c02a521e">2016.amta-researchers.9</url>
      <abstract>We present an interactive translation prediction method based on neural machine translation. Even with the same translation quality of the underlying machine translation systems, the neural prediction method yields much higher word prediction accuracy (61.6% vs. 43.3%) than the traditional method based on search graphs, mainly due to better recovery from errors. We also develop efficient means to enable practical deployment.</abstract>
      <bibkey>knowles-koehn-2016-neural</bibkey>
    </paper>
    <paper id="10">
      <title>Guided Alignment Training for Topic-Aware Neural Machine Translation</title>
      <author><first>Wenhu</first><last>Chen</last></author>
      <author><first>Evgeny</first><last>Matusov</last></author>
      <author><first>Shahram</first><last>Khadivi</last></author>
      <author><first>Jan-Thorsten</first><last>Peter</last></author>
      <pages>121-134</pages>
      <url hash="402534f4">2016.amta-researchers.10</url>
      <abstract>In this paper, we propose an effective way for biasing the attention mechanism of a sequence-to-sequence neural machine translation (NMT) model towards the well-studied statistical word alignment models. We show that our novel guided alignment training approach improves translation quality on real-life e-commerce texts consisting of product titles and descriptions, overcoming the problems posed by many unknown words and a large type/token ratio. We also show that meta-data associated with input texts such as topic or category information can significantly improve translation quality when used as an additional signal to the decoder part of the network. With both novel features, the BLEU score of the NMT system on a product title set improves from 18.6 to 21.3%. Even larger MT quality gains are obtained through domain adaptation of a general domain NMT system to e-commerce data. The developed NMT system also performs well on the IWSLT speech translation task, where an ensemble of four variant systems outperforms the phrase-based baseline by 2.1% BLEU absolute.</abstract>
      <bibkey>chen-etal-2016-guided</bibkey>
    </paper>
    <paper id="11">
      <title>Improving Neural Machine Translation on resource-limited pairs using auxiliary data of a third language</title>
      <author><first>Ander</first><last>Martinez</last></author>
      <author><first>Yuji</first><last>Matsumoto</last></author>
      <pages>135-148</pages>
      <url hash="378d85cd">2016.amta-researchers.11</url>
      <abstract>In the recent years interest in Deep Neural Networks (DNN) has grown in the field of Natural Language Processing, as new training methods have been proposed. The usage of DNN has achieved state-of-the-art performance in various areas. Neural Machine Translation (NMT) described by Bahdanau et al. (2014) and its successive variations have shown promising results. DNN, however, tend to over-fit on small data-sets, which makes this method impracticable for resource-limited language pairs. This article combines three different ideas (splitting words into smaller units, using an extra dataset of a related language pair and using monolingual data) for improving the performance of NMT models on language pairs with limited data. Our experiments show that, in some cases, our proposed approach to subword-units performs better than BPE (Byte pair encoding) and that auxiliary language-pairs and monolingual data can help improve the performance of languages with limited resources.</abstract>
      <bibkey>martinez-matsumoto-2016-improving</bibkey>
    </paper>
    <paper id="12">
      <title>Which Words Matter in Defining Phrase Reordering Behavior in Statistical Machine Translation?</title>
      <author><first>Hamidreza</first><last>Ghader</last></author>
      <author><first>Christof</first><last>Monz</last></author>
      <pages>149-162</pages>
      <url hash="d1093c13">2016.amta-researchers.12</url>
      <abstract>Lexicalized and hierarchical reordering models use relative frequencies of fully lexicalized phrase pairs to learn phrase reordering distributions. This results in unreliable estimation for infrequent phrase pairs which also tend to be longer phrases. There are some smoothing techniques used to smooth the distributions in these models. But these techniques are unable to address the similarities between phrase pairs and their reordering distributions. We propose two models to use shorter sub-phrase pairs of an original phrase pair to smooth the phrase reordering distributions. In the first model we follow the classic idea of backing off to shorter histories commonly used in language model smoothing. In the second model, we use syntactic dependencies to identify the most relevant words in a phrase to back off to. We show how these models can be easily applied to existing lexicalized and hierarchical reordering models. Our models achieve improvements of up to 0.40 BLEU points in Chinese-English translation compared to a baseline which uses a regular lexicalized reordering model and a hierarchical reordering model. The results show that not all the words inside a phrase pair are equally important in defining phrase reordering behavior and shortening towards important words will decrease the sparsity problem for long phrase pairs.</abstract>
      <bibkey>ghader-monz-2016-words</bibkey>
    </paper>
    <paper id="13">
      <title>Translation of Unknown Words in Low Resource Languages</title>
      <author><first>Biman</first><last>Gujral</last></author>
      <author><first>Huda</first><last>Khayrallah</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <pages>163-176</pages>
      <url hash="91825cf8">2016.amta-researchers.13</url>
      <bibkey>gujral-etal-2016-translation</bibkey>
    </paper>
    <paper id="14">
      <title>Automatic Construction of Morphologically Motivated Translation Models for Highly Inflected, Low-Resource Languages</title>
      <author><first>John</first><last>Hewitt</last></author>
      <author><first>Matt</first><last>Post</last></author>
      <author><first>David</first><last>Yarowsky</last></author>
      <pages>177-190</pages>
      <url hash="f380f459">2016.amta-researchers.14</url>
      <abstract>Statistical Machine Translation (SMT) of highly inflected, low-resource languages suffers from the problem of low bitext availability, which is exacerbated by large inflectional paradigms. When translating into English, rich source inflections have a high chance of being poorly estimated or out-of-vocabulary (OOV). We present a source language-agnostic system for automatically constructing phrase pairs from foreign-language inflections and their morphological analyses using manually constructed datasets, including Wiktionary. We then demonstrate the utility of these phrase tables in improving translation into English from Finnish, Czech, and Turkish in simulated low-resource settings, finding substantial gains in translation quality. We report up to +2.58 BLEU in a simulated low-resource setting and +1.65 BLEU in a moderateresource setting. We release our morphologically-motivated translation models, with tens of thousands of inflections in each of 8 languages.</abstract>
      <bibkey>hewitt-etal-2016-automatic</bibkey>
      <pwccode url="https://github.com/john-hewitt/morph16" additional="false">john-hewitt/morph16</pwccode>
    </paper>
    <paper id="15">
      <title>Investigating the Impact of Various Partial Diacritization Schemes on <fixed-case>A</fixed-case>rabic-<fixed-case>E</fixed-case>nglish Statistical Machine Translation</title>
      <author><first>Sawsan</first><last>Alqahtani</last></author>
      <author><first>Mahmoud</first><last>Ghoneim</last></author>
      <author><first>Mona</first><last>Diab</last></author>
      <pages>191-204</pages>
      <url hash="07c74871">2016.amta-researchers.15</url>
      <abstract>Most diacritics in Arabic represent short vowels. In Arabic orthography, such diacritics are considered optional. The absence of these diacritics naturally leads to significant word ambiguity to top the inherent ambiguity present in fully diacritized words. Word ambiguity is a significant impediment for machine translation. Despite the ambiguity presented by lack of diacritization, context helps ameliorate the situation. Identifying the appropriate amount of diacritic restoration to reduce word sense ambiguity in the context of machine translation is the object of this paper. Diacritic marks help reduce the number of possible lexical word choices assigned to a source word which leads to better quality translated sentences. We investigate a variety of (linguistically motivated) partial diacritization schemes that preserve some of the semantics that in essence complement the implicit contextual information present in the sentences. We also study the effect of training data size and report results on three standard test sets that represent a combination of different genres. The results show statistically significant improvements for some schemes compared to two baselines: text with no diacritics (the typical writing system adopted for Arabic) and text that is fully diacritized.</abstract>
      <bibkey>alqahtani-etal-2016-investigating</bibkey>
    </paper>
  </volume>
  <volume id="users" ingest-date="2021-10-17" type="proceedings">
    <meta>
      <booktitle>Conferences of the Association for Machine Translation in the Americas: MT Users' Track</booktitle>
      <publisher>The Association for Machine Translation in the Americas</publisher>
      <address>Austin, TX, USA</address>
      <month>October 28 - November 1</month>
      <year>2016</year>
      <url hash="0286e700">2016.amta-users</url>
      <editor><first>Spence</first><last>Green</last></editor>
      <editor><first>Lane</first><last>Schwartz</last></editor>
      <venue>amta</venue>
    </meta>
    <frontmatter>
      <url hash="0b2e4f45">2016.amta-users.0</url>
      <bibkey>amta-2016-conferences-association</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>MT</fixed-case> crowdsource at <fixed-case>Y</fixed-case>andex</title>
      <author><first>Irina</first><last>Galinskaya</last></author>
      <author><first>Farhat</first><last>Aminov</last></author>
      <pages>1-2</pages>
      <url hash="faca1ef2">2016.amta-users.1</url>
      <bibkey>galinskaya-aminov-2016-mt</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>MT</fixed-case> Post-Editing in a cloud based environment</title>
      <author><first>Jean-Luc</first><last>Saillard</last></author>
      <pages>3-18</pages>
      <attachment type="presentation" hash="0fbcd4fe">2016.amta-users.2.Presentation.pdf</attachment>
      <bibkey>saillard-2016-mt</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>MT</fixed-case> Adaptation from <fixed-case>TM</fixed-case>s in <fixed-case>M</fixed-case>odern<fixed-case>MT</fixed-case></title>
      <author><first>Marcello</first><last>Federico</last></author>
      <pages>19-57</pages>
      <attachment type="presentation" hash="8a566173">2016.amta-users.3.Presentation.pdf</attachment>
      <bibkey>federico-2016-mt</bibkey>
    </paper>
    <paper id="4">
      <title>Web App <fixed-case>UI</fixed-case> Layout Sniffer</title>
      <author><first>Raymond</first><last>Peng</last></author>
      <author><first>Xin Jing</first><last>Hu</last></author>
      <pages>58-64</pages>
      <url hash="08801e56">2016.amta-users.4</url>
      <bibkey>peng-hu-2016-web</bibkey>
    </paper>
    <paper id="5">
      <title>Multilingual Search with Machine Translation in the Intel Communities</title>
      <author><first>Ryan</first><last>Martin</last></author>
      <pages>65-71</pages>
      <url hash="5abfb69a">2016.amta-users.5</url>
      <bibkey>martin-2016-multilingual</bibkey>
    </paper>
    <paper id="6">
      <title><fixed-case>MT</fixed-case> Thresholding: Achieving a defined quality bar with a mix of human and machine translation</title>
      <author><first>Dag</first><last>Schmidtke</last></author>
      <pages>72-81</pages>
      <attachment type="presentation" hash="a5f53088">2016.amta-users.6.Presentation.pdf</attachment>
      <bibkey>schmidtke-2016-mt</bibkey>
    </paper>
    <paper id="7">
      <title>Machine Translation Acceptance Among Professional Linguists: Are We Nearing the Tipping Point?</title>
      <author><first>Yves</first><last>Champollion</last></author>
      <pages>82-85</pages>
      <url hash="9a68640c">2016.amta-users.7</url>
      <bibkey>champollion-2016-machine</bibkey>
    </paper>
    <paper id="8">
      <title>What Can We Really Learn from Post-editing?</title>
      <author><first>Marcis</first><last>Pinnis</last></author>
      <author><first>Rihards</first><last>Kalnins</last></author>
      <author><first>Raivis</first><last>Skadins</last></author>
      <author><first>Inguna</first><last>Skadina</last></author>
      <pages>86-91</pages>
      <url hash="64207e07">2016.amta-users.8</url>
      <bibkey>pinnis-etal-2016-really</bibkey>
    </paper>
    <paper id="9">
      <title>An Empirical Study: Post-editing Effort for <fixed-case>E</fixed-case>nglish to <fixed-case>A</fixed-case>rabic Hybrid Machine Translation</title>
      <author><first>Hassan</first><last>Sajjad</last></author>
      <author><first>Francisco</first><last>Guzman</last></author>
      <author><first>Stephan</first><last>Vogel</last></author>
      <pages>92-113</pages>
      <attachment type="presentation" hash="011d1517">2016.amta-users.9.Presentation.pdf</attachment>
      <bibkey>sajjad-etal-2016-empirical</bibkey>
    </paper>
    <paper id="10">
      <title>Divide and Conquer Strategy for Large Data <fixed-case>MT</fixed-case></title>
      <author><first>Dimitar</first><last>Shterionov</last></author>
      <pages>114-122</pages>
      <url hash="13f49bed">2016.amta-users.10</url>
      <bibkey>shterionov-2016-divide</bibkey>
    </paper>
    <paper id="11">
      <title>The Reasonable Effectiveness of Data</title>
      <author><first>Achim</first><last>Ruopp</last></author>
      <pages>123-142</pages>
      <attachment type="presentation" hash="4ef589a6">2016.amta-users.11.Presentation.pdf</attachment>
      <bibkey>ruopp-2016-reasonable</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>MT</fixed-case> for <fixed-case>U</fixed-case>ralic Languages: <fixed-case>Y</fixed-case>andex Approach</title>
      <author><first>Irina</first><last>Galinskaya</last></author>
      <author><first>Alexey</first><last>Baytin</last></author>
      <pages>143-144</pages>
      <url hash="32103548">2016.amta-users.12</url>
      <bibkey>galinskaya-baytin-2016-mt</bibkey>
    </paper>
    <paper id="13">
      <title>Seamlessly integrating machine translation into existing translation processes (<fixed-case>STAR</fixed-case> <fixed-case>MT</fixed-case> and Transit <fixed-case>NXT</fixed-case>)</title>
      <author><first>Nadira</first><last>Hofmann</last></author>
      <pages>145-169</pages>
      <attachment type="presentation" hash="0bc13dc7">2016.amta-users.13.Presentation.pdf</attachment>
      <bibkey>hofmann-2016-seamlessly</bibkey>
    </paper>
    <paper id="14">
      <title>Building a Translation Memory to Improve Machine Translation Coverage and Quality</title>
      <author><first>Duncan</first><last>Gillespie</last></author>
      <author><first>Benjamin</first><last>Russell</last></author>
      <pages>170-178</pages>
      <url hash="09ee6208">2016.amta-users.14</url>
      <bibkey>gillespie-russell-2016-building</bibkey>
    </paper>
    <paper id="15">
      <title>Enhancing a Production <fixed-case>TM</fixed-case>-<fixed-case>MT</fixed-case> Environment Using a Quotation <fixed-case>TM</fixed-case></title>
      <author><first>Hitokazu</first><last>Matsushita</last></author>
      <author><first>Steve</first><last>Richardson</last></author>
      <pages>179-192</pages>
      <url hash="c8c603c1">2016.amta-users.15</url>
      <bibkey>matsushita-richardson-2016-enhancing</bibkey>
    </paper>
    <paper id="16">
      <title>Improving Machine Translation for Post-Editing via Real Time Adaptation</title>
      <author><first>Dragos</first><last>Munteanu</last></author>
      <pages>193-221</pages>
      <attachment type="presentation" hash="04bc9ed3">2016.amta-users.16.Presentation.pdf</attachment>
      <bibkey>munteanu-2016-improving</bibkey>
    </paper>
    <paper id="17">
      <title>Improving <fixed-case>K</fixed-case>antan<fixed-case>MT</fixed-case> Training Efficiency with fast_align</title>
      <author><first>Dimitar</first><last>Shterionov</last></author>
      <author><first>Jinhua</first><last>Du</last></author>
      <author><first>Marc Anthony</first><last>Palminteri</last></author>
      <author><first>Laura</first><last>Casanellas</last></author>
      <author><first>Tony</first><last>O’Dowd</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <pages>222-231</pages>
      <url hash="c7160a5c">2016.amta-users.17</url>
      <bibkey>shterionov-etal-2016-improving</bibkey>
    </paper>
    <paper id="18">
      <title>Speech translation user experience in practice</title>
      <author><first>Chris</first><last>Wendt</last></author>
      <author><first>Will</first><last>Lewis</last></author>
      <author><first>Tanvi</first><last>Surti</last></author>
      <pages>232-239</pages>
      <url hash="94e55d5d">2016.amta-users.18</url>
      <bibkey>wendt-etal-2016-speech</bibkey>
    </paper>
    <paper id="19">
      <title>Evaluation of machine translation quality in e-commerce environment</title>
      <author><first>Maxim</first><last>Khalilov</last></author>
      <pages>240-262</pages>
      <attachment type="presentation" hash="c8a09281">2016.amta-users.19.Presentation.pdf</attachment>
      <bibkey>khalilov-2016-evaluation</bibkey>
    </paper>
    <paper id="20">
      <title><fixed-case>I</fixed-case> Ate Too Much Cake: Beyond Domain-Specific <fixed-case>MT</fixed-case> Engines</title>
      <author><first>Alex</first><last>Yanishevsky</last></author>
      <pages>263-285</pages>
      <attachment type="presentation" hash="0ec255ef">2016.amta-users.20.Presentation.pdf</attachment>
      <bibkey>yanishevsky-2016-ate</bibkey>
    </paper>
    <paper id="21">
      <title>What? Why? How? - Factors that impact the success of commercial <fixed-case>MT</fixed-case> projects</title>
      <author><first>John</first><last>Tinsley</last></author>
      <pages>286-303</pages>
      <attachment type="presentation" hash="2c9542aa">2016.amta-users.21.Presentation.pdf</attachment>
      <bibkey>tinsley-2016-factors</bibkey>
    </paper>
    <paper id="22">
      <title>Assessing Translation Quality Metrics</title>
      <author><first>Jennifer</first><last>DeCamp</last></author>
      <pages>304-321</pages>
      <attachment type="presentation" hash="a199f3d9">2016.amta-users.22.Presentation.pdf</attachment>
      <bibkey>decamp-2016-assessing</bibkey>
    </paper>
    <paper id="23">
      <title>Machine Translation for <fixed-case>E</fixed-case>nglish Retrieval of Information in Any Language (Machine translation for <fixed-case>E</fixed-case>nglish-based domain-appropriate triage of information in any language)</title>
      <author><first>Carl</first><last>Rubino</last></author>
      <pages>322-354</pages>
      <attachment type="presentation" hash="5bb6df6e">2016.amta-users.23.Presentation.pdf</attachment>
      <bibkey>rubino-2016-machine</bibkey>
    </paper>
    <paper id="24">
      <title>A Taxonomy of Weeds: A Field Guide for Corpus Curators to Winnowing the Parallel Text Harvest</title>
      <author><first>Katherine M.</first><last>Young</last></author>
      <author><first>Jeremy</first><last>Gwinnup</last></author>
      <author><first>Lane O.B.</first><last>Schwartz</last></author>
      <pages>355-370</pages>
      <url hash="a778d025">2016.amta-users.24</url>
      <bibkey>young-etal-2016-taxonomy</bibkey>
    </paper>
    <paper id="25">
      <title>Toward Temporally-aware <fixed-case>MT</fixed-case>: Can Information Extraction Help Preserve Temporal Interpretation?</title>
      <author><first>Taylor</first><last>Cassidy</last></author>
      <author><first>Jamal</first><last>Laoudi</last></author>
      <author><first>Clare</first><last>Voss</last></author>
      <pages>371-384</pages>
      <url hash="91e112c9">2016.amta-users.25</url>
      <bibkey>cassidy-etal-2016-toward</bibkey>
    </paper>
    <paper id="26">
      <title>Did You Mean...? and Dictionary Repair: from Science to Engineering</title>
      <author><first>Michael</first><last>Maxwell</last></author>
      <author><first>Petra</first><last>Bradley</last></author>
      <pages>385-411</pages>
      <attachment type="presentation" hash="0f53f4c2">2016.amta-users.26.Presentation.pdf</attachment>
      <bibkey>maxwell-bradley-2016-mean</bibkey>
    </paper>
    <paper id="27">
      <title>Principle-Based Preparation of Authentic Bilingual Text Resources</title>
      <author><first>Michelle</first><last>Vanni</last></author>
      <pages>412-421</pages>
      <attachment type="presentation" hash="fc1293f8">2016.amta-users.27.Presentation.pdf</attachment>
      <bibkey>vanni-2016-principle</bibkey>
    </paper>
    <paper id="28">
      <title>Machine Translation of <fixed-case>C</fixed-case>anadian Court Decisions</title>
      <author><first>Lucie</first><last>Langlois</last></author>
      <author><first>Michel</first><last>Simard</last></author>
      <author><first>Elliott</first><last>Macklovitch</last></author>
      <pages>422-452</pages>
      <attachment type="presentation" hash="efbfa80b">2016.amta-users.28.Presentation.pdf</attachment>
      <bibkey>langlois-etal-2016-machine</bibkey>
    </paper>
    <paper id="29">
      <title>Putting the “human” back in <fixed-case>HLT</fixed-case>: The importance of human evaluation in assessing the quality and potential uses of translation technology</title>
      <author><first>Erica</first><last>Michael</last></author>
      <author><first>Petra</first><last>Bradley</last></author>
      <author><first>Paul</first><last>McNamee</last></author>
      <author><first>Matt</first><last>Post</last></author>
      <pages>453-550</pages>
      <attachment type="presentation" hash="a3edb329">2016.amta-users.29.Presentation.pdf</attachment>
      <bibkey>michael-etal-2016-putting</bibkey>
    </paper>
    <paper id="30">
      <title>Proto-<fixed-case>MT</fixed-case> Evaluation for Humanitarian Assistance Disaster Response Scenarios</title>
      <author><first>Douglas</first><last>Jones</last></author>
      <pages>551-574</pages>
      <attachment type="presentation" hash="f53c51b1">2016.amta-users.30.Presentation.pdf</attachment>
      <bibkey>jones-2016-proto</bibkey>
    </paper>
    <paper id="31">
      <title>Wearable Devices to Enable Communication via <fixed-case>ASL</fixed-case> (Sign Language Translation)</title>
      <author><first>Patricia</first><last>O’Neill-Brown</last></author>
      <author><first>Nicolas</first><last>Malyska</last></author>
      <pages>575-594</pages>
      <attachment type="presentation" hash="4a361085">2016.amta-users.31.Presentation.pdf</attachment>
      <bibkey>oneill-brown-malyska-2016-wearable</bibkey>
    </paper>
    <paper id="32">
      <title>Tuning for Neural Machine Translation</title>
      <author><first>Guido</first><last>Zarrella</last></author>
      <pages>595-621</pages>
      <attachment type="presentation" hash="cbb74e0b">2016.amta-users.32.Presentation.pdf</attachment>
      <bibkey>zarrella-2016-tuning</bibkey>
    </paper>
    <paper id="33">
      <title>Invisible <fixed-case>MT</fixed-case></title>
      <author><first>Patricia</first><last>O’Neill-Brown</last></author>
      <pages>622-653</pages>
      <attachment type="presentation" hash="4285fa18">2016.amta-users.33.Presentation.pdf</attachment>
      <bibkey>oneill-brown-2016-invisible</bibkey>
    </paper>
    <paper id="34">
      <title><fixed-case>M</fixed-case>o<fixed-case>J</fixed-case>o: Bringing Hybrid <fixed-case>MT</fixed-case> to the Center for Applied Machine Translation</title>
      <author><first>Marianna</first><last>Martindale</last></author>
      <pages>654-714</pages>
      <attachment type="presentation" hash="4a56ba64">2016.amta-users.34.Presentation.pdf</attachment>
      <bibkey>martindale-2016-mojo</bibkey>
    </paper>
    <paper id="35">
      <title>Building Renewable Language Assets in Government Domains</title>
      <author><first>Beth</first><last>Flaherty</last></author>
      <author><first>Joshua</first><last>Johanson</last></author>
      <pages>715-732</pages>
      <attachment type="presentation" hash="77023f25">2016.amta-users.35.Presentation.pdf</attachment>
      <bibkey>flaherty-johanson-2016-building</bibkey>
    </paper>
  </volume>
</collection>
