<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.splurobonlp">
  <volume id="1" ingest-date="2024-07-25" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 4th Workshop on Spatial Language Understanding and Grounded Communication for Robotics (SpLU-RoboNLP 2024)</booktitle>
      <editor><first>Parisa</first><last>Kordjamshidi</last></editor>
      <editor><first>Xin Eric</first><last>Wang</last></editor>
      <editor><first>Yue</first><last>Zhang</last></editor>
      <editor><first>Ziqiao</first><last>Ma</last></editor>
      <editor><first>Mert</first><last>Inan</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Bangkok, Thailand</address>
      <month>August</month>
      <year>2024</year>
      <url hash="69759e9f">2024.splurobonlp-1</url>
      <venue>splurobonlp</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="30890fa3">2024.splurobonlp-1.0</url>
      <bibkey>splurobonlp-2024-spatial</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Language-guided World Models: A Model-based Approach to <fixed-case>AI</fixed-case> Control</title>
      <author><first>Alex</first><last>Zhang</last></author>
      <author><first>Khanh</first><last>Nguyen</last></author>
      <author><first>Jens</first><last>Tuyls</last></author>
      <author><first>Albert</first><last>Lin</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Karthik</first><last>Narasimhan</last><affiliation>Princeton University</affiliation></author>
      <pages>1-16</pages>
      <abstract>Developing internal world models for artificial agents opens an efficient channel for humans to communicate with and control them. In addition to updating policies, humans can modify the world models of these agents in order to influence their decisions.The challenge, however, is that currently existing world models are difficult for humans to adapt because they lack a natural communication interface. Aimed at addressing this shortcoming, we develop *Language-Guided World Models* (LWMs), which can capture environment dynamics by reading language descriptions. These models enhance agent communication efficiency, allowing humans to simultaneously alter their behavior on multiple tasks with concise language feedback. They also enable agents to self-learn from texts originally written to instruct humans. To facilitate the development of LWMs, we design a challenging benchmark based on the game of MESSENGER (Hanjie et al., 2021), requiring compositional generalization to new language descriptions and environment dynamics. Our experiments reveal that the current state-of-the-art Transformer architecture performs poorly on this benchmark, motivating us to design a more robust architecture. To showcase the practicality of our proposed LWMs, we simulate a scenario where these models augment the interpretability and safety of an agent by enabling it to generate and discuss plans with a human before execution. By effectively incorporating language feedback on the plan, the models boost the agent performance in the real environment by up to three times without collecting any interactive experiences in this environment.</abstract>
      <url hash="72d3b102">2024.splurobonlp-1.1</url>
      <bibkey>zhang-etal-2024-language</bibkey>
    </paper>
    <paper id="2">
      <title>Learning Communication Policies for Different Follower Behaviors in a Collaborative Reference Game</title>
      <author><first>Philipp</first><last>Sadler</last><affiliation>University of Potsdam</affiliation></author>
      <author><first>Sherzod</first><last>Hakimov</last><affiliation>Universität Potsdam</affiliation></author>
      <author><first>David</first><last>Schlangen</last><affiliation>University of Potsdam</affiliation></author>
      <pages>17-29</pages>
      <abstract>In this work, we evaluate the adaptability of neural agents towards assumed partner behaviors in a collaborative reference game. In this game, success is achieved when a knowledgeable guide can verbally lead a follower to the selection of a specific puzzle piece among several distractors. We frame this language grounding and coordination task as a reinforcement learning problem and measure to which extent a common reinforcement training algorithm (PPO) is able to produce neural agents (the guides) that perform well with various heuristic follower behaviors that vary along the dimensions of confidence and autonomy. We experiment with a learning signal that in addition to the goal condition also respects an assumed communicative effort. Our results indicate that this novel ingredient leads to communicative strategies that are less verbose (staying silent in some of the steps) and that with respect to that the guide’s strategies indeed adapt to the partner’s level of confidence and autonomy.</abstract>
      <url hash="bf04497e">2024.splurobonlp-1.2</url>
      <bibkey>sadler-etal-2024-learning</bibkey>
    </paper>
    <paper id="3">
      <title>Collection of <fixed-case>J</fixed-case>apanese Route Information Reference Expressions Using Maps as Stimuli</title>
      <author><first>Yoshiko</first><last>Kawabata</last><affiliation>NA</affiliation></author>
      <author><first>Mai</first><last>Omura</last><affiliation>National Institute for Japanese Language and Linguistics</affiliation></author>
      <author><first>Hikari</first><last>Konishi</last><affiliation>NA</affiliation></author>
      <author><first>Masayuki</first><last>Asahara</last><affiliation>National Institute for Japanese Language and Linguistics, Japan</affiliation></author>
      <author><first>Johane</first><last>Takeuchi</last><affiliation>NA</affiliation></author>
      <pages>30-35</pages>
      <abstract>We constructed a database of Japanese expressions based on route information. Using 20 maps as stimuli, we requested descriptions of routes between two points on each map from 40 individuals per route, collecting 1600 route information reference expressions. We determined whether the expressions were based solely on relative reference expressions by using landmarks on the maps. In cases in which only relative reference expressions were used, we labeled the presence or absence of information regarding the starting point, waypoints, and destination. Additionally, we collected clarity ratings for each expression using a survey.</abstract>
      <url hash="e452074d">2024.splurobonlp-1.3</url>
      <bibkey>kawabata-etal-2024-collection</bibkey>
    </paper>
  </volume>
</collection>
