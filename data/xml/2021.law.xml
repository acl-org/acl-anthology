<?xml version='1.0' encoding='UTF-8'?>
<collection id="2021.law">
  <volume id="1" ingest-date="2021-10-28">
    <meta>
      <booktitle>Proceedings of the Joint 15th Linguistic Annotation Workshop (LAW) and 3rd Designing Meaning Representations (DMR) Workshop</booktitle>
      <editor><first>Claire</first><last>Bonial</last></editor>
      <editor><first>Nianwen</first><last>Xue</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Punta Cana, Dominican Republic</address>
      <month>November</month>
      <year>2021</year>
      <venue>law</venue>
    </meta>
    <frontmatter>
      <url hash="45004721">2021.law-1.0</url>
      <bibkey>law-2021-joint</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Zero-shot cross-lingual Meaning Representation Transfer: Annotation of <fixed-case>H</fixed-case>ungarian using the <fixed-case>P</fixed-case>rague Functional Generative Description</title>
      <author><first>Attila</first><last>Novák</last></author>
      <author><first>Borbála</first><last>Novák</last></author>
      <author><first>Csilla</first><last>Novák</last></author>
      <pages>1–11</pages>
      <abstract>In this paper, we present the results of our experiments concerning the zero-shot cross-lingual performance of the PERIN sentence-to-graph semantic parser. We applied the PTG model trained using the PERIN parser on a 740k-token Czech newspaper corpus to Hungarian. We evaluated the performance of the parser using the official evaluation tool of the MRP 2020 shared task. The gold standard Hungarian annotation was created by manual correction of the output of the parser following the annotation manual of the tectogrammatical level of the Prague Dependency Treebank. An English model trained on a larger one-million-token English newspaper corpus is also available, however, we found that the Czech model performed significantly better on Hungarian input due to the fact that Hungarian is typologically more similar to Czech than to English. We have found that zero-shot transfer of the PTG meaning representation across typologically not-too-distant languages using a neural parser model based on a multilingual contextual language model followed by a manual correction by linguist experts seems to be a viable scenario.</abstract>
      <url hash="de5892c7">2021.law-1.1</url>
      <bibkey>novak-etal-2021-zero</bibkey>
      <doi>10.18653/v1/2021.law-1.1</doi>
    </paper>
    <paper id="2">
      <title>Theoretical and Practical Issues in the Semantic Annotation of Four Indigenous Languages</title>
      <author><first>Jens E. L.</first><last>Van Gysel</last></author>
      <author><first>Meagan</first><last>Vigus</last></author>
      <author><first>Lukas</first><last>Denk</last></author>
      <author><first>Andrew</first><last>Cowell</last></author>
      <author><first>Rosa</first><last>Vallejos</last></author>
      <author><first>Tim</first><last>O’Gorman</last></author>
      <author><first>William</first><last>Croft</last></author>
      <pages>12–22</pages>
      <abstract>Computational resources such as semantically annotated corpora can play an important role in enabling speakers of indigenous minority languages to participate in government, education, and other domains of public life in their own language. However, many languages – mainly those with small native speaker populations and without written traditions – have little to no digital support. One hurdle in creating such resources is that for many languages, few speakers would be capable of annotating texts – a task which requires literacy and some linguistic training – and that these experts’ time is typically in high demand for language planning work. This paper assesses whether typologically trained non-speakers of an indigenous language can feasibly perform semantic annotation using Uniform Meaning Representations, thus allowing for the creation of computational materials without putting further strain on community resources.</abstract>
      <url hash="6884a7c9">2021.law-1.2</url>
      <bibkey>van-gysel-etal-2021-theoretical</bibkey>
      <doi>10.18653/v1/2021.law-1.2</doi>
    </paper>
    <paper id="3">
      <title>Representing Implicit Positive Meaning of Negated Statements in <fixed-case>AMR</fixed-case></title>
      <author><first>Katharina</first><last>Stein</last></author>
      <author><first>Lucia</first><last>Donatelli</last></author>
      <pages>23–35</pages>
      <abstract>Abstract Meaning Representation (AMR) has become popular for representing the meaning of natural language in graph structures. However, AMR does not represent scope information, posing a problem for its overall expressivity and specifically for drawing inferences from negated statements. This is the case with so-called “positive interpretations” of negated statements, in which implicit positive meaning is identified by inferring the opposite of the negation’s focus. In this work, we investigate how potential positive interpretations (PPIs) can be represented in AMR. We propose a logically motivated AMR structure for PPIs that makes the focus of negation explicit and sketch an initial proposal for a systematic methodology to generate this more expressive structure.</abstract>
      <url hash="375da95b">2021.law-1.3</url>
      <bibkey>stein-donatelli-2021-representing</bibkey>
      <doi>10.18653/v1/2021.law-1.3</doi>
    </paper>
    <paper id="4">
      <title><fixed-case>A</fixed-case>uto<fixed-case>A</fixed-case>spect: Automatic Annotation of Tense and Aspect for Uniform Meaning Representations</title>
      <author><first>Daniel</first><last>Chen</last></author>
      <author><first>Martha</first><last>Palmer</last></author>
      <author><first>Meagan</first><last>Vigus</last></author>
      <pages>36–45</pages>
      <abstract>We present AutoAspect, a novel, rule-based annotation tool for labeling tense and aspect. The pilot version annotates English data. The aspect labels are designed specifically for Uniform Meaning Representations (UMR), an annotation schema that aims to encode crosslingual semantic information. The annotation tool combines syntactic and semantic cues to assign aspects on a sentence-by-sentence basis, following a sequence of rules that each output a UMR aspect. Identified events proceed through the sequence until they are assigned an aspect. We achieve a recall of 76.17% for identifying UMR events and an accuracy of 62.57% on all identified events, with high precision values for 2 of the aspect labels.</abstract>
      <url hash="058b0f56">2021.law-1.4</url>
      <bibkey>chen-etal-2021-autoaspect</bibkey>
      <revision id="1" href="2021.law-1.4v1" hash="73da1acb"/>
      <revision id="2" href="2021.law-1.4v2" hash="058b0f56" date="2021-11-09">Added a sponsor in acknowledgements.</revision>
      <doi>10.18653/v1/2021.law-1.4</doi>
    </paper>
    <paper id="5">
      <title>Can predicate-argument relationships be extracted from <fixed-case>UD</fixed-case> trees?</title>
      <author><first>Adam</first><last>Ek</last></author>
      <author><first>Jean-Philippe</first><last>Bernardy</last></author>
      <author><first>Stergios</first><last>Chatzikyriakidis</last></author>
      <pages>46–55</pages>
      <abstract>In this paper we investigate the possibility of extracting predicate-argument relations from UD trees (and enhanced UD graphs). Con- cretely, we apply UD parsers on an En- glish question answering/semantic-role label- ing data set (FitzGerald et al., 2018) and check if the annotations reflect the relations in the resulting parse trees, using a small number of rules to extract this information. We find that 79.1% of the argument-predicate pairs can be found in this way, on the basis of Ud- ify (Kondratyuk and Straka, 2019). Error anal- ysis reveals that half of the error cases are at- tributable to shortcomings in the dataset. The remaining errors are mostly due to predicate- argument relations not being extractible algo- rithmically from the UD trees (requiring se- mantic reasoning to be resolved). The parser itself is only responsible for a small portion of errors. Our analysis suggests a number of improvements to the UD annotation schema: we propose to enhance the schema in four ways, in order to capture argument-predicate relations. Additionally, we propose improve- ments regarding data collection for question answering/semantic-role labeling data.</abstract>
      <url hash="37166656">2021.law-1.5</url>
      <bibkey>ek-etal-2021-predicate</bibkey>
      <doi>10.18653/v1/2021.law-1.5</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/qa-srl">QA-SRL</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="6">
      <title>Classifying Divergences in Cross-lingual <fixed-case>AMR</fixed-case> Pairs</title>
      <author><first>Shira</first><last>Wein</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>56–65</pages>
      <abstract>Translation divergences are varied and widespread, challenging approaches that rely on parallel text. To annotate translation divergences, we propose a schema grounded in the Abstract Meaning Representation (AMR), a sentence-level semantic framework instantiated for a number of languages. By comparing parallel AMR graphs, we can identify specific points of divergence. Each divergence is labeled with both a type and a cause. We release a small corpus of annotated English-Spanish data, and analyze the annotations in our corpus.</abstract>
      <url hash="375d34f8">2021.law-1.6</url>
      <bibkey>wein-schneider-2021-classifying</bibkey>
      <doi>10.18653/v1/2021.law-1.6</doi>
      <pwccode url="https://github.com/shirawein/spanish-english-amr-corpus" additional="false">shirawein/spanish-english-amr-corpus</pwccode>
    </paper>
    <paper id="7">
      <title>A Linguistic Annotation Framework to Study Interactions in Multilingual Healthcare Conversational Forums</title>
      <author><first>Ishani</first><last>Mondal</last></author>
      <author><first>Kalika</first><last>Bali</last></author>
      <author><first>Mohit</first><last>Jain</last></author>
      <author><first>Monojit</first><last>Choudhury</last></author>
      <author><first>Ashish</first><last>Sharma</last></author>
      <author><first>Evans</first><last>Gitau</last></author>
      <author><first>Jacki</first><last>O’Neill</last></author>
      <author><first>Kagonya</first><last>Awori</last></author>
      <author><first>Sarah</first><last>Gitau</last></author>
      <pages>66–77</pages>
      <abstract>In recent years, remote digital healthcare using online chats has gained momentum, especially in the Global South. Though prior work has studied interaction patterns in online (health) forums, such as TalkLife, Reddit and Facebook, there has been limited work in understanding interactions in small, close-knit community of instant messengers. In this paper, we propose a linguistic annotation framework to facilitate analysis of health-focused WhatsApp groups. The primary aim of the framework is to understand interpersonal relationships among peer supporters in order to help develop NLP solutions for remote patient care and reduce burden of overworked healthcare providers. Our framework consists of fine-grained peer support categorization and message-level sentiment tagging. Additionally, due to the prevalence of code-mixing in such groups, we incorporate word-level language annotations. We use the proposed framework to study two WhatsApp groups in Kenya for youth living with HIV, facilitated by a healthcare provider.</abstract>
      <url hash="178461c2">2021.law-1.7</url>
      <bibkey>mondal-etal-2021-linguistic</bibkey>
      <doi>10.18653/v1/2021.law-1.7</doi>
    </paper>
    <paper id="8">
      <title>Sister Help: Data Augmentation for Frame-Semantic Role Labeling</title>
      <author><first>Ayush</first><last>Pancholy</last></author>
      <author><first>Miriam R L</first><last>Petruck</last></author>
      <author><first>Swabha</first><last>Swayamdipta</last></author>
      <pages>78–84</pages>
      <abstract>While FrameNet is widely regarded as a rich resource of semantics in natural language processing, a major criticism concerns its lack of coverage and the relative paucity of its labeled data compared to other commonly used lexical resources such as PropBank and VerbNet. This paper reports on a pilot study to address these gaps. We propose a data augmentation approach, which uses existing frame-specific annotation to automatically annotate other lexical units of the same frame which are unannotated. Our rule-based approach defines the notion of a **sister lexical unit** and generates frame-specific augmented data for training. We present experiments on frame-semantic role labeling which demonstrate the importance of this data augmentation: we obtain a large improvement to prior results on frame identification and argument identification for FrameNet, utilizing both full-text and lexicographic annotations under FrameNet. Our findings on data augmentation highlight the value of automatic resource creation for improved models in frame-semantic parsing.</abstract>
      <url hash="ef2f529e">2021.law-1.8</url>
      <bibkey>pancholy-etal-2021-sister</bibkey>
      <doi>10.18653/v1/2021.law-1.8</doi>
      <pwccode url="https://github.com/ayush-pancholy/sister-help" additional="false">ayush-pancholy/sister-help</pwccode>
    </paper>
    <paper id="9">
      <title>A Corpus Study of Creating Rule-Based Enhanced <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies for <fixed-case>G</fixed-case>erman</title>
      <author><first>Teresa</first><last>Bürkle</last></author>
      <author><first>Stefan</first><last>Grünewald</last></author>
      <author><first>Annemarie</first><last>Friedrich</last></author>
      <pages>85–95</pages>
      <abstract>In this paper, we present a first attempt at enriching German Universal Dependencies (UD) treebanks with enhanced dependencies. Similarly to the converter for English (Schuster and Manning, 2016), we develop a rule-based system for deriving enhanced dependencies from the basic layer, covering three linguistic phenomena: relative clauses, coordination, and raising/control. For quality control, we manually correct or validate a set of 196 sentences, finding that around 90% of added relations are correct. Our data analysis reveals that difficulties arise mainly due to inconsistencies in the basic layer annotations. We show that the English system is in general applicable to German data, but that adapting to the particularities of the German treebanks and language increases precision and recall by up to 10%. Comparing the application of our converter on gold standard dependencies vs. automatic parses, we find that F1 drops by around 10% in the latter setting due to error propagation. Finally, an enhanced UD parser trained on a converted treebank performs poorly when evaluated against our annotations, indicating that more work remains to be done to create gold standard enhanced German treebanks.</abstract>
      <url hash="c625c9ca">2021.law-1.9</url>
      <bibkey>burkle-etal-2021-corpus</bibkey>
      <doi>10.18653/v1/2021.law-1.9</doi>
      <pwccode url="https://github.com/boschresearch/german_enhanced_ud_converter_law_dmr_2021" additional="false">boschresearch/german_enhanced_ud_converter_law_dmr_2021</pwccode>
    </paper>
    <paper id="10">
      <title>Subcategorizing Adverbials in <fixed-case>U</fixed-case>niversal <fixed-case>C</fixed-case>onceptual <fixed-case>C</fixed-case>ognitive <fixed-case>A</fixed-case>nnotation</title>
      <author><first>Zhuxin</first><last>Wang</last></author>
      <author><first>Jakob</first><last>Prange</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>96–105</pages>
      <abstract>Universal Conceptual Cognitive Annotation (UCCA) is a semantic annotation scheme that organizes texts into coarse predicate-argument structure, offering broad coverage of semantic phenomena. At the same time, there is still need for a finer-grained treatment of many of the categories. The Adverbial category is of special interest, as it covers a wide range of fundamentally different meanings such as negation, causation, aspect, and event quantification. In this paper we introduce a refinement annotation scheme for UCCA’s Adverbial category, showing that UCCA Adverbials can indeed be subcategorized into at least 7 semantic types, and doing so can help clarify and disambiguate the otherwise coarse-grained labels. We provide a preliminary set of annotation guidelines, as well as pilot annotation experiments with high inter-annotator agreement, confirming the validity of the scheme.</abstract>
      <url hash="b9971d4a">2021.law-1.10</url>
      <bibkey>wang-etal-2021-subcategorizing</bibkey>
      <doi>10.18653/v1/2021.law-1.10</doi>
    </paper>
    <paper id="11">
      <title>Simplifying annotation of intersections in time normalization annotation: exploring syntactic and semantic validation</title>
      <author><first>Peiwen</first><last>Su</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <pages>106–111</pages>
      <abstract>While annotating normalized times in food security documents, we found that the semantically compositional annotation for time normalization (SCATE) scheme required several near-duplicate annotations to get the correct semantics for expressions like Nov. 7th to 11th 2021. To reduce this problem, we explored replacing SCATE’s Sub-Interval property with a Super-Interval property, that is, making the smallest units (e.g., 7th and 11th) rather than the largest units (e.g., 2021) the heads of the intersection chains. To ensure that the semantics of annotated time intervals remained unaltered despite our changes to the syntax of the annotation scheme, we applied several different techniques to validate our changes. These validation techniques detected and allowed us to resolve several important bugs in our automated translation from Sub-Interval to Super-Interval syntax.</abstract>
      <url hash="4d5765ce">2021.law-1.11</url>
      <bibkey>su-bethard-2021-simplifying</bibkey>
      <revision id="1" href="2021.law-1.11v1" hash="c5470273"/>
      <revision id="2" href="2021.law-1.11v2" hash="1acae20b" date="2021-12-02">Corrected paper to show author names instead of anonymous.</revision>
      <doi>10.18653/v1/2021.law-1.11</doi>
      <revision id="3" href="2021.law-1.11v3" hash="4d5765ce" date="2022-03-20">Restored the page numbers and footer lost in the previous revision, and added missing grant acknowledgements.</revision>
    </paper>
    <paper id="12">
      <title>Overcoming the challenges in morphological annotation of <fixed-case>T</fixed-case>urkish in universal dependencies framework</title>
      <author><first>Talha</first><last>Bedir</last></author>
      <author><first>Karahan</first><last>Şahin</last></author>
      <author><first>Onur</first><last>Gungor</last></author>
      <author><first>Suzan</first><last>Uskudarli</last></author>
      <author><first>Arzucan</first><last>Özgür</last></author>
      <author><first>Tunga</first><last>Güngör</last></author>
      <author><first>Balkiz</first><last>Ozturk Basaran</last></author>
      <pages>112–122</pages>
      <abstract>This paper presents several challenges faced when annotating Turkish treebanks in accordance with the Universal Dependencies (UD) guidelines and proposes solutions to address them. Most of these challenges stem from the lack of adequate support in the UD framework to accurately represent null morphemes and complex derivations, which results in a significant loss of information for Turkish. This loss negatively impacts the tools that are developed based on these treebanks. We raised and discussed these issues within the community on the official UD portal. This paper presents these issues and our proposals to more accurately represent morphosyntactic information for Turkish while adhering to guidelines of UD. This work aims to contribute to the representation of Turkish and other agglutinative languages in UD-based treebanks, which in turn aids to develop more accurately annotated datasets for such languages.</abstract>
      <url hash="9e9b4e1f">2021.law-1.12</url>
      <bibkey>bedir-etal-2021-overcoming</bibkey>
      <doi>10.18653/v1/2021.law-1.12</doi>
    </paper>
    <paper id="13">
      <title>Automatic Entity State Annotation using the <fixed-case>V</fixed-case>erb<fixed-case>N</fixed-case>et Semantic Parser</title>
      <author><first>Ghazaleh</first><last>Kazeminejad</last></author>
      <author><first>Martha</first><last>Palmer</last></author>
      <author><first>Tao</first><last>Li</last></author>
      <author><first>Vivek</first><last>Srikumar</last></author>
      <pages>123–132</pages>
      <abstract>Tracking entity states is a natural language processing task assumed to require human annotation. In order to reduce the time and expenses associated with annotation, we introduce a new method to automatically extract entity states, including location and existence state of entities, following Dalvi et al. (2018) and Tandon et al. (2020). For this purpose, we rely primarily on the semantic representations generated by the state of the art VerbNet parser (Gung, 2020), and extract the entities (event participants) and their states, based on the semantic predicates of the generated VerbNet semantic representation, which is in propositional logic format. For evaluation, we used ProPara (Dalvi et al., 2018), a reading comprehension dataset which is annotated with entity states in each sentence, and tracks those states in paragraphs of natural human-authored procedural texts. Given the presented limitations of the method, the peculiarities of the ProPara dataset annotations, and that our system, Lexis, makes no use of task-specific training data and relies solely on VerbNet, the results are promising, showcasing the value of lexical resources.</abstract>
      <url hash="5714102e">2021.law-1.13</url>
      <bibkey>kazeminejad-etal-2021-automatic</bibkey>
      <doi>10.18653/v1/2021.law-1.13</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/propara">ProPara</pwcdataset>
    </paper>
    <paper id="14">
      <title>On Releasing Annotator-Level Labels and Information in Datasets</title>
      <author><first>Vinodkumar</first><last>Prabhakaran</last></author>
      <author><first>Aida</first><last>Mostafazadeh Davani</last></author>
      <author><first>Mark</first><last>Diaz</last></author>
      <pages>133–138</pages>
      <abstract>A common practice in building NLP datasets, especially using crowd-sourced annotations, involves obtaining multiple annotator judgements on the same data instances, which are then flattened to produce a single “ground truth” label or score, through majority voting, averaging, or adjudication. While these approaches may be appropriate in certain annotation tasks, such aggregations overlook the socially constructed nature of human perceptions that annotations for relatively more subjective tasks are meant to capture. In particular, systematic disagreements between annotators owing to their socio-cultural backgrounds and/or lived experiences are often obfuscated through such aggregations. In this paper, we empirically demonstrate that label aggregation may introduce representational biases of individual and group perspectives. Based on this finding, we propose a set of recommendations for increased utility and transparency of datasets for downstream use cases.</abstract>
      <url hash="97be03d3">2021.law-1.14</url>
      <bibkey>prabhakaran-etal-2021-releasing</bibkey>
      <doi>10.18653/v1/2021.law-1.14</doi>
    </paper>
    <paper id="15">
      <title>Increasing Sentence-Level Comprehension Through Text Classification of Epistemic Functions</title>
      <author><first>Maria</first><last>Berger</last></author>
      <author><first>Elizabeth</first><last>Goldstein</last></author>
      <pages>139–150</pages>
      <abstract>Word embeddings capture semantic meaning of individual words. How to bridge word-level linguistic knowledge with sentence-level language representation is an open problem. This paper examines whether sentence-level representations can be achieved by building a custom sentence database focusing on one aspect of a sentence’s meaning. Our three separate semantic aspects are whether the sentence: (1) communicates a causal relationship, (2) indicates that two things are correlated with each other, and (3) expresses information or knowledge. The three classifiers provide epistemic information about a sentence’s content.</abstract>
      <url hash="4f1b226f">2021.law-1.15</url>
      <bibkey>berger-goldstein-2021-increasing</bibkey>
      <doi>10.18653/v1/2021.law-1.15</doi>
    </paper>
    <paper id="16">
      <title>Towards a Methodology Supporting Semiautomatic Annotation of <fixed-case>H</fixed-case>ead<fixed-case>M</fixed-case>ovements in Video-recorded Conversations</title>
      <author><first>Patrizia</first><last>Paggio</last></author>
      <author><first>Costanza</first><last>Navarretta</last></author>
      <author><first>Bart</first><last>Jongejan</last></author>
      <author><first>Manex</first><last>Agirrezabal</last></author>
      <pages>151–159</pages>
      <abstract>We present a method to support the annotation of head movements in video-recorded conversations. Head movement segments from annotated multimodal data are used to train a model to detect head movements in unseen data. The resulting predicted movement sequences are uploaded to the ANVIL tool for post-annotation editing. The automatically identified head movements and the original annotations are compared to assess the overlap between the two. This analysis showed that movement onsets were more easily detected than offsets, and pointed at a number of patterns in the mismatches between original annotations and model predictions that could be dealt with in general terms in post-annotation guidelines.</abstract>
      <url hash="b9485c69">2021.law-1.16</url>
      <bibkey>paggio-etal-2021-towards</bibkey>
      <doi>10.18653/v1/2021.law-1.16</doi>
    </paper>
    <paper id="17">
      <title>Intensionalizing <fixed-case>A</fixed-case>bstract <fixed-case>M</fixed-case>eaning <fixed-case>R</fixed-case>epresentations: Non-Veridicality and Scope</title>
      <author><first>Gregor</first><last>Williamson</last></author>
      <author><first>Patrick</first><last>Elliott</last></author>
      <author><first>Yuxin</first><last>Ji</last></author>
      <pages>160–169</pages>
      <abstract>Abstract Meaning Representation (AMR) is a graphical meaning representation language designed to represent propositional information about argument structure. However, at present it is unable to satisfyingly represent non-veridical intensional contexts, often licensing inappropriate inferences. In this paper, we show how to resolve the problem of non-veridicality without appealing to layered graphs through a mapping from AMRs into Simply-Typed Lambda Calculus (STLC). At least for some cases, this requires the introduction of a new role :content which functions as an intensional operator. The translation proposed is inspired by the formal linguistics literature on the event semantics of attitude reports. Next, we address the interaction of quantifier scope and intensional operators in so-called de re/de dicto ambiguities. We adopt a scope node from the literature and provide an explicit multidimensional semantics utilizing Cooper storage which allows us to derive the de re and de dicto scope readings as well as intermediate scope readings which prove difficult for accounts without a scope node.</abstract>
      <url hash="7697c4cd">2021.law-1.17</url>
      <bibkey>williamson-etal-2021-intensionalizing</bibkey>
      <doi>10.18653/v1/2021.law-1.17</doi>
      <pwccode url="https://github.com/emorynlp/intensionalizing-amr" additional="false">emorynlp/intensionalizing-amr</pwccode>
    </paper>
    <paper id="18">
      <title><fixed-case>W</fixed-case>iki<fixed-case>GUM</fixed-case>: Exhaustive Entity Linking for Wikification in 12 Genres</title>
      <author><first>Jessica</first><last>Lin</last></author>
      <author><first>Amir</first><last>Zeldes</last></author>
      <pages>170–175</pages>
      <abstract>Previous work on Entity Linking has focused on resources targeting non-nested proper named entity mentions, often in data from Wikipedia, i.e. Wikification. In this paper, we present and evaluate WikiGUM, a fully wikified dataset, covering all mentions of named entities, including their non-named and pronominal mentions, as well as mentions nested within other mentions. The dataset covers a broad range of 12 written and spoken genres, most of which have not been included in Entity Linking efforts to date, leading to poor performance by a pretrained SOTA system in our evaluation. The availability of a variety of other annotations for the same data also enables further research on entities in context.</abstract>
      <url hash="a46c418a">2021.law-1.18</url>
      <bibkey>lin-zeldes-2021-wikigum</bibkey>
      <doi>10.18653/v1/2021.law-1.18</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/gum">GUM</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/ipm-nel">IPM NEL</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/nne">NNE</pwcdataset>
    </paper>
  </volume>
</collection>
