<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.vardial">
  <volume id="1" ingest-date="2025-01-25" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 12th Workshop on NLP for Similar Languages, Varieties and Dialects</booktitle>
      <editor><first>Yves</first><last>Scherrer</last></editor>
      <editor><first>Tommi</first><last>Jauhiainen</last></editor>
      <editor><first>Nikola</first><last>Ljubešić</last></editor>
      <editor><first>Preslav</first><last>Nakov</last></editor>
      <editor><first>Jorg</first><last>Tiedemann</last></editor>
      <editor><first>Marcos</first><last>Zampieri</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Abu Dhabi, UAE</address>
      <month>January</month>
      <year>2025</year>
      <url hash="becc71ff">2025.vardial-1</url>
      <venue>vardial</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="5fb4a2b5">2025.vardial-1.0</url>
      <bibkey>vardial-ws-2025-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Findings of the <fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial Evaluation Campaign 2025: The <fixed-case>N</fixed-case>or<fixed-case>SID</fixed-case> Shared Task on <fixed-case>N</fixed-case>orwegian Slot, Intent and Dialect Identification</title>
      <author><first>Yves</first><last>Scherrer</last></author>
      <author><first>Rob</first><last>van der Goot</last></author>
      <author><first>Petter</first><last>Mæhlum</last></author>
      <pages>1–8</pages>
      <abstract>The VarDial Evaluation Campaign 2025 was organized as part of the twelfth workshop on Natural Language Processing for Similar Languages, Varieties and Dialects (VarDial), colocated with COLING 2025. It consisted of one shared task with three subtasks: intent detection, slot filling and dialect identification for Norwegian dialects. This report presents the results of this shared task. Four participating teams have submitted systems with very high performance (&gt; 97% accuracy) for intent detection, whereas slot detection and dialect identification showed to be much more challenging, with respectively span-F1 scores up to 89%, and weighted dialect F1 scores of 84%.</abstract>
      <url hash="a5cd9dd0">2025.vardial-1.1</url>
      <bibkey>scherrer-etal-2025-findings</bibkey>
    </paper>
    <paper id="2">
      <title>Information Theory and Linguistic Variation: A Study of <fixed-case>B</fixed-case>razilian and <fixed-case>E</fixed-case>uropean <fixed-case>P</fixed-case>ortuguese</title>
      <author><first>Diego</first><last>Alves</last></author>
      <pages>9–19</pages>
      <abstract>We present a general analysis of the lexical and grammatical differences between Brazilian and European Portuguese by applying entropy measures, including Kullback-Leibler divergence and word order entropy, across various linguistic levels. Using a parallel corpus of BP and EP sentences translated from English, we quantified these differences and identified characteristic phenomena underlying the divergences between the two varieties. The highest divergence was observed at the lexical level due to word pairs unique to each variety but also related to grammatical distinctions. Furthermore, the analysis of parts-of-speech (POS), dependency relations, and POS tri-grams provided information concerning distinctive grammatical constructions. Finally, the word order entropy analysis revealed that while most of the syntactic features analysed showed similar patterns across BP and EP, specific word order preferences were still apparent.</abstract>
      <url hash="a7814fd7">2025.vardial-1.2</url>
      <bibkey>alves-2025-information</bibkey>
    </paper>
    <paper id="3">
      <title>Leveraging Open-Source Large Language Models for Native Language Identification</title>
      <author><first>Yee Man</first><last>Ng</last></author>
      <author><first>Ilia</first><last>Markov</last></author>
      <pages>20–28</pages>
      <abstract>Native Language Identification (NLI) – the task of identifying the native language (L1) of a person based on their writing in the second language (L2) – has applications in forensics, marketing, and second language acquisition. Historically, conventional machine learning approaches that heavily rely on extensive feature engineering have outperformed transformer-based language models on this task. Recently, closed-source generative large language models (LLMs), e.g., GPT-4, have demonstrated remarkable performance on NLI in a zero-shot setting, including promising results in open-set classification. However, closed-source LLMs have many disadvantages, such as high costs and undisclosed nature of training data. This study explores the potential of using open-source LLMs for NLI. Our results indicate that open-source LLMs do not reach the accuracy levels of closed-source LLMs when used out-of-the-box. However, when fine-tuned on labeled training data, open-source LLMs can achieve performance comparable to that of commercial LLMs.</abstract>
      <url hash="2ab42a41">2025.vardial-1.3</url>
      <bibkey>ng-markov-2025-leveraging</bibkey>
    </paper>
    <paper id="4">
      <title>Adapting Whisper for Regional Dialects: Enhancing Public Services for Vulnerable Populations in the <fixed-case>U</fixed-case>nited <fixed-case>K</fixed-case>ingdom</title>
      <author><first>Melissa</first><last>Torgbi</last></author>
      <author><first>Andrew</first><last>Clayman</last></author>
      <author><first>Jordan J.</first><last>Speight</last></author>
      <author><first>Harish</first><last>Tayyar Madabushi</last></author>
      <pages>29–38</pages>
      <abstract>We collect novel data in the public service domain to evaluate the capability of the state-of-the-art automatic speech recognition (ASR) models in capturing regional differences in accents in the United Kingdom (UK), specifically focusing on two accents from Scotland with distinct dialects. This study addresses real-world problems where biased ASR models can lead to miscommunication in public services, disadvantaging individuals with regional accents particularly those in vulnerable populations. We first examine the out-of-the-box performance of the Whisper large-v3 model on a baseline dataset and our data. We then explore the impact of fine-tuning Whisper on the performance in the two UK regions and investigate the effectiveness of existing model evaluation techniques for our real-world application through manual inspection of model errors. We observe that the Whisper model has a higher word error rate (WER) on our test datasets compared to the baseline data and fine-tuning on a given data improves performance on the test dataset with the same domain and accent. The fine-tuned models also appear to show improved performance when applied to the test data outside of the region it was trained on suggesting that fine-tuned models may be transferable within parts of the UK. Our manual analysis of model outputs reveals the benefits and drawbacks of using WER as an evaluation metric and fine-tuning to adapt to regional dialects.</abstract>
      <url hash="6b30223d">2025.vardial-1.4</url>
      <bibkey>torgbi-etal-2025-adapting</bibkey>
    </paper>
    <paper id="5">
      <title>Large Language Models as a Normalizer for Transliteration and Dialectal Translation</title>
      <author><first>Md Mahfuz Ibn</first><last>Alam</last></author>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <pages>39–67</pages>
      <abstract>NLP models trained on standardized language data often struggle with variations. We assess various Large Language Models (LLMs) for transliteration and dialectal normalization. Tuning open-source LLMs with as little as 10,000 parallel examples using LoRA can achieve results comparable to or better than closed-source LLMs. We perform dialectal normalization experiments for twelve South Asian languages and dialectal translation experiments for six language continua worldwide. The dialectal normalization task can also be a preliminary step for the downstream dialectal translation task. Among the six languages used in dialectal translation, our approach enables Italian and Swiss German to surpass the baseline model by 21.5 and 25.8 BLEU points, respectively.</abstract>
      <url hash="2d0f31cf">2025.vardial-1.5</url>
      <bibkey>alam-anastasopoulos-2025-large</bibkey>
    </paper>
    <paper id="6">
      <title>Testing the Boundaries of <fixed-case>LLM</fixed-case>s: Dialectal and Language-Variety Tasks</title>
      <author><first>Fahim</first><last>Faisal</last></author>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <pages>68–92</pages>
      <abstract>This study evaluates the performance of large language models (LLMs) on benchmark datasets designed for dialect-specific NLP tasks. Dialectal NLP is a low-resource field, yet it is crucial for evaluating the robustness of language models against linguistic diversity. This work is the first to systematically compare state-of-the-art instruction-tuned LLMs—both open-weight multilingual and closed-weight generative models—with encoder-based models that rely on supervised task-specific fine-tuning for dialectal tasks. We conduct extensive empirical analyses to provide insights into the current LLM landscape for dialect-focused tasks. Our findings indicate that certain tasks, such as dialect identification, are challenging for LLMs to replicate effectively due to the complexity of multi-class setups and the suitability of these tasks for supervised fine-tuning. Additionally, the structure of task labels—whether categorical or continuous scoring—significantly affects model performance. While LLMs excel in tasks like machine reading comprehension, their instruction-following ability declines in simpler tasks like POS tagging when task instructions are inherently complex. Overall, subtle variations in prompt design can greatly impact performance, underscoring the need for careful prompt engineering in dialectal evaluations.</abstract>
      <url hash="8a5f9885">2025.vardial-1.6</url>
      <bibkey>faisal-anastasopoulos-2025-testing</bibkey>
    </paper>
    <paper id="7">
      <title>Text Generation Models for <fixed-case>L</fixed-case>uxembourgish with Limited Data: A Balanced Multilingual Strategy</title>
      <author><first>Alistair</first><last>Plum</last></author>
      <author><first>Tharindu</first><last>Ranasinghe</last></author>
      <author><first>Christoph</first><last>Purschke</last></author>
      <pages>93–104</pages>
      <abstract>This paper addresses the challenges in developing language models for less-represented languages, with a focus on Luxembourgish. Despite its active development, Luxembourgish faces a digital data scarcity, exacerbated by Luxembourg’s multilingual context. We propose a novel text generation model based on the T5 architecture, combining limited Luxembourgish data with equal amounts, in terms of size and type, of German and French data. We hypothesise that a model trained on Luxembourgish, German, and French will improve the model’s cross-lingual transfer learning capabilities and outperform monolingual and large multilingual models. To verify this, the study at hand explores whether multilingual or monolingual training is more beneficial for Luxembourgish language generation. For the evaluation, we introduce LuxGen, a text generation benchmark that is the first of its kind for Luxembourgish.</abstract>
      <url hash="46638581">2025.vardial-1.7</url>
      <bibkey>plum-etal-2025-text</bibkey>
    </paper>
    <paper id="8">
      <title>Retrieval of Parallelizable Texts Across <fixed-case>C</fixed-case>hurch <fixed-case>S</fixed-case>lavic Variants</title>
      <author><first>Piroska</first><last>Lendvai</last></author>
      <author><first>Uwe</first><last>Reichel</last></author>
      <author><first>Anna</first><last>Jouravel</last></author>
      <author><first>Achim</first><last>Rabus</last></author>
      <author><first>Elena</first><last>Renje</last></author>
      <pages>105–114</pages>
      <abstract>The goal of our study is to identify parallelizable texts for Church Slavic, across chronological and regional variants. Next to using a benchmark text, we utilize a recently digitized, large text collection and compile new resources for the retrieval of similar texts: a ground truth dataset holding a small amount of manually aligned sentences in Old Church Slavic and in Old East Slavic, and a large unaligned dataset that has a subset of ground truth (GT) quality texts but contains noise from handwritten text recognition (HTR) for the majority of the collection. We discuss preprocessing challenges in the data and the impact of sentence segmentation on retrieval performance. We evaluate sentence snippets mapped across these two diachronic variants of Church Slavic, expressed by mean reciprocal rank, using embedding representations from large language models (LLMs) as well as classical string similarity based approaches combined with k-nearest neighbor (kNN) search. Experimental results indicate that in the current setup (short text snippets, off-the-shelf multilingual embeddings), classical string similarity based retrieval can still outperform embedding based retrieval.</abstract>
      <url hash="011bb656">2025.vardial-1.8</url>
      <bibkey>lendvai-etal-2025-retrieval</bibkey>
    </paper>
    <paper id="9">
      <title>Neural Text Normalization for <fixed-case>L</fixed-case>uxembourgish Using Real-Life Variation Data</title>
      <author><first>Anne-Marie</first><last>Lutgen</last></author>
      <author><first>Alistair</first><last>Plum</last></author>
      <author><first>Christoph</first><last>Purschke</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <pages>115–127</pages>
      <abstract>Orthographic variation is very common in Luxembourgish texts due to the absence of a fully-fledged standard variety. Additionally, developing NLP tools for Luxembourgish is a difficult task given the lack of annotated and parallel data, which is exacerbated by ongoing standardization. In this paper, we propose the first sequence-to-sequence normalization models using the ByT5 and mT5 architectures with training data obtained from word-level real-life variation data. We perform a fine-grained, linguistically-motivated evaluation to test byte-based, word-based and pipeline-based models for their strengths and weaknesses in text normalization. We show that our sequence model using real-life variation data is an effective approach for tailor-made normalization in Luxembourgish.</abstract>
      <url hash="c87937f0">2025.vardial-1.9</url>
      <bibkey>lutgen-etal-2025-neural</bibkey>
    </paper>
    <paper id="10">
      <title>Improving Dialectal Slot and Intent Detection with Auxiliary Tasks: A Multi-Dialectal <fixed-case>B</fixed-case>avarian Case Study</title>
      <author><first>Xaver Maria</first><last>Krückl</last></author>
      <author><first>Verena</first><last>Blaschke</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <pages>128–146</pages>
      <abstract>Reliable slot and intent detection (SID) is crucial in natural language understanding for applications like digital assistants. Encoder-only transformer models fine-tuned on high-resource languages generally perform well on SID. However, they struggle with dialectal data, where no standardized form exists and training data is scarce and costly to produce. We explore zero-shot transfer learning for SID, focusing on multiple Bavarian dialects, for which we release a new dataset for the Munich dialect. We evaluate models trained on auxiliary tasks in Bavarian, and compare joint multi-task learning with intermediate-task training. We also compare three types of auxiliary tasks: token-level syntactic tasks, named entity recognition (NER), and language modelling. We find that the included auxiliary tasks have a more positive effect on slot filling than intent classification (with NER having the most positive effect), and that intermediate-task training yields more consistent performance gains. Our best-performing approach improves intent classification performance on Bavarian dialects by 5.1 and slot filling F1 by 8.4 percentage points.</abstract>
      <url hash="7c592675">2025.vardial-1.10</url>
      <bibkey>kruckl-etal-2025-improving</bibkey>
    </paper>
    <paper id="11">
      <title>Regional Distribution of the /el/-/æl/ Merger in <fixed-case>A</fixed-case>ustralian <fixed-case>E</fixed-case>nglish</title>
      <author><first>Steven</first><last>Coats</last></author>
      <author><first>Chloé</first><last>Diskin-Holdaway</last></author>
      <author><first>Debbie</first><last>Loakes</last></author>
      <pages>147–156</pages>
      <abstract>Prelateral merger of /e/ and /æ/ is a salient acoustic feature of speech from Melbourne and the state of Victoria in Australia, but little is known about its presence in other parts of the country. In this study, automated methods of data collection, forced alignment, and formant extraction are used to analyze the regional distribution of the vowel merger within all of Australia, in 4.3 million vowel tokens from naturalistic speech in 252 locations. The extent of the merger is quantified using the difference in Bhattacharyya’s distance scores based on phonetic context, and the regional distribution is assessed using spatial autocorrelation. The principal findings are that the merger is most prominent in Victoria and least prominent in Sydney and New South Wales. We also find preliminary indications that it may be present in other parts of the country.</abstract>
      <url hash="7a425888">2025.vardial-1.11</url>
      <bibkey>coats-etal-2025-regional</bibkey>
    </paper>
    <paper id="12">
      <title>Learning Cross-Dialectal Morphophonology with Syllable Structure Constraints</title>
      <author><first>Salam</first><last>Khalifa</last></author>
      <author><first>Abdelrahim</first><last>Qaddoumi</last></author>
      <author><first>Jordan</first><last>Kodner</last></author>
      <author><first>Owen</first><last>Rambow</last></author>
      <pages>157–167</pages>
      <abstract>We investigate learning surface forms from underlying morphological forms for low-resource language varieties. We concentrate on learning explicit rules with the aid of learned syllable structure constraints, which outperforms neural methods on this small data task and provides interpretable output. Evaluating across one relatively high-resource and two related low-resource Arabic dialects, we find that a model trained only on the high-resource dialect achieves decent performance on the low-resource dialects, useful when no low-resource training data is available. The best results are obtained when our system is trained only on the low-resource dialect data without augmentation from the related higher-resource dialect. We discuss the impact of syllable structure constraints and the strengths and weaknesses of data augmentation and transfer learning from a related dialect.</abstract>
      <url hash="94e6b101">2025.vardial-1.12</url>
      <bibkey>khalifa-etal-2025-learning</bibkey>
    </paper>
    <paper id="13">
      <title>Common Ground, Diverse Roots: The Difficulty of Classifying Common Examples in <fixed-case>S</fixed-case>panish Varieties</title>
      <author><first>Javier A.</first><last>Lopetegui</last></author>
      <author><first>Arij</first><last>Riabi</last></author>
      <author><first>Djamé</first><last>Seddah</last></author>
      <pages>168–181</pages>
      <abstract>Variations in languages across geographic regions or cultures are crucial to address to avoid biases in NLP systems designed for culturally sensitive tasks, such as hate speech detection or dialog with conversational agents. In languages such as Spanish, where varieties can significantly overlap, many examples can be valid across them, which we refer to as common examples. Ignoring these examples may cause misclassifications, reducing model accuracy and fairness. Therefore, accounting for these common examples is essential to improve the robustness and representativeness of NLP systems trained on such data. In this work, we address this problem in the context of Spanish varieties. We use training dynamics to automatically detect common examples or errors in existing Spanish datasets. We demonstrate the efficacy of using predicted label confidence for our Datamaps (CITATION) implementation for the identification of hard-to-classify examples, especially common examples, enhancing model performance in variety identification tasks. Additionally, we introduce a Cuban Spanish Variety Identification dataset with common examples annotations developed to facilitate more accurate detection of Cuban and Caribbean Spanish varieties. To our knowledge, this is the first dataset focused on identifying the Cuban, or any other Caribbean, Spanish variety.</abstract>
      <url hash="80409651">2025.vardial-1.13</url>
      <bibkey>lopetegui-etal-2025-common</bibkey>
    </paper>
    <paper id="14">
      <title>Add Noise, Tasks, or Layers? <fixed-case>M</fixed-case>ai<fixed-case>NLP</fixed-case> at the <fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial 2025 Shared Task on <fixed-case>N</fixed-case>orwegian Dialectal Slot and Intent Detection</title>
      <author><first>Verena</first><last>Blaschke</last></author>
      <author><first>Felicia</first><last>Körner</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <pages>182–199</pages>
      <abstract>Slot and intent detection (SID) is a classic natural language understanding task. Despite this, research has only more recently begun focusing on SID for dialectal and colloquial varieties. Many approaches for low-resource scenarios have not yet been applied to dialectal SID data, or compared to each other on the same datasets. We participate in the VarDial 2025 shared task on slot and intent detection in Norwegian varieties, and compare multiple set-ups: varying the training data (English, Norwegian, or dialectal Norwegian), injecting character-level noise, training on auxiliary tasks, and applying Layer Swapping, a technique in which layers of models fine-tuned on different datasets are assembled into a model. We find noise injection to be beneficial while the effects of auxiliary tasks are mixed. Though some experimentation was required to successfully assemble a model from layers, it worked surprisingly well; a combination of models trained on English and small amounts of dialectal data produced the most robust slot predictions. Our best models achieve 97.6% intent accuracy and 85.6% slot F1 in the shared task.</abstract>
      <url hash="7e206698">2025.vardial-1.14</url>
      <bibkey>blaschke-etal-2025-add</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>LTG</fixed-case> at <fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial 2025 <fixed-case>N</fixed-case>or<fixed-case>SID</fixed-case>: More and Better Training Data for Slot and Intent Detection</title>
      <author><first>Marthe</first><last>Midtgaard</last></author>
      <author><first>Petter</first><last>Mæhlum</last></author>
      <author><first>Yves</first><last>Scherrer</last></author>
      <pages>200–208</pages>
      <abstract>This paper describes the LTG submission to the VarDial 2025 shared task, where we participate in the Norwegian slot and intent detection subtasks. The shared task focuses on Norwegian dialects, which present challenges due to their low-resource nature and variation. We test a variety of neural models and training data configurations, with the focus on improving and extending the available Norwegian training data. This includes automatically re-aligning slot spans in Norwegian Bokmål, as well as re-translating the original English training data into both Bokmål and Nynorsk. % to address dialectal diversity. We also re-annotate an external Norwegian dataset to augment the training data. Our best models achieve first place in both subtasks, achieving an span F1 score of 0.893 for slot filling and an accuracy of 0.980 for intent detection. Our results indicate that while translation quality is less critical, improving the slot labels has a notable impact on slot performance. Moreover, adding more standard Norwegian data improves performance, but incorporating even small amounts of dialectal data leads to greater gains.</abstract>
      <url hash="4f8f7ade">2025.vardial-1.15</url>
      <bibkey>midtgaard-etal-2025-ltg</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>H</fixed-case>i<fixed-case>TZ</fixed-case> at <fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial 2025 <fixed-case>N</fixed-case>or<fixed-case>SID</fixed-case>: Overcoming Data Scarcity with Language Transfer and Automatic Data Annotation</title>
      <author><first>Jaione</first><last>Bengoetxea</last></author>
      <author><first>Mikel</first><last>Zubillaga</last></author>
      <author><first>Ekhi</first><last>Azurmendi</last></author>
      <author><first>Maite</first><last>Heredia</last></author>
      <author><first>Julen</first><last>Etxaniz</last></author>
      <author><first>Markel</first><last>Ferro</last></author>
      <author><first>Jeremy</first><last>Barnes</last></author>
      <pages>209–219</pages>
      <abstract>In this paper we present our submission for the NorSID Shared Task as part of the 2025 VarDial Workshop, consisting of three tasks: Intent Detection, Slot Filling and Dialect Identification, evaluated using data in different dialects of the Norwegian language. For Intent Detection and Slot Filling, we have fine-tuned a multitask model in a cross-lingual setting, to leverage the xSID dataset available in 17 languages. In the case of Dialect Identification, our final submission consists of a model fine-tuned on the provided development set, which has obtained the highest scores within our experiments. Our final results on the test set show that our models do not drop in performance compared to the development set, likely due to the domain-specificity of the dataset and the similar distribution of both subsets. Finally, we also report an in-depth analysis of the provided datasets and their artifacts, as well as other sets of experiments that have been carried out but did not yield the best results. Additionally, we present an analysis on the reasons why some methods have been more successful than others; mainly the impact of the combination of languages and domain-specificity of the training data on the results.</abstract>
      <url hash="4e8026b1">2025.vardial-1.16</url>
      <bibkey>bengoetxea-etal-2025-hitz</bibkey>
    </paper>
    <paper id="17">
      <title><fixed-case>CUFE</fixed-case>@<fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial 2025 <fixed-case>N</fixed-case>or<fixed-case>SID</fixed-case>: Multilingual <fixed-case>BERT</fixed-case> for <fixed-case>N</fixed-case>orwegian Dialect Identification and Intent Detection</title>
      <author><first>Michael</first><last>Ibrahim</last></author>
      <pages>220–223</pages>
      <abstract>Dialect identification is crucial in enhancing various tasks, including sentiment analysis, as a speaker’s geographical origin can significantly affect their perspective on a topic, also, intent detection has gained significant traction in natural language processing due to its applications in various domains, including virtual assistants, customer service automation, and information retrieval systems. This work describes a system developed for VarDial 2025: Norwegian slot and intent detection and dialect identification shared task (Scherrer et al., 2025), a challenge designed to address the dialect recognition and intent detection problems for a low-resource language like Norwegian. More specifically, this work investigates the performance of different BERT models in solving this problem. Finally, the output of the multilingual version of the BERT model was submitted to this shared task, the developed system achieved a weighted F1 score of 79.64 for dialect identification and an accuracy of 94.38 for intent detection.</abstract>
      <url hash="77740482">2025.vardial-1.17</url>
      <bibkey>ibrahim-2025-cufe</bibkey>
    </paper>
  </volume>
</collection>
