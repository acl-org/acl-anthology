<?xml version='1.0' encoding='UTF-8'?>
<collection id="2020.coling">
  <volume id="main" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the 28th International Conference on Computational Linguistics</booktitle>
      <editor><first>Donia</first><last>Scott</last></editor>
      <editor><first>Nuria</first><last>Bel</last></editor>
      <editor><first>Chengqing</first><last>Zong</last></editor>
      <publisher>International Committee on Computational Linguistics</publisher>
      <address>Barcelona, Spain (Online)</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="e4b60169">2020.coling-main.0</url>
    </frontmatter>
    <paper id="1">
      <title>Exploring Controllable Text Generation Techniques</title>
      <author><first>Shrimai</first><last>Prabhumoye</last></author>
      <author><first>Alan W</first><last>Black</last></author>
      <author><first>Ruslan</first><last>Salakhutdinov</last></author>
      <pages>1–14</pages>
      <abstract>Neural controllable text generation is an important area gaining attention due to its plethora of applications. Although there is a large body of prior work in controllable text generation, there is no unifying theme. In this work, we provide a new schema of the pipeline of the generation process by classifying it into five modules. The control of attributes in the generation process requires modification of these modules. We present an overview of different techniques used to perform the modulation of these modules. We also provide an analysis on the advantages and disadvantages of these techniques. We further pave ways to develop new architectures based on the combination of the modules described in this paper.</abstract>
      <url hash="ce36a613">2020.coling-main.1</url>
    </paper>
    <paper id="2">
      <title>Infusing Sequential Information into Conditional Masked Translation Model with Self-Review Mechanism</title>
      <author><first>Pan</first><last>Xie</last></author>
      <author><first>Zhi</first><last>Cui</last></author>
      <author><first>Xiuying</first><last>Chen</last></author>
      <author><first>XiaoHui</first><last>Hu</last></author>
      <author><first>Jianwei</first><last>Cui</last></author>
      <author><first>Bin</first><last>Wang</last></author>
      <pages>15–25</pages>
      <abstract>Non-autoregressive models generate target words in a parallel way, which achieve a faster decoding speed but at the sacrifice of translation accuracy. To remedy a flawed translation by non-autoregressive models, a promising approach is to train a conditional masked translation model (CMTM), and refine the generated results within several iterations. Unfortunately, such approach hardly considers the sequential dependency among target words, which inevitably results in a translation degradation. Hence, instead of solely training a Transformer-based CMTM, we propose a Self-Review Mechanism to infuse sequential information into it. Concretely, we insert a left-to-right mask to the same decoder of CMTM, and then induce it to autoregressively review whether each generated word from CMTM is supposed to be replaced or kept. The experimental results (WMT14 En ↔ De and WMT16 En ↔ Ro) demonstrate that our model uses dramatically less training computations than the typical CMTM, as well as outperforms several state-of-the-art non-autoregressive models by over 1 BLEU. Through knowledge distillation, our model even surpasses a typical left-to-right Transformer model, while significantly speeding up decoding.</abstract>
      <url hash="57aaf634">2020.coling-main.2</url>
    </paper>
    <paper id="3">
      <title>Building Hierarchically Disentangled Language Models for Text Generation with Named Entities</title>
      <author><first>Yash</first><last>Agarwal</last></author>
      <author><first>Devansh</first><last>Batra</last></author>
      <author><first>Ganesh</first><last>Bagler</last></author>
      <pages>26–38</pages>
      <abstract>Named entities pose a unique challenge to traditional methods of language modeling. While several domains are characterised with a high proportion of named entities, the occurrence of specific entities varies widely. Cooking recipes, for example, contain a lot of named entities — viz. ingredients, cooking techniques (also called processes), and utensils. However, some ingredients occur frequently within the instructions while most occur rarely. In this paper, we build upon the previous work done on language models developed for text with named entities by introducing a Hierarchically Disentangled Model. Training is divided into multiple branches with each branch producing a model with overlapping subsets of vocabulary. We found the existing datasets insufficient to accurately judge the performance of the model. Hence, we have curated 158,473 cooking recipes from several publicly available online sources. To reliably derive the entities within this corpus, we employ a combination of Named Entity Recognition (NER) as well as an unsupervised method of interpretation using dependency parsing and POS tagging, followed by a further cleaning of the dataset. This unsupervised interpretation models instructions as action graphs and is specific to the corpus of cooking recipes, unlike NER which is a general method applicable to all corpora. To delve into the utility of our language model, we apply it to tasks such as graph-to-text generation and ingredients-to-recipe generation, comparing it to previous state-of-the-art baselines. We make our dataset (including annotations and processed action graphs) available for use, considering their potential use cases for language modeling and text generation research.</abstract>
      <url hash="d5355277">2020.coling-main.3</url>
    </paper>
    <paper id="4">
      <title><fixed-case>C</fixed-case>har<fixed-case>BERT</fixed-case>: Character-aware Pre-trained Language Model</title>
      <author><first>Wentao</first><last>Ma</last></author>
      <author><first>Yiming</first><last>Cui</last></author>
      <author><first>Chenglei</first><last>Si</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <author><first>Shijin</first><last>Wang</last></author>
      <author><first>Guoping</first><last>Hu</last></author>
      <pages>39–50</pages>
      <abstract>Most pre-trained language models (PLMs) construct word representations at subword level with Byte-Pair Encoding (BPE) or its variations, by which OOV (out-of-vocab) words are almost avoidable. However, those methods split a word into subword units and make the representation incomplete and fragile.In this paper, we propose a character-aware pre-trained language model named CharBERT improving on the previous methods (such as BERT, RoBERTa) to tackle these problems. We first construct the contextual word embedding for each token from the sequential character representations, then fuse the representations of characters and the subword representations by a novel heterogeneous interaction module. We also propose a new pre-training task named NLM (Noisy LM) for unsupervised character representation learning. We evaluate our method on question answering, sequence labeling, and text classification tasks, both on the original datasets and adversarial misspelling test sets. The experimental results show that our method can significantly improve the performance and robustness of PLMs simultaneously.</abstract>
      <url hash="9387e4ae">2020.coling-main.4</url>
    </paper>
    <paper id="5">
      <title>A Graph Representation of Semi-structured Data for Web Question Answering</title>
      <author><first>Xingyao</first><last>Zhang</last></author>
      <author><first>Linjun</first><last>Shou</last></author>
      <author><first>Jian</first><last>Pei</last></author>
      <author><first>Ming</first><last>Gong</last></author>
      <author><first>Lijie</first><last>Wen</last></author>
      <author><first>Daxin</first><last>Jiang</last></author>
      <pages>51–61</pages>
      <abstract>The abundant semi-structured data on the Web, such as HTML-based tables and lists, provide commercial search engines a rich information source for question answering (QA). Different from plain text passages in Web documents, Web tables and lists have inherent structures, which carry semantic correlations among various elements in tables and lists. Many existing studies treat tables and lists as flat documents with pieces of text and do not make good use of semantic information hidden in structures. In this paper, we propose a novel graph representation of Web tables and lists based on a systematic categorization of the components in semi-structured data as well as their relations. We also develop pre-training and reasoning techniques on the graph model for the QA task. Extensive experiments on several real datasets collected from a commercial engine verify the effectiveness of our approach. Our method improves F1 score by 3.90 points over the state-of-the-art baselines.</abstract>
      <url hash="3b4d1f94">2020.coling-main.5</url>
    </paper>
    <paper id="6">
      <title>Catching Attention with Automatic Pull Quote Selection</title>
      <author><first>Tanner</first><last>Bohn</last></author>
      <author><first>Charles</first><last>Ling</last></author>
      <pages>62–76</pages>
      <abstract>To advance understanding on how to engage readers, we advocate the novel task of automatic pull quote selection. Pull quotes are a component of articles specifically designed to catch the attention of readers with spans of text selected from the article and given more salient presentation. This task differs from related tasks such as summarization and clickbait identification by several aspects. We establish a spectrum of baseline approaches to the task, ranging from handcrafted features to a neural mixture-of-experts to cross-task models. By examining the contributions of individual features and embedding dimensions from these models, we uncover unexpected properties of pull quotes to help answer the important question of what engages readers. Human evaluation also supports the uniqueness of this task and the suitability of our selection models. The benefits of exploring this problem further are clear: pull quotes increase enjoyment and readability, shape reader perceptions, and facilitate learning. Code to reproduce this work is available at https://github.com/tannerbohn/AutomaticPullQuoteSelection.</abstract>
      <url hash="3d59e813">2020.coling-main.6</url>
    </paper>
    <paper id="7">
      <title><fixed-case>MZET</fixed-case>: Memory Augmented Zero-Shot Fine-grained Named Entity Typing</title>
      <author><first>Tao</first><last>Zhang</last></author>
      <author><first>Congying</first><last>Xia</last></author>
      <author><first>Chun-Ta</first><last>Lu</last></author>
      <author><first>Philip</first><last>Yu</last></author>
      <pages>77–87</pages>
      <abstract>Named entity typing (NET) is a classification task of assigning an entity mention in the context with given semantic types. However, with the growing size and granularity of the entity types, few previous researches concern with newly emerged entity types. In this paper, we propose MZET, a novel memory augmented FNET (Fine-grained NET) model, to tackle the unseen types in a zero-shot manner. MZET incorporates character-level, word-level, and contextural-level information to learn the entity mention representation. Besides, MZET considers the semantic meaning and the hierarchical structure into the entity type representation. Finally, through the memory component which models the relationship between the entity mention and the entity type, MZET transfers the knowledge from seen entity types to the zero-shot ones. Extensive experiments on three public datasets show the superior performance obtained by MZET, which surpasses the state-of-the-art FNET neural network models with up to 8% gain in Micro-F1 and Macro-F1 score.</abstract>
      <url hash="19703ff3">2020.coling-main.7</url>
    </paper>
    <paper id="8">
      <title>Span-based Joint Entity and Relation Extraction with Attention-based Span-specific and Contextual Semantic Representations</title>
      <author><first>Bin</first><last>Ji</last></author>
      <author><first>Jie</first><last>Yu</last></author>
      <author><first>Shasha</first><last>Li</last></author>
      <author><first>Jun</first><last>Ma</last></author>
      <author><first>Qingbo</first><last>Wu</last></author>
      <author><first>Yusong</first><last>Tan</last></author>
      <author><first>Huijun</first><last>Liu</last></author>
      <pages>88–99</pages>
      <abstract>Span-based joint extraction models have shown their efficiency on entity recognition and relation extraction. These models regard text spans as candidate entities and span tuples as candidate relation tuples. Span semantic representations are shared in both entity recognition and relation extraction, while existing models cannot well capture semantics of these candidate entities and relations. To address these problems, we introduce a span-based joint extraction framework with attention-based semantic representations. Specially, attentions are utilized to calculate semantic representations, including span-specific and contextual ones. We further investigate effects of four attention variants in generating contextual semantic representations. Experiments show that our model outperforms previous systems and achieves state-of-the-art results on ACE2005, CoNLL2004 and ADE.</abstract>
      <url hash="ed928dd4">2020.coling-main.8</url>
    </paper>
    <paper id="9">
      <title>Hierarchical <fixed-case>C</fixed-case>hinese Legal event extraction via Pedal Attention Mechanism</title>
      <author><first>Shirong</first><last>Shen</last></author>
      <author><first>Guilin</first><last>Qi</last></author>
      <author><first>Zhen</first><last>Li</last></author>
      <author><first>Sheng</first><last>Bi</last></author>
      <author><first>Lusheng</first><last>Wang</last></author>
      <pages>100–113</pages>
      <abstract>Event extraction plays an important role in legal applications, including case push and auxiliary judgment. However, traditional event structure cannot express the connections between arguments, which are extremely important in legal events. Therefore, this paper defines a dynamic event structure for Chinese legal events. To distinguish between similar events, we design hierarchical event features for event detection. Moreover, to address the problem of long-distance semantic dependence and anaphora resolution in argument classification, we propose a novel pedal attention mechanism to extract the semantic relation between two words through their dependent adjacent words. We label a Chinese legal event dataset and evaluate our model on it. Experimental results demonstrate that our model can surpass other state-of-the-art models.</abstract>
      <url hash="d459a535">2020.coling-main.9</url>
    </paper>
    <paper id="10">
      <title>Is Killed More Significant than Fled? A Contextual Model for Salient Event Detection</title>
      <author><first>Disha</first><last>Jindal</last></author>
      <author><first>Daniel</first><last>Deutsch</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>114–124</pages>
      <abstract>Identifying the key events in a document is critical to holistically understanding its important information. Although measuring the salience of events is highly contextual, most previous work has used a limited representation of events that omits essential information. In this work, we propose a highly contextual model of event salience that uses a rich representation of events, incorporates document-level information and allows for interactions between latent event encodings. Our experimental results on an event salience dataset demonstrate that our model improves over previous work by an absolute 2-4% on standard metrics, establishing a new state-of-the-art performance for the task. We also propose a new evaluation metric that addresses flaws in previous evaluation methodologies. Finally, we discuss the importance of salient event detection for the downstream task of summarization.</abstract>
      <url hash="3840d62f">2020.coling-main.10</url>
    </paper>
    <paper id="11">
      <title>Appraisal Theories for Emotion Classification in Text</title>
      <author><first>Jan</first><last>Hofmann</last></author>
      <author><first>Enrica</first><last>Troiano</last></author>
      <author><first>Kai</first><last>Sassenberg</last></author>
      <author><first>Roman</first><last>Klinger</last></author>
      <pages>125–138</pages>
      <abstract>Automatic emotion categorization has been predominantly formulated as text classification in which textual units are assigned to an emotion from a predefined inventory, for instance following the fundamental emotion classes proposed by Paul Ekman (fear, joy, anger, disgust, sadness, surprise) or Robert Plutchik (adding trust, anticipation). This approach ignores existing psychological theories to some degree, which provide explanations regarding the perception of events. For instance, the description that somebody discovers a snake is associated with fear, based on the appraisal as being an unpleasant and non-controllable situation. This emotion reconstruction is even possible without having access to explicit reports of a subjective feeling (for instance expressing this with the words “I am afraid.”). Automatic classification approaches therefore need to learn properties of events as latent variables (for instance that the uncertainty and the mental or physical effort associated with the encounter of a snake leads to fear). With this paper, we propose to make such interpretations of events explicit, following theories of cognitive appraisal of events, and show their potential for emotion classification when being encoded in classification models. Our results show that high quality appraisal dimension assignments in event descriptions lead to an improvement in the classification of discrete emotion categories. We make our corpus of appraisal-annotated emotion-associated event descriptions publicly available.</abstract>
      <url hash="29ca5695">2020.coling-main.11</url>
    </paper>
    <paper id="12">
      <title>A Symmetric Local Search Network for Emotion-Cause Pair Extraction</title>
      <author><first>Zifeng</first><last>Cheng</last></author>
      <author><first>Zhiwei</first><last>Jiang</last></author>
      <author><first>Yafeng</first><last>Yin</last></author>
      <author><first>Hua</first><last>Yu</last></author>
      <author><first>Qing</first><last>Gu</last></author>
      <pages>139–149</pages>
      <abstract>Emotion-cause pair extraction (ECPE) is a new task which aims at extracting the potential clause pairs of emotions and corresponding causes in a document. To tackle this task, a two-step method was proposed by previous study which first extracted emotion clauses and cause clauses individually, then paired the emotion and cause clauses, and filtered out the pairs without causality. Different from this method that separated the detection and the matching of emotion and cause into two steps, we propose a Symmetric Local Search Network (SLSN) model to perform the detection and matching simultaneously by local search. SLSN consists of two symmetric subnetworks, namely the emotion subnetwork and the cause subnetwork. Each subnetwork is composed of a clause representation learner and a local pair searcher. The local pair searcher is a specially-designed cross-subnetwork component which can extract the local emotion-cause pairs. Experimental results on the ECPE corpus demonstrate the superiority of our SLSN over existing state-of-the-art methods.</abstract>
      <url hash="0d0d73ed">2020.coling-main.12</url>
    </paper>
    <paper id="13">
      <title>Jointly Learning Aspect-Focused and Inter-Aspect Relations with Graph Convolutional Networks for Aspect Sentiment Analysis</title>
      <author><first>Bin</first><last>Liang</last></author>
      <author><first>Rongdi</first><last>Yin</last></author>
      <author><first>Lin</first><last>Gui</last></author>
      <author><first>Jiachen</first><last>Du</last></author>
      <author><first>Ruifeng</first><last>Xu</last></author>
      <pages>150–161</pages>
      <abstract>In this paper, we explore a novel solution of constructing a heterogeneous graph for each instance by leveraging aspect-focused and inter-aspect contextual dependencies for the specific aspect and propose an Interactive Graph Convolutional Networks (InterGCN) model for aspect sentiment analysis. Specifically, an ordinary dependency graph is first constructed for each sentence over the dependency tree. Then we refine the graph by considering the syntactical dependencies between contextual words and aspect-specific words to derive the aspect-focused graph. Subsequently, the aspect-focused graph and the corresponding embedding matrix are fed into the aspect-focused GCN to capture the key aspect and contextual words. Besides, to interactively extract the inter-aspect relations for the specific aspect, an inter-aspect GCN is adopted to model the representations learned by aspect-focused GCN based on the inter-aspect graph which is constructed by the relative dependencies between the aspect words and other aspects. Hence, the model can be aware of the significant contextual and aspect words when interactively learning the sentiment features for a specific aspect. Experimental results on four benchmark datasets illustrate that our proposed model outperforms state-of-the-art methods and substantially boosts the performance in comparison with BERT.</abstract>
      <url hash="bd762d8d">2020.coling-main.13</url>
    </paper>
    <paper id="14">
      <title><fixed-case>METN</fixed-case>et: A Mutual Enhanced Transformation Network for Aspect-based Sentiment Analysis</title>
      <author><first>Bin</first><last>Jiang</last></author>
      <author><first>Jing</first><last>Hou</last></author>
      <author><first>Wanyue</first><last>Zhou</last></author>
      <author><first>Chao</first><last>Yang</last></author>
      <author><first>Shihan</first><last>Wang</last></author>
      <author><first>Liang</first><last>Pang</last></author>
      <pages>162–172</pages>
      <abstract>Aspect-based sentiment analysis (ABSA) aims to determine the sentiment polarity of each specific aspect in a given sentence. Existing researches have realized the importance of the aspect for the ABSA task and have derived many interactive learning methods that model context based on specific aspect. However, current interaction mechanisms are ill-equipped to learn complex sentences with multiple aspects, and these methods underestimate the representation learning of the aspect. In order to solve the two problems, we propose a mutual enhanced transformation network (METNet) for the ABSA task. First, the aspect enhancement module in METNet improves the representation learning of the aspect with contextual semantic features, which gives the aspect more abundant information. Second, METNet designs and implements a hierarchical structure, which enhances the representations of aspect and context iteratively. Experimental results on SemEval 2014 Datasets demonstrate the effectiveness of METNet, and we further prove that METNet is outstanding in multi-aspect scenarios.</abstract>
      <url hash="40a1f556">2020.coling-main.14</url>
    </paper>
    <paper id="15">
      <title>Making the Best Use of Review Summary for Sentiment Analysis</title>
      <author><first>Sen</first><last>Yang</last></author>
      <author><first>Leyang</first><last>Cui</last></author>
      <author><first>Jun</first><last>Xie</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <pages>173–184</pages>
      <abstract>Sentiment analysis provides a useful overview of customer review contents. Many review websites allow a user to enter a summary in addition to a full review. Intuitively, summary information may give additional benefit for review sentiment analysis. In this paper, we conduct a study to exploit methods for better use of summary information. We start by finding out that the sentimental signal distribution of a review and that of its corresponding summary are in fact complementary to each other. We thus explore various architectures to better guide the interactions between the two and propose a hierarchically-refined review-centric attention model. Empirical results show that our review-centric model can make better use of user-written summaries for review sentiment analysis, and is also more effective compared to existing methods when the user summary is replaced with summary generated by an automatic summarization system.</abstract>
      <url hash="ceae2b07">2020.coling-main.15</url>
    </paper>
    <paper id="16">
      <title>From Sentiment Annotations to Sentiment Prediction through Discourse Augmentation</title>
      <author><first>Patrick</first><last>Huber</last></author>
      <author><first>Giuseppe</first><last>Carenini</last></author>
      <pages>185–197</pages>
      <abstract>Sentiment analysis, especially for long documents, plausibly requires methods capturing complex linguistics structures. To accommodate this, we propose a novel framework to exploit task-related discourse for the task of sentiment analysis. More specifically, we are combining the large-scale, sentiment-dependent MEGA-DT treebank with a novel neural architecture for sentiment prediction, based on a hybrid TreeLSTM hierarchical attention model. Experiments show that our framework using sentiment-related discourse augmentations for sentiment prediction enhances the overall performance for long documents, even beyond previous approaches using well-established discourse parsers trained on human annotated data. We show that a simple ensemble approach can further enhance performance by selectively using discourse, depending on the document length.</abstract>
      <url hash="642b3a54">2020.coling-main.16</url>
    </paper>
    <paper id="17">
      <title>End-to-End Emotion-Cause Pair Extraction with Graph Convolutional Network</title>
      <author><first>Ying</first><last>Chen</last></author>
      <author><first>Wenjun</first><last>Hou</last></author>
      <author><first>Shoushan</first><last>Li</last></author>
      <author><first>Caicong</first><last>Wu</last></author>
      <author><first>Xiaoqiang</first><last>Zhang</last></author>
      <pages>198–207</pages>
      <abstract>Emotion-cause pair extraction (ECPE), which aims at simultaneously extracting emotion-cause pairs that express emotions and their corresponding causes in a document, plays a vital role in understanding natural languages. Considering that most emotions usually have few causes mentioned in their contexts, we present a novel end-to-end Pair Graph Convolutional Network (PairGCN) to model pair-level contexts so that to capture the dependency information among local neighborhood candidate pairs. Moreover, in the graphical network, contexts are grouped into three types and each type of contexts is propagated by its own way. Experiments on a benchmark Chinese emotion-cause pair extraction corpus demonstrate the effectiveness of the proposed model.</abstract>
      <url hash="ad28c47b">2020.coling-main.17</url>
    </paper>
    <paper id="18">
      <title>A Unified Sequence Labeling Model for Emotion Cause Pair Extraction</title>
      <author><first>Xinhong</first><last>Chen</last></author>
      <author><first>Qing</first><last>Li</last></author>
      <author><first>Jianping</first><last>Wang</last></author>
      <pages>208–218</pages>
      <abstract>Emotion-cause pair extraction (ECPE) aims at extracting emotions and causes as pairs from documents, where each pair contains an emotion clause and a set of cause clauses. Existing approaches address the task by first extracting emotion and cause clauses via two binary classifiers separately, and then training another binary classifier to pair them up. However, the extracted emotion-cause pairs of different emotion types cannot be distinguished from each other through simple binary classifiers, which limits the applicability of the existing approaches. Moreover, such two-step approaches may suffer from possible cascading errors. In this paper, to address the first problem, we assign emotion type labels to emotion and cause clauses so that emotion-cause pairs of different emotion types can be easily distinguished. As for the second problem, we reformulate the ECPE task as a unified sequence labeling task, which can extract multiple emotion-cause pairs in an end-to-end fashion. We propose an approach composed of a convolution neural network for encoding neighboring information and two Bidirectional Long-Short Term Memory networks for two auxiliary tasks. Experiment results demonstrate the feasibility and effectiveness of our approaches.</abstract>
      <url hash="cd83dcf3">2020.coling-main.18</url>
    </paper>
    <paper id="19">
      <title>Regrexit or not Regrexit: Aspect-based Sentiment Analysis in Polarized Contexts</title>
      <author><first>Vorakit</first><last>Vorakitphan</last></author>
      <author><first>Marco</first><last>Guerini</last></author>
      <author><first>Elena</first><last>Cabrio</last></author>
      <author><first>Serena</first><last>Villata</last></author>
      <pages>219–224</pages>
      <abstract>Emotion analysis in polarized contexts represents a challenge for Natural Language Processing modeling. As a step in the aforementioned direction, we present a methodology to extend the task of Aspect-based Sentiment Analysis (ABSA) toward the affect and emotion representation in polarized settings. In particular, we adopt the three-dimensional model of affect based on Valence, Arousal, and Dominance (VAD). We then present a Brexit scenario that proves how affect varies toward the same aspect when politically polarized stances are presented. Our approach captures aspect-based polarization from newspapers regarding the Brexit scenario of 1.2m entities at sentence-level. We demonstrate how basic constituents of emotions can be mapped to the VAD model, along with their interactions respecting the polarized context in ABSA settings using biased key-concepts (e.g., “stop Brexit” vs. “support Brexit”). Quite intriguingly, the framework achieves to produce coherent aspect evidences of Brexit’s stance from key-concepts, showing that VAD influence the support and opposition aspects.</abstract>
      <url hash="e9d259e2">2020.coling-main.19</url>
    </paper>
    <paper id="20">
      <title>Affective and Contextual Embedding for Sarcasm Detection</title>
      <author><first>Nastaran</first><last>Babanejad</last></author>
      <author><first>Heidar</first><last>Davoudi</last></author>
      <author><first>Aijun</first><last>An</last></author>
      <author><first>Manos</first><last>Papagelis</last></author>
      <pages>225–243</pages>
      <abstract>Automatic sarcasm detection from text is an important classification task that can help identify the actual sentiment in user-generated data, such as reviews or tweets. Despite its usefulness, sarcasm detection remains a challenging task, due to a lack of any vocal intonation or facial gestures in textual data. To date, most of the approaches to addressing the problem have relied on hand-crafted affect features, or pre-trained models of non-contextual word embeddings, such as Word2vec. However, these models inherit limitations that render them inadequate for the task of sarcasm detection. In this paper, we propose two novel deep neural network models for sarcasm detection, namely ACE 1 and ACE 2. Given as input a text passage, the models predict whether it is sarcastic (or not). Our models extend the architecture of BERT by incorporating both affective and contextual features. To the best of our knowledge, this is the first attempt to directly alter BERT’s architecture and train it from scratch to build a sarcasm classifier. Extensive experiments on different datasets demonstrate that the proposed models outperform state-of-the-art models for sarcasm detection with significant margins.</abstract>
      <url hash="78c76a6f">2020.coling-main.20</url>
    </paper>
    <paper id="21">
      <title>Understanding Pre-trained <fixed-case>BERT</fixed-case> for Aspect-based Sentiment Analysis</title>
      <author><first>Hu</first><last>Xu</last></author>
      <author><first>Lei</first><last>Shu</last></author>
      <author><first>Philip</first><last>Yu</last></author>
      <author><first>Bing</first><last>Liu</last></author>
      <pages>244–250</pages>
      <abstract>This paper analyzes the pre-trained hidden representations learned from reviews on BERT for tasks in aspect-based sentiment analysis (ABSA). Our work is motivated by the recent progress in BERT-based language models for ABSA. However, it is not clear how the general proxy task of (masked) language model trained on unlabeled corpus without annotations of aspects or opinions can provide important features for downstream tasks in ABSA. By leveraging the annotated datasets in ABSA, we investigate both the attentions and the learned representations of BERT pre-trained on reviews. We found that BERT uses very few self-attention heads to encode context words (such as prepositions or pronouns that indicating an aspect) and opinion words for an aspect. Most features in the representation of an aspect are dedicated to the fine-grained semantics of the domain (or product category) and the aspect itself, instead of carrying summarized opinions from its context. We hope this investigation can help future research in improving self-supervised learning, unsupervised learning and fine-tuning for ABSA. The pre-trained model and code can be found at https://github.com/howardhsu/BERT-for-RRC-ABSA.</abstract>
      <url hash="3bf1600c">2020.coling-main.21</url>
    </paper>
    <paper id="22">
      <title>Weighed Domain-Invariant Representation Learning for Cross-domain Sentiment Analysis</title>
      <author><first>Minlong</first><last>Peng</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <pages>251–265</pages>
      <abstract>Cross-domain sentiment analysis is currently a hot topic in both the research and industrial areas. One of the most popular framework for the task is domain-invariant representation learning (DIRL), which aims to learn a distribution-invariant feature representation across domains. However, in this work, we find out that applying DIRL may degrade domain adaptation performance when the label distribution <tex-math>\rm{P}(\rm{Y})</tex-math> changes across domains. To address this problem, we propose a modification to DIRL, obtaining a novel weighted domain-invariant representation learning (WDIRL) framework. We show that it is easy to transfer existing models of the DIRL framework to the WDIRL framework. Empirical studies on extensive cross-domain sentiment analysis tasks verified our statements and showed the effectiveness of our proposed solution.</abstract>
      <url hash="687bce5b">2020.coling-main.22</url>
    </paper>
    <paper id="23">
      <title>Improving Sentiment Analysis over non-<fixed-case>E</fixed-case>nglish Tweets using Multilingual Transformers and Automatic Translation for Data-Augmentation</title>
      <author><first>Valentin</first><last>Barriere</last></author>
      <author><first>Alexandra</first><last>Balahur</last></author>
      <pages>266–271</pages>
      <abstract>Tweets are specific text data when compared to general text. Although sentiment analysis over tweets has become very popular in the last decade for English, it is still difficult to find huge annotated corpora for non-English languages. The recent rise of the transformer models in Natural Language Processing allows to achieve unparalleled performances in many tasks, but these models need a consequent quantity of text to adapt to the tweet domain. We propose the use of a multilingual transformer model, that we pre-train over English tweets on which we apply data-augmentation using automatic translation to adapt the model to non-English languages. Our experiments in French, Spanish, German and Italian suggest that the proposed technique is an efficient way to improve the results of the transformers over small corpora of tweets in a non-English language.</abstract>
      <url hash="af5cd2eb">2020.coling-main.23</url>
    </paper>
    <paper id="24">
      <title>Joint Aspect Extraction and Sentiment Analysis with Directional Graph Convolutional Networks</title>
      <author><first>Guimin</first><last>Chen</last></author>
      <author><first>Yuanhe</first><last>Tian</last></author>
      <author><first>Yan</first><last>Song</last></author>
      <pages>272–279</pages>
      <abstract>End-to-end aspect-based sentiment analysis (EASA) consists of two sub-tasks: the first extracts the aspect terms in a sentence and the second predicts the sentiment polarities for such terms. For EASA, compared to pipeline and multi-task approaches, joint aspect extraction and sentiment analysis provides a one-step solution to predict both aspect terms and their sentiment polarities through a single decoding process, which avoid the mismatches in between the results of aspect terms and sentiment polarities, as well as error propagation. Previous studies, especially recent ones, for this task focus on using powerful encoders (e.g., Bi-LSTM and BERT) to model contextual information from the input, with limited efforts paid to using advanced neural architectures (such as attentions and graph convolutional networks) or leveraging extra knowledge (such as syntactic information). To extend such efforts, in this paper, we propose directional graph convolutional networks (D-GCN) to jointly perform aspect extraction and sentiment analysis with encoding syntactic information, where dependency among words are integrated in our model to enhance its ability of representing input sentences and help EASA accordingly. Experimental results on three benchmark datasets demonstrate the effectiveness of our approach, where D-GCN achieves state-of-the-art performance on all datasets.</abstract>
      <url hash="39a09f08">2020.coling-main.24</url>
    </paper>
    <paper id="25">
      <title>Train Once, and Decode As You Like</title>
      <author><first>Chao</first><last>Tian</last></author>
      <author><first>Yifei</first><last>Wang</last></author>
      <author><first>Hao</first><last>Cheng</last></author>
      <author><first>Yijiang</first><last>Lian</last></author>
      <author><first>Zhihua</first><last>Zhang</last></author>
      <pages>280–293</pages>
      <abstract>In this paper we propose a unified approach for supporting different generation manners of machine translation, including autoregressive, semi-autoregressive, and refinement-based non-autoregressive models. Our approach works by repeatedly selecting positions and generating tokens at these selected positions. After being trained once, our approach achieves better or competitive translation performance compared with some strong task-specific baseline models in all the settings. This generalization ability benefits mainly from the new training objective that we propose. We validate our approach on the WMT’14 English-German and IWSLT’14 German-English translation tasks. The experimental results are encouraging.</abstract>
      <url hash="4e3bfaaf">2020.coling-main.25</url>
    </paper>
    <paper id="26">
      <title>A Representation Learning Approach to Animal Biodiversity Conservation</title>
      <author><first>Meet</first><last>Mukadam</last></author>
      <author><first>Mandhara</first><last>Jayaram</last></author>
      <author><first>Yongfeng</first><last>Zhang</last></author>
      <pages>294–305</pages>
      <abstract>Generating knowledge from natural language data has aided in solving many artificial intelligence problems. Vector representations of words have been the driving force behind the majority of natural language processing tasks. This paper develops a novel approach for predicting the conservation status of animal species using custom generated scientific name embeddings. We use two different vector embeddings generated using representation learning on Wikipedia text and animal taxonomy data. We generate name embeddings for all species in the animal kingdom using unsupervised learning and build a model on the IUCN Red List dataset to classify species into endangered or least-concern. To our knowledge, this is the first work that makes use of learnt features instead of handcrafted features for this task and achieves competitive results. Based on the high confidence results of our model, we also predict the conservation status of data deficient species whose conservation status is still unknown and thus steering more focus towards them for protection. These embeddings have also been made publicly available here. We believe this will greatly help in solving various downstream tasks and further advance research in the cross-domain involving natural language processing, conservation biology, and life sciences.</abstract>
      <url hash="6dc792d7">2020.coling-main.26</url>
    </paper>
    <paper id="27">
      <title>Integrating External Event Knowledge for Script Learning</title>
      <author><first>Shangwen</first><last>Lv</last></author>
      <author><first>Fuqing</first><last>Zhu</last></author>
      <author><first>Songlin</first><last>Hu</last></author>
      <pages>306–315</pages>
      <abstract>Script learning aims to predict the subsequent event according to the existing event chain. Recent studies focus on event co-occurrence to solve this problem. However, few studies integrate external event knowledge to solve this problem. With our observations, external event knowledge can provide additional knowledge like temporal or causal knowledge for understanding event chain better and predicting the right subsequent event. In this work, we integrate event knowledge from ASER (Activities, States, Events and their Relations) knowledge base to help predict the next event. We propose a new approach consisting of knowledge retrieval stage and knowledge integration stage. In the knowledge retrieval stage, we select relevant external event knowledge from ASER. In the knowledge integration stage, we propose three methods to integrate external knowledge into our model and infer final answers. Experiments on the widely-used Multi- Choice Narrative Cloze (MCNC) task show our approach achieves state-of-the-art performance compared to other methods.</abstract>
      <url hash="58aa8586">2020.coling-main.27</url>
    </paper>
    <paper id="28">
      <title>Pointing to Subwords for Generating Function Names in Source Code</title>
      <author><first>Shogo</first><last>Fujita</last></author>
      <author><first>Hidetaka</first><last>Kamigaito</last></author>
      <author><first>Hiroya</first><last>Takamura</last></author>
      <author><first>Manabu</first><last>Okumura</last></author>
      <pages>316–327</pages>
      <abstract>We tackle the task of automatically generating a function name from source code. Existing generators face difficulties in generating low-frequency or out-of-vocabulary subwords. In this paper, we propose two strategies for copying low-frequency or out-of-vocabulary subwords in inputs. Our best performing model showed an improvement over the conventional method in terms of our modified F1 and accuracy on the Java-small and Java-large datasets.</abstract>
      <url hash="0ab31438">2020.coling-main.28</url>
    </paper>
    <paper id="29">
      <title>Heterogeneous Graph Neural Networks to Predict What Happen Next</title>
      <author><first>Jianming</first><last>Zheng</last></author>
      <author><first>Fei</first><last>Cai</last></author>
      <author><first>Yanxiang</first><last>Ling</last></author>
      <author><first>Honghui</first><last>Chen</last></author>
      <pages>328–338</pages>
      <abstract>Given an incomplete event chain, script learning aims to predict the missing event, which can support a series of NLP applications. Existing work cannot well represent the heterogeneous relations and capture the discontinuous event segments that are common in the event chain. To address these issues, we introduce a heterogeneous-event (HeterEvent) graph network. In particular, we employ each unique word and individual event as nodes in the graph, and explore three kinds of edges based on realistic relations (e.g., the relations of word-and-word, word-and-event, event-and-event). We also design a message passing process to realize information interactions among homo or heterogeneous nodes. And the discontinuous event segments could be explicitly modeled by finding the specific path between corresponding nodes in the graph. The experimental results on one-step and multi-step inference tasks demonstrate that our ensemble model HeterEvent[W+E] can outperform existing baselines.</abstract>
      <url hash="29fb34e5">2020.coling-main.29</url>
    </paper>
    <paper id="30">
      <title><fixed-case>CEREC</fixed-case>: A Corpus for Entity Resolution in Email Conversations</title>
      <author><first>Parag Pravin</first><last>Dakle</last></author>
      <author><first>Dan</first><last>Moldovan</last></author>
      <pages>339–349</pages>
      <abstract>We present the first large scale corpus for entity resolution in email conversations (CEREC). The corpus consists of 6001 email threads from the Enron Email Corpus containing 36,448 email messages and 38,996 entity coreference chains. The annotation is carried out as a two-step process with minimal manual effort. Experiments are carried out for evaluating different features and performance of four baselines on the created corpus. For the task of mention identification and coreference resolution, a best performance of 54.1 F1 is reported, highlighting the room for improvement. An in-depth qualitative and quantitative error analysis is presented to understand the limitations of the baselines considered.</abstract>
      <url hash="5fb06018">2020.coling-main.30</url>
    </paper>
    <paper id="31">
      <title><fixed-case>SQL</fixed-case> Generation via Machine Reading Comprehension</title>
      <author><first>Zeyu</first><last>Yan</last></author>
      <author><first>Jianqiang</first><last>Ma</last></author>
      <author><first>Yang</first><last>Zhang</last></author>
      <author><first>Jianping</first><last>Shen</last></author>
      <pages>350–356</pages>
      <abstract>Text-to-SQL systems offers natural language interfaces to databases, which can automatically generates SQL queries given natural language questions. On the WikiSQL benchmark, state-of- the-art text-to-SQL systems typically take a slot-filling approach by building several specialized models for each type of slot. Despite being effective, such modularized systems are complex and also fall short in jointly learning for different slots. To solve these problems, this paper proposes a novel approach that formulates the task as a question answering problem, where different slots are predicted by a unified machine reading comprehension (MRC) model. For this purpose, we use a BERT-based MRC model, which can also benefit from intermediate training on other MRC datasets. The proposed method can achieve competitive results on WikiSQL, suggesting it being a promising direction for text-to-SQL.</abstract>
      <url hash="ce925ae6">2020.coling-main.31</url>
    </paper>
    <paper id="32">
      <title>Towards Privacy by Design in Learner Corpora Research: A Case of On-the-fly Pseudonymization of <fixed-case>S</fixed-case>wedish Learner Essays</title>
      <author><first>Elena</first><last>Volodina</last></author>
      <author><first>Yousuf</first><last>Ali Mohammed</last></author>
      <author><first>Sandra</first><last>Derbring</last></author>
      <author><first>Arild</first><last>Matsson</last></author>
      <author><first>Beata</first><last>Megyesi</last></author>
      <pages>357–369</pages>
      <abstract>This article reports on an ongoing project aiming at automatization of pseudonymization of learner essays. The process includes three steps: identification of personal information in an unstructured text, labeling for a category, and pseudonymization. We experiment with rule-based methods for detection of 15 categories out of the suggested 19 (Megyesi et al., 2018) that we deem important and/or doable with automatic approaches. For the detection and labeling steps,we use resources covering personal names, geographic names, company and university names and others. For the pseudonymization step, we replace the item using another item of the same type from the above-mentioned resources. Evaluation of the detection and labeling steps are made on a set of manually anonymized essays. The results are promising and show that 89% of the personal information can be successfully identified in learner data, and annotated correctly with an inter-annotator agreement of 86% measured as Fleiss kappa and Krippendorff’s alpha.</abstract>
      <url hash="0d4ab50e">2020.coling-main.32</url>
    </paper>
    <paper id="33">
      <title><fixed-case>PG</fixed-case>-<fixed-case>GSQL</fixed-case>: Pointer-Generator Network with Guide Decoding for Cross-Domain Context-Dependent Text-to-<fixed-case>SQL</fixed-case> Generation</title>
      <author><first>Huajie</first><last>Wang</last></author>
      <author><first>Mei</first><last>Li</last></author>
      <author><first>Lei</first><last>Chen</last></author>
      <pages>370–380</pages>
      <abstract>Text-to-SQL is a task of translating utterances to SQL queries, and most existing neural approaches of text-to-SQL focus on the cross-domain context-independent generation task. We pay close attention to the cross-domain context-dependent text-to-SQL generation task, which requires a model to depend on the interaction history and current utterance to generate SQL query. In this paper, we present an encoder-decoder model called PG-GSQL based on the interaction-level encoder and with two effective innovations in decoder to solve cross-domain context-dependent text-to-SQL task. 1) To effectively capture historical information of SQL query and reuse the previous SQL query tokens, we use a hybrid pointer-generator network as decoder to copy tokens from the previous SQL query via pointer, the generator part is utilized to generate new tokens. 2) We propose a guide component to limit the prediction space of vocabulary for avoiding table-column dependency and foreign key dependency errors during decoding phase. In addition, we design a column-table linking mechanism to improve the prediction accuracy of tables. On the challenging cross-domain context-dependent text-to-SQL benchmark SParC, PG-GSQL achieves 34.0% question matching accuracy and 19.0% interaction matching accuracy on the dev set. With BERT augmentation, PG-GSQL obtains 53.1% question matching accuracy and 34.7% interaction matching accuracy on the dev set, outperforms the previous state-of-the-art model by 5.9% question matching accuracy and 5.2% interaction matching accuracy. Our code is publicly available.</abstract>
      <url hash="0c09fec7">2020.coling-main.33</url>
    </paper>
    <paper id="34">
      <title>Neural Approaches for Natural Language Interfaces to Databases: A Survey</title>
      <author><first>Radu Cristian Alexandru</first><last>Iacob</last></author>
      <author><first>Florin</first><last>Brad</last></author>
      <author><first>Elena-Simona</first><last>Apostol</last></author>
      <author><first>Ciprian-Octavian</first><last>Truică</last></author>
      <author><first>Ionel Alexandru</first><last>Hosu</last></author>
      <author><first>Traian</first><last>Rebedea</last></author>
      <pages>381–395</pages>
      <abstract>A natural language interface to databases (NLIDB) enables users without technical expertise to easily access information from relational databases. Interest in NLIDBs has resurged in the past years due to the availability of large datasets and improvements to neural sequence-to-sequence models. In this survey we focus on the key design decisions behind current state of the art neural approaches, which we group into encoder and decoder improvements. We highlight the three most important directions, namely linking question tokens to database schema elements (schema linking), better architectures for encoding the textual query taking into account the schema (schema encoding), and improved generation of structured queries using autoregressive neural models (grammar-based decoders). To foster future research, we also present an overview of the most important NLIDB datasets, together with a comparison of the top performing neural models and a short insight into recent non deep learning solutions.</abstract>
      <url hash="1da73827">2020.coling-main.34</url>
    </paper>
    <paper id="35">
      <title>Predicting Stance Change Using Modular Architectures</title>
      <author><first>Aldo</first><last>Porco</last></author>
      <author><first>Dan</first><last>Goldwasser</last></author>
      <pages>396–406</pages>
      <abstract>The ability to change a person’s mind on a given issue depends both on the arguments they are presented with and on their underlying perspectives and biases on that issue. Predicting stance changes require characterizing both aspects and the interaction between them, especially in realistic settings in which stance changes are very rare. In this paper, we suggest a modular learning approach, which decomposes the task into multiple modules, focusing on different aspects of the interaction between users, their beliefs, and the arguments they are exposed to. Our experiments show that our modular approach archives significantly better results compared to the end-to-end approach using BERT over the same inputs.</abstract>
      <url hash="3b0999ca">2020.coling-main.35</url>
    </paper>
    <paper id="36">
      <title>Leveraging <fixed-case>HTML</fixed-case> in Free Text Web Named Entity Recognition</title>
      <author><first>Colin</first><last>Ashby</last></author>
      <author><first>David</first><last>Weir</last></author>
      <pages>407–413</pages>
      <abstract>HTML tags are typically discarded in free text Named Entity Recognition from Web pages. We investigate whether these discarded tags might be used to improve NER performance. We compare Text+Tags sentences with their Text-Only equivalents, over five datasets, two free text segmentation granularities and two NER models. We find an increased F1 performance for Text+Tags of between 0.9% and 13.2% over all datasets, variants and models. This performance increase, over datasets of varying entity types, HTML density and construction quality, indicates our method is flexible and adaptable. These findings imply that a similar technique might be of use in other Web-aware NLP tasks, including the enrichment of deep language models.</abstract>
      <url hash="3fabc411">2020.coling-main.36</url>
    </paper>
    <paper id="37">
      <title>Multimodal Review Generation with Privacy and Fairness Awareness</title>
      <author><first>Xuan-Son</first><last>Vu</last></author>
      <author><first>Thanh-Son</first><last>Nguyen</last></author>
      <author><first>Duc-Trong</first><last>Le</last></author>
      <author><first>Lili</first><last>Jiang</last></author>
      <pages>414–425</pages>
      <abstract>Users express their opinions towards entities (e.g., restaurants) via online reviews which can be in diverse forms such as text, ratings, and images. Modeling reviews are advantageous for user behavior understanding which, in turn, supports various user-oriented tasks such as recommendation, sentiment analysis, and review generation. In this paper, we propose MG-PriFair, a multimodal neural-based framework, which generates personalized reviews with privacy and fairness awareness. Motivated by the fact that reviews might contain personal information and sentiment bias, we propose a novel differentially private (dp)-embedding model for training privacy guaranteed embeddings and an evaluation approach for sentiment fairness in the food-review domain. Experiments on our novel review dataset show that MG-PriFair is capable of generating plausibly long reviews while controlling the amount of exploited user data and using the least sentiment biased word embeddings. To the best of our knowledge, we are the first to bring user privacy and sentiment fairness into the review generation task. The dataset and source codes are available at https://github.com/ReML-AI/MG-PriFair.</abstract>
      <url hash="0981498d">2020.coling-main.37</url>
    </paper>
    <paper id="38">
      <title>Generating Equation by Utilizing Operators : <fixed-case>GEO</fixed-case> model</title>
      <author><first>Kyung Seo</first><last>Ki</last></author>
      <author><first>Donggeon</first><last>Lee</last></author>
      <author><first>Bugeun</first><last>Kim</last></author>
      <author><first>Gahgene</first><last>Gweon</last></author>
      <pages>426–436</pages>
      <abstract>Math word problem solving is an emerging research topic in Natural Language Processing. Recently, to address the math word problem-solving task, researchers have applied the encoder-decoder architecture, which is mainly used in machine translation tasks. The state-of-the-art neural models use hand-crafted features and are based on generation methods. In this paper, we propose the GEO (Generation of Equations by utilizing Operators) model that does not use hand-crafted features and addresses two issues that are present in existing neural models: 1. missing domain-specific knowledge features and 2. losing encoder-level knowledge. To address missing domain-specific feature issue, we designed two auxiliary tasks: operation group difference prediction and implicit pair prediction. To address losing encoder-level knowledge issue, we added an Operation Feature Feed Forward (OP3F) layer. Experimental results showed that the GEO model outperformed existing state-of-the-art models on two datasets, 85.1% in MAWPS, and 62.5% in DRAW-1K, and reached comparable performance of 82.1% in ALG514 dataset.</abstract>
      <url hash="d81f0397">2020.coling-main.38</url>
    </paper>
    <paper id="39">
      <title>Improving Abstractive Dialogue Summarization with Graph Structures and Topic Words</title>
      <author><first>Lulu</first><last>Zhao</last></author>
      <author><first>Weiran</first><last>Xu</last></author>
      <author><first>Jun</first><last>Guo</last></author>
      <pages>437–449</pages>
      <abstract>Recently, people have been beginning paying more attention to the abstractive dialogue summarization task. Since the information flows are exchanged between at least two interlocutors and key elements about a certain event are often spanned across multiple utterances, it is necessary for researchers to explore the inherent relations and structures of dialogue contents. However, the existing approaches often process the dialogue with sequence-based models, which are hard to capture long-distance inter-sentence relations. In this paper, we propose a Topic-word Guided Dialogue Graph Attention (TGDGA) network to model the dialogue as an interaction graph according to the topic word information. A masked graph self-attention mechanism is used to integrate cross-sentence information flows and focus more on the related utterances, which makes it better to understand the dialogue. Moreover, the topic word features are introduced to assist the decoding process. We evaluate our model on the SAMSum Corpus and Automobile Master Corpus. The experimental results show that our method outperforms most of the baselines.</abstract>
      <url hash="ac7434a5">2020.coling-main.39</url>
    </paper>
    <paper id="40">
      <title>Speaker-change Aware <fixed-case>CRF</fixed-case> for Dialogue Act Classification</title>
      <author><first>Guokan</first><last>Shang</last></author>
      <author><first>Antoine</first><last>Tixier</last></author>
      <author><first>Michalis</first><last>Vazirgiannis</last></author>
      <author><first>Jean-Pierre</first><last>Lorré</last></author>
      <pages>450–464</pages>
      <abstract>Recent work in Dialogue Act (DA) classification approaches the task as a sequence labeling problem, using neural network models coupled with a Conditional Random Field (CRF) as the last layer. CRF models the conditional probability of the target DA label sequence given the input utterance sequence. However, the task involves another important input sequence, that of speakers, which is ignored by previous work. To address this limitation, this paper proposes a simple modification of the CRF layer that takes speaker-change into account. Experiments on the SwDA corpus show that our modified CRF layer outperforms the original one, with very wide margins for some DA labels. Further, visualizations demonstrate that our CRF layer can learn meaningful, sophisticated transition patterns between DA label pairs conditioned on speaker-change in an end-to-end way. Code is publicly available.</abstract>
      <url hash="98e646b3">2020.coling-main.40</url>
    </paper>
    <paper id="41">
      <title><fixed-case>LAVA</fixed-case>: Latent Action Spaces via Variational Auto-encoding for Dialogue Policy Optimization</title>
      <author><first>Nurul</first><last>Lubis</last></author>
      <author><first>Christian</first><last>Geishauser</last></author>
      <author><first>Michael</first><last>Heck</last></author>
      <author><first>Hsien-chin</first><last>Lin</last></author>
      <author><first>Marco</first><last>Moresi</last></author>
      <author><first>Carel</first><last>van Niekerk</last></author>
      <author><first>Milica</first><last>Gasic</last></author>
      <pages>465–479</pages>
      <abstract>Reinforcement learning (RL) can enable task-oriented dialogue systems to steer the conversation towards successful task completion. In an end-to-end setting, a response can be constructed in a word-level sequential decision making process with the entire system vocabulary as action space. Policies trained in such a fashion do not require expert-defined action spaces, but they have to deal with large action spaces and long trajectories, making RL impractical. Using the latent space of a variational model as action space alleviates this problem. However, current approaches use an uninformed prior for training and optimize the latent distribution solely on the context. It is therefore unclear whether the latent representation truly encodes the characteristics of different actions. In this paper, we explore three ways of leveraging an auxiliary task to shape the latent variable distribution: via pre-training, to obtain an informed prior, and via multitask learning. We choose response auto-encoding as the auxiliary task, as this captures the generative factors of dialogue responses while requiring low computational cost and neither additional data nor labels. Our approach yields a more action-characterized latent representations which support end-to-end dialogue policy optimization and achieves state-of-the-art success rates. These results warrant a more wide-spread use of RL in end-to-end dialogue models.</abstract>
      <url hash="5bfb899f">2020.coling-main.41</url>
    </paper>
    <paper id="42">
      <title>Recent Neural Methods on Slot Filling and Intent Classification for Task-Oriented Dialogue Systems: A Survey</title>
      <author><first>Samuel</first><last>Louvan</last></author>
      <author><first>Bernardo</first><last>Magnini</last></author>
      <pages>480–496</pages>
      <abstract>In recent years, fostered by deep learning technologies and by the high demand for conversational AI, various approaches have been proposed that address the capacity to elicit and understand user’s needs in task-oriented dialogue systems. We focus on two core tasks, slot filling (SF) and intent classification (IC), and survey how neural based models have rapidly evolved to address natural language understanding in dialogue systems. We introduce three neural architectures: independent models, which model SF and IC separately, joint models, which exploit the mutual benefit of the two tasks simultaneously, and transfer learning models, that scale the model to new domains. We discuss the current state of the research in SF and IC, and highlight challenges that still require attention.</abstract>
      <url hash="ba25b7f7">2020.coling-main.42</url>
    </paper>
    <paper id="43">
      <title>Re-framing Incremental Deep Language Models for Dialogue Processing with Multi-task Learning</title>
      <author><first>Morteza</first><last>Rohanian</last></author>
      <author><first>Julian</first><last>Hough</last></author>
      <pages>497–507</pages>
      <abstract>We present a multi-task learning framework to enable the training of one universal incremental dialogue processing model with four tasks of disfluency detection, language modelling, part-of-speech tagging and utterance segmentation in a simple deep recurrent setting. We show that these tasks provide positive inductive biases to each other with optimal contribution of each one relying on the severity of the noise from the task. Our live multi-task model outperforms similar individual tasks, delivers competitive performance and is beneficial for future use in conversational agents in psychiatric treatment.</abstract>
      <url hash="7a1e955e">2020.coling-main.43</url>
    </paper>
    <paper id="44">
      <title><fixed-case>A</fixed-case>pril<fixed-case>E</fixed-case>: Attention with Pseudo Residual Connection for Knowledge Graph Embedding</title>
      <author><first>Yuzhang</first><last>Liu</last></author>
      <author><first>Peng</first><last>Wang</last></author>
      <author><first>Yingtai</first><last>Li</last></author>
      <author><first>Yizhan</first><last>Shao</last></author>
      <author><first>Zhongkai</first><last>Xu</last></author>
      <pages>508–518</pages>
      <abstract>Knowledge graph embedding maps entities and relations into low-dimensional vector space. However, it is still challenging for many existing methods to model diverse relational patterns, especially symmetric and antisymmetric relations. To address this issue, we propose a novel model, AprilE, which employs triple-level self-attention and pseudo residual connection to model relational patterns. The triple-level self-attention treats head entity, relation, and tail entity as a sequence and captures the dependency within a triple. At the same time the pseudo residual connection retains primitive semantic features. Furthermore, to deal with symmetric and antisymmetric relations, two schemas of score function are designed via a position-adaptive mechanism. Experimental results on public datasets demonstrate that our model can produce expressive knowledge embedding and significantly outperforms most of the state-of-the-art works.</abstract>
      <url hash="d97584c9">2020.coling-main.44</url>
    </paper>
    <paper id="45">
      <title>Variational Autoencoder with Embedded Student-t Mixture Model for Authorship Attribution</title>
      <author><first>Benedikt</first><last>Boenninghoff</last></author>
      <author><first>Steffen</first><last>Zeiler</last></author>
      <author><first>Robert</first><last>Nickel</last></author>
      <author><first>Dorothea</first><last>Kolossa</last></author>
      <pages>519–529</pages>
      <abstract>Traditional computational authorship attribution describes a classification task in a closed-set scenario. Given a finite set of candidate authors and corresponding labeled texts, the objective is to determine which of the authors has written another set of anonymous or disputed texts. In this work, we propose a probabilistic autoencoding framework to deal with this supervised classification task. Variational autoencoders (VAEs) have had tremendous success in learning latent representations. However, existing VAEs are currently still bound by limitations imposed by the assumed Gaussianity of the underlying probability distributions in the latent space. In this work, we are extending a VAE with an embedded Gaussian mixture model to a Student-t mixture model, which allows for an independent control of the “heaviness” of the respective tails of the implied probability densities. Experiments over an Amazon review dataset indicate superior performance of the proposed method.</abstract>
      <url hash="30edc025">2020.coling-main.45</url>
    </paper>
    <paper id="46">
      <title>Knowledge Graph Embeddings in Geometric Algebras</title>
      <author><first>Chengjin</first><last>Xu</last></author>
      <author><first>Mojtaba</first><last>Nayyeri</last></author>
      <author><first>Yung-Yu</first><last>Chen</last></author>
      <author><first>Jens</first><last>Lehmann</last></author>
      <pages>530–544</pages>
      <abstract>Knowledge graph (KG) embedding aims at embedding entities and relations in a KG into a low dimensional latent representation space. Existing KG embedding approaches model entities and relations in a KG by utilizing real-valued , complex-valued, or hypercomplex-valued (Quaternion or Octonion) representations, all of which are subsumed into a geometric algebra. In this work, we introduce a novel geometric algebra-based KG embedding framework, GeomE, which utilizes multivector representations and the geometric product to model entities and relations. Our framework subsumes several state-of-the-art KG embedding approaches and is advantageous with its ability of modeling various key relation patterns, including (anti-)symmetry, inversion and composition, rich expressiveness with higher degree of freedom as well as good generalization capacity. Experimental results on multiple benchmark knowledge graphs show that the proposed approach outperforms existing state-of-the-art models for link prediction.</abstract>
      <url hash="5f5dc770">2020.coling-main.46</url>
    </paper>
    <paper id="47">
      <title>Exploiting Node Content for Multiview Graph Convolutional Network and Adversarial Regularization</title>
      <author><first>Qiuhao</first><last>Lu</last></author>
      <author><first>Nisansa</first><last>de Silva</last></author>
      <author><first>Dejing</first><last>Dou</last></author>
      <author><first>Thien Huu</first><last>Nguyen</last></author>
      <author><first>Prithviraj</first><last>Sen</last></author>
      <author><first>Berthold</first><last>Reinwald</last></author>
      <author><first>Yunyao</first><last>Li</last></author>
      <pages>545–555</pages>
      <abstract>Network representation learning (NRL) is crucial in the area of graph learning. Recently, graph autoencoders and its variants have gained much attention and popularity among various types of node embedding approaches. Most existing graph autoencoder-based methods aim to minimize the reconstruction errors of the input network while not explicitly considering the semantic relatedness between nodes. In this paper, we propose a novel network embedding method which models the consistency across different views of networks. More specifically, we create a second view from the input network which captures the relation between nodes based on node content and enforce the latent representations from the two views to be consistent by incorporating a multiview adversarial regularization module. The experimental studies on benchmark datasets prove the effectiveness of this method, and demonstrate that our method compares favorably with the state-of-the-art algorithms on challenging tasks such as link prediction and node clustering. We also evaluate our method on a real-world application, i.e., 30-day unplanned ICU readmission prediction, and achieve promising results compared with several baseline methods.</abstract>
      <url hash="5324c7e4">2020.coling-main.47</url>
    </paper>
    <paper id="48">
      <title><fixed-case>R</fixed-case>at<fixed-case>E</fixed-case>: Relation-Adaptive Translating Embedding for Knowledge Graph Completion</title>
      <author><first>Hao</first><last>Huang</last></author>
      <author><first>Guodong</first><last>Long</last></author>
      <author><first>Tao</first><last>Shen</last></author>
      <author><first>Jing</first><last>Jiang</last></author>
      <author><first>Chengqi</first><last>Zhang</last></author>
      <pages>556–567</pages>
      <abstract>Many graph embedding approaches have been proposed for knowledge graph completion via link prediction. Among those, translating embedding approaches enjoy the advantages of light-weight structure, high efficiency and great interpretability. Especially when extended to complex vector space, they show the capability in handling various relation patterns including symmetry, antisymmetry, inversion and composition. However, previous translating embedding approaches defined in complex vector space suffer from two main issues: 1) representing and modeling capacities of the model are limited by the translation function with rigorous multiplication of two complex numbers; and 2) embedding ambiguity caused by one-to-many relations is not explicitly alleviated. In this paper, we propose a relation-adaptive translation function built upon a novel weighted product in complex space, where the weights are learnable, relation-specific and independent to embedding size. The translation function only requires eight more scalar parameters each relation, but improves expressive power and alleviates embedding ambiguity problem. Based on the function, we then present our Relation-adaptive translating Embedding (RatE) approach to score each graph triple. Moreover, a novel negative sampling method is proposed to utilize both prior knowledge and self-adversarial learning for effective optimization. Experiments verify RatE achieves state-of-the-art performance on four link prediction benchmarks.</abstract>
      <url hash="a583f534">2020.coling-main.48</url>
    </paper>
    <paper id="49">
      <title><fixed-case>S</fixed-case>enti<fixed-case>X</fixed-case>: A Sentiment-Aware Pre-Trained Model for Cross-Domain Sentiment Analysis</title>
      <author><first>Jie</first><last>Zhou</last></author>
      <author><first>Junfeng</first><last>Tian</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <author><first>Yuanbin</first><last>Wu</last></author>
      <author><first>Wenming</first><last>Xiao</last></author>
      <author><first>Liang</first><last>He</last></author>
      <pages>568–579</pages>
      <abstract>Pre-trained language models have been widely applied to cross-domain NLP tasks like sentiment analysis, achieving state-of-the-art performance. However, due to the variety of users’ emotional expressions across domains, fine-tuning the pre-trained models on the source domain tends to overfit, leading to inferior results on the target domain. In this paper, we pre-train a sentiment-aware language model (SentiX) via domain-invariant sentiment knowledge from large-scale review datasets, and utilize it for cross-domain sentiment analysis task without fine-tuning. We propose several pre-training tasks based on existing lexicons and annotations at both token and sentence levels, such as emoticons, sentiment words, and ratings, without human interference. A series of experiments are conducted and the results indicate the great advantages of our model. We obtain new state-of-the-art results in all the cross-domain sentiment analysis tasks, and our proposed SentiX can be trained with only 1% samples (18 samples) and it achieves better performance than BERT with 90% samples.</abstract>
      <url hash="e0bcd477">2020.coling-main.49</url>
    </paper>
    <paper id="50">
      <title><fixed-case>B</fixed-case>ayes-enhanced Lifelong Attention Networks for Sentiment Classification</title>
      <author><first>Hao</first><last>Wang</last></author>
      <author><first>Shuai</first><last>Wang</last></author>
      <author><first>Sahisnu</first><last>Mazumder</last></author>
      <author><first>Bing</first><last>Liu</last></author>
      <author><first>Yan</first><last>Yang</last></author>
      <author><first>Tianrui</first><last>Li</last></author>
      <pages>580–591</pages>
      <abstract>The classic deep learning paradigm learns a model from the training data of a single task and the learned model is also tested on the same task. This paper studies the problem of learning a sequence of tasks (sentiment classification tasks in our case). After each sentiment classification task is learned, its knowledge is retained to help future task learning. Following this setting, we explore attention neural networks and propose a Bayes-enhanced Lifelong Attention Network (BLAN). The key idea is to exploit the generative parameters of naive Bayes to learn attention knowledge. The learned knowledge from each task is stored in a knowledge base and later used to build lifelong attentions. The constructed lifelong attentions are then used to enhance the attention of the network to help new task learning. Experimental results on product reviews from Amazon.com show the effectiveness of the proposed model.</abstract>
      <url hash="e55308f3">2020.coling-main.50</url>
    </paper>
    <paper id="51">
      <title><fixed-case>A</fixed-case>rabizi Language Models for Sentiment Analysis</title>
      <author><first>Gaétan</first><last>Baert</last></author>
      <author><first>Souhir</first><last>Gahbiche</last></author>
      <author><first>Guillaume</first><last>Gadek</last></author>
      <author><first>Alexandre</first><last>Pauchet</last></author>
      <pages>592–603</pages>
      <abstract>Arabizi is a written form of spoken Arabic, relying on Latin characters and digits. It is informal and does not follow any conventional rules, raising many NLP challenges. In particular, Arabizi has recently emerged as the Arabic language in online social networks, becoming of great interest for opinion mining and sentiment analysis. Unfortunately, only few Arabizi resources exist and state-of-the-art language models such as BERT do not consider Arabizi. In this work, we construct and release two datasets: (i) LAD, a corpus of 7.7M tweets written in Arabizi and (ii) SALAD, a subset of LAD, manually annotated for sentiment analysis. Then, a BERT architecture is pre-trained on LAD, in order to create and distribute an Arabizi language model called BAERT. We show that a language model (BAERT) pre-trained on a large corpus (LAD) in the same language (Arabizi) as that of the fine-tuning dataset (SALAD), outperforms a state-of-the-art multi-lingual pretrained model (multilingual BERT) on a sentiment analysis task.</abstract>
      <url hash="87a0e4dc">2020.coling-main.51</url>
    </paper>
    <paper id="52">
      <title>Author’s Sentiment Prediction</title>
      <author><first>Mohaddeseh</first><last>Bastan</last></author>
      <author><first>Mahnaz</first><last>Koupaee</last></author>
      <author><first>Youngseo</first><last>Son</last></author>
      <author><first>Richard</first><last>Sicoli</last></author>
      <author><first>Niranjan</first><last>Balasubramanian</last></author>
      <pages>604–615</pages>
      <abstract>Even though sentiment analysis has been well-studied on a wide range of domains, there hasn’tbeen much work on inferring author sentiment in news articles. To address this gap, we introducePerSenT, a crowd-sourced dataset that captures the sentiment of an author towards the mainentity in a news article. Our benchmarks of multiple strong baselines show that this is a difficultclassification task. BERT performs the best amongst the baselines. However, it only achievesa modest performance overall suggesting that fine-tuning document-level representations aloneisn’t adequate for this task. Making paragraph-level decisions and aggregating over the entiredocument is also ineffective. We present empirical and qualitative analyses that illustrate thespecific challenges posed by this dataset. We release this dataset with 5.3k documents and 38kparagraphs with 3.2k unique entities as a challenge in entity sentiment analysis.</abstract>
      <url hash="f92c3beb">2020.coling-main.52</url>
    </paper>
    <paper id="53">
      <title>Modeling Local Contexts for Joint Dialogue Act Recognition and Sentiment Classification with Bi-channel Dynamic Convolutions</title>
      <author><first>Jingye</first><last>Li</last></author>
      <author><first>Hao</first><last>Fei</last></author>
      <author><first>Donghong</first><last>Ji</last></author>
      <pages>616–626</pages>
      <abstract>In this paper, we target improving the joint dialogue act recognition (DAR) and sentiment classification (SC) tasks by fully modeling the local contexts of utterances. First, we employ the dynamic convolution network (DCN) as the utterance encoder to capture the dialogue contexts. Further, we propose a novel context-aware dynamic convolution network (CDCN) to better leverage the local contexts when dynamically generating kernels. We extended our frameworks into bi-channel version (i.e., BDCN and BCDCN) under multi-task learning to achieve the joint DAR and SC. Two channels can learn their own feature representations for DAR and SC, respectively, but with latent interaction. Besides, we suggest enhancing the tasks by employing the DiaBERT language model. Our frameworks obtain state-of-the-art performances against all baselines on two benchmark datasets, demonstrating the importance of modeling the local contexts.</abstract>
      <url hash="a59a854b">2020.coling-main.53</url>
    </paper>
    <paper id="54">
      <title>Named Entity Recognition for <fixed-case>C</fixed-case>hinese biomedical patents</title>
      <author><first>Yuting</first><last>Hu</last></author>
      <author><first>Suzan</first><last>Verberne</last></author>
      <pages>627–637</pages>
      <abstract>There is a large body of work on Biomedical Entity Recognition (Bio-NER) for English but there have only been a few attempts addressing NER for Chinese biomedical texts. Because of the growing amount of Chinese biomedical discoveries being patented, and lack of NER models for patent data, we train and evaluate NER models for the analysis of Chinese biomedical patent data, based on BERT. By doing so, we show the value and potential of this domain-specific NER task. For the evaluation of our methods we built our own Chinese biomedical patents NER dataset, and our optimized model achieved an F1 score of 0.54±0.15. Further biomedical analysis indicates that our solution can help detecting meaningful biomedical entities and novel gene-gene interactions, with limited labeled data, training time and computing power.</abstract>
      <url hash="2c18b221">2020.coling-main.54</url>
    </paper>
    <paper id="55">
      <title>Learning Health-Bots from Training Data that was Automatically Created using Paraphrase Detection and Expert Knowledge</title>
      <author><first>Anna</first><last>Liednikova</last></author>
      <author><first>Philippe</first><last>Jolivet</last></author>
      <author><first>Alexandre</first><last>Durand-Salmon</last></author>
      <author><first>Claire</first><last>Gardent</last></author>
      <pages>638–648</pages>
      <abstract>A key bottleneck for developing dialog models is the lack of adequate training data. Due to privacy issues, dialog data is even scarcer in the health domain. We propose a novel method for creating dialog corpora which we apply to create doctor-patient interaction data. We use this data to learn both a generation and a hybrid classification/retrieval model and find that the generation model consistently outperforms the hybrid model. We show that our data creation method has several advantages. Not only does it allow for the semi-automatic creation of large quantities of training data. It also provides a natural way of guiding learning and a novel method for assessing the quality of human-machine interactions.</abstract>
      <url hash="84784b0f">2020.coling-main.55</url>
    </paper>
    <paper id="56">
      <title>A Joint Learning Approach based on Self-Distillation for Keyphrase Extraction from Scientific Documents</title>
      <author><first>Tuan</first><last>Lai</last></author>
      <author><first>Trung</first><last>Bui</last></author>
      <author><first>Doo Soon</first><last>Kim</last></author>
      <author><first>Quan Hung</first><last>Tran</last></author>
      <pages>649–656</pages>
      <abstract>Keyphrase extraction is the task of extracting a small set of phrases that best describe a document. Most existing benchmark datasets for the task typically have limited numbers of annotated documents, making it challenging to train increasingly complex neural networks. In contrast, digital libraries store millions of scientific articles online, covering a wide range of topics. While a significant portion of these articles contain keyphrases provided by their authors, most other articles lack such kind of annotations. Therefore, to effectively utilize these large amounts of unlabeled articles, we propose a simple and efficient joint learning approach based on the idea of self-distillation. Experimental results show that our approach consistently improves the performance of baseline models for keyphrase extraction. Furthermore, our best models outperform previous methods for the task, achieving new state-of-the-art results on two public benchmarks: Inspec and SemEval-2017.</abstract>
      <url hash="6dbfdb10">2020.coling-main.56</url>
    </paper>
    <paper id="57">
      <title>Enhancing Clinical <fixed-case>BERT</fixed-case> Embedding using a Biomedical Knowledge Base</title>
      <author><first>Boran</first><last>Hao</last></author>
      <author><first>Henghui</first><last>Zhu</last></author>
      <author><first>Ioannis</first><last>Paschalidis</last></author>
      <pages>657–661</pages>
      <abstract>Domain knowledge is important for building Natural Language Processing (NLP) systems for low-resource settings, such as in the clinical domain. In this paper, a novel joint training method is introduced for adding knowledge base information from the Unified Medical Language System (UMLS) into language model pre-training for some clinical domain corpus. We show that in three different downstream clinical NLP tasks, our pre-trained language model outperforms the corresponding model with no knowledge base information and other state-of-the-art models. Specifically, in a natural language inference task applied to clinical texts, our knowledge base pre-training approach improves accuracy by up to 1.7%, whereas in clinical name entity recognition tasks, the F1-score improves by up to 1.0%. The pre-trained models are available at https://github.com/noc-lab/clinical-kb-bert.</abstract>
      <url hash="afbc70ed">2020.coling-main.57</url>
    </paper>
    <paper id="58">
      <title><fixed-case>TIMBERT</fixed-case>: Toponym Identifier For The Medical Domain Based on <fixed-case>BERT</fixed-case></title>
      <author><first>MohammadReza</first><last>Davari</last></author>
      <author><first>Leila</first><last>Kosseim</last></author>
      <author><first>Tien</first><last>Bui</last></author>
      <pages>662–668</pages>
      <abstract>In this paper, we propose an approach to automate the process of place name detection in the medical domain to enable epidemiologists to better study and model the spread of viruses. We created a family of Toponym Identification Models based on BERT (TIMBERT), in order to learn in an end-to-end fashion the mapping from an input sentence to the associated sentence labeled with toponyms. When evaluated with the SemEval 2019 task 12 test set (Weissenbacher et al., 2019), our best TIMBERT model achieves an F1 score of 90.85%, a significant improvement compared to the state-of-the-art of 89.13% (Wang et al., 2019).</abstract>
      <url hash="f92ae49c">2020.coling-main.58</url>
    </paper>
    <paper id="59">
      <title><fixed-case>B</fixed-case>io<fixed-case>M</fixed-case>ed<fixed-case>BERT</fixed-case>: A Pre-trained Biomedical Language Model for <fixed-case>QA</fixed-case> and <fixed-case>IR</fixed-case></title>
      <author><first>Souradip</first><last>Chakraborty</last></author>
      <author><first>Ekaba</first><last>Bisong</last></author>
      <author><first>Shweta</first><last>Bhatt</last></author>
      <author><first>Thomas</first><last>Wagner</last></author>
      <author><first>Riley</first><last>Elliott</last></author>
      <author><first>Francesco</first><last>Mosconi</last></author>
      <pages>669–679</pages>
      <abstract>The SARS-CoV-2 (COVID-19) pandemic spotlighted the importance of moving quickly with biomedical research. However, as the number of biomedical research papers continue to increase, the task of finding relevant articles to answer pressing questions has become significant. In this work, we propose a textual data mining tool that supports literature search to accelerate the work of researchers in the biomedical domain. We achieve this by building a neural-based deep contextual understanding model for Question-Answering (QA) and Information Retrieval (IR) tasks. We also leverage the new BREATHE dataset which is one of the largest available datasets of biomedical research literature, containing abstracts and full-text articles from ten different biomedical literature sources on which we pre-train our BioMedBERT model. Our work achieves state-of-the-art results on the QA fine-tuning task on BioASQ 5b, 6b and 7b datasets. In addition, we observe superior relevant results when BioMedBERT embeddings are used with Elasticsearch for the Information Retrieval task on the intelligently formulated BioASQ dataset. We believe our diverse dataset and our unique model architecture are what led us to achieve the state-of-the-art results for QA and IR tasks.</abstract>
      <url hash="ef15b2db">2020.coling-main.59</url>
    </paper>
    <paper id="60">
      <title>Extracting Adherence Information from Electronic Health Records</title>
      <author><first>Jordan</first><last>Sanders</last></author>
      <author><first>Meghana</first><last>Gudala</last></author>
      <author><first>Kathleen</first><last>Hamilton</last></author>
      <author><first>Nishtha</first><last>Prasad</last></author>
      <author><first>Jordan</first><last>Stovall</last></author>
      <author><first>Eduardo</first><last>Blanco</last></author>
      <author><first>Jane E</first><last>Hamilton</last></author>
      <author><first>Kirk</first><last>Roberts</last></author>
      <pages>680–695</pages>
      <abstract>Patient adherence is a critical factor in health outcomes. We present a framework to extract adherence information from electronic health records, including both sentence-level information indicating general adherence information (full, partial, none, etc.) and span-level information providing additional information such as adherence type (medication or nonmedication), reasons and outcomes. We annotate and make publicly available a new corpus of 3,000 de-identified sentences, and discuss the language physicians use to document adherence information. We also explore models based on state-of-the-art transformers to automate both tasks.</abstract>
      <url hash="3ec8a245">2020.coling-main.60</url>
    </paper>
    <paper id="61">
      <title>Identifying Depressive Symptoms from Tweets: Figurative Language Enabled Multitask Learning Framework</title>
      <author><first>Shweta</first><last>Yadav</last></author>
      <author><first>Jainish</first><last>Chauhan</last></author>
      <author><first>Joy Prakash</first><last>Sain</last></author>
      <author><first>Krishnaprasad</first><last>Thirunarayan</last></author>
      <author><first>Amit</first><last>Sheth</last></author>
      <author><first>Jeremiah</first><last>Schumm</last></author>
      <pages>696–709</pages>
      <abstract>Existing studies on using social media for deriving mental health status of users focus on the depression detection task. However, for case management and referral to psychiatrists, health-care workers require practical and scalable depressive disorder screening and triage system. This study aims to design and evaluate a decision support system (DSS) to reliably determine the depressive triage level by capturing fine-grained depressive symptoms expressed in user tweets through the emulation of the Patient Health Questionnaire-9 (PHQ-9) that is routinely used in clinical practice. The reliable detection of depressive symptoms from tweets is challenging because the 280-character limit on tweets incentivizes the use of creative artifacts in the utterances and figurative usage contributes to effective expression. We propose a novel BERT based robust multi-task learning framework to accurately identify the depressive symptoms using the auxiliary task of figurative usage detection. Specifically, our proposed novel task sharing mechanism,co-task aware attention, enables automatic selection of optimal information across the BERT lay-ers and tasks by soft-sharing of parameters. Our results show that modeling figurative usage can demonstrably improve the model’s robustness and reliability for distinguishing the depression symptoms.</abstract>
      <url hash="72145aa8">2020.coling-main.61</url>
    </paper>
    <paper id="62">
      <title><fixed-case>F</fixed-case>rench Biomedical Text Simplification: When Small and Precise Helps</title>
      <author><first>Rémi</first><last>Cardon</last></author>
      <author><first>Natalia</first><last>Grabar</last></author>
      <pages>710–716</pages>
      <abstract>We present experiments on biomedical text simplification in French. We use two kinds of corpora – parallel sentences extracted from existing health comparable corpora in French and WikiLarge corpus translated from English to French – and a lexicon that associates medical terms with paraphrases. Then, we train neural models on these parallel corpora using different ratios of general and specialized sentences. We evaluate the results with BLEU, SARI and Kandel scores. The results point out that little specialized data helps significantly the simplification.</abstract>
      <url hash="a36980c5">2020.coling-main.62</url>
    </paper>
    <paper id="63">
      <title>Summarizing Medical Conversations via Identifying Important Utterances</title>
      <author><first>Yan</first><last>Song</last></author>
      <author><first>Yuanhe</first><last>Tian</last></author>
      <author><first>Nan</first><last>Wang</last></author>
      <author><first>Fei</first><last>Xia</last></author>
      <pages>717–729</pages>
      <abstract>Summarization is an important natural language processing (NLP) task in identifying key information from text. For conversations, the summarization systems need to extract salient contents from spontaneous utterances by multiple speakers. In a special task-oriented scenario, namely medical conversations between patients and doctors, the symptoms, diagnoses, and treatments could be highly important because the nature of such conversation is to find a medical solution to the problem proposed by the patients. Especially consider that current online medical platforms provide millions of public available conversations between real patients and doctors, where the patients propose their medical problems and the registered doctors offer diagnosis and treatment, a conversation in most cases could be too long and the key information is hard to be located. Therefore, summarizations to the patients’ problems and the doctors’ treatments in the conversations can be highly useful, in terms of helping other patients with similar problems have a precise reference for potential medical solutions. In this paper, we focus on medical conversation summarization, using a dataset of medical conversations and corresponding summaries which were crawled from a well-known online healthcare service provider in China. We propose a hierarchical encoder-tagger model (HET) to generate summaries by identifying important utterances (with respect to problem proposing and solving) in the conversations. For the particular dataset used in this study, we show that high-quality summaries can be generated by extracting two types of utterances, namely, problem statements and treatment recommendations. Experimental results demonstrate that HET outperforms strong baselines and models from previous studies, and adding conversation-related features can further improve system performance.</abstract>
      <url hash="d7fc8166">2020.coling-main.63</url>
    </paper>
    <paper id="64">
      <title>Probing Multimodal Embeddings for Linguistic Properties: the Visual-Semantic Case</title>
      <author><first>Adam</first><last>Dahlgren Lindström</last></author>
      <author><first>Johanna</first><last>Björklund</last></author>
      <author><first>Suna</first><last>Bensch</last></author>
      <author><first>Frank</first><last>Drewes</last></author>
      <pages>730–744</pages>
      <abstract>Semantic embeddings have advanced the state of the art for countless natural language processing tasks, and various extensions to multimodal domains, such as visual-semantic embeddings, have been proposed. While the power of visual-semantic embeddings comes from the distillation and enrichment of information through machine learning, their inner workings are poorly understood and there is a shortage of analysis tools. To address this problem, we generalize the notion ofprobing tasks to the visual-semantic case. To this end, we (i) discuss the formalization of probing tasks for embeddings of image-caption pairs, (ii) define three concrete probing tasks within our general framework, (iii) train classifiers to probe for those properties, and (iv) compare various state-of-the-art embeddings under the lens of the proposed probing tasks. Our experiments reveal an up to 16% increase in accuracy on visual-semantic embeddings compared to the corresponding unimodal embeddings, which suggest that the text and image dimensions represented in the former do complement each other.</abstract>
      <url hash="36f9d8a0">2020.coling-main.64</url>
    </paper>
    <paper id="65">
      <title>Linguistic Profiling of a Neural Language Model</title>
      <author><first>Alessio</first><last>Miaschi</last></author>
      <author><first>Dominique</first><last>Brunato</last></author>
      <author><first>Felice</first><last>Dell’Orletta</last></author>
      <author><first>Giulia</first><last>Venturi</last></author>
      <pages>745–756</pages>
      <abstract>In this paper we investigate the linguistic knowledge learned by a Neural Language Model (NLM) before and after a fine-tuning process and how this knowledge affects its predictions during several classification problems. We use a wide set of probing tasks, each of which corresponds to a distinct sentence-level feature extracted from different levels of linguistic annotation. We show that BERT is able to encode a wide range of linguistic characteristics, but it tends to lose this information when trained on specific downstream tasks. We also find that BERT’s capacity to encode different kind of linguistic properties has a positive influence on its predictions: the more it stores readable linguistic information of a sentence, the higher will be its capacity of predicting the expected label assigned to that sentence.</abstract>
      <url hash="12e9bbbd">2020.coling-main.65</url>
    </paper>
    <paper id="66">
      <title><fixed-case>I</fixed-case>ndo<fixed-case>LEM</fixed-case> and <fixed-case>I</fixed-case>ndo<fixed-case>BERT</fixed-case>: A Benchmark Dataset and Pre-trained Language Model for <fixed-case>I</fixed-case>ndonesian <fixed-case>NLP</fixed-case></title>
      <author><first>Fajri</first><last>Koto</last></author>
      <author><first>Afshin</first><last>Rahimi</last></author>
      <author><first>Jey Han</first><last>Lau</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <pages>757–770</pages>
      <abstract>Although the Indonesian language is spoken by almost 200 million people and the 10th most spoken language in the world, it is under-represented in NLP research. Previous work on Indonesian has been hampered by a lack of annotated datasets, a sparsity of language resources, and a lack of resource standardization. In this work, we release the IndoLEM dataset comprising seven tasks for the Indonesian language, spanning morpho-syntax, semantics, and discourse. We additionally release IndoBERT, a new pre-trained language model for Indonesian, and evaluate it over IndoLEM, in addition to benchmarking it against existing resources. Our experiments show that IndoBERT achieves state-of-the-art performance over most of the tasks in IndoLEM.</abstract>
      <url hash="ba234f32">2020.coling-main.66</url>
    </paper>
    <paper id="67">
      <title>A Closer Look at Linguistic Knowledge in Masked Language Models: The Case of Relative Clauses in <fixed-case>A</fixed-case>merican <fixed-case>E</fixed-case>nglish</title>
      <author><first>Marius</first><last>Mosbach</last></author>
      <author><first>Stefania</first><last>Degaetano-Ortlieb</last></author>
      <author><first>Marie-Pauline</first><last>Krielke</last></author>
      <author><first>Badr M.</first><last>Abdullah</last></author>
      <author><first>Dietrich</first><last>Klakow</last></author>
      <pages>771–787</pages>
      <abstract>Transformer-based language models achieve high performance on various tasks, but we still lack understanding of the kind of linguistic knowledge they learn and rely on. We evaluate three models (BERT, RoBERTa, and ALBERT), testing their grammatical and semantic knowledge by sentence-level probing, diagnostic cases, and masked prediction tasks. We focus on relative clauses (in American English) as a complex phenomenon needing contextual information and antecedent identification to be resolved. Based on a naturalistic dataset, probing shows that all three models indeed capture linguistic knowledge about grammaticality, achieving high performance.Evaluation on diagnostic cases and masked prediction tasks considering fine-grained linguistic knowledge, however, shows pronounced model-specific weaknesses especially on semantic knowledge, strongly impacting models’ performance. Our results highlight the importance of (a)model comparison in evaluation task and (b) building up claims of model performance and the linguistic knowledge they capture beyond purely probing-based evaluations.</abstract>
      <url hash="044b483d">2020.coling-main.67</url>
    </paper>
    <paper id="68">
      <title>Modeling language evolution and feature dynamics in a realistic geographic environment</title>
      <author><first>Rhea</first><last>Kapur</last></author>
      <author><first>Phillip</first><last>Rogers</last></author>
      <pages>788–798</pages>
      <abstract>Recent, innovative efforts to understand the uneven distribution of languages and linguistic feature values in time and space attest to both the challenge these issues pose and the value in solving them. In this paper, we introduce a model for simulating languages and their features over time in a realistic geographic environment. At its core is a model of language phylogeny and migration whose parameters are chosen to reproduce known language family sizes and geographic dispersions. This foundation in turn is used to explore the dynamics of linguistic features. Languages are assigned feature values that can change randomly or under the influence of nearby languages according to predetermined probabilities. We assess the effects of these settings on resulting geographic and genealogical patterns using homogeneity measures defined in the literature. The resulting model is both flexible and realistic, and it can be employed to answer a wide range of related questions.</abstract>
      <url hash="3bb7af25">2020.coling-main.68</url>
    </paper>
    <paper id="69">
      <title>Syntax-Aware Graph Attention Network for Aspect-Level Sentiment Classification</title>
      <author><first>Lianzhe</first><last>Huang</last></author>
      <author><first>Xin</first><last>Sun</last></author>
      <author><first>Sujian</first><last>Li</last></author>
      <author><first>Linhao</first><last>Zhang</last></author>
      <author><first>Houfeng</first><last>Wang</last></author>
      <pages>799–810</pages>
      <abstract>Aspect-level sentiment classification aims to distinguish the sentiment polarities over aspect terms in a sentence. Existing approaches mostly focus on modeling the relationship between the given aspect words and their contexts with attention, and ignore the use of more elaborate knowledge implicit in the context. In this paper, we exploit syntactic awareness to the model by the graph attention network on the dependency tree structure and external pre-training knowledge by BERT language model, which helps to model the interaction between the context and aspect words better. And the subwords of BERT are integrated into the dependency tree graphs, which can obtain more accurate representations of words by graph attention. Experiments demonstrate the effectiveness of our model.</abstract>
      <url hash="5081e327">2020.coling-main.69</url>
    </paper>
    <paper id="70">
      <title>Attention Transfer Network for Aspect-level Sentiment Classification</title>
      <author><first>Fei</first><last>Zhao</last></author>
      <author><first>Zhen</first><last>Wu</last></author>
      <author><first>Xinyu</first><last>Dai</last></author>
      <pages>811–821</pages>
      <abstract>Aspect-level sentiment classification (ASC) aims to detect the sentiment polarity of a given opinion target in a sentence. In neural network-based methods for ASC, most works employ the attention mechanism to capture the corresponding sentiment words of the opinion target, then aggregate them as evidence to infer the sentiment of the target. However, aspect-level datasets are all relatively small-scale due to the complexity of annotation. Data scarcity causes the attention mechanism sometimes to fail to focus on the corresponding sentiment words of the target, which finally weakens the performance of neural models. To address the issue, we propose a novel Attention Transfer Network (ATN) in this paper, which can successfully exploit attention knowledge from resource-rich document-level sentiment classification datasets to improve the attention capability of the aspect-level sentiment classification task. In the ATN model, we design two different methods to transfer attention knowledge and conduct experiments on two ASC benchmark datasets. Extensive experimental results show that our methods consistently outperform state-of-the-art works. Further analysis also validates the effectiveness of ATN.</abstract>
      <url hash="a011723c">2020.coling-main.70</url>
    </paper>
    <paper id="71">
      <title>Label Correction Model for Aspect-based Sentiment Analysis</title>
      <author><first>Qianlong</first><last>Wang</last></author>
      <author><first>Jiangtao</first><last>Ren</last></author>
      <pages>822–832</pages>
      <abstract>Aspect-based sentiment analysis includes opinion aspect extraction and aspect sentiment classification. Researchers have attempted to discover the relationship between these two sub-tasks and have proposed the joint model for solving aspect-based sentiment analysis. However, they ignore a phenomenon: aspect boundary label and sentiment label of the same word can correct each other. To exploit this phenomenon, we propose a novel deep learning model named the label correction model. Specifically, given an input sentence, our model first predicts the aspect boundary label sequence and sentiment label sequence, then re-predicts the aspect boundary (sentiment) label sequence using the embeddings of the previously predicted sentiment (aspect boundary) label. The goal of the re-prediction operation (can be repeated multiple times) is to use the information of the sentiment (aspect boundary) label to correct the wrong aspect boundary (sentiment) label. Moreover, we explore two ways of using label embeddings: add and gate mechanism. We evaluate our model on three benchmark datasets. Experimental results verify that our model achieves state-of-the-art performance compared with several baselines.</abstract>
      <url hash="7e3cdcfe">2020.coling-main.71</url>
    </paper>
    <paper id="72">
      <title>Aspect-Category based Sentiment Analysis with Hierarchical Graph Convolutional Network</title>
      <author><first>Hongjie</first><last>Cai</last></author>
      <author><first>Yaofeng</first><last>Tu</last></author>
      <author><first>Xiangsheng</first><last>Zhou</last></author>
      <author><first>Jianfei</first><last>Yu</last></author>
      <author><first>Rui</first><last>Xia</last></author>
      <pages>833–843</pages>
      <abstract>Most of the aspect based sentiment analysis research aims at identifying the sentiment polarities toward some explicit aspect terms while ignores implicit aspects in text. To capture both explicit and implicit aspects, we focus on aspect-category based sentiment analysis, which involves joint aspect category detection and category-oriented sentiment classification. However, currently only a few simple studies have focused on this problem. The shortcomings in the way they defined the task make their approaches difficult to effectively learn the inner-relations between categories and the inter-relations between categories and sentiments. In this work, we re-formalize the task as a category-sentiment hierarchy prediction problem, which contains a hierarchy output structure to first identify multiple aspect categories in a piece of text, and then predict the sentiment for each of the identified categories. Specifically, we propose a Hierarchical Graph Convolutional Network (Hier-GCN), where a lower-level GCN is to model the inner-relations among multiple categories, and the higher-level GCN is to capture the inter-relations between aspect categories and sentiments. Extensive evaluations demonstrate that our hierarchy output structure is superior over existing ones, and the Hier-GCN model can consistently achieve the best results on four benchmarks.</abstract>
      <url hash="228d9e7b">2020.coling-main.72</url>
    </paper>
    <paper id="73">
      <title>Constituency Lattice Encoding for Aspect Term Extraction</title>
      <author><first>Yunyi</first><last>Yang</last></author>
      <author><first>Kun</first><last>Li</last></author>
      <author><first>Xiaojun</first><last>Quan</last></author>
      <author><first>Weizhou</first><last>Shen</last></author>
      <author><first>Qinliang</first><last>Su</last></author>
      <pages>844–855</pages>
      <abstract>One of the remaining challenges for aspect term extraction in sentiment analysis resides in the extraction of phrase-level aspect terms, which is non-trivial to determine the boundaries of such terms. In this paper, we aim to address this issue by incorporating the span annotations of constituents of a sentence to leverage the syntactic information in neural network models. To this end, we first construct a constituency lattice structure based on the constituents of a constituency tree. Then, we present two approaches to encoding the constituency lattice using BiLSTM-CRF and BERT as the base models, respectively. We experimented on two benchmark datasets to evaluate the two models, and the results confirm their superiority with respective 3.17 and 1.35 points gained in F1-Measure over the current state of the art. The improvements justify the effectiveness of the constituency lattice for aspect term extraction.</abstract>
      <url hash="c638a7d8">2020.coling-main.73</url>
    </paper>
    <paper id="74">
      <title>A Corpus for Argumentative Writing Support in <fixed-case>G</fixed-case>erman</title>
      <author><first>Thiemo</first><last>Wambsganss</last></author>
      <author><first>Christina</first><last>Niklaus</last></author>
      <author><first>Matthias</first><last>Söllner</last></author>
      <author><first>Siegfried</first><last>Handschuh</last></author>
      <author><first>Jan Marco</first><last>Leimeister</last></author>
      <pages>856–869</pages>
      <abstract>In this paper, we present a novel annotation approach to capture claims and premises of arguments and their relations in student-written persuasive peer reviews on business models in German language. We propose an annotation scheme based on annotation guidelines that allows to model claims and premises as well as support and attack relations for capturing the structure of argumentative discourse in student-written peer reviews. We conduct an annotation study with three annotators on 50 persuasive essays to evaluate our annotation scheme. The obtained inter-rater agreement of α = 0.57 for argument components and α = 0.49 for argumentative relations indicates that the proposed annotation scheme successfully guides annotators to moderate agreement. Finally, we present our freely available corpus of 1,000 persuasive student-written peer reviews on business models and our annotation guidelines to encourage future research on the design and development of argumentative writing support systems for students.</abstract>
      <url hash="827e8fe8">2020.coling-main.74</url>
    </paper>
    <paper id="75">
      <title>Do Word Embeddings Capture Spelling Variation?</title>
      <author><first>Dong</first><last>Nguyen</last></author>
      <author><first>Jack</first><last>Grieve</last></author>
      <pages>870–881</pages>
      <abstract>Analyses of word embeddings have primarily focused on semantic and syntactic properties. However, word embeddings have the potential to encode other properties as well. In this paper, we propose a new perspective on the analysis of word embeddings by focusing on spelling variation. In social media, spelling variation is abundant and often socially meaningful. Here, we analyze word embeddings trained on Twitter and Reddit data. We present three analyses using pairs of word forms covering seven types of spelling variation in English. Taken together, our results show that word embeddings encode spelling variation patterns of various types to some extent, even embeddings trained using the skipgram model which does not take spelling into account. Our results also suggest a link between the intentionality of the variation and the distance of the non-conventional spellings to their conventional spellings.</abstract>
      <url hash="98a9ce97">2020.coling-main.75</url>
    </paper>
    <paper id="76">
      <title>Don’t take “nswvtnvakgxpm” for an answer –The surprising vulnerability of automatic content scoring systems to adversarial input</title>
      <author><first>Yuning</first><last>Ding</last></author>
      <author><first>Brian</first><last>Riordan</last></author>
      <author><first>Andrea</first><last>Horbach</last></author>
      <author><first>Aoife</first><last>Cahill</last></author>
      <author><first>Torsten</first><last>Zesch</last></author>
      <pages>882–892</pages>
      <abstract>Automatic content scoring systems are widely used on short answer tasks to save human effort. However, the use of these systems can invite cheating strategies, such as students writing irrelevant answers in the hopes of gaining at least partial credit. We generate adversarial answers for benchmark content scoring datasets based on different methods of increasing sophistication and show that even simple methods lead to a surprising decrease in content scoring performance. As an extreme example, up to 60% of adversarial answers generated from random shuffling of words in real answers are accepted by a state-of-the-art scoring system. In addition to analyzing the vulnerabilities of content scoring systems, we examine countermeasures such as adversarial training and show that these measures improve system robustness against adversarial answers considerably but do not suffice to completely solve the problem.</abstract>
      <url hash="1e262d9b">2020.coling-main.76</url>
    </paper>
    <paper id="77">
      <title>Automated Prediction of Examinee Proficiency from Short-Answer Questions</title>
      <author><first>Le An</first><last>Ha</last></author>
      <author><first>Victoria</first><last>Yaneva</last></author>
      <author><first>Polina</first><last>Harik</last></author>
      <author><first>Ravi</first><last>Pandian</last></author>
      <author><first>Amy</first><last>Morales</last></author>
      <author><first>Brian</first><last>Clauser</last></author>
      <pages>893–903</pages>
      <abstract>This paper brings together approaches from the fields of NLP and psychometric measurement to address the problem of predicting examinee proficiency from responses to short-answer questions (SAQs). While previous approaches train on manually labeled data to predict the human-ratings assigned to SAQ responses, the approach presented here models examinee proficiency directly and does not require manually labeled data to train on. We use data from a large medical exam where experimental SAQ items are embedded alongside 106 scored multiple-choice questions (MCQs). First, the latent trait of examinee proficiency is measured using the scored MCQs and then a model is trained on the experimental SAQ responses as input, aiming to predict proficiency as its target variable. The predicted value is then used as a “score” for the SAQ response and evaluated in terms of its contribution to the precision of proficiency estimation.</abstract>
      <url hash="032ea910">2020.coling-main.77</url>
    </paper>
    <paper id="78">
      <title>Exploring Cross-sentence Contexts for Named Entity Recognition with <fixed-case>BERT</fixed-case></title>
      <author><first>Jouni</first><last>Luoma</last></author>
      <author><first>Sampo</first><last>Pyysalo</last></author>
      <pages>904–914</pages>
      <abstract>Named entity recognition (NER) is frequently addressed as a sequence classification task with each input consisting of one sentence of text. It is nevertheless clear that useful information for NER is often found also elsewhere in text. Recent self-attention models like BERT can both capture long-distance relationships in input and represent inputs consisting of several sentences. This creates opportunities for adding cross-sentence information in natural language processing tasks. This paper presents a systematic study exploring the use of cross-sentence information for NER using BERT models in five languages. We find that adding context as additional sentences to BERT input systematically increases NER performance. Multiple sentences in input samples allows us to study the predictions of the sentences in different contexts. We propose a straightforward method, Contextual Majority Voting (CMV), to combine these different predictions and demonstrate this to further increase NER performance. Evaluation on established datasets, including the CoNLL’02 and CoNLL’03 NER benchmarks, demonstrates that our proposed approach can improve on the state-of-the-art NER results on English, Dutch, and Finnish, achieves the best reported BERT-based results on German, and is on par with other BERT-based approaches in Spanish. We release all methods implemented in this work under open licenses.</abstract>
      <url hash="390f87d5">2020.coling-main.78</url>
    </paper>
    <paper id="79">
      <title>Cross-lingual Annotation Projection in Legal Texts</title>
      <author><first>Andrea</first><last>Galassi</last></author>
      <author><first>Kasper</first><last>Drazewski</last></author>
      <author><first>Marco</first><last>Lippi</last></author>
      <author><first>Paolo</first><last>Torroni</last></author>
      <pages>915–926</pages>
      <abstract>We study annotation projection in text classification problems where source documents are published in multiple languages and may not be an exact translation of one another. In particular, we focus on the detection of unfair clauses in privacy policies and terms of service. We present the first English-German parallel asymmetric corpus for the task at hand. We study and compare several language-agnostic sentence-level projection methods. Our results indicate that a combination of word embeddings and dynamic time warping performs best.</abstract>
      <url hash="4a3e9c07">2020.coling-main.79</url>
    </paper>
    <paper id="80">
      <title>Deep Learning Framework for Measuring the Digital Strategy of Companies from Earnings Calls</title>
      <author><first>Ahmed Ghanim</first><last>Al-Ali</last></author>
      <author><first>Robert</first><last>Phaal</last></author>
      <author><first>Donald</first><last>Sull</last></author>
      <pages>927–935</pages>
      <abstract>Companies today are racing to leverage the latest digital technologies, such as artificial intelligence, blockchain, and cloud computing. However, many companies report that their strategies did not achieve the anticipated business results. This study is the first to apply state-of-the-art NLP models on unstructured data to understand the different clusters of digital strategy patterns that companies are Adopting. We achieve this by ana-lyzing earnings calls from Fortune’s Global 500 companies between 2015 and 2019. We use Transformer-based architecture for text classification which show a better understanding of the conversation context. We then investigate digital strategy patterns by applying clustering analysis. Our findings suggest that Fortune 500 companies use four distinct strategies which are product-led, customer experience-led, service-led, and efficiency-led . This work provides an empirical baseline for companies and researchers to enhance our understanding of the field.</abstract>
      <url hash="7c32d1a5">2020.coling-main.80</url>
    </paper>
    <paper id="81">
      <title>A Dataset and Evaluation Framework for Complex Geographical Description Parsing</title>
      <author><first>Egoitz</first><last>Laparra</last></author>
      <author><first>Steven</first><last>Bethard</last></author>
      <pages>936–948</pages>
      <abstract>Much previous work on geoparsing has focused on identifying and resolving individual toponyms in text like Adrano, S.Maria di Licodia or Catania. However, geographical locations occur not only as individual toponyms, but also as compositions of reference geolocations joined and modified by connectives, e.g., “. . . between the towns of Adrano and S.Maria di Licodia, 32 kilometres northwest of Catania”. Ideally, a geoparser should be able to take such text, and the geographical shapes of the toponyms referenced within it, and parse these into a geographical shape, formed by a set of coordinates, that represents the location described. But creating a dataset for this complex geoparsing task is difficult and, if done manually, would require a huge amount of effort to annotate the geographical shapes of not only the geolocation described but also the reference toponyms. We present an approach that automates most of the process by combining Wikipedia and OpenStreetMap. As a result, we have gathered a collection of 360,187 uncurated complex geolocation descriptions, from which we have manually curated 1,000 examples intended to be used as a test set. To accompany the data, we define a new geoparsing evaluation framework along with a scoring methodology and a set of baselines.</abstract>
      <url hash="c1fe1587">2020.coling-main.81</url>
    </paper>
    <paper id="82">
      <title><fixed-case>D</fixed-case>oc<fixed-case>B</fixed-case>ank: A Benchmark Dataset for Document Layout Analysis</title>
      <author><first>Minghao</first><last>Li</last></author>
      <author><first>Yiheng</first><last>Xu</last></author>
      <author><first>Lei</first><last>Cui</last></author>
      <author><first>Shaohan</first><last>Huang</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <author><first>Zhoujun</first><last>Li</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <pages>949–960</pages>
      <abstract>Document layout analysis usually relies on computer vision models to understand documents while ignoring textual information that is vital to capture. Meanwhile, high quality labeled datasets with both visual and textual information are still insufficient. In this paper, we present DocBank, a benchmark dataset that contains 500K document pages with fine-grained token-level annotations for document layout analysis. DocBank is constructed using a simple yet effective way with weak supervision from the LaTeX documents available on the arXiv.com. With DocBank, models from different modalities can be compared fairly and multi-modal approaches will be further investigated and boost the performance of document layout analysis. We build several strong baselines and manually split train/dev/test sets for evaluation. Experiment results show that models trained on DocBank accurately recognize the layout information for a variety of documents. The DocBank dataset is publicly available at https://github.com/doc-analysis/DocBank.</abstract>
      <url hash="44294285">2020.coling-main.82</url>
    </paper>
    <paper id="83">
      <title>Building Large-Scale <fixed-case>E</fixed-case>nglish and <fixed-case>K</fixed-case>orean Datasets for Aspect-Level Sentiment Analysis in Automotive Domain</title>
      <author><first>Dongmin</first><last>Hyun</last></author>
      <author><first>Junsu</first><last>Cho</last></author>
      <author><first>Hwanjo</first><last>Yu</last></author>
      <pages>961–966</pages>
      <abstract>We release large-scale datasets of users’ comments in two languages, English and Korean, for aspect-level sentiment analysis in automotive domain. The datasets consist of 58,000+ commentaspect pairs, which are the largest compared to existing datasets. In addition, this work covers new language (i.e., Korean) along with English for aspect-level sentiment analysis. We build the datasets from automotive domain to enable users (e.g., marketers in automotive companies) to analyze the voice of customers on automobiles. We also provide baseline performances for future work by evaluating recent models on the released datasets.</abstract>
      <url hash="72215a27">2020.coling-main.83</url>
    </paper>
    <paper id="84">
      <title>A High Precision Pipeline for Financial Knowledge Graph Construction</title>
      <author><first>Sarah</first><last>Elhammadi</last></author>
      <author><first>Laks</first><last>V.S. Lakshmanan</last></author>
      <author><first>Raymond</first><last>Ng</last></author>
      <author><first>Michael</first><last>Simpson</last></author>
      <author><first>Baoxing</first><last>Huai</last></author>
      <author><first>Zhefeng</first><last>Wang</last></author>
      <author><first>Lanjun</first><last>Wang</last></author>
      <pages>967–977</pages>
      <abstract>Motivated by applications such as question answering, fact checking, and data integration, there is significant interest in constructing knowledge graphs by extracting information from unstructured information sources, particularly text documents. Knowledge graphs have emerged as a standard for structured knowledge representation, whereby entities and their inter-relations are represented and conveniently stored as (subject,predicate,object) triples in a graph that can be used to power various downstream applications. The proliferation of financial news sources reporting on companies, markets, currencies, and stocks presents an opportunity for extracting valuable knowledge about this crucial domain. In this paper, we focus on constructing a knowledge graph automatically by information extraction from a large corpus of financial news articles. For that purpose, we develop a high precision knowledge extraction pipeline tailored for the financial domain. This pipeline combines multiple information extraction techniques with a financial dictionary that we built, all working together to produce over 342,000 compact extractions from over 288,000 financial news articles, with a precision of 78% at the top-100 extractions.The extracted triples are stored in a knowledge graph making them readily available for use in downstream applications.</abstract>
      <url hash="eb85f42b">2020.coling-main.84</url>
    </paper>
    <paper id="85">
      <title>Financial Sentiment Analysis: An Investigation into Common Mistakes and Silver Bullets</title>
      <author><first>Frank</first><last>Xing</last></author>
      <author><first>Lorenzo</first><last>Malandri</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <author><first>Erik</first><last>Cambria</last></author>
      <pages>978–987</pages>
      <abstract>The recent dominance of machine learning-based natural language processing methods has fostered the culture of overemphasizing model accuracies rather than studying the reasons behind their errors. Interpretability, however, is a critical requirement for many downstream AI and NLP applications, e.g., in finance, healthcare, and autonomous driving. This study, instead of proposing any “new model”, investigates the error patterns of some widely acknowledged sentiment analysis methods in the finance domain. We discover that (1) those methods belonging to the same clusters are prone to similar error patterns, and (2) there are six types of linguistic features that are pervasive in the common errors. These findings provide important clues and practical considerations for improving sentiment analysis models for financial applications.</abstract>
      <url hash="5f6b37e7">2020.coling-main.85</url>
    </paper>
    <paper id="86">
      <title>Answering Legal Questions by Learning Neural Attentive Text Representation</title>
      <author><first>Phi Manh</first><last>Kien</last></author>
      <author><first>Ha-Thanh</first><last>Nguyen</last></author>
      <author><first>Ngo Xuan</first><last>Bach</last></author>
      <author><first>Vu</first><last>Tran</last></author>
      <author><first>Minh Le</first><last>Nguyen</last></author>
      <author><first>Tu Minh</first><last>Phuong</last></author>
      <pages>988–998</pages>
      <abstract>Text representation plays a vital role in retrieval-based question answering, especially in the legal domain where documents are usually long and complicated. The better the question and the legal documents are represented, the more accurate they are matched. In this paper, we focus on the task of answering legal questions at the article level. Given a legal question, the goal is to retrieve all the correct and valid legal articles, that can be used as the basic to answer the question. We present a retrieval-based model for the task by learning neural attentive text representation. Our text representation method first leverages convolutional neural networks to extract important information in a question and legal articles. Attention mechanisms are then used to represent the question and articles and select appropriate information to align them in a matching process. Experimental results on an annotated corpus consisting of 5,922 Vietnamese legal questions show that our model outperforms state-of-the-art retrieval-based methods for question answering by large margins in terms of both recall and NDCG.</abstract>
      <url hash="60de0fc8">2020.coling-main.86</url>
    </paper>
    <paper id="87">
      <title>Joint Transformer/<fixed-case>RNN</fixed-case> Architecture for Gesture Typing in Indic Languages</title>
      <author><first>Emil</first><last>Biju</last></author>
      <author><first>Anirudh</first><last>Sriram</last></author>
      <author><first>Mitesh M.</first><last>Khapra</last></author>
      <author><first>Pratyush</first><last>Kumar</last></author>
      <pages>999–1010</pages>
      <abstract>Gesture typing is a method of typing words on a touch-based keyboard by creating a continuous trace passing through the relevant keys. This work is aimed at developing a keyboard that supports gesture typing in Indic languages. We begin by noting that when dealing with Indic languages, one needs to cater to two different sets of users: (i) users who prefer to type in the native Indic script (Devanagari, Bengali, etc.) and (ii) users who prefer to type in the English script but want the transliterated output in the native script. In both cases, we need a model that takes a trace as input and maps it to the intended word. To enable the development of these models, we create and release two datasets. First, we create a dataset containing keyboard traces for 193,658 words from 7 Indic languages. Second, we curate 104,412 English-Indic transliteration pairs from Wikidata across these languages. Using these datasets we build a model that performs path decoding, transliteration and transliteration correction. Unlike prior approaches, our proposed model does not make co-character independence assumptions during decoding. The overall accuracy of our model across the 7 languages varies from 70-95%.</abstract>
      <url hash="db7ce6ac">2020.coling-main.87</url>
    </paper>
    <paper id="88">
      <title>Automatic Charge Identification from Facts: A Few Sentence-Level Charge Annotations is All You Need</title>
      <author><first>Shounak</first><last>Paul</last></author>
      <author><first>Pawan</first><last>Goyal</last></author>
      <author><first>Saptarshi</first><last>Ghosh</last></author>
      <pages>1011–1022</pages>
      <abstract>Automatic Charge Identification (ACI) is the task of identifying the relevant charges given the facts of a situation and the statutory laws that define these charges, and is a crucial aspect of the judicial process. Existing works focus on learning charge-side representations by modeling relationships between the charges, but not much effort has been made in improving fact-side representations. We observe that only a small fraction of sentences in the facts actually indicates the charges. We show that by using a very small subset (&lt; 3%) of fact descriptions annotated with sentence-level charges, we can achieve an improvement across a range of different ACI models, as compared to modeling just the main document-level task on a much larger dataset. Additionally, we propose a novel model that utilizes sentence-level charge labels as an auxiliary task, coupled with the main task of document-level charge identification in a multi-task learning framework. The proposed model comprehensively outperforms a large number of recent baselines for ACI. The improvement in performance is particularly noticeable for the rare charges which are known to be especially challenging to identify.</abstract>
      <url hash="cadbda1c">2020.coling-main.88</url>
    </paper>
    <paper id="89">
      <title>Context-Aware Text Normalisation for Historical Dialects</title>
      <author><first>Maria</first><last>Sukhareva</last></author>
      <pages>1023–1036</pages>
      <abstract>Context-aware historical text normalisation is a severely under-researched area. To fill the gap we propose a context-aware normalisation approach that relies on the state-of-the-art methods in neural machine translation and transfer learning. We propose a multidialect normaliser with a context-aware reranking of the candidates. The reranker relies on a word-level n-gram language model that is applied to the five best normalisation candidates. The results are evaluated on the historical multidialect datasets of German, Spanish, Portuguese and Slovene. We show that incorporating dialectal information into the training leads to an accuracy improvement on all the datasets. The context-aware reranking gives further improvement over the baseline. For three out of six datasets, we reach a significantly higher accuracy than reported in the previous studies. The other three results are comparable with the current state-of-the-art. The code for the reranker is published as open-source.</abstract>
      <url hash="b2951d1f">2020.coling-main.89</url>
    </paper>
    <paper id="90">
      <title><fixed-case>R</fixed-case>u<fixed-case>S</fixed-case>em<fixed-case>S</fixed-case>hift: a dataset of historical lexical semantic change in <fixed-case>R</fixed-case>ussian</title>
      <author><first>Julia</first><last>Rodina</last></author>
      <author><first>Andrey</first><last>Kutuzov</last></author>
      <pages>1037–1047</pages>
      <abstract>We present RuSemShift, a large-scale manually annotated test set for the task of semantic change modeling in Russian for two long-term time period pairs: from the pre-Soviet through the Soviet times and from the Soviet through the post-Soviet times. Target words were annotated by multiple crowd-source workers. The annotation process was organized following the DURel framework and was based on sentence contexts extracted from the Russian National Corpus. Additionally, we report the performance of several distributional approaches on RuSemShift, achieving promising results, which at the same time leave room for other researchers to improve.</abstract>
      <url hash="80b7ae73">2020.coling-main.90</url>
    </paper>
    <paper id="91">
      <title>Exploring <fixed-case>A</fixed-case>mharic Sentiment Analysis from Social Media Texts: Building Annotation Tools and Classification Models</title>
      <author><first>Seid Muhie</first><last>Yimam</last></author>
      <author><first>Hizkiel Mitiku</first><last>Alemayehu</last></author>
      <author><first>Abinew</first><last>Ayele</last></author>
      <author><first>Chris</first><last>Biemann</last></author>
      <pages>1048–1060</pages>
      <abstract>This paper presents the study of sentiment analysis for Amharic social media texts. As the number of social media users is ever-increasing, social media platforms would like to understand the latent meaning and sentiments of a text to enhance decision-making procedures. However, low-resource languages such as Amharic have received less attention due to several reasons such as lack of well-annotated datasets, unavailability of computing resources, and fewer or no expert researchers in the area. This research addresses three main research questions. We first explore the suitability of existing tools for the sentiment analysis task. Annotation tools are scarce to support large-scale annotation tasks in Amharic. Also, the existing crowdsourcing platforms do not support Amharic text annotation. Hence, we build a social-network-friendly annotation tool called ‘ASAB’ using the Telegram bot. We collect 9.4k tweets, where each tweet is annotated by three Telegram users. Moreover, we explore the suitability of machine learning approaches for Amharic sentiment analysis. The FLAIR deep learning text classifier, based on network embeddings that are computed from a distributional thesaurus, outperforms other supervised classifiers. We further investigate the challenges in building a sentiment analysis system for Amharic and we found that the widespread usage of sarcasm and figurative speech are the main issues in dealing with the problem. To advance the sentiment analysis research in Amharic and other related low-resource languages, we release the dataset, the annotation tool, source code, and models publicly under a permissive.</abstract>
      <url hash="07578b97">2020.coling-main.91</url>
    </paper>
    <paper id="92">
      <title>Effective Few-Shot Classification with Transfer Learning</title>
      <author><first>Aakriti</first><last>Gupta</last></author>
      <author><first>Kapil</first><last>Thadani</last></author>
      <author><first>Neil</first><last>O’Hare</last></author>
      <pages>1061–1066</pages>
      <abstract>Few-shot learning addresses the the problem of learning based on a small amount of training data. Although more well-studied in the domain of computer vision, recent work has adapted the Amazon Review Sentiment Classification (ARSC) text dataset for use in the few-shot setting. In this work, we use the ARSC dataset to study a simple application of transfer learning approaches to few-shot classification. We train a single binary classifier to learn all few-shot classes jointly by prefixing class identifiers to the input text. Given the text and class, the model then makes a binary prediction for that text/class pair. Our results show that this simple approach can outperform most published results on this dataset. Surprisingly, we also show that including domain information as part of the task definition only leads to a modest improvement in model accuracy, and zero-shot classification, without further fine-tuning on few-shot domains, performs equivalently to few-shot classification. These results suggest that the classes in the ARSC few-shot task, which are defined by the intersection of domain and rating, are actually very similar to each other, and that a more suitable dataset is needed for the study of few-shot text classification.</abstract>
      <url hash="49dcc430">2020.coling-main.92</url>
    </paper>
    <paper id="93">
      <title><fixed-case>SWAFN</fixed-case>: Sentimental Words Aware Fusion Network for Multimodal Sentiment Analysis</title>
      <author><first>Minping</first><last>Chen</last></author>
      <author><first>Xia</first><last>Li</last></author>
      <pages>1067–1077</pages>
      <abstract>Multimodal sentiment analysis aims to predict sentiment of language text with the help of other modalities, such as vision and acoustic features. Previous studies focused on learning the joint representation of multiple modalities, ignoring some useful knowledge contained in language modal. In this paper, we try to incorporate sentimental words knowledge into the fusion network to guide the learning of joint representation of multimodal features. Our method consists of two components: shallow fusion part and aggregation part. For the shallow fusion part, we use crossmodal coattention mechanism to obtain bidirectional context information of each two modals to get the fused shallow representations. For the aggregation part, we design a multitask of sentimental words classification to help and guide the deep fusion of the three modalities and obtain the final sentimental words aware fusion representation. We carry out several experiments on CMU-MOSI, CMU-MOSEI and YouTube datasets. The experimental results show that introducing sentimental words prediction as a multitask can really improve the fusion representation of multiple modalities.</abstract>
      <url hash="48c82e3d">2020.coling-main.93</url>
    </paper>
    <paper id="94">
      <title>Multimodal Topic-Enriched Auxiliary Learning for Depression Detection</title>
      <author><first>Minghui</first><last>An</last></author>
      <author><first>Jingjing</first><last>Wang</last></author>
      <author><first>Shoushan</first><last>Li</last></author>
      <author><first>Guodong</first><last>Zhou</last></author>
      <pages>1078–1089</pages>
      <abstract>From the perspective of health psychology, human beings with long-term and sustained negativity are highly possible to be diagnosed with depression. Inspired by this, we argue that the global topic information derived from user-generated contents (e.g., texts and images) is crucial to boost the performance of the depression detection task, though this information has been neglected by almost all previous studies on depression detection. To this end, we propose a new Multimodal Topic-enriched Auxiliary Learning (MTAL) approach, aiming at capturing the topic information inside different modalities (i.e., texts and images) for depression detection. Especially, in our approach, a modality-agnostic topic model is proposed to be capable of mining the topical clues from either the discrete textual signals or the continuous visual signals. On this basis, the topic modeling w.r.t. the two modalities are cast as two auxiliary tasks for improving the performance of the primary task (i.e., depression detection). Finally, the detailed evaluation demonstrates the great advantage of our MTAL approach to depression detection over the state-of-the-art baselines. This justifies the importance of the multimodal topic information to depression detection and the effectiveness of our approach in capturing such information.</abstract>
      <url hash="b444abdc">2020.coling-main.94</url>
    </paper>
    <paper id="95">
      <title>Imagining Grounded Conceptual Representations from Perceptual Information in Situated Guessing Games</title>
      <author><first>Alessandro</first><last>Suglia</last></author>
      <author><first>Antonio</first><last>Vergari</last></author>
      <author><first>Ioannis</first><last>Konstas</last></author>
      <author><first>Yonatan</first><last>Bisk</last></author>
      <author><first>Emanuele</first><last>Bastianelli</last></author>
      <author><first>Andrea</first><last>Vanzo</last></author>
      <author><first>Oliver</first><last>Lemon</last></author>
      <pages>1090–1102</pages>
      <abstract>In visual guessing games, a Guesser has to identify a target object in a scene by asking questions to an Oracle. An effective strategy for the players is to learn conceptual representations of objects that are both discriminative and expressive enough to ask questions and guess correctly. However, as shown by Suglia et al. (2020), existing models fail to learn truly multi-modal representations, relying instead on gold category labels for objects in the scene both at training and inference time. This provides an unnatural performance advantage when categories at inference time match those at training time, and it causes models to fail in more realistic “zero-shot” scenarios where out-of-domain object categories are involved. To overcome this issue, we introduce a novel “imagination” module based on Regularized Auto-Encoders, that learns context-aware and category-aware latent embeddings without relying on category labels at inference time. Our imagination module outperforms state-of-the-art competitors by 8.26% gameplay accuracy in the CompGuessWhat?! zero-shot scenario (Suglia et al., 2020), and it improves the Oracle and Guesser accuracy by 2.08% and 12.86% in the GuessWhat?! benchmark, when no gold categories are available at inference time. The imagination module also boosts reasoning about object properties and attributes.</abstract>
      <url hash="8e0a68c5">2020.coling-main.95</url>
    </paper>
    <paper id="96">
      <title>Situated and Interactive Multimodal Conversations</title>
      <author><first>Seungwhan</first><last>Moon</last></author>
      <author><first>Satwik</first><last>Kottur</last></author>
      <author><first>Paul</first><last>Crook</last></author>
      <author><first>Ankita</first><last>De</last></author>
      <author><first>Shivani</first><last>Poddar</last></author>
      <author><first>Theodore</first><last>Levin</last></author>
      <author><first>David</first><last>Whitney</last></author>
      <author><first>Daniel</first><last>Difranco</last></author>
      <author><first>Ahmad</first><last>Beirami</last></author>
      <author><first>Eunjoon</first><last>Cho</last></author>
      <author><first>Rajen</first><last>Subba</last></author>
      <author><first>Alborz</first><last>Geramifard</last></author>
      <pages>1103–1121</pages>
      <abstract>Next generation virtual assistants are envisioned to handle multimodal inputs (e.g., vision, memories of previous interactions, and the user’s utterances), and perform multimodal actions (, displaying a route while generating the system’s utterance). We introduce Situated Interactive MultiModal Conversations (SIMMC) as a new direction aimed at training agents that take multimodal actions grounded in a co-evolving multimodal input context in addition to the dialog history. We provide two SIMMC datasets totalling ~13K human-human dialogs (~169K utterances) collected using a multimodal Wizard-of-Oz (WoZ) setup, on two shopping domains: (a) furniture – grounded in a shared virtual environment; and (b) fashion – grounded in an evolving set of images. Datasets include multimodal context of the items appearing in each scene, and contextual NLU, NLG and coreference annotations using a novel and unified framework of SIMMC conversational acts for both user and assistant utterances. Finally, we present several tasks within SIMMC as objective evaluation protocols, such as structural API prediction, response generation, and dialog state tracking. We benchmark a collection of existing models on these SIMMC tasks as strong baselines, and demonstrate rich multimodal conversational interactions. Our data, annotations, and models will be made publicly available.</abstract>
      <url hash="cb677a49">2020.coling-main.96</url>
    </paper>
    <paper id="97">
      <title>Meet Changes with Constancy: Learning Invariance in Multi-Source Translation</title>
      <author><first>Jianfeng</first><last>Liu</last></author>
      <author><first>Ling</first><last>Luo</last></author>
      <author><first>Xiang</first><last>Ao</last></author>
      <author><first>Yan</first><last>Song</last></author>
      <author><first>Haoran</first><last>Xu</last></author>
      <author><first>Jian</first><last>Ye</last></author>
      <pages>1122–1132</pages>
      <abstract>Multi-source neural machine translation aims to translate from parallel sources of information (e.g. languages, images, etc.) to a single target language, which has shown better performance than most one-to-one systems. Despite the remarkable success of existing models, they usually neglect the fact that multiple source inputs may have inconsistencies. Such differences might bring noise to the task and limit the performance of existing multi-source NMT approaches due to their indiscriminate usage of input sources for target word predictions. In this paper, we attempt to leverage the potential complementary information among distinct sources and alleviate the occasional conflicts of them. To accomplish that, we propose a source invariance network to learn the invariant information of parallel sources. Such network can be easily integrated with multi-encoder based multi-source NMT methods (e.g. multi-encoder RNN and transformer) to enhance the translation results. Extensive experiments on two multi-source translation tasks demonstrate that the proposed approach not only achieves clear gains in translation quality but also captures implicit invariance between different sources.</abstract>
      <url hash="9b0b537b">2020.coling-main.97</url>
    </paper>
    <paper id="98">
      <title>Enhancing Neural Models with Vulnerability via Adversarial Attack</title>
      <author><first>Rong</first><last>Zhang</last></author>
      <author><first>Qifei</first><last>Zhou</last></author>
      <author><first>Bo</first><last>An</last></author>
      <author><first>Weiping</first><last>Li</last></author>
      <author><first>Tong</first><last>Mo</last></author>
      <author><first>Bo</first><last>Wu</last></author>
      <pages>1133–1146</pages>
      <abstract>Natural Language Sentence Matching (NLSM) serves as the core of many natural language processing tasks. 1) Most previous work develops a single specific neural model for NLSM tasks. 2) There is no previous work considering adversarial attack to improve the performance of NLSM tasks. 3) Adversarial attack is usually used to generate adversarial samples that can fool neural models. In this paper, we first find a phenomenon that different categories of samples have different vulnerabilities. Vulnerability is the difficulty degree in changing the label of a sample. Considering the phenomenon, we propose a general two-stage training framework to enhance neural models with Vulnerability via Adversarial Attack (VAA). We design criteria to measure the vulnerability which is obtained by adversarial attack. VAA framework can be adapted to various neural models by incorporating the vulnerability. In addition, we prove a theorem and four corollaries to explain the factors influencing vulnerability effectiveness. Experimental results show that VAA significantly improves the performance of neural models on NLSM datasets. The results are also consistent with the theorem and corollaries. The code is released on https://github.com/rzhangpku/VAA.</abstract>
      <url hash="794db95e">2020.coling-main.98</url>
    </paper>
    <paper id="99">
      <title><fixed-case>R</fixed-case>-<fixed-case>VGAE</fixed-case>: Relational-variational Graph Autoencoder for Unsupervised Prerequisite Chain Learning</title>
      <author><first>Irene</first><last>Li</last></author>
      <author><first>Alexander</first><last>Fabbri</last></author>
      <author><first>Swapnil</first><last>Hingmire</last></author>
      <author><first>Dragomir</first><last>Radev</last></author>
      <pages>1147–1157</pages>
      <abstract>The task of concept prerequisite chain learning is to automatically determine the existence of prerequisite relationships among concept pairs. In this paper, we frame learning prerequisite relationships among concepts as an unsupervised task with no access to labeled concept pairs during training. We propose a model called the Relational-Variational Graph AutoEncoder (R-VGAE) to predict concept relations within a graph consisting of concept and resource nodes. Results show that our unsupervised approach outperforms graph-based semi-supervised methods and other baseline methods by up to 9.77% and 10.47% in terms of prerequisite relation prediction accuracy and F1 score. Our method is notably the first graph-based model that attempts to make use of deep learning representations for the task of unsupervised prerequisite learning. We also expand an existing corpus which totals 1,717 English Natural Language Processing (NLP)-related lecture slide files and manual concept pair annotations over 322 topics.</abstract>
      <url hash="28cb1dd7">2020.coling-main.99</url>
    </paper>
    <paper id="100">
      <title>Fine-tuning <fixed-case>BERT</fixed-case> for Low-Resource Natural Language Understanding via Active Learning</title>
      <author><first>Daniel</first><last>Grießhaber</last></author>
      <author><first>Johannes</first><last>Maucher</last></author>
      <author><first>Ngoc Thang</first><last>Vu</last></author>
      <pages>1158–1171</pages>
      <abstract>Recently, leveraging pre-trained Transformer based language models in down stream, task specific models has advanced state of the art results in natural language understanding tasks. However, only a little research has explored the suitability of this approach in low resource settings with less than 1,000 training data points. In this work, we explore fine-tuning methods of BERT - a pre-trained Transformer based language model - by utilizing pool-based active learning to speed up training while keeping the cost of labeling new data constant. Our experimental results on the GLUE data set show an advantage in model performance by maximizing the approximate knowledge gain of the model when querying from the pool of unlabeled data. Finally, we demonstrate and analyze the benefits of freezing layers of the language model during fine-tuning to reduce the number of trainable parameters, making it more suitable for low-resource settings.</abstract>
      <url hash="cd3afac8">2020.coling-main.100</url>
    </paper>
    <paper id="101">
      <title>Exploring End-to-End Differentiable Natural Logic Modeling</title>
      <author><first>Yufei</first><last>Feng</last></author>
      <author><first>Zi’ou</first><last>Zheng</last></author>
      <author><first>Quan</first><last>Liu</last></author>
      <author><first>Michael</first><last>Greenspan</last></author>
      <author><first>Xiaodan</first><last>Zhu</last></author>
      <pages>1172–1185</pages>
      <abstract>We explore end-to-end trained differentiable models that integrate natural logic with neural networks, aiming to keep the backbone of natural language reasoning based on the natural logic formalism while introducing subsymbolic vector representations and neural components. The proposed model adapts module networks to model natural logic operations, which is enhanced with a memory component to model contextual information. Experiments show that the proposed framework can effectively model monotonicity-based reasoning, compared to the baseline neural network models without built-in inductive bias for monotonicity-based reasoning. Our proposed model shows to be robust when transferred from upward to downward inference. We perform further analyses on the performance of the proposed model on aggregation, showing the effectiveness of the proposed subcomponents on helping achieve better intermediate aggregation performance.</abstract>
      <url hash="bb67dc09">2020.coling-main.101</url>
    </paper>
    <paper id="102">
      <title>A Semantically Consistent and Syntactically Variational Encoder-Decoder Framework for Paraphrase Generation</title>
      <author><first>Wenqing</first><last>Chen</last></author>
      <author><first>Jidong</first><last>Tian</last></author>
      <author><first>Liqiang</first><last>Xiao</last></author>
      <author><first>Hao</first><last>He</last></author>
      <author><first>Yaohui</first><last>Jin</last></author>
      <pages>1186–1198</pages>
      <abstract>Paraphrase generation aims to generate semantically consistent sentences with different syntactic realizations. Most of the recent studies rely on the typical encoder-decoder framework where the generation process is deterministic. However, in practice, the ability to generate multiple syntactically different paraphrases is important. Recent work proposed to cooperate variational inference on a target-related latent variable to introduce the diversity. But the latent variable may be contaminated by the semantic information of other unrelated sentences, and in turn, change the conveyed meaning of generated paraphrases. In this paper, we propose a semantically consistent and syntactically variational encoder-decoder framework, which uses adversarial learning to ensure the syntactic latent variable be semantic-free. Moreover, we adopt another discriminator to improve the word-level and sentence-level semantic consistency. So the proposed framework can generate multiple semantically consistent and syntactically different paraphrases. The experiments show that our model outperforms the baseline models on the metrics based on both n-gram matching and semantic similarity, and our model can generate multiple different paraphrases by assembling different syntactic variables.</abstract>
      <url hash="89837946">2020.coling-main.102</url>
    </paper>
    <paper id="103">
      <title>Tiny Word Embeddings Using Globally Informed Reconstruction</title>
      <author><first>Sora</first><last>Ohashi</last></author>
      <author><first>Mao</first><last>Isogawa</last></author>
      <author><first>Tomoyuki</first><last>Kajiwara</last></author>
      <author><first>Yuki</first><last>Arase</last></author>
      <pages>1199–1203</pages>
      <abstract>We reduce the model size of pre-trained word embeddings by a factor of 200 while preserving its quality. Previous studies in this direction created a smaller word embedding model by reconstructing pre-trained word representations from those of subwords, which allows to store only a smaller number of subword embeddings in the memory. However, previous studies that train the reconstruction models using only target words cannot reduce the model size extremely while preserving its quality. Inspired by the observation of words with similar meanings having similar embeddings, our reconstruction training learns the global relationships among words, which can be employed in various models for word embedding reconstruction. Experimental results on word similarity benchmarks show that the proposed method improves the performance of the all subword-based reconstruction models.</abstract>
      <url hash="bf73c3ef">2020.coling-main.103</url>
    </paper>
    <paper id="104">
      <title>Improving Word Embeddings through Iterative Refinement of Word- and Character-level Models</title>
      <author><first>Phong</first><last>Ha</last></author>
      <author><first>Shanshan</first><last>Zhang</last></author>
      <author><first>Nemanja</first><last>Djuric</last></author>
      <author><first>Slobodan</first><last>Vucetic</last></author>
      <pages>1204–1213</pages>
      <abstract>Embedding of rare and out-of-vocabulary (OOV) words is an important open NLP problem. A popular solution is to train a character-level neural network to reproduce the embeddings from a standard word embedding model. The trained network is then used to assign vectors to any input string, including OOV and rare words. We enhance this approach and introduce an algorithm that iteratively refines and improves both word- and character-level models. We demonstrate that our method outperforms the existing algorithms on 5 word similarity data sets, and that it can be successfully applied to job title normalization, an important problem in the e-recruitment domain that suffers from the OOV problem.</abstract>
      <url hash="8860308b">2020.coling-main.104</url>
    </paper>
    <paper id="105">
      <title>Probing Multilingual <fixed-case>BERT</fixed-case> for Genetic and Typological Signals</title>
      <author><first>Taraka</first><last>Rama</last></author>
      <author><first>Lisa</first><last>Beinborn</last></author>
      <author><first>Steffen</first><last>Eger</last></author>
      <pages>1214–1228</pages>
      <abstract>We probe the layers in multilingual BERT (mBERT) for phylogenetic and geographic language signals across 100 languages and compute language distances based on the mBERT representations. We 1) employ the language distances to infer and evaluate language trees, finding that they are close to the reference family tree in terms of quartet tree distance, 2) perform distance matrix regression analysis, finding that the language distances can be best explained by phylogenetic and worst by structural factors and 3) present a novel measure for measuring diachronic meaning stability (based on cross-lingual representation variability) which correlates significantly with published ranked lists based on linguistic approaches. Our results contribute to the nascent field of typological interpretability of cross-lingual text representations.</abstract>
      <url hash="436716d7">2020.coling-main.105</url>
    </paper>
    <paper id="106">
      <title>Learning Efficient Task-Specific Meta-Embeddings with Word Prisms</title>
      <author><first>Jingyi</first><last>He</last></author>
      <author><first>Kc</first><last>Tsiolis</last></author>
      <author><first>Kian</first><last>Kenyon-Dean</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <pages>1229–1241</pages>
      <abstract>Word embeddings are trained to predict word cooccurrence statistics, which leads them to possess different lexical properties (syntactic, semantic, etc.) depending on the notion of context defined at training time. These properties manifest when querying the embedding space for the most similar vectors, and when used at the input layer of deep neural networks trained to solve downstream NLP problems. Meta-embeddings combine multiple sets of differently trained word embeddings, and have been shown to successfully improve intrinsic and extrinsic performance over equivalent models which use just one set of source embeddings. We introduce word prisms: a simple and efficient meta-embedding method that learns to combine source embeddings according to the task at hand. Word prisms learn orthogonal transformations to linearly combine the input source embeddings, which allows them to be very efficient at inference time. We evaluate word prisms in comparison to other meta-embedding methods on six extrinsic evaluations and observe that word prisms offer improvements in performance on all tasks.</abstract>
      <url hash="f14c9711">2020.coling-main.106</url>
    </paper>
    <paper id="107">
      <title>Always Keep your Target in Mind: Studying Semantics and Improving Performance of Neural Lexical Substitution</title>
      <author><first>Nikolay</first><last>Arefyev</last></author>
      <author><first>Boris</first><last>Sheludko</last></author>
      <author><first>Alexander</first><last>Podolskiy</last></author>
      <author><first>Alexander</first><last>Panchenko</last></author>
      <pages>1242–1255</pages>
      <abstract>Lexical substitution, i.e. generation of plausible words that can replace a particular target word in a given context, is an extremely powerful technology that can be used as a backbone of various NLP applications, including word sense induction and disambiguation, lexical relation extraction, data augmentation, etc. In this paper, we present a large-scale comparative study of lexical substitution methods employing both rather old and most recent language and masked language models (LMs and MLMs), such as context2vec, ELMo, BERT, RoBERTa, XLNet. We show that already competitive results achieved by SOTA LMs/MLMs can be further substantially improved if information about the target word is injected properly. Several existing and new target word injection methods are compared for each LM/MLM using both intrinsic evaluation on lexical substitution datasets and extrinsic evaluation on word sense induction (WSI) datasets. On two WSI datasets we obtain new SOTA results. Besides, we analyze the types of semantic relations between target words and their substitutes generated by different models or given by annotators.</abstract>
      <url hash="6ff67b68">2020.coling-main.107</url>
    </paper>
    <paper id="108">
      <title>Word Embedding Binarization with Semantic Information Preservation</title>
      <author><first>Samarth</first><last>Navali</last></author>
      <author><first>Praneet</first><last>Sherki</last></author>
      <author><first>Ramesh</first><last>Inturi</last></author>
      <author><first>Vanraj</first><last>Vala</last></author>
      <pages>1256–1265</pages>
      <abstract>With growing applications of Machine Learning in daily lives Natural Language Processing (NLP) has emerged as a heavily researched area. Finding its applications in tasks ranging from simple Q/A chatbots to Fully fledged conversational AI, NLP models are vital. Word and Sentence embedding are one of the most common starting points of any NLP task. A word embedding represents a given word in a predefined vector-space while maintaining vector relations with similar or dis-similar entities. As such different pretrained embedding such as Word2Vec, GloVe, fasttext have been developed. These embedding generated on millions of words are however very large in terms of size. Having embedding with floating point precision also makes the downstream evaluation slow. In this paper we present a novel method to convert continuous embedding to its binary representation, thus reducing the overall size of the embedding while keeping the semantic and relational knowledge intact. This will facilitate an option of porting such big embedding onto devices where space is limited. We also present different approaches suitable for different downstream tasks based on the requirement of contextual and semantic information. Experiments have shown comparable result in downstream tasks with 7 to 15 times reduction in file size and about 5 % change in evaluation parameters.</abstract>
      <url hash="62873e4a">2020.coling-main.108</url>
    </paper>
    <paper id="109">
      <title>How Relevant Are Selectional Preferences for Transformer-based Language Models?</title>
      <author><first>Eleni</first><last>Metheniti</last></author>
      <author><first>Tim</first><last>Van de Cruys</last></author>
      <author><first>Nabil</first><last>Hathout</last></author>
      <pages>1266–1278</pages>
      <abstract>Selectional preference is defined as the tendency of a predicate to favor particular arguments within a certain linguistic context, and likewise, reject others that result in conflicting or implausible meanings. The stellar success of contextual word embedding models such as BERT in NLP tasks has led many to question whether these models have learned linguistic information, but up till now, most research has focused on syntactic information. We investigate whether Bert contains information on the selectional preferences of words, by examining the probability it assigns to the dependent word given the presence of a head word in a sentence. We are using word pairs of head-dependent words in five different syntactic relations from the SP-10K corpus of selectional preference (Zhang et al., 2019b), in sentences from the ukWaC corpus, and we are calculating the correlation of the plausibility score (from SP-10K) and the model probabilities. Our results show that overall, there is no strong positive or negative correlation in any syntactic relation, but we do find that certain head words have a strong correlation and that masking all words but the head word yields the most positive correlations in most scenarios –which indicates that the semantics of the predicate is indeed an integral and influential factor for the selection of the argument.</abstract>
      <url hash="2cd4b323">2020.coling-main.109</url>
    </paper>
    <paper id="110">
      <title>Embedding Semantic Taxonomies</title>
      <author><first>Alyssa</first><last>Lees</last></author>
      <author><first>Chris</first><last>Welty</last></author>
      <author><first>Shubin</first><last>Zhao</last></author>
      <author><first>Jacek</first><last>Korycki</last></author>
      <author><first>Sara</first><last>Mc Carthy</last></author>
      <pages>1279–1291</pages>
      <abstract>A common step in developing an understanding of a vertical domain, e.g. shopping, dining, movies, medicine, etc., is curating a taxonomy of categories specific to the domain. These human created artifacts have been the subject of research in embeddings that attempt to encode aspects of the partial ordering property of taxonomies. We compare Box Embeddings, a natural containment representation of category taxonomies, to partial-order embeddings and a baseline Bayes Net, in the context of representing the Medical Subject Headings (MeSH) taxonomy given a set of 300K PubMed articles with subject labels from MeSH. We deeply explore the experimental properties of training box embeddings, including preparation of the training data, sampling ratios and class balance, initialization strategies, and propose a fix to the original box objective. We then present first results in using these techniques for representing a bipartite learning problem (i.e. collaborative filtering) in the presence of taxonomic relations within each partition, inferring disease (anatomical) locations from their use as subject labels in journal articles. Our box model substantially outperforms all baselines for taxonomic reconstruction and bipartite relationship experiments. This performance improvement is observed both in overall accuracy and the weighted spread by true taxonomic depth.</abstract>
      <url hash="5f810d36">2020.coling-main.110</url>
    </paper>
    <paper id="111">
      <title>A Retrofitting Model for Incorporating Semantic Relations into Word Embeddings</title>
      <author><first>Sapan</first><last>Shah</last></author>
      <author><first>Sreedhar</first><last>Reddy</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>1292–1298</pages>
      <abstract>We present a novel retrofitting model that can leverage relational knowledge available in a knowledge resource to improve word embeddings. The knowledge is captured in terms of relation inequality constraints that compare similarity of related and unrelated entities in the context of an anchor entity. These constraints are used as training data to learn a non-linear transformation function that maps original word vectors to a vector space respecting these constraints. The transformation function is learned in a similarity metric learning setting using Triplet network architecture. We applied our model to synonymy, antonymy and hypernymy relations in WordNet and observed large gains in performance over original distributional models as well as other retrofitting approaches on word similarity task and significant overall improvement on lexical entailment detection task.</abstract>
      <url hash="1fe4134f">2020.coling-main.111</url>
    </paper>
    <paper id="112">
      <title>Lexical Relation Mining in Neural Word Embeddings</title>
      <author><first>Aishwarya</first><last>Jadhav</last></author>
      <author><first>Yifat</first><last>Amir</last></author>
      <author><first>Zachary</first><last>Pardos</last></author>
      <pages>1299–1311</pages>
      <abstract>Work with neural word embeddings and lexical relations has largely focused on confirmatory experiments which use human-curated examples of semantic and syntactic relations to validate against. In this paper, we explore the degree to which lexical relations, such as those found in popular validation sets, can be derived and extended from a variety of neural embeddings using classical clustering methods. We show that the Word2Vec space of word-pairs (i.e., offset vectors) significantly outperforms other more contemporary methods, even in the presence of a large number of noisy offsets. Moreover, we show that via a simple nearest neighbor approach in the offset space, new examples of known relations can be discovered. Our results speak to the amenability of offset vectors from non-contextual neural embeddings to find semantically coherent clusters. This simple approach has implications for the exploration of emergent regularities and their examples, such as emerging trends on social media and their related posts.</abstract>
      <url hash="5de54110">2020.coling-main.112</url>
    </paper>
    <paper id="113">
      <title>A <fixed-case>BERT</fixed-case>-based Dual Embedding Model for <fixed-case>C</fixed-case>hinese Idiom Prediction</title>
      <author><first>Minghuan</first><last>Tan</last></author>
      <author><first>Jing</first><last>Jiang</last></author>
      <pages>1312–1322</pages>
      <abstract>Chinese idioms are special fixed phrases usually derived from ancient stories, whose meanings are oftentimes highly idiomatic and non-compositional. The Chinese idiom prediction task is to select the correct idiom from a set of candidate idioms given a context with a blank. We propose a BERT-based dual embedding model to encode the contextual words as well as to learn dual embeddings of the idioms. Specifically, we first match the embedding of each candidate idiom with the hidden representation corresponding to the blank in the context. We then match the embedding of each candidate idiom with the hidden representations of all the tokens in the context thorough context pooling. We further propose to use two separate idiom embeddings for the two kinds of matching. Experiments on a recently released Chinese idiom cloze test dataset show that our proposed method performs better than the existing state of the art. Ablation experiments also show that both context pooling and dual embedding contribute to the improvement of performance.</abstract>
      <url hash="725ccbd5">2020.coling-main.113</url>
    </paper>
    <paper id="114">
      <title><fixed-case>BERT</fixed-case>-based Cohesion Analysis of <fixed-case>J</fixed-case>apanese Texts</title>
      <author><first>Nobuhiro</first><last>Ueda</last></author>
      <author><first>Daisuke</first><last>Kawahara</last></author>
      <author><first>Sadao</first><last>Kurohashi</last></author>
      <pages>1323–1333</pages>
      <abstract>The meaning of natural language text is supported by cohesion among various kinds of entities, including coreference relations, predicate-argument structures, and bridging anaphora relations. However, predicate-argument structures for nominal predicates and bridging anaphora relations have not been studied well, and their analyses have been still very difficult. Recent advances in neural networks, in particular, self training-based language models including BERT (Devlin et al., 2019), have significantly improved many natural language processing tasks, making it possible to dive into the study on analysis of cohesion in the whole text. In this study, we tackle an integrated analysis of cohesion in Japanese texts. Our results significantly outperformed existing studies in each task, especially about 10 to 20 point improvement both for zero anaphora and coreference resolution. Furthermore, we also showed that coreference resolution is different in nature from the other tasks and should be treated specially.</abstract>
      <url hash="f8b6087d">2020.coling-main.114</url>
    </paper>
    <paper id="115">
      <title>Schema Aware Semantic Reasoning for Interpreting Natural Language Queries in Enterprise Settings</title>
      <author><first>Jaydeep</first><last>Sen</last></author>
      <author><first>Tanaya</first><last>Babtiwale</last></author>
      <author><first>Kanishk</first><last>Saxena</last></author>
      <author><first>Yash</first><last>Butala</last></author>
      <author><first>Sumit</first><last>Bhatia</last></author>
      <author><first>Karthik</first><last>Sankaranarayanan</last></author>
      <pages>1334–1345</pages>
      <abstract>Natural Language Query interfaces allow the end-users to access the desired information without the need to know any specialized query language, data storage, or schema details. Even with the recent advances in NLP research space, the state-of-the-art QA systems fall short of understanding implicit intents of real-world Business Intelligence (BI) queries in enterprise systems, since Natural Language Understanding still remains an AI-hard problem. We posit that deploying ontology reasoning over domain semantics can help in achieving better natural language understanding for QA systems. In this paper, we specifically focus on building a Schema Aware Semantic Reasoning Framework that translates natural language interpretation as a sequence of solvable tasks by an ontology reasoner. We apply our framework on top of an ontology based, state-of-the-art natural language question-answering system ATHENA, and experiment with 4 benchmarks focused on BI queries. Our experimental numbers empirically show that the Schema Aware Semantic Reasoning indeed helps in achieving significantly better results for handling BI queries with an average accuracy improvement of ~30%</abstract>
      <url hash="0ff2fefc">2020.coling-main.115</url>
    </paper>
    <paper id="116">
      <title>Multilingual Irony Detection with Dependency Syntax and Neural Models</title>
      <author><first>Alessandra Teresa</first><last>Cignarella</last></author>
      <author><first>Valerio</first><last>Basile</last></author>
      <author><first>Manuela</first><last>Sanguinetti</last></author>
      <author><first>Cristina</first><last>Bosco</last></author>
      <author><first>Paolo</first><last>Rosso</last></author>
      <author><first>Farah</first><last>Benamara</last></author>
      <pages>1346–1358</pages>
      <abstract>This paper presents an in-depth investigation of the effectiveness of dependency-based syntactic features on the irony detection task in a multilingual perspective (English, Spanish, French and Italian). It focuses on the contribution from syntactic knowledge, exploiting linguistic resources where syntax is annotated according to the Universal Dependencies scheme. Three distinct experimental settings are provided. In the first, a variety of syntactic dependency-based features combined with classical machine learning classifiers are explored. In the second scenario, two well-known types of word embeddings are trained on parsed data and tested against gold standard datasets. In the third setting, dependency-based syntactic features are combined into the Multilingual BERT architecture. The results suggest that fine-grained dependency-based syntactic information is informative for the detection of irony.</abstract>
      <url hash="e17507df">2020.coling-main.116</url>
    </paper>
    <paper id="117">
      <title>What Can We Learn from Noun Substitutions in Revision Histories?</title>
      <author><first>Talita</first><last>Anthonio</last></author>
      <author><first>Michael</first><last>Roth</last></author>
      <pages>1359–1370</pages>
      <abstract>In community-edited resources such as wikiHow, sentences are subject to revisions on a daily basis. Recent work has shown that resulting improvements over time can be modelled computationally, assuming that each revision contributes to the improvement. We take a closer look at a subset of such revisions, for which we attempt to improve a computational model and validate in how far the assumption that ‘revised means better’ actually holds. The subset of revisions considered here are noun substitutions, which often involve interesting semantic relations, including synonymy, antonymy and hypernymy. Despite the high semantic relatedness, we find that a supervised classifier can distinguish the revised version of a sentence from an original version with an accuracy close to 70%, when taking context into account. In a human annotation study, we observe that annotators identify the revised sentence as the ‘better version’ with similar performance. Our analysis reveals a fair agreement among annotators when a revision improves fluency. In contrast, noun substitutions that involve other lexical-semantic relationships are often perceived as being equally good or tend to cause disagreements. While these findings are also reflected in classification scores, a comparison of results shows that our model fails in cases where humans can resort to factual knowledge or intuitions about the required level of specificity.</abstract>
      <url hash="0cf41e25">2020.coling-main.117</url>
    </paper>
    <paper id="118">
      <title>Specializing Unsupervised Pretraining Models for Word-Level Semantic Similarity</title>
      <author><first>Anne</first><last>Lauscher</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Edoardo Maria</first><last>Ponti</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <author><first>Goran</first><last>Glavaš</last></author>
      <pages>1371–1383</pages>
      <abstract>Unsupervised pretraining models have been shown to facilitate a wide range of downstream NLP applications. These models, however, retain some of the limitations of traditional static word embeddings. In particular, they encode only the distributional knowledge available in raw text corpora, incorporated through language modeling objectives. In this work, we complement such distributional knowledge with external lexical knowledge, that is, we integrate the discrete knowledge on word-level semantic similarity into pretraining. To this end, we generalize the standard BERT model to a multi-task learning setting where we couple BERT’s masked language modeling and next sentence prediction objectives with an auxiliary task of binary word relation classification. Our experiments suggest that our “Lexically Informed” BERT (LIBERT), specialized for the word-level semantic similarity, yields better performance than the lexically blind “vanilla” BERT on several language understanding tasks. Concretely, LIBERT outperforms BERT in 9 out of 10 tasks of the GLUE benchmark and is on a par with BERT in the remaining one. Moreover, we show consistent gains on 3 benchmarks for lexical simplification, a task where knowledge about word-level semantic similarity is paramount, as well as large gains on lexical reasoning probes.</abstract>
      <url hash="9cf734fa">2020.coling-main.118</url>
    </paper>
    <paper id="119">
      <title>Harnessing Cross-lingual Features to Improve Cognate Detection for Low-resource Languages</title>
      <author><first>Diptesh</first><last>Kanojia</last></author>
      <author><first>Raj</first><last>Dabre</last></author>
      <author><first>Shubham</first><last>Dewangan</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <author><first>Malhar</first><last>Kulkarni</last></author>
      <pages>1384–1395</pages>
      <abstract>Cognates are variants of the same lexical form across different languages; for example “fonema” in Spanish and “phoneme” in English are cognates, both of which mean “a unit of sound”. The task of automatic detection of cognates among any two languages can help downstream NLP tasks such as Cross-lingual Information Retrieval, Computational Phylogenetics, and Machine Translation. In this paper, we demonstrate the use of cross-lingual word embeddings for detecting cognates among fourteen Indian Languages. Our approach introduces the use of context from a knowledge graph to generate improved feature representations for cognate detection. We, then, evaluate the impact of our cognate detection mechanism on neural machine translation (NMT), as a downstream task. We evaluate our methods to detect cognates on a challenging dataset of twelve Indian languages, namely, Sanskrit, Hindi, Assamese, Oriya, Kannada, Gujarati, Tamil, Telugu, Punjabi, Bengali, Marathi, and Malayalam. Additionally, we create evaluation datasets for two more Indian languages, Konkani and Nepali. We observe an improvement of up to 18% points, in terms of F-score, for cognate detection. Furthermore, we observe that cognates extracted using our method help improve NMT quality by up to 2.76 BLEU. We also release our code, newly constructed datasets and cross-lingual models publicly.</abstract>
      <url hash="6b577a99">2020.coling-main.119</url>
    </paper>
    <paper id="120">
      <title>Bridging the Gap in Multilingual Semantic Role Labeling: a Language-Agnostic Approach</title>
      <author><first>Simone</first><last>Conia</last></author>
      <author><first>Roberto</first><last>Navigli</last></author>
      <pages>1396–1410</pages>
      <abstract>Recent research indicates that taking advantage of complex syntactic features leads to favorable results in Semantic Role Labeling. Nonetheless, an analysis of the latest state-of-the-art multilingual systems reveals the difficulty of bridging the wide gap in performance between high-resource (e.g., English) and low-resource (e.g., German) settings. To overcome this issue, we propose a fully language-agnostic model that does away with morphological and syntactic features to achieve robustness across languages. Our approach outperforms the state of the art in all the languages of the CoNLL-2009 benchmark dataset, especially whenever a scarce amount of training data is available. Our objective is not to reject approaches that rely on syntax, rather to set a strong and consistent language-independent baseline for future innovations in Semantic Role Labeling. We release our model code and checkpoints at https://github.com/SapienzaNLP/multi-srl.</abstract>
      <url hash="13847767">2020.coling-main.120</url>
    </paper>
    <paper id="121">
      <title>On the Helpfulness of Document Context to Sentence Simplification</title>
      <author><first>Renliang</first><last>Sun</last></author>
      <author><first>Zhe</first><last>Lin</last></author>
      <author><first>Xiaojun</first><last>Wan</last></author>
      <pages>1411–1423</pages>
      <abstract>Most of the research on text simplification is limited to sentence level nowadays. In this paper, we are the first to investigate the helpfulness of document context on sentence simplification and apply it to the sequence-to-sequence model. We firstly construct a sentence simplification dataset in which the contexts for the original sentence are provided by Wikipedia corpus. The new dataset contains approximately 116K sentence pairs with context. We then propose a new model that makes full use of the context information. Our model uses neural networks to learn the different effects of the preceding sentences and the following sentences on the current sentence and applies them to the improved transformer model. Evaluated on the newly constructed dataset, our model achieves 36.52 on SARI value, which outperforms the best performing model in the baselines by 2.46 (7.22%), indicating that context indeed helps improve sentence simplification. In the ablation experiment, we show that using either the preceding sentences or the following sentences as context can significantly improve simplification.</abstract>
      <url hash="ae5d576d">2020.coling-main.121</url>
    </paper>
    <paper id="122">
      <title><fixed-case>A</fixed-case>uto<fixed-case>M</fixed-case>e<fixed-case>TS</fixed-case>: The Autocomplete for Medical Text Simplification</title>
      <author><first>Hoang</first><last>Van</last></author>
      <author><first>David</first><last>Kauchak</last></author>
      <author><first>Gondy</first><last>Leroy</last></author>
      <pages>1424–1434</pages>
      <abstract>The goal of text simplification (TS) is to transform difficult text into a version that is easier to understand and more broadly accessible to a wide variety of readers. In some domains, such as healthcare, fully automated approaches cannot be used since information must be accurately preserved. Instead, semi-automated approaches can be used that assist a human writer in simplifying text faster and at a higher quality. In this paper, we examine the application of autocomplete to text simplification in the medical domain. We introduce a new parallel medical data set consisting of aligned English Wikipedia with Simple English Wikipedia sentences and examine the application of pretrained neural language models (PNLMs) on this dataset. We compare four PNLMs (BERT, RoBERTa, XLNet, and GPT-2), and show how the additional context of the sentence to be simplified can be incorporated to achieve better results (6.17% absolute improvement over the best individual model). We also introduce an ensemble model that combines the four PNLMs and outperforms the best individual model by 2.1%, resulting in an overall word prediction accuracy of 64.52%.</abstract>
      <url hash="799522c4">2020.coling-main.122</url>
    </paper>
    <paper id="123">
      <title>Multi-Word Lexical Simplification</title>
      <author><first>Piotr</first><last>Przybyła</last></author>
      <author><first>Matthew</first><last>Shardlow</last></author>
      <pages>1435–1446</pages>
      <abstract>In this work we propose the task of multi-word lexical simplification, in which a sentence in natural language is made easier to understand by replacing its fragment with a simpler alternative, both of which can consist of many words. In order to explore this new direction, we contribute a corpus (MWLS1), including 1462 sentences in English from various sources with 7059 simplifications provided by human annotators. We also propose an automatic solution (Plainifier) based on a purpose-trained neural language model and evaluate its performance, comparing to human and resource-based baselines.</abstract>
      <url hash="9a70bafb">2020.coling-main.123</url>
    </paper>
    <paper id="124">
      <title>Exploring the zero-shot limit of <fixed-case>F</fixed-case>ew<fixed-case>R</fixed-case>el</title>
      <author><first>Alberto</first><last>Cetoli</last></author>
      <pages>1447–1451</pages>
      <abstract>This paper proposes a general purpose relation extractor that uses Wikidata descriptions to represent the relation’s surface form. The results are tested on the FewRel 1.0 dataset, which provides an excellent framework for training and evaluating the proposed zero-shot learning system in English. This relation extractor architecture exploits the implicit knowledge of a language model through a question-answering approach.</abstract>
      <url hash="f8f0b94c">2020.coling-main.124</url>
    </paper>
    <paper id="125">
      <title>A Deep Generative Distance-Based Classifier for Out-of-Domain Detection with Mahalanobis Space</title>
      <author><first>Hong</first><last>Xu</last></author>
      <author><first>Keqing</first><last>He</last></author>
      <author><first>Yuanmeng</first><last>Yan</last></author>
      <author><first>Sihong</first><last>Liu</last></author>
      <author><first>Zijun</first><last>Liu</last></author>
      <author><first>Weiran</first><last>Xu</last></author>
      <pages>1452–1460</pages>
      <abstract>Detecting out-of-domain (OOD) input intents is critical in the task-oriented dialog system. Different from most existing methods that rely heavily on manually labeled OOD samples, we focus on the unsupervised OOD detection scenario where there are no labeled OOD samples except for labeled in-domain data. In this paper, we propose a simple but strong generative distance-based classifier to detect OOD samples. We estimate the class-conditional distribution on feature spaces of DNNs via Gaussian discriminant analysis (GDA) to avoid over-confidence problems. And we use two distance functions, Euclidean and Mahalanobis distances, to measure the confidence score of whether a test sample belongs to OOD. Experiments on four benchmark datasets show that our method can consistently outperform the baselines.</abstract>
      <url hash="82084b9d">2020.coling-main.125</url>
    </paper>
    <paper id="126">
      <title>Contrastive Zero-Shot Learning for Cross-Domain Slot Filling with Adversarial Attack</title>
      <author><first>Keqing</first><last>He</last></author>
      <author><first>Jinchao</first><last>Zhang</last></author>
      <author><first>Yuanmeng</first><last>Yan</last></author>
      <author><first>Weiran</first><last>Xu</last></author>
      <author><first>Cheng</first><last>Niu</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>1461–1467</pages>
      <abstract>Zero-shot slot filling has widely arisen to cope with data scarcity in target domains. However, previous approaches often ignore constraints between slot value representation and related slot description representation in the latent space and lack enough model robustness. In this paper, we propose a Contrastive Zero-Shot Learning with Adversarial Attack (CZSL-Adv) method for the cross-domain slot filling. The contrastive loss aims to map slot value contextual representations to the corresponding slot description representations. And we introduce an adversarial attack training strategy to improve model robustness. Experimental results show that our model significantly outperforms state-of-the-art baselines under both zero-shot and few-shot settings.</abstract>
      <url hash="4a5bfa01">2020.coling-main.126</url>
    </paper>
    <paper id="127">
      <title><fixed-case>D</fixed-case>o<fixed-case>LFI</fixed-case>n: Distributions over Latent Features for Interpretability</title>
      <author><first>Phong</first><last>Le</last></author>
      <author><first>Willem</first><last>Zuidema</last></author>
      <pages>1468–1474</pages>
      <abstract>Interpreting the inner workings of neural models is a key step in ensuring the robustness and trustworthiness of the models, but work on neural network interpretability typically faces a trade-off: either the models are too constrained to be very useful, or the solutions found by the models are too complex to interpret. We propose a novel strategy for achieving interpretability that – in our experiments – avoids this trade-off. Our approach builds on the success of using probability as the central quantity, such as for instance within the attention mechanism. In our architecture, DoLFIn (Distributions over Latent Features for Interpretability), we do no determine beforehand what each feature represents, and features go altogether into an unordered set. Each feature has an associated probability ranging from 0 to 1, weighing its importance for further processing. We show that, unlike attention and saliency map approaches, this set-up makes it straight-forward to compute the probability with which an input component supports the decision the neural model makes. To demonstrate the usefulness of the approach, we apply DoLFIn to text classification, and show that DoLFIn not only provides interpretable solutions, but even slightly outperforms the classical CNN and BiLSTM text classifiers on the SST2 and AG-news datasets.</abstract>
      <url hash="cbe64c28">2020.coling-main.127</url>
    </paper>
    <paper id="128">
      <title>Contextual Argument Component Classification for Class Discussions</title>
      <author><first>Luca</first><last>Lugini</last></author>
      <author><first>Diane</first><last>Litman</last></author>
      <pages>1475–1480</pages>
      <abstract>Argument mining systems often consider contextual information, i.e. information outside of an argumentative discourse unit, when trained to accomplish tasks such as argument component identification, classification, and relation extraction. However, prior work has not carefully analyzed the utility of different contextual properties in context-aware models. In this work, we show how two different types of contextual information, local discourse context and speaker context, can be incorporated into a computational model for classifying argument components in multi-party classroom discussions. We find that both context types can improve performance, although the improvements are dependent on context size and position.</abstract>
      <url hash="3c83c686">2020.coling-main.128</url>
    </paper>
    <paper id="129">
      <title>On the Practical Ability of Recurrent Neural Networks to Recognize Hierarchical Languages</title>
      <author><first>Satwik</first><last>Bhattamishra</last></author>
      <author><first>Kabir</first><last>Ahuja</last></author>
      <author><first>Navin</first><last>Goyal</last></author>
      <pages>1481–1494</pages>
      <abstract>While recurrent models have been effective in NLP tasks, their performance on context-free languages (CFLs) has been found to be quite weak. Given that CFLs are believed to capture important phenomena such as hierarchical structure in natural languages, this discrepancy in performance calls for an explanation. We study the performance of recurrent models on Dyck-n languages, a particularly important and well-studied class of CFLs. We find that while recurrent models generalize nearly perfectly if the lengths of the training and test strings are from the same range, they perform poorly if the test strings are longer. At the same time, we observe that RNNs are expressive enough to recognize Dyck words of arbitrary lengths in finite precision if their depths are bounded. Hence, we evaluate our models on samples generated from Dyck languages with bounded depth and find that they are indeed able to generalize to much higher lengths. Since natural language datasets have nested dependencies of bounded depth, this may help explain why they perform well in modeling hierarchical dependencies in natural language data despite prior works indicating poor generalization performance on Dyck languages. We perform probing studies to support our results and provide comparisons with Transformers.</abstract>
      <url hash="81221f8c">2020.coling-main.129</url>
    </paper>
    <paper id="130">
      <title>Pre-trained Language Model Based Active Learning for Sentence Matching</title>
      <author><first>Guirong</first><last>Bai</last></author>
      <author><first>Shizhu</first><last>He</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <author><first>Zaiqing</first><last>Nie</last></author>
      <pages>1495–1504</pages>
      <abstract>Active learning is able to significantly reduce the annotation cost for data-driven techniques. However, previous active learning approaches for natural language processing mainly depend on the entropy-based uncertainty criterion, and ignore the characteristics of natural language. In this paper, we propose a pre-trained language model based active learning approach for sentence matching. Differing from previous active learning, it can provide linguistic criteria from the pre-trained language model to measure instances and help select more effective instances for annotation. Experiments demonstrate our approach can achieve greater accuracy with fewer labeled training instances.</abstract>
      <url hash="1d6ae405">2020.coling-main.130</url>
    </paper>
    <paper id="131">
      <title>Event-Guided Denoising for Multilingual Relation Learning</title>
      <author><first>Amith</first><last>Ananthram</last></author>
      <author><first>Emily</first><last>Allaway</last></author>
      <author><first>Kathleen</first><last>McKeown</last></author>
      <pages>1505–1512</pages>
      <abstract>General purpose relation extraction has recently seen considerable gains in part due to a massively data-intensive distant supervision technique from Soares et al. (2019) that produces state-of-the-art results across many benchmarks. In this work, we present a methodology for collecting high quality training data for relation extraction from unlabeled text that achieves a near-recreation of their zero-shot and few-shot results at a fraction of the training cost. Our approach exploits the predictable distributional structure of date-marked news articles to build a denoised corpus – the extraction process filters out low quality examples. We show that a smaller multilingual encoder trained on this corpus performs comparably to the current state-of-the-art (when both receive little to no fine-tuning) on few-shot and standard relation benchmarks in English and Spanish despite using many fewer examples (50k vs. 300mil+).</abstract>
      <url hash="47cc2b77">2020.coling-main.131</url>
    </paper>
    <paper id="132">
      <title>Using a Penalty-based Loss Re-estimation Method to Improve Implicit Discourse Relation Classification</title>
      <author><first>Xiao</first><last>Li</last></author>
      <author><first>Yu</first><last>Hong</last></author>
      <author><first>Huibin</first><last>Ruan</last></author>
      <author><first>Zhen</first><last>Huang</last></author>
      <pages>1513–1518</pages>
      <abstract>We tackle implicit discourse relation classification, a task of automatically determining semantic relationships between arguments. The attention-worthy words in arguments are crucial clues for classifying the discourse relations. Attention mechanisms have been proven effective in highlighting the attention-worthy words during encoding. However, our survey shows that some inessential words are unintentionally misjudged as the attention-worthy words and, therefore, assigned heavier attention weights than should be. We propose a penalty-based loss re-estimation method to regulate the attention learning process, integrating penalty coefficients into the computation of loss by means of overstability of attention weight distributions. We conduct experiments on the Penn Discourse TreeBank (PDTB) corpus. The test results show that our loss re-estimation method leads to substantial improvements for a variety of attention mechanisms, and it obtains highly competitive performance compared to the state-of-the-art methods.</abstract>
      <url hash="f5f91966">2020.coling-main.132</url>
    </paper>
    <paper id="133">
      <title>A Review of Dataset and Labeling Methods for Causality Extraction</title>
      <author><first>Jinghang</first><last>Xu</last></author>
      <author><first>Wanli</first><last>Zuo</last></author>
      <author><first>Shining</first><last>Liang</last></author>
      <author><first>Xianglin</first><last>Zuo</last></author>
      <pages>1519–1531</pages>
      <abstract>Causality represents the most important kind of correlation between events. Extracting causali-ty from text has become a promising hot topic in NLP. However, there is no mature research systems and datasets for public evaluation. Moreover, there is a lack of unified causal sequence label methods, which constitute the key factors that hinder the progress of causality extraction research. We survey the limitations and shortcomings of existing causality research field com-prehensively from the aspects of basic concepts, extraction methods, experimental data, and la-bel methods, so as to provide reference for future research on causality extraction. We summa-rize the existing causality datasets, explore their practicability and extensibility from multiple perspectives and create a new causal dataset ESC. Aiming at the problem of causal sequence labeling, we analyse the existing methods with a summarization of its regulation and propose a new causal label method of core word. Multiple candidate causal label sequences are put for-ward according to label controversy to explore the optimal label method through experiments, and suggestions are provided for selecting label method.</abstract>
      <url hash="afecd42a">2020.coling-main.133</url>
    </paper>
    <paper id="134">
      <title>Knowledge Graph Embedding with Atrous Convolution and Residual Learning</title>
      <author><first>Feiliang</first><last>Ren</last></author>
      <author><first>Juchen</first><last>Li</last></author>
      <author><first>Huihui</first><last>Zhang</last></author>
      <author><first>Shilei</first><last>Liu</last></author>
      <author><first>Bochao</first><last>Li</last></author>
      <author><first>Ruicheng</first><last>Ming</last></author>
      <author><first>Yujia</first><last>Bai</last></author>
      <pages>1532–1543</pages>
      <abstract>Knowledge graph embedding is an important task and it will benefit lots of downstream applications. Currently, deep neural networks based methods achieve state-of-the-art performance. However, most of these existing methods are very complex and need much time for training and inference. To address this issue, we propose a simple but effective atrous convolution based knowledge graph embedding method. Compared with existing state-of-the-art methods, our method has following main characteristics. First, it effectively increases feature interactions by using atrous convolutions. Second, to address the original information forgotten issue and vanishing/exploding gradient issue, it uses the residual learning method. Third, it has simpler structure but much higher parameter efficiency. We evaluate our method on six benchmark datasets with different evaluation metrics. Extensive experiments show that our model is very effective. On these diverse datasets, it achieves better results than the compared state-of-the-art methods on most of evaluation metrics. The source codes of our model could be found at https://github.com/neukg/AcrE.</abstract>
      <url hash="18a739c2">2020.coling-main.134</url>
    </paper>
    <paper id="135">
      <title><fixed-case>K</fixed-case>now<fixed-case>D</fixed-case>is: Knowledge Enhanced Data Augmentation for Event Causality Detection via Distant Supervision</title>
      <author><first>Xinyu</first><last>Zuo</last></author>
      <author><first>Yubo</first><last>Chen</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <pages>1544–1550</pages>
      <abstract>Modern models of event causality detection (ECD) are mainly based on supervised learning from small hand-labeled corpora. However, hand-labeled training data is expensive to produce, low coverage of causal expressions, and limited in size, which makes supervised methods hard to detect causal relations between events. To solve this data lacking problem, we investigate a data augmentation framework for ECD, dubbed as Knowledge Enhanced Distant Data Augmentation (KnowDis). Experimental results on two benchmark datasets EventStoryLine corpus and Causal-TimeBank show that 1) KnowDis can augment available training data assisted with the lexical and causal commonsense knowledge for ECD via distant supervision, and 2) our method outperforms previous methods by a large margin assisted with automatically labeled training data.</abstract>
      <url hash="f8c85944">2020.coling-main.135</url>
    </paper>
    <paper id="136">
      <title>Graph Enhanced Dual Attention Network for Document-Level Relation Extraction</title>
      <author id="bo-li"><first>Bo</first><last>Li</last></author>
      <author><first>Wei</first><last>Ye</last></author>
      <author><first>Zhonghao</first><last>Sheng</last></author>
      <author><first>Rui</first><last>Xie</last></author>
      <author><first>Xiangyu</first><last>Xi</last></author>
      <author><first>Shikun</first><last>Zhang</last></author>
      <pages>1551–1560</pages>
      <abstract>Document-level relation extraction requires inter-sentence reasoning capabilities to capture local and global contextual information for multiple relational facts. To improve inter-sentence reasoning, we propose to characterize the complex interaction between sentences and potential relation instances via a Graph Enhanced Dual Attention network (GEDA). In GEDA, sentence representation generated by the sentence-to-relation (S2R) attention is refined and synthesized by a Heterogeneous Graph Convolutional Network before being fed into the relation-to-sentence (R2S) attention . We further design a simple yet effective regularizer based on the natural duality of the S2R and R2S attention, whose weights are also supervised by the supporting evidence of relation instances during training. An extensive set of experiments on an existing large-scale dataset show that our model achieve competitive performance, especially for the inter-sentence relation extraction, while the neural predictions can also be interpretable and easily observed.</abstract>
      <url hash="f897b77b">2020.coling-main.136</url>
    </paper>
    <paper id="137">
      <title>Joint Entity and Relation Extraction for Legal Documents with Legal Feature Enhancement</title>
      <author><first>Yanguang</first><last>Chen</last></author>
      <author><first>Yuanyuan</first><last>Sun</last></author>
      <author><first>Zhihao</first><last>Yang</last></author>
      <author><first>Hongfei</first><last>Lin</last></author>
      <pages>1561–1571</pages>
      <abstract>In recent years, the plentiful information contained in Chinese legal documents has attracted a great deal of attention because of the large-scale release of the judgment documents on China Judgments Online. It is in great need of enabling machines to understand the semantic information stored in the documents which are transcribed in the form of natural language. The technique of information extraction provides a way of mining the valuable information implied in the unstructured judgment documents. We propose a Legal Triplet Extraction System for drug-related criminal judgment documents. The system extracts the entities and the semantic relations jointly and benefits from the proposed legal lexicon feature and multi-task learning framework. Furthermore, we manually annotate a dataset for Named Entity Recognition and Relation Extraction in Chinese legal domain, which contributes to training supervised triplet extraction models and evaluating the model performance. Our experimental results show that the legal feature introduction and multi-task learning framework are feasible and effective for the Legal Triplet Extraction System. The F1 score of triplet extraction finally reaches 0.836 on the legal dataset.</abstract>
      <url hash="9e5940b3">2020.coling-main.137</url>
    </paper>
    <paper id="138">
      <title><fixed-case>TPL</fixed-case>inker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking</title>
      <author><first>Yucheng</first><last>Wang</last></author>
      <author><first>Bowen</first><last>Yu</last></author>
      <author><first>Yueyang</first><last>Zhang</last></author>
      <author><first>Tingwen</first><last>Liu</last></author>
      <author><first>Hongsong</first><last>Zhu</last></author>
      <author><first>Limin</first><last>Sun</last></author>
      <pages>1572–1582</pages>
      <abstract>Extracting entities and relations from unstructured text has attracted increasing attention in recent years but remains challenging, due to the intrinsic difficulty in identifying overlapping relations with shared entities. Prior works show that joint learning can result in a noticeable performance gain. However, they usually involve sequential interrelated steps and suffer from the problem of exposure bias. At training time, they predict with the ground truth conditions while at inference it has to make extraction from scratch. This discrepancy leads to error accumulation. To mitigate the issue, we propose in this paper a one-stage joint extraction model, namely, TPLinker, which is capable of discovering overlapping relations sharing one or both entities while being immune from the exposure bias. TPLinker formulates joint extraction as a token pair linking problem and introduces a novel handshaking tagging scheme that aligns the boundary tokens of entity pairs under each relation type. Experiment results show that TPLinker performs significantly better on overlapping and multiple relation extraction, and achieves state-of-the-art performance on two public datasets.</abstract>
      <url hash="8a46bf86">2020.coling-main.138</url>
    </paper>
    <paper id="139">
      <title><fixed-case>T</fixed-case>e<fixed-case>R</fixed-case>o: A Time-aware Knowledge Graph Embedding via Temporal Rotation</title>
      <author><first>Chengjin</first><last>Xu</last></author>
      <author><first>Mojtaba</first><last>Nayyeri</last></author>
      <author><first>Fouad</first><last>Alkhoury</last></author>
      <author><first>Hamed</first><last>Shariat Yazdi</last></author>
      <author><first>Jens</first><last>Lehmann</last></author>
      <pages>1583–1593</pages>
      <abstract>In the last few years, there has been a surge of interest in learning representations of entities and relations in knowledge graph (KG). However, the recent availability of temporal knowledge graphs (TKGs) that contain time information for each fact created the need for reasoning over time in such TKGs. In this regard, we present a new approach of TKG embedding, TeRo, which defines the temporal evolution of entity embedding as a rotation from the initial time to the current time in the complex vector space. Specially, for facts involving time intervals, each relation is represented as a pair of dual complex embeddings to handle the beginning and the end of the relation, respectively. We show our proposed model overcomes the limitations of the existing KG embedding models and TKG embedding models and has the ability of learning and inferring various relation patterns over time. Experimental results on three different TKGs show that TeRo significantly outperforms existing state-of-the-art models for link prediction. In addition, we analyze the effect of time granularity on link prediction over TKGs, which as far as we know has not been investigated in previous literature.</abstract>
      <url hash="6bae730a">2020.coling-main.139</url>
    </paper>
    <paper id="140">
      <title>Meta-Information Guided Meta-Learning for Few-Shot Relation Classification</title>
      <author><first>Bowen</first><last>Dong</last></author>
      <author><first>Yuan</first><last>Yao</last></author>
      <author><first>Ruobing</first><last>Xie</last></author>
      <author><first>Tianyu</first><last>Gao</last></author>
      <author><first>Xu</first><last>Han</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Fen</first><last>Lin</last></author>
      <author><first>Leyu</first><last>Lin</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <pages>1594–1605</pages>
      <abstract>Few-shot classification requires classifiers to adapt to new classes with only a few training instances. State-of-the-art meta-learning approaches such as MAML learn how to initialize and fast adapt parameters from limited instances, which have shown promising results in few-shot classification. However, existing meta-learning models solely rely on implicit instance-based statistics, and thus suffer from instance unreliability and weak interpretability. To solve this problem, we propose a novel meta-information guided meta-learning (MIML) framework, where semantic concepts of classes provide strong guidance for meta-learning in both initialization and adaptation. In effect, our model can establish connections between instance-based information and semantic-based information, which enables more effective initialization and faster adaptation. Comprehensive experimental results on few-shot relation classification demonstrate the effectiveness of the proposed framework. Notably, MIML achieves comparable or superior performance to humans with only one shot on FewRel evaluation.</abstract>
      <url hash="594f3f50">2020.coling-main.140</url>
    </paper>
    <paper id="141">
      <title>Unsupervised Deep Language and Dialect Identification for Short Texts</title>
      <author><first>Koustava</first><last>Goswami</last></author>
      <author><first>Rajdeep</first><last>Sarkar</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Theodorus</first><last>Fransen</last></author>
      <author><first>John P.</first><last>McCrae</last></author>
      <pages>1606–1617</pages>
      <abstract>Automatic Language Identification (LI) or Dialect Identification (DI) of short texts of closely related languages or dialects, is one of the primary steps in many natural language processing pipelines. Language identification is considered a solved task in many cases; however, in the case of very closely related languages, or in an unsupervised scenario (where the languages are not known in advance), performance is still poor. In this paper, we propose the Unsupervised Deep Language and Dialect Identification (UDLDI) method, which can simultaneously learn sentence embeddings and cluster assignments from short texts. The UDLDI model understands the sentence constructions of languages by applying attention to character relations which helps to optimize the clustering of languages. We have performed our experiments on three short-text datasets for different language families, each consisting of closely related languages or dialects, with very minimal training sets. Our experimental evaluations on these datasets have shown significant improvement over state-of-the-art unsupervised methods and our model has outperformed state-of-the-art LI and DI systems in supervised settings.</abstract>
      <url hash="5a84e94b">2020.coling-main.141</url>
    </paper>
    <paper id="142">
      <title>A Two-phase Prototypical Network Model for Incremental Few-shot Relation Classification</title>
      <author><first>Haopeng</first><last>Ren</last></author>
      <author><first>Yi</first><last>Cai</last></author>
      <author><first>Xiaofeng</first><last>Chen</last></author>
      <author><first>Guohua</first><last>Wang</last></author>
      <author><first>Qing</first><last>Li</last></author>
      <pages>1618–1629</pages>
      <abstract>Relation Classification (RC) plays an important role in natural language processing (NLP). Current conventional supervised and distantly supervised RC models always make a closed-world assumption which ignores the emergence of novel relations in open environment. To incrementally recognize the novel relations, current two solutions (i.e, re-training and lifelong learning) are designed but suffer from the lack of large-scale labeled data for novel relations. Meanwhile, prototypical network enjoys better performance on both fields of deep supervised learning and few-shot learning. However, it still suffers from the incompatible feature embedding problem when the novel relations come in. Motivated by them, we propose a two-phase prototypical network with prototype attention alignment and triplet loss to dynamically recognize the novel relations with a few support instances meanwhile without catastrophic forgetting. Extensive experiments are conducted to evaluate the effectiveness of our proposed model.</abstract>
      <url hash="50f4d69d">2020.coling-main.142</url>
    </paper>
    <paper id="143">
      <title>Document-level Relation Extraction with Dual-tier Heterogeneous Graph</title>
      <author><first>Zhenyu</first><last>Zhang</last></author>
      <author><first>Bowen</first><last>Yu</last></author>
      <author><first>Xiaobo</first><last>Shu</last></author>
      <author><first>Tingwen</first><last>Liu</last></author>
      <author><first>Hengzhu</first><last>Tang</last></author>
      <author><first>Wang</first><last>Yubin</last></author>
      <author><first>Li</first><last>Guo</last></author>
      <pages>1630–1641</pages>
      <abstract>Document-level relation extraction (RE) poses new challenges over its sentence-level counterpart since it requires an adequate comprehension of the whole document and the multi-hop reasoning ability across multiple sentences to reach the final result. In this paper, we propose a novel graph-based model with Dual-tier Heterogeneous Graph (DHG) for document-level RE. In particular, DHG is composed of a structure modeling layer followed by a relation reasoning layer. The major advantage is that it is capable of not only capturing both the sequential and structural information of documents but also mixing them together to benefit for multi-hop reasoning and final decision-making. Furthermore, we employ Graph Neural Networks (GNNs) based message propagation strategy to accumulate information on DHG. Experimental results demonstrate that the proposed method achieves state-of-the-art performance on two widely used datasets, and further analyses suggest that all the modules in our model are indispensable for document-level RE.</abstract>
      <url hash="8a978070">2020.coling-main.143</url>
    </paper>
    <paper id="144">
      <title>Biased <fixed-case>T</fixed-case>ext<fixed-case>R</fixed-case>ank: Unsupervised Graph-Based Content Extraction</title>
      <author><first>Ashkan</first><last>Kazemi</last></author>
      <author><first>Verónica</first><last>Pérez-Rosas</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <pages>1642–1652</pages>
      <abstract>We introduce Biased TextRank, a graph-based content extraction method inspired by the popular TextRank algorithm that ranks text spans according to their importance for language processing tasks and according to their relevance to an input “focus.” Biased TextRank enables focused content extraction for text by modifying the random restarts in the execution of TextRank. The random restart probabilities are assigned based on the relevance of the graph nodes to the focus of the task. We present two applications of Biased TextRank: focused summarization and explanation extraction, and show that our algorithm leads to improved performance on two different datasets by significant ROUGE-N score margins. Much like its predecessor, Biased TextRank is unsupervised, easy to implement and orders of magnitude faster and lighter than current state-of-the-art Natural Language Processing methods for similar tasks.</abstract>
      <url hash="a9048070">2020.coling-main.144</url>
    </paper>
    <paper id="145">
      <title>Improving Long-Tail Relation Extraction with Collaborating Relation-Augmented Attention</title>
      <author><first>Yang</first><last>Li</last></author>
      <author><first>Tao</first><last>Shen</last></author>
      <author><first>Guodong</first><last>Long</last></author>
      <author><first>Jing</first><last>Jiang</last></author>
      <author><first>Tianyi</first><last>Zhou</last></author>
      <author><first>Chengqi</first><last>Zhang</last></author>
      <pages>1653–1664</pages>
      <abstract>Wrong labeling problem and long-tail relations are two main challenges caused by distant supervision in relation extraction. Recent works alleviate the wrong labeling by selective attention via multi-instance learning, but cannot well handle long-tail relations even if hierarchies of the relations are introduced to share knowledge. In this work, we propose a novel neural network, Collaborating Relation-augmented Attention (CoRA), to handle both the wrong labeling and long-tail relations. Particularly, we first propose relation-augmented attention network as base model. It operates on sentence bag with a sentence-to-relation attention to minimize the effect of wrong labeling. Then, facilitated by the proposed base model, we introduce collaborating relation features shared among relations in the hierarchies to promote the relation-augmenting process and balance the training data for long-tail relations. Besides the main training objective to predict the relation of a sentence bag, an auxiliary objective is utilized to guide the relation-augmenting process for a more accurate bag-level representation. In the experiments on the popular benchmark dataset NYT, the proposed CoRA improves the prior state-of-the-art performance by a large margin in terms of Precision@N, AUC and Hits@K. Further analyses verify its superior capability in handling long-tail relations in contrast to the competitors.</abstract>
      <url hash="f1bbc9b0">2020.coling-main.145</url>
    </paper>
    <paper id="146">
      <title><fixed-case>T</fixed-case>o<fixed-case>HRE</fixed-case>: A Top-Down Classification Strategy with Hierarchical Bag Representation for Distantly Supervised Relation Extraction</title>
      <author><first>Erxin</first><last>Yu</last></author>
      <author><first>Wenjuan</first><last>Han</last></author>
      <author><first>Yuan</first><last>Tian</last></author>
      <author><first>Yi</first><last>Chang</last></author>
      <pages>1665–1676</pages>
      <abstract>Distantly Supervised Relation Extraction (DSRE) has proven to be effective to find relational facts from texts, but it still suffers from two main problems: the wrong labeling problem and the long-tail problem. Most of the existing approaches address these two problems through flat classification, which lacks hierarchical information of relations. To leverage the informative relation hierarchies, we formulate DSRE as a hierarchical classification task and propose a novel hierarchical classification framework, which extracts the relation in a top-down manner. Specifically, in our proposed framework, 1) we use a hierarchically-refined representation method to achieve hierarchy-specific representation; 2) a top-down classification strategy is introduced instead of training a set of local classifiers. The experiments on NYT dataset demonstrate that our approach significantly outperforms other state-of-the-art approaches, especially for the long-tail problem.</abstract>
      <url hash="42a2027f">2020.coling-main.146</url>
    </paper>
    <paper id="147">
      <title>Unsupervised Fact Checking by Counter-Weighted Positive and Negative Evidential Paths in A Knowledge Graph</title>
      <author><first>Jiseong</first><last>Kim</last></author>
      <author><first>Key-sun</first><last>Choi</last></author>
      <pages>1677–1686</pages>
      <abstract>Misinformation spreads across media, community, and knowledge graphs in the Web by not only human agents but also information extraction algorithms that extract factual statements from unstructured textual data to populate the existing knowledge graphs. Traditional fact checking by experts or crowds is increasingly difficult to keep pace with the volume of newly created misinformation in the Web. Therefore, it is important and necessary to enhance the computational ability to determine whether a given factual statement is truthful or not. We view this problem as a truth scoring task in a knowledge graph. We present a novel rule-based approach that finds positive and negative evidential paths in a knowledge graph for a given factual statement and calculates a truth score for the given statement by unsupervised ensemble of the found positive and negative evidential paths. For example, we can determine the factual statement “United States is the birth place of Barack Obama” as truthful if there is the positive evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) in a knowledge graph. For another example, we can determine the factual statement “Canada is the nationality of Barack Obama” as untruthful if there is the negative evidential path (Barack Obama, nationality, United States) ∧ (United States, ≠, Canada) in a knowledge graph. For evaluating on a real-world situation, we constructed an evaluation dataset by labeling truth or untruth label on factual statements that were extracted from Wikipedia texts by using the state-of-the-art BERT-based information extraction system. Our evaluation results show that our approach outperforms the state-of-the-art unsupervised approaches significantly by up to 0.12 AUC-ROC and even outperforms the supervised approach by up to 0.05 AUC-ROC not only in our dataset but also in the two different standard datasets.</abstract>
      <url hash="c238149d">2020.coling-main.147</url>
    </paper>
    <paper id="148">
      <title>Improving Relation Extraction with Relational Paraphrase Sentences</title>
      <author><first>Junjie</first><last>Yu</last></author>
      <author><first>Tong</first><last>Zhu</last></author>
      <author><first>Wenliang</first><last>Chen</last></author>
      <author><first>Wei</first><last>Zhang</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>1687–1698</pages>
      <abstract>Supervised models for Relation Extraction (RE) typically require human-annotated training data. Due to the limited size, the human-annotated data is usually incapable of covering diverse relation expressions, which could limit the performance of RE. To increase the coverage of relation expressions, we may enlarge the labeled data by hiring annotators or applying Distant Supervision (DS). However, the human-annotated data is costly and non-scalable while the distantly supervised data contains many noises. In this paper, we propose an alternative approach to improve RE systems via enriching diverse expressions by relational paraphrase sentences. Based on an existing labeled data, we first automatically build a task-specific paraphrase data. Then, we propose a novel model to learn the information of diverse relation expressions. In our model, we try to capture this information on the paraphrases via a joint learning framework. Finally, we conduct experiments on a widely used dataset and the experimental results show that our approach is effective to improve the performance on relation extraction, even compared with a strong baseline.</abstract>
      <url hash="174a88d5">2020.coling-main.148</url>
    </paper>
    <paper id="149">
      <title>Autoencoding Improves Pre-trained Word Embeddings</title>
      <author><first>Masahiro</first><last>Kaneko</last></author>
      <author><first>Danushka</first><last>Bollegala</last></author>
      <pages>1699–1713</pages>
      <abstract>Prior works investigating the geometry of pre-trained word embeddings have shown that word embeddings to be distributed in a narrow cone and by centering and projecting using principal component vectors one can increase the accuracy of a given set of pre-trained word embeddings. However, theoretically, this post-processing step is equivalent to applying a linear autoencoder to minimize the squared L2 reconstruction error. This result contradicts prior work (Mu and Viswanath, 2018) that proposed to remove the top principal components from pre-trained embeddings. We experimentally verify our theoretical claims and show that retaining the top principal components is indeed useful for improving pre-trained word embeddings, without requiring access to additional linguistic resources or labeled data.</abstract>
      <url hash="acea39db">2020.coling-main.149</url>
    </paper>
    <paper id="150">
      <title><fixed-case>P</fixed-case>o<fixed-case>D</fixed-case>: Positional Dependency-Based Word Embedding for Aspect Term Extraction</title>
      <author><first>Yichun</first><last>Yin</last></author>
      <author><first>Chenguang</first><last>Wang</last></author>
      <author><first>Ming</first><last>Zhang</last></author>
      <pages>1714–1719</pages>
      <abstract>Dependency context-based word embedding jointly learns the representations of word and dependency context, and has been proved effective in aspect term extraction. In this paper, we design the positional dependency-based word embedding (PoD) which considers both dependency context and positional context for aspect term extraction. Specifically, the positional context is modeled via relative position encoding. Besides, we enhance the dependency context by integrating more lexical information (e.g., POS tags) along dependency paths. Experiments on SemEval 2014/2015/2016 datasets show that our approach outperforms other embedding methods in aspect term extraction.</abstract>
      <url hash="1564532e">2020.coling-main.150</url>
    </paper>
    <paper id="151">
      <title>Unequal Representations: Analyzing Intersectional Biases in Word Embeddings Using Representational Similarity Analysis</title>
      <author><first>Michael</first><last>Lepori</last></author>
      <pages>1720–1728</pages>
      <abstract>We present a new approach for detecting human-like social biases in word embeddings using representational similarity analysis. Specifically, we probe contextualized and non-contextualized embeddings for evidence of intersectional biases against Black women. We show that these embeddings represent Black women as simultaneously less feminine than White women, and less Black than Black men. This finding aligns with intersectionality theory, which argues that multiple identity categories (such as race or sex) layer on top of each other in order to create unique modes of discrimination that are not shared by any individual category.</abstract>
      <url hash="7b4b23fe">2020.coling-main.151</url>
    </paper>
    <paper id="152">
      <title><fixed-case>V</fixed-case>ec2<fixed-case>S</fixed-case>ent: Probing Sentence Embeddings with Natural Language Generation</title>
      <author><first>Martin</first><last>Kerscher</last></author>
      <author><first>Steffen</first><last>Eger</last></author>
      <pages>1729–1736</pages>
      <abstract>We introspect black-box sentence embeddings by conditionally generating from them with the objective to retrieve the underlying discrete sentence. We perceive of this as a new unsupervised probing task and show that it correlates well with downstream task performance. We also illustrate how the language generated from different encoders differs. We apply our approach to generate sentence analogies from sentence embeddings.</abstract>
      <url hash="43cd22bd">2020.coling-main.152</url>
    </paper>
    <paper id="153">
      <title>Multi-Task Learning for Knowledge Graph Completion with Pre-trained Language Models</title>
      <author><first>Bosung</first><last>Kim</last></author>
      <author><first>Taesuk</first><last>Hong</last></author>
      <author><first>Youngjoong</first><last>Ko</last></author>
      <author><first>Jungyun</first><last>Seo</last></author>
      <pages>1737–1743</pages>
      <abstract>As research on utilizing human knowledge in natural language processing has attracted considerable attention in recent years, knowledge graph (KG) completion has come into the spotlight. Recently, a new knowledge graph completion method using a pre-trained language model, such as KG-BERT, is presented and showed high performance. However, its scores in ranking metrics such as Hits@k are still behind state-of-the-art models. We claim that there are two main reasons: 1) failure in sufficiently learning relational information in knowledge graphs, and 2) difficulty in picking out the correct answer from lexically similar candidates. In this paper, we propose an effective multi-task learning method to overcome the limitations of previous works. By combining relation prediction and relevance ranking tasks with our target link prediction, the proposed model can learn more relational properties in KGs and properly perform even when lexical similarity occurs. Experimental results show that we not only largely improve the ranking performances compared to KG-BERT but also achieve the state-of-the-art performances in Mean Rank and Hits@10 on the WN18RR dataset.</abstract>
      <url hash="9aaed09d">2020.coling-main.153</url>
    </paper>
    <paper id="154">
      <title>comp-syn: Perceptually Grounded Word Embeddings with Color</title>
      <author><first>Bhargav</first><last>Srinivasa Desikan</last></author>
      <author><first>Tasker</first><last>Hull</last></author>
      <author><first>Ethan</first><last>Nadler</last></author>
      <author><first>Douglas</first><last>Guilbeault</last></author>
      <author><first>Aabir</first><last>Abubakar Kar</last></author>
      <author><first>Mark</first><last>Chu</last></author>
      <author><first>Donald Ruggiero</first><last>Lo Sardo</last></author>
      <pages>1744–1751</pages>
      <abstract>Popular approaches to natural language processing create word embeddings based on textual co-occurrence patterns, but often ignore embodied, sensory aspects of language. Here, we introduce the Python package comp-syn, which provides grounded word embeddings based on the perceptually uniform color distributions of Google Image search results. We demonstrate that comp-syn significantly enriches models of distributional semantics. In particular, we show that(1) comp-syn predicts human judgments of word concreteness with greater accuracy and in a more interpretable fashion than word2vec using low-dimensional word–color embeddings ,and (2) comp-syn performs comparably to word2vec on a metaphorical vs. literal word-pair classification task. comp-syn is open-source on PyPi and is compatible with mainstream machine-learning Python packages. Our package release includes word–color embeddings forover 40,000 English words, each associated with crowd-sourced word concreteness judgments.</abstract>
      <url hash="cafb289b">2020.coling-main.154</url>
    </paper>
    <paper id="155">
      <title>Try to Substitute: An Unsupervised <fixed-case>C</fixed-case>hinese Word Sense Disambiguation Method Based on <fixed-case>H</fixed-case>ow<fixed-case>N</fixed-case>et</title>
      <author><first>Bairu</first><last>Hou</last></author>
      <author><first>Fanchao</first><last>Qi</last></author>
      <author><first>Yuan</first><last>Zang</last></author>
      <author><first>Xurui</first><last>Zhang</last></author>
      <author><first>Zhiyuan</first><last>Liu</last></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <pages>1752–1757</pages>
      <abstract>Word sense disambiguation (WSD) is a fundamental natural language processing task. Unsupervised knowledge-based WSD only relies on a lexical knowledge base as the sense inventory and has wider practical use than supervised WSD that requires a mass of sense-annotated data. HowNet is the most widely used lexical knowledge base in Chinese WSD. Because of its uniqueness, however, most of existing unsupervised WSD methods cannot work for HowNet-based WSD, and the tailor-made methods have not obtained satisfying results. In this paper, we propose a new unsupervised method for HowNet-based Chinese WSD, which exploits the masked language model task of pre-trained language models. In experiments, considering existing evaluation dataset is small and out-of-date, we build a new and larger HowNet-based WSD dataset. Experimental results demonstrate that our model achieves significantly better performance than all the baseline methods. All the code and data of this paper are available at https://github.com/thunlp/SememeWSD.</abstract>
      <url hash="088aa394">2020.coling-main.155</url>
    </paper>
    <paper id="156">
      <title>Combining Event Semantics and Degree Semantics for Natural Language Inference</title>
      <author><first>Izumi</first><last>Haruta</last></author>
      <author><first>Koji</first><last>Mineshima</last></author>
      <author><first>Daisuke</first><last>Bekki</last></author>
      <pages>1758–1764</pages>
      <abstract>In formal semantics, there are two well-developed semantic frameworks: event semantics, which treats verbs and adverbial modifiers using the notion of event, and degree semantics, which analyzes adjectives and comparatives using the notion of degree. However, it is not obvious whether these frameworks can be combined to handle cases in which the phenomena in question are interacting with each other. Here, we study this issue by focusing on natural language inference (NLI). We implement a logic-based NLI system that combines event semantics and degree semantics and their interaction with lexical knowledge. We evaluate the system on various NLI datasets containing linguistically challenging problems. The results show that the system achieves high accuracies on these datasets in comparison with previous logic-based systems and deep-learning-based systems. This suggests that the two semantic frameworks can be combined consistently to handle various combinations of linguistic phenomena without compromising the advantage of either framework.</abstract>
      <url hash="c2b8ba8d">2020.coling-main.156</url>
    </paper>
    <paper id="157">
      <title>Complaint Identification in Social Media with Transformer Networks</title>
      <author><first>Mali</first><last>Jin</last></author>
      <author><first>Nikolaos</first><last>Aletras</last></author>
      <pages>1765–1771</pages>
      <abstract>Complaining is a speech act extensively used by humans to communicate a negative inconsistency between reality and expectations. Previous work on automatically identifying complaints in social media has focused on using feature-based and task-specific neural network models. Adapting state-of-the-art pre-trained neural language models and their combinations with other linguistic information from topics or sentiment for complaint prediction has yet to be explored. In this paper, we evaluate a battery of neural models underpinned by transformer networks which we subsequently combine with linguistic information. Experiments on a publicly available data set of complaints demonstrate that our models outperform previous state-of-the-art methods by a large margin achieving a macro F1 up to 87.</abstract>
      <url hash="97be8987">2020.coling-main.157</url>
    </paper>
    <paper id="158">
      <title>Syntactically Aware Cross-Domain Aspect and Opinion Terms Extraction</title>
      <author><first>Oren</first><last>Pereg</last></author>
      <author><first>Daniel</first><last>Korat</last></author>
      <author><first>Moshe</first><last>Wasserblat</last></author>
      <pages>1772–1777</pages>
      <abstract>A fundamental task of fine-grained sentiment analysis is aspect and opinion terms extraction. Supervised-learning approaches have shown good results for this task; however, they fail to scale across domains where labeled data is lacking. Non pre-trained unsupervised domain adaptation methods that incorporate external linguistic knowledge have proven effective in transferring aspect and opinion knowledge from a labeled source domain to un-labeled target domains; however, pre-trained transformer-based models like BERT and RoBERTa already exhibit substantial syntactic knowledge. In this paper, we propose a method for incorporating external linguistic information into a self-attention mechanism coupled with the BERT model. This enables leveraging the intrinsic knowledge existing within BERT together with externally introduced syntactic information, to bridge the gap across domains. We successfully demonstrate enhanced results on three benchmark datasets.</abstract>
      <url hash="4d7422d0">2020.coling-main.158</url>
    </paper>
    <paper id="159">
      <title>A Deep Generative Approach to Native Language Identification</title>
      <author><first>Ehsan</first><last>Lotfi</last></author>
      <author><first>Ilia</first><last>Markov</last></author>
      <author><first>Walter</first><last>Daelemans</last></author>
      <pages>1778–1783</pages>
      <abstract>Native language identification (NLI) – identifying the native language (L1) of a person based on his/her writing in the second language (L2) – is useful for a variety of purposes, including marketing, security, and educational applications. From a traditional machine learning perspective,NLI is usually framed as a multi-class classification task, where numerous designed features are combined in order to achieve the state-of-the-art results. We introduce a deep generative language modelling (LM) approach to NLI, which consists in fine-tuning a GPT-2 model separately on texts written by the authors with the same L1, and assigning a label to an unseen text based on the minimum LM loss with respect to one of these fine-tuned GPT-2 models. Our method outperforms traditional machine learning approaches and currently achieves the best results on the benchmark NLI datasets.</abstract>
      <url hash="0607949b">2020.coling-main.159</url>
    </paper>
    <paper id="160">
      <title>Modeling Event Salience in Narratives via Barthes’ Cardinal Functions</title>
      <author><first>Takaki</first><last>Otake</last></author>
      <author><first>Sho</first><last>Yokoi</last></author>
      <author><first>Naoya</first><last>Inoue</last></author>
      <author><first>Ryo</first><last>Takahashi</last></author>
      <author><first>Tatsuki</first><last>Kuribayashi</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <pages>1784–1794</pages>
      <abstract>Events in a narrative differ in salience: some are more important to the story than others. Estimating event salience is useful for tasks such as story generation, and as a tool for text analysis in narratology and folkloristics. To compute event salience without any annotations, we adopt Barthes’ definition of event salience and propose several unsupervised methods that require only a pre-trained language model. Evaluating the proposed methods on folktales with event salience annotation, we show that the proposed methods outperform baseline methods and find fine-tuning a language model on narrative texts is a key factor in improving the proposed methods.</abstract>
      <url hash="cb67fed4">2020.coling-main.160</url>
    </paper>
    <paper id="161">
      <title>Medical Knowledge-enriched Textual Entailment Framework</title>
      <author><first>Shweta</first><last>Yadav</last></author>
      <author><first>Vishal</first><last>Pallagani</last></author>
      <author><first>Amit</first><last>Sheth</last></author>
      <pages>1795–1801</pages>
      <abstract>One of the cardinal tasks in achieving robust medical question answering systems is textual entailment. The existing approaches make use of an ensemble of pre-trained language models or data augmentation, often to clock higher numbers on the validation metrics. However, two major shortcomings impede higher success in identifying entailment: (1) understanding the focus/intent of the question and (2) ability to utilize the real-world background knowledge to capture the con-text beyond the sentence. In this paper, we present a novel Medical Knowledge-Enriched Textual Entailment framework that allows the model to acquire a semantic and global representation of the input medical text with the help of a relevant domain-specific knowledge graph. We evaluate our framework on the benchmark MEDIQA-RQE dataset and manifest that the use of knowledge-enriched dual-encoding mechanism help in achieving an absolute improvement of 8.27% over SOTA language models.</abstract>
      <url hash="bf441ea4">2020.coling-main.161</url>
    </paper>
    <paper id="162">
      <title>Predicting Personal Opinion on Future Events with Fingerprints</title>
      <author><first>Fan</first><last>Yang</last></author>
      <author><first>Eduard</first><last>Dragut</last></author>
      <author><first>Arjun</first><last>Mukherjee</last></author>
      <pages>1802–1807</pages>
      <abstract>Predicting users’ opinions in their response to social events has important real-world applications, many of which political and social impacts. Existing approaches derive a population’s opinion on a going event from large scores of user generated content. In certain scenarios, we may not be able to acquire such content and thus cannot infer an unbiased opinion on those emerging events. To address this problem, we propose to explore opinion on unseen articles based on one’s fingerprinting: the prior reading and commenting history. This work presents a focused study on modeling and leveraging fingerprinting techniques to predict a user’s future opinion. We introduce a recurrent neural network based model that integrates fingerprinting. We collect a large dataset that consists of event-comment pairs from six news websites. We evaluate the proposed model on this dataset. The results show substantial performance gains demonstrating the effectiveness of our approach.</abstract>
      <url hash="a730a246">2020.coling-main.162</url>
    </paper>
    <paper id="163">
      <title>Detecting de minimis Code-Switching in Historical <fixed-case>G</fixed-case>erman Books</title>
      <author><first>Shijia</first><last>Liu</last></author>
      <author><first>David</first><last>Smith</last></author>
      <pages>1808–1814</pages>
      <abstract>Code-switching has long interested linguists, with computational work in particular focusing on speech and social media data (Sitaram et al., 2019). This paper contrasts these informal instances of code-switching to its appearance in more formal registers, by examining the mixture of languages in the Deutsches Textarchiv (DTA), a corpus of 1406 primarily German books from the 17th to 19th centuries. We automatically annotate and manually inspect spans of six embedded languages (Latin, French, English, Italian, Spanish, and Greek) in the corpus. We quantitatively analyze the differences between code-switching patterns in these books and those in more typically studied speech and social media corpora. Furthermore, we address the practical task of predicting code-switching from features of the matrix language alone in the DTA corpus. Such classifiers can help reduce errors when optical character recognition or speech transcription is applied to a large corpus with rare embedded languages.</abstract>
      <url hash="a484b1d6">2020.coling-main.163</url>
    </paper>
    <paper id="164">
      <title>Lin: Unsupervised Extraction of Tasks from Textual Communication</title>
      <author><first>Parth</first><last>Diwanji</last></author>
      <author><first>Hui</first><last>Guo</last></author>
      <author><first>Munindar</first><last>Singh</last></author>
      <author><first>Anup</first><last>Kalia</last></author>
      <pages>1815–1819</pages>
      <abstract>Commitments and requests are a hallmark of collaborative communication, especially in team settings. Identifying specific tasks being committed to or request from emails and chat messages can enable important downstream tasks, such as producing todo lists, reminders, and calendar entries. State-of-the-art approaches for task identification rely on large annotated datasets, which are not always available, especially for domain-specific tasks. Accordingly, we propose Lin, an unsupervised approach of identifying tasks that leverages dependency parsing and VerbNet. Our evaluations show that Lin yields comparable or more accurate results than supervised models on domains with large training sets, and maintains its excellent performance on unseen domains.</abstract>
      <url hash="94c53303">2020.coling-main.164</url>
    </paper>
    <paper id="165">
      <title>Connecting the Dots Between Fact Verification and Fake News Detection</title>
      <author><first>Qifei</first><last>Li</last></author>
      <author><first>Wangchunshu</first><last>Zhou</last></author>
      <pages>1820–1825</pages>
      <abstract>Fact verification models have enjoyed a fast advancement in the last two years with the development of pre-trained language models like BERT and the release of large scale datasets such as FEVER. However, the challenging problem of fake news detection has not benefited from the improvement of fact verification models, which is closely related to fake news detection. In this paper, we propose a simple yet effective approach to connect the dots between fact verification and fake news detection. Our approach first employs a text summarization model pre-trained on news corpora to summarize the long news article into a short claim. Then we use a fact verification model pre-trained on the FEVER dataset to detect whether the input news article is real or fake. Our approach makes use of the recent success of fact verification models and enables zero-shot fake news detection, alleviating the need of large scale training data to train fake news detection models. Experimental results on FakenewsNet, a benchmark dataset for fake news detection, demonstrate the effectiveness of our proposed approach.</abstract>
      <url hash="cbb3d9a5">2020.coling-main.165</url>
    </paper>
    <paper id="166">
      <title>Personalized Multimodal Feedback Generation in Education</title>
      <author><first>Haochen</first><last>Liu</last></author>
      <author><first>Zitao</first><last>Liu</last></author>
      <author><first>Zhongqin</first><last>Wu</last></author>
      <author><first>Jiliang</first><last>Tang</last></author>
      <pages>1826–1840</pages>
      <abstract>The automatic feedback of school assignments is an important application of AI in education. In this work, we focus on the task of personalized multimodal feedback generation, which aims to generate personalized feedback for teachers to evaluate students’ assignments involving multimodal inputs such as images, audios, and texts. This task involves the representation and fusion of multimodal information and natural language generation, which presents the challenges from three aspects: (1) how to encode and integrate multimodal inputs; (2) how to generate feedback specific to each modality; and (3) how to fulfill personalized feedback generation. In this paper, we propose a novel Personalized Multimodal Feedback Generation Network (PMFGN) armed with a modality gate mechanism and a personalized bias mechanism to address these challenges. Extensive experiments on real-world K-12 education data show that our model significantly outperforms baselines by generating more accurate and diverse feedback. In addition, detailed ablation experiments are conducted to deepen our understanding of the proposed framework.</abstract>
      <url hash="e51d5034">2020.coling-main.166</url>
    </paper>
    <paper id="167">
      <title>Reasoning Step-by-Step: Temporal Sentence Localization in Videos via Deep Rectification-Modulation Network</title>
      <author><first>Daizong</first><last>Liu</last></author>
      <author><first>Xiaoye</first><last>Qu</last></author>
      <author><first>Jianfeng</first><last>Dong</last></author>
      <author><first>Pan</first><last>Zhou</last></author>
      <pages>1841–1851</pages>
      <abstract>Temporal sentence localization in videos aims to ground the best matched segment in an untrimmed video according to a given sentence query. Previous works in this field mainly rely on attentional frameworks to align the temporal boundaries by a soft selection. Although they focus on the visual content relevant to the query, these single-step attention are insufficient to model complex video contents and restrict the higher-level reasoning demand for this task. In this paper, we propose a novel deep rectification-modulation network (RMN), transforming this task into a multi-step reasoning process by repeating rectification and modulation. In each rectification-modulation layer, unlike existing methods directly conducting the cross-modal interaction, we first devise a rectification module to correct implicit attention misalignment which focuses on the wrong position during the cross-interaction process. Then, a modulation module is developed to capture the frame-to-frame relation with the help of sentence information for better correlating and composing the video contents over time. With multiple such layers cascaded in depth, our RMN progressively refines video and query interactions, thus enabling a further precise localization. Experimental evaluations on three public datasets show that the proposed method achieves state-of-the-art performance. Extensive ablation studies are carried out for the comprehensive analysis of the proposed method.</abstract>
      <url hash="028b7c90">2020.coling-main.167</url>
    </paper>
    <paper id="168">
      <title><fixed-case>RIVA</fixed-case>: A Pre-trained Tweet Multimodal Model Based on Text-image Relation for Multimodal <fixed-case>NER</fixed-case></title>
      <author><first>Lin</first><last>Sun</last></author>
      <author><first>Jiquan</first><last>Wang</last></author>
      <author><first>Yindu</first><last>Su</last></author>
      <author><first>Fangsheng</first><last>Weng</last></author>
      <author><first>Yuxuan</first><last>Sun</last></author>
      <author><first>Zengwei</first><last>Zheng</last></author>
      <author><first>Yuanyi</first><last>Chen</last></author>
      <pages>1852–1862</pages>
      <abstract>Multimodal named entity recognition (MNER) for tweets has received increasing attention recently. Most of the multimodal methods used attention mechanisms to capture the text-related visual information. However, unrelated or weakly related text-image pairs account for a large proportion in tweets. Visual clues unrelated to the text would incur uncertain or even negative effects for multimodal model learning. In this paper, we propose a novel pre-trained multimodal model based on Relationship Inference and Visual Attention (RIVA) for tweets. The RIVA model controls the attention-based visual clues with a gate regarding the role of image to the semantics of text. We use a teacher-student semi-supervised paradigm to leverage a large unlabeled multimodal tweet corpus with a labeled data set for text-image relation classification. In the multimodal NER task, the experimental results show the significance of text-related visual features for the visual-linguistic model and our approach achieves SOTA performance on the MNER datasets.</abstract>
      <url hash="5e71f125">2020.coling-main.168</url>
    </paper>
    <paper id="169">
      <title>Towards Knowledge-Augmented Visual Question Answering</title>
      <author><first>Maryam</first><last>Ziaeefard</last></author>
      <author><first>Freddy</first><last>Lecue</last></author>
      <pages>1863–1873</pages>
      <abstract>Visual Question Answering (VQA) remains algorithmically challenging while it is effortless for humans. Humans combine visual observations with general and commonsense knowledge to answer questions about a given image. In this paper, we address the problem of incorporating general knowledge into VQA models while leveraging the visual information. We propose a model that captures the interactions between objects in a visual scene and entities in an external knowledge source. Our model is a graph-based approach that combines scene graphs with concept graphs, which learns a question-adaptive graph representation of related knowledge instances. We use Graph Attention Networks to set higher importance to key knowledge instances that are mostly relevant to each question. We exploit ConceptNet as the source of general knowledge and evaluate the performance of our model on the challenging OK-VQA dataset.</abstract>
      <url hash="63f81e25">2020.coling-main.169</url>
    </paper>
    <paper id="170">
      <title>Visual-Textual Alignment for Graph Inference in Visual Dialog</title>
      <author><first>Tianling</first><last>Jiang</last></author>
      <author><first>Yi</first><last>Ji</last></author>
      <author><first>Chunping</first><last>Liu</last></author>
      <author><first>Hailin</first><last>Shao</last></author>
      <pages>1874–1885</pages>
      <abstract>As a conversational intelligence task, visual dialog entails answering a series of questions grounded in an image, using the dialog history as context. To generate correct answers, the comprehension of the semantic dependencies among implicit visual and textual contents is critical. Prior works usually ignored the underlying relation and failed to infer it reasonably. In this paper, we propose a Visual-Textual Alignment for Graph Inference (VTAGI) network. Compared with other approaches, it makes up the lack of structural inference in visual dialog. The whole system consists of two modules, Visual and Textual Alignment (VTA) and Visual Graph Attended by Text (VGAT). Specially, the VTA module aims at representing an image with a set of integrated visual regions and corresponding textual concepts, reflecting certain semantics. The VGAT module views the visual features with semantic information as observed nodes and each node learns the relationship with others in visual graph. We also qualitatively and quantitatively evaluate the model on VisDial v1.0 dataset, showing our VTAGI outperforms previous state-of-the-art models.</abstract>
      <url hash="d602f9cd">2020.coling-main.170</url>
    </paper>
    <paper id="171">
      <title>Ad Lingua: Text Classification Improves Symbolism Prediction in Image Advertisements</title>
      <author><first>Andrey</first><last>Savchenko</last></author>
      <author><first>Anton</first><last>Alekseev</last></author>
      <author><first>Sejeong</first><last>Kwon</last></author>
      <author><first>Elena</first><last>Tutubalina</last></author>
      <author><first>Evgeny</first><last>Myasnikov</last></author>
      <author><first>Sergey</first><last>Nikolenko</last></author>
      <pages>1886–1892</pages>
      <abstract>Understanding image advertisements is a challenging task, often requiring non-literal interpretation. We argue that standard image-based predictions are insufficient for symbolism prediction. Following the intuition that texts and images are complementary in advertising, we introduce a multimodal ensemble of a state of the art image-based classifier, a classifier based on an object detection architecture, and a fine-tuned language model applied to texts extracted from ads by OCR. The resulting system establishes a new state of the art in symbolism prediction.</abstract>
      <url hash="6abbead8">2020.coling-main.171</url>
    </paper>
    <paper id="172">
      <title>Humans Meet Models on Object Naming: A New Dataset and Analysis</title>
      <author><first>Carina</first><last>Silberer</last></author>
      <author><first>Sina</first><last>Zarrieß</last></author>
      <author><first>Matthijs</first><last>Westera</last></author>
      <author><first>Gemma</first><last>Boleda</last></author>
      <pages>1893–1905</pages>
      <abstract>We release ManyNames v2 (MN v2), a verified version of an object naming dataset that contains dozens of valid names per object for 25K images. We analyze issues in the data collection method originally employed, standard in Language &amp; Vision (L&amp;V), and find that the main source of noise in the data comes from simulating a naming context solely from an image with a target object marked with a bounding box, which causes subjects to sometimes disagree regarding which object is the target. We also find that both the degree of this uncertainty in the original data and the amount of true naming variation in MN v2 differs substantially across object domains. We use MN v2 to analyze a popular L&amp;V model and demonstrate its effectiveness on the task of object naming. However, our fine-grained analysis reveals that what appears to be human-like model behavior is not stable across domains, e.g., the model confuses people and clothing objects much more frequently than humans do. We also find that standard evaluations underestimate the actual effectiveness of the naming model: on the single-label names of the original dataset (Visual Genome), it obtains −27% accuracy points than on MN v2, that includes all valid object names.</abstract>
      <url hash="e53ac11a">2020.coling-main.172</url>
    </paper>
    <paper id="173">
      <title>Encoding Lexico-Semantic Knowledge using Ensembles of Feature Maps from Deep Convolutional Neural Networks</title>
      <author><first>Steven</first><last>Derby</last></author>
      <author><first>Paul</first><last>Miller</last></author>
      <author><first>Barry</first><last>Devereux</last></author>
      <pages>1906–1921</pages>
      <abstract>Semantic models derived from visual information have helped to overcome some of the limitations of solely text-based distributional semantic models. Researchers have demonstrated that text and image-based representations encode complementary semantic information, which when combined provide a more complete representation of word meaning, in particular when compared with data on human conceptual knowledge. In this work, we reveal that these vision-based representations, whilst quite effective, do not make use of all the semantic information available in the neural network that could be used to inform vector-based models of semantic representation. Instead, we build image-based meta-embeddings from computer vision models, which can incorporate information from all layers of the network, and show that they encode a richer set of semantic attributes and yield a more complete representation of human conceptual knowledge.</abstract>
      <url hash="145d1b8f">2020.coling-main.173</url>
    </paper>
    <paper id="174">
      <title>Language-Driven Region Pointer Advancement for Controllable Image Captioning</title>
      <author><first>Annika</first><last>Lindh</last></author>
      <author><first>Robert</first><last>Ross</last></author>
      <author><first>John</first><last>Kelleher</last></author>
      <pages>1922–1935</pages>
      <abstract>Controllable Image Captioning is a recent sub-field in the multi-modal task of Image Captioning wherein constraints are placed on which regions in an image should be described in the generated natural language caption. This puts a stronger focus on producing more detailed descriptions, and opens the door for more end-user control over results. A vital component of the Controllable Image Captioning architecture is the mechanism that decides the timing of attending to each region through the advancement of a region pointer. In this paper, we propose a novel method for predicting the timing of region pointer advancement by treating the advancement step as a natural part of the language structure via a NEXT-token, motivated by a strong correlation to the sentence structure in the training data. We find that our timing agrees with the ground-truth timing in the Flickr30k Entities test data with a precision of 86.55% and a recall of 97.92%. Our model implementing this technique improves the state-of-the-art on standard captioning metrics while additionally demonstrating a considerably larger effective vocabulary size.</abstract>
      <url hash="0bbea776">2020.coling-main.174</url>
    </paper>
    <paper id="175">
      <title>Offensive Language Detection on Video Live Streaming Chat</title>
      <author><first>Zhiwei</first><last>Gao</last></author>
      <author><first>Shuntaro</first><last>Yada</last></author>
      <author><first>Shoko</first><last>Wakamiya</last></author>
      <author><first>Eiji</first><last>Aramaki</last></author>
      <pages>1936–1940</pages>
      <abstract>This paper presents a prototype of a chat room that detects offensive expressions in a video live streaming chat in real time. Focusing on Twitch, one of the most popular live streaming platforms, we created a dataset for the task of detecting offensive expressions. We collected 2,000 chat posts across four popular game titles with genre diversity (e.g., competitive, violent, peaceful). To make use of the similarity in offensive expressions among different social media platforms, we adopted state-of-the-art models trained on offensive expressions from Twitter for our Twitch data (i.e., transfer learning). We investigated two similarity measurements to predict the transferability, textual similarity, and game-genre similarity. Our results show that the transfer of features from social media to live streaming is effective. However, the two measurements show less correlation in the transferability prediction.</abstract>
      <url hash="4ad64c79">2020.coling-main.175</url>
    </paper>
    <paper id="176">
      <title>Image Caption Generation for News Articles</title>
      <author><first>Zhishen</first><last>Yang</last></author>
      <author><first>Naoaki</first><last>Okazaki</last></author>
      <pages>1941–1951</pages>
      <abstract>In this paper, we address the task of news-image captioning, which generates a description of an image given the image and its article body as input. This task is more challenging than the conventional image captioning, because it requires a joint understanding of image and text. We present a Transformer model that integrates text and image modalities and attends to textual features from visual features in generating a caption. Experiments based on automatic evaluation metrics and human evaluation show that an article text provides primary information to reproduce news-image captions written by journalists. The results also demonstrate that the proposed model outperforms the state-of-the-art model. In addition, we also confirm that visual features contribute to improving the quality of news-image captions.</abstract>
      <url hash="048fa540">2020.coling-main.176</url>
    </paper>
    <paper id="177">
      <title><fixed-case>C</fixed-case>o<fixed-case>NAN</fixed-case>: A Complementary Neighboring-based Attention Network for Referring Expression Generation</title>
      <author><first>Jungjun</first><last>Kim</last></author>
      <author><first>Hanbin</first><last>Ko</last></author>
      <author><first>Jialin</first><last>Wu</last></author>
      <pages>1952–1962</pages>
      <abstract>Daily scenes are complex in the real world due to occlusion, undesired lighting conditions, etc. Although humans handle those complicated environments well, they evoke challenges for machine learning systems to identify and describe the target without ambiguity. Most previous research focuses on mining discriminating features within the same category for the target object. One the other hand, as the scene becomes more complicated, human frequently uses the neighbor objects as complementary information to describe the target one. Motivated by that, we propose a novel Complementary Neighboring-based Attention Network (CoNAN) that explicitly utilizes the visual differences between the target object and its highly-related neighbors. These highly-related neighbors are determined by an attentional ranking module, as complementary features, highlighting the discriminating aspects for the target object. The speaker module then takes the visual difference features as an additional input to generate the expression. Our qualitative and quantitative results on the dataset RefCOCO, RefCOCO+, and RefCOCOg demonstrate that our generated expressions outperform other state-of-the-art models by a clear margin.</abstract>
      <url hash="c84740d9">2020.coling-main.177</url>
    </paper>
    <paper id="178">
      <title>Mark-Evaluate: Assessing Language Generation using Population Estimation Methods</title>
      <author><first>Gonçalo</first><last>Mordido</last></author>
      <author><first>Christoph</first><last>Meinel</last></author>
      <pages>1963–1977</pages>
      <abstract>We propose a family of metrics to assess language generation derived from population estimation methods widely used in ecology. More specifically, we use mark-recapture and maximum-likelihood methods that have been applied over the past several decades to estimate the size of closed populations in the wild. We propose three novel metrics: ME<tex-math>_\text{Petersen}</tex-math> and ME<tex-math>_\text{CAPTURE}</tex-math>, which retrieve a single-valued assessment, and ME<tex-math>_\text{Schnabel}</tex-math> which returns a double-valued metric to assess the evaluation set in terms of quality and diversity, separately. In synthetic experiments, our family of methods is sensitive to drops in quality and diversity. Moreover, our methods show a higher correlation to human evaluation than existing metrics on several challenging tasks, namely unconditional language generation, machine translation, and text summarization.</abstract>
      <url hash="c239ea4d">2020.coling-main.178</url>
    </paper>
    <paper id="179">
      <title><fixed-case>T</fixed-case>able<fixed-case>GPT</fixed-case>: Few-shot Table-to-Text Generation with Table Structure Reconstruction and Content Matching</title>
      <author><first>Heng</first><last>Gong</last></author>
      <author><first>Yawei</first><last>Sun</last></author>
      <author><first>Xiaocheng</first><last>Feng</last></author>
      <author><first>Bing</first><last>Qin</last></author>
      <author><first>Wei</first><last>Bi</last></author>
      <author><first>Xiaojiang</first><last>Liu</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <pages>1978–1988</pages>
      <abstract>Although neural table-to-text models have achieved remarkable progress with the help of large-scale datasets, they suffer insufficient learning problem with limited training data. Recently, pre-trained language models show potential in few-shot learning with linguistic knowledge learnt from pretraining on large-scale corpus. However, benefiting table-to-text generation in few-shot setting with the powerful pretrained language model faces three challenges, including (1) the gap between the task’s structured input and the natural language input for pretraining language model. (2) The lack of modeling for table structure and (3) improving text fidelity with less incorrect expressions that are contradicting to the table. To address aforementioned problems, we propose TableGPT for table-to-text generation. At first, we utilize table transformation module with template to rewrite structured table in natural language as input for GPT-2. In addition, we exploit multi-task learning with two auxiliary tasks that preserve table’s structural information by reconstructing the structure from GPT-2’s representation and improving the text’s fidelity with content matching task aligning the table and information in the generated text. By experimenting on Humans, Songs and Books, three few-shot table-to-text datasets in different domains, our model outperforms existing systems on most few-shot settings.</abstract>
      <url hash="59da6617">2020.coling-main.179</url>
    </paper>
    <paper id="180">
      <title>The <fixed-case>A</fixed-case>ppos<fixed-case>C</fixed-case>orpus: a new multilingual, multi-domain dataset for factual appositive generation</title>
      <author><first>Yova</first><last>Kementchedjhieva</last></author>
      <author><first>Di</first><last>Lu</last></author>
      <author><first>Joel</first><last>Tetreault</last></author>
      <pages>1989–2003</pages>
      <abstract>News articles, image captions, product reviews and many other texts mention people and organizations whose name recognition could vary for different audiences. In such cases, background information about the named entities could be provided in the form of an appositive noun phrase, either written by a human or generated automatically. We expand on the previous work in appositive generation with a new, more realistic, end-to-end definition of the task, instantiated by a dataset that spans four languages (English, Spanish, German and Polish), two entity types (person and organization) and two domains (Wikipedia and News). We carry out an extensive analysis of the data and the task, pointing to the various modeling challenges it poses. The results we obtain with standard language generation methods show that the task is indeed non-trivial, and leaves plenty of room for improvement.</abstract>
      <url hash="a97c130d">2020.coling-main.180</url>
    </paper>
    <paper id="181">
      <title>Generalized Shortest-Paths Encoders for <fixed-case>AMR</fixed-case>-to-Text Generation</title>
      <author><first>Lisa</first><last>Jin</last></author>
      <author><first>Daniel</first><last>Gildea</last></author>
      <pages>2004–2013</pages>
      <abstract>For text generation from semantic graphs, past neural models encoded input structure via gated convolutions along graph edges. Although these operations provide local context, the distance messages can travel is bounded by the number of encoder propagation steps. We adopt recent efforts of applying Transformer self-attention to graphs to allow global feature propagation. Instead of feeding shortest paths to the vertex self-attention module, we train a model to learn them using generalized shortest-paths algorithms. This approach widens the receptive field of a graph encoder by exposing it to all possible graph paths. We explore how this path diversity affects performance across levels of AMR connectivity, demonstrating gains on AMRs of higher reentrancy counts and diameters. Analysis of generated sentences also supports high semantic coherence of our models for reentrant AMRs. Our best model achieves a 1.4 BLEU and 1.8 chrF++ margin over a baseline that encodes only pairwise-unique shortest paths.</abstract>
      <url hash="9077fb95">2020.coling-main.181</url>
    </paper>
    <paper id="182">
      <title>An Enhanced Knowledge Injection Model for Commonsense Generation</title>
      <author><first>Zhihao</first><last>Fan</last></author>
      <author><first>Yeyun</first><last>Gong</last></author>
      <author><first>Zhongyu</first><last>Wei</last></author>
      <author><first>Siyuan</first><last>Wang</last></author>
      <author><first>Yameng</first><last>Huang</last></author>
      <author><first>Jian</first><last>Jiao</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <author><first>Nan</first><last>Duan</last></author>
      <author><first>Ruofei</first><last>Zhang</last></author>
      <pages>2014–2025</pages>
      <abstract>Commonsense generation aims at generating plausible everyday scenario description based on a set of provided concepts. Digging the relationship of concepts from scratch is non-trivial, therefore, we retrieve prototypes from external knowledge to assist the understanding of the scenario for better description generation. We integrate two additional modules into the pretrained encoder-decoder model for prototype modeling to enhance the knowledge injection procedure. We conduct experiment on CommonGen benchmark, experimental results show that our method significantly improves the performance on all the metrics.</abstract>
      <url hash="64c06459">2020.coling-main.182</url>
    </paper>
    <paper id="183">
      <title>Multi-grained <fixed-case>C</fixed-case>hinese Word Segmentation with Weakly Labeled Data</title>
      <author><first>Chen</first><last>Gong</last></author>
      <author><first>Zhenghua</first><last>Li</last></author>
      <author><first>Bowei</first><last>Zou</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>2026–2036</pages>
      <abstract>In contrast with the traditional single-grained word segmentation (SWS), where a sentence corresponds to a single word sequence, multi-grained Chinese word segmentation (MWS) aims to segment a sentence into multiple word sequences to preserve all words of different granularities. Due to the lack of manually annotated MWS data, previous work train and tune MWS models only on automatically generated pseudo MWS data. In this work, we further take advantage of the rich word boundary information in existing SWS data and naturally annotated data from dictionary example (DictEx) sentences, to advance the state-of-the-art MWS model based on the idea of weak supervision. Particularly, we propose to accommodate two types of weakly labeled data for MWS, i.e., SWS data and DictEx data by employing a simple yet competitive graph-based parser with local loss. Besides, we manually annotate a high-quality MWS dataset according to our newly compiled annotation guideline, consisting of over 9,000 sentences from two types of texts, i.e., canonical newswire (NEWS) and non-canonical web (BAIKE) data for better evaluation. Detailed evaluation shows that our proposed model with weakly labeled data significantly outperforms the state-of-the-art MWS model by 1.12 and 5.97 on NEWS and BAIKE data in F1.</abstract>
      <url hash="bded6266">2020.coling-main.183</url>
    </paper>
    <paper id="184">
      <title><fixed-case>K</fixed-case>ey<fixed-case>G</fixed-case>ames: A Game Theoretic Approach to Automatic Keyphrase Extraction</title>
      <author><first>Arnav</first><last>Saxena</last></author>
      <author><first>Mudit</first><last>Mangal</last></author>
      <author><first>Goonjan</first><last>Jain</last></author>
      <pages>2037–2048</pages>
      <abstract>In this paper, we introduce two advancements in the automatic keyphrase extraction (AKE) space - KeyGames and pke+. KeyGames is an unsupervised AKE framework that employs the concept of evolutionary game theory and consistent labelling problem to ensure consistent classification of candidates into keyphrase and non-keyphrase. Pke+ is a python based pipeline built on top of the existing pke library to standardize various AKE steps, namely candidate extraction and evaluation, to ensure truly systematic and comparable performance analysis of AKE models. In the experiments section, we compare the performance of KeyGames across three publicly available datasets (Inspec 2001, SemEval 2010, DUC 2001) against the results quoted by the existing state-of-the-art models as well as their performance when reproduced using pke+. The results show that KeyGames outperforms most of the state-of-the-art systems while generalizing better on input documents with different domains and length. Further, pke+’s pre-processing brings out improvement in several other system’s quoted performance as well.</abstract>
      <url hash="6f981ddc">2020.coling-main.184</url>
    </paper>
    <paper id="185">
      <title>Parsers Know Best: <fixed-case>G</fixed-case>erman <fixed-case>PP</fixed-case> Attachment Revisited</title>
      <author><first>Bich-Ngoc</first><last>Do</last></author>
      <author><first>Ines</first><last>Rehbein</last></author>
      <pages>2049–2061</pages>
      <abstract>In the paper, we revisit the PP attachment problem which has been identified as one of the major sources for parser errors and discuss shortcomings of recent work. In particular, we show that using gold information for the extraction of attachment candidates as well as a missing comparison of the system’s output to the output of a full syntactic parser leads to an overly optimistic assessment of the results. We address these issues by presenting a realistic evaluation of the potential of different PP attachment systems, using fully predicted information as system input. We compare our results against the output of a strong neural parser and show that the full parsing approach is superior to modeling PP attachment disambiguation as a separate task.</abstract>
      <url hash="20b281b8">2020.coling-main.185</url>
    </paper>
    <paper id="186">
      <title>Towards Fast and Accurate Neural <fixed-case>C</fixed-case>hinese Word Segmentation with Multi-Criteria Learning</title>
      <author><first>Weipeng</first><last>Huang</last></author>
      <author><first>Xingyi</first><last>Cheng</last></author>
      <author><first>Kunlong</first><last>Chen</last></author>
      <author><first>Taifeng</first><last>Wang</last></author>
      <author><first>Wei</first><last>Chu</last></author>
      <pages>2062–2072</pages>
      <abstract>The ambiguous annotation criteria lead to divergence of Chinese Word Segmentation (CWS) datasets in various granularities. Multi-criteria Chinese word segmentation aims to capture various annotation criteria among datasets and leverage their common underlying knowledge. In this paper, we propose a domain adaptive segmenter to exploit diverse criteria of various datasets. Our model is based on Bidirectional Encoder Representations from Transformers (BERT), which is responsible for introducing open-domain knowledge. Private and shared projection layers are proposed to capture domain-specific knowledge and common knowledge, respectively. We also optimize computational efficiency via distillation, quantization, and compiler optimization. Experiments show that our segmenter outperforms the previous state of the art (SOTA) models on 10 CWS datasets with superior efficiency.</abstract>
      <url hash="fac45d30">2020.coling-main.186</url>
    </paper>
    <paper id="187">
      <title>Joint <fixed-case>C</fixed-case>hinese Word Segmentation and Part-of-speech Tagging via Multi-channel Attention of Character N-grams</title>
      <author><first>Yuanhe</first><last>Tian</last></author>
      <author><first>Yan</first><last>Song</last></author>
      <author><first>Fei</first><last>Xia</last></author>
      <pages>2073–2084</pages>
      <abstract>Chinese word segmentation (CWS) and part-of-speech (POS) tagging are two fundamental tasks for Chinese language processing. Previous studies have demonstrated that jointly performing them can be an effective one-step solution to both tasks and this joint task can benefit from a good modeling of contextual features such as n-grams. However, their work on modeling such contextual features is limited to concatenating the features or their embeddings directly with the input embeddings without distinguishing whether the contextual features are important for the joint task in the specific context. Therefore, their models for the joint task could be misled by unimportant contextual information. In this paper, we propose a character-based neural model for the joint task enhanced by multi-channel attention of n-grams. In the attention module, n-gram features are categorized into different groups according to several criteria, and n-grams in each group are weighted and distinguished according to their importance for the joint task in the specific context. To categorize n-grams, we try two criteria in this study, i.e., n-gram frequency and length, so that n-grams having different capabilities of carrying contextual information are discriminatively learned by our proposed attention module. Experimental results on five benchmark datasets for CWS and POS tagging demonstrate that our approach outperforms strong baseline models and achieves state-of-the-art performance on all five datasets.</abstract>
      <url hash="3770cea2">2020.coling-main.187</url>
    </paper>
    <paper id="188">
      <title>Taking the Correction Difficulty into Account in Grammatical Error Correction Evaluation</title>
      <author><first>Takumi</first><last>Gotou</last></author>
      <author><first>Ryo</first><last>Nagata</last></author>
      <author><first>Masato</first><last>Mita</last></author>
      <author><first>Kazuaki</first><last>Hanawa</last></author>
      <pages>2085–2095</pages>
      <abstract>This paper presents performance measures for grammatical error correction which take into account the difficulty of error correction. To the best of our knowledge, no conventional measure has such functionality despite the fact that some errors are easy to correct and others are not. The main purpose of this work is to provide a way of determining the difficulty of error correction and to motivate researchers in the domain to attack such difficult errors. The performance measures are based on the simple idea that the more systems successfully correct an error, the easier it is considered to be. This paper presents a set of algorithms to implement this idea. It evaluates the performance measures quantitatively and qualitatively on a wide variety of corpora and systems, revealing that they agree with our intuition of correction difficulty. A scorer and difficulty weight data based on the algorithms have been made available on the web.</abstract>
      <url hash="aa83b157">2020.coling-main.188</url>
    </paper>
    <paper id="189">
      <title>Automatic Distractor Generation for Multiple Choice Questions in Standard Tests</title>
      <author><first>Zhaopeng</first><last>Qiu</last></author>
      <author><first>Xian</first><last>Wu</last></author>
      <author><first>Wei</first><last>Fan</last></author>
      <pages>2096–2106</pages>
      <abstract>To assess knowledge proficiency of a learner, multiple choice question is an efficient and widespread form in standard tests. However, the composition of the multiple choice question, especially the construction of distractors is quite challenging. The distractors are required to both incorrect and plausible enough to confuse the learners who did not master the knowledge. Currently, the distractors are generated by domain experts which are both expensive and time-consuming. This urges the emergence of automatic distractor generation, which can benefit various standard tests in a wide range of domains. In this paper, we propose a question and answer guided distractor generation (EDGE) framework to automate distractor generation. EDGE consists of three major modules: (1) the Reforming Question Module and the Reforming Passage Module apply gate layers to guarantee the inherent incorrectness of the generated distractors; (2) the Distractor Generator Module applies attention mechanism to control the level of plausibility. Experimental results on a large-scale public dataset demonstrate that our model significantly outperforms existing models and achieves a new state-of-the-art.</abstract>
      <url hash="b6f44f82">2020.coling-main.189</url>
    </paper>
    <paper id="190">
      <title>Towards A Friendly Online Community: An Unsupervised Style Transfer Framework for Profanity Redaction</title>
      <author><first>Minh</first><last>Tran</last></author>
      <author><first>Yipeng</first><last>Zhang</last></author>
      <author><first>Mohammad</first><last>Soleymani</last></author>
      <pages>2107–2114</pages>
      <abstract>Offensive and abusive language is a pressing problem on social media platforms. In this work, we propose a method for transforming offensive comments, statements containing profanity or offensive language, into non-offensive ones. We design a Retrieve, Generate and Edit unsupervised style transfer pipeline to redact the offensive comments in a word-restricted manner while maintaining a high level of fluency and preserving the content of the original text. We extensively evaluate our method’s performance and compare it to previous style transfer models using both automatic metrics and human evaluations. Experimental results show that our method outperforms other models on human evaluations and is the only approach that consistently performs well on all automatic evaluation metrics.</abstract>
      <url hash="d94e5153">2020.coling-main.190</url>
    </paper>
    <paper id="191">
      <title>How Positive Are You: Text Style Transfer using Adaptive Style Embedding</title>
      <author><first>Heejin</first><last>Kim</last></author>
      <author><first>Kyung-Ah</first><last>Sohn</last></author>
      <pages>2115–2125</pages>
      <abstract>The prevalent approach for unsupervised text style transfer is disentanglement between content and style. However, it is difficult to completely separate style information from the content. Other approaches allow the latent text representation to contain style and the target style to affect the generated output more than the latent representation does. In both approaches, however, it is impossible to adjust the strength of the style in the generated output. Moreover, those previous approaches typically perform both the sentence reconstruction and style control tasks in a single model, which complicates the overall architecture. In this paper, we address these issues by separating the model into a sentence reconstruction module and a style module. We use the Transformer-based autoencoder model for sentence reconstruction and the adaptive style embedding is learned directly in the style module. Because of this separation, each module can better focus on its own task. Moreover, we can vary the style strength of the generated sentence by changing the style of the embedding expression. Therefore, our approach not only controls the strength of the style, but also simplifies the model architecture. Experimental results show that our approach achieves better style transfer performance and content preservation than previous approaches.</abstract>
      <url hash="c03067ea">2020.coling-main.191</url>
    </paper>
    <paper id="192">
      <title>Neural text normalization leveraging similarities of strings and sounds</title>
      <author><first>Riku</first><last>Kawamura</last></author>
      <author><first>Tatsuya</first><last>Aoki</last></author>
      <author><first>Hidetaka</first><last>Kamigaito</last></author>
      <author><first>Hiroya</first><last>Takamura</last></author>
      <author><first>Manabu</first><last>Okumura</last></author>
      <pages>2126–2131</pages>
      <abstract>We propose neural models that can normalize text by considering the similarities of word strings and sounds. We experimentally compared a model that considers the similarities of both word strings and sounds, a model that considers only the similarity of word strings or of sounds, and a model without the similarities as a baseline. Results showed that leveraging the word string similarity succeeded in dealing with misspellings and abbreviations, and taking into account the sound similarity succeeded in dealing with phonetic substitutions and emphasized characters. So that the proposed models achieved higher F1 scores than the baseline.</abstract>
      <url hash="1a16cb92">2020.coling-main.192</url>
    </paper>
    <paper id="193">
      <title>Generating Diverse Corrections with Local Beam Search for Grammatical Error Correction</title>
      <author><first>Kengo</first><last>Hotate</last></author>
      <author><first>Masahiro</first><last>Kaneko</last></author>
      <author><first>Mamoru</first><last>Komachi</last></author>
      <pages>2132–2137</pages>
      <abstract>In this study, we propose a beam search method to obtain diverse outputs in a local sequence transduction task where most of the tokens in the source and target sentences overlap, such as in grammatical error correction (GEC). In GEC, it is advisable to rewrite only the local sequences that must be rewritten while leaving the correct sequences unchanged. However, existing methods of acquiring various outputs focus on revising all tokens of a sentence. Therefore, existing methods may either generate ungrammatical sentences because they force the entire sentence to be changed or produce non-diversified sentences by weakening the constraints to avoid generating ungrammatical sentences. Considering these issues, we propose a method that does not rewrite all the tokens in a text, but only rewrites those parts that need to be diversely corrected. Our beam search method adjusts the search token in the beam according to the probability that the prediction is copied from the source sentence. The experimental results show that our proposed method generates more diverse corrections than existing methods without losing accuracy in the GEC task.</abstract>
      <url hash="e374aa42">2020.coling-main.193</url>
    </paper>
    <paper id="194">
      <title>A Neural Local Coherence Analysis Model for Clarity Text Scoring</title>
      <author><first>Panitan</first><last>Muangkammuen</last></author>
      <author><first>Sheng</first><last>Xu</last></author>
      <author><first>Fumiyo</first><last>Fukumoto</last></author>
      <author><first>Kanda</first><last>Runapongsa Saikaew</last></author>
      <author><first>Jiyi</first><last>Li</last></author>
      <pages>2138–2143</pages>
      <abstract>Local coherence relation between two phrases/sentences such as cause-effect and contrast gives a strong influence of whether a text is well-structured or not. This paper follows the assumption and presents a method for scoring text clarity by utilizing local coherence between adjacent sentences. We hypothesize that the contextual features of coherence relations learned by utilizing different data from the target training data are also possible to discriminate well-structured of the target text and thus help to score the text clarity. We propose a text clarity scoring method that utilizes local coherence analysis with an out-domain setting, i.e. the training data for the source and target tasks are different from each other. The method with language model pre-training BERT firstly trains the local coherence model as an auxiliary manner and then re-trains it together with clarity text scoring model. The experimental results by using the PeerRead benchmark dataset show the improvement compared with a single model, scoring text clarity model. Our source codes are available online.</abstract>
      <url hash="345a29da">2020.coling-main.194</url>
    </paper>
    <paper id="195">
      <title>Grammatical error detection in transcriptions of spoken <fixed-case>E</fixed-case>nglish</title>
      <author><first>Andrew</first><last>Caines</last></author>
      <author><first>Christian</first><last>Bentz</last></author>
      <author><first>Kate</first><last>Knill</last></author>
      <author><first>Marek</first><last>Rei</last></author>
      <author><first>Paula</first><last>Buttery</last></author>
      <pages>2144–2162</pages>
      <abstract>We describe the collection of transcription corrections and grammatical error annotations for the CrowdED Corpus of spoken English monologues on business topics. The corpus recordings were crowdsourced from native speakers of English and learners of English with German as their first language. The new transcriptions and annotations are obtained from different crowdworkers: we analyse the 1108 new crowdworker submissions and propose that they can be used for automatic transcription post-editing and grammatical error correction for speech. To further explore the data we train grammatical error detection models with various configurations including pre-trained and contextual word representations as input, additional features and auxiliary objectives, and extra training data from written error-annotated corpora. We find that a model concatenating pre-trained and contextual word representations as input performs best, and that additional information does not lead to further performance gains.</abstract>
      <url hash="4cdfa216">2020.coling-main.195</url>
    </paper>
    <paper id="196">
      <title>Automatic Assistance for Academic Word Usage</title>
      <author><first>Dariush</first><last>Saberi</last></author>
      <author><first>John</first><last>Lee</last></author>
      <author><first>Jonathan</first><last>James Webster</last></author>
      <pages>2163–2168</pages>
      <abstract>This paper describes a writing assistance system that helps students improve their academic writing. Given an input text, the system suggests lexical substitutions that aim to incorporate more academic vocabulary. The substitution candidates are drawn from an academic word list and ranked by a masked language model. Experimental results show that lexical formality analysis can improve the quality of the suggestions, in comparison to a baseline that relies on the masked language model only.</abstract>
      <url hash="29a405e7">2020.coling-main.196</url>
    </paper>
    <paper id="197">
      <title>Style versus Content: A distinction without a (learnable) difference?</title>
      <author><first>Somayeh</first><last>Jafaritazehjani</last></author>
      <author><first>Gwénolé</first><last>Lecorvé</last></author>
      <author><first>Damien</first><last>Lolive</last></author>
      <author><first>John</first><last>Kelleher</last></author>
      <pages>2169–2180</pages>
      <abstract>Textual style transfer involves modifying the style of a text while preserving its content. This assumes that it is possible to separate style from content. This paper investigates whether this separation is possible. We use sentiment transfer as our case study for style transfer analysis. Our experimental methodology frames style transfer as a multi-objective problem, balancing style shift with content preservation and fluency. Due to the lack of parallel data for style transfer we employ a variety of adversarial encoder-decoder networks in our experiments. Also, we use of a probing methodology to analyse how these models encode style-related features in their latent spaces. The results of our experiments which are further confirmed by a human evaluation reveal the inherent trade-off between the multiple style transfer objectives which indicates that style cannot be usefully separated from content within these style-transfer systems.</abstract>
      <url hash="91707b51">2020.coling-main.197</url>
    </paper>
    <paper id="198">
      <title>Contextualized Embeddings for Enriching Linguistic Analyses on Politeness</title>
      <author><first>Ahmad</first><last>Aljanaideh</last></author>
      <author><first>Eric</first><last>Fosler-Lussier</last></author>
      <author><first>Marie-Catherine</first><last>de Marneffe</last></author>
      <pages>2181–2190</pages>
      <abstract>Linguistic analyses in natural language processing (NLP) have often been performed around the static notion of words where the context (surrounding words) is not considered. For example, previous analyses on politeness have focused on comparing the use of static words such as personal pronouns across (im)polite requests without taking the context of those words into account. Current word embeddings in NLP do capture context and thus can be leveraged to enrich linguistic analyses. In this work, we introduce a model which leverages the pre-trained BERT model to cluster contextualized representations of a word based on (1) the context in which the word appears and (2) the labels of items the word occurs in. Using politeness as case study, this model is able to automatically discover interpretable, fine-grained context patterns of words, some of which align with existing theories on politeness. Our model further discovers novel finer-grained patterns associated with (im)polite language. For example, the word please can occur in impolite contexts that are predictable from BERT clustering. The approach proposed here is validated by showing that features based on fine-grained patterns inferred from the clustering improve over politeness-word baselines.</abstract>
      <url hash="3db35047">2020.coling-main.198</url>
    </paper>
    <paper id="199">
      <title>Heterogeneous Recycle Generation for <fixed-case>C</fixed-case>hinese Grammatical Error Correction</title>
      <author><first>Charles</first><last>Hinson</last></author>
      <author><first>Hen-Hsen</first><last>Huang</last></author>
      <author><first>Hsin-Hsi</first><last>Chen</last></author>
      <pages>2191–2201</pages>
      <abstract>Most recent works in the field of grammatical error correction (GEC) rely on neural machine translation-based models. Although these models boast impressive performance, they require a massive amount of data to properly train. Furthermore, NMT-based systems treat GEC purely as a translation task and overlook the editing aspect of it. In this work we propose a heterogeneous approach to Chinese GEC, composed of a NMT-based model, a sequence editing model, and a spell checker. Our methodology not only achieves a new state-of-the-art performance for Chinese GEC, but also does so without relying on data augmentation or GEC-specific architecture changes. We further experiment with all possible configurations of our system with respect to model composition order and number of rounds of correction. A detailed analysis of each model and their contributions to the correction process is performed by adapting the ERRANT scorer to be able to score Chinese sentences.</abstract>
      <url hash="c36b8935">2020.coling-main.199</url>
    </paper>
    <paper id="200">
      <title>Improving Grammatical Error Correction with Data Augmentation by Editing Latent Representation</title>
      <author><first>Zhaohong</first><last>Wan</last></author>
      <author><first>Xiaojun</first><last>Wan</last></author>
      <author><first>Wenguang</first><last>Wang</last></author>
      <pages>2202–2212</pages>
      <abstract>The incorporation of data augmentation method in grammatical error correction task has attracted much attention. However, existing data augmentation methods mainly apply noise to tokens, which leads to the lack of diversity of generated errors. In view of this, we propose a new data augmentation method that can apply noise to the latent representation of a sentence.By editing the latent representations of grammatical sentences, we can generate synthetic samples with various error types. Combining with some pre-defined rules, our method can greatly improve the performance and robustness of existing grammatical error correction models. We evaluate our method on public benchmarks of GEC task and it achieves the state-of-the-art performance on CoNLL-2014 and FCE benchmarks.</abstract>
      <url hash="c78ebf1e">2020.coling-main.200</url>
    </paper>
    <paper id="201">
      <title>Cycle-Consistent Adversarial Autoencoders for Unsupervised Text Style Transfer</title>
      <author><first>Yufang</first><last>Huang</last></author>
      <author><first>Wentao</first><last>Zhu</last></author>
      <author><first>Deyi</first><last>Xiong</last></author>
      <author><first>Yiye</first><last>Zhang</last></author>
      <author><first>Changjian</first><last>Hu</last></author>
      <author><first>Feiyu</first><last>Xu</last></author>
      <pages>2213–2223</pages>
      <abstract>Unsupervised text style transfer is full of challenges due to the lack of parallel data and difficulties in content preservation. In this paper, we propose a novel neural approach to unsupervised text style transfer which we refer to as Cycle-consistent Adversarial autoEncoders (CAE) trained from non-parallel data. CAE consists of three essential components: (1) LSTM autoencoders that encode a text in one style into its latent representation and decode an encoded representation into its original text or a transferred representation into a style-transferred text, (2) adversarial style transfer networks that use an adversarially trained generator to transform a latent representation in one style into a representation in another style, and (3) a cycle-consistent constraint that enhances the capacity of the adversarial style transfer networks in content preservation. The entire CAE with these three components can be trained end-to-end. Extensive experiments and in-depth analyses on two widely-used public datasets consistently validate the effectiveness of proposed CAE in both style transfer and content preservation against several strong baselines in terms of four automatic evaluation metrics and human evaluation.</abstract>
      <url hash="a2857204">2020.coling-main.201</url>
    </paper>
    <paper id="202">
      <title>Ask to Learn: A Study on Curiosity-driven Question Generation</title>
      <author><first>Thomas</first><last>Scialom</last></author>
      <author><first>Jacopo</first><last>Staiano</last></author>
      <pages>2224–2235</pages>
      <abstract>We propose a novel text generation task, namely Curiosity-driven Question Generation. We start from the observation that the Question Generation task has traditionally been considered as the dual problem of Question Answering, hence tackling the problem of generating a question given the text that contains its answer. Such questions can be used to evaluate machine reading comprehension. However, in real life, and especially in conversational settings, humans tend to ask questions with the goal of enriching their knowledge and/or clarifying aspects of previously gathered information. We refer to these inquisitive questions as Curiosity-driven: these questions are generated with the goal of obtaining new information (the answer) which is not present in the input text. In this work, we experiment on this new task using a conversational Question Answering (QA) dataset; further, since the majority of QA dataset are not built in a conversational manner, we describe a methodology to derive data for this novel task from non-conversational QA data. We investigate several automated metrics to measure the different properties of Curious Questions, and experiment different approaches on the Curiosity-driven Question Generation task, including model pre-training and reinforcement learning. Finally, we report a qualitative evaluation of the generated outputs.</abstract>
      <url hash="b1e5b74e">2020.coling-main.202</url>
    </paper>
    <paper id="203">
      <title>Formality Style Transfer with Shared Latent Space</title>
      <author><first>Yunli</first><last>Wang</last></author>
      <author><first>Yu</first><last>Wu</last></author>
      <author><first>Lili</first><last>Mou</last></author>
      <author><first>Zhoujun</first><last>Li</last></author>
      <author><first>WenHan</first><last>Chao</last></author>
      <pages>2236–2249</pages>
      <abstract>Conventional approaches for formality style transfer borrow models from neural machine translation, which typically requires massive parallel data for training. However, the dataset for formality style transfer is considerably smaller than translation corpora. Moreover, we observe that informal and formal sentences closely resemble each other, which is different from the translation task where two languages have different vocabularies and grammars. In this paper, we present a new approach, Sequence-to-Sequence with Shared Latent Space (S2S-SLS), for formality style transfer, where we propose two auxiliary losses and adopt joint training of bi-directional transfer and auto-encoding. Experimental results show that S2S-SLS (with either RNN or Transformer architectures) consistently outperforms baselines in various settings, especially when we have limited data.</abstract>
      <url hash="be20c7c6">2020.coling-main.203</url>
    </paper>
    <paper id="204">
      <title>Keep it Consistent: Topic-Aware Storytelling from an Image Stream via Iterative Multi-agent Communication</title>
      <author><first>Ruize</first><last>Wang</last></author>
      <author><first>Zhongyu</first><last>Wei</last></author>
      <author><first>Ying</first><last>Cheng</last></author>
      <author><first>Piji</first><last>Li</last></author>
      <author><first>Haijun</first><last>Shan</last></author>
      <author><first>Ji</first><last>Zhang</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>2250–2260</pages>
      <abstract>Visual storytelling aims to generate a narrative paragraph from a sequence of images automatically. Existing approaches construct text description independently for each image and roughly concatenate them as a story, which leads to the problem of generating semantically incoherent content. In this paper, we propose a new way for visual storytelling by introducing a topic description task to detect the global semantic context of an image stream. A story is then constructed with the guidance of the topic description. In order to combine the two generation tasks, we propose a multi-agent communication framework that regards the topic description generator and the story generator as two agents and learn them simultaneously via iterative updating mechanism. We validate our approach on VIST dataset, where quantitative results, ablations, and human evaluation demonstrate our method’s good ability in generating stories with higher quality compared to state-of-the-art methods.</abstract>
      <url hash="b354b0e0">2020.coling-main.204</url>
    </paper>
    <paper id="205">
      <title>Referring to what you know and do not know: Making Referring Expression Generation Models Generalize To Unseen Entities</title>
      <author><first>Rossana</first><last>Cunha</last></author>
      <author><first>Thiago</first><last>Castro Ferreira</last></author>
      <author><first>Adriana</first><last>Pagano</last></author>
      <author><first>Fabio</first><last>Alves</last></author>
      <pages>2261–2272</pages>
      <abstract>Data-to-text Natural Language Generation (NLG) is the computational process of generating natural language in the form of text or voice from non-linguistic data. A core micro-planning task within NLG is referring expression generation (REG), which aims to automatically generate noun phrases to refer to entities mentioned as discourse unfolds. A limitation of novel REG models is not being able to generate referring expressions to entities not encountered during the training process. To solve this problem, we propose two extensions to NeuralREG, a state-of-the-art encoder-decoder REG model. The first is a copy mechanism, whereas the second consists of representing the gender and type of the referent as inputs to the model. Drawing on the results of automatic and human evaluation as well as an ablation study using the WebNLG corpus, we contend that our proposal contributes to the generation of more meaningful referring expressions to unseen entities than the original system and related work. Code and all produced data are publicly available.</abstract>
      <url hash="d178fdc7">2020.coling-main.205</url>
    </paper>
    <paper id="206">
      <title>Topic-driven Ensemble for Online Advertising Generation</title>
      <author><first>Egor</first><last>Nevezhin</last></author>
      <author><first>Nikolay</first><last>Butakov</last></author>
      <author><first>Maria</first><last>Khodorchenko</last></author>
      <author><first>Maxim</first><last>Petrov</last></author>
      <author><first>Denis</first><last>Nasonov</last></author>
      <pages>2273–2283</pages>
      <abstract>Online advertising is one of the most widespread ways to reach and increase a target audience for those selling products. Usually having a form of a banner, advertising engages users into visiting a corresponding webpage. Professional generation of banners requires creative and writing skills and a basic understanding of target products. The great variety of goods presented in the online market enforce professionals to spend more and more time creating new advertisements different from existing ones. In this paper, we propose a neural network-based approach for the automatic generation of online advertising using texts from given webpages as sources. The important part of the approach is training on open data available online, which allows avoiding costly procedures of manual labeling. Collected open data consist of multiple subdomains with high data heterogeneity. The subdomains belong to different topics and vary in used vocabularies, phrases, styles that lead to reduced quality in adverts generation. We try to solve the problem of identifying existed subdomains and proposing a new ensemble approach based on exploiting multiple instances of a seq2seq model. Our experimental study on a dataset in the Russian language shows that our approach can significantly improve the quality of adverts generation.</abstract>
      <url hash="60dbe915">2020.coling-main.206</url>
    </paper>
    <paper id="207">
      <title>Retrieval-Augmented Controllable Review Generation</title>
      <author><first>Jihyeok</first><last>Kim</last></author>
      <author><first>Seungtaek</first><last>Choi</last></author>
      <author><first>Reinald Kim</first><last>Amplayo</last></author>
      <author><first>Seung-won</first><last>Hwang</last></author>
      <pages>2284–2295</pages>
      <abstract>In this paper, we study review generation given a set of attribute identifiers which are user ID, product ID and rating. This is a difficult subtask of natural language generation since models are limited to the given identifiers, without any specific descriptive information regarding the inputs, when generating the text. The capacity of these models is thus confined and dependent to how well the models can capture vector representations of attributes. We thus propose to additionally leverage references, which are selected from a large pool of texts labeled with one of the attributes, as textual information that enriches inductive biases of given attributes. With these references, we can now pose the problem as an instance of text-to-text generation, which makes the task easier since texts that are syntactically, semantically similar with the output text are provided as input. Using this framework, we address issues such as selecting references from a large candidate set without textual context and improving the model complexity for generation. Our experiments show that our models improve over previous approaches on both automatic and human evaluation metrics.</abstract>
      <url hash="8b1066d9">2020.coling-main.207</url>
    </paper>
    <paper id="208">
      <title>Automatic Detection of Machine Generated Text: A Critical Survey</title>
      <author><first>Ganesh</first><last>Jawahar</last></author>
      <author><first>Muhammad</first><last>Abdul-Mageed</last></author>
      <author><first>Laks</first><last>Lakshmanan, V.S.</last></author>
      <pages>2296–2309</pages>
      <abstract>Text generative models (TGMs) excel in producing text that matches the style of human language reasonably well. Such TGMs can be misused by adversaries, e.g., by automatically generating fake news and fake product reviews that can look authentic and fool humans. Detectors that can distinguish text generated by TGM from human written text play a vital role in mitigating such misuse of TGMs. Recently, there has been a flurry of works from both natural language processing (NLP) and machine learning (ML) communities to build accurate detectors for English. Despite the importance of this problem, there is currently no work that surveys this fast-growing literature and introduces newcomers to important research challenges. In this work, we fill this void by providing a critical survey and review of this literature to facilitate a comprehensive understanding of this problem. We conduct an in-depth error analysis of the state-of-the-art detector and discuss research directions to guide future work in this exciting area.</abstract>
      <url hash="c42f6e6c">2020.coling-main.208</url>
    </paper>
    <paper id="209">
      <title>A Learning-Exploring Method to Generate Diverse Paraphrases with Multi-Objective Deep Reinforcement Learning</title>
      <author><first>Mingtong</first><last>Liu</last></author>
      <author><first>Erguang</first><last>Yang</last></author>
      <author><first>Deyi</first><last>Xiong</last></author>
      <author><first>Yujie</first><last>Zhang</last></author>
      <author><first>Yao</first><last>Meng</last></author>
      <author><first>Changjian</first><last>Hu</last></author>
      <author><first>Jinan</first><last>Xu</last></author>
      <author><first>Yufeng</first><last>Chen</last></author>
      <pages>2310–2321</pages>
      <abstract>Paraphrase generation (PG) is of great importance to many downstream tasks in natural language processing. Diversity is an essential nature to PG for enhancing generalization capability and robustness of downstream applications. Recently, neural sequence-to-sequence (Seq2Seq) models have shown promising results in PG. However, traditional model training for PG focuses on optimizing model prediction against single reference and employs cross-entropy loss, which objective is unable to encourage model to generate diverse paraphrases. In this work, we present a novel approach with multi-objective learning to PG. We propose a learning-exploring method to generate sentences as learning objectives from the learned data distribution, and employ reinforcement learning to combine these new learning objectives for model training. We first design a sample-based algorithm to explore diverse sentences. Then we introduce several reward functions to evaluate the sampled sentences as learning signals in terms of expressive diversity and semantic fidelity, aiming to generate diverse and high-quality paraphrases. To effectively optimize model performance satisfying different evaluating aspects, we use a GradNorm-based algorithm that automatically balances these training objectives. Experiments and analyses on Quora and Twitter datasets demonstrate that our proposed method not only gains a significant increase in diversity but also improves generation quality over several state-of-the-art baselines.</abstract>
      <url hash="02521248">2020.coling-main.209</url>
    </paper>
    <paper id="210">
      <title>Curious Case of Language Generation Evaluation Metrics: A Cautionary Tale</title>
      <author><first>Ozan</first><last>Caglayan</last></author>
      <author><first>Pranava</first><last>Madhyastha</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <pages>2322–2328</pages>
      <abstract>Automatic evaluation of language generation systems is a well-studied problem in Natural Language Processing. While novel metrics are proposed every year, a few popular metrics remain as the de facto metrics to evaluate tasks such as image captioning and machine translation, despite their known limitations. This is partly due to ease of use, and partly because researchers expect to see them and know how to interpret them. In this paper, we urge the community for more careful consideration of how they automatically evaluate their models by demonstrating important failure cases on multiple datasets, language pairs and tasks. Our experiments show that metrics (i) usually prefer system outputs to human-authored texts, (ii) can be insensitive to correct translations of rare words, (iii) can yield surprisingly high scores when given a single sentence as system output for the entire test set.</abstract>
      <url hash="8b80a470">2020.coling-main.210</url>
    </paper>
    <paper id="211">
      <title><fixed-case>F</fixed-case>acts2<fixed-case>S</fixed-case>tory: Controlling Text Generation by Key Facts</title>
      <author><first>Eyal</first><last>Orbach</last></author>
      <author><first>Yoav</first><last>Goldberg</last></author>
      <pages>2329–2345</pages>
      <abstract>Recent advancements in self-attention neural network architectures have raised the bar for open-ended text generation. Yet, while current methods are capable of producing a coherent text which is several hundred words long, attaining control over the content that is being generated—as well as evaluating it—are still open questions. We propose a controlled generation task which is based on expanding a sequence of facts, expressed in natural language, into a longer narrative. We introduce human-based evaluation metrics for this task, as well as a method for deriving a large training dataset. We evaluate three methods on this task, based on fine-tuning pre-trained models. We show that while auto-regressive, unidirectional Language Models such as GPT2 produce better fluency, they struggle to adhere to the requested facts. We propose a plan-and-cloze model (using fine-tuned XLNet) which produces competitive fluency while adhering to the requested content.</abstract>
      <url hash="549ffda8">2020.coling-main.211</url>
    </paper>
    <paper id="212">
      <title>Story Generation with Rich Details</title>
      <author><first>Fangzhou</first><last>Zhai</last></author>
      <author><first>Vera</first><last>Demberg</last></author>
      <author><first>Alexander</first><last>Koller</last></author>
      <pages>2346–2351</pages>
      <abstract>Automatically generated stories need to be not only coherent, but also interesting. Apart from realizing a story line, the text also needs to include rich details to engage the readers. We propose a model that features two different generation components: an outliner, which proceeds the main story line to realize global coherence; a detailer, which supplies relevant details to the story in a locally coherent manner. Human evaluations show our model substantially improves the informativeness of generated text while retaining its coherence, outperforming various baselines.</abstract>
      <url hash="84313bae">2020.coling-main.212</url>
    </paper>
    <paper id="213">
      <title>Learning with Contrastive Examples for Data-to-Text Generation</title>
      <author><first>Yui</first><last>Uehara</last></author>
      <author><first>Tatsuya</first><last>Ishigaki</last></author>
      <author><first>Kasumi</first><last>Aoki</last></author>
      <author><first>Hiroshi</first><last>Noji</last></author>
      <author><first>Keiichi</first><last>Goshima</last></author>
      <author><first>Ichiro</first><last>Kobayashi</last></author>
      <author><first>Hiroya</first><last>Takamura</last></author>
      <author><first>Yusuke</first><last>Miyao</last></author>
      <pages>2352–2362</pages>
      <abstract>Existing models for data-to-text tasks generate fluent but sometimes incorrect sentences e.g., “Nikkei gains” is generated when “Nikkei drops” is expected. We investigate models trained on contrastive examples i.e., incorrect sentences or terms, in addition to correct ones to reduce such errors. We first create rules to produce contrastive examples from correct ones by replacing frequent crucial terms such as “gain” or “drop”. We then use learning methods with several losses that exploit contrastive examples. Experiments on the market comment generation task show that 1) exploiting contrastive examples improves the capability of generating sentences with better lexical choice, without degrading the fluency, 2) the choice of the loss function is an important factor because the performances on different metrics depend on the types of loss functions, and 3) the use of the examples produced by some specific rules further improves performance. Human evaluation also supports the effectiveness of using contrastive examples.</abstract>
      <url hash="fa2b8f55">2020.coling-main.213</url>
    </paper>
    <paper id="214">
      <title><fixed-case>M</fixed-case>ed<fixed-case>W</fixed-case>riter: Knowledge-Aware Medical Text Generation</title>
      <author><first>Youcheng</first><last>Pan</last></author>
      <author><first>Qingcai</first><last>Chen</last></author>
      <author><first>Weihua</first><last>Peng</last></author>
      <author><first>Xiaolong</first><last>Wang</last></author>
      <author><first>Baotian</first><last>Hu</last></author>
      <author><first>Xin</first><last>Liu</last></author>
      <author><first>Junying</first><last>Chen</last></author>
      <author><first>Wenxiu</first><last>Zhou</last></author>
      <pages>2363–2368</pages>
      <abstract>To exploit the domain knowledge to guarantee the correctness of generated text has been a hot topic in recent years, especially for high professional domains such as medical. However, most of recent works only consider the information of unstructured text rather than structured information of the knowledge graph. In this paper, we focus on the medical topic-to-text generation task and adapt a knowledge-aware text generation model to the medical domain, named MedWriter, which not only introduces the specific knowledge from the external MKG but also is capable of learning graph-level representation. We conduct experiments on a medical literature dataset collected from medical journals, each of which has a set of topic words, an abstract of medical literature and a corresponding knowledge graph from CMeKG. Experimental results demonstrate incorporating knowledge graph into generation model can improve the quality of the generated text and has robust superiority over the competitor methods.</abstract>
      <url hash="4c8a118e">2020.coling-main.214</url>
    </paper>
    <paper id="215">
      <title>Dynamic Topic Tracker for <fixed-case>KB</fixed-case>-to-Text Generation</title>
      <author><first>Zihao</first><last>Fu</last></author>
      <author><first>Lidong</first><last>Bing</last></author>
      <author><first>Wai</first><last>Lam</last></author>
      <author><first>Shoaib</first><last>Jameel</last></author>
      <pages>2369–2380</pages>
      <abstract>Recently, many KB-to-text generation tasks have been proposed to bridge the gap between knowledge bases and natural language by directly converting a group of knowledge base triples into human-readable sentences. However, most of the existing models suffer from the off-topic problem, namely, the models are prone to generate some unrelated clauses that are somehow involved with certain input terms regardless of the given input data. This problem seriously degrades the quality of the generation results. In this paper, we propose a novel dynamic topic tracker for solving this problem. Different from existing models, our proposed model learns a global hidden representation for topics and recognizes the corresponding topic during each generation step. The recognized topic is used as additional information to guide the generation process and thus alleviates the off-topic problem. The experimental results show that our proposed model can enhance the performance of sentence generation and the off-topic problem is significantly mitigated.</abstract>
      <url hash="c272db5a">2020.coling-main.215</url>
    </paper>
    <paper id="216">
      <title>Improving Variational Autoencoder for Text Modelling with Timestep-Wise Regularisation</title>
      <author><first>Ruizhe</first><last>Li</last></author>
      <author><first>Xiao</first><last>Li</last></author>
      <author><first>Guanyi</first><last>Chen</last></author>
      <author><first>Chenghua</first><last>Lin</last></author>
      <pages>2381–2397</pages>
      <abstract>The Variational Autoencoder (VAE) is a popular and powerful model applied to text modelling to generate diverse sentences. However, an issue known as posterior collapse (or KL loss vanishing) happens when the VAE is used in text modelling, where the approximate posterior collapses to the prior, and the model will totally ignore the latent variables and be degraded to a plain language model during text generation. Such an issue is particularly prevalent when RNN-based VAE models are employed for text modelling. In this paper, we propose a simple, generic architecture called Timestep-Wise Regularisation VAE (TWR-VAE), which can effectively avoid posterior collapse and can be applied to any RNN-based VAE models. The effectiveness and versatility of our model are demonstrated in different tasks, including language modelling and dialogue response generation.</abstract>
      <url hash="acace488">2020.coling-main.216</url>
    </paper>
    <paper id="217">
      <title><fixed-case>G</fixed-case>en<fixed-case>W</fixed-case>iki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation</title>
      <author><first>Zhijing</first><last>Jin</last></author>
      <author><first>Qipeng</first><last>Guo</last></author>
      <author><first>Xipeng</first><last>Qiu</last></author>
      <author><first>Zheng</first><last>Zhang</last></author>
      <pages>2398–2409</pages>
      <abstract>Data collection for the knowledge graph-to-text generation is expensive. As a result, research on unsupervised models has emerged as an active field recently. However, most unsupervised models have to use non-parallel versions of existing small supervised datasets, which largely constrain their potential. In this paper, we propose a large-scale, general-domain dataset, GenWiki. Our unsupervised dataset has 1.3M text and graph examples, respectively. With a human-annotated test set, we provide this new benchmark dataset for future research on unsupervised text generation from knowledge graphs.</abstract>
      <url hash="a1914552">2020.coling-main.217</url>
    </paper>
    <paper id="218">
      <title>Have Your Text and Use It Too! End-to-End Neural Data-to-Text Generation with Semantic Fidelity</title>
      <author><first>Hamza</first><last>Harkous</last></author>
      <author><first>Isabel</first><last>Groves</last></author>
      <author><first>Amir</first><last>Saffari</last></author>
      <pages>2410–2424</pages>
      <abstract>End-to-end neural data-to-text (D2T) generation has recently emerged as an alternative to pipeline-based architectures. However, it has faced challenges generalizing to new domains and generating semantically consistent text. In this work, we present DataTuner, a neural, end-to-end data-to-text generation system that makes minimal assumptions about the data representation and target domain. We take a two-stage generation-reranking approach, combining a fine-tuned language model with a semantic fidelity classifier. Each component is learnt end-toe-nd without needing dataset-specific heuristics, entity delexicalization, or post-processing. We show that DataTuner achieves state of the art results on automated metrics across four major D2T datasets (LDC2017T10, WebNLG, ViGGO, and Cleaned E2E), with fluency assessed by human annotators as nearing or exceeding the human-written reference texts. Our generated text has better semantic fidelity than the state of the art on these datasets. We further demonstrate that our model-based semantic fidelity scorer is a better assessment tool compared to traditional heuristic-based measures of semantic accuracy.</abstract>
      <url hash="70cacc74">2020.coling-main.218</url>
    </paper>
    <paper id="219">
      <title>Graph-Based Knowledge Integration for Question Answering over Dialogue</title>
      <author><first>Jian</first><last>Liu</last></author>
      <author><first>Dianbo</first><last>Sui</last></author>
      <author><first>Kang</first><last>Liu</last></author>
      <author><first>Jun</first><last>Zhao</last></author>
      <pages>2425–2435</pages>
      <abstract>Question answering over dialogue, a specialized machine reading comprehension task, aims to comprehend a dialogue and to answer specific questions. Despite many advances, existing approaches for this task did not consider dialogue structure and background knowledge (e.g., relationships between speakers). In this paper, we introduce a new approach for the task, featured by its novelty in structuring dialogue and integrating background knowledge for reasoning. Specifically, different from previous “structure-less” approaches, our method organizes a dialogue as a “relational graph”, using edges to represent relationships between entities. To encode this relational graph, we devise a relational graph convolutional network (R-GCN), which can traverse the graph’s topological structure and effectively encode multi-relational knowledge for reasoning. The extensive experiments have justified the effectiveness of our approach over competitive baselines. Moreover, a deeper analysis shows that our model is better at tackling complex questions requiring relational reasoning and defending adversarial attacks with distracting sentences.</abstract>
      <url hash="b20803db">2020.coling-main.219</url>
    </paper>
    <paper id="220">
      <title>A hierarchical approach to vision-based language generation: from simple sentences to complex natural language</title>
      <author><first>Simion-Vlad</first><last>Bogolin</last></author>
      <author><first>Ioana</first><last>Croitoru</last></author>
      <author><first>Marius</first><last>Leordeanu</last></author>
      <pages>2436–2447</pages>
      <abstract>Automatically describing videos in natural language is an ambitious problem, which could bridge our understanding of vision and language. We propose a hierarchical approach, by first generating video descriptions as sequences of simple sentences, followed at the next level by a more complex and fluent description in natural language. While the simple sentences describe simple actions in the form of (subject, verb, object), the second-level paragraph descriptions, indirectly using information from the first-level description, presents the visual content in a more compact, coherent and semantically rich manner. To this end, we introduce the first video dataset in the literature that is annotated with captions at two levels of linguistic complexity. We perform extensive tests that demonstrate that our hierarchical linguistic representation, from simple to complex language, allows us to train a two-stage network that is able to generate significantly more complex paragraphs than current one-stage approaches.</abstract>
      <url hash="2327d3db">2020.coling-main.220</url>
    </paper>
    <paper id="221">
      <title>Sentiment Forecasting in Dialog</title>
      <author><first>Zhongqing</first><last>Wang</last></author>
      <author><first>Xiujun</first><last>Zhu</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <author><first>Shoushan</first><last>Li</last></author>
      <author><first>Guodong</first><last>Zhou</last></author>
      <pages>2448–2458</pages>
      <abstract>Sentiment forecasting in dialog aims to predict the polarity of next utterance to come, and can help speakers revise their utterances in sentimental utterances generation. However, the polarity of next utterance is normally hard to predict, due to the lack of content of next utterance (yet to come). In this study, we propose a Neural Sentiment Forecasting (NSF) model to address inherent challenges. In particular, we employ a neural simulation model to simulate the next utterance based on the context (previous utterances encountered). Moreover, we employ a sequence influence model to learn both pair-wise and seq-wise influence. Empirical studies illustrate the importance of proposed sentiment forecasting task, and justify the effectiveness of our NSF model over several strong baselines.</abstract>
      <url hash="e07ed27f">2020.coling-main.221</url>
    </paper>
    <paper id="222">
      <title><fixed-case>I</fixed-case> Know What You Asked: Graph Path Learning using <fixed-case>AMR</fixed-case> for Commonsense Reasoning</title>
      <author><first>Jungwoo</first><last>Lim</last></author>
      <author><first>Dongsuk</first><last>Oh</last></author>
      <author><first>Yoonna</first><last>Jang</last></author>
      <author><first>Kisu</first><last>Yang</last></author>
      <author><first>Heuiseok</first><last>Lim</last></author>
      <pages>2459–2471</pages>
      <abstract>CommonsenseQA is a task in which a correct answer is predicted through commonsense reasoning with pre-defined knowledge. Most previous works have aimed to improve the performance with distributed representation without considering the process of predicting the answer from the semantic representation of the question. To shed light upon the semantic interpretation of the question, we propose an AMR-ConceptNet-Pruned (ACP) graph. The ACP graph is pruned from a full integrated graph encompassing Abstract Meaning Representation (AMR) graph generated from input questions and an external commonsense knowledge graph, ConceptNet (CN). Then the ACP graph is exploited to interpret the reasoning path as well as to predict the correct answer on the CommonsenseQA task. This paper presents the manner in which the commonsense reasoning process can be interpreted with the relations and concepts provided by the ACP graph. Moreover, ACP-based models are shown to outperform the baselines.</abstract>
      <url hash="b3a6a8b1">2020.coling-main.222</url>
    </paper>
    <paper id="223">
      <title>Bracketing Encodings for 2-Planar Dependency Parsing</title>
      <author><first>Michalina</first><last>Strzyz</last></author>
      <author><first>David</first><last>Vilares</last></author>
      <author><first>Carlos</first><last>Gómez-Rodríguez</last></author>
      <pages>2472–2484</pages>
      <abstract>We present a bracketing-based encoding that can be used to represent any 2-planar dependency tree over a sentence of length n as a sequence of n labels, hence providing almost total coverage of crossing arcs in sequence labeling parsing. First, we show that existing bracketing encodings for parsing as labeling can only handle a very mild extension of projective trees. Second, we overcome this limitation by taking into account the well-known property of 2-planarity, which is present in the vast majority of dependency syntactic structures in treebanks, i.e., the arcs of a dependency tree can be split into two planes such that arcs in a given plane do not cross. We take advantage of this property to design a method that balances the brackets and that encodes the arcs belonging to each of those planes, allowing for almost unrestricted non-projectivity (∼99.9% coverage) in sequence labeling parsing. The experiments show that our linearizations improve over the accuracy of the original bracketing encoding in highly non-projective treebanks (on average by 0.4 LAS), while achieving a similar speed. Also, they are especially suitable when PoS tags are not used as input parameters to the models.</abstract>
      <url hash="1ffc5db0">2020.coling-main.223</url>
    </paper>
    <paper id="224">
      <title>Semi-Supervised Dependency Parsing with Arc-Factored Variational Autoencoding</title>
      <author><first>Ge</first><last>Wang</last></author>
      <author><first>Kewei</first><last>Tu</last></author>
      <pages>2485–2496</pages>
      <abstract>Mannual annotation for dependency parsing is both labourious and time costly, resulting in the difficulty to learn practical dependency parsers for many languages due to the lack of labelled training corpora. To compensate for the scarcity of labelled data, semi-supervised dependency parsing methods are developed to utilize unlabelled data in the training procedure of dependency parsers. In previous work, the autoencoder framework is a prevalent approach for the utilization of unlabelled data. In this framework, training sentences are reconstructed from a decoder conditioned on dependency trees predicted by an encoder. The tree structure requirement brings challenges for both the encoder and the decoder. Sophisticated techniques are employed to tackle these challenges at the expense of model complexity and approximations in encoding and decoding. In this paper, we propose a model based on the variational autoencoder framework. By relaxing the tree constraint in both the encoder and the decoder during training, we make the learning of our model fully arc-factored and thus circumvent the challenges brought by the tree constraint. We evaluate our model on datasets across several languages and the results demonstrate the advantage of our model over previous approaches in both parsing accuracy and speed.</abstract>
      <url hash="b52f934c">2020.coling-main.224</url>
    </paper>
    <paper id="225">
      <title>Multitask Easy-First Dependency Parsing: Exploiting Complementarities of Different Dependency Representations</title>
      <author><first>Yash</first><last>Kankanampati</last></author>
      <author><first>Joseph</first><last>Le Roux</last></author>
      <author><first>Nadi</first><last>Tomeh</last></author>
      <author><first>Dima</first><last>Taji</last></author>
      <author><first>Nizar</first><last>Habash</last></author>
      <pages>2497–2508</pages>
      <abstract>In this paper we present a parsing model for projective dependency trees which takes advantage of the existence of complementary dependency annotations which is the case in Arabic, with the availability of CATiB and UD treebanks. Our system performs syntactic parsing according to both annotation types jointly as a sequence of arc-creating operations, and partially created trees for one annotation are also available to the other as features for the score function. This method gives error reduction of 9.9% on CATiB and 6.1% on UD compared to a strong baseline, and ablation tests show that the main contribution of this reduction is given by sharing tree representation between tasks, and not simply sharing BiLSTM layers as is often performed in NLP multitask systems.</abstract>
      <url hash="9a96ccf9">2020.coling-main.225</url>
    </paper>
    <paper id="226">
      <title>Context Dependent Semantic Parsing: A Survey</title>
      <author><first>Zhuang</first><last>Li</last></author>
      <author><first>Lizhen</first><last>Qu</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>2509–2521</pages>
      <abstract>Semantic parsing is the task of translating natural language utterances into machine-readable meaning representations. Currently, most semantic parsing methods are not able to utilize the contextual information (e.g. dialogue and comments history), which has a great potential to boost the semantic parsing systems. To address this issue, context dependent semantic parsing has recently drawn a lot of attention. In this survey, we investigate progress on the methods for the context dependent semantic parsing, together with the current datasets and tasks. We then point out open problems and challenges for future research in this area.</abstract>
      <url hash="3acaa8c9">2020.coling-main.226</url>
    </paper>
    <paper id="227">
      <title>A Survey of Unsupervised Dependency Parsing</title>
      <author><first>Wenjuan</first><last>Han</last></author>
      <author><first>Yong</first><last>Jiang</last></author>
      <author><first>Hwee Tou</first><last>Ng</last></author>
      <author><first>Kewei</first><last>Tu</last></author>
      <pages>2522–2533</pages>
      <abstract>Syntactic dependency parsing is an important task in natural language processing. Unsupervised dependency parsing aims to learn a dependency parser from sentences that have no annotation of their correct parse trees. Despite its difficulty, unsupervised parsing is an interesting research direction because of its capability of utilizing almost unlimited unannotated text data. It also serves as the basis for other research in low-resource parsing. In this paper, we survey existing approaches to unsupervised dependency parsing, identify two major classes of approaches, and discuss recent trends. We hope that our survey can provide insights for researchers and facilitate future research on this topic.</abstract>
      <url hash="b3db2891">2020.coling-main.227</url>
    </paper>
    <paper id="228">
      <title>Exploring Question-Specific Rewards for Generating Deep Questions</title>
      <author><first>Yuxi</first><last>Xie</last></author>
      <author><first>Liangming</first><last>Pan</last></author>
      <author><first>Dongzhe</first><last>Wang</last></author>
      <author><first>Min-Yen</first><last>Kan</last></author>
      <author><first>Yansong</first><last>Feng</last></author>
      <pages>2534–2546</pages>
      <abstract>Recent question generation (QG) approaches often utilize the sequence-to-sequence framework (Seq2Seq) to optimize the log likelihood of ground-truth questions using teacher forcing. However, this training objective is inconsistent with actual question quality, which is often reflected by certain global properties such as whether the question can be answered by the document. As such, we directly optimize for QG-specific objectives via reinforcement learning to improve question quality. We design three different rewards that target to improve the fluency, relevance, and answerability of generated questions. We conduct both automatic and human evaluations in addition to thorough analysis to explore the effect of each QG-specific reward. We find that optimizing on question-specific rewards generally leads to better performance in automatic evaluation metrics. However, only the rewards that correlate well with human judgement (e.g., relevance) lead to real improvement in question quality. Optimizing for the others, especially answerability, introduces incorrect bias to the model, resulting in poorer question quality. The code is publicly available at https://github.com/YuxiXie/RL-for-Question-Generation.</abstract>
      <url hash="6d66e1d2">2020.coling-main.228</url>
    </paper>
    <paper id="229">
      <title><fixed-case>CHIME</fixed-case>: Cross-passage Hierarchical Memory Network for Generative Review Question Answering</title>
      <author><first>Junru</first><last>Lu</last></author>
      <author><first>Gabriele</first><last>Pergola</last></author>
      <author><first>Lin</first><last>Gui</last></author>
      <author><first>Binyang</first><last>Li</last></author>
      <author><first>Yulan</first><last>He</last></author>
      <pages>2547–2560</pages>
      <abstract>We introduce CHIME, a cross-passage hierarchical memory network for question answering (QA) via text generation. It extends XLNet introducing an auxiliary memory module consisting of two components: the context memory collecting cross-passage evidences, and the answer memory working as a buffer continually refining the generated answers. Empirically, we show the efficacy of the proposed architecture in the multi-passage generative QA, outperforming the state-of-the-art baselines with better syntactically well-formed answers and increased precision in addressing the questions of the AmazonQA review dataset. An additional qualitative analysis revealed the interpretability introduced by the memory module.</abstract>
      <url hash="4dad5176">2020.coling-main.229</url>
    </paper>
    <paper id="230">
      <title>Improving Conversational Question Answering Systems after Deployment using Feedback-Weighted Learning</title>
      <author><first>Jon Ander</first><last>Campos</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <author><first>Arantxa</first><last>Otegi</last></author>
      <author><first>Aitor</first><last>Soroa</last></author>
      <author><first>Eneko</first><last>Agirre</last></author>
      <author><first>Gorka</first><last>Azkune</last></author>
      <pages>2561–2571</pages>
      <abstract>The interaction of conversational systems with users poses an exciting opportunity for improving them after deployment, but little evidence has been provided of its feasibility. In most applications, users are not able to provide the correct answer to the system, but they are able to provide binary (correct, incorrect) feedback. In this paper we propose feedback-weighted learning based on importance sampling to improve upon an initial supervised system using binary user feedback. We perform simulated experiments on document classification (for development) and Conversational Question Answering datasets like QuAC and DoQA, where binary user feedback is derived from gold annotations. The results show that our method is able to improve over the initial supervised system, getting close to a fully-supervised system that has access to the same labeled examples in in-domain experiments (QuAC), and even matching in out-of-domain experiments (DoQA). Our work opens the prospect to exploit interactions with real users and improve conversational systems after deployment.</abstract>
      <url hash="52e6ec68">2020.coling-main.230</url>
    </paper>
    <paper id="231">
      <title>Modelling Long-distance Node Relations for <fixed-case>KBQA</fixed-case> with Global Dynamic Graph</title>
      <author><first>Xu</first><last>Wang</last></author>
      <author><first>Shuai</first><last>Zhao</last></author>
      <author><first>Jiale</first><last>Han</last></author>
      <author><first>Bo</first><last>Cheng</last></author>
      <author><first>Hao</first><last>Yang</last></author>
      <author><first>Jianchang</first><last>Ao</last></author>
      <author><first>Zhenzi</first><last>Li</last></author>
      <pages>2572–2582</pages>
      <abstract>The structural information of Knowledge Bases (KBs) has proven effective to Question Answering (QA). Previous studies rely on deep graph neural networks (GNNs) to capture rich structural information, which may not model node relations in particularly long distance due to oversmoothing issue. To address this challenge, we propose a novel framework <b>GlobalGraph</b>, which models long-distance node relations from two views: 1) Node type similarity: GlobalGraph assigns each node a global type label and models long-distance node relations through the global type label similarity; 2) Correlation between nodes and questions: we learn similarity scores between nodes and the question, and model long-distance node relations through the sum score of two nodes. We conduct extensive experiments on two widely used multi-hop KBQA datasets to prove the effectiveness of our method.</abstract>
      <url hash="d4187722">2020.coling-main.231</url>
    </paper>
    <paper id="232">
      <title>Improving Commonsense Question Answering by Graph-based Iterative Retrieval over Multiple Knowledge Sources</title>
      <author><first>Qianglong</first><last>Chen</last></author>
      <author><first>Feng</first><last>Ji</last></author>
      <author><first>Haiqing</first><last>Chen</last></author>
      <author><first>Yin</first><last>Zhang</last></author>
      <pages>2583–2594</pages>
      <abstract>In order to facilitate natural language understanding, the key is to engage commonsense or background knowledge. However, how to engage commonsense effectively in question answering systems is still under exploration in both research academia and industry. In this paper, we propose a novel question-answering method by integrating multiple knowledge sources, i.e. ConceptNet, Wikipedia, and the Cambridge Dictionary, to boost the performance. More concretely, we first introduce a novel graph-based iterative knowledge retrieval module, which iteratively retrieves concepts and entities related to the given question and its choices from multiple knowledge sources. Afterward, we use a pre-trained language model to encode the question, retrieved knowledge and choices, and propose an answer choice-aware attention mechanism to fuse all hidden representations of the previous modules. Finally, the linear classifier for specific tasks is used to predict the answer. Experimental results on the CommonsenseQA dataset show that our method significantly outperforms other competitive methods and achieves the new state-of-the-art. In addition, further ablation studies demonstrate the effectiveness of our graph-based iterative knowledge retrieval module and the answer choice-aware attention module in retrieving and synthesizing background knowledge from multiple knowledge sources.</abstract>
      <url hash="dc953daf">2020.coling-main.232</url>
    </paper>
    <paper id="233">
      <title>A <fixed-case>V</fixed-case>ietnamese Dataset for Evaluating Machine Reading Comprehension</title>
      <author><first>Kiet</first><last>Nguyen</last></author>
      <author><first>Vu</first><last>Nguyen</last></author>
      <author><first>Anh</first><last>Nguyen</last></author>
      <author><first>Ngan</first><last>Nguyen</last></author>
      <pages>2595–2605</pages>
      <abstract>Over 97 million inhabitants speak Vietnamese as the native language in the world. However, there are few research studies on machine reading comprehension (MRC) in Vietnamese, the task of understanding a document or text, and answering questions related to it. Due to the lack of benchmark datasets for Vietnamese, we present the Vietnamese Question Answering Dataset (UIT-ViQuAD), a new dataset for the low-resource language as Vietnamese to evaluate MRC models. This dataset comprises over 23,000 human-generated question-answer pairs based on 5,109 passages of 174 Vietnamese articles from Wikipedia. In particular, we propose a new process of dataset creation for Vietnamese MRC. Our in-depth analyses illustrate that our dataset requires abilities beyond simple reasoning like word matching and demands complicate reasoning such as single-sentence and multiple-sentence inferences. Besides, we conduct experiments on state-of-the-art MRC methods in English and Chinese as the first experimental models on UIT-ViQuAD, which will be compared to further models. We also estimate human performances on the dataset and compare it to the experimental results of several powerful machine models. As a result, the substantial differences between humans and the best model performances on the dataset indicate that improvements can be explored on UIT-ViQuAD through future research. Our dataset is freely available to encourage the research community to overcome challenges in Vietnamese MRC.</abstract>
      <url hash="e0347935">2020.coling-main.233</url>
    </paper>
    <paper id="234">
      <title>Improving Spoken Language Understanding by Wisdom of Crowds</title>
      <author><first>Koichiro</first><last>Yoshino</last></author>
      <author><first>Kana</first><last>Ikeuchi</last></author>
      <author><first>Katsuhito</first><last>Sudoh</last></author>
      <author><first>Satoshi</first><last>Nakamura</last></author>
      <pages>2606–2612</pages>
      <abstract>Spoken language understanding (SLU), which converts user requests in natural language to machine-interpretable expressions, is becoming an essential task. The lack of training data is an important problem, especially for new system tasks, because existing SLU systems are based on statistical approaches. In this paper, we proposed to use two sources of the “wisdom of crowds,” crowdsourcing and knowledge community website, for improving the SLU system. We firstly collected paraphrasing variations for new system tasks through crowdsourcing as seed data, and then augmented them using similar questions from a knowledge community website. We investigated the effects of the proposed data augmentation method in SLU task, even with small seed data. In particular, the proposed architecture augmented more than 120,000 samples to improve SLU accuracies.</abstract>
      <url hash="d7ef98fb">2020.coling-main.234</url>
    </paper>
    <paper id="235">
      <title>Bi-directional <fixed-case>C</fixed-case>ognitive<fixed-case>T</fixed-case>hinking Network for Machine Reading Comprehension</title>
      <author><first>Wei</first><last>Peng</last></author>
      <author><first>Yue</first><last>Hu</last></author>
      <author><first>Luxi</first><last>Xing</last></author>
      <author><first>Yuqiang</first><last>Xie</last></author>
      <author><first>Jing</first><last>Yu</last></author>
      <author><first>Yajing</first><last>Sun</last></author>
      <author><first>Xiangpeng</first><last>Wei</last></author>
      <pages>2613–2623</pages>
      <abstract>We propose a novel Bi-directional Cognitive Knowledge Framework (BCKF) for reading comprehension from the perspective of complementary learning systems theory. It aims to simulate two ways of thinking in the brain to answer questions, including reverse thinking and inertial thinking. To validate the effectiveness of our framework, we design a corresponding Bi-directional Cognitive Thinking Network (BCTN) to encode the passage and generate a question (answer) given an answer (question) and decouple the bi-directional knowledge. The model has the ability to reverse reasoning questions which can assist inertial thinking to generate more accurate answers. Competitive improvement is observed in DuReader dataset, confirming our hypothesis that bi-directional knowledge helps the QA task. The novel framework shows an interesting perspective on machine reading comprehension and cognitive science.</abstract>
      <url hash="5cc5df79">2020.coling-main.235</url>
    </paper>
    <paper id="236">
      <title>Learn with Noisy Data via Unsupervised Loss Correction for Weakly Supervised Reading Comprehension</title>
      <author><first>Xuemiao</first><last>Zhang</last></author>
      <author><first>Kun</first><last>Zhou</last></author>
      <author><first>Sirui</first><last>Wang</last></author>
      <author><first>Fuzheng</first><last>Zhang</last></author>
      <author><first>Zhongyuan</first><last>Wang</last></author>
      <author><first>Junfei</first><last>Liu</last></author>
      <pages>2624–2634</pages>
      <abstract>Weakly supervised machine reading comprehension (MRC) task is practical and promising for its easily available and massive training data, but inevitablely introduces noise. Existing related methods usually incorporate extra submodels to help filter noise before the noisy data is input to main models. However, these multistage methods often make training difficult, and the qualities of submodels are hard to be controlled. In this paper, we first explore and analyze the essential characteristics of noise from the perspective of loss distribution, and find that in the early stage of training, noisy samples usually lead to significantly larger loss values than clean ones. Based on the observation, we propose a hierarchical loss correction strategy to avoid fitting noise and enhance clean supervision signals, including using an unsupervisedly fitted Gaussian mixture model to calculate the weight factors for all losses to correct the loss distribution, and employ a hard bootstrapping loss to modify loss function. Experimental results on different weakly supervised MRC datasets show that the proposed methods can help improve models significantly.</abstract>
      <url hash="25e8f3fb">2020.coling-main.236</url>
    </paper>
    <paper id="237">
      <title>Incorporating Syntax and Frame Semantics in Neural Network for Machine Reading Comprehension</title>
      <author><first>Shaoru</first><last>Guo</last></author>
      <author><first>Yong</first><last>Guan</last></author>
      <author><first>Ru</first><last>Li</last></author>
      <author><first>Xiaoli</first><last>Li</last></author>
      <author><first>Hongye</first><last>Tan</last></author>
      <pages>2635–2641</pages>
      <abstract>Machine reading comprehension (MRC) is one of the most critical yet challenging tasks in natural language understanding(NLU), where both syntax and semantics information of text are essential components for text understanding. It is surprising that jointly considering syntax and semantics in neural networks was never formally reported in literature. This paper makes the first attempt by proposing a novel Syntax and Frame Semantics model for Machine Reading Comprehension (SS-MRC), which takes full advantage of syntax and frame semantics to get richer text representation. Our extensive experimental results demonstrate that SS-MRC performs better than ten state-of-the-art technologies on machine reading comprehension task.</abstract>
      <url hash="61bab644">2020.coling-main.237</url>
    </paper>
    <paper id="238">
      <title>Molweni: A Challenge Multiparty Dialogues-based Machine Reading Comprehension Dataset with Discourse Structure</title>
      <author><first>Jiaqi</first><last>Li</last></author>
      <author><first>Ming</first><last>Liu</last></author>
      <author><first>Min-Yen</first><last>Kan</last></author>
      <author><first>Zihao</first><last>Zheng</last></author>
      <author><first>Zekun</first><last>Wang</last></author>
      <author><first>Wenqiang</first><last>Lei</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <author><first>Bing</first><last>Qin</last></author>
      <pages>2642–2652</pages>
      <abstract>Research into the area of multiparty dialog has grown considerably over recent years. We present the Molweni dataset, a machine reading comprehension (MRC) dataset with discourse structure built over multiparty dialog. Molweni’s source samples from the Ubuntu Chat Corpus, including 10,000 dialogs comprising 88,303 utterances. We annotate 30,066 questions on this corpus, including both answerable and unanswerable questions. Molweni also uniquely contributes discourse dependency annotations in a modified Segmented Discourse Representation Theory (SDRT; Asher et al., 2016) style for all of its multiparty dialogs, contributing large-scale (78,245 annotated discourse relations) data to bear on the task of multiparty dialog discourse parsing. Our experiments show that Molweni is a challenging dataset for current MRC models: BERT-wwm, a current, strong SQuAD 2.0 performer, achieves only 67.7% F1 on Molweni’s questions, a 20+% significant drop as compared against its SQuAD 2.0 performance.</abstract>
      <url hash="3a17e3f7">2020.coling-main.238</url>
    </paper>
    <paper id="239">
      <title>Joint Event Extraction with Hierarchical Policy Network</title>
      <author><first>Peixin</first><last>Huang</last></author>
      <author><first>Xiang</first><last>Zhao</last></author>
      <author><first>Ryuichi</first><last>Takanobu</last></author>
      <author><first>Zhen</first><last>Tan</last></author>
      <author><first>Weidong</first><last>Xiao</last></author>
      <pages>2653–2664</pages>
      <abstract>Most existing work on event extraction (EE) either follows a pipelined manner or uses a joint structure but is pipelined in essence. As a result, these efforts fail to utilize information interactions among event triggers, event arguments, and argument roles, which causes information redundancy. In view of this, we propose to exploit the role information of the arguments in an event and devise a Hierarchical Policy Network (HPNet) to perform joint EE. The whole EE process is fulfilled through a two-level hierarchical structure consisting of two policy networks for event detection and argument detection. The deep information interactions among the subtasks are realized, and it is more natural to deal with multiple events issue. Extensive experiments on ACE2005 and TAC2015 demonstrate the superiority of HPNet, leading to state-of-the-art performance and is more powerful for sentences with multiple events.</abstract>
      <url hash="b9f97ced">2020.coling-main.239</url>
    </paper>
    <paper id="240">
      <title>Automated Graph Generation at Sentence Level for Reading Comprehension Based on Conceptual Graphs</title>
      <author><first>Wan-Hsuan</first><last>Lin</last></author>
      <author><first>Chun-Shien</first><last>Lu</last></author>
      <pages>2665–2675</pages>
      <abstract>This paper proposes a novel miscellaneous-context-based method to convert a sentence into a knowledge embedding in the form of a directed graph. We adopt the idea of conceptual graphs to frame for the miscellaneous textual information into conceptual compactness. We first empirically observe that this graph representation method can (1) accommodate the slot-filling challenges in typical question answering and (2) access to the sentence-level graph structure in order to explicitly capture the neighbouring connections of reference concept nodes. Secondly, we propose a task-agnostic semantics-measured module, which cooperates with the graph representation method, in order to (3) project an edge of a sentence-level graph to the space of semantic relevance with respect to the corresponding concept nodes. As a result of experiments on the QA-type relation extraction, the combination of the graph representation and the semantics-measured module achieves the high accuracy of answer prediction and offers human-comprehensible graphical interpretation for every well-formed sample. To our knowledge, our approach is the first towards the interpretable process of learning vocabulary representations with the experimental evidence.</abstract>
      <url hash="973b1e51">2020.coling-main.240</url>
    </paper>
    <paper id="241">
      <title><fixed-case>F</fixed-case>orce<fixed-case>R</fixed-case>eader: a <fixed-case>BERT</fixed-case>-based Interactive Machine Reading Comprehension Model with Attention Separation</title>
      <author><first>Zheng</first><last>Chen</last></author>
      <author><first>Kangjian</first><last>Wu</last></author>
      <pages>2676–2686</pages>
      <abstract>The release of BERT revolutionized the development of NLP. Various BERT-based reading comprehension models have been proposed, thus updating the performance ranking of reading comprehension tasks. However, the above BERT-based models inherently employ BERT’s combined input method, representing the input question and paragraph as a single packed sequence, without further modification for reading comprehension. This paper makes an in-depth analysis of this input method, proposes a problem of this approach. We call it attention deconcentration. Accordingly, this paper proposes ForceReader, a BERT-based interactive machine reading comprehension model. First, ForceReader proposes a novel solution called the Attention Separation Representation to respond to attention deconcentration. Moreover, starting from the logical nature of reading comprehension tasks, ForceReader adopts Multi-mode Reading and Interactive Reasoning strategy. For the calculation of attention, ForceReader employs Conditional Background Attention to solve the lack of the overall context semantic after the separation of attention. As an integral model, ForceReader shows a significant improvement in reading comprehension tasks compared to BERT. Moreover, this paper makes detailed visual analyses of the attention and propose strategies accordingly. This may be another argument to the explanations of the attention.</abstract>
      <url hash="46224819">2020.coling-main.241</url>
    </paper>
    <paper id="242">
      <title><fixed-case>NUT</fixed-case>-<fixed-case>RC</fixed-case>: Noisy User-generated Text-oriented Reading Comprehension</title>
      <author><first>Rongtao</first><last>Huang</last></author>
      <author><first>Bowei</first><last>Zou</last></author>
      <author><first>Yu</first><last>Hong</last></author>
      <author><first>Wei</first><last>Zhang</last></author>
      <author><first>AiTi</first><last>Aw</last></author>
      <author><first>Guodong</first><last>Zhou</last></author>
      <pages>2687–2698</pages>
      <abstract>Reading comprehension (RC) on social media such as Twitter is a critical and challenging task due to its noisy, informal, but informative nature. Most existing RC models are developed on formal datasets such as news articles and Wikipedia documents, which severely limit their performances when directly applied to the noisy and informal texts in social media. Moreover, these models only focus on a certain type of RC, extractive or generative, but ignore the integration of them. To well address these challenges, we come up with a noisy user-generated text-oriented RC model. In particular, we first introduce a set of text normalizers to transform the noisy and informal texts to the formal ones. Then, we integrate the extractive and the generative RC model by a multi-task learning mechanism and an answer selection module. Experimental results on TweetQA demonstrate that our NUT-RC model significantly outperforms the state-of-the-art social media-oriented RC models.</abstract>
      <url hash="1e28a441">2020.coling-main.242</url>
    </paper>
    <paper id="243">
      <title>To What Degree Can Language Borders Be Blurred In <fixed-case>BERT</fixed-case>-based Multilingual Spoken Language Understanding?</title>
      <author><first>Quynh</first><last>Do</last></author>
      <author><first>Judith</first><last>Gaspers</last></author>
      <author><first>Tobias</first><last>Roeding</last></author>
      <author><first>Melanie</first><last>Bradford</last></author>
      <pages>2699–2709</pages>
      <abstract>This paper addresses the question as to what degree a BERT-based multilingual Spoken Language Understanding (SLU) model can transfer knowledge across languages. Through experiments we will show that, although it works substantially well even on distant language groups, there is still a gap to the ideal multilingual performance. In addition, we propose a novel BERT-based adversarial model architecture to learn language-shared and language-specific representations for multilingual SLU. Our experimental results prove that the proposed model is capable of narrowing the gap to the ideal multilingual performance.</abstract>
      <url hash="7af663d3">2020.coling-main.243</url>
    </paper>
    <paper id="244">
      <title>Cross-lingual Machine Reading Comprehension with Language Branch Knowledge Distillation</title>
      <author><first>Junhao</first><last>Liu</last></author>
      <author><first>Linjun</first><last>Shou</last></author>
      <author><first>Jian</first><last>Pei</last></author>
      <author><first>Ming</first><last>Gong</last></author>
      <author><first>Min</first><last>Yang</last></author>
      <author><first>Daxin</first><last>Jiang</last></author>
      <pages>2710–2721</pages>
      <abstract>Cross-lingual Machine Reading Comprehension (CLMRC) remains a challenging problem due to the lack of large-scale annotated datasets in low-source languages, such as Arabic, Hindi, and Vietnamese. Many previous approaches use translation data by translating from a rich-source language, such as English, to low-source languages as auxiliary supervision. However, how to effectively leverage translation data and reduce the impact of noise introduced by translation remains onerous. In this paper, we tackle this challenge and enhance the cross-lingual transferring performance by a novel augmentation approach named Language Branch Machine Reading Comprehension (LBMRC). A language branch is a group of passages in one single language paired with questions in all target languages. We train multiple machine reading comprehension (MRC) models proficient in individual language based on LBMRC. Then, we devise a multilingual distillation approach to amalgamate knowledge from multiple language branch models to a single model for all target languages. Combining the LBMRC and multilingual distillation can be more robust to the data noises, therefore, improving the model’s cross-lingual ability. Meanwhile, the produced single multilingual model can apply to all target languages, which saves the cost of training, inference, and maintenance for multiple models. Extensive experiments on two CLMRC benchmarks clearly show the effectiveness of our proposed method.</abstract>
      <url hash="945465a5">2020.coling-main.244</url>
    </paper>
    <paper id="245">
      <title>Neural Networks approaches focused on <fixed-case>F</fixed-case>rench Spoken Language Understanding: application to the <fixed-case>MEDIA</fixed-case> Evaluation Task</title>
      <author><first>Sahar</first><last>Ghannay</last></author>
      <author><first>Christophe</first><last>Servan</last></author>
      <author><first>Sophie</first><last>Rosset</last></author>
      <pages>2722–2727</pages>
      <abstract>In this paper, we present a study on a French Spoken Language Understanding (SLU) task: the MEDIA task. Many works and studies have been proposed for many tasks, but most of them are focused on English language and tasks. The exploration of a richer language like French within the framework of a SLU task implies to recent approaches to handle this difficulty. Since the MEDIA task seems to be one of the most difficult, according several previous studies, we propose to explore Neural Networks approaches focusing of three aspects: firstly, the Neural Network inputs and more specifically the word embeddings; secondly, we compared French version of BERT against the best setup through different ways; Finally, the comparison against State-of-the-Art approaches. Results show that the word embeddings trained on a small corpus need to be updated during SLU model training. Furthermore, the French BERT fine-tuned approaches outperform the classical Neural Network Architectures and achieves state of the art results. However, the contextual embeddings extracted from one of the French BERT approaches achieve comparable results in comparison to word embedding, when integrated into the proposed neural architecture.</abstract>
      <url hash="053b48b2">2020.coling-main.245</url>
    </paper>
    <paper id="246">
      <title>Syntactic Graph Convolutional Network for Spoken Language Understanding</title>
      <author><first>Keqing</first><last>He</last></author>
      <author><first>Shuyu</first><last>Lei</last></author>
      <author><first>Yushu</first><last>Yang</last></author>
      <author><first>Huixing</first><last>Jiang</last></author>
      <author><first>Zhongyuan</first><last>Wang</last></author>
      <pages>2728–2738</pages>
      <abstract>Slot filling and intent detection are two major tasks for spoken language understanding. In most existing work, these two tasks are built as joint models with multi-task learning with no consideration of prior linguistic knowledge. In this paper, we propose a novel joint model that applies a graph convolutional network over dependency trees to integrate the syntactic structure for learning slot filling and intent detection jointly. Experimental results show that our proposed model achieves state-of-the-art performance on two public benchmark datasets and outperforms existing work. At last, we apply the BERT model to further improve the performance on both slot filling and intent detection.</abstract>
      <url hash="48f1d819">2020.coling-main.246</url>
    </paper>
    <paper id="247">
      <title>Conversational Machine Comprehension: a Literature Review</title>
      <author><first>Somil</first><last>Gupta</last></author>
      <author><first>Bhanu Pratap Singh</first><last>Rawat</last></author>
      <author><first>Hong</first><last>Yu</last></author>
      <pages>2739–2753</pages>
      <abstract>Conversational Machine Comprehension (CMC), a research track in conversational AI, expects the machine to understand an open-domain natural language text and thereafter engage in a multi-turn conversation to answer questions related to the text. While most of the research in Machine Reading Comprehension (MRC) revolves around single-turn question answering (QA), multi-turn CMC has recently gained prominence, thanks to the advancement in natural language understanding via neural language models such as BERT and the introduction of large-scale conversational datasets such as CoQA and QuAC. The rise in interest has, however, led to a flurry of concurrent publications, each with a different yet structurally similar modeling approach and an inconsistent view of the surrounding literature. With the volume of model submissions to conversational datasets increasing every year, there exists a need to consolidate the scattered knowledge in this domain to streamline future research. This literature review attempts at providing a holistic overview of CMC with an emphasis on the common trends across recently published models, specifically in their approach to tackling conversational history. The review synthesizes a generic framework for CMC models while highlighting the differences in recent approaches and intends to serve as a compendium of CMC for future researchers.</abstract>
      <url hash="93b02c89">2020.coling-main.247</url>
    </paper>
    <paper id="248">
      <title>Robust Machine Reading Comprehension by Learning Soft labels</title>
      <author><first>Zhenyu</first><last>Zhao</last></author>
      <author><first>Shuangzhi</first><last>Wu</last></author>
      <author><first>Muyun</first><last>Yang</last></author>
      <author><first>Kehai</first><last>Chen</last></author>
      <author><first>Tiejun</first><last>Zhao</last></author>
      <pages>2754–2759</pages>
      <abstract>Neural models have achieved great success on the task of machine reading comprehension (MRC), which are typically trained on hard labels. We argue that hard labels limit the model capability on generalization due to the label sparseness problem. In this paper, we propose a robust training method for MRC models to address this problem. Our method consists of three strategies, 1) label smoothing, 2) word overlapping, 3) distribution prediction. All of them help to train models on soft labels. We validate our approach on the representative architecture - ALBERT. Experimental results show that our method can greatly boost the baseline with 1% improvement in average, and achieve state-of-the-art performance on NewsQA and QUOREF.</abstract>
      <url hash="193d47b6">2020.coling-main.248</url>
    </paper>
    <paper id="249">
      <title>Reinforced Multi-task Approach for Multi-hop Question Generation</title>
      <author><first>Deepak</first><last>Gupta</last></author>
      <author><first>Hardik</first><last>Chauhan</last></author>
      <author><first>Ravi Tej</first><last>Akella</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>2760–2775</pages>
      <abstract>Question generation (QG) attempts to solve the inverse of question answering (QA) problem by generating a natural language question given a document and an answer. While sequence to sequence neural models surpass rule-based systems for QG, they are limited in their capacity to focus on more than one supporting fact. For QG, we often require multiple supporting facts to generate high-quality questions. Inspired by recent works on multi-hop reasoning in QA, we take up Multi-hop question generation, which aims at generating relevant questions based on supporting facts in the context. We employ multitask learning with the auxiliary task of answer-aware supporting fact prediction to guide the question generator. In addition, we also proposed a question-aware reward function in a Reinforcement Learning (RL) framework to maximize the utilization of the supporting facts. We demonstrate the effectiveness of our approach through experiments on the multi-hop question answering dataset, HotPotQA. Empirical evaluation shows our model to outperform the single-hop neural question generation models on both automatic evaluation metrics such as BLEU, METEOR, and ROUGE and human evaluation metrics for quality and coverage of the generated questions.</abstract>
      <url hash="d1b4f202">2020.coling-main.249</url>
    </paper>
    <paper id="250">
      <title>Knowledge-enriched, Type-constrained and Grammar-guided Question Generation over Knowledge Bases</title>
      <author><first>Sheng</first><last>Bi</last></author>
      <author><first>Xiya</first><last>Cheng</last></author>
      <author><first>Yuan-Fang</first><last>Li</last></author>
      <author><first>Yongzhen</first><last>Wang</last></author>
      <author><first>Guilin</first><last>Qi</last></author>
      <pages>2776–2786</pages>
      <abstract>Question generation over knowledge bases (KBQG) aims at generating natural-language questions about a subgraph, i.e. a set of triples. Two main challenges still face the current crop of encoder-decoder-based methods, especially on small subgraphs: (1) low diversity and poor fluency due to the limited information contained in the subgraphs, and (2) semantic drift due to the decoder’s oblivion of the semantics of the answer entity. We propose an innovative knowledge-enriched, type-constrained and grammar-guided KBQG model, named KTG, to addresses the above challenges. In our model, the encoder is equipped with auxiliary information from the KB, and the decoder is constrained with word types during QG. Specifically, entity domain and description, as well as relation hierarchy information are considered to construct question contexts, while a conditional copy mechanism is incorporated to modulate question semantics according to current word types. Besides, a novel reward function featuring grammatical similarity is designed to improve both generative richness and syntactic correctness via reinforcement learning. Extensive experiments show that our proposed model outperforms existing methods by a significant margin on two widely-used benchmark datasets SimpleQuestion and PathQuestion.</abstract>
      <url hash="b62be091">2020.coling-main.250</url>
    </paper>
    <paper id="251">
      <title>Adapting a Language Model for Controlled Affective Text Generation</title>
      <author><first>Tushar</first><last>Goswamy</last></author>
      <author><first>Ishika</first><last>Singh</last></author>
      <author><first>Ahsan</first><last>Barkati</last></author>
      <author><first>Ashutosh</first><last>Modi</last></author>
      <pages>2787–2801</pages>
      <abstract>Human use language not just to convey information but also to express their inner feelings and mental states. In this work, we adapt the state-of-the-art language generation models to generate affective (emotional) text. We posit a model capable of generating affect-driven and topic focused sentences without losing grammatical correctness as the affect intensity increases. We propose to incorporate emotion as prior for the probabilistic state-of-the-art text generation model such as GPT-2. The model gives a user the flexibility to control the category and intensity of emotion as well as the topic of the generated text. Previous attempts at modelling fine-grained emotions fall out on grammatical correctness at extreme intensities, but our model is resilient to this and delivers robust results at all intensities. We conduct automated evaluations and human studies to test the performance of our model, and provide a detailed comparison of the results with other models. In all evaluations, our model outperforms existing affective text generation models.</abstract>
      <url hash="b60dfc89">2020.coling-main.251</url>
    </paper>
    <paper id="252">
      <title>Generating Instructions at Different Levels of Abstraction</title>
      <author><first>Arne</first><last>Köhn</last></author>
      <author><first>Julia</first><last>Wichlacz</last></author>
      <author><first>Álvaro</first><last>Torralba</last></author>
      <author><first>Daniel</first><last>Höller</last></author>
      <author><first>Jörg</first><last>Hoffmann</last></author>
      <author><first>Alexander</first><last>Koller</last></author>
      <pages>2802–2813</pages>
      <abstract>When generating technical instructions, it is often convenient to describe complex objects in the world at different levels of abstraction. A novice user might need an object explained piece by piece, while for an expert, talking about the complex object (e.g. a wall or railing) directly may be more succinct and efficient. We show how to generate building instructions at different levels of abstraction in Minecraft. We introduce the use of hierarchical planning to this end, a method from AI planning which can capture the structure of complex objects neatly. A crowdsourcing evaluation shows that the choice of abstraction level matters to users, and that an abstraction strategy which balances low-level and high-level object descriptions compares favorably to ones which don’t.</abstract>
      <url hash="5347e44b">2020.coling-main.252</url>
    </paper>
    <paper id="253">
      <title>“Judge me by my size (noun), do you?” <fixed-case>Y</fixed-case>oda<fixed-case>L</fixed-case>ib: A Demographic-Aware Humor Generation Framework</title>
      <author><first>Aparna</first><last>Garimella</last></author>
      <author><first>Carmen</first><last>Banea</last></author>
      <author><first>Nabil</first><last>Hossain</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <pages>2814–2825</pages>
      <abstract>The subjective nature of humor makes computerized humor generation a challenging task. We propose an automatic humor generation framework for filling the blanks in Mad Libs® stories, while accounting for the demographic backgrounds of the desired audience. We collect a dataset consisting of such stories, which are filled in and judged by carefully selected workers on Amazon Mechanical Turk. We build upon the BERT platform to predict location-biased word fillings in incomplete sentences, and we fine-tune BERT to classify location-specific humor in a sentence. We leverage these components to produce YodaLib, a fully-automated Mad Libs style humor generation framework, which selects and ranks appropriate candidate words and sentences in order to generate a coherent and funny story tailored to certain demographics. Our experimental results indicate that YodaLib outperforms a previous semi-automated approach proposed for this task, while also surpassing human annotators in both qualitative and quantitative analyses.</abstract>
      <url hash="5fdb2dea">2020.coling-main.253</url>
    </paper>
    <paper id="254">
      <title>Does <fixed-case>C</fixed-case>hinese <fixed-case>BERT</fixed-case> Encode Word Structure?</title>
      <author><first>Yile</first><last>Wang</last></author>
      <author><first>Leyang</first><last>Cui</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <pages>2826–2836</pages>
      <abstract>Contextualized representations give significantly improved results for a wide range of NLP tasks. Much work has been dedicated to analyzing the features captured by representative models such as BERT. Existing work finds that syntactic, semantic and word sense knowledge are encoded in BERT. However, little work has investigated word features for character languages such as Chinese. We investigate Chinese BERT using both attention weight distribution statistics and probing tasks, finding that (1) word information is captured by BERT; (2) word-level features are mostly in the middle representation layers; (3) downstream tasks make different use of word features in BERT, with POS tagging and chunking relying the most on word features, and natural language inference relying the least on such features.</abstract>
      <url hash="ff93dc0d">2020.coling-main.254</url>
    </paper>
    <paper id="255">
      <title>Noise Isn’t Always Negative: Countering Exposure Bias in Sequence-to-Sequence Inflection Models</title>
      <author><first>Garrett</first><last>Nicolai</last></author>
      <author><first>Miikka</first><last>Silfverberg</last></author>
      <pages>2837–2846</pages>
      <abstract>Morphological inflection, like many sequence-to-sequence tasks, sees great performance from recurrent neural architectures when data is plentiful, but performance falls off sharply in lower-data settings. We investigate one aspect of neural seq2seq models that we hypothesize contributes to overfitting - teacher forcing. By creating different training and test conditions, exposure bias increases the likelihood that a system too closely models its training data. Experiments show that teacher-forced models struggle to recover when they enter unknown territory. However, a simple modification to the training algorithm to more closely mimic test conditions creates models that are better able to generalize to unseen environments.</abstract>
      <url hash="57201e29">2020.coling-main.255</url>
    </paper>
    <paper id="256">
      <title>Morphologically Aware Word-Level Translation</title>
      <author><first>Paula</first><last>Czarnowska</last></author>
      <author><first>Sebastian</first><last>Ruder</last></author>
      <author><first>Ryan</first><last>Cotterell</last></author>
      <author><first>Ann</first><last>Copestake</last></author>
      <pages>2847–2860</pages>
      <abstract>We propose a novel morphologically aware probability model for bilingual lexicon induction, which jointly models lexeme translation and inflectional morphology in a structured way. Our model exploits the basic linguistic intuition that the lexeme is the key lexical unit of meaning, while inflectional morphology provides additional syntactic information. This approach leads to substantial performance improvements—19% average improvement in accuracy across 6 language pairs over the state of the art in the supervised setting and 16% in the weakly supervised setting. As another contribution, we highlight issues associated with modern BLI that stem from ignoring inflectional morphology, and propose three suggestions for improving the task.</abstract>
      <url hash="955eaf74">2020.coling-main.256</url>
    </paper>
    <paper id="257">
      <title>Analogy Models for Neural Word Inflection</title>
      <author><first>Ling</first><last>Liu</last></author>
      <author><first>Mans</first><last>Hulden</last></author>
      <pages>2861–2878</pages>
      <abstract>Analogy is assumed to be the cognitive mechanism speakers resort to in order to inflect an unknown form of a lexeme based on knowledge of other words in a language. In this process, an analogy is formed between word forms within an inflectional paradigm but also across paradigms. As neural network models for inflection are typically trained only on lemma-target form pairs, we propose three new ways to provide neural models with additional source forms to strengthen analogy-formation, and compare our methods to other approaches in the literature. We show that the proposed methods of providing a Transformer sequence-to-sequence model with additional analogy sources in the input are consistently effective, and improve upon recent state-of-the-art results on 46 languages, particularly in low-resource settings. We also propose a method to combine the analogy-motivated approach with data hallucination or augmentation. We find that the two approaches are complementary to each other and combining the two approaches is especially helpful when the training data is extremely limited.</abstract>
      <url hash="2417d657">2020.coling-main.257</url>
    </paper>
    <paper id="258">
      <title>Computational Modeling of Affixoid Behavior in <fixed-case>C</fixed-case>hinese Morphology</title>
      <author><first>Yu-Hsiang</first><last>Tseng</last></author>
      <author><first>Shu-Kai</first><last>Hsieh</last></author>
      <author><first>Pei-Yi</first><last>Chen</last></author>
      <author><first>Sara</first><last>Court</last></author>
      <pages>2879–2888</pages>
      <abstract>The morphological status of affixes in Chinese has long been a matter of debate. How one might apply the conventional criteria of free/bound and content/function features to distinguish word-forming affixes from bound roots in Chinese is still far from clear. Issues involving polysemy and diachronic dynamics further blur the boundaries. In this paper, we propose three quantitative features in a computational model of affixoid behavior in Mandarin Chinese. The results show that, except for in a very few cases, there are no clear criteria that can be used to identify an affix’s status in an isolating language like Chinese. A diachronic check using contextualized embeddings with the WordNet Sense Inventory also demonstrates the possible role of the polysemy of lexical roots across diachronic settings.</abstract>
      <url hash="adbea87c">2020.coling-main.258</url>
    </paper>
    <paper id="259">
      <title>One Comment from One Perspective: An Effective Strategy for Enhancing Automatic Music Comment</title>
      <author><first>Tengfei</first><last>Huo</last></author>
      <author><first>Zhiqiang</first><last>Liu</last></author>
      <author><first>Jinchao</first><last>Zhang</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>2889–2899</pages>
      <abstract>The automatic generation of music comments is of great significance for increasing the popularity of music and the music platform’s activity. In human music comments, there exists high distinction and diverse perspectives for the same song. In other words, for a song, different comments stem from different musical perspectives. However, to date, this characteristic has not been considered well in research on automatic comment generation. The existing methods tend to generate common and meaningless comments. In this paper, we propose an effective multi-perspective strategy to enhance the diversity of the generated comments. The experiment results on two music comment datasets show that our proposed model can effectively generate a series of diverse music comments based on different perspectives, which outperforms state-of-the-art baselines by a substantial margin.</abstract>
      <url hash="59fd3f41">2020.coling-main.259</url>
    </paper>
    <paper id="260">
      <title>A Tale of Two Linkings: Dynamically Gating between Schema Linking and Structural Linking for Text-to-<fixed-case>SQL</fixed-case> Parsing</title>
      <author><first>Sanxing</first><last>Chen</last></author>
      <author><first>Aidan</first><last>San</last></author>
      <author><first>Xiaodong</first><last>Liu</last></author>
      <author><first>Yangfeng</first><last>Ji</last></author>
      <pages>2900–2912</pages>
      <abstract>In Text-to-SQL semantic parsing, selecting the correct entities (tables and columns) for the generated SQL query is both crucial and challenging; the parser is required to connect the natural language (NL) question and the SQL query to the structured knowledge in the database. We formulate two linking processes to address this challenge: schema linking which links explicit NL mentions to the database and structural linking which links the entities in the output SQL with their structural relationships in the database schema. Intuitively, the effectiveness of these two linking processes changes based on the entity being generated, thus we propose to dynamically choose between them using a gating mechanism. Integrating the proposed method with two graph neural network-based semantic parsers together with BERT representations demonstrates substantial gains in parsing accuracy on the challenging Spider dataset. Analyses show that our proposed method helps to enhance the structure of the model output when generating complicated SQL queries and offers more explainable predictions.</abstract>
      <url hash="6e6e9cd6">2020.coling-main.260</url>
    </paper>
    <paper id="261">
      <title>Autoregressive Affective Language Forecasting: A Self-Supervised Task</title>
      <author><first>Matthew</first><last>Matero</last></author>
      <author><first>H. Andrew</first><last>Schwartz</last></author>
      <pages>2913–2923</pages>
      <abstract>Human natural language is mentioned at a specific point in time while human emotions change over time. While much work has established a strong link between language use and emotional states, few have attempted to model emotional language in time. Here, we introduce the task of <i>affective language forecasting</i> – predicting future change in language based on past changes of language, a task with real-world applications such as treating mental health or forecasting trends in consumer confidence. We establish some of the fundamental autoregressive characteristics of the task (necessary history size, static versus dynamic length, varying time-step resolutions) and then build on popular sequence models for <i>words</i> to instead model sequences of <i>language-based emotion in time</i>. Over a novel Twitter dataset of 1,900 users and weekly + daily scores for 6 emotions and 2 additional linguistic attributes, we find a novel dual-sequence GRU model with decayed hidden states achieves best results (<tex-math>r = .66</tex-math>) significantly out-predicting, e.g., a moving averaging based on the past time-steps (<tex-math>r = .49</tex-math>). We make our anonymized dataset as well as task setup and evaluation code available for others to build on.</abstract>
      <url hash="12f5f064">2020.coling-main.261</url>
    </paper>
    <paper id="262">
      <title>Solving Math Word Problems with Multi-Encoders and Multi-Decoders</title>
      <author><first>Yibin</first><last>Shen</last></author>
      <author><first>Cheqing</first><last>Jin</last></author>
      <pages>2924–2934</pages>
      <abstract>Math word problems solving remains a challenging task where potential semantic and mathematical logic need to be mined from natural language. Although previous researches employ the Seq2Seq technique to transform text descriptions into equation expressions, most of them achieve inferior performance due to insufficient consideration in the design of encoder and decoder. Specifically, these models only consider input/output objects as sequences, ignoring the important structural information contained in text descriptions and equation expressions. To overcome those defects, a model with multi-encoders and multi-decoders is proposed in this paper, which combines sequence-based encoder and graph-based encoder to enhance the representation of text descriptions, and generates different equation expressions via sequence-based decoder and tree-based decoder. Experimental results on the dataset Math23K show that our model outperforms existing state-of-the-art methods.</abstract>
      <url hash="26b85d0a">2020.coling-main.262</url>
    </paper>
    <paper id="263">
      <title>End to End <fixed-case>C</fixed-case>hinese Lexical Fusion Recognition with Sememe Knowledge</title>
      <author><first>Yijiang</first><last>Liu</last></author>
      <author><first>Meishan</first><last>Zhang</last></author>
      <author><first>Donghong</first><last>Ji</last></author>
      <pages>2935–2946</pages>
      <abstract>In this paper, we present Chinese lexical fusion recognition, a new task which could be regarded as one kind of coreference recognition. First, we introduce the task in detail, showing the relationship with coreference recognition and differences from the existing tasks. Second, we propose an end-to-end model for the task, handling mentions as well as coreference relationship jointly. The model exploits the state-of-the-art contextualized BERT representations as an encoder, and is further enhanced with the sememe knowledge from HowNet by graph attention networks. We manually annotate a benchmark dataset for the task and then conduct experiments on it. Results demonstrate that our final model is effective and competitive for the task. Detailed analysis is offered for comprehensively understanding the new task and our proposed model.</abstract>
      <url hash="71ce220e">2020.coling-main.263</url>
    </paper>
    <paper id="264">
      <title>Comparison by Conversion: Reverse-Engineering <fixed-case>UCCA</fixed-case> from Syntax and Lexical Semantics</title>
      <author><first>Daniel</first><last>Hershcovich</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <author><first>Dotan</first><last>Dvir</last></author>
      <author><first>Jakob</first><last>Prange</last></author>
      <author><first>Miryam</first><last>de Lhoneux</last></author>
      <author><first>Omri</first><last>Abend</last></author>
      <pages>2947–2966</pages>
      <abstract>Building robust natural language understanding systems will require a clear characterization of whether and how various linguistic meaning representations complement each other. To perform a systematic comparative analysis, we evaluate the mapping between meaning representations from different frameworks using two complementary methods: (i) a rule-based converter, and (ii) a supervised delexicalized parser that parses to one framework using only information from the other as features. We apply these methods to convert the STREUSLE corpus (with syntactic and lexical semantic annotations) to UCCA (a graph-structured full-sentence meaning representation). Both methods yield surprisingly accurate target representations, close to fully supervised UCCA parser quality—indicating that UCCA annotations are partially redundant with STREUSLE annotations. Despite this substantial convergence between frameworks, we find several important areas of divergence.</abstract>
      <url hash="e0937815">2020.coling-main.264</url>
    </paper>
    <paper id="265">
      <title>Logic-guided Semantic Representation Learning for Zero-Shot Relation Classification</title>
      <author><first>Juan</first><last>Li</last></author>
      <author><first>Ruoxu</first><last>Wang</last></author>
      <author><first>Ningyu</first><last>Zhang</last></author>
      <author><first>Wen</first><last>Zhang</last></author>
      <author><first>Fan</first><last>Yang</last></author>
      <author><first>Huajun</first><last>Chen</last></author>
      <pages>2967–2978</pages>
      <abstract>Relation classification aims to extract semantic relations between entity pairs from the sentences. However, most existing methods can only identify seen relation classes that occurred during training. To recognize unseen relations at test time, we explore the problem of zero-shot relation classification. Previous work regards the problem as reading comprehension or textual entailment, which have to rely on artificial descriptive information to improve the understandability of relation types. Thus, rich semantic knowledge of the relation labels is ignored. In this paper, we propose a novel logic-guided semantic representation learning model for zero-shot relation classification. Our approach builds connections between seen and unseen relations via implicit and explicit semantic representations with knowledge graph embeddings and logic rules. Extensive experimental results demonstrate that our method can generalize to unseen relation types and achieve promising improvements.</abstract>
      <url hash="8be95fd9">2020.coling-main.265</url>
    </paper>
    <paper id="266">
      <title>Semantic Role Labeling with Heterogeneous Syntactic Knowledge</title>
      <author><first>Qingrong</first><last>Xia</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <author><first>Zhenghua</first><last>Li</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>2979–2990</pages>
      <abstract>Recently, due to the interplay between syntax and semantics, incorporating syntactic knowledge into neural semantic role labeling (SRL) has achieved much attention. Most of the previous syntax-aware SRL works focus on explicitly modeling homogeneous syntactic knowledge over tree outputs. In this work, we propose to encode <i>heterogeneous</i> syntactic knowledge for SRL from both explicit and implicit representations. First, we introduce graph convolutional networks to explicitly encode multiple heterogeneous dependency parse trees. Second, we extract the implicit syntactic representations from syntactic parser trained with heterogeneous treebanks. Finally, we inject the two types of heterogeneous syntax-aware representations into the base SRL model as extra inputs. We conduct experiments on two widely-used benchmark datasets, i.e., Chinese Proposition Bank 1.0 and English CoNLL-2005 dataset. Experimental results show that incorporating heterogeneous syntactic knowledge brings significant improvements over strong baselines. We further conduct detailed analysis to gain insights on the usefulness of heterogeneous (vs. homogeneous) syntactic knowledge and the effectiveness of our proposed approaches for modeling such knowledge.</abstract>
      <url hash="3b7a31af">2020.coling-main.266</url>
    </paper>
    <paper id="267">
      <title>Normalizing Compositional Structures Across Graphbanks</title>
      <author><first>Lucia</first><last>Donatelli</last></author>
      <author><first>Jonas</first><last>Groschwitz</last></author>
      <author><first>Matthias</first><last>Lindemann</last></author>
      <author><first>Alexander</first><last>Koller</last></author>
      <author><first>Pia</first><last>Weißenhorn</last></author>
      <pages>2991–3006</pages>
      <abstract>The emergence of a variety of graph-based meaning representations (MRs) has sparked an important conversation about how to adequately represent semantic structure. MRs exhibit structural differences that reflect different theoretical and design considerations, presenting challenges to uniform linguistic analysis and cross-framework semantic parsing. Here, we ask the question of which design differences between MRs are meaningful and semantically-rooted, and which are superficial. We present a methodology for normalizing discrepancies between MRs at the compositional level (Lindemann et al., 2019), finding that we can normalize the majority of divergent phenomena using linguistically-grounded rules. Our work significantly increases the match in compositional structure between MRs and improves multi-task learning (MTL) in a low-resource setting, serving as a proof of concept for future broad-scale cross-MR normalization.</abstract>
      <url hash="f73f1ac4">2020.coling-main.267</url>
    </paper>
    <paper id="268">
      <title>Leveraging <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et Paths for Neural Hypernym Prediction</title>
      <author><first>Yejin</first><last>Cho</last></author>
      <author><first>Juan Diego</first><last>Rodriguez</last></author>
      <author><first>Yifan</first><last>Gao</last></author>
      <author><first>Katrin</first><last>Erk</last></author>
      <pages>3007–3018</pages>
      <abstract>We formulate the problem of hypernym prediction as a sequence generation task, where the sequences are taxonomy paths in WordNet. Our experiments with encoder-decoder models show that training to generate taxonomy paths can improve the performance of direct hypernym prediction. As a simple but powerful model, the hypo2path model achieves state-of-the-art performance, outperforming the best benchmark by 4.11 points in hit-at-one (H@1).</abstract>
      <url hash="c4d8fa84">2020.coling-main.268</url>
    </paper>
    <paper id="269">
      <title>When Beards Start Shaving Men: A Subject-object Resolution Test Suite for Morpho-syntactic and Semantic Model Introspection</title>
      <author><first>Patricia</first><last>Fischer</last></author>
      <author><first>Daniël</first><last>de Kok</last></author>
      <author><first>Erhard</first><last>Hinrichs</last></author>
      <pages>3019–3035</pages>
      <abstract>In this paper, we introduce the SORTS Subject-Object Resolution Test Suite of German minimal sentence pairs for model introspection. The full test suite consists of 18,502 transitive clauses with manual annotations of 8 word order patterns, 5 morphological and syntactic and 11 semantic property classes. The test suite has been constructed such that sentences are minimal pairs with respect to a property class. Each property has been selected with a particular focus on its effect on subject-object resolution, the second-most error-prone task within syntactic parsing of German after prepositional phrase attachment (Fischer et al., 2019). The size and detail of annotations make the test suite a valuable resource for natural language processing applications with syntactic and semantic tasks. We use dependency parsing to demonstrate how the test suite allows insights into the process of subject-object resolution. Based on the test suite annotations, word order and case syncretism can be identified as most important factors that affect subject-object resolution.</abstract>
      <url hash="df5d77d1">2020.coling-main.269</url>
    </paper>
    <paper id="270">
      <title>Modality Enriched Neural Network for Metaphor Detection</title>
      <author><first>Mingyu</first><last>Wan</last></author>
      <author><first>Baixi</first><last>Xing</last></author>
      <pages>3036–3042</pages>
      <abstract>Metaphor as a cognitive mechanism in human’s conceptual system manifests itself an effective way for language communication. Although being intuitively sensible for human, metaphor detection is still a challenging task due to the subtle ontological differences between metaphorical and non-metaphorical expressions. This work proposes a modality enriched deep learning model for tackling this unsolved issue. It provides a new perspective for understanding metaphor as a modality shift, as in ‘sweet voice’. It also attempts to enhance metaphor detection by combining deep learning with effective linguistic insight. Extending the work at Wan et al. (2020), we concatenate word sensorimotor scores (Lynott et al., 2019) with word vectors as the input of attention-based Bi-LSTM using a benchmark dataset–the VUA corpus. The experimental results show great F1 improvement (above 0.5%) of the proposed model over other methods in record, demonstrating the usefulness of leveraging modality norms for metaphor detection.</abstract>
      <url hash="fdb4e76e">2020.coling-main.270</url>
    </paper>
    <paper id="271">
      <title>Coordination Boundary Identification without Labeled Data for Compound Terms Disambiguation</title>
      <author><first>Yuya</first><last>Sawada</last></author>
      <author><first>Takashi</first><last>Wada</last></author>
      <author><first>Takayoshi</first><last>Shibahara</last></author>
      <author><first>Hiroki</first><last>Teranishi</last></author>
      <author><first>Shuhei</first><last>Kondo</last></author>
      <author><first>Hiroyuki</first><last>Shindo</last></author>
      <author><first>Taro</first><last>Watanabe</last></author>
      <author><first>Yuji</first><last>Matsumoto</last></author>
      <pages>3043–3049</pages>
      <abstract>We propose a simple method for nominal coordination boundary identification. As the main strength of our method, it can identify the coordination boundaries without training on labeled data, and can be applied even if coordination structure annotations are not available. Our system employs pre-trained word embeddings to measure the similarities of words and detects the span of coordination, assuming that conjuncts share syntactic and semantic similarities. We demonstrate that our method yields good results in identifying coordinated noun phrases in the GENIA corpus and is comparable to a recent supervised method for the case when the coordinator conjoins simple noun phrases.</abstract>
      <url hash="90c56d9f">2020.coling-main.271</url>
    </paper>
    <paper id="272">
      <title>Learning Semantic Correspondences from Noisy Data-text Pairs by Local-to-Global Alignments</title>
      <author><first>Feng</first><last>Nie</last></author>
      <author><first>Jinpeng</first><last>Wang</last></author>
      <author><first>Chin-Yew</first><last>Lin</last></author>
      <pages>3050–3059</pages>
      <abstract>Learning semantic correspondences between structured input data (e.g., slot-value pairs) and associated texts is a core problem for many downstream NLP applications, e.g., data-to-text generation. Large-scale datasets recently proposed for generation contain loosely corresponding data text pairs, where part of spans in text cannot be aligned to its incomplete paired input. To learn semantic correspondences from such datasets, we propose a two-stage local-to-global alignment (L2GA) framework. First, a local model based on multi-instance learning is applied to build alignments for texts spans that can be directly grounded to its paired structured input. Then, a novel global model built upon a memory-guided conditional random field (CRF) layer aims to infer missing alignments for text spans which not supported by paired incomplete inputs, where the memory is designed to leverage alignment clues provided by the local model to strengthen the global model. In this way, the local model and global model can work jointly to learn semantic correspondences in the same framework. Experimental results show that our proposed method can be generalized to both restaurant and computer domains and improve the alignment accuracy.</abstract>
      <url hash="cab5d260">2020.coling-main.272</url>
    </paper>
    <paper id="273">
      <title>Definition Frames: Using Definitions for Hybrid Concept Representations</title>
      <author><first>Evangelia</first><last>Spiliopoulou</last></author>
      <author><first>Artidoro</first><last>Pagnoni</last></author>
      <author><first>Eduard</first><last>Hovy</last></author>
      <pages>3060–3068</pages>
      <abstract>Advances in word representations have shown tremendous improvements in downstream NLP tasks, but lack semantic interpretability. In this paper, we introduce Definition Frames (DF), a matrix distributed representation extracted from definitions, where each dimension is semantically interpretable. DF dimensions correspond to the Qualia structure relations: a set of relations that uniquely define a term. Our results show that DFs have competitive performance with other distributional semantic approaches on word similarity tasks.</abstract>
      <url hash="b9b53905">2020.coling-main.273</url>
    </paper>
    <paper id="274">
      <title><fixed-case>QAN</fixed-case>om: Question-Answer driven <fixed-case>SRL</fixed-case> for Nominalizations</title>
      <author><first>Ayal</first><last>Klein</last></author>
      <author><first>Jonathan</first><last>Mamou</last></author>
      <author><first>Valentina</first><last>Pyatkin</last></author>
      <author><first>Daniela</first><last>Stepanov</last></author>
      <author><first>Hangfeng</first><last>He</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <author><first>Luke</first><last>Zettlemoyer</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <pages>3069–3083</pages>
      <abstract>We propose a new semantic scheme for capturing predicate-argument relations for nominalizations, termed QANom. This scheme extends the QA-SRL formalism (He et al., 2015), modeling the relations between nominalizations and their arguments via natural language question-answer pairs. We construct the first QANom dataset using controlled crowdsourcing, analyze its quality and compare it to expertly annotated nominal-SRL annotations, as well as to other QA-driven annotations. In addition, we train a baseline QANom parser for identifying nominalizations and labeling their arguments with question-answer pairs. Finally, we demonstrate the extrinsic utility of our annotations for downstream tasks using both indirect supervision and zero-shot settings.</abstract>
      <url hash="4ea38bfc">2020.coling-main.274</url>
    </paper>
    <paper id="275">
      <title>Event Coreference Resolution with their Paraphrases and Argument-aware Embeddings</title>
      <author><first>Yutao</first><last>Zeng</last></author>
      <author><first>Xiaolong</first><last>Jin</last></author>
      <author><first>Saiping</first><last>Guan</last></author>
      <author><first>Jiafeng</first><last>Guo</last></author>
      <author><first>Xueqi</first><last>Cheng</last></author>
      <pages>3084–3094</pages>
      <abstract>Event coreference resolution aims to classify all event mentions that refer to the same real-world event into the same group, which is necessary to information aggregation and many downstream applications. To resolve event coreference, existing methods usually calculate the similarities between event mentions and between specific kinds of event arguments. However, they fail to accurately identify paraphrase relations between events and may suffer from error propagation while extracting event components (i.e., event mentions and their arguments). Therefore, we propose a new model based on Event-specific Paraphrases and Argument-aware Semantic Embeddings, thus called EPASE, for event coreference resolution. EPASE recognizes deep paraphrase relations in an event-specific context of sentences and can cover event paraphrases of more situations, bringing about a better generalization. Additionally, the embeddings of argument roles are encoded into event embedding without relying on a fixed number and type of arguments, which results in the better scalability of EPASE. Experiments on both within- and cross-document event coreference demonstrate its consistent and significant superiority compared to existing methods.</abstract>
      <url hash="5dfeefea">2020.coling-main.275</url>
    </paper>
    <paper id="276">
      <title>Studying Taxonomy Enrichment on Diachronic <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et Versions</title>
      <author><first>Irina</first><last>Nikishina</last></author>
      <author><first>Varvara</first><last>Logacheva</last></author>
      <author><first>Alexander</first><last>Panchenko</last></author>
      <author><first>Natalia</first><last>Loukachevitch</last></author>
      <pages>3095–3106</pages>
      <abstract>Ontologies, taxonomies, and thesauri have always been in high demand in a large number of NLP tasks. However, most studies are focused on the creation of lexical resources rather than the maintenance of the existing ones and keeping them up-to-date. In this paper, we address the problem of taxonomy enrichment. Namely, we explore the possibilities of taxonomy extension in a resource-poor setting and present several methods which are applicable to a large number of languages. We also create novel English and Russian datasets for training and evaluating taxonomy enrichment systems and describe a technique of creating such datasets for other languages.</abstract>
      <url hash="2c9537f6">2020.coling-main.276</url>
    </paper>
    <paper id="277">
      <title><fixed-case>VICTR</fixed-case>: Visual Information Captured Text Representation for Text-to-Vision Multimodal Tasks</title>
      <author><first>Caren</first><last>Han</last></author>
      <author><first>Siqu</first><last>Long</last></author>
      <author><first>Siwen</first><last>Luo</last></author>
      <author><first>Kunze</first><last>Wang</last></author>
      <author><first>Josiah</first><last>Poon</last></author>
      <pages>3107–3117</pages>
      <abstract>Text-to-image multimodal tasks, generating/retrieving an image from a given text description, are extremely challenging tasks since raw text descriptions cover quite limited information in order to fully describe visually realistic images. We propose a new visual contextual text representation for text-to-image multimodal tasks, VICTR, which captures rich visual semantic information of objects from the text input. First, we use the text description as initial input and conduct dependency parsing to extract the syntactic structure and analyse the semantic aspect, including object quantities, to extract the scene graph. Then, we train the extracted objects, attributes, and relations in the scene graph and the corresponding geometric relation information using Graph Convolutional Networks, and it generates text representation which integrates textual and visual semantic information. The text representation is aggregated with word-level and sentence-level embedding to generate both visual contextual word and sentence representation. For the evaluation, we attached VICTR to the state-of-the-art models in text-to-image generation.VICTR is easily added to existing models and improves across both quantitative and qualitative aspects.</abstract>
      <url hash="b990c50c">2020.coling-main.277</url>
    </paper>
    <paper id="278">
      <title>Finding the Evidence: Localization-aware Answer Prediction for Text Visual Question Answering</title>
      <author><first>Wei</first><last>Han</last></author>
      <author><first>Hantao</first><last>Huang</last></author>
      <author><first>Tao</first><last>Han</last></author>
      <pages>3118–3131</pages>
      <abstract>Image text carries essential information to understand the scene and perform reasoning. Text-based visual question answering (text VQA) task focuses on visual questions that require reading text in images. Existing text VQA systems generate an answer by selecting from optical character recognition (OCR) texts or a fixed vocabulary. Positional information of text is underused and there is a lack of evidence for the generated answer. As such, this paper proposes a localization-aware answer prediction network (LaAP-Net) to address this challenge. Our LaAP-Net not only generates the answer to the question but also predicts a bounding box as evidence of the generated answer. Moreover, a context-enriched OCR representation (COR) for multimodal fusion is proposed to facilitate the localization task. Our proposed LaAP-Net outperforms existing approaches on three benchmark datasets for the text VQA task by a noticeable margin.</abstract>
      <url hash="f4e0af7c">2020.coling-main.278</url>
    </paper>
    <paper id="279">
      <title>Interactive Key-Value Memory-augmented Attention for Image Paragraph Captioning</title>
      <author><first>Chunpu</first><last>Xu</last></author>
      <author><first>Yu</first><last>Li</last></author>
      <author><first>Chengming</first><last>Li</last></author>
      <author><first>Xiang</first><last>Ao</last></author>
      <author><first>Min</first><last>Yang</last></author>
      <author><first>Jinwen</first><last>Tian</last></author>
      <pages>3132–3142</pages>
      <abstract>Image paragraph captioning (IPC) aims to generate a fine-grained paragraph to describe the visual content of an image. Significant progress has been made by deep neural networks, in which the attention mechanism plays an essential role. However, conventional attention mechanisms tend to ignore the past alignment information, which often results in problems of repetitive captioning and incomplete captioning. In this paper, we propose an Interactive key-value Memory- augmented Attention model for image Paragraph captioning (IMAP) to keep track of the attention history (salient objects coverage information) along with the update-chain of the decoder state and therefore avoid generating repetitive or incomplete image descriptions. In addition, we employ an adaptive attention mechanism to realize adaptive alignment from image regions to caption words, where an image region can be mapped to an arbitrary number of caption words while a caption word can also attend to an arbitrary number of image regions. Extensive experiments on a benchmark dataset (i.e., Stanford) demonstrate the effectiveness of our IMAP model.</abstract>
      <url hash="d717ce90">2020.coling-main.279</url>
    </paper>
    <paper id="280">
      <title>Geo-Aware Image Caption Generation</title>
      <author><first>Sofia</first><last>Nikiforova</last></author>
      <author><first>Tejaswini</first><last>Deoskar</last></author>
      <author><first>Denis</first><last>Paperno</last></author>
      <author><first>Yoad</first><last>Winter</last></author>
      <pages>3143–3156</pages>
      <abstract>Standard image caption generation systems produce generic descriptions of images and do not utilize any contextual information or world knowledge. In particular, they are unable to generate captions that contain references to the geographic context of an image, for example, the location where a photograph is taken or relevant geographic objects around an image location. In this paper, we develop a geo-aware image caption generation system, which incorporates geographic contextual information into a standard image captioning pipeline. We propose a way to build an image-specific representation of the geographic context and adapt the caption generation network to produce appropriate geographic names in the image descriptions. We evaluate our system on a novel captioning dataset that contains contextualized captions and geographic metadata and achieve substantial improvements in BLEU, ROUGE, METEOR and CIDEr scores. We also introduce a new metric to assess generated geographic references directly and empirically demonstrate our system’s ability to produce captions with relevant and factually accurate geographic referencing.</abstract>
      <url hash="2d6d8bc6">2020.coling-main.280</url>
    </paper>
    <paper id="281">
      <title>Bridge the Gap: High-level Semantic Planning for Image Captioning</title>
      <author><first>Chenxi</first><last>Yuan</last></author>
      <author><first>Yang</first><last>Bai</last></author>
      <author><first>Chun</first><last>Yuan</last></author>
      <pages>3157–3167</pages>
      <abstract>Recent image captioning models have made much progress for exploring the multi-modal interaction, such as attention mechanisms. Though these mechanisms can boost the interaction, there are still two gaps between the visual and language domains: (1) the gap between the visual features and textual semantics, (2) the gap between the disordering of visual features and the ordering of texts. To bridge the gaps we propose a high-level semantic planning (HSP) mechanism that incorporates both a semantic reconstruction and an explicit order planning. We integrate the planning mechanism to the attention based caption model and propose the High-level Semantic PLanning based Attention Network (HS-PLAN). First, an attention based reconstruction module is designed to reconstruct the visual features with high-level semantic information. Then we apply a pointer network to serialize the features and obtain the explicit order plan to guide the generation. Experiments conducted on MS COCO show that our model outperforms previous methods and achieves the state-of-the-art performance of 133.4% CIDEr-D score.</abstract>
      <url hash="d52dded1">2020.coling-main.281</url>
    </paper>
    <paper id="282">
      <title>Interactively-Propagative Attention Learning for Implicit Discourse Relation Recognition</title>
      <author><first>Huibin</first><last>Ruan</last></author>
      <author><first>Yu</first><last>Hong</last></author>
      <author><first>Yang</first><last>Xu</last></author>
      <author><first>Zhen</first><last>Huang</last></author>
      <author><first>Guodong</first><last>Zhou</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>3168–3178</pages>
      <abstract>We tackle implicit discourse relation recognition. Both self-attention and interactive-attention mechanisms have been applied for attention-aware representation learning, which improves the current discourse analysis models. To take advantages of the two attention mechanisms simultaneously, we develop a propagative attention learning model using a cross-coupled two-channel network. We experiment on Penn Discourse Treebank. The test results demonstrate that our model yields substantial improvements over the baselines (BiLSTM and BERT).</abstract>
      <url hash="16e6e220">2020.coling-main.282</url>
    </paper>
    <paper id="283">
      <title>Dual Attention Model for Citation Recommendation</title>
      <author><first>Yang</first><last>Zhang</last></author>
      <author><first>Qiang</first><last>Ma</last></author>
      <pages>3179–3189</pages>
      <abstract>Based on an exponentially increasing number of academic articles, discovering and citing comprehensive and appropriate resources has become a non-trivial task. Conventional citation recommender methods suffer from severe information loss. For example, they do not consider the section of the paper that the user is writing and for which they need to find a citation, the relatedness between the words in the local context (the text span that describes a citation), or the importance on each word from the local context. These shortcomings make such methods insufficient for recommending adequate citations to academic manuscripts. In this study, we propose a novel embedding-based neural network called “dual attention model for citation recommendation (DACR)” to recommend citations during manuscript preparation. Our method adapts embedding of three semantic information: words in the local context, structural contexts, and the section on which a user is working. A neural network model is designed to maximize the similarity between the embedding of the three input (local context words, section and structural contexts) and the target citation appearing in the context. The core of the neural network model is composed of self-attention and additive attention, where the former aims to capture the relatedness between the contextual words and structural context, and the latter aims to learn the importance of them. The experiments on real-world datasets demonstrate the effectiveness of the proposed approach.</abstract>
      <url hash="dd80be1b">2020.coling-main.283</url>
    </paper>
    <paper id="284">
      <title>Dual Attention Network for Cross-lingual Entity Alignment</title>
      <author><first>Jian</first><last>Sun</last></author>
      <author><first>Yu</first><last>Zhou</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <pages>3190–3201</pages>
      <abstract>Cross-lingual Entity alignment is an essential part of building a knowledge graph, which can help integrate knowledge among different language knowledge graphs. In the real KGs, there exists an imbalance among the information in the same hierarchy of corresponding entities, which results in the heterogeneity of neighborhood structure, making this task challenging. To tackle this problem, we propose a dual attention network for cross-lingual entity alignment (DAEA). Specifically, our dual attention consists of relation-aware graph attention and hierarchical attention. The relation-aware graph attention aims at selectively aggregating multi-hierarchy neighborhood information to alleviate the difference of heterogeneity among counterpart entities. The hierarchical attention adaptively aggregates the low-hierarchy and the high-hierarchy information, which is beneficial to balance the neighborhood information of counterpart entities and distinguish non-counterpart entities with similar structures. Finally, we treat cross-lingual entity alignment as a process of linking prediction. Experimental results on three real-world cross-lingual entity alignment datasets have shown the effectiveness of DAEA.</abstract>
      <url hash="8257996a">2020.coling-main.284</url>
    </paper>
    <paper id="285">
      <title>Task-Aware Representation of Sentences for Generic Text Classification</title>
      <author><first>Kishaloy</first><last>Halder</last></author>
      <author><first>Alan</first><last>Akbik</last></author>
      <author><first>Josip</first><last>Krapac</last></author>
      <author><first>Roland</first><last>Vollgraf</last></author>
      <pages>3202–3213</pages>
      <abstract>State-of-the-art approaches for text classification leverage a transformer architecture with a linear layer on top that outputs a class distribution for a given prediction problem. While effective, this approach suffers from conceptual limitations that affect its utility in few-shot or zero-shot transfer learning scenarios. First, the number of classes to predict needs to be pre-defined. In a transfer learning setting, in which new classes are added to an already trained classifier, all information contained in a linear layer is therefore discarded, and a new layer is trained from scratch. Second, this approach only learns the semantics of classes implicitly from training examples, as opposed to leveraging the explicit semantic information provided by the natural language names of the classes. For instance, a classifier trained to predict the topics of news articles might have classes like “business” or “sports” that themselves carry semantic information. Extending a classifier to predict a new class named “politics” with only a handful of training examples would benefit from both leveraging the semantic information in the name of a new class and using the information contained in the already trained linear layer. This paper presents a novel formulation of text classification that addresses these limitations. It imbues the notion of the task at hand into the transformer model itself by factorizing arbitrary classification problems into a generic binary classification problem. We present experiments in few-shot and zero-shot transfer learning that show that our approach significantly outperforms previous approaches on small training data and can even learn to predict new classes with no training examples at all. The implementation of our model is publicly available at: https://github.com/flairNLP/flair.</abstract>
      <url hash="85fb90d9">2020.coling-main.285</url>
    </paper>
    <paper id="286">
      <title><fixed-case>RANCC</fixed-case>: Rationalizing Neural Networks via Concept Clustering</title>
      <author><first>Housam Khalifa</first><last>Bashier</last></author>
      <author><first>Mi-Young</first><last>Kim</last></author>
      <author><first>Randy</first><last>Goebel</last></author>
      <pages>3214–3224</pages>
      <abstract>We propose a new self-explainable model for Natural Language Processing (NLP) text classification tasks. Our approach constructs explanations concurrently with the formulation of classification predictions. To do so, we extract a rationale from the text, then use it to predict a concept of interest as the final prediction. We provide three types of explanations: 1) rationale extraction, 2) a measure of feature importance, and 3) clustering of concepts. In addition, we show how our model can be compressed without applying complicated compression techniques. We experimentally demonstrate our explainability approach on a number of well-known text classification datasets.</abstract>
      <url hash="039ac694">2020.coling-main.286</url>
    </paper>
    <paper id="287">
      <title><fixed-case>L</fixed-case>ada<fixed-case>BERT</fixed-case>: Lightweight Adaptation of <fixed-case>BERT</fixed-case> through Hybrid Model Compression</title>
      <author><first>Yihuan</first><last>Mao</last></author>
      <author><first>Yujing</first><last>Wang</last></author>
      <author><first>Chufan</first><last>Wu</last></author>
      <author><first>Chen</first><last>Zhang</last></author>
      <author><first>Yang</first><last>Wang</last></author>
      <author><first>Quanlu</first><last>Zhang</last></author>
      <author><first>Yaming</first><last>Yang</last></author>
      <author><first>Yunhai</first><last>Tong</last></author>
      <author><first>Jing</first><last>Bai</last></author>
      <pages>3225–3234</pages>
      <abstract>BERT is a cutting-edge language representation model pre-trained by a large corpus, which achieves superior performances on various natural language understanding tasks. However, a major blocking issue of applying BERT to online services is that it is memory-intensive and leads to unsatisfactory latency of user requests, raising the necessity of model compression. Existing solutions leverage the knowledge distillation framework to learn a smaller model that imitates the behaviors of BERT. However, the training procedure of knowledge distillation is expensive itself as it requires sufficient training data to imitate the teacher model. In this paper, we address this issue by proposing a tailored solution named LadaBERT (Lightweight adaptation of BERT through hybrid model compression), which combines the advantages of different model compression methods, including weight pruning, matrix factorization and knowledge distillation. LadaBERT achieves state-of-the-art accuracy on various public datasets while the training overheads can be reduced by an order of magnitude.</abstract>
      <url hash="bb38d5fb">2020.coling-main.287</url>
    </paper>
    <paper id="288">
      <title>Emotion Classification by Jointly Learning to Lexiconize and Classify</title>
      <author><first>Deyu</first><last>Zhou</last></author>
      <author><first>Shuangzhi</first><last>Wu</last></author>
      <author><first>Qing</first><last>Wang</last></author>
      <author><first>Jun</first><last>Xie</last></author>
      <author><first>Zhaopeng</first><last>Tu</last></author>
      <author><first>Mu</first><last>Li</last></author>
      <pages>3235–3245</pages>
      <abstract>Emotion lexicons have been shown effective for emotion classification (Baziotis et al., 2018). Previous studies handle emotion lexicon construction and emotion classification separately. In this paper, we propose an emotional network (EmNet) to jointly learn sentence emotions and construct emotion lexicons which are dynamically adapted to a given context. The dynamic emotion lexicons are useful for handling words with multiple emotions based on different context, which can effectively improve the classification accuracy. We validate the approach on two representative architectures – LSTM and BERT, demonstrating its superiority on identifying emotions in Tweets. Our model outperforms several approaches proposed in previous studies and achieves new state-of-the-art on the benchmark Twitter dataset.</abstract>
      <url hash="5c014d89">2020.coling-main.288</url>
    </paper>
    <paper id="289">
      <title>Multi-level Alignment Pretraining for Multi-lingual Semantic Parsing</title>
      <author><first>Bo</first><last>Shao</last></author>
      <author><first>Yeyun</first><last>Gong</last></author>
      <author><first>Weizhen</first><last>Qi</last></author>
      <author><first>Nan</first><last>Duan</last></author>
      <author><first>Xiaola</first><last>Lin</last></author>
      <pages>3246–3256</pages>
      <abstract>In this paper, we present a multi-level alignment pretraining method in a unified architecture formulti-lingual semantic parsing. In this architecture, we use an adversarial training method toalign the space of different languages and use sentence level and word level parallel corpus assupervision information to align the semantic of different languages. Finally, we jointly train themulti-level alignment and semantic parsing tasks. We conduct experiments on a publicly avail-able multi-lingual semantic parsing dataset ATIS and a newly constructed dataset. Experimentalresults show that our model outperforms state-of-the-art methods on both datasets.</abstract>
      <url hash="9126e4ec">2020.coling-main.289</url>
    </paper>
    <paper id="290">
      <title>Transformation of Dense and Sparse Text Representations</title>
      <author><first>Wenpeng</first><last>Hu</last></author>
      <author><first>Mengyu</first><last>Wang</last></author>
      <author><first>Bing</first><last>Liu</last></author>
      <author><first>Feng</first><last>Ji</last></author>
      <author><first>Jinwen</first><last>Ma</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <pages>3257–3267</pages>
      <abstract>Sparsity is regarded as a desirable property of representations, especially in terms of explanation. However, its usage has been limited due to the gap with dense representations. Most research progresses in NLP in recent years are based on dense representations. Thus the desirable property of sparsity cannot be leveraged. Inspired by Fourier Transformation, in this paper, we propose a novel Semantic Transformation method to bridge the dense and sparse spaces, which can facilitate the NLP research to shift from dense spaces to sparse spaces or to jointly use both spaces. Experiments using classification tasks and natural language inference task show that the proposed Semantic Transformation is effective.</abstract>
      <url hash="f73f614f">2020.coling-main.290</url>
    </paper>
    <paper id="291">
      <title>Conception: Multilingually-Enhanced, Human-Readable Concept Vector Representations</title>
      <author><first>Simone</first><last>Conia</last></author>
      <author><first>Roberto</first><last>Navigli</last></author>
      <pages>3268–3284</pages>
      <abstract>To date, the most successful word, word sense, and concept modelling techniques have used large corpora and knowledge resources to produce dense vector representations that capture semantic similarities in a relatively low-dimensional space. Most current approaches, however, suffer from a monolingual bias, with their strength depending on the amount of data available across languages. In this paper we address this issue and propose Conception, a novel technique for building language-independent vector representations of concepts which places multilinguality at its core while retaining explicit relationships between concepts. Our approach results in high-coverage representations that outperform the state of the art in multilingual and cross-lingual Semantic Word Similarity and Word Sense Disambiguation, proving particularly robust on low-resource languages. Conception – its software and the complete set of representations – is available at https://github.com/SapienzaNLP/conception.</abstract>
      <url hash="a009e288">2020.coling-main.291</url>
    </paper>
    <paper id="292">
      <title>What Does This Acronym Mean? Introducing a New Dataset for Acronym Identification and Disambiguation</title>
      <author><first>Amir</first><last>Pouran Ben Veyseh</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Quan Hung</first><last>Tran</last></author>
      <author><first>Thien Huu</first><last>Nguyen</last></author>
      <pages>3285–3301</pages>
      <abstract>Acronyms are the short forms of phrases that facilitate conveying lengthy sentences in documents and serve as one of the mainstays of writing. Due to their importance, identifying acronyms and corresponding phrases (i.e., acronym identification (AI)) and finding the correct meaning of each acronym (i.e., acronym disambiguation (AD)) are crucial for text understanding. Despite the recent progress on this task, there are some limitations in the existing datasets which hinder further improvement. More specifically, limited size of manually annotated AI datasets or noises in the automatically created acronym identification datasets obstruct designing advanced high-performing acronym identification models. Moreover, the existing datasets are mostly limited to the medical domain and ignore other domains. In order to address these two limitations, we first create a manually annotated large AI dataset for scientific domain. This dataset contains 17,506 sentences which is substantially larger than previous scientific AI datasets. Next, we prepare an AD dataset for scientific domain with 62,441 samples which is significantly larger than previous scientific AD dataset. Our experiments show that the existing state-of-the-art models fall far behind human-level performance on both datasets proposed by this work. In addition, we propose a new deep learning model which utilizes the syntactical structure of the sentence to expand an ambiguous acronym in a sentence. The proposed model outperforms the state-of-the-art models on the new AD dataset, providing a strong baseline for future research on this dataset.</abstract>
      <url hash="cf244330">2020.coling-main.292</url>
    </paper>
    <paper id="293">
      <title>Sentence Matching with Syntax- and Semantics-Aware <fixed-case>BERT</fixed-case></title>
      <author><first>Tao</first><last>Liu</last></author>
      <author><first>Xin</first><last>Wang</last></author>
      <author><first>Chengguo</first><last>Lv</last></author>
      <author><first>Ranran</first><last>Zhen</last></author>
      <author><first>Guohong</first><last>Fu</last></author>
      <pages>3302–3312</pages>
      <abstract>Sentence matching aims to identify the special relationship between two sentences, and plays a key role in many natural language processing tasks. However, previous studies mainly focused on exploiting either syntactic or semantic information for sentence matching, and no studies consider integrating both of them. In this study, we propose integrating syntax and semantics into BERT with sentence matching. In particular, we use an implicit syntax and semantics integration method that is less sensitive to the output structure information. Thus the implicit integration can alleviate the error propagation problem. The experimental results show that our approach has achieved state-of-the-art or competitive performance on several sentence matching datasets, demonstrating the benefits of implicitly integrating syntactic and semantic features in sentence matching.</abstract>
      <url hash="7d9c761a">2020.coling-main.293</url>
    </paper>
    <paper id="294">
      <title>Temporal Relations Annotation and Extrapolation Based on Semi-intervals and Boundig Relations</title>
      <author><first>Alejandro</first><last>Pimentel</last></author>
      <author><first>Gemma</first><last>Bel Enguix</last></author>
      <author><first>Gerardo</first><last>Sierra Martínez</last></author>
      <author><first>Azucena</first><last>Montes</last></author>
      <pages>3313–3323</pages>
      <abstract>The computational treatment of temporal relations is based on the work of Allen, who establishes 13 different types, and Freksa, who designs a cognitive procedure to manage them. Freksa’s notation is not widely used because, although it has cognitive and expressive advantages, it is too complex from the computational perspective. This paper proposes a system for the annotation and management of temporal relations that combines the richness and expressiveness of Freksa’s approach with the simplicity of Allen’s notation. Our method is summarized in the application of bounding relations, thanks to which it is possible to obtain the temporary representation of complete neighborhoods capable of representing vague temporal relations such as those that can be frequently found in a text. Such advantages are obtained without the need to greatly increase the complexity of the labeling process since the markup language is almost the same as TimeML, to which only a second temporary “relType”’ type label relationship is added. Our experiments show that the temporal relationships that present vagueness are in fact much more common than those in which a single relationship can be established precisely. For these reasons, our new labeling system achieves a more agreeable representation of temporal relations.</abstract>
      <url hash="19ca0684">2020.coling-main.294</url>
    </paper>
    <paper id="295">
      <title>Homonym normalisation by word sense clustering: a case in <fixed-case>J</fixed-case>apanese</title>
      <author><first>Yo</first><last>Sato</last></author>
      <author><first>Kevin</first><last>Heffernan</last></author>
      <pages>3324–3332</pages>
      <abstract>This work presents a method of word sense clustering that differentiates homonyms and merge homophones, taking Japanese as an example, where orthographical variation causes problem for language processing. It uses contextualised embeddings (BERT) to cluster tokens into distinct sense groups, and we use these groups to normalise synonymous instances to a single representative form. We see the benefit of this normalisation in language model, as well as in transliteration.</abstract>
      <url hash="dc8497e0">2020.coling-main.295</url>
    </paper>
    <paper id="296">
      <title>Verbal Multiword Expression Identification: Do We Need a Sledgehammer to Crack a Nut?</title>
      <author><first>Caroline</first><last>Pasquer</last></author>
      <author><first>Agata</first><last>Savary</last></author>
      <author><first>Carlos</first><last>Ramisch</last></author>
      <author><first>Jean-Yves</first><last>Antoine</last></author>
      <pages>3333–3345</pages>
      <abstract>Automatic identification of multiword expressions (MWEs), like ‘to cut corners’ (to do an incomplete job), is a pre-requisite for semantically-oriented downstream applications. This task is challenging because MWEs, especially verbal ones (VMWEs), exhibit surface variability. This paper deals with a subproblem of VMWE identification: the identification of occurrences of previously seen VMWEs. A simple language-independent system based on a combination of filters competes with the best systems from a recent shared task: it obtains the best averaged F-score over 11 languages (0.6653) and even the best score for both seen and unseen VMWEs due to the high proportion of seen VMWEs in texts. This highlights the fact that focusing on the identification of seen VMWEs could be a strategy to improve VMWE identification in general.</abstract>
      <url hash="73da9965">2020.coling-main.296</url>
    </paper>
    <paper id="297">
      <title>An Unsupervised Method for Learning Representations of Multi-word Expressions for Semantic Classification</title>
      <author><first>Robert</first><last>Vacareanu</last></author>
      <author><first>Marco A.</first><last>Valenzuela-Escárcega</last></author>
      <author><first>Rebecca</first><last>Sharp</last></author>
      <author><first>Mihai</first><last>Surdeanu</last></author>
      <pages>3346–3356</pages>
      <abstract>This paper explores an unsupervised approach to learning a compositional representation function for multi-word expressions (MWEs), and evaluates it on the Tratz dataset, which associates two-word expressions with the semantic relation between the compound constituents (e.g. the label employer is associated with the noun compound government agency) (Tratz, 2011). The composition function is based on recurrent neural networks, and is trained using the Skip-Gram objective to predict the words in the context of MWEs. Thus our approach can naturally leverage large unlabeled text sources. Further, our method can make use of provided MWEs when available, but can also function as a completely unsupervised algorithm, using MWE boundaries predicted by a single, domain-agnostic part-of-speech pattern. With pre-defined MWE boundaries, our method outperforms the previous state-of-the-art performance on the coarse-grained evaluation of the Tratz dataset (Tratz, 2011), with an F1 score of 50.4%. The unsupervised version of our method approaches the performance of the supervised one, and even outperforms it in some configurations.</abstract>
      <url hash="c1896903">2020.coling-main.297</url>
    </paper>
    <paper id="298">
      <title><fixed-case>SLICE</fixed-case>: Supersense-based Lightweight Interpretable Contextual Embeddings</title>
      <author><first>Cindy</first><last>Aloui</last></author>
      <author><first>Carlos</first><last>Ramisch</last></author>
      <author><first>Alexis</first><last>Nasr</last></author>
      <author><first>Lucie</first><last>Barque</last></author>
      <pages>3357–3370</pages>
      <abstract>Contextualised embeddings such as BERT have become de facto state-of-the-art references in many NLP applications, thanks to their impressive performances. However, their opaqueness makes it hard to interpret their behaviour. SLICE is a hybrid model that combines supersense labels with contextual embeddings. We introduce a weakly supervised method to learn interpretable embeddings from raw corpora and small lists of seed words. Our model is able to represent both a word and its context as embeddings into the same compact space, whose dimensions correspond to interpretable supersenses. We assess the model in a task of supersense tagging for French nouns. The little amount of supervision required makes it particularly well suited for low-resourced scenarios. Thanks to its interpretability, we perform linguistic analyses about the predicted supersenses in terms of input word and context representations.</abstract>
      <url hash="5f921628">2020.coling-main.298</url>
    </paper>
    <paper id="299">
      <title>An Empirical Study of the Downstream Reliability of Pre-Trained Word Embeddings</title>
      <author><first>Anthony</first><last>Rios</last></author>
      <author><first>Brandon</first><last>Lwowski</last></author>
      <pages>3371–3388</pages>
      <abstract>While pre-trained word embeddings have been shown to improve the performance of downstream tasks, many questions remain regarding their reliability: Do the same pre-trained word embeddings result in the best performance with slight changes to the training data? Do the same pre-trained embeddings perform well with multiple neural network architectures? Do imputation strategies for unknown words impact reliability? In this paper, we introduce two new metrics to understand the downstream reliability of word embeddings. We find that downstream reliability of word embeddings depends on multiple factors, including, the evaluation metric, the handling of out-of-vocabulary words, and whether the embeddings are fine-tuned.</abstract>
      <url hash="a49db181">2020.coling-main.299</url>
    </paper>
    <paper id="300">
      <title>Sentence Analogies: Linguistic Regularities in Sentence Embeddings</title>
      <author><first>Xunjie</first><last>Zhu</last></author>
      <author><first>Gerard</first><last>de Melo</last></author>
      <pages>3389–3400</pages>
      <abstract>While important properties of word vector representations have been studied extensively, far less is known about the properties of sentence vector representations. Word vectors are often evaluated by assessing to what degree they exhibit regularities with regard to relationships of the sort considered in word analogies. In this paper, we investigate to what extent commonly used sentence vector representation spaces as well reflect certain kinds of regularities. We propose a number of schemes to induce evaluation data, based on lexical analogy data as well as semantic relationships between sentences. Our experiments consider a wide range of sentence embedding methods, including ones based on BERT-style contextual embeddings. We find that different models differ substantially in their ability to reflect such regularities.</abstract>
      <url hash="b5f0f59b">2020.coling-main.300</url>
    </paper>
    <paper id="301">
      <title>Manifold Learning-based Word Representation Refinement Incorporating Global and Local Information</title>
      <author><first>Wenyu</first><last>Zhao</last></author>
      <author><first>Dong</first><last>Zhou</last></author>
      <author><first>Lin</first><last>Li</last></author>
      <author><first>Jinjun</first><last>Chen</last></author>
      <pages>3401–3412</pages>
      <abstract>Recent studies show that word embedding models often underestimate similarities between similar words and overestimate similarities between distant words. This results in word similarity results obtained from embedding models inconsistent with human judgment. Manifold learning-based methods are widely utilized to refine word representations by re-embedding word vectors from the original embedding space to a new refined semantic space. These methods mainly focus on preserving local geometry information through performing weighted locally linear combination between words and their neighbors twice. However, these reconstruction weights are easily influenced by different selections of neighboring words and the whole combination process is time-consuming. In this paper, we propose two novel word representation refinement methods leveraging isometry feature mapping and local tangent space respectively. Unlike previous methods, our first method corrects pre-trained word embeddings by preserving global geometry information of all words instead of local geometry information between words and their neighbors. Our second method refines word representations by aligning original and re-fined embedding spaces based on local tangent space instead of performing weighted locally linear combination twice. Experimental results obtained from standard semantic relatedness and semantic similarity tasks show that our methods outperform various state-of-the-art baselines for word representation refinement.</abstract>
      <url hash="c82f4000">2020.coling-main.301</url>
    </paper>
    <paper id="302">
      <title>Collective Wisdom: Improving Low-resource Neural Machine Translation using Adaptive Knowledge Distillation</title>
      <author><first>Fahimeh</first><last>Saleh</last></author>
      <author><first>Wray</first><last>Buntine</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>3413–3421</pages>
      <abstract>Scarcity of parallel sentence-pairs poses a significant hurdle for training high-quality Neural Machine Translation (NMT) models in bilingually low-resource scenarios. A standard approach is transfer learning, which involves taking a model trained on a high-resource language-pair and fine-tuning it on the data of the low-resource MT condition of interest. However, it is not clear generally which high-resource language-pair offers the best transfer learning for the target MT setting. Furthermore, different transferred models may have complementary semantic and/or syntactic strengths, hence using only one model may be sub-optimal. In this paper, we tackle this problem using knowledge distillation, where we propose to distill the knowledge of ensemble of teacher models to a single student model. As the quality of these teacher models varies, we propose an effective adaptive knowledge distillation approach to dynamically adjust the contribution of the teacher models during the distillation process. Experiments on transferring from a collection of six language pairs from IWSLT to five low-resource language-pairs from TED Talks demonstrate the effectiveness of our approach, achieving up to +0.9 BLEU score improvements compared to strong baselines.</abstract>
      <url hash="230256c3">2020.coling-main.302</url>
    </paper>
    <paper id="303">
      <title>Enabling Interactive Transcription in an Indigenous Community</title>
      <author><first>Eric</first><last>Le Ferrand</last></author>
      <author><first>Steven</first><last>Bird</last></author>
      <author><first>Laurent</first><last>Besacier</last></author>
      <pages>3422–3428</pages>
      <abstract>We propose a novel transcription workflow which combines spoken term detection and human-in-the-loop, together with a pilot experiment. This work is grounded in an almost zero-resource scenario where only a few terms have so far been identified, involving two endangered languages. We show that in the early stages of transcription, when the available data is insufficient to train a robust ASR system, it is possible to take advantage of the transcription of a small number of isolated words in order to bootstrap the transcription of a speech collection.</abstract>
      <url hash="1dc7d671">2020.coling-main.303</url>
    </paper>
    <paper id="304">
      <title>Optimizing Transformer for Low-Resource Neural Machine Translation</title>
      <author><first>Ali</first><last>Araabi</last></author>
      <author><first>Christof</first><last>Monz</last></author>
      <pages>3429–3435</pages>
      <abstract>Language pairs with limited amounts of parallel data, also known as low-resource languages, remain a challenge for neural machine translation. While the Transformer model has achieved significant improvements for many language pairs and has become the de facto mainstream architecture, its capability under low-resource conditions has not been fully investigated yet. Our experiments on different subsets of the IWSLT14 training data show that the effectiveness of Transformer under low-resource conditions is highly dependent on the hyper-parameter settings. Our experiments show that using an optimized Transformer for low-resource conditions improves the translation quality up to 7.3 BLEU points compared to using the Transformer default settings.</abstract>
      <url hash="0420d08e">2020.coling-main.304</url>
    </paper>
    <paper id="305">
      <title>Mixup-Transformer: Dynamic Data Augmentation for <fixed-case>NLP</fixed-case> Tasks</title>
      <author><first>Lichao</first><last>Sun</last></author>
      <author><first>Congying</first><last>Xia</last></author>
      <author><first>Wenpeng</first><last>Yin</last></author>
      <author><first>Tingting</first><last>Liang</last></author>
      <author><first>Philip</first><last>Yu</last></author>
      <author><first>Lifang</first><last>He</last></author>
      <pages>3436–3440</pages>
      <abstract>Mixup is a latest data augmentation technique that linearly interpolates input examples and the corresponding labels. It has shown strong effectiveness in image classification by interpolating images at the pixel level. Inspired by this line of research, in this paper, we explore i) how to apply mixup to natural language processing tasks since text data can hardly be mixed in the raw format; ii) if mixup is still effective in transformer-based learning models,e.g., BERT.To achieve the goal, we incorporate mixup to transformer-based pre-trained architecture, named“mixup-transformer”, for a wide range of NLP tasks while keeping the whole end-to-end training system. We evaluate the proposed framework by running extensive experiments on the GLUEbenchmark. Furthermore, we also examine the performance of mixup-transformer in low-resource scenarios by reducing the training data with a certain ratio. Our studies show that mixup is a domain-independent data augmentation technique to pre-trained language models, resulting in significant performance improvement for transformer-based models.</abstract>
      <url hash="b30ddcc9">2020.coling-main.305</url>
    </paper>
    <paper id="306">
      <title>Handling Anomalies of Synthetic Questions in Unsupervised Question Answering</title>
      <author><first>Giwon</first><last>Hong</last></author>
      <author><first>Junmo</first><last>Kang</last></author>
      <author><first>Doyeon</first><last>Lim</last></author>
      <author><first>Sung-Hyon</first><last>Myaeng</last></author>
      <pages>3441–3448</pages>
      <abstract>Advances in Question Answering (QA) research require additional datasets for new domains, languages, and types of questions, as well as for performance increases. Human creation of a QA dataset like SQuAD, however, is expensive. As an alternative, an unsupervised QA approach has been proposed so that QA training data can be generated automatically. However, the performance of unsupervised QA is much lower than that of supervised QA models. We identify two anomalies in the automatically generated questions and propose how they can be mitigated. We show our approach helps improve unsupervised QA significantly across a number of QA tasks.</abstract>
      <url hash="4d0a06d6">2020.coling-main.306</url>
    </paper>
    <paper id="307">
      <title>Designing Templates for Eliciting Commonsense Knowledge from Pretrained Sequence-to-Sequence Models</title>
      <author><first>Jheng-Hong</first><last>Yang</last></author>
      <author><first>Sheng-Chieh</first><last>Lin</last></author>
      <author><first>Rodrigo</first><last>Nogueira</last></author>
      <author><first>Ming-Feng</first><last>Tsai</last></author>
      <author><first>Chuan-Ju</first><last>Wang</last></author>
      <author><first>Jimmy</first><last>Lin</last></author>
      <pages>3449–3453</pages>
      <abstract>While internalized “implicit knowledge” in pretrained transformers has led to fruitful progress in many natural language understanding tasks, how to most effectively elicit such knowledge remains an open question. Based on the text-to-text transfer transformer (T5) model, this work explores a template-based approach to extract implicit knowledge for commonsense reasoning on multiple-choice (MC) question answering tasks. Experiments on three representative MC datasets show the surprisingly good performance of our simple template, coupled with a logit normalization technique for disambiguation. Furthermore, we verify that our proposed template can be easily extended to other MC tasks with contexts such as supporting facts in open-book question answering settings. Starting from the MC task, this work initiates further research to find generic natural language templates that can effectively leverage stored knowledge in pretrained models.</abstract>
      <url hash="4844f2fc">2020.coling-main.307</url>
    </paper>
    <paper id="308">
      <title>Towards the First Machine Translation System for <fixed-case>S</fixed-case>umerian Transliterations</title>
      <author><first>Ravneet</first><last>Punia</last></author>
      <author><first>Niko</first><last>Schenk</last></author>
      <author><first>Christian</first><last>Chiarcos</last></author>
      <author><first>Émilie</first><last>Pagé-Perron</last></author>
      <pages>3454–3460</pages>
      <abstract>The Sumerian cuneiform script was invented more than 5,000 years ago and represents one of the oldest in history. We present the first attempt to translate Sumerian texts into English automatically. We publicly release high-quality corpora for standardized training and evaluation and report results on experiments with supervised, phrase-based, and transfer learning techniques for machine translation. Quantitative and qualitative evaluations indicate the usefulness of the translations. Our proposed methodology provides a broader audience of researchers with novel access to the data, accelerates the costly and time-consuming manual translation process, and helps them better explore the relationships between Sumerian cuneiform and Mesopotamian culture.</abstract>
      <url hash="3780e163">2020.coling-main.308</url>
    </paper>
    <paper id="309">
      <title>Using Bilingual Patents for Translation Training</title>
      <author><first>John</first><last>Lee</last></author>
      <author><first>Benjamin</first><last>Tsou</last></author>
      <author><first>Tianyuan</first><last>Cai</last></author>
      <pages>3461–3466</pages>
      <abstract>While bilingual corpora have been instrumental for machine translation, their utility for training translators has been less explored. We investigate the use of bilingual corpora as pedagogical tools for translation in the technical domain. In a user study, novice translators revised Chinese translations of English patents through bilingual concordancing. Results show that concordancing with an in-domain bilingual corpus can yield greater improvement in translation quality of technical terms than a general-domain bilingual corpus.</abstract>
      <url hash="12ccc4cc">2020.coling-main.309</url>
    </paper>
    <paper id="310">
      <title>Federated Learning for Spoken Language Understanding</title>
      <author><first>Zhiqi</first><last>Huang</last></author>
      <author><first>Fenglin</first><last>Liu</last></author>
      <author><first>Yuexian</first><last>Zou</last></author>
      <pages>3467–3478</pages>
      <abstract>Recently, spoken language understanding (SLU) has attracted extensive research interests, and various SLU datasets have been proposed to promote the development. However, most of the existing methods focus on a single individual dataset, the efforts to improve the robustness of models and obtain better performance by combining the merits of various datasets are not well studied. In this paper, we argue that if these SLU datasets are considered together, different knowledge from different datasets could be learned jointly, and there are high chances to promote the performance of each dataset. At the same time, we further attempt to prevent data leakage when unifying multiple datasets which, arguably, is more useful in an industry setting. To this end, we propose a federated learning framework, which could unify various types of datasets as well as tasks to learn and fuse various types of knowledge, i.e., text representations, from different datasets and tasks, without the sharing of downstream task data. The fused text representations merge useful features from different SLU datasets and tasks and are thus much more powerful than the original text representations alone in individual tasks. At last, in order to provide multi-granularity text representations for our framework, we propose a novel Multi-view Encoder (MV-Encoder) as the backbone of our federated learning framework. Experiments on two SLU benchmark datasets, including two tasks (intention detection and slot filling) and federated learning settings (horizontal federated learning, vertical federated learning and federated transfer learning), demonstrate the effectiveness and universality of our approach. Specifically, we are able to get 1.53% improvement on the intent detection metric accuracy. And we could also boost the performance of a strong baseline by up to 5.29% on the slot filling metric F1. Furthermore, by leveraging BERT as an additional encoder, we establish new state-of-the-art results on SNIPS and ATIS datasets, where we get 99.33% and 98.28% in terms of accuracy on intent detection task as well as 97.20% and 96.41% in terms of F1 score on slot filling task, respectively.</abstract>
      <url hash="ef433e49">2020.coling-main.310</url>
    </paper>
    <paper id="311">
      <title>Attentively Embracing Noise for Robust Latent Representation in <fixed-case>BERT</fixed-case></title>
      <author><first>Gwenaelle</first><last>Cunha Sergio</last></author>
      <author><first>Dennis Singh</first><last>Moirangthem</last></author>
      <author><first>Minho</first><last>Lee</last></author>
      <pages>3479–3491</pages>
      <abstract>Modern digital personal assistants interact with users through voice. Therefore, they heavily rely on automatic speech recognition (ASR) in order to convert speech to text and perform further tasks. We introduce EBERT, which stands for EmbraceBERT, with the goal of extracting more robust latent representations for the task of noisy ASR text classification. Conventionally, BERT is fine-tuned for downstream classification tasks using only the [CLS] starter token, with the remaining tokens being discarded. We propose using all encoded transformer tokens and further encode them using a novel attentive embracement layer and multi-head attention layer. This approach uses the otherwise discarded tokens as a source of additional information and the multi-head attention in conjunction with the attentive embracement layer to select important features from clean data during training. This allows for the extraction of a robust latent vector resulting in improved classification performance during testing when presented with noisy inputs. We show the impact of our model on both the Chatbot and Snips corpora for intent classification with ASR error. Results, in terms of F1-score and mean between 10 runs, show that our model significantly outperforms the baseline model.</abstract>
      <url hash="adb49cf2">2020.coling-main.311</url>
    </paper>
    <paper id="312">
      <title>A Comprehensive Evaluation of Incremental Speech Recognition and Diarization for Conversational <fixed-case>AI</fixed-case></title>
      <author><first>Angus</first><last>Addlesee</last></author>
      <author><first>Yanchao</first><last>Yu</last></author>
      <author><first>Arash</first><last>Eshghi</last></author>
      <pages>3492–3503</pages>
      <abstract>Automatic Speech Recognition (ASR) systems are increasingly powerful and more accurate, but also more numerous with several options existing currently as a service (e.g. Google, IBM, and Microsoft). Currently the most stringent standards for such systems are set within the context of their use in, and for, Conversational AI technology. These systems are expected to operate incrementally in real-time, be responsive, stable, and robust to the pervasive yet peculiar characteristics of conversational speech such as disfluencies and overlaps. In this paper we evaluate the most popular of such systems with metrics and experiments designed with these standards in mind. We also evaluate the speaker diarization (SD) capabilities of the same systems which will be particularly important for dialogue systems designed to handle multi-party interaction. We found that Microsoft has the leading incremental ASR system which preserves disfluent materials and IBM has the leading incremental SD system in addition to the ASR that is most robust to speech overlaps. Google strikes a balance between the two but none of these systems are yet suitable to reliably handle natural spontaneous conversations in real-time.</abstract>
      <url hash="7cc37337">2020.coling-main.312</url>
    </paper>
    <paper id="313">
      <title>Decolonising Speech and Language Technology</title>
      <author><first>Steven</first><last>Bird</last></author>
      <pages>3504–3519</pages>
      <abstract>After generations of exploitation, Indigenous people often respond negatively to the idea that their languages are data ready for the taking. By treating Indigenous knowledge as a commodity, speech and language technologists risk disenfranchising local knowledge authorities, reenacting the causes of language endangerment. Scholars in related fields have responded to calls for decolonisation, and we in the speech and language technology community need to follow suit, and explore what this means for our practices that involve Indigenous languages and the communities who own them. This paper reviews colonising discourses in speech and language technology, and suggests new ways of working with Indigenous communities, and seeks to open a discussion of a postcolonial approach to computational methods for supporting language vitality.</abstract>
      <url hash="e5bb639f">2020.coling-main.313</url>
    </paper>
    <paper id="314">
      <title>Dual-decoder Transformer for Joint Automatic Speech Recognition and Multilingual Speech Translation</title>
      <author><first>Hang</first><last>Le</last></author>
      <author><first>Juan</first><last>Pino</last></author>
      <author><first>Changhan</first><last>Wang</last></author>
      <author><first>Jiatao</first><last>Gu</last></author>
      <author><first>Didier</first><last>Schwab</last></author>
      <author><first>Laurent</first><last>Besacier</last></author>
      <pages>3520–3533</pages>
      <abstract>We introduce dual-decoder Transformer, a new model architecture that jointly performs automatic speech recognition (ASR) and multilingual speech translation (ST). Our models are based on the original Transformer architecture (Vaswani et al., 2017) but consist of two decoders, each responsible for one task (ASR or ST). Our major contribution lies in how these decoders interact with each other: one decoder can attend to different information sources from the other via a dual-attention mechanism. We propose two variants of these architectures corresponding to two different levels of dependencies between the decoders, called the parallel and cross dual-decoder Transformers, respectively. Extensive experiments on the MuST-C dataset show that our models outperform the previously-reported highest translation performance in the multilingual settings, and outperform as well bilingual one-to-one results. Furthermore, our parallel models demonstrate no trade-off between ASR and ST compared to the vanilla multi-task architecture. Our code and pre-trained models are available at https://github.com/formiel/speech-translation.</abstract>
      <url hash="66494499">2020.coling-main.314</url>
    </paper>
    <paper id="315">
      <title>Multitask Learning-Based Neural Bridging Reference Resolution</title>
      <author><first>Juntao</first><last>Yu</last></author>
      <author><first>Massimo</first><last>Poesio</last></author>
      <pages>3534–3546</pages>
      <abstract>We propose a multi task learning-based neural model for resolving bridging references tackling two key challenges. The first challenge is the lack of large corpora annotated with bridging references. To address this, we use multi-task learning to help bridging reference resolution with coreference resolution. We show that substantial improvements of up to 8 p.p. can be achieved on full bridging resolution with this architecture. The second challenge is the different definitions of bridging used in different corpora, meaning that hand-coded systems or systems using special features designed for one corpus do not work well with other corpora. Our neural model only uses a small number of corpus independent features, thus can be applied to different corpora. Evaluations with very different bridging corpora (ARRAU, ISNOTES, BASHI and SCICORP) suggest that our architecture works equally well on all corpora, and achieves the SoTA results on full bridging resolution for all corpora, outperforming the best reported results by up to 36.3 p.p..</abstract>
      <url hash="6f1b6a65">2020.coling-main.315</url>
    </paper>
    <paper id="316">
      <title>Improving Human-Labeled Data through Dynamic Automatic Conflict Resolution</title>
      <author><first>David Q.</first><last>Sun</last></author>
      <author><first>Hadas</first><last>Kotek</last></author>
      <author><first>Christopher</first><last>Klein</last></author>
      <author><first>Mayank</first><last>Gupta</last></author>
      <author><first>William</first><last>Li</last></author>
      <author><first>Jason D.</first><last>Williams</last></author>
      <pages>3547–3557</pages>
      <abstract>This paper develops and implements a scalable methodology for (a) estimating the noisiness of labels produced by a typical crowdsourcing semantic annotation task, and (b) reducing the resulting error of the labeling process by as much as 20-30% in comparison to other common labeling strategies. Importantly, this new approach to the labeling process, which we name Dynamic Automatic Conflict Resolution (DACR), does not require a ground truth dataset and is instead based on inter-project annotation inconsistencies. This makes DACR not only more accurate but also available to a broad range of labeling tasks. In what follows we present results from a text classification task performed at scale for a commercial personal assistant, and evaluate the inherent ambiguity uncovered by this annotation strategy as compared to other common labeling strategies.</abstract>
      <url hash="267e2b91">2020.coling-main.316</url>
    </paper>
    <paper id="317">
      <title>Automatic Discovery of Heterogeneous Machine Learning Pipelines: An Application to Natural Language Processing</title>
      <author><first>Suilan</first><last>Estevez-Velarde</last></author>
      <author><first>Yoan</first><last>Gutiérrez</last></author>
      <author><first>Andres</first><last>Montoyo</last></author>
      <author><first>Yudivián</first><last>Almeida Cruz</last></author>
      <pages>3558–3568</pages>
      <abstract>This paper presents AutoGOAL, a system for automatic machine learning (AutoML) that uses heterogeneous techniques. In contrast with existing AutoML approaches, our contribution can automatically build machine learning pipelines that combine techniques and algorithms from different frameworks, including shallow classifiers, natural language processing tools, and neural networks. We define the heterogeneous AutoML optimization problem as the search for the best sequence of algorithms that transforms specific input data into the desired output. This provides a novel theoretical and practical approach to AutoML. Our proposal is experimentally evaluated in diverse machine learning problems and compared with alternative approaches, showing that it is competitive with other AutoML alternatives in standard benchmarks. Furthermore, it can be applied to novel scenarios, such as several NLP tasks, where existing alternatives cannot be directly deployed. The system is freely available and includes in-built compatibility with a large number of popular machine learning frameworks, which makes our approach useful for solving practical problems with relative ease and effort.</abstract>
      <url hash="d3b40df7">2020.coling-main.317</url>
    </paper>
    <paper id="318">
      <title>Distill and Replay for Continual Language Learning</title>
      <author><first>Jingyuan</first><last>Sun</last></author>
      <author><first>Shaonan</first><last>Wang</last></author>
      <author><first>Jiajun</first><last>Zhang</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <pages>3569–3579</pages>
      <abstract>Accumulating knowledge to tackle new tasks without necessarily forgetting the old ones is a hallmark of human-like intelligence. But the current dominant paradigm of machine learning is still to train a model that works well on static datasets. When learning tasks in a stream where data distribution may fluctuate, fitting on new tasks often leads to forgetting on the previous ones. We propose a simple yet effective framework that continually learns natural language understanding tasks with one model. Our framework distills knowledge and replays experience from previous tasks when fitting on a new task, thus named DnR (distill and replay). The framework is based on language models and can be smoothly built with different language model architectures. Experimental results demonstrate that DnR outperfoms previous state-of-the-art models in continually learning tasks of the same type but from different domains, as well as tasks of different types. With the distillation method, we further show that it’s possible for DnR to incrementally compress the model size while still outperforming most of the baselines. We hope that DnR could promote the empirical application of continual language learning, and contribute to building human-level language intelligence minimally bothered by catastrophic forgetting.</abstract>
      <url hash="1b6d17ad">2020.coling-main.318</url>
    </paper>
    <paper id="319">
      <title>Incorporating Noisy Length Constraints into Transformer with Length-aware Positional Encodings</title>
      <author><first>Yui</first><last>Oka</last></author>
      <author><first>Katsuki</first><last>Chousa</last></author>
      <author><first>Katsuhito</first><last>Sudoh</last></author>
      <author><first>Satoshi</first><last>Nakamura</last></author>
      <pages>3580–3585</pages>
      <abstract>Neural Machine Translation often suffers from an under-translation problem due to its limited modeling of output sequence lengths. In this work, we propose a novel approach to training a Transformer model using length constraints based on length-aware positional encoding (PE). Since length constraints with exact target sentence lengths degrade translation performance, we add random noise within a certain window size to the length constraints in the PE during the training. In the inference step, we predict the output lengths using input sequences and a BERT-based length prediction model. Experimental results in an ASPEC English-to-Japanese translation showed the proposed method produced translations with lengths close to the reference ones and outperformed a vanilla Transformer (especially in short sentences) by 3.22 points in BLEU. The average translation results using our length prediction model were also better than another baseline method using input lengths for the length constraints. The proposed noise injection improved robustness for length prediction errors, especially within the window size.</abstract>
      <url hash="64bdf0c8">2020.coling-main.319</url>
    </paper>
    <paper id="320">
      <title>Rethinking Skip Connection with Layer Normalization</title>
      <author><first>Fenglin</first><last>Liu</last></author>
      <author><first>Xuancheng</first><last>Ren</last></author>
      <author><first>Zhiyuan</first><last>Zhang</last></author>
      <author><first>Xu</first><last>Sun</last></author>
      <author><first>Yuexian</first><last>Zou</last></author>
      <pages>3586–3598</pages>
      <abstract>Skip connection is a widely-used technique to improve the performance and the convergence of deep neural networks, which is believed to relieve the difficulty in optimization due to non-linearity by propagating a linear component through the neural network layers. However, from another point of view, it can also be seen as a modulating mechanism between the input and the output, with the input scaled by a pre-defined value one. In this work, we investigate how the scale factors in the effectiveness of the skip connection and reveal that a trivial adjustment of the scale will lead to spurious gradient exploding or vanishing in line with the deepness of the models, which could by addressed by normalization, in particular, layer normalization, which induces consistent improvements over the plain skip connection. Inspired by the findings, we further propose to adaptively adjust the scale of the input by recursively applying skip connection with layer normalization, which promotes the performance substantially and generalizes well across diverse tasks including both machine translation and image classification datasets.</abstract>
      <url hash="bee21bd6">2020.coling-main.320</url>
    </paper>
    <paper id="321">
      <title>Specializing Word Vectors by Spectral Decomposition on Heterogeneously Twisted Graphs</title>
      <author><first>Yuanhang</first><last>Ren</last></author>
      <author><first>Ye</first><last>Du</last></author>
      <pages>3599–3609</pages>
      <abstract>Traditional word vectors, such as word2vec and glove, have a well-known inclination to conflate the semantic similarity with other semantic relations. A retrofitting procedure may be needed to solve this issue. In this work, we propose a new retrofitting method called Heterogeneously Retrofitted Spectral Word Embedding. It heterogeneously twists the similarity matrix of word pairs with lexical constraints. A new set of word vectors is generated by a spectral decomposition of the similarity matrix, which has a linear algebraic analytic form. Our method has a competitive performance compared with the state-of-the-art retrofitting method such as AR (CITATION). In addition, since our embedding has a clear linear algebraic relationship with the similarity matrix, we carefully study the contribution of each component in our model. Last but not least, our method is very efficient to execute.</abstract>
      <url hash="200ca932">2020.coling-main.321</url>
    </paper>
    <paper id="322">
      <title>Deep Inside-outside Recursive Autoencoder with All-span Objective</title>
      <author><first>Ruyue</first><last>Hong</last></author>
      <author><first>Jiong</first><last>Cai</last></author>
      <author><first>Kewei</first><last>Tu</last></author>
      <pages>3610–3615</pages>
      <abstract>Deep inside-outside recursive autoencoder (DIORA) is a neural-based model designed for unsupervised constituency parsing. During its forward computation, it provides phrase and contextual representations for all spans in the input sentence. By utilizing the contextual representation of each leaf-level span, the span of length 1, to reconstruct the word inside the span, the model is trained without labeled data. In this work, we extend the training objective of DIORA by making use of all spans instead of only leaf-level spans. We test our new training objective on datasets of two languages: English and Japanese, and empirically show that our method achieves improvement in parsing accuracy over the original DIORA.</abstract>
      <url hash="1cb24d50">2020.coling-main.322</url>
    </paper>
    <paper id="323">
      <title>Cross-Lingual Document Retrieval with Smooth Learning</title>
      <author><first>Jiapeng</first><last>Liu</last></author>
      <author><first>Xiao</first><last>Zhang</last></author>
      <author><first>Dan</first><last>Goldwasser</last></author>
      <author><first>Xiao</first><last>Wang</last></author>
      <pages>3616–3629</pages>
      <abstract>Cross-lingual document search is an information retrieval task in which the queries’ language and the documents’ language are different. In this paper, we study the instability of neural document search models and propose a novel end-to-end robust framework that achieves improved performance in cross-lingual search with different documents’ languages. This framework includes a novel measure of the relevance, smooth cosine similarity, between queries and documents, and a novel loss function, Smooth Ordinal Search Loss, as the objective function. We further provide theoretical guarantee on the generalization error bound for the proposed framework. We conduct experiments to compare our approach with other document search models, and observe significant gains under commonly used ranking metrics on the cross-lingual document retrieval task in a variety of languages.</abstract>
      <url hash="edcd7df6">2020.coling-main.323</url>
    </paper>
    <paper id="324">
      <title>Increasing Learning Efficiency of Self-Attention Networks through Direct Position Interactions, Learnable Temperature, and Convoluted Attention</title>
      <author><first>Philipp</first><last>Dufter</last></author>
      <author><first>Martin</first><last>Schmitt</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>3630–3636</pages>
      <abstract>Self-Attention Networks (SANs) are an integral part of successful neural architectures such as Transformer (Vaswani et al., 2017), and thus of pretrained language models such as BERT (Devlin et al., 2019) or GPT-3 (Brown et al., 2020). Training SANs on a task or pretraining them on language modeling requires large amounts of data and compute resources. We are searching for modifications to SANs that enable faster learning, i.e., higher accuracies after fewer update steps. We investigate three modifications to SANs: direct position interactions, learnable temperature, and convoluted attention. When evaluating them on part-of-speech tagging, we find that direct position interactions are an alternative to position embeddings, and convoluted attention has the potential to speed up the learning process.</abstract>
      <url hash="1a4a1834">2020.coling-main.324</url>
    </paper>
    <paper id="325">
      <title>Picking <fixed-case>BERT</fixed-case>’s Brain: Probing for Linguistic Dependencies in Contextualized Embeddings Using Representational Similarity Analysis</title>
      <author><first>Michael</first><last>Lepori</last></author>
      <author><first>R. Thomas</first><last>McCoy</last></author>
      <pages>3637–3651</pages>
      <abstract>As the name implies, contextualized representations of language are typically motivated by their ability to encode context. Which aspects of context are captured by such representations? We introduce an approach to address this question using Representational Similarity Analysis (RSA). As case studies, we investigate the degree to which a verb embedding encodes the verb’s subject, a pronoun embedding encodes the pronoun’s antecedent, and a full-sentence representation encodes the sentence’s head word (as determined by a dependency parse). In all cases, we show that BERT’s contextualized embeddings reflect the linguistic dependency being studied, and that BERT encodes these dependencies to a greater degree than it encodes less linguistically-salient controls. These results demonstrate the ability of our approach to adjudicate between hypotheses about which aspects of context are encoded in representations of language.</abstract>
      <url hash="be244c3d">2020.coling-main.325</url>
    </paper>
    <paper id="326">
      <title>The Devil is in the Details: Evaluating Limitations of Transformer-based Methods for Granular Tasks</title>
      <author><first>Brihi</first><last>Joshi</last></author>
      <author><first>Neil</first><last>Shah</last></author>
      <author><first>Francesco</first><last>Barbieri</last></author>
      <author><first>Leonardo</first><last>Neves</last></author>
      <pages>3652–3659</pages>
      <abstract>Contextual embeddings derived from transformer-based neural language models have shown state-of-the-art performance for various tasks such as question answering, sentiment analysis, and textual similarity in recent years. Extensive work shows how accurately such models can represent abstract, semantic information present in text. In this expository work, we explore a tangent direction and analyze such models’ performance on tasks that require a more granular level of representation. We focus on the problem of textual similarity from two perspectives: matching documents on a granular level (requiring embeddings to capture fine-grained attributes in the text), and an abstract level (requiring embeddings to capture overall textual semantics). We empirically demonstrate, across two datasets from different domains, that despite high performance in abstract document matching as expected, contextual embeddings are consistently (and at times, vastly) outperformed by simple baselines like TF-IDF for more granular tasks. We then propose a simple but effective method to incorporate TF-IDF into models that use contextual embeddings, achieving relative improvements of up to 36% on granular tasks.</abstract>
      <url hash="916a8087">2020.coling-main.326</url>
    </paper>
    <paper id="327">
      <title><fixed-case>C</fixed-case>o<fixed-case>LAKE</fixed-case>: Contextualized Language and Knowledge Embedding</title>
      <author><first>Tianxiang</first><last>Sun</last></author>
      <author><first>Yunfan</first><last>Shao</last></author>
      <author><first>Xipeng</first><last>Qiu</last></author>
      <author><first>Qipeng</first><last>Guo</last></author>
      <author><first>Yaru</first><last>Hu</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <author><first>Zheng</first><last>Zhang</last></author>
      <pages>3660–3670</pages>
      <abstract>With the emerging branch of incorporating factual knowledge into pre-trained language models such as BERT, most existing models consider shallow, static, and separately pre-trained entity embeddings, which limits the performance gains of these models. Few works explore the potential of deep contextualized knowledge representation when injecting knowledge. In this paper, we propose the Contextualized Language and Knowledge Embedding (CoLAKE), which jointly learns contextualized representation for both language and knowledge with the extended MLM objective. Instead of injecting only entity embeddings, CoLAKE extracts the knowledge context of an entity from large-scale knowledge bases. To handle the heterogeneity of knowledge context and language context, we integrate them in a unified data structure, word-knowledge graph (WK graph). CoLAKE is pre-trained on large-scale WK graphs with the modified Transformer encoder. We conduct experiments on knowledge-driven tasks, knowledge probing tasks, and language understanding tasks. Experimental results show that CoLAKE outperforms previous counterparts on most of the tasks. Besides, CoLAKE achieves surprisingly high performance on our synthetic task called word-knowledge graph completion, which shows the superiority of simultaneously contextualizing language and knowledge representation.</abstract>
      <url hash="8a4bcb0a">2020.coling-main.327</url>
    </paper>
    <paper id="328">
      <title>Invertible Tree Embeddings using a Cryptographic Role Embedding Scheme</title>
      <author><first>Coleman</first><last>Haley</last></author>
      <author><first>Paul</first><last>Smolensky</last></author>
      <pages>3671–3683</pages>
      <abstract>We present a novel method for embedding trees in a vector space based on Tensor-Product Representations (TPRs) which allows for inversion: the retrieval of the original tree structure and nodes from the vectorial embedding. Unlike previous attempts, this does not come at the cost of intractable representation size; we utilize a method for non-exact inversion, showing that it works well when there is sufficient randomness in the representation scheme for simple data and providing an upper bound on its error. To handle the huge number of possible tree positions without memoizing position representation vectors, we present a method (Cryptographic Role Embedding) using cryptographic hashing algorithms that allows for the representation of unboundedly many positions. Through experiments on parse tree data, we show a 30,000-dimensional Cryptographic Role Embedding of trees can provide invertibility with error &lt; 1% that previous methods would require 8.6 × 1057 dimensions to represent.</abstract>
      <url hash="8bc4496d">2020.coling-main.328</url>
    </paper>
    <paper id="329">
      <title>Synonym Knowledge Enhanced Reader for <fixed-case>C</fixed-case>hinese Idiom Reading Comprehension</title>
      <author><first>Siyu</first><last>Long</last></author>
      <author><first>Ran</first><last>Wang</last></author>
      <author><first>Kun</first><last>Tao</last></author>
      <author><first>Jiali</first><last>Zeng</last></author>
      <author><first>Xinyu</first><last>Dai</last></author>
      <pages>3684–3695</pages>
      <abstract>Machine reading comprehension (MRC) is the task that asks a machine to answer questions based on a given context. For Chinese MRC, due to the non-literal and non-compositional semantic characteristics, Chinese idioms pose unique challenges for machines to understand. Previous studies tend to treat idioms separately without fully exploiting the relationship among them. In this paper, we first define the concept of literal meaning coverage to measure the consistency between semantics and literal meanings for Chinese idioms. With the definition, we prove that the literal meanings of many idioms are far from their semantics, and we also verify that the synonymic relationship can mitigate this inconsistency, which would be beneficial for idiom comprehension. Furthermore, to fully utilize the synonymic relationship, we propose the synonym knowledge enhanced reader. Specifically, for each idiom, we first construct a synonym graph according to the annotations from the high-quality synonym dictionary or the cosine similarity between the pre-trained idiom embeddings and then incorporate the graph attention network and gate mechanism to encode the graph. Experimental results on ChID, a large-scale Chinese idiom reading comprehension dataset, show that our model achieves state-of-the-art performance.</abstract>
      <url hash="26a2b26f">2020.coling-main.329</url>
    </paper>
    <paper id="330">
      <title>Target Word Masking for Location Metonymy Resolution</title>
      <author><first>Haonan</first><last>Li</last></author>
      <author><first>Maria</first><last>Vasardani</last></author>
      <author><first>Martin</first><last>Tomko</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <pages>3696–3707</pages>
      <abstract>Existing metonymy resolution approaches rely on features extracted from external resources like dictionaries and hand-crafted lexical resources. In this paper, we propose an end-to-end word-level classification approach based only on BERT, without dependencies on taggers, parsers, curated dictionaries of place names, or other external resources. We show that our approach achieves the state-of-the-art on 5 datasets, surpassing conventional BERT models and benchmarks by a large margin. We also show that our approach generalises well to unseen data.</abstract>
      <url hash="e7833d8a">2020.coling-main.330</url>
    </paper>
    <paper id="331">
      <title>Bridging Resolution: A Survey of the State of the Art</title>
      <author><first>Hideo</first><last>Kobayashi</last></author>
      <author><first>Vincent</first><last>Ng</last></author>
      <pages>3708–3721</pages>
      <abstract>Bridging reference resolution is an anaphora resolution task that is arguably more challenging and less studied than entity coreference resolution. Given that significant progress has been made on coreference resolution in recent years, we believe that bridging resolution will receive increasing attention in the NLP community. Nevertheless, progress on bridging resolution is currently hampered in part by the scarcity of large annotated corpora for model training as well as the lack of standardized evaluation protocols. This paper presents a survey of the current state of research on bridging reference resolution and discusses future research directions.</abstract>
      <url hash="347fb2e4">2020.coling-main.331</url>
    </paper>
    <paper id="332">
      <title>An analysis of language models for metaphor recognition</title>
      <author><first>Arthur</first><last>Neidlein</last></author>
      <author><first>Philip</first><last>Wiesenbach</last></author>
      <author><first>Katja</first><last>Markert</last></author>
      <pages>3722–3736</pages>
      <abstract>We conduct a linguistic analysis of recent metaphor recognition systems, all of which are based on language models. We show that their performance, although reaching high F-scores, has considerable gaps from a linguistic perspective. First, they perform substantially worse on unconventional metaphors than on conventional ones. Second, they struggle with handling rarer word types. These two findings together suggest that a large part of the systems’ success is due to optimising the disambiguation of conventionalised, metaphoric word senses for specific words instead of modelling general properties of metaphors. As a positive result, the systems show increasing capabilities to recognise metaphoric readings of unseen words if synonyms or morphological variations of these words have been seen before, leading to enhanced generalisation beyond word sense disambiguation.</abstract>
      <url hash="7ffa5d46">2020.coling-main.332</url>
    </paper>
    <paper id="333">
      <title>What Meaning-Form Correlation Has to Compose With: A Study of <fixed-case>MFC</fixed-case> on Artificial and Natural Language</title>
      <author><first>Timothee</first><last>Mickus</last></author>
      <author><first>Timothée</first><last>Bernard</last></author>
      <author><first>Denis</first><last>Paperno</last></author>
      <pages>3737–3749</pages>
      <abstract>Compositionality is a widely discussed property of natural languages, although its exact definition has been elusive. We focus on the proposal that compositionality can be assessed by measuring meaning-form correlation. We analyze meaning-form correlation on three sets of languages: (i) artificial toy languages tailored to be compositional, (ii) a set of English dictionary definitions, and (iii) a set of English sentences drawn from literature. We find that linguistic phenomena such as synonymy and ungrounded stop-words weigh on MFC measurements, and that straightforward methods to mitigate their effects have widely varying results depending on the dataset they are applied to. Data and code are made publicly available.</abstract>
      <url hash="2000947e">2020.coling-main.333</url>
    </paper>
    <paper id="334">
      <title>Evaluating Pretrained Transformer-based Models on the Task of Fine-Grained Named Entity Recognition</title>
      <author><first>Cedric</first><last>Lothritz</last></author>
      <author><first>Kevin</first><last>Allix</last></author>
      <author><first>Lisa</first><last>Veiber</last></author>
      <author><first>Tegawendé F.</first><last>Bissyandé</last></author>
      <author><first>Jacques</first><last>Klein</last></author>
      <pages>3750–3760</pages>
      <abstract>Named Entity Recognition (NER) is a fundamental Natural Language Processing (NLP) task and has remained an active research field. In recent years, transformer models and more specifically the BERT model developed at Google revolutionised the field of NLP. While the performance of transformer-based approaches such as BERT has been studied for NER, there has not yet been a study for the fine-grained Named Entity Recognition (FG-NER) task. In this paper, we compare three transformer-based models (BERT, RoBERTa, and XLNet) to two non-transformer-based models (CRF and BiLSTM-CNN-CRF). Furthermore, we apply each model to a multitude of distinct domains. We find that transformer-based models incrementally outperform the studied non-transformer-based models in most domains with respect to the F1 score. Furthermore, we find that the choice of domains significantly influenced the performance regardless of the respective data size or the model chosen.</abstract>
      <url hash="2eef7da9">2020.coling-main.334</url>
    </paper>
    <paper id="335">
      <title>Seeing Both the Forest and the Trees: Multi-head Attention for Joint Classification on Different Compositional Levels</title>
      <author><first>Miruna</first><last>Pislar</last></author>
      <author><first>Marek</first><last>Rei</last></author>
      <pages>3761–3775</pages>
      <abstract>In natural languages, words are used in association to construct sentences. It is not words in isolation, but the appropriate use of hierarchical structures that conveys the meaning of the whole sentence. Neural networks have the ability to capture expressive language features; however, insights into the link between words and sentences are difficult to acquire automatically. In this work, we design a deep neural network architecture that explicitly wires lower and higher linguistic components; we then evaluate its ability to perform the same task at different hierarchical levels. Settling on broad text classification tasks, we show that our model, MHAL, learns to simultaneously solve them at different levels of granularity by fluidly transferring knowledge between hierarchies. Using a multi-head attention mechanism to tie the representations between single words and full sentences, MHAL systematically outperforms equivalent models that are not incentivized towards developing compositional representations. Moreover, we demonstrate that, with the proposed architecture, the sentence information flows naturally to individual words, allowing the model to behave like a sequence labeler (which is a lower, word-level task) even without any word supervision, in a zero-shot fashion.</abstract>
      <url hash="6945dc14">2020.coling-main.335</url>
    </paper>
    <paper id="336">
      <title>A Unifying Theory of Transition-based and Sequence Labeling Parsing</title>
      <author><first>Carlos</first><last>Gómez-Rodríguez</last></author>
      <author><first>Michalina</first><last>Strzyz</last></author>
      <author><first>David</first><last>Vilares</last></author>
      <pages>3776–3793</pages>
      <abstract>We define a mapping from transition-based parsing algorithms that read sentences from left to right to sequence labeling encodings of syntactic trees. This not only establishes a theoretical relation between transition-based parsing and sequence-labeling parsing, but also provides a method to obtain new encodings for fast and simple sequence labeling parsing from the many existing transition-based parsers for different formalisms. Applying it to dependency parsing, we implement sequence labeling versions of four algorithms, showing that they are learnable and obtain comparable performance to existing encodings.</abstract>
      <url hash="e0de3919">2020.coling-main.336</url>
    </paper>
    <paper id="337">
      <title>Unleashing the Power of Neural Discourse Parsers - A Context and Structure Aware Approach Using Large Scale Pretraining</title>
      <author><first>Grigorii</first><last>Guz</last></author>
      <author><first>Patrick</first><last>Huber</last></author>
      <author><first>Giuseppe</first><last>Carenini</last></author>
      <pages>3794–3805</pages>
      <abstract>RST-based discourse parsing is an important NLP task with numerous downstream applications, such as summarization, machine translation and opinion mining. In this paper, we demonstrate a simple, yet highly accurate discourse parser, incorporating recent contextual language models. Our parser establishes the new state-of-the-art (SOTA) performance for predicting structure and nuclearity on two key RST datasets, RST-DT and Instr-DT. We further demonstrate that pretraining our parser on the recently available large-scale “silver-standard” discourse treebank MEGA-DT provides even larger performance benefits, suggesting a novel and promising research direction in the field of discourse analysis.</abstract>
      <url hash="4d8953b1">2020.coling-main.337</url>
    </paper>
    <paper id="338">
      <title>Semi-supervised Domain Adaptation for Dependency Parsing via Improved Contextualized Word Representations</title>
      <author><first>Ying</first><last>Li</last></author>
      <author><first>Zhenghua</first><last>Li</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>3806–3817</pages>
      <abstract>In recent years, parsing performance is dramatically improved on in-domain texts thanks to the rapid progress of deep neural network models. The major challenge for current parsing research is to improve parsing performance on out-of-domain texts that are very different from the in-domain training data when there is only a small-scale out-domain labeled data. To deal with this problem, we propose to improve the contextualized word representations via adversarial learning and fine-tuning BERT processes. Concretely, we apply adversarial learning to three representative semi-supervised domain adaption methods, i.e., direct concatenation (CON), feature augmentation (FA), and domain embedding (DE) with two useful strategies, i.e., fused target-domain word representations and orthogonality constraints, thus enabling to model more pure yet effective domain-specific and domain-invariant representations. Simultaneously, we utilize a large-scale target-domain unlabeled data to fine-tune BERT with only the language model loss, thus obtaining reliable contextualized word representations that benefit for the cross-domain dependency parsing. Experiments on a benchmark dataset show that our proposed adversarial approaches achieve consistent improvement, and fine-tuning BERT further boosts parsing accuracy by a large margin. Our single model achieves the same state-of-the-art performance as the top submitted system in the NLPCC-2019 shared task, which uses ensemble models and BERT.</abstract>
      <url hash="1f438093">2020.coling-main.338</url>
    </paper>
    <paper id="339">
      <title>Data Augmentation via Subtree Swapping for Dependency Parsing of Low-Resource Languages</title>
      <author><first>Mathieu</first><last>Dehouck</last></author>
      <author><first>Carlos</first><last>Gómez-Rodríguez</last></author>
      <pages>3818–3830</pages>
      <abstract>The lack of annotated data is a big issue for building reliable NLP systems for most of the world’s languages. But this problem can be alleviated by automatic data generation. In this paper, we present a new data augmentation method for artificially creating new dependency-annotated sentences. The main idea is to swap subtrees between annotated sentences while enforcing strong constraints on those trees to ensure maximal grammaticality of the new sentences. We also propose a method to perform low-resource experiments using resource-rich languages by mimicking low-resource languages by sampling sentences under a low-resource distribution. In a series of experiments, we show that our newly proposed data augmentation method outperforms previous proposals using the same basic inputs.</abstract>
      <url hash="6650f16e">2020.coling-main.339</url>
    </paper>
    <paper id="340">
      <title>Porous Lattice Transformer Encoder for <fixed-case>C</fixed-case>hinese <fixed-case>NER</fixed-case></title>
      <author><first>Xue</first><last>Mengge</last></author>
      <author><first>Bowen</first><last>Yu</last></author>
      <author><first>Tingwen</first><last>Liu</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <author><first>Erli</first><last>Meng</last></author>
      <author><first>Bin</first><last>Wang</last></author>
      <pages>3831–3841</pages>
      <abstract>Incorporating lexicons into character-level Chinese NER by lattices is proven effective to exploitrich word boundary information. Previous work has extended RNNs to consume lattice inputsand achieved great success. However, due to the DAG structure and the inherently unidirectionalsequential nature, this method precludes batched computation and sufficient semantic interaction.In this paper, we propose PLTE, an extension of transformer encoder that is tailored for ChineseNER, which models all the characters and matched lexical words in parallel with batch process-ing. PLTE augments self-attention with positional relation representations to incorporate latticestructure. It also introduces a porous mechanism to augment localness modeling and maintainthe strength of capturing the rich long-term dependencies. Experimental results show that PLTEperforms up to 11.4 times faster than state-of-the-art methods while realizing better performance.We also demonstrate that using BERT representations further substantially boosts the performanceand brings out the best in PLTE.</abstract>
      <url hash="77c1dfa0">2020.coling-main.340</url>
    </paper>
    <paper id="341">
      <title>Learning to Prune Dependency Trees with Rethinking for Neural Relation Extraction</title>
      <author><first>Bowen</first><last>Yu</last></author>
      <author><first>Xue</first><last>Mengge</last></author>
      <author><first>Zhenyu</first><last>Zhang</last></author>
      <author><first>Tingwen</first><last>Liu</last></author>
      <author><first>Wang</first><last>Yubin</last></author>
      <author><first>Bin</first><last>Wang</last></author>
      <pages>3842–3852</pages>
      <abstract>Dependency trees have been shown to be effective in capturing long-range relations between target entities. Nevertheless, how to selectively emphasize target-relevant information and remove irrelevant content from the tree is still an open problem. Existing approaches employing pre-defined rules to eliminate noise may not always yield optimal results due to the complexity and variability of natural language. In this paper, we present a novel architecture named Dynamically Pruned Graph Convolutional Network (DP-GCN), which learns to prune the dependency tree with rethinking in an end-to-end scheme. In each layer of DP-GCN, we employ a selection module to concentrate on nodes expressing the target relation by a set of binary gates, and then augment the pruned tree with a pruned semantic graph to ensure the connectivity. After that, we introduce a rethinking mechanism to guide and refine the pruning operation by feeding back the high-level learned features repeatedly. Extensive experimental results demonstrate that our model achieves impressive results compared to strong competitors.</abstract>
      <url hash="d6fbde07">2020.coling-main.341</url>
    </paper>
    <paper id="342">
      <title>How Far Does <fixed-case>BERT</fixed-case> Look At: Distance-based Clustering and Analysis of <fixed-case>BERT</fixed-case>’s Attention</title>
      <author><first>Yue</first><last>Guan</last></author>
      <author><first>Jingwen</first><last>Leng</last></author>
      <author><first>Chao</first><last>Li</last></author>
      <author><first>Quan</first><last>Chen</last></author>
      <author><first>Minyi</first><last>Guo</last></author>
      <pages>3853–3860</pages>
      <abstract>Recent research on the multi-head attention mechanism, especially that in pre-trained models such as BERT, has shown us heuristics and clues in analyzing various aspects of the mechanism. As most of the research focus on probing tasks or hidden states, previous works have found some primitive patterns of attention head behavior by heuristic analytical methods, but a more systematic analysis specific on the attention patterns still remains primitive. In this work, we clearly cluster the attention heatmaps into significantly different patterns through unsupervised clustering on top of a set of proposed features, which corroborates with previous observations. We further study their corresponding functions through analytical study. In addition, our proposed features can be used to explain and calibrate different attention heads in Transformer models.</abstract>
      <url hash="d3d385b2">2020.coling-main.342</url>
    </paper>
    <paper id="343">
      <title>An Analysis of Simple Data Augmentation for Named Entity Recognition</title>
      <author><first>Xiang</first><last>Dai</last></author>
      <author><first>Heike</first><last>Adel</last></author>
      <pages>3861–3867</pages>
      <abstract>Simple yet effective data augmentation techniques have been proposed for sentence-level and sentence-pair natural language processing tasks. Inspired by these efforts, we design and compare data augmentation for named entity recognition, which is usually modeled as a token-level sequence labeling problem. Through experiments on two data sets from the biomedical and materials science domains (i2b2-2010 and MaSciP), we show that simple augmentation can boost performance for both recurrent and transformer-based models, especially for small training sets.</abstract>
      <url hash="99d2ce5e">2020.coling-main.343</url>
    </paper>
    <paper id="344">
      <title>Semi-supervised Autoencoding Projective Dependency Parsing</title>
      <author><first>Xiao</first><last>Zhang</last></author>
      <author><first>Dan</first><last>Goldwasser</last></author>
      <pages>3868–3885</pages>
      <abstract>We describe two end-to-end autoencoding models for semi-supervised graph-based projective dependency parsing. The first model is a Locally Autoencoding Parser (LAP) encoding the input using continuous latent variables in a sequential manner; The second model is a Globally Autoencoding Parser (GAP) encoding the input into dependency trees as latent variables, with exact inference. Both models consist of two parts: an encoder enhanced by deep neural networks (DNN) that can utilize the contextual information to encode the input into latent variables, and a decoder which is a generative model able to reconstruct the input. Both LAP and GAP admit a unified structure with different loss functions for labeled and unlabeled data with shared parameters. We conducted experiments on WSJ and UD dependency parsing data sets, showing that our models can exploit the unlabeled data to improve the performance given a limited amount of labeled data, and outperform a previously proposed semi-supervised model.</abstract>
      <url hash="7f655de2">2020.coling-main.344</url>
    </paper>
    <paper id="345">
      <title>Towards Instance-Level Parser Selection for Cross-Lingual Transfer of Dependency Parsers</title>
      <author><first>Robert</first><last>Litschko</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Željko</first><last>Agić</last></author>
      <author><first>Goran</first><last>Glavaš</last></author>
      <pages>3886–3898</pages>
      <abstract>Current methods of cross-lingual parser transfer focus on predicting the best parser for a low-resource target language globally, that is, “at treebank level”. In this work, we propose and argue for a novel cross-lingual transfer paradigm: instance-level parser selection (ILPS), and present a proof-of-concept study focused on instance-level selection in the framework of delexicalized parser transfer. Our work is motivated by an empirical observation that different source parsers are the best choice for different Universal POS-sequences (i.e., UPOS sentences) in the target language. We then propose to predict the best parser at the instance level. To this end, we train a supervised regression model, based on the Transformer architecture, to predict parser accuracies for individual POS-sequences. We compare ILPS against two strong single-best parser selection baselines (SBPS): (1) a model that compares POS n-gram distributions between the source and target languages (KL) and (2) a model that selects the source based on the similarity between manually created language vectors encoding syntactic properties of languages (L2V). The results from our extensive evaluation, coupling 42 source parsers and 20 diverse low-resource test languages, show that ILPS outperforms KL and L2V on 13/20 and 14/20 test languages, respectively. Further, we show that by predicting the best parser “at treebank level” (SBPS), using the aggregation of predictions from our instance-level model, we outperform the same baselines on 17/20 and 16/20 test languages.</abstract>
      <url hash="e641a812">2020.coling-main.345</url>
    </paper>
    <paper id="346">
      <title>Learning from Non-Binary Constituency Trees via Tensor Decomposition</title>
      <author><first>Daniele</first><last>Castellana</last></author>
      <author><first>Davide</first><last>Bacciu</last></author>
      <pages>3899–3910</pages>
      <abstract>Processing sentence constituency trees in binarised form is a common and popular approach in literature. However, constituency trees are non-binary by nature. The binarisation procedure changes deeply the structure, furthering constituents that instead are close. In this work, we introduce a new approach to deal with non-binary constituency trees which leverages tensor-based models. In particular, we show how a powerful composition function based on the canonical tensor decomposition can exploit such a rich structure. A key point of our approach is the weight sharing constraint imposed on the factor matrices, which allows limiting the number of model parameters. Finally, we introduce a Tree-LSTM model which takes advantage of this composition function and we experimentally assess its performance on different NLP tasks.</abstract>
      <url hash="7657d224">2020.coling-main.346</url>
    </paper>
    <paper id="347">
      <title>Second-Order Unsupervised Neural Dependency Parsing</title>
      <author><first>Songlin</first><last>Yang</last></author>
      <author><first>Yong</first><last>Jiang</last></author>
      <author><first>Wenjuan</first><last>Han</last></author>
      <author><first>Kewei</first><last>Tu</last></author>
      <pages>3911–3924</pages>
      <abstract>Most of the unsupervised dependency parsers are based on first-order probabilistic generative models that only consider local parent-child information. Inspired by second-order supervised dependency parsing, we proposed a second-order extension of unsupervised neural dependency models that incorporate grandparent-child or sibling information. We also propose a novel design of the neural parameterization and optimization methods of the dependency models. In second-order models, the number of grammar rules grows cubically with the increase of vocabulary size, making it difficult to train lexicalized models that may contain thousands of words. To circumvent this problem while still benefiting from both second-order parsing and lexicalization, we use the agreement-based learning framework to jointly train a second-order unlexicalized model and a first-order lexicalized model. Experiments on multiple datasets show the effectiveness of our second-order models compared with recent state-of-the-art methods. Our joint model achieves a 10% improvement over the previous state-of-the-art parser on the full WSJ test set.</abstract>
      <url hash="5eb3b736">2020.coling-main.347</url>
    </paper>
    <paper id="348">
      <title>Integrating Domain Terminology into Neural Machine Translation</title>
      <author><first>Elise</first><last>Michon</last></author>
      <author><first>Josep</first><last>Crego</last></author>
      <author><first>Jean</first><last>Senellart</last></author>
      <pages>3925–3937</pages>
      <abstract>This paper extends existing work on terminology integration into Neural Machine Translation, a common industrial practice to dynamically adapt translation to a specific domain. Our method, based on the use of placeholders complemented with morphosyntactic annotation, efficiently taps into the ability of the neural network to deal with symbolic knowledge to surpass the surface generalization shown by alternative techniques. We compare our approach to state-of-the-art systems and benchmark them through a well-defined evaluation framework, focusing on actual application of terminology and not just on the overall performance. Results indicate the suitability of our method in the use-case where terminology is used in a system trained on generic data only.</abstract>
      <url hash="2e55076d">2020.coling-main.348</url>
    </paper>
    <paper id="349">
      <title>Understanding the effects of word-level linguistic annotations in under-resourced neural machine translation</title>
      <author><first>Víctor M.</first><last>Sánchez-Cartagena</last></author>
      <author><first>Juan Antonio</first><last>Pérez-Ortiz</last></author>
      <author><first>Felipe</first><last>Sánchez-Martínez</last></author>
      <pages>3938–3950</pages>
      <abstract>This paper studies the effects of word-level linguistic annotations in under-resourced neural machine translation, for which there is incomplete evidence in the literature. The study covers eight language pairs, different training corpus sizes, two architectures, and three types of annotation: dummy tags (with no linguistic information at all), part-of-speech tags, and morpho-syntactic description tags, which consist of part of speech and morphological features. These linguistic annotations are interleaved in the input or output streams as a single tag placed before each word. In order to measure the performance under each scenario, we use automatic evaluation metrics and perform automatic error classification. Our experiments show that, in general, source-language annotations are helpful and morpho-syntactic descriptions outperform part of speech for some language pairs. On the contrary, when words are annotated in the target language, part-of-speech tags systematically outperform morpho-syntactic description tags in terms of automatic evaluation metrics, even though the use of morpho-syntactic description tags improves the grammaticality of the output. We provide a detailed analysis of the reasons behind this result.</abstract>
      <url hash="ce86f649">2020.coling-main.349</url>
    </paper>
    <paper id="350">
      <title>Breeding Gender-aware Direct Speech Translation Systems</title>
      <author><first>Marco</first><last>Gaido</last></author>
      <author><first>Beatrice</first><last>Savoldi</last></author>
      <author><first>Luisa</first><last>Bentivogli</last></author>
      <author><first>Matteo</first><last>Negri</last></author>
      <author><first>Marco</first><last>Turchi</last></author>
      <pages>3951–3964</pages>
      <abstract>In automatic speech translation (ST), traditional cascade approaches involving separate transcription and translation steps are giving ground to increasingly competitive and more robust direct solutions. In particular, by translating speech audio data without intermediate transcription, direct ST models are able to leverage and preserve essential information present in the input (e.g.speaker’s vocal characteristics) that is otherwise lost in the cascade framework. Although such ability proved to be useful for gender translation, direct ST is nonetheless affected by gender bias just like its cascade counterpart, as well as machine translation and numerous other natural language processing applications. Moreover, direct ST systems that exclusively rely on vocal biometric features as a gender cue can be unsuitable or even potentially problematic for certain users. Going beyond speech signals, in this paper we compare different approaches to inform direct ST models about the speaker’s gender and test their ability to handle gender translation from English into Italian and French. To this aim, we manually annotated large datasets with speak-ers’ gender information and used them for experiments reflecting different possible real-world scenarios. Our results show that gender-aware direct ST solutions can significantly outperform strong – but gender-unaware – direct ST models. In particular, the translation of gender-marked words can increase up to 30 points in accuracy while preserving overall translation quality.</abstract>
      <url hash="629a4156">2020.coling-main.350</url>
    </paper>
    <paper id="351">
      <title>Neural Machine Translation Models with Back-Translation for the Extremely Low-Resource Indigenous Language <fixed-case>B</fixed-case>ribri</title>
      <author><first>Isaac</first><last>Feldman</last></author>
      <author><first>Rolando</first><last>Coto-Solano</last></author>
      <pages>3965–3976</pages>
      <abstract>This paper presents a neural machine translation model and dataset for the Chibchan language Bribri, with an average performance of BLEU 16.9±1.7. This was trained on an extremely small dataset (5923 Bribri-Spanish pairs), providing evidence for the applicability of NMT in extremely low-resource environments. We discuss the challenges entailed in managing training input from languages without standard orthographies, we provide evidence of successful learning of Bribri grammar, and also examine the translations of structures that are infrequent in major Indo-European languages, such as positional verbs, ergative markers, numerical classifiers and complex demonstrative systems. In addition to this, we perform an experiment of augmenting the dataset through iterative back-translation (Sennrich et al., 2016a; Hoang et al., 2018) by using Spanish sentences to create synthetic Bribri sentences. This improves the score by an average of 1.0 BLEU, but only when the new Spanish sentences belong to the same domain as the other Spanish examples. This contributes to the small but growing body of research on Chibchan NLP.</abstract>
      <url hash="7304beb7">2020.coling-main.351</url>
    </paper>
    <paper id="352">
      <title>Dynamic Curriculum Learning for Low-Resource Neural Machine Translation</title>
      <author><first>Chen</first><last>Xu</last></author>
      <author><first>Bojie</first><last>Hu</last></author>
      <author><first>Yufan</first><last>Jiang</last></author>
      <author><first>Kai</first><last>Feng</last></author>
      <author><first>Zeyang</first><last>Wang</last></author>
      <author><first>Shen</first><last>Huang</last></author>
      <author><first>Qi</first><last>Ju</last></author>
      <author><first>Tong</first><last>Xiao</last></author>
      <author><first>Jingbo</first><last>Zhu</last></author>
      <pages>3977–3989</pages>
      <abstract>Large amounts of data has made neural machine translation (NMT) a big success in recent years. But it is still a challenge if we train these models on small-scale corpora. In this case, the way of using data appears to be more important. Here, we investigate the effective use of training data for low-resource NMT. In particular, we propose a dynamic curriculum learning (DCL) method to reorder training samples in training. Unlike previous work, we do not use a static scoring function for reordering. Instead, the order of training samples is dynamically determined in two ways - loss decline and model competence. This eases training by highlighting easy samples that the current model has enough competence to learn. We test our DCL method in a Transformer-based system. Experimental results show that DCL outperforms several strong baselines on three low-resource machine translation benchmarks and different sized data of WMT’16 En-De.</abstract>
      <url hash="104ce6f5">2020.coling-main.352</url>
    </paper>
    <paper id="353">
      <title>Real-Valued Logics for Typological Universals: Framework and Application</title>
      <author><first>Tillmann</first><last>Dönicke</last></author>
      <author><first>Xiang</first><last>Yu</last></author>
      <author><first>Jonas</first><last>Kuhn</last></author>
      <pages>3990–4003</pages>
      <abstract>This paper proposes a framework for the expression of typological statements which uses real-valued logics to capture the empirical truth value (truth degree) of a formula on a given data source, e.g. a collection of multilingual treebanks with comparable annotation. The formulae can be arbitrarily complex expressions of propositional logic. To illustrate the usefulness of such a framework, we present experiments on the Universal Dependencies treebanks for two use cases: (i) empirical (re-)evaluation of established formulae against the spectrum of available treebanks and (ii) evaluating new formulae (i.e. potential candidates for universals) generated by a search algorithm.</abstract>
      <url hash="7c1a6f65">2020.coling-main.353</url>
    </paper>
    <paper id="354">
      <title>Comparative Probing of Lexical Semantics Theories for Cognitive Plausibility and Technological Usefulness</title>
      <author><first>António</first><last>Branco</last></author>
      <author><first>João</first><last>António Rodrigues</last></author>
      <author><first>Malgorzata</first><last>Salawa</last></author>
      <author><first>Ruben</first><last>Branco</last></author>
      <author><first>Chakaveh</first><last>Saedi</last></author>
      <pages>4004–4019</pages>
      <abstract>Lexical semantics theories differ in advocating that the meaning of words is represented as an inference graph, a feature mapping or a cooccurrence vector, thus raising the question: is it the case that one of these approaches is superior to the others in representing lexical semantics appropriately? Or in its non antagonistic counterpart: could there be a unified account of lexical semantics where these approaches seamlessly emerge as (partial) renderings of (different) aspects of a core semantic knowledge base? In this paper, we contribute to these research questions with a number of experiments that systematically probe different lexical semantics theories for their levels of cognitive plausibility and of technological usefulness. The empirical findings obtained from these experiments advance our insight on lexical semantics as the feature-based approach emerges as superior to the other ones, and arguably also move us closer to finding answers to the research questions above.</abstract>
      <url hash="2a2fce5d">2020.coling-main.354</url>
    </paper>
    <paper id="355">
      <title><fixed-case>C</fixed-case>x<fixed-case>GBERT</fixed-case>: <fixed-case>BERT</fixed-case> meets Construction Grammar</title>
      <author><first>Harish</first><last>Tayyar Madabushi</last></author>
      <author><first>Laurence</first><last>Romain</last></author>
      <author><first>Dagmar</first><last>Divjak</last></author>
      <author><first>Petar</first><last>Milin</last></author>
      <pages>4020–4032</pages>
      <abstract>While lexico-semantic elements no doubt capture a large amount of linguistic information, it has been argued that they do not capture all information contained in text. This assumption is central to constructionist approaches to language which argue that language consists of constructions, learned pairings of a form and a function or meaning that are either frequent or have a meaning that cannot be predicted from its component parts. BERT’s training objectives give it access to a tremendous amount of lexico-semantic information, and while BERTology has shown that BERT captures certain important linguistic dimensions, there have been no studies exploring the extent to which BERT might have access to constructional information. In this work we design several probes and conduct extensive experiments to answer this question. Our results allow us to conclude that BERT does indeed have access to a significant amount of information, much of which linguists typically call constructional information. The impact of this observation is potentially far-reaching as it provides insights into what deep learning methods learn from text, while also showing that information contained in constructions is redundantly encoded in lexico-semantics.</abstract>
      <url hash="e8920739">2020.coling-main.355</url>
    </paper>
    <paper id="356">
      <title>How <fixed-case>LSTM</fixed-case> Encodes Syntax: Exploring Context Vectors and Semi-Quantization on Natural Text</title>
      <author><first>Chihiro</first><last>Shibata</last></author>
      <author><first>Kei</first><last>Uchiumi</last></author>
      <author><first>Daichi</first><last>Mochihashi</last></author>
      <pages>4033–4043</pages>
      <abstract>Long Short-Term Memory recurrent neural network (LSTM) is widely used and known to capture informative long-term syntactic dependencies. However, how such information are reflected in its internal vectors for natural text has not yet been sufficiently investigated. We analyze them by learning a language model where syntactic structures are implicitly given. We empirically show that the context update vectors, i.e. outputs of internal gates, are approximately quantized to binary or ternary values to help the language model to count the depth of nesting accurately, as Suzgun et al. (2019) recently show for synthetic Dyck languages. For some dimensions in the context vector, we show that their activations are highly correlated with the depth of phrase structures, such as VP and NP. Moreover, with an L1 regularization, we also found that it can accurately predict whether a word is inside a phrase structure or not from a small number of components of the context vector. Even for the case of learning from raw text, context vectors are shown to still correlate well with the phrase structures. Finally, we show that natural clusters of the functional words and the part of speeches that trigger phrases are represented in a small but principal subspace of the context-update vector of LSTM.</abstract>
      <url hash="d22aefe9">2020.coling-main.356</url>
    </paper>
    <paper id="357">
      <title>Corpus-based Identification of Verbs Participating in Verb Alternations Using Classification and Manual Annotation</title>
      <author><first>Esther</first><last>Seyffarth</last></author>
      <author><first>Laura</first><last>Kallmeyer</last></author>
      <pages>4044–4055</pages>
      <abstract>English verb alternations allow participating verbs to appear in a set of syntactically different constructions whose associated semantic frames are systematically related. We use ENCOW and VerbNet data to train classifiers to predict the instrument subject alternation and the causative-inchoative alternation, relying on count-based and vector-based features as well as perplexity-based language model features, which are intended to reflect each alternation’s felicity by simulating it. Beyond the prediction task, we use the classifier results as a source for a manual annotation step in order to identify new, unseen instances of each alternation. This is possible because existing alternation datasets contain positive, but no negative instances and are not comprehensive. Over several sequences of classification-annotation steps, we iteratively extend our sets of alternating verbs. Our hybrid approach to the identification of new alternating verbs reduces the required annotation effort by only presenting annotators with the highest-scoring candidates from the previous classification. Due to the success of semi-supervised and unsupervised features, our approach can easily be transferred to further alternations.</abstract>
      <url hash="d13df207">2020.coling-main.357</url>
    </paper>
    <paper id="358">
      <title>When and Who? Conversation Transition Based on Bot-Agent Symbiosis Learning Network</title>
      <author><first>Yipeng</first><last>Yu</last></author>
      <author><first>Ran</first><last>Guan</last></author>
      <author><first>Jie</first><last>Ma</last></author>
      <author><first>Zhuoxuan</first><last>Jiang</last></author>
      <author><first>Jingchang</first><last>Huang</last></author>
      <pages>4056–4066</pages>
      <abstract>In online customer service applications, multiple chatbots that are specialized in various topics are typically developed separately and are then merged with other human agents to a single platform, presenting to the users with a unified interface. Ideally the conversation can be transparently transferred between different sources of customer support so that domain-specific questions can be answered timely and this is what we coined as a Bot-Agent symbiosis. Conversation transition is a major challenge in such online customer service and our work formalises the challenge as two core problems, namely, when to transfer and which bot or agent to transfer to and introduces a deep neural networks based approach that addresses these problems. Inspired by the net promoter score (NPS), our research reveals how the problems can be effectively solved by providing user feedback and developing deep neural networks that predict the conversation category distribution and the NPS of the dialogues. Experiments on realistic data generated from an online service support platform demonstrate that the proposed approach outperforms state-of-the-art methods and shows promising perspective for transparent conversation transition.</abstract>
      <url hash="76fabb71">2020.coling-main.358</url>
    </paper>
    <paper id="359">
      <title>Topic-relevant Response Generation using Optimal Transport for an Open-domain Dialog System</title>
      <author><first>Shuying</first><last>Zhang</last></author>
      <author><first>Tianyu</first><last>Zhao</last></author>
      <author><first>Tatsuya</first><last>Kawahara</last></author>
      <pages>4067–4077</pages>
      <abstract>Conventional neural generative models tend to generate safe and generic responses which have little connection with previous utterances semantically and would disengage users in a dialog system. To generate relevant responses, we propose a method that employs two types of constraints - topical constraint and semantic constraint. Under the hypothesis that a response and its context have higher relevance when they share the same topics, the topical constraint encourages the topics of a response to match its context by conditioning response decoding on topic words’ embeddings. The semantic constraint, which encourages a response to be semantically related to its context by regularizing the decoding objective function with semantic distance, is proposed. Optimal transport is applied to compute a weighted semantic distance between the representation of a response and the context. Generated responses are evaluated by automatic metrics, as well as human judgment, showing that the proposed method can generate more topic-relevant and content-rich responses than conventional models.</abstract>
      <url hash="a312a8c8">2020.coling-main.359</url>
    </paper>
    <paper id="360">
      <title>An Iterative Emotion Interaction Network for Emotion Recognition in Conversations</title>
      <author><first>Xin</first><last>Lu</last></author>
      <author><first>Yanyan</first><last>Zhao</last></author>
      <author><first>Yang</first><last>Wu</last></author>
      <author><first>Yijian</first><last>Tian</last></author>
      <author><first>Huipeng</first><last>Chen</last></author>
      <author><first>Bing</first><last>Qin</last></author>
      <pages>4078–4088</pages>
      <abstract>Emotion recognition in conversations (ERC) has received much attention recently in the natural language processing community. Considering that the emotions of the utterances in conversations are interactive, previous works usually implicitly model the emotion interaction between utterances by modeling dialogue context, but the misleading emotion information from context often interferes with the emotion interaction. We noticed that the gold emotion labels of the context utterances can provide explicit and accurate emotion interaction, but it is impossible to input gold labels at inference time. To address this problem, we propose an iterative emotion interaction network, which uses iteratively predicted emotion labels instead of gold emotion labels to explicitly model the emotion interaction. This approach solves the above problem, and can effectively retain the performance advantages of explicit modeling. We conduct experiments on two datasets, and our approach achieves state-of-the-art performance.</abstract>
      <url hash="fe4d1730">2020.coling-main.360</url>
    </paper>
    <paper id="361">
      <title><fixed-case>PEDN</fixed-case>et: A Persona Enhanced Dual Alternating Learning Network for Conversational Response Generation</title>
      <author><first>Bin</first><last>Jiang</last></author>
      <author><first>Wanyue</first><last>Zhou</last></author>
      <author><first>Jingxu</first><last>Yang</last></author>
      <author><first>Chao</first><last>Yang</last></author>
      <author><first>Shihan</first><last>Wang</last></author>
      <author><first>Liang</first><last>Pang</last></author>
      <pages>4089–4099</pages>
      <abstract>Endowing a chatbot with a personality is essential to deliver more realistic conversations. Various persona-based dialogue models have been proposed to generate personalized and diverse responses by utilizing predefined persona information. However, generating personalized responses is still a challenging task since the leverage of predefined persona information is often insufficient. To alleviate this problem, we propose a novel Persona Enhanced Dual Alternating Learning Network (PEDNet) aiming at producing more personalized responses in various open-domain conversation scenarios. PEDNet consists of a Context-Dominate Network (CDNet) and a Persona-Dominate Network (PDNet), which are built upon a common encoder-decoder backbone. CDNet learns to select a proper persona as well as ensure the contextual relevance of the predicted response, while PDNet learns to enhance the utilization of persona information when generating the response by weakening the disturbance of specific content in the conversation context. CDNet and PDNet are trained alternately using a multi-task training approach to equip PEDNet with the both capabilities they have learned. Both automatic and human evaluations on a newly released dialogue dataset Persona-chat demonstrate that our method could deliver more personalized responses than baseline methods.</abstract>
      <url hash="360e1940">2020.coling-main.361</url>
    </paper>
    <paper id="362">
      <title>Dual Dynamic Memory Network for End-to-End Multi-turn Task-oriented Dialog Systems</title>
      <author><first>Jian</first><last>Wang</last></author>
      <author><first>Junhao</first><last>Liu</last></author>
      <author><first>Wei</first><last>Bi</last></author>
      <author><first>Xiaojiang</first><last>Liu</last></author>
      <author><first>Kejing</first><last>He</last></author>
      <author><first>Ruifeng</first><last>Xu</last></author>
      <author><first>Min</first><last>Yang</last></author>
      <pages>4100–4110</pages>
      <abstract>Existing end-to-end task-oriented dialog systems struggle to dynamically model long dialog context for interactions and effectively incorporate knowledge base (KB) information into dialog generation. To conquer these limitations, we propose a Dual Dynamic Memory Network (DDMN) for multi-turn dialog generation, which maintains two core components: dialog memory manager and KB memory manager. The dialog memory manager dynamically expands the dialog memory turn by turn and keeps track of dialog history with an updating mechanism, which encourages the model to filter irrelevant dialog history and memorize important newly coming information. The KB memory manager shares the structural KB triples throughout the whole conversation, and dynamically extracts KB information with a memory pointer at each turn. Experimental results on three benchmark datasets demonstrate that DDMN significantly outperforms the strong baselines in terms of both automatic evaluation and human evaluation. Our code is available at https://github.com/siat-nlp/DDMN.</abstract>
      <url hash="0d32a31f">2020.coling-main.362</url>
    </paper>
    <paper id="363">
      <title>Translation vs. Dialogue: A Comparative Analysis of Sequence-to-Sequence Modeling</title>
      <author><first>Wenpeng</first><last>Hu</last></author>
      <author><first>Ran</first><last>Le</last></author>
      <author><first>Bing</first><last>Liu</last></author>
      <author><first>Jinwen</first><last>Ma</last></author>
      <author><first>Dongyan</first><last>Zhao</last></author>
      <author><first>Rui</first><last>Yan</last></author>
      <pages>4111–4122</pages>
      <abstract>Understanding neural models is a major topic of interest in the deep learning community. In this paper, we propose to interpret a general neural model comparatively. Specifically, we study the sequence-to-sequence (Seq2Seq) model in the contexts of two mainstream NLP tasks–machine translation and dialogue response generation–as they both use the seq2seq model. We investigate how the two tasks are different and how their task difference results in major differences in the behaviors of the resulting translation and dialogue generation systems. This study allows us to make several interesting observations and gain valuable insights, which can be used to help develop better translation and dialogue generation models. To our knowledge, no such comparative study has been done so far.</abstract>
      <url hash="3fffc135">2020.coling-main.363</url>
    </paper>
    <paper id="364">
      <title>Diverse dialogue generation with context dependent dynamic loss function</title>
      <author><first>Ayaka</first><last>Ueyama</last></author>
      <author><first>Yoshinobu</first><last>Kano</last></author>
      <pages>4123–4127</pages>
      <abstract>Dialogue systems using deep learning have achieved generation of fluent response sentences to user utterances. Nevertheless, they tend to produce responses that are not diverse and which are less context-dependent. To address these shortcomings, we propose a new loss function, an Inverse N-gram loss (INF), which incorporates contextual fluency and diversity at the same time by a simple formula. Our INF loss can adjust its loss dynamically by a weight using the inverse frequency of the tokens’ n-gram applied to Softmax Cross-Entropy loss, so that rare tokens appear more likely while retaining the fluency of the generated sentences. We trained Transformer using English and Japanese Twitter replies as single-turn dialogues using different loss functions. Our INF loss model outperformed the baselines of SCE loss and ITF loss models in automatic evaluations such as DIST-N and ROUGE, and also achieved higher scores on our human evaluations of coherence and richness.</abstract>
      <url hash="59f5755f">2020.coling-main.364</url>
    </paper>
    <paper id="365">
      <title>Towards Topic-Guided Conversational Recommender System</title>
      <author><first>Kun</first><last>Zhou</last></author>
      <author><first>Yuanhang</first><last>Zhou</last></author>
      <author><first>Wayne Xin</first><last>Zhao</last></author>
      <author><first>Xiaoke</first><last>Wang</last></author>
      <author><first>Ji-Rong</first><last>Wen</last></author>
      <pages>4128–4139</pages>
      <abstract>Conversational recommender systems (CRS) aim to recommend high-quality items to users through interactive conversations. To develop an effective CRS, the support of high-quality datasets is essential. Existing CRS datasets mainly focus on immediate requests from users, while lack proactive guidance to the recommendation scenario. In this paper, we contribute a new CRS dataset named <b>TG-ReDial</b> (<b>Re</b>commendation through <b>T</b>opic-<b>G</b>uided <b>Dial</b>og). Our dataset has two major features. First, it incorporates topic threads to enforce natural semantic transitions towards the recommendation scenario. Second, it is created in a semi-automatic way, hence human annotation is more reasonable and controllable. Based on TG-ReDial, we present the task of topic-guided conversational recommendation, and propose an effective approach to this task. Extensive experiments have demonstrated the effectiveness of our approach on three sub-tasks, namely topic prediction, item recommendation and response generation. TG-ReDial is available at blue<url>https://github.com/RUCAIBox/TG-ReDial</url>.</abstract>
      <url hash="37f9bf31">2020.coling-main.365</url>
    </paper>
    <paper id="366">
      <title>Intent Mining from past conversations for Conversational Agent</title>
      <author><first>Ajay</first><last>Chatterjee</last></author>
      <author><first>Shubhashis</first><last>Sengupta</last></author>
      <pages>4140–4152</pages>
      <abstract>Conversational systems are of primary interest in the AI community. Organizations are increasingly using chatbot to provide round-the-clock support and to increase customer engagement. Many commercial bot building frameworks follow a standard approach that requires one to build and train an intent model to recognize user input. These frameworks require a collection of user utterances and corresponding intent to train an intent model. Collecting a substantial coverage of training data is a bottleneck in the bot building process. In cases where past conversation data is available, the cost of labeling hundreds of utterances with intent labels is time-consuming and laborious. In this paper, we present an intent discovery framework that can mine a vast amount of conversational logs and to generate labeled data sets for training intent models. We have introduced an extension to the DBSCAN algorithm and presented a density-based clustering algorithm ITER-DBSCAN for unbalanced data clustering. Empirical evaluation on one conversation dataset, six different intent dataset, and one short text clustering dataset show the effectiveness of our hypothesis.</abstract>
      <url hash="d7c2fb4b">2020.coling-main.366</url>
    </paper>
    <paper id="367">
      <title>Summarize before Aggregate: A Global-to-local Heterogeneous Graph Inference Network for Conversational Emotion Recognition</title>
      <author><first>Dongming</first><last>Sheng</last></author>
      <author><first>Dong</first><last>Wang</last></author>
      <author><first>Ying</first><last>Shen</last></author>
      <author><first>Haitao</first><last>Zheng</last></author>
      <author><first>Haozhuang</first><last>Liu</last></author>
      <pages>4153–4163</pages>
      <abstract>Conversational Emotion Recognition (CER) is a crucial task in Natural Language Processing (NLP) with wide applications. Prior works in CER generally focus on modeling emotion influences solely with utterance-level features, with little attention paid on phrase-level semantic connection between utterances. Phrases carry sentiments when they are referred to emotional events under certain topics, providing a global semantic connection between utterances throughout the entire conversation. In this work, we propose a two-stage Summarization and Aggregation Graph Inference Network (SumAggGIN), which seamlessly integrates inference for topic-related emotional phrases and local dependency reasoning over neighbouring utterances in a global-to-local fashion. Topic-related emotional phrases, which constitutes the global topic-related emotional connections, are recognized by our proposed heterogeneous Summarization Graph. Local dependencies, which captures short-term emotional effects between neighbouring utterances, are further injected via an Aggregation Graph to distinguish the subtle differences between utterances containing emotional phrases. The two steps of graph inference are tightly-coupled for a comprehensively understanding of emotional fluctuation. Experimental results on three CER benchmark datasets verify the effectiveness of our proposed model, which outperforms the state-of-the-art approaches.</abstract>
      <url hash="6166bca4">2020.coling-main.367</url>
    </paper>
    <paper id="368">
      <title>Deconstruct to Reconstruct a Configurable Evaluation Metric for Open-Domain Dialogue Systems</title>
      <author><first>Vitou</first><last>Phy</last></author>
      <author><first>Yang</first><last>Zhao</last></author>
      <author><first>Akiko</first><last>Aizawa</last></author>
      <pages>4164–4178</pages>
      <abstract>Many automatic evaluation metrics have been proposed to score the overall quality of a response in open-domain dialogue. Generally, the overall quality is comprised of various aspects, such as relevancy, specificity, and empathy, and the importance of each aspect differs according to the task. For instance, specificity is mandatory in a food-ordering dialogue task, whereas fluency is preferred in a language-teaching dialogue system. However, existing metrics are not designed to cope with such flexibility. For example, BLEU score fundamentally relies only on word overlapping, whereas BERTScore relies on semantic similarity between reference and candidate response. Thus, they are not guaranteed to capture the required aspects, i.e., specificity. To design a metric that is flexible to a task, we first propose making these qualities manageable by grouping them into three groups: understandability, sensibleness, and likability, where likability is a combination of qualities that are essential for a task. We also propose a simple method to composite metrics of each aspect to obtain a single metric called USL-H, which stands for Understandability, Sensibleness, and Likability in Hierarchy. We demonstrated that USL-H score achieves good correlations with human judgment and maintains its configurability towards different aspects and metrics.</abstract>
      <url hash="92ee61f2">2020.coling-main.368</url>
    </paper>
    <paper id="369">
      <title>Suggest me a movie for tonight: Leveraging Knowledge Graphs for Conversational Recommendation</title>
      <author><first>Rajdeep</first><last>Sarkar</last></author>
      <author><first>Koustava</first><last>Goswami</last></author>
      <author><first>Mihael</first><last>Arcan</last></author>
      <author><first>John P.</first><last>McCrae</last></author>
      <pages>4179–4189</pages>
      <abstract>Conversational recommender systems focus on the task of suggesting products to users based on the conversation flow. Recently, the use of external knowledge in the form of knowledge graphs has shown to improve the performance in recommendation and dialogue systems. Information from knowledge graphs aids in enriching those systems by providing additional information such as closely related products and textual descriptions of the items. However, knowledge graphs are incomplete since they do not contain all factual information present on the web. Furthermore, when working on a specific domain, knowledge graphs in its entirety contribute towards extraneous information and noise. In this work, we study several subgraph construction methods and compare their performance across the recommendation task. We incorporate pre-trained embeddings from the subgraphs along with positional embeddings in our models. Extensive experiments show that our method has a relative improvement of at least 5.62% compared to the state-of-the-art on multiple metrics on the recommendation task.</abstract>
      <url hash="1d52f878">2020.coling-main.369</url>
    </paper>
    <paper id="370">
      <title><fixed-case>H</fixed-case>i<fixed-case>T</fixed-case>rans: A Transformer-Based Context- and Speaker-Sensitive Model for Emotion Detection in Conversations</title>
      <author><first>Jingye</first><last>Li</last></author>
      <author><first>Donghong</first><last>Ji</last></author>
      <author><first>Fei</first><last>Li</last></author>
      <author><first>Meishan</first><last>Zhang</last></author>
      <author><first>Yijiang</first><last>Liu</last></author>
      <pages>4190–4200</pages>
      <abstract>Emotion detection in conversations (EDC) is to detect the emotion for each utterance in conversations that have multiple speakers. Different from the traditional non-conversational emotion detection, the model for EDC should be context-sensitive (e.g., understanding the whole conversation rather than one utterance) and speaker-sensitive (e.g., understanding which utterance belongs to which speaker). In this paper, we propose a transformer-based context- and speaker-sensitive model for EDC, namely HiTrans, which consists of two hierarchical transformers. We utilize BERT as the low-level transformer to generate local utterance representations, and feed them into another high-level transformer so that utterance representations could be sensitive to the global context of the conversation. Moreover, we exploit an auxiliary task to make our model speaker-sensitive, called pairwise utterance speaker verification (PUSV), which aims to classify whether two utterances belong to the same speaker. We evaluate our model on three benchmark datasets, namely EmoryNLP, MELD and IEMOCAP. Results show that our model outperforms previous state-of-the-art models.</abstract>
      <url hash="b46fc085">2020.coling-main.370</url>
    </paper>
    <paper id="371">
      <title>A Co-Attentive Cross-Lingual Neural Model for Dialogue Breakdown Detection</title>
      <author><first>Qian</first><last>Lin</last></author>
      <author><first>Souvik</first><last>Kundu</last></author>
      <author><first>Hwee Tou</first><last>Ng</last></author>
      <pages>4201–4210</pages>
      <abstract>Ensuring smooth communication is essential in a chat-oriented dialogue system, so that a user can obtain meaningful responses through interactions with the system. Most prior work on dialogue research does not focus on preventing dialogue breakdown. One of the major challenges is that a dialogue system may generate an undesired utterance leading to a dialogue breakdown, which degrades the overall interaction quality. Hence, it is crucial for a machine to detect dialogue breakdowns in an ongoing conversation. In this paper, we propose a novel dialogue breakdown detection model that jointly incorporates a pretrained cross-lingual language model and a co-attention network. Our proposed model leverages effective word embeddings trained on one hundred different languages to generate contextualized representations. Co-attention aims to capture the interaction between the latest utterance and the conversation history, and thereby determines whether the latest utterance causes a dialogue breakdown. Experimental results show that our proposed model outperforms all previous approaches on all evaluation metrics in both the Japanese and English tracks in Dialogue Breakdown Detection Challenge 4 (DBDC4 at IWSDS2019).</abstract>
      <url hash="0f77eda7">2020.coling-main.371</url>
    </paper>
    <paper id="372">
      <title>Integrating User History into Heterogeneous Graph for Dialogue Act Recognition</title>
      <author><first>Dong</first><last>Wang</last></author>
      <author><first>Ziran</first><last>Li</last></author>
      <author><first>Haitao</first><last>Zheng</last></author>
      <author><first>Ying</first><last>Shen</last></author>
      <pages>4211–4221</pages>
      <abstract>Dialogue Act Recognition (DAR) is a challenging problem in Natural Language Understanding, which aims to attach Dialogue Act (DA) labels to each utterance in a conversation. However, previous studies cannot fully recognize the specific expressions given by users due to the informality and diversity of natural language expressions. To solve this problem, we propose a Heterogeneous User History (HUH) graph convolution network, which utilizes the user’s historical answers grouped by DA labels as additional clues to recognize the DA label of utterances. To handle the noise caused by introducing the user’s historical answers, we design sets of denoising mechanisms, including a History Selection process, a Similarity Re-weighting process, and an Edge Re-weighting process. We evaluate the proposed method on two benchmark datasets MSDialog and MRDA. The experimental results verify the effectiveness of integrating user’s historical answers, and show that our proposed model outperforms the state-of-the-art methods.</abstract>
      <url hash="6a11cb1e">2020.coling-main.372</url>
    </paper>
    <paper id="373">
      <title>A Two-Level Interpretation of Modality in Human-Robot Dialogue</title>
      <author><first>Lucia</first><last>Donatelli</last></author>
      <author><first>Kenneth</first><last>Lai</last></author>
      <author><first>James</first><last>Pustejovsky</last></author>
      <pages>4222–4238</pages>
      <abstract>We analyze the use and interpretation of modal expressions in a corpus of situated human-robot dialogue and ask how to effectively represent these expressions for automatic learning. We present a two-level annotation scheme for modality that captures both content and intent, integrating a logic-based, semantic representation and a task-oriented, pragmatic representation that maps to our robot’s capabilities. Data from our annotation task reveals that the interpretation of modal expressions in human-robot dialogue is quite diverse, yet highly constrained by the physical environment and asymmetrical speaker/addressee relationship. We sketch a formal model of human-robot common ground in which modality can be grounded and dynamically interpreted.</abstract>
      <url hash="7187803a">2020.coling-main.373</url>
    </paper>
    <paper id="374">
      <title>Robust Unsupervised Neural Machine Translation with Adversarial Denoising Training</title>
      <author><first>Haipeng</first><last>Sun</last></author>
      <author><first>Rui</first><last>Wang</last></author>
      <author><first>Kehai</first><last>Chen</last></author>
      <author><first>Xugang</first><last>Lu</last></author>
      <author><first>Masao</first><last>Utiyama</last></author>
      <author><first>Eiichiro</first><last>Sumita</last></author>
      <author><first>Tiejun</first><last>Zhao</last></author>
      <pages>4239–4250</pages>
      <abstract>Unsupervised neural machine translation (UNMT) has recently attracted great interest in the machine translation community. The main advantage of the UNMT lies in its easy collection of required large training text sentences while with only a slightly worse performance than supervised neural machine translation which requires expensive annotated translation pairs on some translation tasks. In most studies, the UMNT is trained with clean data without considering its robustness to the noisy data. However, in real-world scenarios, there usually exists noise in the collected input sentences which degrades the performance of the translation system since the UNMT is sensitive to the small perturbations of the input sentences. In this paper, we first time explicitly take the noisy data into consideration to improve the robustness of the UNMT based systems. First of all, we clearly defined two types of noises in training sentences, i.e., word noise and word order noise, and empirically investigate its effect in the UNMT, then we propose adversarial training methods with denoising process in the UNMT. Experimental results on several language pairs show that our proposed methods substantially improved the robustness of the conventional UNMT systems in noisy scenarios.</abstract>
      <url hash="9ef2abfe">2020.coling-main.374</url>
    </paper>
    <paper id="375">
      <title>Understanding Pure Character-Based Neural Machine Translation: The Case of Translating <fixed-case>F</fixed-case>innish into <fixed-case>E</fixed-case>nglish</title>
      <author><first>Gongbo</first><last>Tang</last></author>
      <author><first>Rico</first><last>Sennrich</last></author>
      <author><first>Joakim</first><last>Nivre</last></author>
      <pages>4251–4262</pages>
      <abstract>Recent work has shown that deeper character-based neural machine translation (NMT) models can outperform subword-based models. However, it is still unclear what makes deeper character-based models successful. In this paper, we conduct an investigation into pure character-based models in the case of translating Finnish into English, including exploring the ability to learn word senses and morphological inflections and the attention mechanism. We demonstrate that word-level information is distributed over the entire character sequence rather than over a single character, and characters at different positions play different roles in learning linguistic knowledge. In addition, character-based models need more layers to encode word senses which explains why only deeper models outperform subword-based models. The attention distribution pattern shows that separators attract a lot of attention and we explore a sparse word-level attention to enforce character hidden states to capture the full word-level information. Experimental results show that the word-level attention with a single head results in 1.2 BLEU points drop.</abstract>
      <url hash="8d716cae">2020.coling-main.375</url>
    </paper>
    <paper id="376">
      <title>Improving Low-Resource <fixed-case>NMT</fixed-case> through Relevance Based Linguistic Features Incorporation</title>
      <author><first>Abhisek</first><last>Chakrabarty</last></author>
      <author><first>Raj</first><last>Dabre</last></author>
      <author><first>Chenchen</first><last>Ding</last></author>
      <author><first>Masao</first><last>Utiyama</last></author>
      <author><first>Eiichiro</first><last>Sumita</last></author>
      <pages>4263–4274</pages>
      <abstract>In this study, linguistic knowledge at different levels are incorporated into the neural machine translation (NMT) framework to improve translation quality for language pairs with extremely limited data. Integrating manually designed or automatically extracted features into the NMT framework is known to be beneficial. However, this study emphasizes that the relevance of the features is crucial to the performance. Specifically, we propose two methods, 1) self relevance and 2) word-based relevance, to improve the representation of features for NMT. Experiments are conducted on translation tasks from English to eight Asian languages, with no more than twenty thousand sentences for training. The proposed methods improve translation quality for all tasks by up to 3.09 BLEU points. Discussions with visualization provide the explainability of the proposed methods where we show that the relevance methods provide weights to features thereby enhancing their impact on low-resource machine translation.</abstract>
      <url hash="ef68f3a1">2020.coling-main.376</url>
    </paper>
    <paper id="377">
      <title>Layer-Wise Multi-View Learning for Neural Machine Translation</title>
      <author><first>Qiang</first><last>Wang</last></author>
      <author><first>Changliang</first><last>Li</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <author><first>Tong</first><last>Xiao</last></author>
      <author><first>Jingbo</first><last>Zhu</last></author>
      <pages>4275–4286</pages>
      <abstract>Traditional neural machine translation is limited to the topmost encoder layer’s context representation and cannot directly perceive the lower encoder layers. Existing solutions usually rely on the adjustment of network architecture, making the calculation more complicated or introducing additional structural restrictions. In this work, we propose layer-wise multi-view learning to solve this problem, circumventing the necessity to change the model structure. We regard each encoder layer’s off-the-shelf output, a by-product in layer-by-layer encoding, as the redundant view for the input sentence. In this way, in addition to the topmost encoder layer (referred to as the primary view), we also incorporate an intermediate encoder layer as the auxiliary view. We feed the two views to a partially shared decoder to maintain independent prediction. Consistency regularization based on KL divergence is used to encourage the two views to learn from each other. Extensive experimental results on five translation tasks show that our approach yields stable improvements over multiple strong baselines. As another bonus, our method is agnostic to network architectures and can maintain the same inference speed as the original model.</abstract>
      <url hash="f6c8de0f">2020.coling-main.377</url>
    </paper>
    <paper id="378">
      <title>Bilingual Subword Segmentation for Neural Machine Translation</title>
      <author><first>Hiroyuki</first><last>Deguchi</last></author>
      <author><first>Masao</first><last>Utiyama</last></author>
      <author><first>Akihiro</first><last>Tamura</last></author>
      <author><first>Takashi</first><last>Ninomiya</last></author>
      <author><first>Eiichiro</first><last>Sumita</last></author>
      <pages>4287–4297</pages>
      <abstract>This paper proposed a new subword segmentation method for neural machine translation, “Bilingual Subword Segmentation,” which tokenizes sentences to minimize the difference between the number of subword units in a sentence and that of its translation. While existing subword segmentation methods tokenize a sentence without considering its translation, the proposed method tokenizes a sentence by using subword units induced from bilingual sentences; this method could be more favorable to machine translation. Evaluations on WAT Asian Scientific Paper Excerpt Corpus (ASPEC) English-to-Japanese and Japanese-to-English translation tasks and WMT14 English-to-German and German-to-English translation tasks show that our bilingual subword segmentation improves the performance of Transformer neural machine translation (up to +0.81 BLEU).</abstract>
      <url hash="d97bd9a6">2020.coling-main.378</url>
    </paper>
    <paper id="379">
      <title>Token Drop mechanism for Neural Machine Translation</title>
      <author><first>Huaao</first><last>Zhang</last></author>
      <author><first>Shigui</first><last>Qiu</last></author>
      <author><first>Xiangyu</first><last>Duan</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>4298–4303</pages>
      <abstract>Neural machine translation with millions of parameters is vulnerable to unfamiliar inputs. We propose Token Drop to improve generalization and avoid overfitting for the NMT model. Similar to word dropout, whereas we replace dropped token with a special token instead of setting zero to words. We further introduce two self-supervised objectives: Replaced Token Detection and Dropped Token Prediction. Our method aims to force model generating target translation with less information, in this way the model can learn textual representation better. Experiments on Chinese-English and English-Romanian benchmark demonstrate the effectiveness of our approach and our model achieves significant improvements over a strong Transformer baseline.</abstract>
      <url hash="2f2a0c7f">2020.coling-main.379</url>
    </paper>
    <paper id="380">
      <title>Supervised Visual Attention for Multimodal Neural Machine Translation</title>
      <author><first>Tetsuro</first><last>Nishihara</last></author>
      <author><first>Akihiro</first><last>Tamura</last></author>
      <author><first>Takashi</first><last>Ninomiya</last></author>
      <author><first>Yutaro</first><last>Omote</last></author>
      <author><first>Hideki</first><last>Nakayama</last></author>
      <pages>4304–4314</pages>
      <abstract>This paper proposed a supervised visual attention mechanism for multimodal neural machine translation (MNMT), trained with constraints based on manual alignments between words in a sentence and their corresponding regions of an image. The proposed visual attention mechanism captures the relationship between a word and an image region more precisely than a conventional visual attention mechanism trained through MNMT in an unsupervised manner. Our experiments on English-German and German-English translation tasks using the Multi30k dataset and on English-Japanese and Japanese-English translation tasks using the Flickr30k Entities JP dataset show that a Transformer-based MNMT model can be improved by incorporating our proposed supervised visual attention mechanism and that further improvements can be achieved by combining it with a supervised cross-lingual attention mechanism (up to +1.61 BLEU, +1.7 METEOR).</abstract>
      <url hash="8efd8972">2020.coling-main.380</url>
    </paper>
    <paper id="381">
      <title>Investigating Catastrophic Forgetting During Continual Training for Neural Machine Translation</title>
      <author><first>Shuhao</first><last>Gu</last></author>
      <author><first>Yang</first><last>Feng</last></author>
      <pages>4315–4326</pages>
      <abstract>Neural machine translation (NMT) models usually suffer from catastrophic forgetting during continual training where the models tend to gradually forget previously learned knowledge and swing to fit the newly added data which may have a different distribution, e.g. a different domain. Although many methods have been proposed to solve this problem, we cannot get to know what causes this phenomenon yet. Under the background of domain adaptation, we investigate the cause of catastrophic forgetting from the perspectives of modules and parameters (neurons). The investigation on the modules of the NMT model shows that some modules have tight relation with the general-domain knowledge while some other modules are more essential in the domain adaptation. And the investigation on the parameters shows that some parameters are important for both the general-domain and in-domain translation and the great change of them during continual training brings about the performance decline in general-domain. We conducted experiments across different language pairs and domains to ensure the validity and reliability of our findings.</abstract>
      <url hash="a1f83445">2020.coling-main.381</url>
    </paper>
    <paper id="382">
      <title>The Two Shades of Dubbing in Neural Machine Translation</title>
      <author><first>Alina</first><last>Karakanta</last></author>
      <author><first>Supratik</first><last>Bhattacharya</last></author>
      <author><first>Shravan</first><last>Nayak</last></author>
      <author><first>Timo</first><last>Baumann</last></author>
      <author><first>Matteo</first><last>Negri</last></author>
      <author><first>Marco</first><last>Turchi</last></author>
      <pages>4327–4333</pages>
      <abstract>Dubbing has two shades; synchronisation constraints are applied only when the actor’s mouth is visible on screen, while the translation is unconstrained for off-screen dubbing. Consequently, different synchronisation requirements, and therefore translation strategies, are applied depending on the type of dubbing. In this work, we manually annotate an existing dubbing corpus (Heroes) for this dichotomy. We show that, even though we did not observe distinctive features between on- and off-screen dubbing at the textual level, on-screen dubbing is more difficult for MT (-4 BLEU points). Moreover, synchronisation constraints dramatically decrease translation quality for off-screen dubbing. We conclude that, distinguishing between on-screen and off-screen dubbing is necessary for determining successful strategies for dubbing-customised Machine Translation.</abstract>
      <url hash="b1559028">2020.coling-main.382</url>
    </paper>
    <paper id="383">
      <title>Filtering Back-Translated Data in Unsupervised Neural Machine Translation</title>
      <author><first>Jyotsana</first><last>Khatri</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>4334–4339</pages>
      <abstract>Unsupervised neural machine translation (NMT) utilizes only monolingual data for training. The quality of back-translated data plays an important role in the performance of NMT systems. In back-translation, all generated pseudo parallel sentence pairs are not of the same quality. Taking inspiration from domain adaptation where in-domain sentences are given more weight in training, in this paper we propose an approach to filter back-translated data as part of the training process of unsupervised NMT. Our approach gives more weight to good pseudo parallel sentence pairs in the back-translation phase. We calculate the weight of each pseudo parallel sentence pair using sentence-wise round-trip BLEU score which is normalized batch-wise. We compare our approach with the current state of the art approaches for unsupervised NMT.</abstract>
      <url hash="3ff08612">2020.coling-main.383</url>
    </paper>
    <paper id="384">
      <title>Lost in Back-Translation: Emotion Preservation in Neural Machine Translation</title>
      <author><first>Enrica</first><last>Troiano</last></author>
      <author><first>Roman</first><last>Klinger</last></author>
      <author><first>Sebastian</first><last>Padó</last></author>
      <pages>4340–4354</pages>
      <abstract>Machine translation provides powerful methods to convert text between languages, and is therefore a technology enabling a multilingual world. An important part of communication, however, takes place at the non-propositional level (e.g., politeness, formality, emotions), and it is far from clear whether current MT methods properly translate this information. This paper investigates the specific hypothesis that the non-propositional level of emotions is at least partially lost in MT. We carry out a number of experiments in a back-translation setup and establish that (1) emotions are indeed partially lost during translation; (2) this tendency can be reversed almost completely with a simple re-ranking approach informed by an emotion classifier, taking advantage of diversity in the n-best list; (3) the re-ranking approach can also be applied to change emotions, obtaining a model for emotion style transfer. An in-depth qualitative analysis reveals that there are recurring linguistic changes through which emotions are toned down or amplified, such as change of modality.</abstract>
      <url hash="6cba3e1e">2020.coling-main.384</url>
    </paper>
    <paper id="385">
      <title>Intermediate Self-supervised Learning for Machine Translation Quality Estimation</title>
      <author><first>Raphael</first><last>Rubino</last></author>
      <author><first>Eiichiro</first><last>Sumita</last></author>
      <pages>4355–4360</pages>
      <abstract>Pre-training sentence encoders is effective in many natural language processing tasks including machine translation (MT) quality estimation (QE), due partly to the scarcity of annotated QE data required for supervised learning. In this paper, we investigate the use of an intermediate self-supervised learning task for sentence encoder aiming at improving QE performances at the sentence and word levels. Our approach is motivated by a problem inherent to QE: mistakes in translation caused by wrongly inserted and deleted tokens. We modify the translation language model (TLM) training objective of the cross-lingual language model (XLM) to orientate the pre-trained model towards the target task. The proposed method does not rely on annotated data and is complementary to QE methods involving pre-trained sentence encoders and domain adaptation. Experiments on English-to-German and English-to-Russian translation directions show that intermediate learning improves over domain adaptated models. Additionally, our method reaches results in par with state-of-the-art QE models without requiring the combination of several approaches and outperforms similar methods based on pre-trained sentence encoders.</abstract>
      <url hash="62ac7415">2020.coling-main.385</url>
    </paper>
    <paper id="386">
      <title>Unifying Input and Output Smoothing in Neural Machine Translation</title>
      <author><first>Yingbo</first><last>Gao</last></author>
      <author><first>Baohao</first><last>Liao</last></author>
      <author><first>Hermann</first><last>Ney</last></author>
      <pages>4361–4372</pages>
      <abstract>Soft contextualized data augmentation is a recent method that replaces one-hot representation of words with soft posterior distributions of an external language model, smoothing the input of neural machine translation systems. Label smoothing is another effective method that penalizes over-confident model outputs by discounting some probability mass from the true target word, smoothing the output of neural machine translation systems. Having the benefit of updating all word vectors in each optimization step and better regularizing the models, the two smoothing methods are shown to bring significant improvements in translation performance. In this work, we study how to best combine the methods and stack the improvements. Specifically, we vary the prior distributions to smooth with, the hyperparameters that control the smoothing strength, and the token selection procedures. We conduct extensive experiments on small datasets, evaluate the recipes on larger datasets, and examine the implications when back-translation is further used. Our results confirm cumulative improvements when input and output smoothing are used in combination, giving up to +1.9 BLEU scores on standard machine translation tasks and reveal reasons why these smoothing methods should be preferred.</abstract>
      <url hash="ab25c3e9">2020.coling-main.386</url>
    </paper>
    <paper id="387">
      <title>Neural Transduction for Multilingual Lexical Translation</title>
      <author><first>Dylan</first><last>Lewis</last></author>
      <author><first>Winston</first><last>Wu</last></author>
      <author><first>Arya D.</first><last>McCarthy</last></author>
      <author><first>David</first><last>Yarowsky</last></author>
      <pages>4373–4384</pages>
      <abstract>We present a method for completing multilingual translation dictionaries. Our probabilistic approach can synthesize new word forms, allowing it to operate in settings where correct translations have not been observed in text (cf. cross-lingual embeddings). In addition, we propose an approximate Maximum Mutual Information (MMI) decoding objective to further improve performance in both many-to-one and one-to-one word level translation tasks where we use either multiple input languages for a single target language or more typical single language pair translation. The model is trained in a many-to-many setting, where it can leverage information from related languages to predict words in each of its many target languages. We focus on 6 languages: French, Spanish, Italian, Portuguese, Romanian, and Turkish. When indirect multilingual information is available, ensembling with mixture-of-experts as well as incorporating related languages leads to a 27% relative improvement in whole-word accuracy of predictions over a single-source baseline. To seed the completion when multilingual data is unavailable, it is better to decode with an MMI objective.</abstract>
      <url hash="4e42ebf4">2020.coling-main.387</url>
    </paper>
    <paper id="388">
      <title>A Document-Level Neural Machine Translation Model with Dynamic Caching Guided by Theme-Rheme Information</title>
      <author><first>Yiqi</first><last>Tong</last></author>
      <author><first>Jiangbin</first><last>Zheng</last></author>
      <author><first>Hongkang</first><last>Zhu</last></author>
      <author><first>Yidong</first><last>Chen</last></author>
      <author><first>Xiaodong</first><last>Shi</last></author>
      <pages>4385–4395</pages>
      <abstract>Research on document-level Neural Machine Translation (NMT) models has attracted increasing attention in recent years. Although the proposed works have proved that the inter-sentence information is helpful for improving the performance of the NMT models, what information should be regarded as context remains ambiguous. To solve this problem, we proposed a novel cache-based document-level NMT model which conducts dynamic caching guided by theme-rheme information. The experiments on NIST evaluation sets demonstrate that our proposed model achieves substantial improvements over the state-of-the-art baseline NMT models. As far as we know, we are the first to introduce theme-rheme theory into the field of machine translation.</abstract>
      <url hash="807a28e4">2020.coling-main.388</url>
    </paper>
    <paper id="389">
      <title>Context-Aware Cross-Attention for Non-Autoregressive Translation</title>
      <author><first>Liang</first><last>Ding</last></author>
      <author><first>Longyue</first><last>Wang</last></author>
      <author><first>Di</first><last>Wu</last></author>
      <author><first>Dacheng</first><last>Tao</last></author>
      <author><first>Zhaopeng</first><last>Tu</last></author>
      <pages>4396–4402</pages>
      <abstract>Non-autoregressive translation (NAT) significantly accelerates the inference process by predicting the entire target sequence. However, due to the lack of target dependency modelling in the decoder, the conditional generation process heavily depends on the cross-attention. In this paper, we reveal a localness perception problem in NAT cross-attention, for which it is difficult to adequately capture source context. To alleviate this problem, we propose to enhance signals of neighbour source tokens into conventional cross-attention. Experimental results on several representative datasets show that our approach can consistently improve translation quality over strong NAT baselines. Extensive analyses demonstrate that the enhanced cross-attention achieves better exploitation of source contexts by leveraging both local and global information.</abstract>
      <url hash="af3b7f1d">2020.coling-main.389</url>
    </paper>
    <paper id="390">
      <title>Does Gender Matter? Towards Fairness in Dialogue Systems</title>
      <author><first>Haochen</first><last>Liu</last></author>
      <author><first>Jamell</first><last>Dacon</last></author>
      <author><first>Wenqi</first><last>Fan</last></author>
      <author><first>Hui</first><last>Liu</last></author>
      <author><first>Zitao</first><last>Liu</last></author>
      <author><first>Jiliang</first><last>Tang</last></author>
      <pages>4403–4416</pages>
      <abstract>Recently there are increasing concerns about the fairness of Artificial Intelligence (AI) in real-world applications such as computer vision and recommendations. For example, recognition algorithms in computer vision are unfair to black people such as poorly detecting their faces and inappropriately identifying them as “gorillas”. As one crucial application of AI, dialogue systems have been extensively applied in our society. They are usually built with real human conversational data; thus they could inherit some fairness issues which are held in the real world. However, the fairness of dialogue systems has not been well investigated. In this paper, we perform a pioneering study about the fairness issues in dialogue systems. In particular, we construct a benchmark dataset and propose quantitative measures to understand fairness in dialogue models. Our studies demonstrate that popular dialogue models show significant prejudice towards different genders and races. Besides, to mitigate the bias in dialogue systems, we propose two simple but effective debiasing methods. Experiments show that our methods can reduce the bias in dialogue systems significantly. The dataset and the implementation are released to foster fairness research in dialogue systems.</abstract>
      <url hash="5fbda8e5">2020.coling-main.390</url>
    </paper>
    <paper id="391">
      <title>Combining Cognitive Modeling and Reinforcement Learning for Clarification in Dialogue</title>
      <author><first>Baber</first><last>Khalid</last></author>
      <author><first>Malihe</first><last>Alikhani</last></author>
      <author><first>Matthew</first><last>Stone</last></author>
      <pages>4417–4428</pages>
      <abstract>In many domains, dialogue systems need to work collaboratively with users to successfully reconstruct the meaning the user had in mind. In this paper, we show how cognitive models of users’ communicative strategies can be leveraged in a reinforcement learning approach to dialogue planning to enable interactive systems to give targeted, effective feedback about the system’s understanding. We describe a prototype system that collaborates on reference tasks that distinguish arbitrarily varying color patches from similar distractors, and use experiments with crowd workers and analyses of our learned policies to document that our approach leads to context-sensitive clarification strategies that focus on key missing information, elicit correct answers that the system understands, and contribute to increasing dialogue success.</abstract>
      <url hash="0d2c8a30">2020.coling-main.391</url>
    </paper>
    <paper id="392">
      <title>Knowledge Aware Emotion Recognition in Textual Conversations via Multi-Task Incremental Transformer</title>
      <author><first>Duzhen</first><last>Zhang</last></author>
      <author><first>Xiuyi</first><last>Chen</last></author>
      <author><first>Shuang</first><last>Xu</last></author>
      <author><first>Bo</first><last>Xu</last></author>
      <pages>4429–4440</pages>
      <abstract>Emotion recognition in textual conversations (ERTC) plays an important role in a wide range of applications, such as opinion mining, recommender systems, and so on. ERTC, however, is a challenging task. For one thing, speakers often rely on the context and commonsense knowledge to express emotions; for another, most utterances contain neutral emotion in conversations, as a result, the confusion between a few non-neutral utterances and much more neutral ones restrains the emotion recognition performance. In this paper, we propose a novel Knowledge Aware Incremental Transformer with Multi-task Learning (KAITML) to address these challenges. Firstly, we devise a dual-level graph attention mechanism to leverage commonsense knowledge, which augments the semantic information of the utterance. Then we apply the Incremental Transformer to encode multi-turn contextual utterances. Moreover, we are the first to introduce multi-task learning to alleviate the aforementioned confusion and thus further improve the emotion recognition performance. Extensive experimental results show that our KAITML model outperforms the state-of-the-art models across five benchmark datasets.</abstract>
      <url hash="d02dc5d3">2020.coling-main.392</url>
    </paper>
    <paper id="393">
      <title><fixed-case>MEISD</fixed-case>: A Multimodal Multi-Label Emotion, Intensity and Sentiment Dialogue Dataset for Emotion Recognition and Sentiment Analysis in Conversations</title>
      <author><first>Mauajama</first><last>Firdaus</last></author>
      <author><first>Hardik</first><last>Chauhan</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>4441–4453</pages>
      <abstract>Emotion and sentiment classification in dialogues is a challenging task that has gained popularity in recent times. Humans tend to have multiple emotions with varying intensities while expressing their thoughts and feelings. Emotions in an utterance of dialogue can either be independent or dependent on the previous utterances, thus making the task complex and interesting. Multi-label emotion detection in conversations is a significant task that provides the ability to the system to understand the various emotions of the users interacting. Sentiment analysis in dialogue/conversation, on the other hand, helps in understanding the perspective of the user with respect to the ongoing conversation. Along with text, additional information in the form of audio and video assist in identifying the correct emotions with the appropriate intensity and sentiments in an utterance of a dialogue. Lately, quite a few datasets have been made available for dialogue emotion and sentiment classification, but these datasets are imbalanced in representing different emotions and consist of an only single emotion. Hence, we present at first a large-scale balanced Multimodal Multi-label Emotion, Intensity, and Sentiment Dialogue dataset (MEISD), collected from different TV series that has textual, audio and visual features, and then establish a baseline setup for further research.</abstract>
      <url hash="373068df">2020.coling-main.393</url>
    </paper>
    <paper id="394">
      <title><fixed-case>E</fixed-case>mp<fixed-case>DG</fixed-case>: Multi-resolution Interactive Empathetic Dialogue Generation</title>
      <author><first>Qintong</first><last>Li</last></author>
      <author><first>Hongshen</first><last>Chen</last></author>
      <author><first>Zhaochun</first><last>Ren</last></author>
      <author><first>Pengjie</first><last>Ren</last></author>
      <author><first>Zhaopeng</first><last>Tu</last></author>
      <author><first>Zhumin</first><last>Chen</last></author>
      <pages>4454–4466</pages>
      <abstract>A humanized dialogue system is expected to generate empathetic replies, which should be sensitive to the users’ expressed emotion. The task of empathetic dialogue generation is proposed to address this problem. The essential challenges lie in accurately capturing the nuances of human emotion and considering the potential of user feedback, which are overlooked by the majority of existing work. In response to this problem, we propose a multi-resolution adversarial model – EmpDG, to generate more empathetic responses. EmpDG exploits both the coarse-grained dialogue-level and fine-grained token-level emotions, the latter of which helps to better capture the nuances of user emotion. In addition, we introduce an interactive adversarial learning framework which exploits the user feedback, to identify whether the generated responses evoke emotion perceptivity in dialogues. Experimental results show that the proposed approach significantly outperforms the state-of-the-art baselines in both content quality and emotion perceptivity.</abstract>
      <url hash="fecaf50f">2020.coling-main.394</url>
    </paper>
    <paper id="395">
      <title>Leveraging Discourse Rewards for Document-Level Neural Machine Translation</title>
      <author><first>Inigo</first><last>Jauregi Unanue</last></author>
      <author><first>Nazanin</first><last>Esmaili</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <author><first>Massimo</first><last>Piccardi</last></author>
      <pages>4467–4482</pages>
      <abstract>Document-level machine translation focuses on the translation of entire documents from a source to a target language. It is widely regarded as a challenging task since the translation of the individual sentences in the document needs to retain aspects of the discourse at document level. However, document-level translation models are usually not trained to explicitly ensure discourse quality. Therefore, in this paper we propose a training approach that explicitly optimizes two established discourse metrics, lexical cohesion and coherence, by using a reinforcement learning objective. Experiments over four different language pairs and three translation domains have shown that our training approach has been able to achieve more cohesive and coherent document translations than other competitive approaches, yet without compromising the faithfulness to the reference translation. In the case of the Zh-En language pair, our method has achieved an improvement of 2.46 percentage points (pp) in LC and 1.17 pp in COH over the runner-up, while at the same time improving 0.63 pp in BLEU score and 0.47 pp in F-BERT.</abstract>
      <url hash="729d0952">2020.coling-main.395</url>
    </paper>
    <paper id="396">
      <title>Effective Use of Target-side Context for Neural Machine Translation</title>
      <author><first>Hideya</first><last>Mino</last></author>
      <author><first>Hitoshi</first><last>Ito</last></author>
      <author><first>Isao</first><last>Goto</last></author>
      <author><first>Ichiro</first><last>Yamada</last></author>
      <author><first>Takenobu</first><last>Tokunaga</last></author>
      <pages>4483–4494</pages>
      <abstract>In this paper, we deal with two problems in Japanese-English machine translation of news articles. The first problem is the quality of parallel corpora. Neural machine translation (NMT) systems suffer degraded performance when trained with noisy data. Because there is no clean Japanese-English parallel data for news articles, we build a novel parallel news corpus consisting of Japanese news articles translated into English in a content-equivalent manner. This is the first content-equivalent Japanese-English news corpus translated specifically for training NMT systems. The second problem involves the domain-adaptation technique. NMT systems suffer degraded performance when trained with mixed data having different features, such as noisy data and clean data. Though the existing methods try to overcome this problem by using tags for distinguishing the differences between corpora, it is not sufficient. We thus extend a domain-adaptation method using multi-tags to train an NMT model effectively with the clean corpus and existing parallel news corpora with some types of noise. Experimental results show that our corpus increases the translation quality, and that our domain-adaptation method is more effective for learning with the multiple types of corpora than existing domain-adaptation methods are.</abstract>
      <url hash="9b223a17">2020.coling-main.396</url>
    </paper>
    <paper id="397">
      <title>Knowledge Graph Enhanced Neural Machine Translation via Multi-task Learning on Sub-entity Granularity</title>
      <author><first>Yang</first><last>Zhao</last></author>
      <author><first>Lu</first><last>Xiang</last></author>
      <author><first>Junnan</first><last>Zhu</last></author>
      <author><first>Jiajun</first><last>Zhang</last></author>
      <author><first>Yu</first><last>Zhou</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <pages>4495–4505</pages>
      <abstract>Previous studies combining knowledge graph (KG) with neural machine translation (NMT) have two problems: i) Knowledge under-utilization: they only focus on the entities that appear in both KG and training sentence pairs, making much knowledge in KG unable to be fully utilized. ii) Granularity mismatch: the current KG methods utilize the entity as the basic granularity, while NMT utilizes the sub-word as the granularity, making the KG different to be utilized in NMT. To alleviate above problems, we propose a multi-task learning method on sub-entity granularity. Specifically, we first split the entities in KG and sentence pairs into sub-entity granularity by using joint BPE. Then we utilize the multi-task learning to combine the machine translation task and knowledge reasoning task. The extensive experiments on various translation tasks have demonstrated that our method significantly outperforms the baseline models in both translation quality and handling the entities.</abstract>
      <url hash="8640b107">2020.coling-main.397</url>
    </paper>
    <paper id="398">
      <title>Is <fixed-case>MAP</fixed-case> Decoding All You Need? The Inadequacy of the Mode in Neural Machine Translation</title>
      <author><first>Bryan</first><last>Eikema</last></author>
      <author><first>Wilker</first><last>Aziz</last></author>
      <pages>4506–4520</pages>
      <abstract>Recent studies have revealed a number of pathologies of neural machine translation (NMT) systems. Hypotheses explaining these mostly suggest there is something fundamentally wrong with NMT as a model or its training algorithm, maximum likelihood estimation (MLE). Most of this evidence was gathered using maximum a posteriori (MAP) decoding, a decision rule aimed at identifying the highest-scoring translation, i.e. the mode. We argue that the evidence corroborates the inadequacy of MAP decoding more than casts doubt on the model and its training algorithm. In this work, we show that translation distributions do reproduce various statistics of the data well, but that beam search strays from such statistics. We show that some of the known pathologies and biases of NMT are due to MAP decoding and not to NMT’s statistical assumptions nor MLE. In particular, we show that the most likely translations under the model accumulate so little probability mass that the mode can be considered essentially arbitrary. We therefore advocate for the use of decision rules that take into account the translation distribution holistically. We show that an approximation to minimum Bayes risk decoding gives competitive results confirming that NMT models do capture important aspects of translation well in expectation.</abstract>
      <url hash="97fe9a27">2020.coling-main.398</url>
    </paper>
    <paper id="399">
      <title>Domain Transfer based Data Augmentation for Neural Query Translation</title>
      <author><first>Liang</first><last>Yao</last></author>
      <author><first>Baosong</first><last>Yang</last></author>
      <author><first>Haibo</first><last>Zhang</last></author>
      <author><first>Boxing</first><last>Chen</last></author>
      <author><first>Weihua</first><last>Luo</last></author>
      <pages>4521–4533</pages>
      <abstract>Query translation (QT) serves as a critical factor in successful cross-lingual information retrieval (CLIR). Due to the lack of parallel query samples, neural-based QT models are usually optimized with synthetic data which are derived from large-scale monolingual queries. Nevertheless, such kind of pseudo corpus is mostly produced by a general-domain translation model, making it be insufficient to guide the learning of QT model. In this paper, we extend the data augmentation with a domain transfer procedure, thus to revise synthetic candidates to search-aware examples. Specifically, the domain transfer model is built upon advanced Transformer, in which layer coordination and mixed attention are exploited to speed up the refining process and leverage parameters from a pre-trained cross-lingual language model. In order to examine the effectiveness of the proposed method, we collected French-to-English and Spanish-to-English QT test sets, each of which consists of 10,000 parallel query pairs with careful manual-checking. Qualitative and quantitative analyses reveal that our model significantly outperforms strong baselines and the related domain transfer methods on both translation quality and retrieval accuracy.</abstract>
      <url hash="b4be3e4c">2020.coling-main.399</url>
    </paper>
    <paper id="400">
      <title>Living Machines: A study of atypical animacy</title>
      <author><first>Mariona</first><last>Coll Ardanuy</last></author>
      <author><first>Federico</first><last>Nanni</last></author>
      <author><first>Kaspar</first><last>Beelen</last></author>
      <author><first>Kasra</first><last>Hosseini</last></author>
      <author><first>Ruth</first><last>Ahnert</last></author>
      <author><first>Jon</first><last>Lawrence</last></author>
      <author><first>Katherine</first><last>McDonough</last></author>
      <author><first>Giorgia</first><last>Tolfo</last></author>
      <author><first>Daniel CS</first><last>Wilson</last></author>
      <author><first>Barbara</first><last>McGillivray</last></author>
      <pages>4534–4545</pages>
      <abstract>This paper proposes a new approach to animacy detection, the task of determining whether an entity is represented as animate in a text. In particular, this work is focused on atypical animacy and examines the scenario in which typically inanimate objects, specifically machines, are given animate attributes. To address it, we have created the first dataset for atypical animacy detection, based on nineteenth-century sentences in English, with machines represented as either animate or inanimate. Our method builds on recent innovations in language modeling, specifically BERT contextualized word embeddings, to better capture fine-grained contextual properties of words. We present a fully unsupervised pipeline, which can be easily adapted to different contexts, and report its performance on an established animacy dataset and our newly introduced resource. We show that our method provides a substantially more accurate characterization of atypical animacy, especially when applied to highly complex forms of language use.</abstract>
      <url hash="23df5df9">2020.coling-main.400</url>
    </paper>
    <paper id="401">
      <title>Aspectuality Across Genre: A Distributional Semantics Approach</title>
      <author><first>Thomas</first><last>Kober</last></author>
      <author><first>Malihe</first><last>Alikhani</last></author>
      <author><first>Matthew</first><last>Stone</last></author>
      <author><first>Mark</first><last>Steedman</last></author>
      <pages>4546–4562</pages>
      <abstract>The interpretation of the lexical aspect of verbs in English plays a crucial role in tasks such as recognizing textual entailment and learning discourse-level inferences. We show that two elementary dimensions of aspectual class, states vs. events, and telic vs. atelic events, can be modelled effectively with distributional semantics. We find that a verb’s local context is most indicative of its aspectual class, and we demonstrate that closed class words tend to be stronger discriminating contexts than content words. Our approach outperforms previous work on three datasets. Further, we present a new dataset of human-human conversations annotated with lexical aspects and present experiments that show the correlation of telicity with genre and discourse goals.</abstract>
      <url hash="33cc1b13">2020.coling-main.401</url>
    </paper>
    <paper id="402">
      <title>Rhetoric, Logic, and Dialectic: Advancing Theory-based Argument Quality Assessment in Natural Language Processing</title>
      <author><first>Anne</first><last>Lauscher</last></author>
      <author><first>Lily</first><last>Ng</last></author>
      <author><first>Courtney</first><last>Napoles</last></author>
      <author><first>Joel</first><last>Tetreault</last></author>
      <pages>4563–4574</pages>
      <abstract>Though preceding work in computational argument quality (AQ) mostly focuses on assessing overall AQ, researchers agree that writers would benefit from feedback targeting individual dimensions of argumentation theory. However, a large-scale theory-based corpus and corresponding computational models are missing. We fill this gap by conducting an extensive analysis covering three diverse domains of online argumentative writing and presenting GAQCorpus: the first large-scale English multi-domain (community Q&amp;A forums, debate forums, review forums) corpus annotated with theory-based AQ scores. We then propose the first computational approaches to theory-based assessment, which can serve as strong baselines for future work. We demonstrate the feasibility of large-scale AQ annotation, show that exploiting relations between dimensions yields performance improvements, and explore the synergies between theory-based prediction and practical AQ assessment.</abstract>
      <url hash="89c3c023">2020.coling-main.402</url>
    </paper>
    <paper id="403">
      <title>A Linguistic Perspective on Reference: Choosing a Feature Set for Generating Referring Expressions in Context</title>
      <author><first>Fahime</first><last>Same</last></author>
      <author><first>Kees</first><last>van Deemter</last></author>
      <pages>4575–4586</pages>
      <abstract>This paper reports on a structured evaluation of feature-based Machine Learning algorithms for selecting the form of a referring expression in discourse context. Based on this evaluation, we selected seven feature sets from the literature, amounting to 65 distinct linguistic features. The features were then grouped into 9 broad classes. After building Random Forest models, we used Feature Importance Ranking and Sequential Forward Search methods to assess the “importance” of the features. Combining the results of the two methods, we propose a consensus feature set. The 6 features in our consensus set come from 4 different classes, namely grammatical role, inherent features of the referent, antecedent form and recency.</abstract>
      <url hash="e83273a0">2020.coling-main.403</url>
    </paper>
    <paper id="404">
      <title>Coreference information guides human expectations during natural reading</title>
      <author><first>Evan</first><last>Jaffe</last></author>
      <author><first>Cory</first><last>Shain</last></author>
      <author><first>William</first><last>Schuler</last></author>
      <pages>4587–4599</pages>
      <abstract>Models of human sentence processing effort tend to focus on costs associated with retrieving structures and discourse referents from memory (memory-based) and/or on costs associated with anticipating upcoming words and structures based on contextual cues (expectation-based) (Levy,2008). Although evidence suggests that expectation and memory may play separable roles in language comprehension (Levy et al., 2013), theories of coreference processing have largely focused on memory: how comprehenders identify likely referents of linguistic expressions. In this study, we hypothesize that coreference tracking also informs human expectations about upcoming words, and we test this hypothesis by evaluating the degree to which incremental surprisal measures generated by a novel coreference-aware semantic parser explain human response times in a naturalistic self-paced reading experiment. Results indicate (1) that coreference information indeed guides human expectations and (2) that coreference effects on memory retrieval may exist independently of coreference effects on expectations. Together, these findings suggest that the language processing system exploits coreference information both to retrieve referents from memory and to anticipate upcoming material.</abstract>
      <url hash="c484a5af">2020.coling-main.404</url>
    </paper>
    <paper id="405">
      <title>Interactive Word Completion for Morphologically Complex Languages</title>
      <author><first>William</first><last>Lane</last></author>
      <author><first>Steven</first><last>Bird</last></author>
      <pages>4600–4611</pages>
      <abstract>Text input technologies for low-resource languages support literacy, content authoring, and language learning. However, tasks such as word completion pose a challenge for morphologically complex languages thanks to the combinatorial explosion of possible words. We have developed a method for morphologically-aware text input in Kunwinjku, a polysynthetic language of northern Australia. We modify an existing finite state recognizer to map input morph prefixes to morph completions, respecting the morphosyntax and morphophonology of the language. We demonstrate the portability of the method by applying it to Turkish. We show that the space of proximal morph completions is many orders of magnitude smaller than the space of full word completions for Kunwinjku. We provide a visualization of the morph completion space to enable the text completion parameters to be fine-tuned. Finally, we report on a web services deployment, along with a web interface which helps users enter morphologically complex words and which retrieves corresponding entries from the lexicon.</abstract>
      <url hash="66264a5b">2020.coling-main.405</url>
    </paper>
    <paper id="406">
      <title>Joint <fixed-case>P</fixed-case>ersian Word Segmentation Correction and Zero-Width Non-Joiner Recognition Using <fixed-case>BERT</fixed-case></title>
      <author><first>Ehsan</first><last>Doostmohammadi</last></author>
      <author><first>Minoo</first><last>Nassajian</last></author>
      <author><first>Adel</first><last>Rahimi</last></author>
      <pages>4612–4618</pages>
      <abstract>Words are properly segmented in the Persian writing system; in practice, however, these writing rules are often neglected, resulting in single words being written disjointedly and multiple words written without any white spaces between them. This paper addresses the problems of word segmentation and zero-width non-joiner (ZWNJ) recognition in Persian, which we approach jointly as a sequence labeling problem. We achieved a macro-averaged F1-score of 92.40% on a carefully collected corpus of 500 sentences with a high level of difficulty.</abstract>
      <url hash="29114f3f">2020.coling-main.406</url>
    </paper>
    <paper id="407">
      <title>Syllable-based Neural <fixed-case>T</fixed-case>hai Word Segmentation</title>
      <author><first>Pattarawat</first><last>Chormai</last></author>
      <author><first>Ponrawee</first><last>Prasertsom</last></author>
      <author><first>Jin</first><last>Cheevaprawatdomrong</last></author>
      <author><first>Attapol</first><last>Rutherford</last></author>
      <pages>4619–4637</pages>
      <abstract>Word segmentation is a challenging pre-processing step for Thai Natural Language Processing due to the lack of explicit word boundaries.The previous systems rely on powerful neural network architecture alone and ignore linguistic substructures of Thai words. We utilize the linguistic observation that Thai strings can be segmented into syllables, which should narrow down the search space for the word boundaries and provide helpful features. Here, we propose a neural Thai Word Segmenter that uses syllable embeddings to capture linguistic constraints and uses dilated CNN filters to capture the environment of each character. Within this goal, we develop the first ML-based Thai orthographical syllable segmenter, which yields syllable embeddings to be used as features by the word segmenter. Our word segmentation system outperforms the previous state-of-the-art system in both speed and accuracy on both in-domain and out-domain datasets.</abstract>
      <url hash="dfa4aac3">2020.coling-main.407</url>
    </paper>
    <paper id="408">
      <title>Incorporating Inner-word and Out-word Features for <fixed-case>M</fixed-case>ongolian Morphological Segmentation</title>
      <author><first>Na</first><last>Liu</last></author>
      <author><first>Xiangdong</first><last>Su</last></author>
      <author><first>Haoran</first><last>Zhang</last></author>
      <author><first>Guanglai</first><last>Gao</last></author>
      <author><first>Feilong</first><last>Bao</last></author>
      <pages>4638–4648</pages>
      <abstract>Mongolian morphological segmentation is regarded as a crucial preprocessing step in many Mongolian related NLP applications and has received extensive attention. Recently, end-to-end segmentation approaches with long short-term memory networks (LSTM) have achieved excellent results. However, the inner-word features among characters in the word and the out-word features from context are not well utilized in the segmentation process. In this paper, we propose a neural network incorporating inner-word and out-word features for Mongolian morphological segmentation. The network consists of two encoders and one decoder. The inner-word encoder uses the self-attention mechanisms to capture the inner-word features of the target word. The out-word encoder employs a two layers BiLSTM network to extract out-word features in the sentence. Then, the decoder adopts a multi-head double attention layer to fuse the inner-word features and out-word features and produces the segmentation result. The evaluation experiment compares the proposed network with the baselines and explores the effectiveness of the sub-modules.</abstract>
      <url hash="ff8a60c1">2020.coling-main.408</url>
    </paper>
    <paper id="409">
      <title>Morphological disambiguation from stemming data</title>
      <author><first>Antoine</first><last>Nzeyimana</last></author>
      <pages>4649–4660</pages>
      <abstract>Morphological analysis and disambiguation is an important task and a crucial preprocessing step in natural language processing of morphologically rich languages. Kinyarwanda, a morphologically rich language, currently lacks tools for automated morphological analysis. While linguistically curated finite state tools can be easily developed for morphological analysis, the morphological richness of the language allows many ambiguous analyses to be produced, requiring effective disambiguation. In this paper, we propose learning to morphologically disambiguate Kinyarwanda verbal forms from a new stemming dataset collected through crowd-sourcing. Using feature engineering and a feed-forward neural network based classifier, we achieve about 89% non-contextualized disambiguation accuracy. Our experiments reveal that inflectional properties of stems and morpheme association rules are the most discriminative features for disambiguation.</abstract>
      <url hash="da1e0d78">2020.coling-main.409</url>
    </paper>
    <paper id="410">
      <title>Revitalization of Indigenous Languages through Pre-processing and Neural Machine Translation: The case of <fixed-case>I</fixed-case>nuktitut</title>
      <author><first>Tan</first><last>Ngoc Le</last></author>
      <author><first>Fatiha</first><last>Sadat</last></author>
      <pages>4661–4666</pages>
      <abstract>Indigenous languages have been very challenging when dealing with NLP tasks and applications because of multiple reasons. These languages, in linguistic typology, are polysynthetic and highly inflected with rich morphophonemics and variable dialectal-dependent spellings; which affected studies on any NLP task in the recent years. Moreover, Indigenous languages have been considered as low-resource and/or endangered; which poses a great challenge for research related to Artificial Intelligence and its fields, such as NLP and machine learning. In this paper, we propose a study on the Inuktitut language through pre-processing and neural machine translation, in order to revitalize the language which belongs to the Inuit family, a type of polysynthetic languages spoken in Northern Canada. Our focus is concentrated on: (1) the preprocessing phase, and (2) applications on specific NLP tasks such as morphological analysis and neural machine translation, both for Indigenous languages of Canada. Our evaluations in the context of lowresource Inuktitut-English Neural Machine Translation, showed significant improvements of the proposed approach compared to the state-of-the-art.</abstract>
      <url hash="812cf396">2020.coling-main.410</url>
    </paper>
    <paper id="411">
      <title>Semi-supervised <fixed-case>URL</fixed-case> Segmentation with Recurrent Neural Networks Pre-trained on Knowledge Graph Entities</title>
      <author><first>Hao</first><last>Zhang</last></author>
      <author><first>Jae</first><last>Ro</last></author>
      <author><first>Richard</first><last>Sproat</last></author>
      <pages>4667–4675</pages>
      <abstract>Breaking domain names such as openresearch into component words open and research is important for applications like Text-to-Speech synthesis and web search. We link this problem to the classic problem of Chinese word segmentation and show the effectiveness of a tagging model based on Recurrent Neural Networks (RNNs) using characters as input. To compensate for the lack of training data, we propose a pre-training method on concatenated entity names in a large knowledge database. Pre-training improves the model by 33% and brings the sequence accuracy to 85%.</abstract>
      <url hash="12db9bed">2020.coling-main.411</url>
    </paper>
    <paper id="412">
      <title>Utilizing Subword Entities in Character-Level Sequence-to-Sequence Lemmatization Models</title>
      <author><first>Nasser</first><last>Zalmout</last></author>
      <author><first>Nizar</first><last>Habash</last></author>
      <pages>4676–4682</pages>
      <abstract>In this paper we present a character-level sequence-to-sequence lemmatization model, utilizing several subword features in multiple configurations. In addition to generic n-gram embeddings (using FastText), we experiment with concatenative (stems) and templatic (roots and patterns) morphological subwords. We present several architectures that embed these features directly at the encoder side, or learn them jointly at the decoder side with a multitask learning architecture. The results indicate that using the generic n-gram embeddings (through FastText) outperform the other linguistically-driven subwords. We use Modern Standard Arabic and Egyptian Arabic as test cases, with up to 22% and 13% relative error reduction, respectively, from a strong baseline. An error analysis shows that our best system is even able to handle word/lemma pairs that are both unseen in the training data.</abstract>
      <url hash="3939d51e">2020.coling-main.412</url>
    </paper>
    <paper id="413">
      <title><fixed-case>W</fixed-case>iktionary Normalization of Translations and Morphological Information</title>
      <author><first>Winston</first><last>Wu</last></author>
      <author><first>David</first><last>Yarowsky</last></author>
      <pages>4683–4692</pages>
      <abstract>We extend the Yawipa Wiktionary Parser (Wu and Yarowsky, 2020) to extract and normalize translations from etymology glosses, and morphological form-of relations, resulting in 300K unique translations and over 4 million instances of 168 annotated morphological relations. We propose a method to identify typos in translation annotations. Using the extracted morphological data, we develop multilingual neural models for predicting three types of word formation—clipping, contraction, and eye dialect—and improve upon a standard attention baseline by using copy attention.</abstract>
      <url hash="ebdc58a0">2020.coling-main.413</url>
    </paper>
    <paper id="414">
      <title>Detecting Urgency Status of Crisis Tweets: A Transfer Learning Approach for Low Resource Languages</title>
      <author><first>Efsun</first><last>Sarioglu Kayi</last></author>
      <author><first>Linyong</first><last>Nan</last></author>
      <author><first>Bohan</first><last>Qu</last></author>
      <author><first>Mona</first><last>Diab</last></author>
      <author><first>Kathleen</first><last>McKeown</last></author>
      <pages>4693–4703</pages>
      <abstract>We release an urgency dataset that consists of English tweets relating to natural crises, along with annotations of their corresponding urgency status. Additionally, we release evaluation datasets for two low-resource languages, i.e. Sinhala and Odia, and demonstrate an effective zero-shot transfer from English to these two languages by training cross-lingual classifiers. We adopt cross-lingual embeddings constructed using different methods to extract features of the tweets, including a few state-of-the-art contextual embeddings such as BERT, RoBERTa and XLM-R. We train classifiers of different architectures on the extracted features. We also explore semi-supervised approaches by utilizing unlabeled tweets and experiment with ensembling different classifiers. With very limited amounts of labeled data in English and zero data in the low resource languages, we show a successful framework of training monolingual and cross-lingual classifiers using deep learning methods which are known to be data hungry. Specifically, we show that the recent deep contextual embeddings are also helpful when dealing with very small-scale datasets. Classifiers that incorporate RoBERTa yield the best performance for English urgency detection task, with F1 scores that are more than 25 points over our baseline classifier. For the zero-shot transfer to low resource languages, classifiers that use LASER features perform the best for Sinhala transfer while XLM-R features benefit the Odia transfer the most.</abstract>
      <url hash="6aec89a0">2020.coling-main.414</url>
    </paper>
    <paper id="415">
      <title>Cross-lingual Transfer Learning for Grammatical Error Correction</title>
      <author><first>Ikumi</first><last>Yamashita</last></author>
      <author><first>Satoru</first><last>Katsumata</last></author>
      <author><first>Masahiro</first><last>Kaneko</last></author>
      <author><first>Aizhan</first><last>Imankulova</last></author>
      <author><first>Mamoru</first><last>Komachi</last></author>
      <pages>4704–4715</pages>
      <abstract>In this study, we explore cross-lingual transfer learning in grammatical error correction (GEC) tasks. Many languages lack the resources required to train GEC models. Cross-lingual transfer learning from high-resource languages (the source models) is effective for training models of low-resource languages (the target models) for various tasks. However, in GEC tasks, the possibility of transferring grammatical knowledge (e.g., grammatical functions) across languages is not evident. Therefore, we investigate cross-lingual transfer learning methods for GEC. Our results demonstrate that transfer learning from other languages can improve the accuracy of GEC. We also demonstrate that proximity to source languages has a significant impact on the accuracy of correcting certain types of errors.</abstract>
      <url hash="bcaa2415">2020.coling-main.415</url>
    </paper>
    <paper id="416">
      <title>Emergent Communication Pretraining for Few-Shot Machine Translation</title>
      <author><first>Yaoyiran</first><last>Li</last></author>
      <author><first>Edoardo Maria</first><last>Ponti</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <pages>4716–4731</pages>
      <abstract>While state-of-the-art models that rely upon massively multilingual pretrained encoders achieve sample efficiency in downstream applications, they still require abundant amounts of unlabelled text. Nevertheless, most of the world’s languages lack such resources. Hence, we investigate a more radical form of unsupervised knowledge transfer in the absence of linguistic data. In particular, for the first time we pretrain neural networks via emergent communication from referential games. Our key assumption is that grounding communication on images—as a crude approximation of real-world environments—inductively biases the model towards learning natural languages. On the one hand, we show that this substantially benefits machine translation in few-shot settings. On the other hand, this also provides an extrinsic evaluation protocol to probe the properties of emergent languages ex vitro. Intuitively, the closer they are to natural languages, the higher the gains from pretraining on them should be. For instance, in this work we measure the influence of communication success and maximum sequence length on downstream performances. Finally, we introduce a customised adapter layer and annealing strategies for the regulariser of maximum-a-posteriori inference during fine-tuning. These turn out to be crucial to facilitate knowledge transfer and prevent catastrophic forgetting. Compared to a recurrent baseline, our method yields gains of 59.0% 147.6% in BLEU score with only 500 NMT training instances and 65.1% 196.7% with 1,000 NMT training instances across four language pairs. These proof-of-concept results reveal the potential of emergent communication pretraining for both natural language processing tasks in resource-poor settings and extrinsic evaluation of artificial languages.</abstract>
      <url hash="d61443d8">2020.coling-main.416</url>
    </paper>
    <paper id="417">
      <title><fixed-case>C</fixed-case>ontra<fixed-case>CAT</fixed-case>: Contrastive Coreference Analytical Templates for Machine Translation</title>
      <author><first>Dario</first><last>Stojanovski</last></author>
      <author><first>Benno</first><last>Krojer</last></author>
      <author><first>Denis</first><last>Peskov</last></author>
      <author><first>Alexander</first><last>Fraser</last></author>
      <pages>4732–4749</pages>
      <abstract>Recent high scores on pronoun translation using context-aware neural machine translation have suggested that current approaches work well. ContraPro is a notable example of a contrastive challenge set for English→German pronoun translation. The high scores achieved by transformer models may suggest that they are able to effectively model the complicated set of inferences required to carry out pronoun translation. This entails the ability to determine which entities could be referred to, identify which entity a source-language pronoun refers to (if any), and access the target-language grammatical gender for that entity. We first show through a series of targeted adversarial attacks that in fact current approaches are not able to model all of this information well. Inserting small amounts of distracting information is enough to strongly reduce scores, which should not be the case. We then create a new template test set ContraCAT, designed to individually assess the ability to handle the specific steps necessary for successful pronoun translation. Our analyses show that current approaches to context-aware NMT rely on a set of surface heuristics, which break down when translations require real reasoning. We also propose an approach for augmenting the training data, with some improvements.</abstract>
      <url hash="c310e6b8">2020.coling-main.417</url>
    </paper>
    <paper id="418">
      <title><fixed-case>S</fixed-case>pan<fixed-case>A</fixed-case>lign: Sentence Alignment Method based on Cross-Language Span Prediction and <fixed-case>ILP</fixed-case></title>
      <author><first>Katsuki</first><last>Chousa</last></author>
      <author><first>Masaaki</first><last>Nagata</last></author>
      <author><first>Masaaki</first><last>Nishino</last></author>
      <pages>4750–4761</pages>
      <abstract>We propose a novel method of automatic sentence alignment from noisy parallel documents. We first formalize the sentence alignment problem as the independent predictions of spans in the target document from sentences in the source document. We then introduce a total optimization method using integer linear programming to prevent span overlapping and obtain non-monotonic alignments. We implement cross-language span prediction by fine-tuning pre-trained multilingual language models based on BERT architecture and train them using pseudo-labeled data obtained from unsupervised sentence alignment method. While the baseline methods use sentence embeddings and assume monotonic alignment, our method can capture the token-to-token interaction between the tokens of source and target text and handle non-monotonic alignments. In sentence alignment experiments on English-Japanese, our method achieved 70.3 F1 scores, which are +8.0 points higher than the baseline method. In particular, our method improved by +53.9 F1 scores for extracting non-parallel sentences. Our method improved the downstream machine translation accuracy by 4.1 BLEU scores when the extracted bilingual sentences are used for fine-tuning a pre-trained Japanese-to-English translation model.</abstract>
      <url hash="5927fe9c">2020.coling-main.418</url>
    </paper>
    <paper id="419">
      <title><fixed-case>CLUE</fixed-case>: A <fixed-case>C</fixed-case>hinese Language Understanding Evaluation Benchmark</title>
      <author><first>Liang</first><last>Xu</last></author>
      <author><first>Hai</first><last>Hu</last></author>
      <author><first>Xuanwei</first><last>Zhang</last></author>
      <author><first>Lu</first><last>Li</last></author>
      <author><first>Chenjie</first><last>Cao</last></author>
      <author><first>Yudong</first><last>Li</last></author>
      <author><first>Yechen</first><last>Xu</last></author>
      <author><first>Kai</first><last>Sun</last></author>
      <author><first>Dian</first><last>Yu</last></author>
      <author><first>Cong</first><last>Yu</last></author>
      <author><first>Yin</first><last>Tian</last></author>
      <author><first>Qianqian</first><last>Dong</last></author>
      <author><first>Weitang</first><last>Liu</last></author>
      <author><first>Bo</first><last>Shi</last></author>
      <author><first>Yiming</first><last>Cui</last></author>
      <author><first>Junyi</first><last>Li</last></author>
      <author><first>Jun</first><last>Zeng</last></author>
      <author><first>Rongzhao</first><last>Wang</last></author>
      <author><first>Weijian</first><last>Xie</last></author>
      <author><first>Yanting</first><last>Li</last></author>
      <author><first>Yina</first><last>Patterson</last></author>
      <author><first>Zuoyu</first><last>Tian</last></author>
      <author><first>Yiwen</first><last>Zhang</last></author>
      <author><first>He</first><last>Zhou</last></author>
      <author><first>Shaoweihua</first><last>Liu</last></author>
      <author><first>Zhe</first><last>Zhao</last></author>
      <author><first>Qipeng</first><last>Zhao</last></author>
      <author><first>Cong</first><last>Yue</last></author>
      <author><first>Xinrui</first><last>Zhang</last></author>
      <author><first>Zhengliang</first><last>Yang</last></author>
      <author><first>Kyle</first><last>Richardson</last></author>
      <author><first>Zhenzhong</first><last>Lan</last></author>
      <pages>4762–4772</pages>
      <abstract>The advent of natural language understanding (NLU) benchmarks for English, such as GLUE and SuperGLUE allows new NLU models to be evaluated across a diverse set of tasks. These comprehensive benchmarks have facilitated a broad range of research and applications in natural language processing (NLP). The problem, however, is that most such benchmarks are limited to English, which has made it difficult to replicate many of the successes in English NLU for other languages. To help remedy this issue, we introduce the first large-scale Chinese Language Understanding Evaluation (CLUE) benchmark. CLUE is an open-ended, community-driven project that brings together 9 tasks spanning several well-established single-sentence/sentence-pair classification tasks, as well as machine reading comprehension, all on original Chinese text. To establish results on these tasks, we report scores using an exhaustive set of current state-of-the-art pre-trained Chinese models (9 in total). We also introduce a number of supplementary datasets and additional tools to help facilitate further progress on Chinese NLU. Our benchmark is released at https://www.cluebenchmarks.com</abstract>
      <url hash="dafc82b6">2020.coling-main.419</url>
    </paper>
    <paper id="420">
      <title>A Human Evaluation of <fixed-case>AMR</fixed-case>-to-<fixed-case>E</fixed-case>nglish Generation Systems</title>
      <author><first>Emma</first><last>Manning</last></author>
      <author><first>Shira</first><last>Wein</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>4773–4786</pages>
      <abstract>Most current state-of-the art systems for generating English text from Abstract Meaning Representation (AMR) have been evaluated only using automated metrics, such as BLEU, which are known to be problematic for natural language generation. In this work, we present the results of a new human evaluation which collects fluency and adequacy scores, as well as categorization of error types, for several recent AMR generation systems. We discuss the relative quality of these systems and how our results compare to those of automatic metrics, finding that while the metrics are mostly successful in ranking systems overall, collecting human judgments allows for more nuanced comparisons. We also analyze common errors made by these systems.</abstract>
      <url hash="783ef6da">2020.coling-main.420</url>
    </paper>
    <paper id="421">
      <title>Identifying Annotator Bias: A new <fixed-case>IRT</fixed-case>-based method for bias identification</title>
      <author><first>Jacopo</first><last>Amidei</last></author>
      <author><first>Paul</first><last>Piwek</last></author>
      <author><first>Alistair</first><last>Willis</last></author>
      <pages>4787–4797</pages>
      <abstract>A basic step in any annotation effort is the measurement of the Inter Annotator Agreement (IAA). An important factor that can affect the IAA is the presence of annotator bias. In this paper we introduce a new interpretation and application of the Item Response Theory (IRT) to detect annotators’ bias. Our interpretation of IRT offers an original bias identification method that can be used to compare annotators’ bias and characterise annotation disagreement. Our method can be used to spot outlier annotators, improve annotation guidelines and provide a better picture of the annotation reliability. Additionally, because scales for IAA interpretation are not generally agreed upon, our bias identification method is valuable as a complement to the IAA value which can help with understanding the annotation disagreement.</abstract>
      <url hash="63d61fad">2020.coling-main.421</url>
    </paper>
    <paper id="422">
      <title>Would you describe a leopard as yellow? Evaluating crowd-annotations with justified and informative disagreement</title>
      <author><first>Pia</first><last>Sommerauer</last></author>
      <author><first>Antske</first><last>Fokkens</last></author>
      <author><first>Piek</first><last>Vossen</last></author>
      <pages>4798–4809</pages>
      <abstract>Semantic annotation tasks contain ambiguity and vagueness and require varying degrees of world knowledge. Disagreement is an important indication of these phenomena. Most traditional evaluation methods, however, critically hinge upon the notion of inter-annotator agreement. While alternative frameworks have been proposed, they do not move beyond agreement as the most important indicator of quality. Critically, evaluations usually do not distinguish between instances in which agreement is expected and instances in which disagreement is not only valid but desired because it captures the linguistic and cognitive phenomena in the data. We attempt to overcome these limitations using the example of a dataset that provides semantic representations for diagnostic experiments on language models. Ambiguity, vagueness, and difficulty are not only highly relevant for this use-case, but also play an important role in other types of semantic annotation tasks. We establish an additional, agreement-independent quality metric based on answer-coherence and evaluate it in comparison to existing metrics. We compare against a gold standard and evaluate on expected disagreement. Despite generally low agreement, annotations follow expected behavior and have high accuracy when selected based on coherence. We show that combining different quality metrics enables a more comprehensive evaluation than relying exclusively on agreement.</abstract>
      <url hash="494e4d27">2020.coling-main.422</url>
    </paper>
    <paper id="423">
      <title>Manual Clustering and Spatial Arrangement of Verbs for Multilingual Evaluation and Typology Analysis</title>
      <author><first>Olga</first><last>Majewska</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <author><first>Diana</first><last>McCarthy</last></author>
      <author><first>Anna</first><last>Korhonen</last></author>
      <pages>4810–4824</pages>
      <abstract>We present the first evaluation of the applicability of a spatial arrangement method (SpAM) to a typologically diverse language sample, and its potential to produce semantic evaluation resources to support multilingual NLP, with a focus on verb semantics. We demonstrate SpAM’s utility in allowing for quick bottom-up creation of large-scale evaluation datasets that balance cross-lingual alignment with language specificity. Starting from a shared sample of 825 English verbs, translated into Chinese, Japanese, Finnish, Polish, and Italian, we apply a two-phase annotation process which produces (i) semantic verb classes and (ii) fine-grained similarity scores for nearly 130 thousand verb pairs. We use the two types of verb data to (a) examine cross-lingual similarities and variation, and (b) evaluate the capacity of static and contextualised representation models to accurately reflect verb semantics, contrasting the performance of large language specific pretraining models with their multilingual equivalent on semantic clustering and lexical similarity, across different domains of verb meaning. We release the data from both phases as a large-scale multilingual resource, comprising 85 verb classes and nearly 130k pairwise similarity scores, offering a wealth of possibilities for further evaluation and research on multilingual verb semantics.</abstract>
      <url hash="d04c6a2a">2020.coling-main.423</url>
    </paper>
    <paper id="424">
      <title>Hierarchical Trivia Fact Extraction from <fixed-case>W</fixed-case>ikipedia Articles</title>
      <author><first>Jingun</first><last>Kwon</last></author>
      <author><first>Hidetaka</first><last>Kamigaito</last></author>
      <author><first>Young-In</first><last>Song</last></author>
      <author><first>Manabu</first><last>Okumura</last></author>
      <pages>4825–4834</pages>
      <abstract>Recently, automatic trivia fact extraction has attracted much research interest. Modern search engines have begun to provide trivia facts as the information for entities because they can motivate more user engagement. In this paper, we propose a new unsupervised algorithm that automatically mines trivia facts for a given entity. Unlike previous studies, the proposed algorithm targets at a single Wikipedia article and leverages its hierarchical structure via top-down processing. Thus, the proposed algorithm offers two distinctive advantages: it does not incur high computation time, and it provides a domain-independent approach for extracting trivia facts. Experimental results demonstrate that the proposed algorithm is over 100 times faster than the existing method which considers Wikipedia categories. Human evaluation demonstrates that the proposed algorithm can mine better trivia facts regardless of the target entity domain and outperforms the existing methods.</abstract>
      <url hash="bc3b01da">2020.coling-main.424</url>
    </paper>
    <paper id="425">
      <title>Predicting Clickbait Strength in Online Social Media</title>
      <author><first>Vijayasaradhi</first><last>Indurthi</last></author>
      <author><first>Bakhtiyar</first><last>Syed</last></author>
      <author><first>Manish</first><last>Gupta</last></author>
      <author><first>Vasudeva</first><last>Varma</last></author>
      <pages>4835–4846</pages>
      <abstract>Hoping for a large number of clicks and potentially high social shares, journalists of various news media outlets publish sensationalist headlines on social media. These headlines lure the readers to click on them and satisfy the curiosity gap in their mind. Low quality material pointed to by clickbaits leads to time wastage and annoyance for users. Even for enterprises publishing clickbaits, it hurts more than it helps as it erodes user trust, attracts wrong visitors, and produces negative signals for ranking algorithms. Hence, identifying and flagging clickbait titles is very essential. Previous work on clickbaits has majorly focused on binary classification of clickbait titles. However not all clickbaits are equally clickbaity. It is not only essential to identify a click-bait, but also to identify the intensity of the clickbait based on the strength of the clickbait. In this work, we model clickbait strength prediction as a regression problem. While previous methods have relied on traditional machine learning or vanilla recurrent neural networks, we rigorously investigate the use of transformers for clickbait strength prediction. On a benchmark dataset with ∼39K posts, our methods outperform all the existing methods in the Clickbait Challenge.</abstract>
      <url hash="6faffeca">2020.coling-main.425</url>
    </paper>
    <paper id="426">
      <title><fixed-case>GP</fixed-case>ol<fixed-case>S</fixed-case>: A Contextual Graph-Based Language Model for Analyzing Parliamentary Debates and Political Cohesion</title>
      <author><first>Ramit</first><last>Sawhney</last></author>
      <author><first>Arnav</first><last>Wadhwa</last></author>
      <author><first>Shivam</first><last>Agarwal</last></author>
      <author><first>Rajiv Ratn</first><last>Shah</last></author>
      <pages>4847–4859</pages>
      <abstract>Parliamentary debates present a valuable language resource for analyzing comprehensive options in electing representatives under a functional, free society. However, the esoteric nature of political speech coupled with non-linguistic aspects such as political cohesion between party members presents a complex and underexplored task of contextual parliamentary debate analysis. We introduce GPolS, a neural model for political speech sentiment analysis jointly exploiting both semantic language representations and relations between debate transcripts, motions, and political party members. Through experiments on real-world English data and by visualizing attention, we provide a use case of GPolS as a tool for political speech analysis and polarity prediction.</abstract>
      <url hash="c4b32a92">2020.coling-main.426</url>
    </paper>
    <paper id="427">
      <title>Measuring Correlation-to-Causation Exaggeration in Press Releases</title>
      <author><first>Bei</first><last>Yu</last></author>
      <author><first>Jun</first><last>Wang</last></author>
      <author><first>Lu</first><last>Guo</last></author>
      <author><first>Yingya</first><last>Li</last></author>
      <pages>4860–4872</pages>
      <abstract>Press releases have an increasingly strong influence on media coverage of health research; however, they have been found to contain seriously exaggerated claims that can misinform the public and undermine public trust in science. In this study we propose an NLP approach to identify exaggerated causal claims made in health press releases that report on observational studies, which are designed to establish correlational findings, but are often exaggerated as causal. We developed a new corpus and trained models that can identify causal claims in the main statements in a press release. By comparing the claims made in a press release with the corresponding claims in the original research paper, we found that 22% of press releases made exaggerated causal claims from correlational findings in observational studies. Furthermore, universities exaggerated more often than journal publishers by a ratio of 1.5 to 1. Encouragingly, the exaggeration rate has slightly decreased over the past 10 years, despite the increase of the total number of press releases. More research is needed to understand the cause of the decreasing pattern.</abstract>
      <url hash="67caa1f7">2020.coling-main.427</url>
    </paper>
    <paper id="428">
      <title>Inflating Topic Relevance with Ideology: A Case Study of Political Ideology Bias in Social Topic Detection Models</title>
      <author><first>Meiqi</first><last>Guo</last></author>
      <author><first>Rebecca</first><last>Hwa</last></author>
      <author><first>Yu-Ru</first><last>Lin</last></author>
      <author><first>Wen-Ting</first><last>Chung</last></author>
      <pages>4873–4885</pages>
      <abstract>We investigate the impact of political ideology biases in training data. Through a set of comparison studies, we examine the propagation of biases in several widely-used NLP models and its effect on the overall retrieval accuracy. Our work highlights the susceptibility of large, complex models to propagating the biases from human-selected input, which may lead to a deterioration of retrieval accuracy, and the importance of controlling for these biases. Finally, as a way to mitigate the bias, we propose to learn a text representation that is invariant to political ideology while still judging topic relevance.</abstract>
      <url hash="1727ea61">2020.coling-main.428</url>
    </paper>
    <paper id="429">
      <title>A Taxonomy of Empathetic Response Intents in Human Social Conversations</title>
      <author><first>Anuradha</first><last>Welivita</last></author>
      <author><first>Pearl</first><last>Pu</last></author>
      <pages>4886–4899</pages>
      <abstract>Open-domain conversational agents or chatbots are becoming increasingly popular in the natural language processing community. One of the challenges is enabling them to converse in an empathetic manner. Current neural response generation methods rely solely on end-to-end learning from large scale conversation data to generate dialogues. This approach can produce socially unacceptable responses due to the lack of large-scale quality data used to train the neural models. However, recent work has shown the promise of combining dialogue act/intent modelling and neural response generation. This hybrid method improves the response quality of chatbots and makes them more controllable and interpretable. A key element in dialog intent modelling is the development of a taxonomy. Inspired by this idea, we have manually labeled 500 response intents using a subset of a sizeable empathetic dialogue dataset (25K dialogues). Our goal is to produce a large-scale taxonomy for empathetic response intents. Furthermore, using lexical and machine learning methods, we automatically analysed both speaker and listener utterances of the entire dataset with identified response intents and 32 emotion categories. Finally, we use information visualization methods to summarize emotional dialogue exchange patterns and their temporal progression. These results reveal novel and important empathy patterns in human-human open-domain conversations and can serve as heuristics for hybrid approaches.</abstract>
      <url hash="ab3a8d09">2020.coling-main.429</url>
    </paper>
    <paper id="430">
      <title>A Multitask Active Learning Framework for Natural Language Understanding</title>
      <author><first>Hua</first><last>Zhu</last></author>
      <author><first>Wu</first><last>Ye</last></author>
      <author><first>Sihan</first><last>Luo</last></author>
      <author><first>Xidong</first><last>Zhang</last></author>
      <pages>4900–4914</pages>
      <abstract>Natural language understanding (NLU) aims at identifying user intent and extracting semantic slots. This requires sufficient annotating data to get considerable performance in real-world situations. Active learning (AL) has been well-studied to decrease the needed amount of the annotating data and successfully applied to NLU. However, no research has been done on investigating how the relation information between intents and slots can improve the efficiency of AL algorithms. In this paper, we propose a multitask AL framework for NLU. Our framework enables pool-based AL algorithms to make use of the relation information between sub-tasks provided by a joint model, and we propose an efficient computation for the entropy of a joint model. Experimental results show our framework can achieve competitive performance with less training data than baseline methods on all datasets. We also demonstrate that when using the entropy as the query strategy, the model with complete relation information can perform better than those with partial information. Additionally, we demonstrate that the efficiency of these active learning algorithms in our framework is still effective when incorporate with the Bidirectional Encoder Representations from Transformers (BERT).</abstract>
      <url hash="598b4453">2020.coling-main.430</url>
    </paper>
    <paper id="431">
      <title>Two-level classification for dialogue act recognition in task-oriented dialogues</title>
      <author><first>Philippe</first><last>Blache</last></author>
      <author><first>Massina</first><last>Abderrahmane</last></author>
      <author><first>Stéphane</first><last>Rauzy</last></author>
      <author><first>Magalie</first><last>Ochs</last></author>
      <author><first>Houda</first><last>Oufaida</last></author>
      <pages>4915–4925</pages>
      <abstract>Dialogue act classification becomes a complex task when dealing with fine-grain labels. Many applications require such level of labelling, typically automatic dialogue systems. We present in this paper a 2-level classification technique, distinguishing between generic and specific dialogue acts (DA). This approach makes it possible to benefit from the very good accuracy of generic DA classification at the first level and proposes an efficient approach for specific DA, based on high-level linguistic features. Our results show the interest of involving such features into the classifiers, outperforming all other feature sets, in particular those classically used in DA classification.</abstract>
      <url hash="aa005e86">2020.coling-main.431</url>
    </paper>
    <paper id="432">
      <title>Balanced Joint Adversarial Training for Robust Intent Detection and Slot Filling</title>
      <author><first>Xu</first><last>Cao</last></author>
      <author><first>Deyi</first><last>Xiong</last></author>
      <author><first>Chongyang</first><last>Shi</last></author>
      <author><first>Chao</first><last>Wang</last></author>
      <author><first>Yao</first><last>Meng</last></author>
      <author><first>Changjian</first><last>Hu</last></author>
      <pages>4926–4936</pages>
      <abstract>Joint intent detection and slot filling has recently achieved tremendous success in advancing the performance of utterance understanding. However, many joint models still suffer from the robustness problem, especially on noisy inputs or rare/unseen events. To address this issue, we propose a Joint Adversarial Training (JAT) model to improve the robustness of joint intent detection and slot filling, which consists of two parts: (1) automatically generating joint adversarial examples to attack the joint model, and (2) training the model to defend against the joint adversarial examples so as to robustify the model on small perturbations. As the generated joint adversarial examples have different impacts on the intent detection and slot filling loss, we further propose a Balanced Joint Adversarial Training (BJAT) model that applies a balance factor as a regularization term to the final loss function, which yields a stable training procedure. Extensive experiments and analyses on the lightweight models show that our proposed methods achieve significantly higher scores and substantially improve the robustness of both intent detection and slot filling. In addition, the combination of our BJAT with BERT-large achieves state-of-the-art results on two datasets.</abstract>
      <url hash="402afdc3">2020.coling-main.432</url>
    </paper>
    <paper id="433">
      <title>Reasoning Requirements for Indirect Speech Act Interpretation</title>
      <author><first>Vasanth</first><last>Sarathy</last></author>
      <author><first>Alexander</first><last>Tsuetaki</last></author>
      <author><first>Antonio</first><last>Roque</last></author>
      <author><first>Matthias</first><last>Scheutz</last></author>
      <pages>4937–4948</pages>
      <abstract>We perform a corpus analysis to develop a representation of the knowledge and reasoning used to interpret indirect speech acts. An indirect speech act (ISA) is an utterance whose intended meaning is different from its literal meaning. We focus on those speech acts in which slight changes in situational or contextual information can switch the dominant intended meaning of an utterance from direct to indirect or vice-versa. We computationalize how various contextual features can influence a speaker’s beliefs, and how these beliefs can influence the intended meaning and choice of the surface form of an utterance. We axiomatize the domain-general patterns of reasoning involved, and implement a proof-of-concept architecture using Answer Set Programming. Our model is presented as a contribution to cognitive science and psycholinguistics, so representational decisions are justified by existing theoretical work.</abstract>
      <url hash="9f3792c9">2020.coling-main.433</url>
    </paper>
    <paper id="434">
      <title>Understanding Unnatural Questions Improves Reasoning over Text</title>
      <author><first>Xiaoyu</first><last>Guo</last></author>
      <author><first>Yuan-Fang</first><last>Li</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>4949–4955</pages>
      <abstract>Complex question answering (CQA) over raw text is a challenging task. A prominent approach to this task is based on the programmer-interpreter framework, where the programmer maps the question into a sequence of reasoning actions and the interpreter then executes these actions on the raw text. Learning an effective CQA model requires large amounts of human-annotated data, consisting of the ground-truth sequence of reasoning actions, which is time-consuming and expensive to collect at scale. In this paper, we address the challenge of learning a high-quality programmer (parser) by projecting natural human-generated questions into unnatural machine-generated questions which are more convenient to parse. We firstly generate synthetic (question, action sequence) pairs by a data generator, and train a semantic parser that associates synthetic questions with their corresponding action sequences. To capture the diversity when applied to natural questions, we learn a projection model to map natural questions into their most similar unnatural questions for which the parser can work well. Without any natural training data, our projection model provides high-quality action sequences for the CQA task. Experimental results show that the QA model trained exclusively with synthetic data outperforms its state-of-the-art counterpart trained on human-labeled data.</abstract>
      <url hash="d70b1c45">2020.coling-main.434</url>
    </paper>
    <paper id="435">
      <title>An Empirical Study of Contextual Data Augmentation for <fixed-case>J</fixed-case>apanese Zero Anaphora Resolution</title>
      <author><first>Ryuto</first><last>Konno</last></author>
      <author><first>Yuichiroh</first><last>Matsubayashi</last></author>
      <author><first>Shun</first><last>Kiyono</last></author>
      <author><first>Hiroki</first><last>Ouchi</last></author>
      <author><first>Ryo</first><last>Takahashi</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <pages>4956–4968</pages>
      <abstract>One critical issue of zero anaphora resolution (ZAR) is the scarcity of labeled data. This study explores how effectively this problem can be alleviated by data augmentation. We adopt a state-of-the-art data augmentation method, called the contextual data augmentation (CDA), that generates labeled training instances using a pretrained language model. The CDA has been reported to work well for several other natural language processing tasks, including text classification and machine translation. This study addresses two underexplored issues on CDA, that is, how to reduce the computational cost of data augmentation and how to ensure the quality of the generated data. We also propose two methods to adapt CDA to ZAR: [MASK]-based augmentation and linguistically-controlled masking. Consequently, the experimental results on Japanese ZAR show that our methods contribute to both the accuracy gainand the computation cost reduction. Our closer analysis reveals that the proposed method can improve the quality of the augmented training data when compared to the conventional CDA.</abstract>
      <url hash="e0fafed8">2020.coling-main.435</url>
    </paper>
    <paper id="436">
      <title>A Large-Scale Corpus of <fixed-case>E</fixed-case>-mail Conversations with Standard and Two-Level Dialogue Act Annotations</title>
      <author><first>Motoki</first><last>Taniguchi</last></author>
      <author><first>Yoshihiro</first><last>Ueda</last></author>
      <author><first>Tomoki</first><last>Taniguchi</last></author>
      <author><first>Tomoko</first><last>Ohkuma</last></author>
      <pages>4969–4980</pages>
      <abstract>We present a large-scale corpus of e-mail conversations with domain-agnostic and two-level dialogue act (DA) annotations towards the goal of a better understanding of asynchronous conversations. We annotate over 6,000 messages and 35,000 sentences from more than 2,000 threads. For a domain-independent and application-independent DA annotations, we choose ISO standard 24617-2 as the annotation scheme. To assess the difficulty of DA recognition on our corpus, we evaluate several models, including a pre-trained contextual representation model, as our baselines. The experimental results show that BERT outperforms other neural network models, including previous state-of-the-art models, but falls short of a human performance. We also demonstrate that DA tags of two-level granularity enable a DA recognition model to learn efficiently by using multi-task learning. An evaluation of a model trained on our corpus against other domains of asynchronous conversation reveals the domain independence of our DA annotations.</abstract>
      <url hash="0a065870">2020.coling-main.436</url>
    </paper>
    <paper id="437">
      <title>Intra-/Inter-Interaction Network with Latent Interaction Modeling for Multi-turn Response Selection</title>
      <author><first>Yang</first><last>Deng</last></author>
      <author><first>Wenxuan</first><last>Zhang</last></author>
      <author><first>Wai</first><last>Lam</last></author>
      <pages>4981–4992</pages>
      <abstract>Multi-turn response selection has been extensively studied and applied to many real-world applications in recent years. However, current methods typically model the interactions between multi-turn utterances and candidate responses with iterative approaches, which is not practical as the turns of conversations vary. Besides, some latent features, such as user intent and conversation topic, are under-discovered in existing works. In this work, we propose Intra-/Inter-Interaction Network (I<tex-math>^3</tex-math>) with latent interaction modeling to comprehensively model multi-level interactions between the utterance context and the response. In specific, we first encode the intra- and inter-utterance interaction with the given response from both individual utterance and the overall utterance context. Then we develop a latent multi-view subspace clustering module to model the latent interaction between the utterance and response. Experimental results show that the proposed method substantially and consistently outperforms existing state-of-the-art methods on three multi-turn response selection benchmark datasets.</abstract>
      <url hash="6dfe5f52">2020.coling-main.437</url>
    </paper>
    <paper id="438">
      <title>Few-shot Pseudo-Labeling for Intent Detection</title>
      <author><first>Thomas</first><last>Dopierre</last></author>
      <author><first>Christophe</first><last>Gravier</last></author>
      <author><first>Julien</first><last>Subercaze</last></author>
      <author><first>Wilfried</first><last>Logerais</last></author>
      <pages>4993–5003</pages>
      <abstract>In this paper, we introduce a state-of-the-art pseudo-labeling technique for few-shot intent detection. We devise a folding/unfolding hierarchical clustering algorithm which assigns weighted pseudo-labels to unlabeled user utterances. We show that our two-step method yields significant improvement over existing solutions. This performance is achieved on multiple intent detection datasets, even in more challenging situations where the number of classes is large or when the dataset is highly imbalanced. Moreover, we confirm this results on the more general text classification task. We also demonstrate that our approach nicely complements existing solutions, thereby providing an even stronger state-of-the-art ensemble method.</abstract>
      <url hash="5bf698e5">2020.coling-main.438</url>
    </paper>
    <paper id="439">
      <title>Similarity or deeper understanding? Analyzing the <fixed-case>TED</fixed-case>-<fixed-case>Q</fixed-case> dataset of evoked questions</title>
      <author><first>Matthijs</first><last>Westera</last></author>
      <author><first>Jacopo</first><last>Amidei</last></author>
      <author><first>Laia</first><last>Mayol</last></author>
      <pages>5004–5012</pages>
      <abstract>We take a close look at a recent dataset of TED-talks annotated with the questions they implicitly evoke, TED-Q (Westera et al., 2020). We test to what extent the relation between a discourse and the questions it evokes is merely one of similarity or association, as opposed to deeper semantic/pragmatic interpretation. We do so by turning the TED-Q dataset into a binary classification task, constructing an analogous task from explicit questions we extract from the BookCorpus (Zhu et al., 2015), and fitting a BERT-based classifier alongside models based on different notions of similarity. The BERT-based classifier, achieving close to human performance, outperforms all similarity-based models, suggesting that there is more to identifying true evoked questions than plain similarity.</abstract>
      <url hash="577dcebd">2020.coling-main.439</url>
    </paper>
    <paper id="440">
      <title>Sentiment Analysis for Emotional Speech Synthesis in a News Dialogue System</title>
      <author><first>Hiroaki</first><last>Takatsu</last></author>
      <author><first>Ryota</first><last>Ando</last></author>
      <author><first>Yoichi</first><last>Matsuyama</last></author>
      <author><first>Tetsunori</first><last>Kobayashi</last></author>
      <pages>5013–5025</pages>
      <abstract>As smart speakers and conversational robots become ubiquitous, the demand for expressive speech synthesis has increased. In this paper, to control the emotional parameters of the speech synthesis according to certain dialogue contents, we construct a news dataset with emotion labels (“positive,” “negative,” or “neutral”) annotated for each sentence. We then propose a method to identify emotion labels using a model combining BERT and BiLSTM-CRF, and evaluate its effectiveness using the constructed dataset. The results showed that the classification model performance can be efficiently improved by preferentially annotating news articles with low confidence in the human-in-the-loop machine learning framework.</abstract>
      <url hash="118b954a">2020.coling-main.440</url>
    </paper>
    <paper id="441">
      <title>Adversarial Learning on the Latent Space for Diverse Dialog Generation</title>
      <author><first>Kashif</first><last>Khan</last></author>
      <author><first>Gaurav</first><last>Sahu</last></author>
      <author><first>Vikash</first><last>Balasubramanian</last></author>
      <author><first>Lili</first><last>Mou</last></author>
      <author><first>Olga</first><last>Vechtomova</last></author>
      <pages>5026–5034</pages>
      <abstract>Generating relevant responses in a dialog is challenging, and requires not only proper modeling of context in the conversation, but also being able to generate fluent sentences during inference. In this paper, we propose a two-step framework based on generative adversarial nets for generating conditioned responses. Our model first learns a meaningful representation of sentences by autoencoding, and then learns to map an input query to the response representation, which is in turn decoded as a response sentence. Both quantitative and qualitative evaluations show that our model generates more fluent, relevant, and diverse responses than existing state-of-the-art methods.</abstract>
      <url hash="b4a8c68f">2020.coling-main.441</url>
    </paper>
    <paper id="442">
      <title>Inconsistencies in Crowdsourced Slot-Filling Annotations: A Typology and Identification Methods</title>
      <author><first>Stefan</first><last>Larson</last></author>
      <author><first>Adrian</first><last>Cheung</last></author>
      <author><first>Anish</first><last>Mahendran</last></author>
      <author><first>Kevin</first><last>Leach</last></author>
      <author><first>Jonathan K.</first><last>Kummerfeld</last></author>
      <pages>5035–5046</pages>
      <abstract>Slot-filling models in task-driven dialog systems rely on carefully annotated training data. However, annotations by crowd workers are often inconsistent or contain errors. Simple solutions like manually checking annotations or having multiple workers label each sample are expensive and waste effort on samples that are correct. If we can identify inconsistencies, we can focus effort where it is needed. Toward this end, we define six inconsistency types in slot-filling annotations. Using three new noisy crowd-annotated datasets, we show that a wide range of inconsistencies occur and can impact system performance if not addressed. We then introduce automatic methods of identifying inconsistencies. Experiments on our new datasets show that these methods effectively reveal inconsistencies in data, though there is further scope for improvement.</abstract>
      <url hash="9ac4e7b0">2020.coling-main.442</url>
    </paper>
    <paper id="443">
      <title>Online Versus Offline <fixed-case>NMT</fixed-case> Quality: An In-depth Analysis on <fixed-case>E</fixed-case>nglish-<fixed-case>G</fixed-case>erman and <fixed-case>G</fixed-case>erman-<fixed-case>E</fixed-case>nglish</title>
      <author><first>Maha</first><last>Elbayad</last></author>
      <author><first>Michael</first><last>Ustaszewski</last></author>
      <author><first>Emmanuelle</first><last>Esperança-Rodier</last></author>
      <author><first>Francis</first><last>Brunet-Manquat</last></author>
      <author><first>Jakob</first><last>Verbeek</last></author>
      <author><first>Laurent</first><last>Besacier</last></author>
      <pages>5047–5058</pages>
      <abstract>We conduct in this work an evaluation study comparing offline and online neural machine translation architectures. Two sequence-to-sequence models: convolutional Pervasive Attention (Elbayad et al. 2018) and attention-based Transformer (Vaswani et al. 2017) are considered. We investigate, for both architectures, the impact of online decoding constraints on the translation quality through a carefully designed human evaluation on English-German and German-English language pairs, the latter being particularly sensitive to latency constraints. The evaluation results allow us to identify the strengths and shortcomings of each model when we shift to the online setup.</abstract>
      <url hash="3de0dc31">2020.coling-main.443</url>
    </paper>
    <paper id="444">
      <title>Informative Manual Evaluation of Machine Translation Output</title>
      <author><first>Maja</first><last>Popović</last></author>
      <pages>5059–5069</pages>
      <abstract>This work proposes a new method for manual evaluation of Machine Translation (MT) output based on marking actual issues in the translated text. The novelty is that the evaluators are not assigning any scores, nor classifying errors, but marking all problematic parts (words, phrases, sentences) of the translation. The main advantage of this method is that the resulting annotations do not only provide overall scores by counting words with assigned tags, but can be further used for analysis of errors and challenging linguistic phenomena, as well as inter-annotator disagreements. Detailed analysis and understanding of actual problems are not enabled by typical manual evaluations where the annotators are asked to assign overall scores or to rank two or more translations. The proposed method is very general: it can be applied on any genre/domain and language pair, and it can be guided by various types of quality criteria. Also, it is not restricted to MT output, but can be used for other types of generated text.</abstract>
      <url hash="3d68c0ac">2020.coling-main.444</url>
    </paper>
    <paper id="445">
      <title><fixed-case>T</fixed-case>rans<fixed-case>Q</fixed-case>uest: Translation Quality Estimation with Cross-lingual Transformers</title>
      <author><first>Tharindu</first><last>Ranasinghe</last></author>
      <author><first>Constantin</first><last>Orasan</last></author>
      <author><first>Ruslan</first><last>Mitkov</last></author>
      <pages>5070–5081</pages>
      <abstract>Recent years have seen big advances in the field of sentence-level quality estimation (QE), largely as a result of using neural-based architectures. However, the majority of these methods work only on the language pair they are trained on and need retraining for new language pairs. This process can prove difficult from a technical point of view and is usually computationally expensive. In this paper we propose a simple QE framework based on cross-lingual transformers, and we use it to implement and evaluate two different neural architectures. Our evaluation shows that the proposed methods achieve state-of-the-art results outperforming current open-source quality estimation frameworks when trained on datasets from WMT. In addition, the framework proves very useful in transfer learning settings, especially when dealing with low-resourced languages, allowing us to obtain very competitive results.</abstract>
      <url hash="b5d16bd9">2020.coling-main.445</url>
    </paper>
    <paper id="446">
      <title>Monolingual and Multilingual Reduction of Gender Bias in Contextualized Representations</title>
      <author><first>Sheng</first><last>Liang</last></author>
      <author><first>Philipp</first><last>Dufter</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>5082–5093</pages>
      <abstract>Pretrained language models (PLMs) learn stereotypes held by humans and reflected in text from their training corpora, including gender bias. When PLMs are used for downstream tasks such as picking candidates for a job, people’s lives can be negatively affected by these learned stereotypes. Prior work usually identifies a linear gender subspace and removes gender information by eliminating the subspace. Following this line of work, we propose to use DensRay, an analytical method for obtaining interpretable dense subspaces. We show that DensRay performs on-par with prior approaches, but provide arguments that it is more robust and provide indications that it preserves language model performance better. By applying DensRay to attention heads and layers of BERT we show that gender information is spread across all attention heads and most of the layers. Also we show that DensRay can obtain gender bias scores on both token and sentence levels. Finally, we demonstrate that we can remove bias multilingually, e.g., from Chinese, using only English training data.</abstract>
      <url hash="e7874a34">2020.coling-main.446</url>
    </paper>
    <paper id="447">
      <title><fixed-case>A</fixed-case>ra<fixed-case>B</fixed-case>ench: Benchmarking Dialectal <fixed-case>A</fixed-case>rabic-<fixed-case>E</fixed-case>nglish Machine Translation</title>
      <author><first>Hassan</first><last>Sajjad</last></author>
      <author><first>Ahmed</first><last>Abdelali</last></author>
      <author><first>Nadir</first><last>Durrani</last></author>
      <author><first>Fahim</first><last>Dalvi</last></author>
      <pages>5094–5107</pages>
      <abstract>Low-resource machine translation suffers from the scarcity of training data and the unavailability of standard evaluation sets. While a number of research efforts target the former, the unavailability of evaluation benchmarks remain a major hindrance in tracking the progress in low-resource machine translation. In this paper, we introduce AraBench, an evaluation suite for dialectal Arabic to English machine translation. Compared to Modern Standard Arabic, Arabic dialects are challenging due to their spoken nature, non-standard orthography, and a large variation in dialectness. To this end, we pool together already available Dialectal Arabic-English resources and additionally build novel test sets. AraBench offers 4 coarse, 15 fine-grained and 25 city-level dialect categories, belonging to diverse genres, such as media, chat, religion and travel with varying level of dialectness. We report strong baselines using several training settings: fine-tuning, back-translation and data augmentation. The evaluation suite opens a wide range of research frontiers to push efforts in low-resource machine translation, particularly Arabic dialect translation. The evaluation suite and the dialectal system are publicly available for research purposes.</abstract>
      <url hash="e98e3442">2020.coling-main.447</url>
    </paper>
    <paper id="448">
      <title>Learning to Few-Shot Learn Across Diverse Natural Language Classification Tasks</title>
      <author><first>Trapit</first><last>Bansal</last></author>
      <author><first>Rishikesh</first><last>Jha</last></author>
      <author><first>Andrew</first><last>McCallum</last></author>
      <pages>5108–5123</pages>
      <abstract>Pre-trained transformer models have shown enormous success in improving performance on several downstream tasks. However, fine-tuning on a new task still requires large amounts of task-specific labeled data to achieve good performance. We consider this problem of learning to generalize to new tasks, with a few examples, as a meta-learning problem. While meta-learning has shown tremendous progress in recent years, its application is still limited to simulated problems or problems with limited diversity across tasks. We develop a novel method, LEOPARD, which enables optimization-based meta-learning across tasks with a different number of classes, and evaluate different methods on generalization to diverse NLP classification tasks. LEOPARD is trained with the state-of-the-art transformer architecture and shows better generalization to tasks not seen at all during training, with as few as 4 examples per label. Across 17 NLP tasks, including diverse domains of entity typing, natural language inference, sentiment analysis, and several other text classification tasks, we show that LEOPARD learns better initial parameters for few-shot learning than self-supervised pre-training or multi-task training, outperforming many strong baselines, for example, yielding 14.6% average relative gain in accuracy on unseen tasks with only 4 examples per label.</abstract>
      <url hash="f90373b4">2020.coling-main.448</url>
    </paper>
    <paper id="449">
      <title>A Mixture-of-Experts Model for Learning Multi-Facet Entity Embeddings</title>
      <author><first>Rana</first><last>Alshaikh</last></author>
      <author><first>Zied</first><last>Bouraoui</last></author>
      <author><first>Shelan</first><last>Jeawak</last></author>
      <author><first>Steven</first><last>Schockaert</last></author>
      <pages>5124–5135</pages>
      <abstract>Various methods have already been proposed for learning entity embeddings from text descriptions. Such embeddings are commonly used for inferring properties of entities, for recommendation and entity-oriented search, and for injecting background knowledge into neural architectures, among others. Entity embeddings essentially serve as a compact encoding of a similarity relation, but similarity is an inherently multi-faceted notion. By representing entities as single vectors, existing methods leave it to downstream applications to identify these different facets, and to select the most relevant ones. In this paper, we propose a model that instead learns several vectors for each entity, each of which intuitively captures a different aspect of the considered domain. We use a mixture-of-experts formulation to jointly learn these facet-specific embeddings. The individual entity embeddings are learned using a variant of the GloVe model, which has the advantage that we can easily identify which properties are modelled well in which of the learned embeddings. This is exploited by an associated gating network, which uses pre-trained word vectors to encourage the properties that are modelled by a given embedding to be semantically coherent, i.e. to encourage each of the individual embeddings to capture a meaningful facet.</abstract>
      <url hash="bc4616c1">2020.coling-main.449</url>
    </paper>
    <paper id="450">
      <title>Classifier Probes May Just Learn from Linear Context Features</title>
      <author><first>Jenny</first><last>Kunz</last></author>
      <author><first>Marco</first><last>Kuhlmann</last></author>
      <pages>5136–5146</pages>
      <abstract>Classifiers trained on auxiliary probing tasks are a popular tool to analyze the representations learned by neural sentence encoders such as BERT and ELMo. While many authors are aware of the difficulty to distinguish between “extracting the linguistic structure encoded in the representations” and “learning the probing task,” the validity of probing methods calls for further research. Using a neighboring word identity prediction task, we show that the token embeddings learned by neural sentence encoders contain a significant amount of information about the exact linear context of the token, and hypothesize that, with such information, learning standard probing tasks may be feasible even without additional linguistic structure. We develop this hypothesis into a framework in which analysis efforts can be scrutinized and argue that, with current models and baselines, conclusions that representations contain linguistic structure are not well-founded. Current probing methodology, such as restricting the classifier’s expressiveness or using strong baselines, can help to better estimate the complexity of learning, but not build a foundation for speculations about the nature of the linguistic structure encoded in the learned representations.</abstract>
      <url hash="991d7e01">2020.coling-main.450</url>
    </paper>
    <paper id="451">
      <title>Priorless Recurrent Networks Learn Curiously</title>
      <author><first>Jeff</first><last>Mitchell</last></author>
      <author><first>Jeffrey</first><last>Bowers</last></author>
      <pages>5147–5158</pages>
      <abstract>Recently, domain-general recurrent neural networks, without explicit linguistic inductive biases, have been shown to successfully reproduce a range of human language behaviours, such as accurately predicting number agreement between nouns and verbs. We show that such networks will also learn number agreement within unnatural sentence structures, i.e. structures that are not found within any natural languages and which humans struggle to process. These results suggest that the models are learning from their input in a manner that is substantially different from human language acquisition, and we undertake an analysis of how the learned knowledge is stored in the weights of the network. We find that while the model has an effective understanding of singular versus plural for individual sentences, there is a lack of a unified concept of number agreement connecting these processes across the full range of inputs. Moreover, the weights handling natural and unnatural structures overlap substantially, in a way that underlines the non-human-like nature of the knowledge learned by the network.</abstract>
      <url hash="19f59145">2020.coling-main.451</url>
    </paper>
    <paper id="452">
      <title>Answer-driven Deep Question Generation based on Reinforcement Learning</title>
      <author><first>Liuyin</first><last>Wang</last></author>
      <author><first>Zihan</first><last>Xu</last></author>
      <author><first>Zibo</first><last>Lin</last></author>
      <author><first>Haitao</first><last>Zheng</last></author>
      <author><first>Ying</first><last>Shen</last></author>
      <pages>5159–5170</pages>
      <abstract>Deep question generation (DQG) aims to generate complex questions through reasoning over multiple documents. The task is challenging and underexplored. Existing methods mainly focus on enhancing document representations, with little attention paid to the answer information, which may result in the generated question not matching the answer type and being answerirrelevant. In this paper, we propose an Answer-driven Deep Question Generation (ADDQG) model based on the encoder-decoder framework. The model makes better use of the target answer as a guidance to facilitate question generation. First, we propose an answer-aware initialization module with a gated connection layer which introduces both document and answer information to the decoder, thus helping to guide the choice of answer-focused question words. Then a semantic-rich fusion attention mechanism is designed to support the decoding process, which integrates the answer with the document representations to promote the proper handling of answer information during generation. Moreover, reinforcement learning is applied to integrate both syntactic and semantic metrics as the reward to enhance the training of the ADDQG. Extensive experiments on the HotpotQA dataset show that ADDQG outperforms state-of-the-art models in both automatic and human evaluations.</abstract>
      <url hash="4bed9f79">2020.coling-main.452</url>
    </paper>
    <paper id="453">
      <title>Distinguishing Between Foreground and Background Events in News</title>
      <author><first>Mohammed</first><last>Aldawsari</last></author>
      <author><first>Adrian</first><last>Perez</last></author>
      <author><first>Deya</first><last>Banisakher</last></author>
      <author><first>Mark</first><last>Finlayson</last></author>
      <pages>5171–5180</pages>
      <abstract>Determining whether an event in a news article is a foreground or background event would be useful in many natural language processing tasks, for example, temporal relation extraction, summarization, or storyline generation. We introduce the task of distinguishing between foreground and background events in news articles as well as identifying the general temporal position of background events relative to the foreground period (past, present, future, and their combinations). We achieve good performance (0.73 F1 for background vs. foreground and temporal position, and 0.79 F1 for background vs. foreground only) on a dataset of news articles by leveraging discourse information in a featurized model. We release our implementation and annotated data for other researchers</abstract>
      <url hash="ed029fa7">2020.coling-main.453</url>
    </paper>
    <paper id="454">
      <title>Pick a Fight or Bite your Tongue: Investigation of Gender Differences in Idiomatic Language Usage</title>
      <author><first>Ella</first><last>Rabinovich</last></author>
      <author><first>Hila</first><last>Gonen</last></author>
      <author><first>Suzanne</first><last>Stevenson</last></author>
      <pages>5181–5192</pages>
      <abstract>A large body of research on gender-linked language has established foundations regarding cross-gender differences in lexical, emotional, and topical preferences, along with their sociological underpinnings. We compile a novel, large and diverse corpus of spontaneous linguistic productions annotated with speakers’ gender, and perform a first large-scale empirical study of distinctions in the usage of figurative language between male and female authors. Our analyses suggest that (1) idiomatic choices reflect gender-specific lexical and semantic preferences in general language, (2) men’s and women’s idiomatic usages express higher emotion than their literal language, with detectable, albeit more subtle, differences between male and female authors along the dimension of dominance compared to similar distinctions in their literal utterances, and (3) contextual analysis of idiomatic expressions reveals considerable differences, reflecting subtle divergences in usage environments, shaped by cross-gender communication styles and semantic biases.</abstract>
      <url hash="fa1c3a18">2020.coling-main.454</url>
    </paper>
    <paper id="455">
      <title>Intra-Correlation Encoding for <fixed-case>C</fixed-case>hinese Sentence Intention Matching</title>
      <author><first>Xu</first><last>Zhang</last></author>
      <author><first>Yifeng</first><last>Li</last></author>
      <author><first>Wenpeng</first><last>Lu</last></author>
      <author><first>Ping</first><last>Jian</last></author>
      <author><first>Guoqiang</first><last>Zhang</last></author>
      <pages>5193–5204</pages>
      <abstract>Sentence intention matching is vital for natural language understanding. Especially for Chinese sentence intention matching task, due to the ambiguity of Chinese words, semantic missing or semantic confusion are more likely to occur in the encoding process. Although the existing methods have enriched text representation through pre-trained word embedding to solve this problem, due to the particularity of Chinese text, different granularities of pre-trained word embedding will affect the semantic description of a piece of text. In this paper, we propose an effective approach that combines character-granularity and word-granularity features to perform sentence intention matching, and we utilize soft alignment attention to enhance the local information of sentences on the corresponding levels. The proposed method can capture sentence feature information from multiple perspectives and correlation information between different levels of sentences. By evaluating on BQ and LCQMC datasets, our model has achieved remarkable results, and demonstrates better or comparable performance with BERT-based models.</abstract>
      <url hash="34fc65e8">2020.coling-main.455</url>
    </paper>
    <paper id="456">
      <title>Explain by Evidence: An Explainable Memory-based Neural Network for Question Answering</title>
      <author><first>Quan Hung</first><last>Tran</last></author>
      <author><first>Nhan</first><last>Dam</last></author>
      <author><first>Tuan</first><last>Lai</last></author>
      <author><first>Franck</first><last>Dernoncourt</last></author>
      <author><first>Trung</first><last>Le</last></author>
      <author><first>Nham</first><last>Le</last></author>
      <author><first>Dinh</first><last>Phung</last></author>
      <pages>5205–5210</pages>
      <abstract>Interpretability and explainability of deep neural net models are always challenging due to their size and complexity. Many previous works focused on visualizing internal components of neural networks to represent them through human-friendly concepts. On the other hand, in real life, when making a decision, human tends to rely on similar situations in the past. Thus, we argue that one potential approach to make the model interpretable and explainable is to design it in a way such that the model explicitly connects the current sample with the seen samples, and bases its decision on these samples. In this work, we design one such model: an explainable, evidence-based memory network architecture, which learns to summarize the dataset and extract supporting evidences to make its decision. The model achieves state-of-the-art performance on two popular question answering datasets, the TrecQA dataset and the WikiQA dataset. Via further analysis, we showed that this model can reliably trace the errors it has made in the validation step to the training instances that might have caused this error. We believe that this error-tracing capability might be beneficial in improving dataset quality in many applications.</abstract>
      <url hash="012ae11e">2020.coling-main.456</url>
    </paper>
    <paper id="457">
      <title>A Study on Efficiency, Accuracy and Document Structure for Answer Sentence Selection</title>
      <author><first>Daniele</first><last>Bonadiman</last></author>
      <author><first>Alessandro</first><last>Moschitti</last></author>
      <pages>5211–5222</pages>
      <abstract>An essential task of most Question Answering (QA) systems is to re-rank the set of answer candidates, i.e., Answer Sentence Selection (AS2). These candidates are typically sentences either extracted from one or more documents preserving their natural order or retrieved by a search engine. Most state-of-the-art approaches to the task use huge neural models, such as BERT, or complex attentive architectures. In this paper, we argue that by exploiting the intrinsic structure of the original rank together with an effective word-relatedness encoder, we achieve the highest accuracy among the cost-efficient models, with two orders of magnitude fewer parameters than the current state of the art. Our model takes 9.5 seconds to train on the WikiQA dataset, i.e., very fast in comparison with the 18 minutes required by a standard BERT-base fine-tuning.</abstract>
      <url hash="e8fca78e">2020.coling-main.457</url>
    </paper>
    <paper id="458">
      <title>Auto-Encoding Variational <fixed-case>B</fixed-case>ayes for Inferring Topics and Visualization</title>
      <author><first>Dang</first><last>Pham</last></author>
      <author><first>Tuan</first><last>Le</last></author>
      <pages>5223–5234</pages>
      <abstract>Visualization and topic modeling are widely used approaches for text analysis. Traditional visualization methods find low-dimensional representations of documents in the visualization space (typically 2D or 3D) that can be displayed using a scatterplot. In contrast, topic modeling aims to discover topics from text, but for visualization, one needs to perform a post-hoc embedding using dimensionality reduction methods. Recent approaches propose using a generative model to jointly find topics and visualization, allowing the semantics to be infused in the visualization space for a meaningful interpretation. A major challenge that prevents these methods from being used practically is the scalability of their inference algorithms. We present, to the best of our knowledge, the first fast Auto-Encoding Variational Bayes based inference method for jointly inferring topics and visualization. Since our method is black box, it can handle model changes efficiently with little mathematical rederivation effort. We demonstrate the efficiency and effectiveness of our method on real-world large datasets and compare it with existing baselines.</abstract>
      <url hash="d7eaf949">2020.coling-main.458</url>
    </paper>
    <paper id="459">
      <title>Hy-<fixed-case>NLI</fixed-case>: a Hybrid system for Natural Language Inference</title>
      <author><first>Aikaterini-Lida</first><last>Kalouli</last></author>
      <author><first>Richard</first><last>Crouch</last></author>
      <author><first>Valeria</first><last>de Paiva</last></author>
      <pages>5235–5249</pages>
      <abstract>Despite the advances in Natural Language Inference through the training of massive deep models, recent work has revealed the generalization difficulties of such models, which fail to perform on adversarial datasets with challenging linguistic phenomena. Such phenomena, however, can be handled well by symbolic systems. Thus, we propose Hy-NLI, a hybrid system that learns to identify an NLI pair as linguistically challenging or not. Based on that, it uses its symbolic or deep learning component, respectively, to make the final inference decision. We show how linguistically less complex cases are best solved by robust state-of-the-art models, like BERT and XLNet, while hard linguistic phenomena are best handled by our implemented symbolic engine. Our thorough evaluation shows that our hybrid system achieves state-of-the-art performance across mainstream and adversarial datasets and opens the way for further research into the hybrid direction.</abstract>
      <url hash="7004313a">2020.coling-main.459</url>
    </paper>
    <paper id="460">
      <title>Identifying Motion Entities in Natural Language and A Case Study for Named Entity Recognition</title>
      <author><first>Ngoc Phuoc An</first><last>Vo</last></author>
      <author><first>Irene</first><last>Manotas</last></author>
      <author><first>Vadim</first><last>Sheinin</last></author>
      <author><first>Octavian</first><last>Popescu</last></author>
      <pages>5250–5258</pages>
      <abstract>Motion recognition is one of the basic cognitive capabilities of many life forms, however, detecting and understanding motion in text is not a trivial task. In addition, identifying motion entities in natural language is not only challenging but also beneficial for a better natural language understanding. In this paper, we present a Motion Entity Tagging (MET) model to identify entities in motion in a text using the Literal-Motion-in-Text (LiMiT) dataset for training and evaluating the model. Then we propose a new method to split clauses and phrases from complex and long motion sentences to improve the performance of our MET model. We also present results showing that motion features, in particular, entity in motion benefits the Named-Entity Recognition (NER) task. Finally, we present an analysis for the special co-occurrence relation between the person category in NER and animate entities in motion, which significantly improves the classification performance for the person category in NER.</abstract>
      <url hash="8845c18d">2020.coling-main.460</url>
    </paper>
    <paper id="461">
      <title>Global Context-enhanced Graph Convolutional Networks for Document-level Relation Extraction</title>
      <author><first>Huiwei</first><last>Zhou</last></author>
      <author><first>Yibin</first><last>Xu</last></author>
      <author><first>Weihong</first><last>Yao</last></author>
      <author><first>Zhe</first><last>Liu</last></author>
      <author><first>Chengkun</first><last>Lang</last></author>
      <author><first>Haibin</first><last>Jiang</last></author>
      <pages>5259–5270</pages>
      <abstract>Document-level Relation Extraction (RE) is particularly challenging due to complex semantic interactions among multiple entities in a document. Among exiting approaches, Graph Convolutional Networks (GCN) is one of the most effective approaches for document-level RE. However, traditional GCN simply takes word nodes and adjacency matrix to represent graphs, which is difficult to establish direct connections between distant entity pairs. In this paper, we propose Global Context-enhanced Graph Convolutional Networks (GCGCN), a novel model which is composed of entities as nodes and context of entity pairs as edges between nodes to capture rich global context information of entities in a document. Two hierarchical blocks, Context-aware Attention Guided Graph Convolution (CAGGC) for partially connected graphs and Multi-head Attention Guided Graph Convolution (MAGGC) for fully connected graphs, could take progressively more global context into account. Meantime, we leverage a large-scale distantly supervised dataset to pre-train a GCGCN model with curriculum learning, which is then fine-tuned on the human-annotated dataset for further improving document-level RE performance. The experimental results on DocRED show that our model could effectively capture rich global context information in the document, leading to a state-of-the-art result. Our code is available at https://github.com/Huiweizhou/GCGCN.</abstract>
      <url hash="b92e6f9c">2020.coling-main.461</url>
    </paper>
    <paper id="462">
      <title>Diverse Keyphrase Generation with Neural Unlikelihood Training</title>
      <author><first>Hareesh</first><last>Bahuleyan</last></author>
      <author><first>Layla</first><last>El Asri</last></author>
      <pages>5271–5287</pages>
      <abstract>In this paper, we study sequence-to-sequence (S2S) keyphrase generation models from the perspective of diversity. Recent advances in neural natural language generation have made possible remarkable progress on the task of keyphrase generation, demonstrated through improvements on quality metrics such as F1-score. However, the importance of diversity in keyphrase generation has been largely ignored. We first analyze the extent of information redundancy present in the outputs generated by a baseline model trained using maximum likelihood estimation (MLE). Our findings show that repetition of keyphrases is a major issue with MLE training. To alleviate this issue, we adopt neural unlikelihood (UL) objective for training the S2S model. Our version of UL training operates at (1) the target token level to discourage the generation of repeating tokens; (2) the copy token level to avoid copying repetitive tokens from the source text. Further, to encourage better model planning during the decoding process, we incorporate K-step ahead token prediction objective that computes both MLE and UL losses on future tokens as well. Through extensive experiments on datasets from three different domains we demonstrate that the proposed approach attains considerably large diversity gains, while maintaining competitive output quality.</abstract>
      <url hash="0a755a19">2020.coling-main.462</url>
    </paper>
    <paper id="463">
      <title>User Memory Reasoning for Conversational Recommendation</title>
      <author><first>Hu</first><last>Xu</last></author>
      <author><first>Seungwhan</first><last>Moon</last></author>
      <author><first>Honglei</first><last>Liu</last></author>
      <author><first>Bing</first><last>Liu</last></author>
      <author><first>Pararth</first><last>Shah</last></author>
      <author><first>Bing</first><last>Liu</last></author>
      <author><first>Philip</first><last>Yu</last></author>
      <pages>5288–5308</pages>
      <abstract>We study an end-to-end approach for conversational recommendation that dynamically manages and reasons over users’ past (offline) preferences and current (online) requests through a structured and cumulative user memory knowledge graph. This formulation extends existing state tracking beyond the boundary of a single dialog to user state tracking (UST). For this study, we create a new Memory Graph (MG) &lt;-&gt; Conversational Recommendation parallel corpus called MGConvRex with 7K+ human-to-human role-playing dialogs, grounded on a large-scale user memory bootstrapped from real-world user scenarios. MGConvRex captures human-level reasoning over user memory and has disjoint training/testing sets of users for zero-shot (cold-start) reasoning for recommendation. We propose a simple yet expandable formulation for constructing and updating the MG, and an end-to-end graph-based reasoning model that updates MG from unstructured utterances and predicts optimal dialog policies (eg recommendation) based on updated MG. The prediction of our proposed model inherits the graph structure, providing a natural way to explain policies. Experiments are conducted for both offline metrics and online simulation, showing competitive results.</abstract>
      <url hash="5d0bdbff">2020.coling-main.463</url>
    </paper>
    <paper id="464">
      <title>Diverse and Non-redundant Answer Set Extraction on Community <fixed-case>QA</fixed-case> based on <fixed-case>DPP</fixed-case>s</title>
      <author><first>Shogo</first><last>Fujita</last></author>
      <author><first>Tomohide</first><last>Shibata</last></author>
      <author><first>Manabu</first><last>Okumura</last></author>
      <pages>5309–5320</pages>
      <abstract>In community-based question answering (CQA) platforms, it takes time for a user to get useful information from among many answers. Although one solution is an answer ranking method, the user still needs to read through the top-ranked answers carefully. This paper proposes a new task of selecting a diverse and non-redundant answer set rather than ranking the answers. Our method is based on determinantal point processes (DPPs), and it calculates the answer importance and similarity between answers by using BERT. We built a dataset focusing on a Japanese CQA site, and the experiments on this dataset demonstrated that the proposed method outperformed several baseline methods.</abstract>
      <url hash="d40601f3">2020.coling-main.464</url>
    </paper>
    <paper id="465">
      <title>An empirical analysis of existing systems and datasets toward general simple question answering</title>
      <author><first>Namgi</first><last>Han</last></author>
      <author><first>Goran</first><last>Topic</last></author>
      <author><first>Hiroshi</first><last>Noji</last></author>
      <author><first>Hiroya</first><last>Takamura</last></author>
      <author><first>Yusuke</first><last>Miyao</last></author>
      <pages>5321–5334</pages>
      <abstract>In this paper, we evaluate the progress of our field toward solving simple factoid questions over a knowledge base, a practically important problem in natural language interface to database. As in other natural language understanding tasks, a common practice for this task is to train and evaluate a model on a single dataset, and recent studies suggest that SimpleQuestions, the most popular and largest dataset, is nearly solved under this setting. However, this common setting does not evaluate the robustness of the systems outside of the distribution of the used training data. We rigorously evaluate such robustness of existing systems using different datasets. Our analysis, including shifting of training and test datasets and training on a union of the datasets, suggests that our progress in solving SimpleQuestions dataset does not indicate the success of more general simple question answering. We discuss a possible future direction toward this goal.</abstract>
      <url hash="7541df51">2020.coling-main.465</url>
    </paper>
    <paper id="466">
      <title>Learn to Combine Linguistic and Symbolic Information for Table-based Fact Verification</title>
      <author><first>Qi</first><last>Shi</last></author>
      <author><first>Yu</first><last>Zhang</last></author>
      <author><first>Qingyu</first><last>Yin</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <pages>5335–5346</pages>
      <abstract>Table-based fact verification is expected to perform both linguistic reasoning and symbolic reasoning. Existing methods lack attention to take advantage of the combination of linguistic information and symbolic information. In this work, we propose HeterTFV, a graph-based reasoning approach, that learns to combine linguistic information and symbolic information effectively. We first construct a program graph to encode programs, a kind of LISP-like logical form, to learn the semantic compositionality of the programs. Then we construct a heterogeneous graph to incorporate both linguistic information and symbolic information by introducing program nodes into the heterogeneous graph. Finally, we propose a graph-based reasoning approach to reason over the multiple types of nodes to make an effective combination of both types of information. Experimental results on a large-scale benchmark dataset TABFACT illustrate the effect of our approach.</abstract>
      <url hash="12c19d31">2020.coling-main.466</url>
    </paper>
    <paper id="467">
      <title><fixed-case>C</fixed-case>os<fixed-case>M</fixed-case>o: Conditional <fixed-case>S</fixed-case>eq2<fixed-case>S</fixed-case>eq-based Mixture Model for Zero-Shot Commonsense Question Answering</title>
      <author><first>Farhad</first><last>Moghimifar</last></author>
      <author><first>Lizhen</first><last>Qu</last></author>
      <author><first>Yue</first><last>Zhuo</last></author>
      <author><first>Mahsa</first><last>Baktashmotlagh</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>5347–5359</pages>
      <abstract>Commonsense reasoning refers to the ability of evaluating a social situation and acting accordingly. Identification of the implicit causes and effects of a social context is the driving capability which can enable machines to perform commonsense reasoning. The dynamic world of social interactions requires context-dependent on-demand systems to infer such underlying information. However, current approaches in this realm lack the ability to perform commonsense reasoning upon facing an unseen situation, mostly due to incapability of identifying a diverse range of implicit social relations. Hence they fail to estimate the correct reasoning path. In this paper, we present Conditional Seq2Seq-based Mixture model (CosMo), which provides us with the capabilities of dynamic and diverse content generation. We use CosMo to generate context-dependent clauses, which form a dynamic Knowledge Graph (KG) on-the-fly for commonsense reasoning. To show the adaptability of our model to context-dependant knowledge generation, we address the task of zero-shot commonsense question answering. The empirical results indicate an improvement of up to +5.2% over the state-of-the-art models.</abstract>
      <url hash="a0a29d7f">2020.coling-main.467</url>
    </paper>
    <paper id="468">
      <title>Enhancing Extractive Text Summarization with Topic-Aware Graph Neural Networks</title>
      <author><first>Peng</first><last>Cui</last></author>
      <author><first>Le</first><last>Hu</last></author>
      <author><first>Yuanchao</first><last>Liu</last></author>
      <pages>5360–5371</pages>
      <abstract>Text summarization aims to compress a textual document to a short summary while keeping salient information. Extractive approaches are widely used in text summarization because of their fluency and efficiency. However, most of existing extractive models hardly capture inter-sentence relationships, particularly in long documents. They also often ignore the effect of topical information on capturing important contents. To address these issues, this paper proposes a graph neural network (GNN)-based extractive summarization model, enabling to capture inter-sentence relationships efficiently via graph-structured document representation. Moreover, our model integrates a joint neural topic model (NTM) to discover latent topics, which can provide document-level features for sentence selection. The experimental results demonstrate that our model not only substantially achieves state-of-the-art results on CNN/DM and NYT datasets but also considerably outperforms existing approaches on scientific paper datasets consisting of much longer documents, indicating its better robustness in document genres and lengths. Further discussions show that topical information can help the model preselect salient contents from an entire document, which interprets its effectiveness in long document summarization.</abstract>
      <url hash="d4305bf0">2020.coling-main.468</url>
    </paper>
    <paper id="469">
      <title><fixed-case>S</fixed-case>a<fixed-case>SAKE</fixed-case>: Syntax and Semantics Aware Keyphrase Extraction from Research Papers</title>
      <author><first>T.y.s.s</first><last>Santosh</last></author>
      <author><first>Debarshi</first><last>Kumar Sanyal</last></author>
      <author><first>Plaban Kumar</first><last>Bhowmick</last></author>
      <author><first>Partha Pratim</first><last>Das</last></author>
      <pages>5372–5383</pages>
      <abstract>Keyphrases in a research paper succinctly capture the primary content of the paper and also assist in indexing the paper at a concept level. Given the huge rate at which scientific papers are published today, it is important to have effective ways of automatically extracting keyphrases from a research paper. In this paper, we present a novel method, Syntax and Semantics Aware Keyphrase Extraction (SaSAKE), to extract keyphrases from research papers. It uses a transformer architecture, stacking up sentence encoders to incorporate sequential information, and graph encoders to incorporate syntactic and semantic dependency graph information. Incorporation of these dependency graphs helps to alleviate long-range dependency problems and identify the boundaries of multi-word keyphrases effectively. Experimental results on three benchmark datasets show that our proposed method SaSAKE achieves state-of-the-art performance in keyphrase extraction from scientific papers.</abstract>
      <url hash="f1d5a17d">2020.coling-main.469</url>
    </paper>
    <paper id="470">
      <title>News Editorials: Towards Summarizing Long Argumentative Texts</title>
      <author><first>Shahbaz</first><last>Syed</last></author>
      <author><first>Roxanne</first><last>El Baff</last></author>
      <author><first>Johannes</first><last>Kiesel</last></author>
      <author><first>Khalid</first><last>Al Khatib</last></author>
      <author><first>Benno</first><last>Stein</last></author>
      <author><first>Martin</first><last>Potthast</last></author>
      <pages>5384–5396</pages>
      <abstract>The automatic summarization of argumentative texts has hardly been explored. This paper takes a further step in this direction, targeting news editorials, i.e., opinionated articles with a well-defined argumentation structure. With Webis-EditorialSum-2020, we present a corpus of 1330 carefully curated summaries for 266 news editorials. We evaluate these summaries based on a tailored annotation scheme, where a high-quality summary is expected to be thesis-indicative, persuasive, reasonable, concise, and self-contained. Our corpus contains at least three high-quality summaries for about 90% of the editorials, rendering it a valuable resource for the development and evaluation of summarization technology for long argumentative texts. We further report details of both, an in-depth corpus analysis, and the evaluation of two extractive summarization models.</abstract>
      <url hash="9f07054d">2020.coling-main.470</url>
    </paper>
    <paper id="471">
      <title>Automatic Interlinear Glossing for Under-Resourced Languages Leveraging Translations</title>
      <author><first>Xingyuan</first><last>Zhao</last></author>
      <author><first>Satoru</first><last>Ozaki</last></author>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Lori</first><last>Levin</last></author>
      <pages>5397–5408</pages>
      <abstract>Interlinear Glossed Text (IGT) is a widely used format for encoding linguistic information in language documentation projects and scholarly papers. Manual production of IGT takes time and requires linguistic expertise. We attempt to address this issue by creating automatic glossing models, using modern multi-source neural models that additionally leverage easy-to-collect translations. We further explore cross-lingual transfer and a simple output length control mechanism, further refining our models. Evaluated on three challenging low-resource scenarios, our approach significantly outperforms a recent, state-of-the-art baseline, particularly improving on overall accuracy as well as lemma and tag recall.</abstract>
      <url hash="1784e4a4">2020.coling-main.471</url>
    </paper>
    <paper id="472">
      <title>Scientific Keyphrase Identification and Classification by Pre-Trained Language Models Intermediate Task Transfer Learning</title>
      <author><first>Seoyeon</first><last>Park</last></author>
      <author><first>Cornelia</first><last>Caragea</last></author>
      <pages>5409–5419</pages>
      <abstract>Scientific keyphrase identification and classification is the task of detecting and classifying keyphrases from scholarly text with their types from a set of predefined classes. This task has a wide range of benefits, but it is still challenging in performance due to the lack of large amounts of labeled data required for training deep neural models. In order to overcome this challenge, we explore pre-trained language models BERT and SciBERT with intermediate task transfer learning, using 42 data-rich related intermediate-target task combinations. We reveal that intermediate task transfer learning on SciBERT induces a better starting point for target task fine-tuning compared with BERT and achieves competitive performance in scientific keyphrase identification and classification compared to both previous works and strong baselines. Interestingly, we observe that BERT with intermediate task transfer learning fails to improve the performance of scientific keyphrase identification and classification potentially due to significant catastrophic forgetting. This result highlights that scientific knowledge achieved during the pre-training of language models on large scientific collections plays an important role in the target tasks. We also observe that sequence tagging related intermediate tasks, especially syntactic structure learning tasks such as POS Tagging, tend to work best for scientific keyphrase identification and classification.</abstract>
      <url hash="71f7b7b4">2020.coling-main.472</url>
    </paper>
    <paper id="473">
      <title>Exploiting Microblog Conversation Structures to Detect Rumors</title>
      <author><first>Jiawen</first><last>Li</last></author>
      <author><first>Yudianto</first><last>Sujana</last></author>
      <author><first>Hung-Yu</first><last>Kao</last></author>
      <pages>5420–5429</pages>
      <abstract>As one of the most popular social media platforms, Twitter has become a primary source of information for many people. Unfortunately, both valid information and rumors are propagated on Twitter due to the lack of an automatic information verification system. Twitter users communicate by replying to other users’ messages, forming a conversation structure. Using this structure, users can decide whether the information in the source tweet is a rumor by reading the tweet’s replies, which voice other users’ stances on the tweet. The majority of rumor detection researchers process such tweets based on time, ignoring the conversation structure. To reap the benefits of the Twitter conversation structure, we developed a model to detect rumors by modeling conversation structure as a graph. Thus, our model’s improved representation of the conversation structure enhances its rumor detection accuracy. The experimental results on two rumor datasets show that our model outperforms several baseline models, including a state-of-the-art model</abstract>
      <url hash="21f44db3">2020.coling-main.473</url>
    </paper>
    <paper id="474">
      <title>Explainable Automated Fact-Checking: A Survey</title>
      <author><first>Neema</first><last>Kotonya</last></author>
      <author><first>Francesca</first><last>Toni</last></author>
      <pages>5430–5443</pages>
      <abstract>A number of exciting advances have been made in automated fact-checking thanks to increasingly larger datasets and more powerful systems, leading to improvements in the complexity of claims which can be accurately fact-checked. However, despite these advances, there are still desirable functionalities missing from the fact-checking pipeline. In this survey, we focus on the explanation functionality – that is fact-checking systems providing reasons for their predictions. We summarize existing methods for explaining the predictions of fact-checking systems and we explore trends in this topic. Further, we consider what makes for good explanations in this specific domain through a comparative analysis of existing fact-checking explanations against some desirable properties. Finally, we propose further research directions for generating fact-checking explanations, and describe how these may lead to improvements in the research area.</abstract>
      <url hash="3dd019a1">2020.coling-main.474</url>
    </paper>
    <paper id="475">
      <title>Early Detection of Fake News by Utilizing the Credibility of News, Publishers, and Users based on Weakly Supervised Learning</title>
      <author><first>Chunyuan</first><last>Yuan</last></author>
      <author><first>Qianwen</first><last>Ma</last></author>
      <author><first>Wei</first><last>Zhou</last></author>
      <author><first>Jizhong</first><last>Han</last></author>
      <author><first>Songlin</first><last>Hu</last></author>
      <pages>5444–5454</pages>
      <abstract>The dissemination of fake news significantly affects personal reputation and public trust. Recently, fake news detection has attracted tremendous attention, and previous studies mainly focused on finding clues from news content or diffusion path. However, the required features of previous models are often unavailable or insufficient in early detection scenarios, resulting in poor performance. Thus, early fake news detection remains a tough challenge. Intuitively, the news from trusted and authoritative sources or shared by many users with a good reputation is more reliable than other news. Using the credibility of publishers and users as prior weakly supervised information, we can quickly locate fake news in massive news and detect them in the early stages of dissemination. In this paper, we propose a novel structure-aware multi-head attention network (SMAN), which combines the news content, publishing, and reposting relations of publishers and users, to jointly optimize the fake news detection and credibility prediction tasks. In this way, we can explicitly exploit the credibility of publishers and users for early fake news detection. We conducted experiments on three real-world datasets, and the results show that SMAN can detect fake news in 4 hours with an accuracy of over 91%, which is much faster than the state-of-the-art models.</abstract>
      <url hash="5f225a5e">2020.coling-main.475</url>
    </paper>
    <paper id="476">
      <title>Debunking Rumors on <fixed-case>T</fixed-case>witter with Tree Transformer</title>
      <author><first>Jing</first><last>Ma</last></author>
      <author><first>Wei</first><last>Gao</last></author>
      <pages>5455–5466</pages>
      <abstract>Rumors are manufactured with no respect for accuracy, but can circulate quickly and widely by “word-of-post” through social media conversations. Conversation tree encodes important information indicative of the credibility of rumor. Existing conversation-based techniques for rumor detection either just strictly follow tree edges or treat all the posts fully-connected during feature learning. In this paper, we propose a novel detection model based on tree transformer to better utilize user interactions in the dialogue where post-level self-attention plays the key role for aggregating the intra-/inter-subtree stances. Experimental results on the TWITTER and PHEME datasets show that the proposed approach consistently improves rumor detection performance.</abstract>
      <url hash="91bc01bf">2020.coling-main.476</url>
    </paper>
    <paper id="477">
      <title>Words are the Window to the Soul: Language-based User Representations for Fake News Detection</title>
      <author><first>Marco</first><last>Del Tredici</last></author>
      <author><first>Raquel</first><last>Fernández</last></author>
      <pages>5467–5479</pages>
      <abstract>Cognitive and social traits of individuals are reflected in language use. Moreover, individuals who are prone to spread fake news online often share common traits. Building on these ideas, we introduce a model that creates representations of individuals on social media based only on the language they produce, and use them to detect fake news. We show that language-based user representations are beneficial for this task. We also present an extended analysis of the language of fake news spreaders, showing that its main features are mostly domain independent and consistent across two English datasets. Finally, we exploit the relation between language use and connections in the social graph to assess the presence of the Echo Chamber effect in our data.</abstract>
      <url hash="d1089209">2020.coling-main.477</url>
    </paper>
    <paper id="478">
      <title>Argumentation Mining on Essays at Multi Scales</title>
      <author><first>Hao</first><last>Wang</last></author>
      <author><first>Zhen</first><last>Huang</last></author>
      <author><first>Yong</first><last>Dou</last></author>
      <author><first>Yu</first><last>Hong</last></author>
      <pages>5480–5493</pages>
      <abstract>Argumentation mining on essays is a new challenging task in natural language processing, which aims to identify the types and locations of argumentation components. Recent research mainly models the task as a sequence tagging problem and deal with all the argumentation components at word level. However, this task is not scale-independent. Some types of argumentation components which serve as core opinions on essays or paragraphs, are at essay level or paragraph level. Sequence tagging method conducts reasoning by local context words, and fails to effectively mine these components. To this end, we propose a multi-scale argumentation mining model, where we respectively mine different types of argumentation components at corresponding levels. Besides, an effective coarse-to-fine argumentation fusion mechanism is proposed to further improve the performance. We conduct a serial of experiments on the Persuasive Essay dataset (PE2.0). Experimental results indicate that our model outperforms existing models on mining all types of argumentation components.</abstract>
      <url hash="a3c654e9">2020.coling-main.478</url>
    </paper>
    <paper id="479">
      <title>Data Augmentation for Multiclass Utterance Classification – A Systematic Study</title>
      <author><first>Binxia</first><last>Xu</last></author>
      <author><first>Siyuan</first><last>Qiu</last></author>
      <author><first>Jie</first><last>Zhang</last></author>
      <author><first>Yafang</first><last>Wang</last></author>
      <author><first>Xiaoyu</first><last>Shen</last></author>
      <author><first>Gerard</first><last>de Melo</last></author>
      <pages>5494–5506</pages>
      <abstract>Utterance classification is a key component in many conversational systems. However, classifying real-world user utterances is challenging, as people may express their ideas and thoughts in manifold ways, and the amount of training data for some categories may be fairly limited, resulting in imbalanced data distributions. To alleviate these issues, we conduct a comprehensive survey regarding data augmentation approaches for text classification, including simple random resampling, word-level transformations, and neural text generation to cope with imbalanced data. Our experiments focus on multi-class datasets with a large number of data samples, which has not been systematically studied in previous work. The results show that the effectiveness of different data augmentation schemes depends on the nature of the dataset under consideration.</abstract>
      <url hash="326b6e1c">2020.coling-main.479</url>
    </paper>
    <paper id="480">
      <title><fixed-case>KINNEWS</fixed-case> and <fixed-case>KIRNEWS</fixed-case>: Benchmarking Cross-Lingual Text Classification for <fixed-case>K</fixed-case>inyarwanda and <fixed-case>K</fixed-case>irundi</title>
      <author><first>Rubungo Andre</first><last>Niyongabo</last></author>
      <author><first>Qu</first><last>Hong</last></author>
      <author><first>Julia</first><last>Kreutzer</last></author>
      <author><first>Li</first><last>Huang</last></author>
      <pages>5507–5521</pages>
      <abstract>Recent progress in text classification has been focused on high-resource languages such as English and Chinese. For low-resource languages, amongst them most African languages, the lack of well-annotated data and effective preprocessing, is hindering the progress and the transfer of successful methods. In this paper, we introduce two news datasets (KINNEWS and IRNEWS) for multi-class classification of news articles in Kinyarwanda and Kirundi, two low-resource African languages. The two languages are mutually intelligible, but while Kinyarwanda has been studied in Natural Language Processing (NLP) to some extent, this work constitutes the first study on Kirundi. Along with the datasets, we provide statistics, guidelines for preprocessing, and monolingual and cross-lingual baseline models. Our experiments show that training embeddings on the relatively higher-resourced Kinyarwanda yields successful cross-lingual transfer to Kirundi. In addition, the design of the created datasets allows for a wider use in NLP beyond text classification in future studies, such as representation learning, cross-lingual learning with more distant languages, or as base for new annotations for tasks such as parsing, POS tagging, and NER. The datasets, stopwords, and pre-trained embeddings are publicly available at https://github.com/Andrews2017/KINNEWS-and-KIRNEWS-Corpus.</abstract>
      <url hash="57085d91">2020.coling-main.480</url>
    </paper>
    <paper id="481">
      <title>Go Simple and Pre-Train on Domain-Specific Corpora: On the Role of Training Data for Text Classification</title>
      <author><first>Aleksandra</first><last>Edwards</last></author>
      <author><first>Jose</first><last>Camacho-Collados</last></author>
      <author><first>Hélène</first><last>De Ribaupierre</last></author>
      <author><first>Alun</first><last>Preece</last></author>
      <pages>5522–5529</pages>
      <abstract>Pre-trained language models provide the foundations for state-of-the-art performance across a wide range of natural language processing tasks, including text classification. However, most classification datasets assume a large amount labeled data, which is commonly not the case in practical settings. In particular, in this paper we compare the performance of a light-weight linear classifier based on word embeddings, i.e., fastText (Joulin et al., 2017), versus a pre-trained language model, i.e., BERT (Devlin et al., 2019), across a wide range of datasets and classification tasks. In general, results show the importance of domain-specific unlabeled data, both in the form of word embeddings or language models. As for the comparison, BERT outperforms all baselines in standard datasets with large training sets. However, in settings with small training datasets a simple method like fastText coupled with domain-specific word embeddings performs equally well or better than BERT, even when pre-trained on domain-specific data.</abstract>
      <url hash="161bb6a3">2020.coling-main.481</url>
    </paper>
    <paper id="482">
      <title>Unsupervised Fine-tuning for Text Clustering</title>
      <author><first>Shaohan</first><last>Huang</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <author><first>Lei</first><last>Cui</last></author>
      <author><first>Xingxing</first><last>Zhang</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <pages>5530–5534</pages>
      <abstract>Fine-tuning with pre-trained language models (e.g. BERT) has achieved great success in many language understanding tasks in supervised settings (e.g. text classification). However, relatively little work has been focused on applying pre-trained models in unsupervised settings, such as text clustering. In this paper, we propose a novel method to fine-tune pre-trained models unsupervisedly for text clustering, which simultaneously learns text representations and cluster assignments using a clustering oriented loss. Experiments on three text clustering datasets (namely TREC-6, Yelp, and DBpedia) show that our model outperforms the baseline methods and achieves state-of-the-art results.</abstract>
      <url hash="63eb6a7a">2020.coling-main.482</url>
    </paper>
    <paper id="483">
      <title>Exploiting Narrative Context and A Priori Knowledge of Categories in Textual Emotion Classification</title>
      <author><first>Hikari</first><last>Tanabe</last></author>
      <author><first>Tetsuji</first><last>Ogawa</last></author>
      <author><first>Tetsunori</first><last>Kobayashi</last></author>
      <author><first>Yoshihiko</first><last>Hayashi</last></author>
      <pages>5535–5540</pages>
      <abstract>Recognition of the mental state of a human character in text is a major challenge in natural language processing. In this study, we investigate the efficacy of the narrative context in recognizing the emotional states of human characters in text and discuss an approach to make use of a priori knowledge regarding the employed emotion category system. Specifically, we experimentally show that the accuracy of emotion classification is substantially increased by encoding the preceding context of the target sentence using a BERT-based text encoder. We also compare ways to incorporate a priori knowledge of emotion categories by altering the loss function used in training, in which our proposal of multi-task learning that jointly learns to classify positive/negative polarity of emotions is included. The experimental results suggest that, when using Plutchik’s Wheel of Emotions, it is better to jointly classify the basic emotion categories with positive/negative polarity rather than directly exploiting its characteristic structure in which eight basic categories are arranged in a wheel.</abstract>
      <url hash="b912df67">2020.coling-main.483</url>
    </paper>
    <paper id="484">
      <title>Word-Level Uncertainty Estimation for Black-Box Text Classifiers using <fixed-case>RNN</fixed-case>s</title>
      <author><first>Jakob Smedegaard</first><last>Andersen</last></author>
      <author><first>Tom</first><last>Schöner</last></author>
      <author><first>Walid</first><last>Maalej</last></author>
      <pages>5541–5546</pages>
      <abstract>Estimating uncertainties of Neural Network predictions paves the way towards more reliable and trustful text classifications. However, common uncertainty estimation approaches remain as black-boxes without explaining which features have led to the uncertainty of a prediction. This hinders users from understanding the cause of unreliable model behaviour. We introduce an approach to decompose and visualize the uncertainty of text classifiers at the level of words. Our approach builds on top of Recurrent Neural Networks and Bayesian modelling in order to provide detailed explanations of uncertainties, enabling a deeper reasoning about unreliable model behaviours. We conduct a preliminary experiment to check the impact and correctness of our approach. By explaining and investigating the predictive uncertainties of a sentiment analysis task, we argue that our approach is able to provide a more profound understanding of artificial decision making.</abstract>
      <url hash="cfc1fc27">2020.coling-main.484</url>
    </paper>
    <paper id="485">
      <title>Few-Shot Text Classification with Edge-Labeling Graph Neural Network-Based Prototypical Network</title>
      <author><first>Chen</first><last>Lyu</last></author>
      <author><first>Weijie</first><last>Liu</last></author>
      <author><first>Ping</first><last>Wang</last></author>
      <pages>5547–5552</pages>
      <abstract>In this paper, we propose a new few-shot text classification method. Compared with supervised learning methods which require a large corpus of labeled documents, our method aims to make it possible to classify unlabeled text with few labeled data. To achieve this goal, we take advantage of advanced pre-trained language model to extract the semantic features of each document. Furthermore, we utilize an edge-labeling graph neural network to implicitly models the intra-cluster similarity and the inter-cluster dissimilarity of the documents. Finally, we take the results of the graph neural network as the input of a prototypical network to classify the unlabeled texts. We verify the effectiveness of our method on a sentiment analysis dataset and a relation classification dataset and achieve the state-of-the-art performance on both tasks.</abstract>
      <url hash="e5c0f4ba">2020.coling-main.485</url>
    </paper>
    <paper id="486">
      <title><fixed-case>M</fixed-case>any<fixed-case>E</fixed-case>nt: A Dataset for Few-shot Entity Typing</title>
      <author><first>Markus</first><last>Eberts</last></author>
      <author><first>Kevin</first><last>Pech</last></author>
      <author><first>Adrian</first><last>Ulges</last></author>
      <pages>5553–5557</pages>
      <abstract>We introduce ManyEnt, a benchmark for entity typing models in few-shot scenarios. ManyEnt offers a rich typeset, with a fine-grain variant featuring 256 entity types and a coarse-grain one with 53 entity types. Both versions have been derived from the Wikidata knowledge graph in a semi-automatic fashion. We also report results for two baselines using BERT, reaching up to 70.68% accuracy (10-way 1-shot).</abstract>
      <url hash="ab1d553a">2020.coling-main.486</url>
    </paper>
    <paper id="487">
      <title>Embedding Meta-Textual Information for Improved Learning to Rank</title>
      <author><first>Toshitaka</first><last>Kuwa</last></author>
      <author><first>Shigehiko</first><last>Schamoni</last></author>
      <author><first>Stefan</first><last>Riezler</last></author>
      <pages>5558–5568</pages>
      <abstract>Neural approaches to learning term embeddings have led to improved computation of similarity and ranking in information retrieval (IR). So far neural representation learning has not been extended to meta-textual information that is readily available for many IR tasks, for example, patent classes in prior-art retrieval, topical information in Wikipedia articles, or product categories in e-commerce data. We present a framework that learns embeddings for meta-textual categories, and optimizes a pairwise ranking objective for improved matching based on combined embeddings of textual and meta-textual information. We show considerable gains in an experimental evaluation on cross-lingual retrieval in the Wikipedia domain for three language pairs, and in the Patent domain for one language pair. Our results emphasize that the mode of combining different types of information is crucial for model improvement.</abstract>
      <url hash="046db5bc">2020.coling-main.487</url>
    </paper>
    <paper id="488">
      <title>Automatically Identifying Words That Can Serve as Labels for Few-Shot Text Classification</title>
      <author><first>Timo</first><last>Schick</last></author>
      <author><first>Helmut</first><last>Schmid</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>5569–5578</pages>
      <abstract>A recent approach for few-shot text classification is to convert textual inputs to cloze questions that contain some form of task description, process them with a pretrained language model and map the predicted words to labels. Manually defining this mapping between words and labels requires both domain expertise and an understanding of the language model’s abilities. To mitigate this issue, we devise an approach that automatically finds such a mapping given small amounts of training data. For a number of tasks, the mapping found by our approach performs almost as well as hand-crafted label-to-word mappings.</abstract>
      <url hash="d5041c46">2020.coling-main.488</url>
    </paper>
    <paper id="489">
      <title>Knowledge Base Embedding By Cooperative Knowledge Distillation</title>
      <author><first>Raphaël</first><last>Sourty</last></author>
      <author><first>Jose G.</first><last>Moreno</last></author>
      <author><first>François-Paul</first><last>Servant</last></author>
      <author><first>Lynda</first><last>Tamine-Lechani</last></author>
      <pages>5579–5590</pages>
      <abstract>Knowledge bases are increasingly exploited as gold standard data sources which benefit various knowledge-driven NLP tasks. In this paper, we explore a new research direction to perform knowledge base (KB) representation learning grounded with the recent theoretical framework of knowledge distillation over neural networks. Given a set of KBs, our proposed approach KD-MKB, learns KB embeddings by mutually and jointly distilling knowledge within a dynamic teacher-student setting. Experimental results on two standard datasets show that knowledge distillation between KBs through entity and relation inference is actually observed. We also show that cooperative learning significantly outperforms the two proposed baselines, namely traditional and sequential distillation.</abstract>
      <url hash="97f8cc5c">2020.coling-main.489</url>
    </paper>
    <paper id="490">
      <title><fixed-case>I</fixed-case>nt<fixed-case>KB</fixed-case>: A Verifiable Interactive Framework for Knowledge Base Completion</title>
      <author><first>Bernhard</first><last>Kratzwald</last></author>
      <author><first>Guo</first><last>Kunpeng</last></author>
      <author><first>Stefan</first><last>Feuerriegel</last></author>
      <author><first>Dennis</first><last>Diefenbach</last></author>
      <pages>5591–5603</pages>
      <abstract>Knowledge bases (KBs) are essential for many downstream NLP tasks, yet their prime shortcoming is that they are often incomplete. State-of-the-art frameworks for KB completion often lack sufficient accuracy to work fully automated without human supervision. As a remedy, we propose : a novel interactive framework for KB completion from text based on a question answering pipeline. Our framework is tailored to the specific needs of a human-in-the-loop paradigm: (i) We generate facts that are aligned with text snippets and are thus immediately verifiable by humans. (ii) Our system is designed such that it continuously learns during the KB completion task and, therefore, significantly improves its performance upon initial zero- and few-shot relations over time. (iii) We only trigger human interactions when there is enough information for a correct prediction. Therefore, we train our system with negative examples and a fold-option if there is no answer. Our framework yields a favorable performance: it achieves a hit@1 ratio of 29.7% for initially unseen relations, upon which it gradually improves to 46.2%.</abstract>
      <url hash="146f8762">2020.coling-main.490</url>
    </paper>
    <paper id="491">
      <title>Reference and Document Aware Semantic Evaluation Methods for <fixed-case>K</fixed-case>orean Language Summarization</title>
      <author><first>Dongyub</first><last>Lee</last></author>
      <author><first>Myeong Cheol</first><last>Shin</last></author>
      <author><first>Taesun</first><last>Whang</last></author>
      <author><first>Seungwoo</first><last>Cho</last></author>
      <author><first>Byeongil</first><last>Ko</last></author>
      <author><first>Daniel</first><last>Lee</last></author>
      <author><first>EungGyun</first><last>Kim</last></author>
      <author><first>Jaechoon</first><last>Jo</last></author>
      <pages>5604–5616</pages>
      <abstract>Text summarization refers to the process that generates a shorter form of text from the source document preserving salient information. Many existing works for text summarization are generally evaluated by using recall-oriented understudy for gisting evaluation (ROUGE) scores. However, as ROUGE scores are computed based on n-gram overlap, they do not reflect semantic meaning correspondences between generated and reference summaries. Because Korean is an agglutinative language that combines various morphemes into a word that express several meanings, ROUGE is not suitable for Korean summarization. In this paper, we propose evaluation metrics that reflect semantic meanings of a reference summary and the original document, Reference and Document Aware Semantic Score (RDASS). We then propose a method for improving the correlation of the metrics with human judgment. Evaluation results show that the correlation with human judgment is significantly higher for our evaluation metrics than for ROUGE scores.</abstract>
      <url hash="d1f75f4c">2020.coling-main.491</url>
    </paper>
    <paper id="492">
      <title>At Which Level Should We Extract? An Empirical Analysis on Extractive Document Summarization</title>
      <author><first>Qingyu</first><last>Zhou</last></author>
      <author><first>Furu</first><last>Wei</last></author>
      <author><first>Ming</first><last>Zhou</last></author>
      <pages>5617–5628</pages>
      <abstract>Extractive methods have been proven effective in automatic document summarization. Previous works perform this task by identifying informative contents at sentence level. However, it is unclear whether performing extraction at sentence level is the best solution. In this work, we show that unnecessity and redundancy issues exist when extracting full sentences, and extracting sub-sentential units is a promising alternative. Specifically, we propose extracting sub-sentential units based on the constituency parsing tree. A neural extractive model which leverages the sub-sentential information and extracts them is presented. Extensive experiments and analyses show that extracting sub-sentential units performs competitively comparing to full sentence extraction under the evaluation of both automatic and human evaluations. Hopefully, our work could provide some inspiration of the basic extraction units in extractive summarization for future research.</abstract>
      <url hash="545eaa48">2020.coling-main.492</url>
    </paper>
    <paper id="493">
      <title>Fact-level Extractive Summarization with Hierarchical Graph Mask on <fixed-case>BERT</fixed-case></title>
      <author><first>Ruifeng</first><last>Yuan</last></author>
      <author><first>Zili</first><last>Wang</last></author>
      <author><first>Wenjie</first><last>Li</last></author>
      <pages>5629–5639</pages>
      <abstract>Most current extractive summarization models generate summaries by selecting salient sentences. However, one of the problems with sentence-level extractive summarization is that there exists a gap between the human-written gold summary and the oracle sentence labels. In this paper, we propose to extract fact-level semantic units for better extractive summarization. We also introduce a hierarchical structure, which incorporates the multi-level of granularities of the textual information into the model. In addition, we incorporate our model with BERT using a hierarchical graph mask. This allows us to combine BERT’s ability in natural language understanding and the structural information without increasing the scale of the model. Experiments on the CNN/DaliyMail dataset show that our model achieves state-of-the-art results.</abstract>
      <url hash="cc5e00e9">2020.coling-main.493</url>
    </paper>
    <paper id="494">
      <title>Flight of the <fixed-case>PEGASUS</fixed-case>? Comparing Transformers on Few-shot and Zero-shot Multi-document Abstractive Summarization</title>
      <author><first>Travis</first><last>Goodwin</last></author>
      <author><first>Max</first><last>Savery</last></author>
      <author><first>Dina</first><last>Demner-Fushman</last></author>
      <pages>5640–5646</pages>
      <abstract>Recent work has shown that pre-trained Transformers obtain remarkable performance on many natural language processing tasks including automatic summarization. However, most work has focused on (relatively) data-rich single-document summarization settings. In this paper, we explore highly-abstractive multi-document summarization where the summary is explicitly conditioned on a user-given topic statement or question. We compare the summarization quality produced by three state-of-the-art transformer-based models: BART, T5, and PEGASUS. We report the performance on four challenging summarization datasets: three from the general domain and one from consumer health in both zero-shot and few-shot learning settings. While prior work has shown significant differences in performance for these models on standard summarization tasks, our results indicate that with as few as 10 labeled examples there is no statistically significant difference in summary quality, suggesting the need for more abstractive benchmark collections when determining state-of-the-art.</abstract>
      <url hash="af5bd96a">2020.coling-main.494</url>
    </paper>
    <paper id="495">
      <title><fixed-case>WSL</fixed-case>-<fixed-case>DS</fixed-case>: Weakly Supervised Learning with Distant Supervision for Query Focused Multi-Document Abstractive Summarization</title>
      <author><first>Md Tahmid Rahman</first><last>Laskar</last></author>
      <author><first>Enamul</first><last>Hoque</last></author>
      <author><first>Jimmy Xiangji</first><last>Huang</last></author>
      <pages>5647–5654</pages>
      <abstract>In the Query Focused Multi-Document Summarization (QF-MDS) task, a set of documents and a query are given where the goal is to generate a summary from these documents based on the given query. However, one major challenge for this task is the lack of availability of labeled training datasets. To overcome this issue, in this paper, we propose a novel weakly supervised learning approach via utilizing distant supervision. In particular, we use datasets similar to the target dataset as the training data where we leverage pre-trained sentence similarity models to generate the weak reference summary of each individual document in a document set from the multi-document gold reference summaries. Then, we iteratively train our summarization model on each single-document to alleviate the computational complexity issue that occurs while training neural summarization models in multiple documents (i.e., long sequences) at once. Experimental results on the Document Understanding Conferences (DUC) datasets show that our proposed approach sets a new state-of-the-art result in terms of various evaluation metrics.</abstract>
      <url hash="c0c5f86c">2020.coling-main.495</url>
    </paper>
    <paper id="496">
      <title>Multimodal Sentence Summarization via Multimodal Selective Encoding</title>
      <author><first>Haoran</first><last>Li</last></author>
      <author><first>Junnan</first><last>Zhu</last></author>
      <author><first>Jiajun</first><last>Zhang</last></author>
      <author><first>Xiaodong</first><last>He</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <pages>5655–5667</pages>
      <abstract>This paper studies the problem of generating a summary for a given sentence-image pair. Existing multimodal sequence-to-sequence approaches mainly focus on enhancing the decoder by visual signals, while ignoring that the image can improve the ability of the encoder to identify highlights of a news event or a document. Thus, we propose a multimodal selective gate network that considers reciprocal relationships between textual and multi-level visual features, including global image descriptor, activation grids, and object proposals, to select highlights of the event when encoding the source sentence. In addition, we introduce a modality regularization to encourage the summary to capture the highlights embedded in the image more accurately. To verify the generalization of our model, we adopt the multimodal selective gate to the text-based decoder and multimodal-based decoder. Experimental results on a public multimodal sentence summarization dataset demonstrate the advantage of our models over baselines. Further analysis suggests that our proposed multimodal selective gate network can effectively select important information in the input sentence.</abstract>
      <url hash="c739b976">2020.coling-main.496</url>
    </paper>
    <paper id="497">
      <title>Controllable Abstractive Sentence Summarization with Guiding Entities</title>
      <author><first>Changmeng</first><last>Zheng</last></author>
      <author><first>Yi</first><last>Cai</last></author>
      <author><first>Guanjie</first><last>Zhang</last></author>
      <author><first>Qing</first><last>Li</last></author>
      <pages>5668–5678</pages>
      <abstract>Entities are the major proportion and build up the topic of text summaries. Although existing text summarization models can produce promising results of automatic metrics, for example, ROUGE, it is difficult to guarantee that an entity is contained in generated summaries. In this paper, we propose a controllable abstractive sentence summarization model which generates summaries with guiding entities. Instead of generating summaries from left to right, we start with a selected entity, generate the left part first, then the right part of a complete summary. Compared to previous entity-based text summarization models, our method can ensure that entities appear in final output summaries rather than generating the complete sentence with implicit entity and article representations. Our model can also generate more novel entities with them incorporated into outputs directly. To evaluate the informativeness of the proposed model, we develop a fine-grained informativeness metrics in the relevance, extraness and omission perspectives. We conduct experiments in two widely-used sentence summarization datasets and experimental results show that our model outperforms the state-of-the-art methods in both automatic evaluation scores and informativeness metrics.</abstract>
      <url hash="ebe3f102">2020.coling-main.497</url>
    </paper>
    <paper id="498">
      <title><fixed-case>HOLMS</fixed-case>: Alternative Summary Evaluation with Large Language Models</title>
      <author><first>Yassine</first><last>Mrabet</last></author>
      <author><first>Dina</first><last>Demner-Fushman</last></author>
      <pages>5679–5688</pages>
      <abstract>Efficient document summarization requires evaluation measures that can not only rank a set of systems based on an average score, but also highlight which individual summary is better than another. However, despite the very active research on summarization approaches, few works have proposed new evaluation measures in the recent years. The standard measures relied upon for the development of summarization systems are most often ROUGE and BLEU which, despite being efficient in overall system ranking, remain lexical in nature and have a limited potential when it comes to training neural networks. In this paper, we present a new hybrid evaluation measure for summarization, called HOLMS, that combines both language models pre-trained on large corpora and lexical similarity measures. Through several experiments, we show that HOLMS outperforms ROUGE and BLEU substantially in its correlation with human judgments on several extractive summarization datasets for both linguistic quality and pyramid scores.</abstract>
      <url hash="8eaf5a22">2020.coling-main.498</url>
    </paper>
    <paper id="499">
      <title>How Domain Terminology Affects Meeting Summarization Performance</title>
      <author><first>Jia Jin</first><last>Koay</last></author>
      <author><first>Alexander</first><last>Roustai</last></author>
      <author><first>Xiaojin</first><last>Dai</last></author>
      <author><first>Dillon</first><last>Burns</last></author>
      <author><first>Alec</first><last>Kerrigan</last></author>
      <author id="fei-liu-utdallas"><first>Fei</first><last>Liu</last></author>
      <pages>5689–5695</pages>
      <abstract>Meetings are essential to modern organizations. Numerous meetings are held and recorded daily, more than can ever be comprehended. A meeting summarization system that identifies salient utterances from the transcripts to automatically generate meeting minutes can help. It empowers users to rapidly search and sift through large meeting collections. To date, the impact of domain terminology on the performance of meeting summarization remains understudied, despite that meetings are rich with domain knowledge. In this paper, we create gold-standard annotations for domain terminology on a sizable meeting corpus; they are known as jargon terms. We then analyze the performance of a meeting summarization system with and without jargon terms. Our findings reveal that domain terminology can have a substantial impact on summarization performance. We publicly release all domain terminology to advance research in meeting summarization.</abstract>
      <url hash="fd1ed29e">2020.coling-main.499</url>
    </paper>
    <paper id="500">
      <title>An Anchor-Based Automatic Evaluation Metric for Document Summarization</title>
      <author><first>Kexiang</first><last>Wang</last></author>
      <author><first>Tianyu</first><last>Liu</last></author>
      <author><first>Baobao</first><last>Chang</last></author>
      <author><first>Zhifang</first><last>Sui</last></author>
      <pages>5696–5701</pages>
      <abstract>The widespread adoption of reference-based automatic evaluation metrics such as ROUGE has promoted the development of document summarization. In this paper, we consider a new protocol for designing reference-based metrics that require the endorsement of source document(s). Following protocol, we propose an anchored ROUGE metric fixing each summary particle on source document, which bases the computation on more solid ground. Empirical results on benchmark datasets validate that source document helps to induce a higher correlation with human judgments for ROUGE metric. Being self-explanatory and easy-to-implement, the protocol can naturally foster various effective designs of reference-based metrics besides the anchored ROUGE introduced here.</abstract>
      <url hash="dd41a2c0">2020.coling-main.500</url>
    </paper>
    <paper id="501">
      <title>Metrics also Disagree in the Low Scoring Range: Revisiting Summarization Evaluation Metrics</title>
      <author><first>Manik</first><last>Bhandari</last></author>
      <author><first>Pranav Narayan</first><last>Gour</last></author>
      <author><first>Atabak</first><last>Ashfaq</last></author>
      <author><first>Pengfei</first><last>Liu</last></author>
      <pages>5702–5711</pages>
      <abstract>In text summarization, evaluating the efficacy of automatic metrics without human judgments has become recently popular. One exemplar work (Peyrard, 2019) concludes that automatic metrics strongly disagree when ranking high-scoring summaries. In this paper, we revisit their experiments and find that their observations stem from the fact that metrics disagree in ranking summaries from any narrow scoring range. We hypothesize that this may be because summaries are similar to each other in a narrow scoring range and are thus, difficult to rank. Apart from the width of the scoring range of summaries, we analyze three other properties that impact inter-metric agreement - Ease of Summarization, Abstractiveness, and Coverage.</abstract>
      <url hash="387dcd61">2020.coling-main.501</url>
    </paper>
    <paper id="502">
      <title>On the Faithfulness for <fixed-case>E</fixed-case>-commerce Product Summarization</title>
      <author><first>Peng</first><last>Yuan</last></author>
      <author><first>Haoran</first><last>Li</last></author>
      <author><first>Song</first><last>Xu</last></author>
      <author><first>Youzheng</first><last>Wu</last></author>
      <author><first>Xiaodong</first><last>He</last></author>
      <author><first>Bowen</first><last>Zhou</last></author>
      <pages>5712–5717</pages>
      <abstract>In this work, we present a model to generate e-commerce product summaries. The consistency between the generated summary and the product attributes is an essential criterion for the ecommerce product summarization task. To enhance the consistency, first, we encode the product attribute table to guide the process of summary generation. Second, we identify the attribute words from the vocabulary, and we constrain these attribute words can be presented in the summaries only through copying from the source, i.e., the attribute words not in the source cannot be generated. We construct a Chinese e-commerce product summarization dataset, and the experimental results on this dataset demonstrate that our models significantly improve the faithfulness.</abstract>
      <url hash="58f00e0f">2020.coling-main.502</url>
    </paper>
    <paper id="503">
      <title><fixed-case>S</fixed-case>um<fixed-case>T</fixed-case>itles: a Summarization Dataset with Low Extractiveness</title>
      <author><first>Valentin</first><last>Malykh</last></author>
      <author><first>Konstantin</first><last>Chernis</last></author>
      <author><first>Ekaterina</first><last>Artemova</last></author>
      <author><first>Irina</first><last>Piontkovskaya</last></author>
      <pages>5718–5730</pages>
      <abstract>The existing dialogue summarization corpora are significantly extractive. We introduce a methodology for dataset extractiveness evaluation and present a new low-extractive corpus of movie dialogues for abstractive text summarization along with baseline evaluation. The corpus contains 153k dialogues and consists of three parts: 1) automatically aligned subtitles, 2) automatically aligned scenes from scripts, and 3) manually aligned scenes from scripts. We also present an alignment algorithm which we use to construct the corpus.</abstract>
      <url hash="a345cf97">2020.coling-main.503</url>
    </paper>
    <paper id="504">
      <title><fixed-case>TWEETSUM</fixed-case>: Event oriented Social Summarization Dataset</title>
      <author><first>Ruifang</first><last>He</last></author>
      <author><first>Liangliang</first><last>Zhao</last></author>
      <author><first>Huanyu</first><last>Liu</last></author>
      <pages>5731–5736</pages>
      <abstract>With social media becoming popular, a vast of short and noisy messages are produced by millions of users when a hot event happens. Developing social summarization systems becomes more and more critical for people to quickly grasp core and essential information. However, the publicly available and high-quality large scale social summarization dataset is rare. Constructing such corpus is not easy and very expensive since short texts have very complex social characteristics. In this paper, we construct TWEETSUM, a new event-oriented dataset for social summarization. The original data is collected from twitter and contains 12 real world hot events with a total of 44,034 tweets and 11,240 users. Each event has four expert summaries, and we also have the annotation quality evaluation. In addition, we collect additional social signals (i.e. user relations, hashtags and user profiles) and further establish user relation network for each event. Besides the detailed dataset description, we show the performance of several typical extractive summarization methods on TWEETSUM to establish baselines. For further researches, we will release this dataset to the public.</abstract>
      <url hash="64c09af9">2020.coling-main.504</url>
    </paper>
    <paper id="505">
      <title>Exploiting a lexical resource for discourse connective disambiguation in <fixed-case>G</fixed-case>erman</title>
      <author><first>Peter</first><last>Bourgonje</last></author>
      <author><first>Manfred</first><last>Stede</last></author>
      <pages>5737–5748</pages>
      <abstract>In this paper we focus on connective identification and sense classification for explicit discourse relations in German, as two individual sub-tasks of the overarching Shallow Discourse Parsing task. We successively augment a purely-empirical approach based on contextualised embeddings with linguistic knowledge encoded in a connective lexicon. In this way, we improve over published results for connective identification, achieving a final F1-score of 87.93; and we introduce, to the best of our knowledge, first results for German sense classification, achieving an F1-score of 87.13. Our approach demonstrates that a connective lexicon can be a valuable resource for those languages that do not have a large PDTB-style-annotated coprus available.</abstract>
      <url hash="30c60888">2020.coling-main.505</url>
    </paper>
    <paper id="506">
      <title><fixed-case>C</fixed-case>hinese Paragraph-level Discourse Parsing with Global Backward and Local Reverse Reading</title>
      <author><first>Feng</first><last>Jiang</last></author>
      <author><first>Xiaomin</first><last>Chu</last></author>
      <author><first>Peifeng</first><last>Li</last></author>
      <author><first>Fang</first><last>Kong</last></author>
      <author><first>Qiaoming</first><last>Zhu</last></author>
      <pages>5749–5759</pages>
      <abstract>Discourse structure tree construction is the fundamental task of discourse parsing and most previous work focused on English. Due to the cultural and linguistic differences, existing successful methods on English discourse parsing cannot be transformed into Chinese directly, especially in paragraph level suffering from longer discourse units and fewer explicit connectives. To alleviate the above issues, we propose two reading modes, i.e., the global backward reading and the local reverse reading, to construct Chinese paragraph level discourse trees. The former processes discourse units from the end to the beginning in a document to utilize the left-branching bias of discourse structure in Chinese, while the latter reverses the position of paragraphs in a discourse unit to enhance the differentiation of coherence between adjacent discourse units. The experimental results on Chinese MCDTB demonstrate that our model outperforms all strong baselines.</abstract>
      <url hash="49f9e74c">2020.coling-main.506</url>
    </paper>
    <paper id="507">
      <title>A Neural Model for Aggregating Coreference Annotation in Crowdsourcing</title>
      <author><first>Maolin</first><last>Li</last></author>
      <author><first>Hiroya</first><last>Takamura</last></author>
      <author><first>Sophia</first><last>Ananiadou</last></author>
      <pages>5760–5773</pages>
      <abstract>Coreference resolution is the task of identifying all mentions in a text that refer to the same real-world entity. Collecting sufficient labelled data from expert annotators to train a high-performance coreference resolution system is time-consuming and expensive. Crowdsourcing makes it possible to obtain the required amounts of data rapidly and cost-effectively. However, crowd-sourced labels can be noisy. To ensure high-quality data, it is crucial to infer the correct labels by aggregating the noisy labels. In this paper, we split the aggregation into two subtasks, i.e, mention classification and coreference chain inference. Firstly, we predict the general class of each mention using an autoencoder, which incorporates contextual information about each mention, while at the same time taking into account the mention’s annotation complexity and annotators’ reliability at different levels. Secondly, to determine the coreference chain of each mention, we use weighted voting which takes into account the learned reliability in the first subtask. Experimental results demonstrate the effectiveness of our method in predicting the correct labels. We also illustrate our model’s interpretability through a comprehensive analysis of experimental results.</abstract>
      <url hash="357a764a">2020.coling-main.507</url>
    </paper>
    <paper id="508">
      <title>Variation in Coreference Strategies across Genres and Production Media</title>
      <author><first>Berfin</first><last>Aktaş</last></author>
      <author><first>Manfred</first><last>Stede</last></author>
      <pages>5774–5785</pages>
      <abstract>In response to (i) inconclusive results in the literature as to the properties of coreference chains in written versus spoken language, and (ii) a general lack of work on automatic coreference resolution on both spoken language and social media, we undertake a corpus study involving the various genre sections of Ontonotes, the Switchboard corpus, and a corpus of Twitter conversations. Using a set of measures that previously have been applied individually to different data sets, we find fairly clear patterns of “behavior” for the different genres/media. Besides their role for psycholinguistic investigation (why do we employ different coreference strategies when we write or speak) and for the placement of Twitter in the spoken–written continuum, we see our results as a contribution to approaching genre-/media-specific coreference resolution.</abstract>
      <url hash="ae9b8700">2020.coling-main.508</url>
    </paper>
    <paper id="509">
      <title>Towards automatically generating Questions under Discussion to link information and discourse structure</title>
      <author><first>Kordula</first><last>De Kuthy</last></author>
      <author><first>Madeeswaran</first><last>Kannan</last></author>
      <author><first>Haemanth</first><last>Santhi Ponnusamy</last></author>
      <author><first>Detmar</first><last>Meurers</last></author>
      <pages>5786–5798</pages>
      <abstract>Questions under Discussion (QUD; Roberts, 2012) are emerging as a conceptually fruitful approach to spelling out the connection between the information structure of a sentence and the nature of the discourse in which the sentence can function. To make this approach useful for analyzing authentic data, Riester, Brunetti &amp; De Kuthy (2018) presented a discourse annotation framework based on explicit pragmatic principles for determining a QUD for every assertion in a text. De Kuthy et al. (2018) demonstrate that this supports more reliable discourse structure annotation, and Ziai and Meurers (2018) show that based on explicit questions, automatic focus annotation becomes feasible. But both approaches are based on manually specified questions. In this paper, we present an automatic question generation approach to partially automate QUD annotation by generating all potentially relevant questions for a given sentence. While transformation rules can concisely capture the typical question formation process, a rule-based approach is not sufficiently robust for authentic data. We therefore employ the transformation rules to generate a large set of sentence-question-answer triples and train a neural question generation model on them to obtain both systematic question type coverage and robustness.</abstract>
      <url hash="8b09e90c">2020.coling-main.509</url>
    </paper>
    <paper id="510">
      <title>Learning to Decouple Relations: Few-Shot Relation Classification with Entity-Guided Attention and Confusion-Aware Training</title>
      <author><first>Yingyao</first><last>Wang</last></author>
      <author><first>Junwei</first><last>Bao</last></author>
      <author><first>Guangyi</first><last>Liu</last></author>
      <author><first>Youzheng</first><last>Wu</last></author>
      <author><first>Xiaodong</first><last>He</last></author>
      <author><first>Bowen</first><last>Zhou</last></author>
      <author><first>Tiejun</first><last>Zhao</last></author>
      <pages>5799–5809</pages>
      <abstract>This paper aims to enhance the few-shot relation classification especially for sentences that jointly describe multiple relations. Due to the fact that some relations usually keep high co-occurrence in the same context, previous few-shot relation classifiers struggle to distinguish them with few annotated instances. To alleviate the above relation confusion problem, we propose CTEG, a model equipped with two novel mechanisms to learn to decouple these easily-confused relations. On the one hand, an Entity -Guided Attention (EGA) mechanism, which leverages the syntactic relations and relative positions between each word and the specified entity pair, is introduced to guide the attention to filter out information causing confusion. On the other hand, a Confusion-Aware Training (CAT) method is proposed to explicitly learn to distinguish relations by playing a pushing-away game between classifying a sentence into a true relation and its confusing relation. Extensive experiments are conducted on the FewRel dataset, and the results show that our proposed model achieves comparable and even much better results to strong baselines in terms of accuracy. Furthermore, the ablation test and case study verify the effectiveness of our proposed EGA and CAT, especially in addressing the relation confusion problem.</abstract>
      <url hash="55e58987">2020.coling-main.510</url>
    </paper>
    <paper id="511">
      <title>Semi-supervised Multi-task Learning for Multi-label Fine-grained Sexism Classification</title>
      <author><first>Harika</first><last>Abburi</last></author>
      <author><first>Pulkit</first><last>Parikh</last></author>
      <author><first>Niyati</first><last>Chhaya</last></author>
      <author><first>Vasudeva</first><last>Varma</last></author>
      <pages>5810–5820</pages>
      <abstract>Sexism, a form of oppression based on one’s sex, manifests itself in numerous ways and causes enormous suffering. In view of the growing number of experiences of sexism reported online, categorizing these recollections automatically can assist the fight against sexism, as it can facilitate effective analyses by gender studies researchers and government officials involved in policy making. In this paper, we investigate the fine-grained, multi-label classification of accounts (reports) of sexism. To the best of our knowledge, we work with considerably more categories of sexism than any published work through our 23-class problem formulation. Moreover, we propose a multi-task approach for fine-grained multi-label sexism classification that leverages several supporting tasks without incurring any manual labeling cost. Unlabeled accounts of sexism are utilized through unsupervised learning to help construct our multi-task setup. We also devise objective functions that exploit label correlations in the training data explicitly. Multiple proposed methods outperform the state-of-the-art for multi-label sexism classification on a recently released dataset across five standard metrics.</abstract>
      <url hash="2e3bebe3">2020.coling-main.511</url>
    </paper>
    <paper id="512">
      <title>Using Eye-tracking Data to Predict the Readability of <fixed-case>B</fixed-case>razilian <fixed-case>P</fixed-case>ortuguese Sentences in Single-task, Multi-task and Sequential Transfer Learning Approaches</title>
      <author><first>Sidney</first><last>Evaldo Leal</last></author>
      <author><first>João Marcos</first><last>Munguba Vieira</last></author>
      <author><first>Erica</first><last>dos Santos Rodrigues</last></author>
      <author><first>Elisângela</first><last>Nogueira Teixeira</last></author>
      <author><first>Sandra</first><last>Aluísio</last></author>
      <pages>5821–5831</pages>
      <abstract>Sentence complexity assessment is a relatively new task in Natural Language Processing. One of its aims is to highlight in a text which sentences are more complex to support the simplification of contents for a target audience (e.g., children, cognitively impaired users, non-native speakers and low-literacy readers (Scarton and Specia, 2018)). This task is evaluated using datasets of pairs of aligned sentences including the complex and simple version of the same sentence. For Brazilian Portuguese, the task was addressed by (Leal et al., 2018), who set up the first dataset to evaluate the task in this language, reaching 87.8% of accuracy with linguistic features. The present work advances these results, using models inspired by (Gonzalez-Garduño and Søgaard, 2018), which hold the state-of-the-art for the English language, with multi-task learning and eye-tracking measures. First-Pass Duration, Total Regression Duration and Total Fixation Duration were used in two moments; first to select a subset of linguistic features and then as an auxiliary task in the multi-task and sequential learning models. The best model proposed here reaches the new state-of-the-art for Portuguese with 97.5% accuracy 1 , an increase of almost 10 points compared to the best previous results, in addition to proposing improvements in the public dataset after analysing the errors of our best model.</abstract>
      <url hash="7976d13b">2020.coling-main.512</url>
    </paper>
    <paper id="513">
      <title>Retrieving Skills from Job Descriptions: A Language Model Based Extreme Multi-label Classification Framework</title>
      <author><first>Akshay</first><last>Bhola</last></author>
      <author><first>Kishaloy</first><last>Halder</last></author>
      <author><first>Animesh</first><last>Prasad</last></author>
      <author><first>Min-Yen</first><last>Kan</last></author>
      <pages>5832–5842</pages>
      <abstract>We introduce a deep learning model to learn the set of enumerated job skills associated with a job description. In our analysis of a large-scale government job portal mycareersfuture.sg, we observe that as much as 65% of job descriptions miss describing a significant number of relevant skills. Our model addresses this task from the perspective of an extreme multi-label classification (XMLC) problem, where descriptions are the evidence for the binary relevance of thousands of individual skills. Building upon the current state-of-the-art language modeling approaches such as BERT, we show our XMLC method improves on an existing baseline solution by over 9% and 7% absolute improvements in terms of recall and normalized discounted cumulative gain. We further show that our approach effectively addresses the missing skills problem, and helps in recovering relevant skills that were missed out in the job postings by taking into account the structured semantic representation of skills and their co-occurrences through a Correlation Aware Bootstrapping process. We further show that our approach, to ensure the BERT-XMLC model accounts for structured semantic representation of skills and their co-occurrences through a Correlation Aware Bootstrapping process, effectively addresses the missing skills problem, and helps in recovering relevant skills that were missed out in the job postings. To facilitate future research and replication of our work, we have made the dataset and the implementation of our model publicly available.</abstract>
      <url hash="6da419b0">2020.coling-main.513</url>
    </paper>
    <paper id="514">
      <title>Native-like Expression Identification by Contrasting Native and Proficient Second Language Speakers</title>
      <author><first>Oleksandr</first><last>Harust</last></author>
      <author><first>Yugo</first><last>Murawaki</last></author>
      <author><first>Sadao</first><last>Kurohashi</last></author>
      <pages>5843–5854</pages>
      <abstract>We propose a novel task of native-like expression identification by contrasting texts written by native speakers and those by proficient second language speakers. This task is highly challenging mainly because 1) the combinatorial nature of expressions prevents us from choosing candidate expressions a priori and 2) the distributions of the two types of texts overlap considerably. Our solution to the first problem is to combine a powerful neural network-based classifier of sentence-level nativeness with an explainability method that measures an approximate contribution of a given expression to the classifier’s prediction. To address the second problem, we introduce a special label neutral and reformulate the classification task as complementary-label learning. Our crowdsourcing-based evaluation and in-depth analysis suggest that our method successfully uncovers linguistically interesting usages distinctive of native speech.</abstract>
      <url hash="c9956554">2020.coling-main.514</url>
    </paper>
    <paper id="515">
      <title>An Analysis of Dataset Overlap on <fixed-case>W</fixed-case>inograd-Style Tasks</title>
      <author><first>Ali</first><last>Emami</last></author>
      <author><first>Kaheer</first><last>Suleman</last></author>
      <author><first>Adam</first><last>Trischler</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <pages>5855–5865</pages>
      <abstract>The Winograd Schema Challenge (WSC) and variants inspired by it have become important benchmarks for common-sense reasoning (CSR). Model performance on the WSC has quickly progressed from chance-level to near-human using neural language models trained on massive corpora. In this paper, we analyze the effects of varying degrees of overlaps that occur between these corpora and the test instances in WSC-style tasks. We find that a large number of test instances overlap considerably with the pretraining corpora on which state-of-the-art models are trained, and that a significant drop in classification accuracy occurs when models are evaluated on instances with minimal overlap. Based on these results, we provide the WSC-Web dataset, consisting of over 60k pronoun disambiguation problems scraped from web data, being both the largest corpus to date, and having a significantly lower proportion of overlaps with current pretraining corpora.</abstract>
      <url hash="362f2902">2020.coling-main.515</url>
    </paper>
    <paper id="516">
      <title>The Indigenous Languages Technology project at <fixed-case>NRC</fixed-case> <fixed-case>C</fixed-case>anada: An empowerment-oriented approach to developing language software</title>
      <author><first>Roland</first><last>Kuhn</last></author>
      <author><first>Fineen</first><last>Davis</last></author>
      <author><first>Alain</first><last>Désilets</last></author>
      <author><first>Eric</first><last>Joanis</last></author>
      <author><first>Anna</first><last>Kazantseva</last></author>
      <author><first>Rebecca</first><last>Knowles</last></author>
      <author><first>Patrick</first><last>Littell</last></author>
      <author><first>Delaney</first><last>Lothian</last></author>
      <author><first>Aidan</first><last>Pine</last></author>
      <author><first>Caroline</first><last>Running Wolf</last></author>
      <author><first>Eddie</first><last>Santos</last></author>
      <author><first>Darlene</first><last>Stewart</last></author>
      <author><first>Gilles</first><last>Boulianne</last></author>
      <author><first>Vishwa</first><last>Gupta</last></author>
      <author><first>Brian</first><last>Maracle Owennatékha</last></author>
      <author><first>Akwiratékha’</first><last>Martin</last></author>
      <author><first>Christopher</first><last>Cox</last></author>
      <author><first>Marie-Odile</first><last>Junker</last></author>
      <author><first>Olivia</first><last>Sammons</last></author>
      <author><first>Delasie</first><last>Torkornoo</last></author>
      <author><first>Nathan</first><last>Thanyehténhas Brinklow</last></author>
      <author><first>Sara</first><last>Child</last></author>
      <author><first>Benoît</first><last>Farley</last></author>
      <author><first>David</first><last>Huggins-Daines</last></author>
      <author><first>Daisy</first><last>Rosenblum</last></author>
      <author><first>Heather</first><last>Souter</last></author>
      <pages>5866–5878</pages>
      <abstract>This paper surveys the first, three-year phase of a project at the National Research Council of Canada that is developing software to assist Indigenous communities in Canada in preserving their languages and extending their use. The project aimed to work within the empowerment paradigm, where collaboration with communities and fulfillment of their goals is central. Since many of the technologies we developed were in response to community needs, the project ended up as a collection of diverse subprojects, including the creation of a sophisticated framework for building verb conjugators for highly inflectional polysynthetic languages (such as Kanyen’kéha, in the Iroquoian language family), release of what is probably the largest available corpus of sentences in a polysynthetic language (Inuktut) aligned with English sentences and experiments with machine translation (MT) systems trained on this corpus, free online services based on automatic speech recognition (ASR) for easing the transcription bottleneck for recordings of speech in Indigenous languages (and other languages), software for implementing text prediction and read-along audiobooks for Indigenous languages, and several other subprojects.</abstract>
      <url hash="4dfe37b8">2020.coling-main.516</url>
    </paper>
    <paper id="517">
      <title>Cross-Lingual Emotion Lexicon Induction using Representation Alignment in Low-Resource Settings</title>
      <author><first>Arun</first><last>Ramachandran</last></author>
      <author><first>Gerard</first><last>de Melo</last></author>
      <pages>5879–5890</pages>
      <abstract>Emotion lexicons provide information about associations between words and emotions. They have proven useful in analyses of reviews, literary texts, and posts on social media, among other things. We evaluate the feasibility of deriving emotion lexicons cross-lingually, especially for low-resource languages, from existing emotion lexicons in resource-rich languages. For this, we start out from very small corpora to induce cross-lingually aligned vector spaces. Our study empirically analyses the effectiveness of the induced emotion lexicons by measuring translation precision and correlations with existing emotion lexicons, along with measurements on a downstream task of sentence emotion prediction.</abstract>
      <url hash="f43cd808">2020.coling-main.517</url>
    </paper>
    <paper id="518">
      <title>Don’t Patronize Me! An Annotated Dataset with Patronizing and Condescending Language towards Vulnerable Communities</title>
      <author><first>Carla</first><last>Perez Almendros</last></author>
      <author><first>Luis</first><last>Espinosa Anke</last></author>
      <author><first>Steven</first><last>Schockaert</last></author>
      <pages>5891–5902</pages>
      <abstract>In this paper, we introduce a new annotated dataset which is aimed at supporting the development of NLP models to identify and categorize language that is patronizing or condescending towards vulnerable communities (e.g. refugees, homeless people, poor families). While the prevalence of such language in the general media has long been shown to have harmful effects, it differs from other types of harmful language, in that it is generally used unconsciously and with good intentions. We furthermore believe that the often subtle nature of patronizing and condescending language (PCL) presents an interesting technical challenge for the NLP community. Our analysis of the proposed dataset shows that identifying PCL is hard for standard NLP models, with language models such as BERT achieving the best results.</abstract>
      <url hash="8db103e8">2020.coling-main.518</url>
    </paper>
    <paper id="519">
      <title>100,000 Podcasts: A Spoken <fixed-case>E</fixed-case>nglish Document Corpus</title>
      <author><first>Ann</first><last>Clifton</last></author>
      <author><first>Sravana</first><last>Reddy</last></author>
      <author><first>Yongze</first><last>Yu</last></author>
      <author><first>Aasish</first><last>Pappu</last></author>
      <author><first>Rezvaneh</first><last>Rezapour</last></author>
      <author><first>Hamed</first><last>Bonab</last></author>
      <author><first>Maria</first><last>Eskevich</last></author>
      <author><first>Gareth</first><last>Jones</last></author>
      <author><first>Jussi</first><last>Karlgren</last></author>
      <author><first>Ben</first><last>Carterette</last></author>
      <author><first>Rosie</first><last>Jones</last></author>
      <pages>5903–5917</pages>
      <abstract>Podcasts are a large and growing repository of spoken audio. As an audio format, podcasts are more varied in style and production type than broadcast news, contain more genres than typically studied in video data, and are more varied in style and format than previous corpora of conversations. When transcribed with automatic speech recognition they represent a noisy but fascinating collection of documents which can be studied through the lens of natural language processing, information retrieval, and linguistics. Paired with the audio files, they are also a resource for speech processing and the study of paralinguistic, sociolinguistic, and acoustic aspects of the domain. We introduce the Spotify Podcast Dataset, a new corpus of 100,000 podcasts. We demonstrate the complexity of the domain with a case study of two tasks: (1) passage search and (2) summarization. This is orders of magnitude larger than previous speech corpora used for search and summarization. Our results show that the size and variability of this corpus opens up new avenues for research.</abstract>
      <url hash="853d8af4">2020.coling-main.519</url>
    </paper>
    <paper id="520">
      <title>A Contextual Alignment Enhanced Cross Graph Attention Network for Cross-lingual Entity Alignment</title>
      <author><first>Zhiwen</first><last>Xie</last></author>
      <author><first>Runjie</first><last>Zhu</last></author>
      <author><first>Kunsong</first><last>Zhao</last></author>
      <author><first>Jin</first><last>Liu</last></author>
      <author><first>Guangyou</first><last>Zhou</last></author>
      <author><first>Jimmy Xiangji</first><last>Huang</last></author>
      <pages>5918–5928</pages>
      <abstract>Cross-lingual entity alignment, which aims to match equivalent entities in KGs with different languages, has attracted considerable focus in recent years. Recently, many graph neural network (GNN) based methods are proposed for entity alignment and obtain promising results. However, existing GNN-based methods consider the two KGs independently and learn embeddings for different KGs separately, which ignore the useful pre-aligned links between two KGs. In this paper, we propose a novel Contextual Alignment Enhanced Cross Graph Attention Network (CAECGAT) for the task of cross-lingual entity alignment, which is able to jointly learn the embeddings in different KGs by propagating cross-KG information through pre-aligned seed alignments. We conduct extensive experiments on three benchmark cross-lingual entity alignment datasets. The experimental results demonstrate that our proposed method obtains remarkable performance gains compared to state-of-the-art methods.</abstract>
      <url hash="8879014d">2020.coling-main.520</url>
    </paper>
    <paper id="521">
      <title><fixed-case>P</fixed-case>he<fixed-case>MT</fixed-case>: A Phenomenon-wise Dataset for Machine Translation Robustness on User-Generated Contents</title>
      <author><first>Ryo</first><last>Fujii</last></author>
      <author><first>Masato</first><last>Mita</last></author>
      <author><first>Kaori</first><last>Abe</last></author>
      <author><first>Kazuaki</first><last>Hanawa</last></author>
      <author><first>Makoto</first><last>Morishita</last></author>
      <author><first>Jun</first><last>Suzuki</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <pages>5929–5943</pages>
      <abstract>Neural Machine Translation (NMT) has shown drastic improvement in its quality when translating clean input, such as text from the news domain. However, existing studies suggest that NMT still struggles with certain kinds of input with considerable noise, such as User-Generated Contents (UGC) on the Internet. To make better use of NMT for cross-cultural communication, one of the most promising directions is to develop a model that correctly handles these expressions. Though its importance has been recognized, it is still not clear as to what creates the great gap in performance between the translation of clean input and that of UGC. To answer the question, we present a new dataset, PheMT, for evaluating the robustness of MT systems against specific linguistic phenomena in Japanese-English translation. Our experiments with the created dataset revealed that not only our in-house models but even widely used off-the-shelf systems are greatly disturbed by the presence of certain phenomena.</abstract>
      <url hash="9024c715">2020.coling-main.521</url>
    </paper>
    <paper id="522">
      <title>Detecting Non-literal Translations by Fine-tuning Cross-lingual Pre-trained Language Models</title>
      <author><first>Yuming</first><last>Zhai</last></author>
      <author><first>Gabriel</first><last>Illouz</last></author>
      <author><first>Anne</first><last>Vilnat</last></author>
      <pages>5944–5956</pages>
      <abstract>Human-generated non-literal translations reflect the richness of human languages and are sometimes indispensable to ensure adequacy and fluency. Non-literal translations are difficult to produce even for human translators, especially for foreign language learners, and machine translations are still on the way to simulate human ones on this aspect. In order to foster the study on appropriate and creative non-literal translations, automatically detecting them in parallel corpora is an important step, which can benefit downstream NLP tasks or help to construct materials to teach translation. This article demonstrates that generic sentence representations produced by a pre-trained cross-lingual language model could be fine-tuned to solve this task. We show that there exists a moderate positive correlation between the prediction probability of being human translation and the non-literal translations’ proportion in a sentence. The fine-tuning experiments show an accuracy of 80.16% when predicting the presence of non-literal translations in a sentence and an accuracy of 85.20% when distinguishing literal and non-literal translations at phrase level. We further conduct a linguistic error analysis and propose directions for future work.</abstract>
      <url hash="ec6f1018">2020.coling-main.522</url>
    </paper>
    <paper id="523">
      <title><fixed-case>W</fixed-case>iki<fixed-case>UMLS</fixed-case>: Aligning <fixed-case>UMLS</fixed-case> to <fixed-case>W</fixed-case>ikipedia via Cross-lingual Neural Ranking</title>
      <author><first>Afshin</first><last>Rahimi</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Karin</first><last>Verspoor</last></author>
      <pages>5957–5962</pages>
      <abstract>We present our work on aligning the Unified Medical Language System (UMLS) to Wikipedia, to facilitate manual alignment of the two resources. We propose a cross-lingual neural reranking model to match a UMLS concept with a Wikipedia page, which achieves a recall@1of 72%, a substantial improvement of 20% over word- and char-level BM25, enabling manual alignment with minimal effort. We release our resources, including ranked Wikipedia pages for 700k UMLSconcepts, and WikiUMLS, a dataset for training and evaluation of alignment models between UMLS and Wikipedia collected from Wikidata. This will provide easier access to Wikipedia for health professionals, patients, and NLP systems, including in multilingual settings.</abstract>
      <url hash="4044fcdc">2020.coling-main.523</url>
    </paper>
    <paper id="524">
      <title>The Transference Architecture for Automatic Post-Editing</title>
      <author><first>Santanu</first><last>Pal</last></author>
      <author><first>Hongfei</first><last>Xu</last></author>
      <author><first>Nico</first><last>Herbig</last></author>
      <author><first>Sudip Kumar</first><last>Naskar</last></author>
      <author><first>Antonio</first><last>Krüger</last></author>
      <author><first>Josef</first><last>van Genabith</last></author>
      <pages>5963–5974</pages>
      <abstract>In automatic post-editing (APE) it makes sense to condition post-editing (pe) decisions on both the source (src) and the machine translated text (mt) as input. This has led to multi-encoder based neural APE approaches. A research challenge now is the search for architectures that best support the capture, preparation and provision of src and mt information and its integration with pe decisions. In this paper we present an efficient multi-encoder based APE model, called transference. Unlike previous approaches, it (i) uses a transformer encoder block for src, (ii) followed by a decoder block, but without masking for self-attention on mt, which effectively acts as second encoder combining src –&gt; mt, and (iii) feeds this representation into a final decoder block generating pe. Our model outperforms the best performing systems by 1 BLEU point on the WMT 2016, 2017, and 2018 English–German APE shared tasks (PBSMT and NMT). Furthermore, the results of our model on the WMT 2019 APE task using NMT data shows a comparable performance to the state-of-the-art system. The inference time of our model is similar to the vanilla transformer-based NMT system although our model deals with two separate encoders. We further investigate the importance of our newly introduced second encoder and find that a too small amount of layers does hurt the performance, while reducing the number of layers of the decoder does not matter much.</abstract>
      <url hash="66fed489">2020.coling-main.524</url>
    </paper>
    <paper id="525">
      <title>Better Sign Language Translation with <fixed-case>STMC</fixed-case>-Transformer</title>
      <author><first>Kayo</first><last>Yin</last></author>
      <author><first>Jesse</first><last>Read</last></author>
      <pages>5975–5989</pages>
      <abstract>Sign Language Translation (SLT) first uses a Sign Language Recognition (SLR) system to extract sign language glosses from videos. Then, a translation system generates spoken language translations from the sign language glosses. This paper focuses on the translation system and introduces the STMC-Transformer which improves on the current state-of-the-art by over 5 and 7 BLEU respectively on gloss-to-text and video-to-text translation of the PHOENIX-Weather 2014T dataset. On the ASLG-PC12 corpus, we report an increase of over 16 BLEU. We also demonstrate the problem in current methods that rely on gloss supervision. The video-to-text translation of our STMC-Transformer outperforms translation of GT glosses. This contradicts previous claims that GT gloss translation acts as an upper bound for SLT performance and reveals that glosses are an inefficient representation of sign language. For future SLT research, we therefore suggest an end-to-end training of the recognition and translation models, or using a different sign language annotation scheme.</abstract>
      <url hash="11f6d2c2">2020.coling-main.525</url>
    </paper>
    <paper id="526">
      <title>A Simple and Effective Approach to Robust Unsupervised Bilingual Dictionary Induction</title>
      <author><first>Yanyang</first><last>Li</last></author>
      <author><first>Yingfeng</first><last>Luo</last></author>
      <author><first>Ye</first><last>Lin</last></author>
      <author><first>Quan</first><last>Du</last></author>
      <author><first>Huizhen</first><last>Wang</last></author>
      <author><first>Shujian</first><last>Huang</last></author>
      <author><first>Tong</first><last>Xiao</last></author>
      <author><first>Jingbo</first><last>Zhu</last></author>
      <pages>5990–6001</pages>
      <abstract>Unsupervised Bilingual Dictionary Induction methods based on the initialization and the self-learning have achieved great success in similar language pairs, e.g., English-Spanish. But they still fail and have an accuracy of 0% in many distant language pairs, e.g., English-Japanese. In this work, we show that this failure results from the gap between the actual initialization performance and the minimum initialization performance for the self-learning to succeed. We propose Iterative Dimension Reduction to bridge this gap. Our experiments show that this simple method does not hamper the performance of similar language pairs and achieves an accuracy of 13.64 55.53% between English and four distant languages, i.e., Chinese, Japanese, Vietnamese and Thai.</abstract>
      <url hash="7185992b">2020.coling-main.526</url>
    </paper>
    <paper id="527">
      <title>Data Selection for Bilingual Lexicon Induction from Specialized Comparable Corpora</title>
      <author><first>Martin</first><last>Laville</last></author>
      <author><first>Amir</first><last>Hazem</last></author>
      <author><first>Emmanuel</first><last>Morin</last></author>
      <author><first>Phillippe</first><last>Langlais</last></author>
      <pages>6002–6012</pages>
      <abstract>Narrow specialized comparable corpora are often small in size. This particularity makes it difficult to build efficient models to acquire translation equivalents, especially for less frequent and rare words. One way to overcome this issue is to enrich the specialized corpora with out-of-domain resources. Although some recent studies have shown improvements using data augmentation, the enrichment method was roughly conducted by adding out-of-domain data with no particular attention given to how to enrich words and how to do it optimally. In this paper, we contrast several data selection techniques to improve bilingual lexicon induction from specialized comparable corpora. We first apply two well-established data selection techniques often used in machine translation that is: Tf-Idf and cross entropy. Then, we propose to exploit BERT for data selection. Overall, all the proposed techniques improve the quality of the extracted bilingual lexicons by a large margin. The best performing model is the cross entropy, obtaining a gain of about 4 points in MAP while decreasing computation time by a factor of 10.</abstract>
      <url hash="8944ad0c">2020.coling-main.527</url>
    </paper>
    <paper id="528">
      <title>A Locally Linear Procedure for Word Translation</title>
      <author><first>Soham</first><last>Dan</last></author>
      <author><first>Hagai</first><last>Taitelbaum</last></author>
      <author><first>Jacob</first><last>Goldberger</last></author>
      <pages>6013–6018</pages>
      <abstract>Learning a mapping between word embeddings of two languages given a dictionary is an important problem with several applications. A common mapping approach is using an orthogonal matrix. The Orthogonal Procrustes Analysis (PA) algorithm can be applied to find the optimal orthogonal matrix. This solution restricts the expressiveness of the translation model which may result in sub-optimal translations. We propose a natural extension of the PA algorithm that uses multiple orthogonal translation matrices to model the mapping and derive an algorithm to learn these multiple matrices. We achieve better performance in a bilingual word translation task and a cross-lingual word similarity task compared to the single matrix baseline. We also show how multiple matrices can model multiple senses of a word.</abstract>
      <url hash="b0c6a36e">2020.coling-main.528</url>
    </paper>
    <paper id="529">
      <title>Rethinking the Value of Transformer Components</title>
      <author><first>Wenxuan</first><last>Wang</last></author>
      <author><first>Zhaopeng</first><last>Tu</last></author>
      <pages>6019–6029</pages>
      <abstract>Transformer becomes the state-of-the-art translation model, while it is not well studied how each intermediate component contributes to the model performance, which poses significant challenges for designing optimal architectures. In this work, we bridge this gap by evaluating the impact of individual component (sub-layer) in trained Transformer models from different perspectives. Experimental results across language pairs, training strategies, and model capacities show that certain components are consistently more important than the others. We also report a number of interesting findings that might help humans better analyze, understand and improve Transformer models. Based on these observations, we further propose a new training strategy that can improves translation performance by distinguishing the unimportant components in training.</abstract>
      <url hash="67775673">2020.coling-main.529</url>
    </paper>
    <paper id="530">
      <title>The <fixed-case>SADID</fixed-case> Evaluation Datasets for Low-Resource Spoken Language Machine Translation of <fixed-case>A</fixed-case>rabic Dialects</title>
      <author><first>Wael</first><last>Abid</last></author>
      <pages>6030–6043</pages>
      <abstract>Low-resource Machine Translation recently gained a lot of popularity, and for certain languages, it has made great strides. However, it is still difficult to track progress in other languages for which there is no publicly available evaluation data. In this paper, we introduce benchmark datasets for Arabic and its dialects. We describe our design process and motivations and analyze the datasets to understand their resulting properties. Numerous successful attempts use large monolingual corpora to augment low-resource pairs. We try to approach augmentation differently and investigate whether it is possible to improve MT models without any external sources of data. We accomplish this by bootstrapping existing parallel sentences and complement this with multilingual training to achieve strong baselines.</abstract>
      <url hash="896ff392">2020.coling-main.530</url>
    </paper>
    <paper id="531">
      <title>Combining Word Embeddings with Bilingual Orthography Embeddings for Bilingual Dictionary Induction</title>
      <author><first>Silvia</first><last>Severini</last></author>
      <author><first>Viktor</first><last>Hangya</last></author>
      <author><first>Alexander</first><last>Fraser</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>6044–6055</pages>
      <abstract>Bilingual dictionary induction (BDI) is the task of accurately translating words to the target language. It is of great importance in many low-resource scenarios where cross-lingual training data is not available. To perform BDI, bilingual word embeddings (BWEs) are often used due to their low bilingual training signal requirements. They achieve high performance, but problematic cases still remain, such as the translation of rare words or named entities, which often need to be transliterated. In this paper, we enrich BWE-based BDI with transliteration information by using Bilingual Orthography Embeddings (BOEs). BOEs represent source and target language transliteration word pairs with similar vectors. A key problem in our BDI setup is to decide which information source – BWEs (or semantics) vs. BOEs (or orthography) – is more reliable for a particular word pair. We propose a novel classification-based BDI system that uses BWEs, BOEs and a number of other features to make this decision. We test our system on English-Russian BDI and show improved performance. In addition, we show the effectiveness of our BOEs by successfully using them for transliteration mining based on cosine similarity.</abstract>
      <url hash="776a4be3">2020.coling-main.531</url>
    </paper>
    <paper id="532">
      <title>Understanding Translationese in Multi-view Embedding Spaces</title>
      <author><first>Koel</first><last>Dutta Chowdhury</last></author>
      <author><first>Cristina</first><last>España-Bonet</last></author>
      <author><first>Josef</first><last>van Genabith</last></author>
      <pages>6056–6062</pages>
      <abstract>Recent studies use a combination of lexical and syntactic features to show that footprints of the source language remain visible in translations, to the extent that it is possible to predict the original source language from the translation. In this paper, we focus on embedding-based semantic spaces, exploiting departures from isomorphism between spaces built from original target language and translations into this target language to predict relations between languages in an unsupervised way. We use different views of the data — words, parts of speech, semantic tags and synsets — to track translationese. Our analysis shows that (i) semantic distances between original target language and translations into this target language can be detected using the notion of isomorphism, (ii) language family ties with characteristics similar to linguistically motivated phylogenetic trees can be inferred from the distances and (iii) with delexicalised embeddings exhibiting source-language interference most significantly, other levels of abstraction display the same tendency, indicating the lexicalised results to be not “just” due to possible topic differences between original and translated texts. To the best of our knowledge, this is the first time departures from isomorphism between embedding spaces are used to track translationese.</abstract>
      <url hash="6c65d093">2020.coling-main.532</url>
    </paper>
    <paper id="533">
      <title>Building The First <fixed-case>E</fixed-case>nglish-<fixed-case>B</fixed-case>razilian <fixed-case>P</fixed-case>ortuguese Corpus for Automatic Post-Editing</title>
      <author><first>Felipe</first><last>Almeida Costa</last></author>
      <author><first>Thiago</first><last>Castro Ferreira</last></author>
      <author><first>Adriana</first><last>Pagano</last></author>
      <author><first>Wagner</first><last>Meira</last></author>
      <pages>6063–6069</pages>
      <abstract>This paper introduces the first corpus for Automatic Post-Editing of English and a low-resource language, Brazilian Portuguese. The source English texts were extracted from the WebNLG corpus and automatically translated into Portuguese using a state-of-the-art industrial neural machine translator. Post-edits were then obtained in an experiment with native speakers of Brazilian Portuguese. To assess the quality of the corpus, we performed error analysis and computed complexity indicators measuring how difficult the APE task would be. We report preliminary results of Phrase-Based and Neural Machine Translation Models on this new corpus. Data and code publicly available in our repository.</abstract>
      <url hash="dc04c14a">2020.coling-main.533</url>
    </paper>
    <paper id="534">
      <title>Analysing cross-lingual transfer in lemmatisation for <fixed-case>I</fixed-case>ndian languages</title>
      <author><first>Kumar</first><last>Saurav</last></author>
      <author><first>Kumar</first><last>Saunack</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>6070–6076</pages>
      <abstract>Lemmatization aims to reduce the sparse data problem by relating the inflected forms of a word to its dictionary form. However, most of the prior work on this topic has focused on high resource languages. In this paper, we evaluate cross-lingual approaches for low resource languages, especially in the context of morphologically rich Indian languages. We test our model on six languages from two different families and develop linguistic insights into each model’s performance.</abstract>
      <url hash="3b55cd40">2020.coling-main.534</url>
    </paper>
    <paper id="535">
      <title>Neural Automated Essay Scoring Incorporating Handcrafted Features</title>
      <author><first>Masaki</first><last>Uto</last></author>
      <author><first>Yikuan</first><last>Xie</last></author>
      <author><first>Maomi</first><last>Ueno</last></author>
      <pages>6077–6088</pages>
      <abstract>Automated essay scoring (AES) is the task of automatically assigning scores to essays as an alternative to grading by human raters. Conventional AES typically relies on handcrafted features, whereas recent studies have proposed AES models based on deep neural networks (DNNs) to obviate the need for feature engineering. Furthermore, hybrid methods that integrate handcrafted features in a DNN-AES model have been recently developed and have achieved state-of-the-art accuracy. One of the most popular hybrid methods is formulated as a DNN-AES model with an additional recurrent neural network (RNN) that processes a sequence of handcrafted sentence-level features. However, this method has the following problems: 1) It cannot incorporate effective essay-level features developed in previous AES research. 2) It greatly increases the numbers of model parameters and tuning parameters, increasing the difficulty of model training. 3) It has an additional RNN to process sentence-level features, enabling extension to various DNN-AES models complex. To resolve these problems, we propose a new hybrid method that integrates handcrafted essay-level features into a DNN-AES model. Specifically, our method concatenates handcrafted essay-level features to a distributed essay representation vector, which is obtained from an intermediate layer of a DNN-AES model. Our method is a simple DNN-AES extension, but significantly improves scoring accuracy.</abstract>
      <url hash="3f7916ab">2020.coling-main.535</url>
    </paper>
    <paper id="536">
      <title>A Straightforward Approach to Narratologically Grounded Character Identification</title>
      <author><first>Labiba</first><last>Jahan</last></author>
      <author><first>Rahul</first><last>Mittal</last></author>
      <author><first>W. Victor</first><last>Yarlott</last></author>
      <author><first>Mark</first><last>Finlayson</last></author>
      <pages>6089–6100</pages>
      <abstract>One of the most fundamental elements of narrative is character: if we are to understand a narrative, we must be able to identify the characters of that narrative. Therefore, character identification is a critical task in narrative natural language understanding. Most prior work has lacked a narratologically grounded definition of character, instead relying on simplified or implicit definitions that do not capture essential distinctions between characters and other referents in narratives. In prior work we proposed a preliminary definition of character that was based in clear narratological principles: a character is an animate entity that is important to the plot. Here we flesh out this concept, demonstrate that it can be reliably annotated (0.78 Cohen’s κ), and provide annotations of 170 narrative texts, drawn from 3 different corpora, containing 1,347 character co-reference chains and 21,999 non-character chains that include 3,937 animate chains. Furthermore, we have shown that a supervised classifier using a simple set of easily computable features can effectively identify these characters (overall F1 of 0.90). A detailed error analysis shows that character identification is first and foremost affected by co-reference quality, and further, that the shorter a chain is the harder it is to effectively identify as a character. We release our code and data for the benefit of other researchers</abstract>
      <url hash="d7c76355">2020.coling-main.536</url>
    </paper>
    <paper id="537">
      <title>Fine-grained Information Status Classification Using Discourse Context-Aware <fixed-case>BERT</fixed-case></title>
      <author><first>Yufang</first><last>Hou</last></author>
      <pages>6101–6112</pages>
      <abstract>Previous work on bridging anaphora recognition (Hou et al., 2013) casts the problem as a subtask of learning fine-grained information status (IS). However, these systems heavily depend on many hand-crafted linguistic features. In this paper, we propose a simple discourse context-aware BERT model for fine-grained IS classification. On the ISNotes corpus (Markert et al., 2012), our model achieves new state-of-the-art performances on fine-grained IS classification, obtaining a 4.8 absolute overall accuracy improvement compared to Hou et al. (2013). More importantly, we also show an improvement of 10.5 F1 points for bridging anaphora recognition without using any complex hand-crafted semantic features designed for capturing the bridging phenomenon. We further analyze the trained model and find that the most attended signals for each IS category correspond well to linguistic notions of information status.</abstract>
      <url hash="d3a4e91b">2020.coling-main.537</url>
    </paper>
    <paper id="538">
      <title>Free the Plural: Unrestricted Split-Antecedent Anaphora Resolution</title>
      <author><first>Juntao</first><last>Yu</last></author>
      <author><first>Nafise Sadat</first><last>Moosavi</last></author>
      <author><first>Silviu</first><last>Paun</last></author>
      <author><first>Massimo</first><last>Poesio</last></author>
      <pages>6113–6125</pages>
      <abstract>Now that the performance of coreference resolvers on the simpler forms of anaphoric reference has greatly improved, more attention is devoted to more complex aspects of anaphora. One limitation of virtually all coreference resolution models is the focus on single-antecedent anaphors. Plural anaphors with multiple antecedents-so-called split-antecedent anaphors (as in John met Mary. They went to the movies) have not been widely studied, because they are not annotated in ONTONOTES and are relatively infrequent in other corpora. In this paper, we introduce the first model for unrestricted resolution of split-antecedent anaphors. We start with a strong baseline enhanced by BERT embeddings, and show that we can substantially improve its performance by addressing the sparsity issue. To do this, we experiment with auxiliary corpora where split-antecedent anaphors were annotated by the crowd, and with transfer learning models using element-of bridging references and single-antecedent coreference as auxiliary tasks. Evaluation on the gold annotated ARRAU corpus shows that the out best model uses a combination of three auxiliary corpora achieved F1 scores of 70% and 43.6% when evaluated in a lenient and strict setting, respectively, i.e., 11 and 21 percentage points gain when compared with our baseline.</abstract>
      <url hash="608fd338">2020.coling-main.538</url>
    </paper>
    <paper id="539">
      <title>How coherent are neural models of coherence?</title>
      <author><first>Leila</first><last>Pishdad</last></author>
      <author><first>Federico</first><last>Fancellu</last></author>
      <author><first>Ran</first><last>Zhang</last></author>
      <author><first>Afsaneh</first><last>Fazly</last></author>
      <pages>6126–6138</pages>
      <abstract>Despite the recent advances in coherence modelling, most such models including state-of-the-art neural ones, are evaluated on either contrived proxy tasks such as the standard order discrimination benchmark, or tasks that require special expert annotation. Moreover, most evaluations are conducted on small newswire corpora. To address these shortcomings, in this paper we propose four generic evaluation tasks that draw on different aspects of coherence at both the lexical and document levels, and can be applied to any corpora. In designing these tasks, we aim at capturing coherence-specific properties, such as the correct use of discourse connectives, lexical cohesion, as well as the overall temporal and causal consistency among events and participants in a story. Importantly, our proposed tasks either rely on automatically-generated data, or data annotated for other purposes, hence alleviating the need for annotation specifically targeted to the task of coherence modelling. We perform experiments with several existing state-of-the-art neural models of coherence on these tasks, across large corpora from different domains, including newswire, dialogue, as well as narrative and instructional text. Our findings point to a strong need for revisiting the common practices in the development and evaluation of coherence models.</abstract>
      <url hash="5695a996">2020.coling-main.539</url>
    </paper>
    <paper id="540">
      <title>Fact vs. Opinion: the Role of Argumentation Features in News Classification</title>
      <author><first>Tariq</first><last>Alhindi</last></author>
      <author><first>Smaranda</first><last>Muresan</last></author>
      <author><first>Daniel</first><last>Preotiuc-Pietro</last></author>
      <pages>6139–6149</pages>
      <abstract>A 2018 study led by the Media Insight Project showed that most journalists think that a clearmarking of what is news reporting and what is commentary or opinion (e.g., editorial, op-ed)is essential for gaining public trust. We present an approach to classify news articles into newsstories (i.e., reporting of factual information) and opinion pieces using models that aim to sup-plement the article content representation with argumentation features. Our hypothesis is thatthe nature of argumentative discourse is important in distinguishing between news stories andopinion articles. We show that argumentation features outperform linguistic features used previ-ously and improve on fine-tuned transformer-based models when tested on data from publishersunseen in training. Automatically flagging opinion pieces vs. news stories can aid applicationssuch as fact-checking or event extraction.</abstract>
      <url hash="18f3f623">2020.coling-main.540</url>
    </paper>
    <paper id="541">
      <title>Generating Plausible Counterfactual Explanations for Deep Transformers in Financial Text Classification</title>
      <author><first>Linyi</first><last>Yang</last></author>
      <author><first>Eoin</first><last>Kenny</last></author>
      <author><first>Tin Lok James</first><last>Ng</last></author>
      <author><first>Yi</first><last>Yang</last></author>
      <author><first>Barry</first><last>Smyth</last></author>
      <author><first>Ruihai</first><last>Dong</last></author>
      <pages>6150–6160</pages>
      <abstract>Corporate mergers and acquisitions (M&amp;A) account for billions of dollars of investment globally every year and offer an interesting and challenging domain for artificial intelligence. However, in these highly sensitive domains, it is crucial to not only have a highly robust/accurate model, but be able to generate useful explanations to garner a user’s trust in the automated system. Regrettably, the recent research regarding eXplainable AI (XAI) in financial text classification has received little to no attention, and many current methods for generating textual-based explanations result in highly implausible explanations, which damage a user’s trust in the system. To address these issues, this paper proposes a novel methodology for producing plausible counterfactual explanations, whilst exploring the regularization benefits of adversarial training on language models in the domain of FinTech. Exhaustive quantitative experiments demonstrate that not only does this approach improve the model accuracy when compared to the current state-of-the-art and human performance, but it also generates counterfactual explanations which are significantly more plausible based on human trials.</abstract>
      <url hash="fa241c73">2020.coling-main.541</url>
    </paper>
    <paper id="542">
      <title>Text Classification by Contrastive Learning and Cross-lingual Data Augmentation for <fixed-case>A</fixed-case>lzheimer’s Disease Detection</title>
      <author><first>Zhiqiang</first><last>Guo</last></author>
      <author><first>Zhaoci</first><last>Liu</last></author>
      <author><first>Zhenhua</first><last>Ling</last></author>
      <author><first>Shijin</first><last>Wang</last></author>
      <author><first>Lingjing</first><last>Jin</last></author>
      <author><first>Yunxia</first><last>Li</last></author>
      <pages>6161–6171</pages>
      <abstract>Data scarcity is always a constraint on analyzing speech transcriptions for automatic Alzheimer’s disease (AD) detection, especially when the subjects are non-English speakers. To deal with this issue, this paper first proposes a contrastive learning method to obtain effective representations for text classification based on monolingual embeddings of BERT. Furthermore, a cross-lingual data augmentation method is designed by building autoencoders to learn the text representations shared by both languages. Experiments on a Mandarin AD corpus show that the contrastive learning method can achieve better detection accuracy than conventional CNN-based and BERTbased methods. Our cross-lingual data augmentation method also outperforms other compared methods when using another English AD corpus for augmentation. Finally, a best detection accuracy of 81.6% is obtained by our proposed methods on the Mandarin AD corpus.</abstract>
      <url hash="ad73a32b">2020.coling-main.542</url>
    </paper>
    <paper id="543">
      <title>Multilingual Epidemiological Text Classification: A Comparative Study</title>
      <author><first>Stephen</first><last>Mutuvi</last></author>
      <author><first>Emanuela</first><last>Boros</last></author>
      <author><first>Antoine</first><last>Doucet</last></author>
      <author><first>Adam</first><last>Jatowt</last></author>
      <author><first>Gaël</first><last>Lejeune</last></author>
      <author><first>Moses</first><last>Odeo</last></author>
      <pages>6172–6183</pages>
      <abstract>In this paper, we approach the multilingual text classification task in the context of the epidemiological field. Multilingual text classification models tend to perform differently across different languages (low- or high-resourced), more particularly when the dataset is highly imbalanced, which is the case for epidemiological datasets. We conduct a comparative study of different machine and deep learning text classification models using a dataset comprising news articles related to epidemic outbreaks from six languages, four low-resourced and two high-resourced, in order to analyze the influence of the nature of the language, the structure of the document, and the size of the data. Our findings indicate that the performance of the models based on fine-tuned language models exceeds by more than 50% the chosen baseline models that include a specialized epidemiological news surveillance system and several machine learning models. Also, low-resource languages are highly influenced not only by the typology of the languages on which the models have been pre-trained or/and fine-tuned but also by their size. Furthermore, we discover that the beginning and the end of documents provide the most salient features for this task and, as expected, the performance of the models was proportionate to the training data size.</abstract>
      <url hash="ce98ef5c">2020.coling-main.543</url>
    </paper>
    <paper id="544">
      <title>Pointing to Select: A Fast Pointer-<fixed-case>LSTM</fixed-case> for Long Text Classification</title>
      <author><first>Jinhua</first><last>Du</last></author>
      <author><first>Yan</first><last>Huang</last></author>
      <author><first>Karo</first><last>Moilanen</last></author>
      <pages>6184–6193</pages>
      <abstract>Recurrent neural networks (RNNs) suffer from well-known limitations and complications which include slow inference and vanishing gradients when processing long sequences in text classification. Recent studies have attempted to accelerate RNNs via various ad hoc mechanisms to skip irrelevant words in the input. However, word skipping approaches proposed to date effectively stop at each or a given time step to decide whether or not a given input word should be skipped, breaking the coherence of input processing in RNNs. Furthermore, current methods cannot change skip rates during inference and are consequently unable to support different skip rates in demanding real-world conditions. To overcome these limitations, we propose Pointer- LSTM, a novel LSTM framework which relies on a pointer network to select important words for target prediction. The model maintains a coherent input process for the LSTM modules and makes it possible to change the skip rate during inference. Our evaluation on four public data sets demonstrates that Pointer-LSTM (a) is 1.1x∼3.5x faster than the standard LSTM architecture; (b) is more accurate than Leap-LSTM (the state-of-the-art LSTM skipping model) at high skip rates; and (c) reaches robust accuracy levels even when the skip rate is changed during inference.</abstract>
      <url hash="5ba9d3c6">2020.coling-main.544</url>
    </paper>
    <paper id="545">
      <title>Aspect-based Document Similarity for Research Papers</title>
      <author><first>Malte</first><last>Ostendorff</last></author>
      <author><first>Terry</first><last>Ruas</last></author>
      <author><first>Till</first><last>Blume</last></author>
      <author><first>Bela</first><last>Gipp</last></author>
      <author><first>Georg</first><last>Rehm</last></author>
      <pages>6194–6206</pages>
      <abstract>Traditional document similarity measures provide a coarse-grained distinction between similar and dissimilar documents. Typically, they do not consider in what aspects two documents are similar. This limits the granularity of applications like recommender systems that rely on document similarity. In this paper, we extend similarity with aspect information by performing a pairwise document classification task. We evaluate our aspect-based document similarity approach for research papers. Paper citations indicate the aspect-based similarity, i.e., the title of a section in which a citation occurs acts as a label for the pair of citing and cited paper. We apply a series of Transformer models such as RoBERTa, ELECTRA, XLNet, and BERT variations and compare them to an LSTM baseline. We perform our experiments on two newly constructed datasets of 172,073 research paper pairs from the ACL Anthology and CORD-19 corpus. According to our results, SciBERT is the best performing system with F1-scores of up to 0.83. A qualitative analysis validates our quantitative results and indicates that aspect-based document similarity indeed leads to more fine-grained recommendations.</abstract>
      <url hash="245c9847">2020.coling-main.545</url>
    </paper>
    <paper id="546">
      <title>Explainable and Sparse Representations of Academic Articles for Knowledge Exploration</title>
      <author><first>Keng-Te</first><last>Liao</last></author>
      <author><first>Zhihong</first><last>Shen</last></author>
      <author><first>Chiyuan</first><last>Huang</last></author>
      <author><first>Chieh-Han</first><last>Wu</last></author>
      <author><first>PoChun</first><last>Chen</last></author>
      <author><first>Kuansan</first><last>Wang</last></author>
      <author><first>Shou-de</first><last>Lin</last></author>
      <pages>6207–6216</pages>
      <abstract>We focus on a recently deployed system built for summarizing academic articles by concept tagging. The system has shown great coverage and high accuracy of concept identification which could be contributed by the knowledge acquired from millions of publications. Provided with the interpretable concepts and knowledge encoded in a pre-trained neural model, we investigate whether the tagged concepts can be applied to a broader class of applications. We propose transforming the tagged concepts into sparse vectors as representations of academic documents. The effectiveness of the representations is analyzed theoretically by a proposed framework. We also empirically show that the representations can have advantages on academic topic discovery and paper recommendation. On these applications, we reveal that the knowledge encoded in the tagging system can be effectively utilized and can help infer additional features from data with limited information.</abstract>
      <url hash="5bbf9662">2020.coling-main.546</url>
    </paper>
    <paper id="547">
      <title>“What is on your mind?” Automated Scoring of Mindreading in Childhood and Early Adolescence</title>
      <author><first>Venelin</first><last>Kovatchev</last></author>
      <author><first>Phillip</first><last>Smith</last></author>
      <author><first>Mark</first><last>Lee</last></author>
      <author><first>Imogen</first><last>Grumley Traynor</last></author>
      <author><first>Irene</first><last>Luque Aguilera</last></author>
      <author><first>Rory</first><last>Devine</last></author>
      <pages>6217–6228</pages>
      <abstract>In this paper we present the first work on the automated scoring of mindreading ability in middle childhood and early adolescence. We create MIND-CA, a new corpus of 11,311 question-answer pairs in English from 1,066 children aged from 7 to 14. We perform machine learning experiments and carry out extensive quantitative and qualitative evaluation. We obtain promising results, demonstrating the applicability of state-of-the-art NLP solutions to a new domain and task.</abstract>
      <url hash="2d04e372">2020.coling-main.547</url>
    </paper>
    <paper id="548">
      <title>A Deep Metric Learning Method for Biomedical Passage Retrieval</title>
      <author><first>Andrés</first><last>Rosso-Mateus</last></author>
      <author><first>Fabio A.</first><last>González</last></author>
      <author><first>Manuel</first><last>Montes-y-Gómez</last></author>
      <pages>6229–6239</pages>
      <abstract>Passage retrieval is the task of identifying text snippets that are valid answers for a natural language posed question. One way to address this problem is to look at it as a metric learning problem, where we want to induce a metric between questions and passages that assign smaller distances to more relevant passages. In this work, we present a novel method for passage retrieval that learns a metric for questions and passages based on their internal semantic interactions. The method uses a similar approach to that of triplet networks, where the training samples are composed of one anchor (the question) and two positive and negative samples (passages). However,and in contrast with triplet networks, the proposed method uses a novel deep architecture that better exploits the particularities of text and takes into consideration complementary relatedness measures. Besides, the paper presents a sampling strategy that selects both easy and hard negative samples which improves the accuracy of the trained model. The method is particularly well suited for domain-specific passage retrieval where it is very important to take into account different sources of information. The proposed approach was evaluated in a biomedical passage retrieval task, the BioASQ challenge, outperforming standard triplet loss substantially by 10%,and state-of-the-art performance by 26%.</abstract>
      <url hash="f9994fc4">2020.coling-main.548</url>
    </paper>
    <paper id="549">
      <title>Hierarchical Text Segmentation for Medieval Manuscripts</title>
      <author><first>Amir</first><last>Hazem</last></author>
      <author><first>Beatrice</first><last>Daille</last></author>
      <author><first>Dominique</first><last>Stutzmann</last></author>
      <author><first>Christopher</first><last>Kermorvant</last></author>
      <author><first>Louis</first><last>Chevalier</last></author>
      <pages>6240–6251</pages>
      <abstract>In this paper, we address the segmentation of books of hours, Latin devotional manuscripts of the late Middle Ages, that exhibit challenging issues: a complex hierarchical entangled structure, variable content, noisy transcriptions with no sentence markers, and strong correlations between sections for which topical information is no longer sufficient to draw segmentation boundaries. We show that the main state-of-the-art segmentation methods are either inefficient or inapplicable for books of hours and propose a bottom-up greedy approach that considerably enhances the segmentation results. We stress the importance of such hierarchical segmentation of books of hours for historians to explore their overarching differences underlying conception about Church.</abstract>
      <url hash="0d1313a4">2020.coling-main.549</url>
    </paper>
    <paper id="550">
      <title>Are We Ready for this Disaster? Towards Location Mention Recognition from Crisis Tweets</title>
      <author><first>Reem</first><last>Suwaileh</last></author>
      <author><first>Muhammad</first><last>Imran</last></author>
      <author><first>Tamer</first><last>Elsayed</last></author>
      <author><first>Hassan</first><last>Sajjad</last></author>
      <pages>6252–6263</pages>
      <abstract>The widespread usage of Twitter during emergencies has provided a new opportunity and timely resource to crisis responders for various disaster management tasks. Geolocation information of pertinent tweets is crucial for gaining situational awareness and delivering aid. However, the majority of tweets do not come with geoinformation. In this work, we focus on the task of location mention recognition from crisis-related tweets. Specifically, we investigate the influence of different types of labeled training data on the performance of a BERT-based classification model. We explore several training settings such as combing in- and out-domain data from news articles and general-purpose and crisis-related tweets. Furthermore, we investigate the effect of geospatial proximity while training on near or far-away events from the target event. Using five different datasets, our extensive experiments provide answers to several critical research questions that are useful for the research community to foster research in this important direction. For example, results show that, for training a location mention recognition model, Twitter-based data is preferred over general-purpose data; and crisis-related data is preferred over general-purpose Twitter data. Furthermore, training on data from geographically-nearby disaster events to the target event boosts the performance compared to training on distant events.</abstract>
      <url hash="c9601ff6">2020.coling-main.550</url>
    </paper>
    <paper id="551">
      <title>Mining Crowdsourcing Problems from Discussion Forums of Workers</title>
      <author><first>Zahra</first><last>Nouri</last></author>
      <author><first>Henning</first><last>Wachsmuth</last></author>
      <author><first>Gregor</first><last>Engels</last></author>
      <pages>6264–6276</pages>
      <abstract>Crowdsourcing is used in academia and industry to solve tasks that are easy for humans but hard for computers, in natural language processing mostly to annotate data. The quality of annotations is affected by problems in the task design, task operation, and task evaluation that workers face with requesters in crowdsourcing processes. To learn about the major problems, we provide a short but comprehensive survey based on two complementary studies: (1) a literature review where we collect and organize problems known from interviews with workers, and (2) an empirical data analysis where we use topic modeling to mine workers’ complaints from a new English corpus of workers’ forum discussions. While literature covers all process phases, problems in the task evaluation are prevalent, including unfair rejections, late payments, and unjustified blockings of workers. According to the data, however, poor task design in terms of malfunctioning environments, bad workload estimation, and privacy violations seems to bother the workers most. Our findings form the basis for future research on how to improve crowdsourcing processes.</abstract>
      <url hash="0fdb2624">2020.coling-main.551</url>
    </paper>
    <paper id="552">
      <title><fixed-case>A</fixed-case>buse<fixed-case>A</fixed-case>nalyzer: Abuse Detection, Severity and Target Prediction for Gab Posts</title>
      <author><first>Mohit</first><last>Chandra</last></author>
      <author><first>Ashwin</first><last>Pathak</last></author>
      <author><first>Eesha</first><last>Dutta</last></author>
      <author><first>Paryul</first><last>Jain</last></author>
      <author><first>Manish</first><last>Gupta</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <author><first>Ponnurangam</first><last>Kumaraguru</last></author>
      <pages>6277–6283</pages>
      <abstract>While extensive popularity of online social media platforms has made information dissemination faster, it has also resulted in widespread online abuse of different types like hate speech, offensive language, sexist and racist opinions, etc. Detection and curtailment of such abusive content is critical for avoiding its psychological impact on victim communities, and thereby preventing hate crimes. Previous works have focused on classifying user posts into various forms of abusive behavior. But there has hardly been any focus on estimating the severity of abuse and the target. In this paper, we present a first of the kind dataset with 7,601 posts from Gab which looks at online abuse from the perspective of presence of abuse, severity and target of abusive behavior. We also propose a system to address these tasks, obtaining an accuracy of ∼80% for abuse presence, ∼82% for abuse target prediction, and ∼65% for abuse severity prediction.</abstract>
      <url hash="4e86fa7b">2020.coling-main.552</url>
    </paper>
    <paper id="553">
      <title>A Survey of Automatic Personality Detection from Texts</title>
      <author><first>Sanja</first><last>Stajner</last></author>
      <author><first>Seren</first><last>Yenikent</last></author>
      <pages>6284–6295</pages>
      <abstract>Personality profiling has long been used in psychology to predict life outcomes. Recently, automatic detection of personality traits from written messages has gained significant attention in computational linguistics and natural language processing communities, due to its applicability in various fields. In this survey, we show the trajectory of research towards automatic personality detection from purely psychology approaches, through psycholinguistics, to the recent purely natural language processing approaches on large datasets automatically extracted from social media. We point out what has been gained and what lost during that trajectory, and show what can be realistic expectations in the field.</abstract>
      <url hash="1275a841">2020.coling-main.553</url>
    </paper>
    <paper id="554">
      <title>Mama/Papa, Is this Text for Me?</title>
      <author><first>Rashedur</first><last>Rahman</last></author>
      <author><first>Gwénolé</first><last>Lecorvé</last></author>
      <author><first>Aline</first><last>Étienne</last></author>
      <author><first>Delphine</first><last>Battistelli</last></author>
      <author><first>Nicolas</first><last>Béchet</last></author>
      <author><first>Jonathan</first><last>Chevelu</last></author>
      <pages>6296–6301</pages>
      <abstract>Children have less linguistic skills than adults, which makes it more difficult for them to understand some texts, for instance when browsing the Internet. In this context, we present a novel method which predicts the minimal age from which a text can be understood. This method analyses each sentence of a text using a recurrent neural network, and then aggregates this information to provide the text-level prediction. Different approaches are proposed and compared to baseline models, at sentence and text levels. Experiments are carried out on a corpus of 1, 500 texts and 160K sentences. Our best model, based on LSTMs, outperforms state-of-the-art results and achieves mean absolute errors of 1.86 and 2.28, at sentence and text levels, respectively.</abstract>
      <url hash="5cb5788a">2020.coling-main.554</url>
    </paper>
    <paper id="555">
      <title>Hierarchical Bi-Directional Self-Attention Networks for Paper Review Rating Recommendation</title>
      <author><first>Zhongfen</first><last>Deng</last></author>
      <author><first>Hao</first><last>Peng</last></author>
      <author><first>Congying</first><last>Xia</last></author>
      <author><first>Jianxin</first><last>Li</last></author>
      <author><first>Lifang</first><last>He</last></author>
      <author><first>Philip</first><last>Yu</last></author>
      <pages>6302–6314</pages>
      <abstract>Review rating prediction of text reviews is a rapidly growing technology with a wide range of applications in natural language processing. However, most existing methods either use hand-crafted features or learn features using deep learning with simple text corpus as input for review rating prediction, ignoring the hierarchies among data. In this paper, we propose a Hierarchical bi-directional self-attention Network framework (HabNet) for paper review rating prediction and recommendation, which can serve as an effective decision-making tool for the academic paper review process. Specifically, we leverage the hierarchical structure of the paper reviews with three levels of encoders: sentence encoder (level one), intra-review encoder (level two) and inter-review encoder (level three). Each encoder first derives contextual representation of each level, then generates a higher-level representation, and after the learning process, we are able to identify useful predictors to make the final acceptance decision, as well as to help discover the inconsistency between numerical review ratings and text sentiment conveyed by reviewers. Furthermore, we introduce two new metrics to evaluate models in data imbalance situations. Extensive experiments on a publicly available dataset (PeerRead) and our own collected dataset (OpenReview) demonstrate the superiority of the proposed approach compared with state-of-the-art methods.</abstract>
      <url hash="27a0e813">2020.coling-main.555</url>
    </paper>
    <paper id="556">
      <title>Context in Informational Bias Detection</title>
      <author><first>Esther</first><last>van den Berg</last></author>
      <author><first>Katja</first><last>Markert</last></author>
      <pages>6315–6326</pages>
      <abstract>Informational bias is bias conveyed through sentences or clauses that provide tangential, speculative or background information that can sway readers’ opinions towards entities. By nature, informational bias is context-dependent, but previous work on informational bias detection has not explored the role of context beyond the sentence. In this paper, we explore four kinds of context for informational bias in English news articles: neighboring sentences, the full article, articles on the same event from other news publishers, and articles from the same domain (but potentially different events). We find that integrating event context improves classification performance over a very strong baseline. In addition, we perform the first error analysis of models on this task. We find that the best-performing context-inclusive model outperforms the baseline on longer sentences, and sentences from politically centrist articles.</abstract>
      <url hash="1f44db7d">2020.coling-main.556</url>
    </paper>
    <paper id="557">
      <title><fixed-case>H</fixed-case>ate<fixed-case>GAN</fixed-case>: Adversarial Generative-Based Data Augmentation for Hate Speech Detection</title>
      <author><first>Rui</first><last>Cao</last></author>
      <author><first>Roy Ka-Wei</first><last>Lee</last></author>
      <pages>6327–6338</pages>
      <abstract>Academia and industry have developed machine learning and natural language processing models to detect online hate speech automatically. However, most of these existing methods adopt a supervised approach that heavily depends on labeled datasets for training. This results in the methods’ poor detection performance of the hate speech class as the training datasets are highly imbalanced. In this paper, we propose HateGAN, a deep generative reinforcement learning model, which addresses the challenge of imbalance class by augmenting the dataset with hateful tweets. We conduct extensive experiments to augment two commonly-used hate speech detection datasets with the HateGAN generated tweets. Our experiment results show that HateGAN improves the detection performance of the hate speech class regardless of the classifiers and datasets used in the detection task. Specifically, we observe an average 5% improvement for the hate class F1 scores across all state-of-the-art hate speech classifiers. We also conduct case studies to empirically examine the HateGAN generated hate speeches and show that the generated tweets are diverse, coherent, and relevant to hate speech detection.</abstract>
      <url hash="9be64bd3">2020.coling-main.557</url>
    </paper>
    <paper id="558">
      <title>Evaluating Unsupervised Representation Learning for Detecting Stances of Fake News</title>
      <author><first>Maike</first><last>Guderlei</last></author>
      <author><first>Matthias</first><last>Aßenmacher</last></author>
      <pages>6339–6349</pages>
      <abstract>Our goal is to evaluate the usefulness of unsupervised representation learning techniques for detecting stances of Fake News. Therefore we examine several pre-trained language models with respect to their performance on two Fake News related data sets, both consisting of instances with a headline, an associated news article and the stance of the article towards the respective headline. Specifically, the aim is to understand how much hyperparameter tuning is necessary when fine-tuning the pre-trained architectures, how well transfer learning works in this specific case of stance detection and how sensitive the models are to changes in hyperparameters like batch size, learning rate (schedule), sequence length as well as the freezing technique. The results indicate that the computationally more expensive autoregression approach of XLNet (Yanget al., 2019) is outperformed by BERT-based models, notably by RoBERTa (Liu et al., 2019).While the learning rate seems to be the most important hyperparameter, experiments with different freezing techniques indicate that all evaluated architectures had already learned powerful language representations that pose a good starting point for fine-tuning them.</abstract>
      <url hash="53c9b7a5">2020.coling-main.558</url>
    </paper>
    <paper id="559">
      <title><fixed-case>XH</fixed-case>ate-999: Analyzing and Detecting Abusive Language Across Domains and Languages</title>
      <author><first>Goran</first><last>Glavaš</last></author>
      <author><first>Mladen</first><last>Karan</last></author>
      <author><first>Ivan</first><last>Vulić</last></author>
      <pages>6350–6365</pages>
      <abstract>We present XHate-999, a multi-domain and multilingual evaluation data set for abusive language detection. By aligning test instances across six typologically diverse languages, XHate-999 for the first time allows for disentanglement of the domain transfer and language transfer effects in abusive language detection. We conduct a series of domain- and language-transfer experiments with state-of-the-art monolingual and multilingual transformer models, setting strong baseline results and profiling XHate-999 as a comprehensive evaluation resource for abusive language detection. Finally, we show that domain- and language-adaption, via intermediate masked language modeling on abusive corpora in the target language, can lead to substantially improved abusive language detection in the target language in the zero-shot transfer setups.</abstract>
      <url hash="91724a39">2020.coling-main.559</url>
    </paper>
    <paper id="560">
      <title>Detect All Abuse! Toward Universal Abusive Language Detection Models</title>
      <author><first>Kunze</first><last>Wang</last></author>
      <author><first>Dong</first><last>Lu</last></author>
      <author><first>Caren</first><last>Han</last></author>
      <author><first>Siqu</first><last>Long</last></author>
      <author><first>Josiah</first><last>Poon</last></author>
      <pages>6366–6376</pages>
      <abstract>Online abusive language detection (ALD) has become a societal issue of increasing importance in recent years. Several previous works in online ALD focused on solving a single abusive language problem in a single domain, like Twitter, and have not been successfully transferable to the general ALD task or domain. In this paper, we introduce a new generic ALD framework, MACAS, which is capable of addressing several types of ALD tasks across different domains. Our generic framework covers multi-aspect abusive language embeddings that represent the target and content aspects of abusive language and applies a textual graph embedding that analyses the user’s linguistic behaviour. Then, we propose and use the cross-attention gate flow mechanism to embrace multiple aspects of abusive language. Quantitative and qualitative evaluation results show that our ALD algorithm rivals or exceeds the six state-of-the-art ALD algorithms across seven ALD datasets covering multiple aspects of abusive language and different online community domains.</abstract>
      <url hash="53f8f985">2020.coling-main.560</url>
    </paper>
    <paper id="561">
      <title>Modeling Evolution of Message Interaction for Rumor Resolution</title>
      <author><first>Lei</first><last>Chen</last></author>
      <author><first>Zhongyu</first><last>Wei</last></author>
      <author><first>Jing</first><last>Li</last></author>
      <author><first>Baohua</first><last>Zhou</last></author>
      <author><first>Qi</first><last>Zhang</last></author>
      <author><first>Xuanjing</first><last>Huang</last></author>
      <pages>6377–6387</pages>
      <abstract>Previous work for rumor resolution concentrates on exploiting time-series characteristics or modeling topology structure separately. However, how local interactive pattern affects global information assemblage has not been explored. In this paper, we attempt to address the problem by learning evolution of message interaction. We model confrontation and reciprocity between message pairs via discrete variational autoencoders which effectively reflects the diversified opinion interactivity. Moreover, we capture the variation of message interaction using a hierarchical framework to better integrate information flow of a rumor cascade. Experiments on PHEME dataset demonstrate our proposed model achieves higher accuracy than existing methods.</abstract>
      <url hash="56d059e8">2020.coling-main.561</url>
    </paper>
    <paper id="562">
      <title>Regularized Attentive Capsule Network for Overlapped Relation Extraction</title>
      <author><first>Tianyi</first><last>Liu</last></author>
      <author><first>Xiangyu</first><last>Lin</last></author>
      <author><first>Weijia</first><last>Jia</last></author>
      <author><first>Mingliang</first><last>Zhou</last></author>
      <author><first>Wei</first><last>Zhao</last></author>
      <pages>6388–6398</pages>
      <abstract>Distantly supervised relation extraction has been widely applied in knowledge base construction due to its less requirement of human efforts. However, the automatically established training datasets in distant supervision contain low-quality instances with noisy words and overlapped relations, introducing great challenges to the accurate extraction of relations. To address this problem, we propose a novel Regularized Attentive Capsule Network (RA-CapNet) to better identify highly overlapped relations in each informal sentence. To discover multiple relation features in an instance, we embed multi-head attention into the capsule network as the low-level capsules, where the subtraction of two entities acts as a new form of relation query to select salient features regardless of their positions. To further discriminate overlapped relation features, we devise disagreement regularization to explicitly encourage the diversity among both multiple attention heads and low-level capsules. Extensive experiments conducted on widely used datasets show that our model achieves significant improvements in relation extraction.</abstract>
      <url hash="ed9983f1">2020.coling-main.562</url>
    </paper>
    <paper id="563">
      <title>Bridging Text and Knowledge with Multi-Prototype Embedding for Few-Shot Relational Triple Extraction</title>
      <author><first>Haiyang</first><last>Yu</last></author>
      <author><first>Ningyu</first><last>Zhang</last></author>
      <author><first>Shumin</first><last>Deng</last></author>
      <author><first>Hongbin</first><last>Ye</last></author>
      <author><first>Wei</first><last>Zhang</last></author>
      <author><first>Huajun</first><last>Chen</last></author>
      <pages>6399–6410</pages>
      <abstract>Current supervised relational triple extraction approaches require huge amounts of labeled data and thus suffer from poor performance in few-shot settings. However, people can grasp new knowledge by learning a few instances. To this end, we take the first step to study the few-shot relational triple extraction, which has not been well understood. Unlike previous single-task few-shot problems, relational triple extraction is more challenging as the entities and relations have implicit correlations. In this paper, We propose a novel multi-prototype embedding network model to jointly extract the composition of relational triples, namely, entity pairs and corresponding relations. To be specific, we design a hybrid prototypical learning mechanism that bridges text and knowledge concerning both entities and relations. Thus, implicit correlations between entities and relations are injected. Additionally, we propose a prototype-aware regularization to learn more representative prototypes. Experimental results demonstrate that the proposed method can improve the performance of the few-shot triple extraction.</abstract>
      <url hash="49d524dc">2020.coling-main.563</url>
    </paper>
    <paper id="564">
      <title>Dual Supervision Framework for Relation Extraction with Distant Supervision and Human Annotation</title>
      <author><first>Woohwan</first><last>Jung</last></author>
      <author><first>Kyuseok</first><last>Shim</last></author>
      <pages>6411–6423</pages>
      <abstract>Relation extraction (RE) has been extensively studied due to its importance in real-world applications such as knowledge base construction and question answering. Most of the existing works train the models on either distantly supervised data or human-annotated data. To take advantage of the high accuracy of human annotation and the cheap cost of distant supervision, we propose the dual supervision framework which effectively utilizes both types of data. However, simply combining the two types of data to train a RE model may decrease the prediction accuracy since distant supervision has labeling bias. We employ two separate prediction networks HA-Net and DS-Net to predict the labels by human annotation and distant supervision, respectively, to prevent the degradation of accuracy by the incorrect labeling of distant supervision. Furthermore, we propose an additional loss term called disagreement penalty to enable HA-Net to learn from distantly supervised labels. In addition, we exploit additional networks to adaptively assess the labeling bias by considering contextual information. Our performance study on sentence-level and document-level REs confirms the effectiveness of the dual supervision framework.</abstract>
      <url hash="32931fac">2020.coling-main.564</url>
    </paper>
    <paper id="565">
      <title>Graph Convolution over Multiple Dependency Sub-graphs for Relation Extraction</title>
      <author><first>Angrosh</first><last>Mandya</last></author>
      <author><first>Danushka</first><last>Bollegala</last></author>
      <author><first>Frans</first><last>Coenen</last></author>
      <pages>6424–6435</pages>
      <abstract>We propose a contextualised graph convolution network over multiple dependency-based sub-graphs for relation extraction. A novel method to construct multiple sub-graphs using words in shortest dependency path and words linked to entities in the dependency parse is proposed. Graph convolution operation is performed over the resulting multiple sub-graphs to obtain more informative features useful for relation extraction. Our experimental results show that the proposed method achieves superior performance over the existing GCN-based models achieving state-of-the-art performance on cross-sentence n-ary relation extraction dataset and SemEval 2010 Task 8 sentence-level relation extraction dataset. Our model also achieves a comparable performance to the SoTA on the TACRED dataset.</abstract>
      <url hash="ddc3de6d">2020.coling-main.565</url>
    </paper>
    <paper id="566">
      <title>Towards Accurate and Consistent Evaluation: A Dataset for Distantly-Supervised Relation Extraction</title>
      <author><first>Tong</first><last>Zhu</last></author>
      <author><first>Haitao</first><last>Wang</last></author>
      <author><first>Junjie</first><last>Yu</last></author>
      <author><first>Xiabing</first><last>Zhou</last></author>
      <author><first>Wenliang</first><last>Chen</last></author>
      <author><first>Wei</first><last>Zhang</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <pages>6436–6447</pages>
      <abstract>In recent years, distantly-supervised relation extraction has achieved a certain success by using deep neural networks. Distant Supervision (DS) can automatically generate large-scale annotated data by aligning entity pairs from Knowledge Bases (KB) to sentences. However, these DS-generated datasets inevitably have wrong labels that result in incorrect evaluation scores during testing, which may mislead the researchers. To solve this problem, we build a new dataset NYTH, where we use the DS-generated data as training data and hire annotators to label test data. Compared with the previous datasets, NYT-H has a much larger test set and then we can perform more accurate and consistent evaluation. Finally, we present the experimental results of several widely used systems on NYT-H. The experimental results show that the ranking lists of the comparison systems on the DS-labelled test data and human-annotated test data are different. This indicates that our human-annotated data is necessary for evaluation of distantly-supervised relation extraction.</abstract>
      <url hash="00c79e94">2020.coling-main.566</url>
    </paper>
    <paper id="567">
      <title>Multi-choice Relational Reasoning for Machine Reading Comprehension</title>
      <author><first>Wuya</first><last>Chen</last></author>
      <author><first>Xiaojun</first><last>Quan</last></author>
      <author><first>Chunyu</first><last>Kit</last></author>
      <author><first>Zhengcheng</first><last>Min</last></author>
      <author><first>Jiahai</first><last>Wang</last></author>
      <pages>6448–6458</pages>
      <abstract>This paper presents our study of cloze-style reading comprehension by imitating human reading comprehension, which normally involves tactical comparing and reasoning over candidates while choosing the best answer. We propose a multi-choice relational reasoning (McR<tex-math>^2</tex-math>) model with an aim to enable relational reasoning on candidates based on fusion representations of document, query and candidates. For the fusion representations, we develop an efficient encoding architecture by integrating the schemes of bidirectional attention flow, self-attention and document-gated query reading. Then, comparing and inferring over candidates are executed by a novel relational reasoning network. We conduct extensive experiments on four datasets derived from two public corpora, Children’s Book Test and Who DiD What, to verify the validity and advantages of our model. The results show that it outperforms all baseline models significantly on the four benchmark datasets. The effectiveness of its key components is also validated by an ablation study.</abstract>
      <url hash="32dc484f">2020.coling-main.567</url>
    </paper>
    <paper id="568">
      <title><fixed-case>FASTMATCH</fixed-case>: Accelerating the Inference of <fixed-case>BERT</fixed-case>-based Text Matching</title>
      <author><first>Shuai</first><last>Pang</last></author>
      <author><first>Jianqiang</first><last>Ma</last></author>
      <author><first>Zeyu</first><last>Yan</last></author>
      <author><first>Yang</first><last>Zhang</last></author>
      <author><first>Jianping</first><last>Shen</last></author>
      <pages>6459–6469</pages>
      <abstract>Recently, pre-trained language models such as BERT have shown state-of-the-art accuracies in text matching. When being applied to IR (or QA), the BERT-based matching models need to online calculate the representations and interactions for all query-candidate pairs. The high inference cost has prohibited the deployments of BERT-based matching models in many practical applications. To address this issue, we propose a novel BERT-based text matching model, in which the representations and the interactions are decoupled. Then, the representations of the candidates can be calculated and stored offline, and directly retrieved during the online matching phase. To conduct the interactions and generate final matching scores, a lightweight attention network is designed. Experiments based on several large scale text matching datasets show that the proposed model, called FASTMATCH, can achieve up to 100X speed-up to BERT and RoBERTa at the online matching phase, while keeping more up to 98.7% of the performance.</abstract>
      <url hash="5abcb3b2">2020.coling-main.568</url>
    </paper>
    <paper id="569">
      <title><fixed-case>DT</fixed-case>-<fixed-case>QDC</fixed-case>: A Dataset for Question Comprehension in Online Test</title>
      <author><first>Sijin</first><last>Wu</last></author>
      <author><first>Yujiu</first><last>Yang</last></author>
      <author><first>Nicholas</first><last>Yung</last></author>
      <author><first>Zhengchen</first><last>Shen</last></author>
      <author><first>Zeyang</first><last>Lei</last></author>
      <pages>6470–6480</pages>
      <abstract>With the transformation of education from the traditional classroom environment to online education and assessment, it is more and more important to accurately assess the difficulty of questions than ever. As teachers may not be able to follow the student’s performance and learning behavior closely, a well-defined method to measure the difficulty of questions to guide learning is necessary. In this paper, we explore the concept of question difficulty and provide our new Chinese DT-QDC dataset. This is currently the largest and only Chinese question dataset, and it also has enriched attributes and difficulty labels. Additional attributes such as keywords, chapter, and question type would allow models to understand questions more precisely. We proposed the MTMS-BERT and ORMS-BERT, which can improve the judgment of difficulty from different views. The proposed methods outperforms different baselines by 7.79% on F1-score and 15.92% on MAE, 28.26% on MSE on the new DT-QDC dataset, laying the foundation for the question difficulty comprehension task.</abstract>
      <url hash="34899759">2020.coling-main.569</url>
    </paper>
    <paper id="570">
      <title>Read and Reason with <fixed-case>M</fixed-case>u<fixed-case>S</fixed-case>e<fixed-case>RC</fixed-case> and <fixed-case>R</fixed-case>u<fixed-case>C</fixed-case>o<fixed-case>S</fixed-case>: Datasets for Machine Reading Comprehension for <fixed-case>R</fixed-case>ussian</title>
      <author><first>Alena</first><last>Fenogenova</last></author>
      <author><first>Vladislav</first><last>Mikhailov</last></author>
      <author><first>Denis</first><last>Shevelev</last></author>
      <pages>6481–6497</pages>
      <abstract>The paper introduces two Russian machine reading comprehension (MRC) datasets, called MuSeRC and RuCoS, which require reasoning over multiple sentences and commonsense knowledge to infer the answer. The former follows the design of MultiRC, while the latter is a counterpart of the ReCoRD dataset. The datasets are included in RussianSuperGLUE, the Russian general language understanding benchmark. We provide a comparative analysis and demonstrate that the proposed tasks are relatively more complex as compared to the original ones for English. Besides, performance results of human solvers and BERT-based models show that MuSeRC and RuCoS represent a challenge for recent advanced neural models. We thus hope to facilitate research in the field of MRC for Russian and prompt the study of multi-hop reasoning in a cross-lingual scenario.</abstract>
      <url hash="066b4e9c">2020.coling-main.570</url>
    </paper>
    <paper id="571">
      <title>Knowledge-Enhanced Natural Language Inference Based on Knowledge Graphs</title>
      <author><first>Zikang</first><last>Wang</last></author>
      <author><first>Linjing</first><last>Li</last></author>
      <author><first>Daniel</first><last>Zeng</last></author>
      <pages>6498–6508</pages>
      <abstract>Natural Language Inference (NLI) is a vital task in natural language processing. It aims to identify the logical relationship between two sentences. Most of the existing approaches make such inference based on semantic knowledge obtained through training corpus. The adoption of background knowledge is rarely seen or limited to a few specific types. In this paper, we propose a novel Knowledge Graph-enhanced NLI (KGNLI) model to leverage the usage of background knowledge stored in knowledge graphs in the field of NLI. KGNLI model consists of three components: a semantic-relation representation module, a knowledge-relation representation module, and a label prediction module. Different from previous methods, various kinds of background knowledge can be flexibly combined in the proposed KGNLI model. Experiments on four benchmarks, SNLI, MultiNLI, SciTail, and BNLI, validate the effectiveness of our model.</abstract>
      <url hash="c9bc02b6">2020.coling-main.571</url>
    </paper>
    <paper id="572">
      <title><fixed-case>NYTWIT</fixed-case>: A Dataset of Novel Words in the <fixed-case>N</fixed-case>ew <fixed-case>Y</fixed-case>ork <fixed-case>T</fixed-case>imes</title>
      <author><first>Yuval</first><last>Pinter</last></author>
      <author><first>Cassandra L.</first><last>Jacobs</last></author>
      <author><first>Max</first><last>Bittker</last></author>
      <pages>6509–6515</pages>
      <abstract>We present the New York Times Word Innovation Types dataset, or NYTWIT, a collection of over 2,500 novel English words published in the New York Times between November 2017 and March 2019, manually annotated for their class of novelty (such as lexical derivation, dialectal variation, blending, or compounding). We present baseline results for both uncontextual and contextual prediction of novelty class, showing that there is room for improvement even for state-of-the-art NLP systems. We hope this resource will prove useful for linguists and NLP practitioners by providing a real-world environment of novel word appearance.</abstract>
      <url hash="6656790e">2020.coling-main.572</url>
    </paper>
    <paper id="573">
      <title><fixed-case>SOME</fixed-case>: Reference-less Sub-Metrics Optimized for Manual Evaluations of Grammatical Error Correction</title>
      <author><first>Ryoma</first><last>Yoshimura</last></author>
      <author><first>Masahiro</first><last>Kaneko</last></author>
      <author><first>Tomoyuki</first><last>Kajiwara</last></author>
      <author><first>Mamoru</first><last>Komachi</last></author>
      <pages>6516–6522</pages>
      <abstract>We propose a reference-less metric trained on manual evaluations of system outputs for grammatical error correction (GEC). Previous studies have shown that reference-less metrics are promising; however, existing metrics are not optimized for manual evaluations of the system outputs because no dataset of the system output exists with manual evaluation. This study manually evaluates outputs of GEC systems to optimize the metrics. Experimental results show that the proposed metric improves correlation with the manual evaluation in both system- and sentence-level meta-evaluation. Our dataset and metric will be made publicly available.</abstract>
      <url hash="19e03c70">2020.coling-main.573</url>
    </paper>
    <paper id="574">
      <title>Continual Lifelong Learning in Natural Language Processing: A Survey</title>
      <author><first>Magdalena</first><last>Biesialska</last></author>
      <author><first>Katarzyna</first><last>Biesialska</last></author>
      <author><first>Marta R.</first><last>Costa-jussà</last></author>
      <pages>6523–6541</pages>
      <abstract>Continual learning (CL) aims to enable information systems to learn from a continuous data stream across time. However, it is difficult for existing deep learning architectures to learn a new task without largely forgetting previously acquired knowledge. Furthermore, CL is particularly challenging for language learning, as natural language is ambiguous: it is discrete, compositional, and its meaning is context-dependent. In this work, we look at the problem of CL through the lens of various NLP tasks. Our survey discusses major challenges in CL and current methods applied in neural network models. We also provide a critical review of the existing CL evaluation methods and datasets in NLP. Finally, we present our outlook on future research directions.</abstract>
      <url hash="80ca90cd">2020.coling-main.574</url>
    </paper>
    <paper id="575">
      <title><fixed-case>XED</fixed-case>: A Multilingual Dataset for Sentiment Analysis and Emotion Detection</title>
      <author><first>Emily</first><last>Öhman</last></author>
      <author><first>Marc</first><last>Pàmies</last></author>
      <author><first>Kaisla</first><last>Kajava</last></author>
      <author><first>Jörg</first><last>Tiedemann</last></author>
      <pages>6542–6552</pages>
      <abstract>We introduce XED, a multilingual fine-grained emotion dataset. The dataset consists of human-annotated Finnish (25k) and English sentences (30k), as well as projected annotations for 30 additional languages, providing new resources for many low-resource languages. We use Plutchik’s core emotions to annotate the dataset with the addition of neutral to create a multilabel multiclass dataset. The dataset is carefully evaluated using language-specific BERT models and SVMs to show that XED performs on par with other similar datasets and is therefore a useful tool for sentiment analysis and emotion detection.</abstract>
      <url hash="7530b805">2020.coling-main.575</url>
    </paper>
    <paper id="576">
      <title>Human or Neural Translation?</title>
      <author><first>Shivendra</first><last>Bhardwaj</last></author>
      <author><first>David</first><last>Alfonso Hermelo</last></author>
      <author><first>Phillippe</first><last>Langlais</last></author>
      <author><first>Gabriel</first><last>Bernier-Colborne</last></author>
      <author><first>Cyril</first><last>Goutte</last></author>
      <author><first>Michel</first><last>Simard</last></author>
      <pages>6553–6564</pages>
      <abstract>Deep neural models tremendously improved machine translation. In this context, we investigate whether distinguishing machine from human translations is still feasible. We trained and applied 18 classifiers under two settings: a monolingual task, in which the classifier only looks at the translation; and a bilingual task, in which the source text is also taken into consideration. We report on extensive experiments involving 4 neural MT systems (Google Translate, DeepL, as well as two systems we trained) and varying the domain of texts. We show that the bilingual task is the easiest one and that transfer-based deep-learning classifiers perform best, with mean accuracies around 85% in-domain and 75% out-of-domain .</abstract>
      <url hash="25e5fe35">2020.coling-main.576</url>
    </paper>
    <paper id="577">
      <title>Biomedical Concept Relatedness – A large <fixed-case>EHR</fixed-case>-based benchmark</title>
      <author><first>Claudia</first><last>Schulz</last></author>
      <author><first>Josh</first><last>Levy-Kramer</last></author>
      <author><first>Camille</first><last>Van Assel</last></author>
      <author><first>Miklos</first><last>Kepes</last></author>
      <author><first>Nils</first><last>Hammerla</last></author>
      <pages>6565–6575</pages>
      <abstract>A promising application of AI to healthcare is the retrieval of information from electronic health records (EHRs), e.g. to aid clinicians in finding relevant information for a consultation or to recruit suitable patients for a study. This requires search capabilities far beyond simple string matching, including the retrieval of concepts (diagnoses, symptoms, medications, etc.) related to the one in question. The suitability of AI methods for such applications is tested by predicting the relatedness of concepts with known relatedness scores. However, all existing biomedical concept relatedness datasets are notoriously small and consist of hand-picked concept pairs. We open-source a novel concept relatedness benchmark overcoming these issues: it is six times larger than existing datasets and concept pairs are chosen based on co-occurrence in EHRs, ensuring their relevance for the application of interest. We present an in-depth analysis of our new dataset and compare it to existing ones, highlighting that it is not only larger but also complements existing datasets in terms of the types of concepts included. Initial experiments with state-of-the-art embedding methods show that our dataset is a challenging new benchmark for testing concept relatedness models.</abstract>
      <url hash="51027681">2020.coling-main.577</url>
    </paper>
    <paper id="578">
      <title>Domain-Specific Sentiment Lexicons Induced from Labeled Documents</title>
      <author><first>SM Mazharul</first><last>Islam</last></author>
      <author><first>Xin</first><last>Dong</last></author>
      <author><first>Gerard</first><last>de Melo</last></author>
      <pages>6576–6587</pages>
      <abstract>Sentiment analysis is an area of substantial relevance both in industry and in academia, including for instance in social studies. Although supervised learning algorithms have advanced considerably in recent years, in many settings it remains more practical to apply an unsupervised technique. The latter are oftentimes based on sentiment lexicons. However, existing sentiment lexicons reflect an abstract notion of polarity and do not do justice to the substantial differences of word polarities between different domains. In this work, we draw on a collection of domain-specific data to induce a set of 24 domain-specific sentiment lexicons. We rely on initial linear models to induce initial word intensity scores, and then train new deep models based on word vector representations to overcome the scarcity of the original seed data. Our analysis shows substantial differences between domains, which make domain-specific sentiment lexicons a promising form of lexical resource in downstream tasks, and the predicted lexicons indeed perform effectively on tasks such as review classification and cross-lingual word sentiment prediction.</abstract>
      <url hash="ba0e5d0b">2020.coling-main.578</url>
    </paper>
    <paper id="579">
      <title>Language <fixed-case>ID</fixed-case> in the Wild: Unexpected Challenges on the Path to a Thousand-Language Web Text Corpus</title>
      <author><first>Isaac</first><last>Caswell</last></author>
      <author><first>Theresa</first><last>Breiner</last></author>
      <author><first>Daan</first><last>van Esch</last></author>
      <author><first>Ankur</first><last>Bapna</last></author>
      <pages>6588–6608</pages>
      <abstract>Large text corpora are increasingly important for a wide variety of Natural Language Processing (NLP) tasks, and automatic language identification (LangID) is a core technology needed to collect such datasets in a multilingual context. LangID is largely treated as solved in the literature, with models reported that achieve over 90% average F1 on as many as 1,366 languages. We train LangID models on up to 1,629 languages with comparable quality on held-out test sets, but find that human-judged LangID accuracy for web-crawl text corpora created using these models is only around 5% for many lower-resource languages, suggesting a need for more robust evaluation. Further analysis revealed a variety of error modes, arising from domain mismatch, class imbalance, language similarity, and insufficiently expressive models. We propose two classes of techniques to mitigate these errors: wordlist-based tunable-precision filters (for which we release curated lists in about 500 languages) and transformer-based semi-supervised LangID models, which increase median dataset precision from 5.5% to 71.2%. These techniques enable us to create an initial data set covering 100K or more relatively clean sentences in each of 500+ languages, paving the way towards a 1,000-language web text corpus.</abstract>
      <url hash="7bafc8df">2020.coling-main.579</url>
    </paper>
    <paper id="580">
      <title>Constructing A Multi-hop <fixed-case>QA</fixed-case> Dataset for Comprehensive Evaluation of Reasoning Steps</title>
      <author><first>Xanh</first><last>Ho</last></author>
      <author><first>Anh-Khoa</first><last>Duong Nguyen</last></author>
      <author><first>Saku</first><last>Sugawara</last></author>
      <author><first>Akiko</first><last>Aizawa</last></author>
      <pages>6609–6625</pages>
      <abstract>A multi-hop question answering (QA) dataset aims to test reasoning and inference skills by requiring a model to read multiple paragraphs to answer a given question. However, current datasets do not provide a complete explanation for the reasoning process from the question to the answer. Further, previous studies revealed that many examples in existing multi-hop datasets do not require multi-hop reasoning to answer a question. In this study, we present a new multi-hop QA dataset, called 2WikiMultiHopQA, which uses structured and unstructured data. In our dataset, we introduce the evidence information containing a reasoning path for multi-hop questions. The evidence information has two benefits: (i) providing a comprehensive explanation for predictions and (ii) evaluating the reasoning skills of a model. We carefully design a pipeline and a set of templates when generating a question-answer pair that guarantees the multi-hop steps and the quality of the questions. We also exploit the structured format in Wikidata and use logical rules to create questions that are natural but still require multi-hop reasoning. Through experiments, we demonstrate that our dataset is challenging for multi-hop models and it ensures that multi-hop reasoning is required.</abstract>
      <url hash="9d4f8121">2020.coling-main.580</url>
    </paper>
    <paper id="581">
      <title><fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case> – A <fixed-case>R</fixed-case>omanian <fixed-case>BERT</fixed-case> Model</title>
      <author><first>Mihai</first><last>Masala</last></author>
      <author><first>Stefan</first><last>Ruseti</last></author>
      <author><first>Mihai</first><last>Dascalu</last></author>
      <pages>6626–6637</pages>
      <abstract>Deep pre-trained language models tend to become ubiquitous in the field of Natural Language Processing (NLP). These models learn contextualized representations by using a huge amount of unlabeled text data and obtain state of the art results on a multitude of NLP tasks, by enabling efficient transfer learning. For other languages besides English, there are limited options of such models, most of which are trained only on multi-lingual corpora. In this paper we introduce a Romanian-only pre-trained BERT model – RoBERT – and compare it with different multi-lingual models on seven Romanian specific NLP tasks grouped into three categories, namely: sentiment analysis, dialect and cross-dialect topic identification, and diacritics restoration. Our model surpasses the multi-lingual models, as well as a another mono-lingual implementation of BERT, on all tasks.</abstract>
      <url hash="c6d92864">2020.coling-main.581</url>
    </paper>
    <paper id="582">
      <title>Exploring the Language of Data</title>
      <author><first>Gábor</first><last>Bella</last></author>
      <author><first>Linda</first><last>Gremes</last></author>
      <author><first>Fausto</first><last>Giunchiglia</last></author>
      <pages>6638–6648</pages>
      <abstract>We set out to uncover the unique grammatical properties of an important yet so far under-researched type of natural language text: that of short labels typically found within structured datasets. We show that such labels obey a specific type of abbreviated grammar that we call the Language of Data, with properties significantly different from the kinds of text typically addressed in computational linguistics and NLP, such as ‘standard’ written language or social media messages. We analyse orthography, parts of speech, and syntax over a large, bilingual, hand-annotated corpus of data labels collected from a variety of domains. We perform experiments on tokenisation, part-of-speech tagging, and named entity recognition over real-world structured data, demonstrating that models adapted to the Language of Data outperform those trained on standard text. These observations point in a new direction to be explored as future research, in order to develop new NLP tools and models dedicated to the Language of Data.</abstract>
      <url hash="959343fe">2020.coling-main.582</url>
    </paper>
    <paper id="583">
      <title><fixed-case>D</fixed-case>a<fixed-case>N</fixed-case>+: <fixed-case>D</fixed-case>anish Nested Named Entities and Lexical Normalization</title>
      <author><first>Barbara</first><last>Plank</last></author>
      <author><first>Kristian Nørgaard</first><last>Jensen</last></author>
      <author><first>Rob</first><last>van der Goot</last></author>
      <pages>6649–6662</pages>
      <abstract>This paper introduces DAN+, a new multi-domain corpus and annotation guidelines for Dan-ish nested named entities (NEs) and lexical normalization to support research on cross-lingualcross-domain learning for a less-resourced language. We empirically assess three strategies tomodel the two-layer Named Entity Recognition (NER) task. We compare transfer capabilitiesfrom German versus in-language annotation from scratch. We examine language-specific versusmultilingual BERT, and study the effect of lexical normalization on NER. Our results show that 1) the most robust strategy is multi-task learning which is rivaled by multi-label decoding, 2) BERT-based NER models are sensitive to domain shifts, and 3) in-language BERT and lexicalnormalization are the most beneficial on the least canonical data. Our results also show that anout-of-domain setup remains challenging, while performance on news plateaus quickly. Thishighlights the importance of cross-domain evaluation of cross-lingual transfer.</abstract>
      <url hash="ea9f5700">2020.coling-main.583</url>
    </paper>
    <paper id="584">
      <title>New Benchmark Corpus and Models for Fine-grained Event Classification: To <fixed-case>BERT</fixed-case> or not to <fixed-case>BERT</fixed-case>?</title>
      <author><first>Jakub</first><last>Piskorski</last></author>
      <author><first>Jacek</first><last>Haneczok</last></author>
      <author><first>Guillaume</first><last>Jacquet</last></author>
      <pages>6663–6678</pages>
      <abstract>We introduce a new set of benchmark datasets derived from ACLED data for fine-grained event classification and compare the performance of various state-of-the-art models on these datasets, including SVM based on TF-IDF character n-grams and neural context-free embeddings (GLOVE and FASTTEXT) as well as deep learning-based BERT with its contextual embeddings. The best results in terms of micro (94.3-94.9%) and macro F1 (86.0-88.9%) were obtained using BERT transformer, with simpler TF-IDF character n-gram based SVM being an interesting alternative. Further, we discuss the pros and cons of the considered benchmark models in terms of their robustness and the dependence of the classification performance on the size of training data.</abstract>
      <url hash="2c334ae2">2020.coling-main.584</url>
    </paper>
    <paper id="585">
      <title>A Geometry-Inspired Attack for Generating Natural Language Adversarial Examples</title>
      <author><first>Zhao</first><last>Meng</last></author>
      <author><first>Roger</first><last>Wattenhofer</last></author>
      <pages>6679–6689</pages>
      <abstract>Generating adversarial examples for natural language is hard, as natural language consists of discrete symbols, and examples are often of variable lengths. In this paper, we propose a geometry-inspired attack for generating natural language adversarial examples. Our attack generates adversarial examples by iteratively approximating the decision boundary of Deep Neural Networks (DNNs). Experiments on two datasets with two different models show that our attack fools natural language models with high success rates, while only replacing a few words. Human evaluation shows that adversarial examples generated by our attack are hard for humans to recognize. Further experiments show that adversarial training can improve model robustness against our attack.</abstract>
      <url hash="b1335bbc">2020.coling-main.585</url>
    </paper>
    <paper id="586">
      <title>Expert Concept-Modeling Ground Truth Construction for Word Embeddings Evaluation in Concept-Focused Domains</title>
      <author><first>Arianna</first><last>Betti</last></author>
      <author><first>Martin</first><last>Reynaert</last></author>
      <author><first>Thijs</first><last>Ossenkoppele</last></author>
      <author><first>Yvette</first><last>Oortwijn</last></author>
      <author><first>Andrew</first><last>Salway</last></author>
      <author><first>Jelke</first><last>Bloem</last></author>
      <pages>6690–6702</pages>
      <abstract>We present a novel, domain expert-controlled, replicable procedure for the construction of concept-modeling ground truths with the aim of evaluating the application of word embeddings. In particular, our method is designed to evaluate the application of word and paragraph embeddings in concept-focused textual domains, where a generic ontology does not provide enough information. We illustrate the procedure, and validate it by describing the construction of an expert ground truth, QuiNE-GT. QuiNE-GT is built to answer research questions concerning the concept of naturalized epistemology in QUINE, a 2-million-token, single-author, 20th-century English philosophy corpus of outstanding quality, cleaned up and enriched for the purpose. To the best of our ken, expert concept-modeling ground truths are extremely rare in current literature, nor has the theoretical methodology behind their construction ever been explicitly conceptualised and properly systematised. Expert-controlled concept-modeling ground truths are however essential to allow proper evaluation of word embeddings techniques, and increase their trustworthiness in specialised domains in which the detection of concepts through their expression in texts is important. We highlight challenges, requirements, and prospects for future work.</abstract>
      <url hash="5783947d">2020.coling-main.586</url>
    </paper>
    <paper id="587">
      <title>Creation of Corpus and analysis in Code-Mixed <fixed-case>K</fixed-case>annada-<fixed-case>E</fixed-case>nglish <fixed-case>T</fixed-case>witter data for Emotion Prediction</title>
      <author><first>Abhinav Reddy</first><last>Appidi</last></author>
      <author><first>Vamshi Krishna</first><last>Srirangam</last></author>
      <author><first>Darsi</first><last>Suhas</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <pages>6703–6709</pages>
      <abstract>Emotion prediction is a critical task in the field of Natural Language Processing (NLP). There has been a significant amount of work done in emotion prediction for resource-rich languages. There has been work done on code-mixed social media corpus but not on emotion prediction of Kannada-English code-mixed Twitter data. In this paper, we analyze the problem of emotion prediction on corpus obtained from code-mixed Kannada-English extracted from Twitter annotated with their respective ‘Emotion’ for each tweet. We experimented with machine learning prediction models using features like Character N-Grams, Word N-Grams, Repetitive characters, and others on SVM and LSTM on our corpus, which resulted in an accuracy of 30% and 32% respectively.</abstract>
      <url hash="8aeb7965">2020.coling-main.587</url>
    </paper>
    <paper id="588">
      <title>Fair Evaluation in Concept Normalization: a Large-scale Comparative Analysis for <fixed-case>BERT</fixed-case>-based Models</title>
      <author><first>Elena</first><last>Tutubalina</last></author>
      <author><first>Artur</first><last>Kadurin</last></author>
      <author><first>Zulfat</first><last>Miftahutdinov</last></author>
      <pages>6710–6716</pages>
      <abstract>Linking of biomedical entity mentions to various terminologies of chemicals, diseases, genes, adverse drug reactions is a challenging task, often requiring non-syntactic interpretation. A large number of biomedical corpora and state-of-the-art models have been introduced in the past five years. However, there are no general guidelines regarding the evaluation of models on these corpora in single- and cross-terminology settings. In this work, we perform a comparative evaluation of various benchmarks and study the efficiency of state-of-the-art neural architectures based on Bidirectional Encoder Representations from Transformers (BERT) for linking of three entity types across three domains: research abstracts, drug labels, and user-generated texts on drug therapy in English. We have made the source code and results available at https://github.com/insilicomedicine/Fair-Evaluation-BERT.</abstract>
      <url hash="44d0ebf1">2020.coling-main.588</url>
    </paper>
    <paper id="589">
      <title>A Sentence Cloze Dataset for <fixed-case>C</fixed-case>hinese Machine Reading Comprehension</title>
      <author><first>Yiming</first><last>Cui</last></author>
      <author><first>Ting</first><last>Liu</last></author>
      <author><first>Ziqing</first><last>Yang</last></author>
      <author><first>Zhipeng</first><last>Chen</last></author>
      <author><first>Wentao</first><last>Ma</last></author>
      <author><first>Wanxiang</first><last>Che</last></author>
      <author><first>Shijin</first><last>Wang</last></author>
      <author><first>Guoping</first><last>Hu</last></author>
      <pages>6717–6723</pages>
      <abstract>Owing to the continuous efforts by the Chinese NLP community, more and more Chinese machine reading comprehension datasets become available. To add diversity in this area, in this paper, we propose a new task called Sentence Cloze-style Machine Reading Comprehension (SC-MRC). The proposed task aims to fill the right candidate sentence into the passage that has several blanks. We built a Chinese dataset called CMRC 2019 to evaluate the difficulty of the SC-MRC task. Moreover, to add more difficulties, we also made fake candidates that are similar to the correct ones, which requires the machine to judge their correctness in the context. The proposed dataset contains over 100K blanks (questions) within over 10K passages, which was originated from Chinese narrative stories. To evaluate the dataset, we implement several baseline systems based on the pre-trained models, and the results show that the state-of-the-art model still underperforms human performance by a large margin. We release the dataset and baseline system to further facilitate our community. Resources available through https://github.com/ymcui/cmrc2019</abstract>
      <url hash="106e6694">2020.coling-main.589</url>
    </paper>
    <paper id="590">
      <title>Improving Document-Level Sentiment Analysis with User and Product Context</title>
      <author><first>Chenyang</first><last>Lyu</last></author>
      <author><first>Jennifer</first><last>Foster</last></author>
      <author><first>Yvette</first><last>Graham</last></author>
      <pages>6724–6729</pages>
      <abstract>Past work that improves document-level sentiment analysis by encoding user and product in- formation has been limited to considering only the text of the current review. We investigate incorporating additional review text available at the time of sentiment prediction that may prove meaningful for guiding prediction. Firstly, we incorporate all available historical review text belonging to the author of the review in question. Secondly, we investigate the inclusion of his- torical reviews associated with the current product (written by other users). We achieve this by explicitly storing representations of reviews written by the same user and about the same product and force the model to memorize all reviews for one particular user and product. Additionally, we drop the hierarchical architecture used in previous work to enable words in the text to directly attend to each other. Experiment results on IMDB, Yelp 2013 and Yelp 2014 datasets show improvement to state-of-the-art of more than 2 percentage points in the best case.</abstract>
      <url hash="80a4121b">2020.coling-main.590</url>
    </paper>
    <paper id="591">
      <title>Multilingual Neural <fixed-case>RST</fixed-case> Discourse Parsing</title>
      <author><first>Zhengyuan</first><last>Liu</last></author>
      <author><first>Ke</first><last>Shi</last></author>
      <author><first>Nancy</first><last>Chen</last></author>
      <pages>6730–6738</pages>
      <abstract>Text discourse parsing plays an important role in understanding information flow and argumentative structure in natural language. Previous research under the Rhetorical Structure Theory (RST) has mostly focused on inducing and evaluating models from the English treebank. However, the parsing tasks for other languages such as German, Dutch, and Portuguese are still challenging due to the shortage of annotated data. In this work, we investigate two approaches to establish a neural, cross-lingual discourse parser via: (1) utilizing multilingual vector representations; and (2) adopting segment-level translation of the source content. Experiment results show that both methods are effective even with limited training data, and achieve state-of-the-art performance on cross-lingual, document-level discourse parsing on all sub-tasks.</abstract>
      <url hash="a1cc5e02">2020.coling-main.591</url>
    </paper>
    <paper id="592">
      <title>Intrinsic Quality Assessment of Arguments</title>
      <author><first>Henning</first><last>Wachsmuth</last></author>
      <author><first>Till</first><last>Werner</last></author>
      <pages>6739–6745</pages>
      <abstract>Several quality dimensions of natural language arguments have been investigated. Some are likely to be reflected in linguistic features (e.g., an argument’s arrangement), whereas others depend on context (e.g., relevance) or topic knowledge (e.g., acceptability). In this paper, we study the intrinsic computational assessment of 15 dimensions, i.e., only learning from an argument’s text. In systematic experiments with eight feature types on an existing corpus, we observe moderate but significant learning success for most dimensions. Rhetorical quality seems hardest to assess, and subjectivity features turn out strong, although length bias in the corpus impedes full validity. We also find that human assessors differ more clearly to each other than to our approach.</abstract>
      <url hash="daaa038c">2020.coling-main.592</url>
    </paper>
    <paper id="593">
      <title>Tree Representations in Transition System for <fixed-case>RST</fixed-case> Parsing</title>
      <author><first>Jinfen</first><last>Li</last></author>
      <author><first>Lu</first><last>Xiao</last></author>
      <pages>6746–6751</pages>
      <abstract>The transition-based systems in the past studies propose a series of actions, to build a right-heavy binarized tree for the RST parsing. However, the nodes of the binary-nuclear relations (e.g., Contrast) have the same nuclear type with those of the multi-nuclear relations (e.g., Joint) in the binary tree structure. In addition, the reduce action only construct binary trees instead of multi-branch trees, which is the original RST tree structure. In our paper, we design a new nuclear type for the multi-nuclear relations, and a new action to construct a multi-branch tree. We enrich the feature set by extracting additional refined dependency feature of texts from the Bi-Affine model. We also compare the performance of two approaches for RST parsing in the transition-based system: a joint action of reduce-shift and nuclear type (i.e., Reduce-SN) vs a separate one that applies Reduce action first and then assigns nuclear type. We find that the new devised nuclear type and action are more capable of capturing the multi-nuclear relation and the joint action is more suitable than the separate one. Our multi-branch tree structure obtains the state-of-the-art performance for all the 18 coarse relations.</abstract>
      <url hash="29f67d78">2020.coling-main.593</url>
    </paper>
    <paper id="594">
      <title>Incremental Neural Lexical Coherence Modeling</title>
      <author><first>Sungho</first><last>Jeon</last></author>
      <author><first>Michael</first><last>Strube</last></author>
      <pages>6752–6758</pages>
      <abstract>Pretrained language models, neural models pretrained on massive amounts of data, have established the state of the art in a range of NLP tasks. They are based on a modern machine-learning technique, the Transformer which relates all items simultaneously to capture semantic relations in sequences. However, it differs from what humans do. Humans read sentences one-by-one, incrementally. Can neural models benefit by interpreting texts incrementally as humans do? We investigate this question in coherence modeling. We propose a coherence model which interprets sentences incrementally to capture lexical relations between them. We compare the state of the art in each task, simple neural models relying on a pretrained language model, and our model in two downstream tasks. Our findings suggest that interpreting texts incrementally as humans could be useful to design more advanced models.</abstract>
      <url hash="1be6caf5">2020.coling-main.594</url>
    </paper>
    <paper id="595">
      <title>Statistical Parsing of Tree Wrapping Grammars</title>
      <author><first>Tatiana</first><last>Bladier</last></author>
      <author><first>Jakub</first><last>Waszczuk</last></author>
      <author><first>Laura</first><last>Kallmeyer</last></author>
      <pages>6759–6766</pages>
      <abstract>We describe an approach to statistical parsing with Tree-Wrapping Grammars (TWG). TWG is a tree-rewriting formalism which includes the tree-combination operations of substitution, sister-adjunction and tree-wrapping substitution. TWGs can be extracted from constituency treebanks and aim at representing long distance dependencies (LDDs) in a linguistically adequate way. We present a parsing algorithm for TWGs based on neural supertagging and A* parsing. We extract a TWG for English from the treebanks for Role and Reference Grammar and discuss first parsing results with this grammar.</abstract>
      <url hash="c6029c6b">2020.coling-main.595</url>
    </paper>
    <paper id="596">
      <title>Out-of-Task Training for Dialog State Tracking Models</title>
      <author><first>Michael</first><last>Heck</last></author>
      <author><first>Christian</first><last>Geishauser</last></author>
      <author><first>Hsien-chin</first><last>Lin</last></author>
      <author><first>Nurul</first><last>Lubis</last></author>
      <author><first>Marco</first><last>Moresi</last></author>
      <author><first>Carel</first><last>van Niekerk</last></author>
      <author><first>Milica</first><last>Gasic</last></author>
      <pages>6767–6774</pages>
      <abstract>Dialog state tracking (DST) suffers from severe data sparsity. While many natural language processing (NLP) tasks benefit from transfer learning and multi-task learning, in dialog these methods are limited by the amount of available data and by the specificity of dialog applications. In this work, we successfully utilize non-dialog data from unrelated NLP tasks to train dialog state trackers. This opens the door to the abundance of unrelated NLP corpora to mitigate the data sparsity issue inherent to DST.</abstract>
      <url hash="b3ad69a7">2020.coling-main.596</url>
    </paper>
    <paper id="597">
      <title>Resource Constrained Dialog Policy Learning Via Differentiable Inductive Logic Programming</title>
      <author><first>Zhenpeng</first><last>Zhou</last></author>
      <author><first>Ahmad</first><last>Beirami</last></author>
      <author><first>Paul</first><last>Crook</last></author>
      <author><first>Pararth</first><last>Shah</last></author>
      <author><first>Rajen</first><last>Subba</last></author>
      <author><first>Alborz</first><last>Geramifard</last></author>
      <pages>6775–6787</pages>
      <abstract>Motivated by the needs of resource constrained dialog policy learning, we introduce dialog policy via differentiable inductive logic (DILOG). We explore the tasks of one-shot learning and zero-shot domain transfer with DILOG on SimDial and MultiWoZ. Using a single representative dialog from the restaurant domain, we train DILOG on the SimDial dataset and obtain 99+% in-domain test accuracy. We also show that the trained DILOG zero-shot transfers to all other domains with 99+% accuracy, proving the suitability of DILOG to slot-filling dialogs. We further extend our study to the MultiWoZ dataset achieving 90+% inform and success metrics. We also observe that these metrics are not capturing some of the shortcomings of DILOG in terms of false positives, prompting us to measure an auxiliary Action F1 score. We show that DILOG is 100x more data efficient than state-of-the-art neural approaches on MultiWoZ while achieving similar performance metrics. We conclude with a discussion on the strengths and weaknesses of DILOG.</abstract>
      <url hash="cfa7ea08">2020.coling-main.597</url>
    </paper>
    <paper id="598">
      <title><fixed-case>G</fixed-case>erman’s Next Language Model</title>
      <author><first>Branden</first><last>Chan</last></author>
      <author><first>Stefan</first><last>Schweter</last></author>
      <author><first>Timo</first><last>Möller</last></author>
      <pages>6788–6796</pages>
      <abstract>In this work we present the experiments which lead to the creation of our BERT and ELECTRA based German language models, GBERT and GELECTRA. By varying the input training data, model size, and the presence of Whole Word Masking (WWM) we were able to attain SoTA performance across a set of document classification and named entity recognition (NER) tasks for both models of base and large size. We adopt an evaluation driven approach in training these models and our results indicate that both adding more data and utilizing WWM improve model performance. By benchmarking against existing German models, we show that these models are the best German models to date. All trained models will be made publicly available to the research community.</abstract>
      <url hash="355d274d">2020.coling-main.598</url>
    </paper>
    <paper id="599">
      <title>Language Model Transformers as Evaluators for Open-domain Dialogues</title>
      <author><first>Rostislav</first><last>Nedelchev</last></author>
      <author><first>Jens</first><last>Lehmann</last></author>
      <author><first>Ricardo</first><last>Usbeck</last></author>
      <pages>6797–6808</pages>
      <abstract>Computer-based systems for communication with humans are a cornerstone of AI research since the 1950s. So far, the most effective way to assess the quality of the dialogues produced by these systems is to use resource-intensive manual labor instead of automated means. In this work, we investigate whether language models (LM) based on transformer neural networks can indicate the quality of a conversation. In a general sense, language models are methods that learn to predict one or more words based on an already given context. Due to their unsupervised nature, they are candidates for efficient, automatic indication of dialogue quality. We demonstrate that human evaluators have a positive correlation between the output of the language models and scores. We also provide some insights into their behavior and inner-working in a conversational context.</abstract>
      <url hash="4f8cb48f">2020.coling-main.599</url>
    </paper>
    <paper id="600">
      <title>Embedding Dynamic Attributed Networks by Modeling the Evolution Processes</title>
      <author><first>Zenan</first><last>Xu</last></author>
      <author><first>Zijing</first><last>Ou</last></author>
      <author><first>Qinliang</first><last>Su</last></author>
      <author><first>Jianxing</first><last>Yu</last></author>
      <author><first>Xiaojun</first><last>Quan</last></author>
      <author><first>ZhenKun</first><last>Lin</last></author>
      <pages>6809–6819</pages>
      <abstract>Network embedding has recently emerged as a promising technique to embed nodes of a network into low-dimensional vectors. While fairly successful, most existing works focus on the embedding techniques for static networks. But in practice, there are many networks that are evolving over time and hence are dynamic, e.g., the social networks. To address this issue, a high-order spatio-temporal embedding model is developed to track the evolutions of dynamic networks. Specifically, an activeness-aware neighborhood embedding method is first proposed to extract the high-order neighborhood information at each given timestamp. Then, an embedding prediction framework is further developed to capture the temporal correlations, in which the attention mechanism is employed instead of recurrent neural networks (RNNs) for its efficiency in computing and flexibility in modeling. Extensive experiments are conducted on four real-world datasets from three different areas. It is shown that the proposed method outperforms all the baselines by a substantial margin for the tasks of dynamic link prediction and node classification, which demonstrates the effectiveness of the proposed methods on tracking the evolutions of dynamic networks.</abstract>
      <url hash="951c6d42">2020.coling-main.600</url>
    </paper>
    <paper id="601">
      <title>Learning distributed sentence vectors with bi-directional 3<fixed-case>D</fixed-case> convolutions</title>
      <author><first>Bin</first><last>Liu</last></author>
      <author><first>Liang</first><last>Wang</last></author>
      <author><first>Guosheng</first><last>Yin</last></author>
      <pages>6820–6830</pages>
      <abstract>We propose to learn distributed sentence representation using text’s visual features as input. Different from the existing methods that render the words or characters of a sentence into images separately, we further fold these images into a 3-dimensional sentence tensor. Then, multiple 3-dimensional convolutions with different lengths (the third dimension) are applied to the sentence tensor, which act as bi-gram, tri-gram, quad-gram, and even five-gram detectors jointly. Similar to the Bi-LSTM, these n-gram detectors learn both forward and backward distributional semantic knowledge from the sentence tensor. That is, the proposed model using bi-directional convolutions to learn text embedding according to the semantic order of words. The feature maps from the two directions are concatenated for final sentence embedding learning. Our model involves only a single-layer of convolution which makes it easy and fast to train. Finally, we evaluate the sentence embeddings on several downstream Natural Language Processing (NLP) tasks, which demonstrate a surprisingly excellent performance of the proposed model.</abstract>
      <url hash="6ee03eba">2020.coling-main.601</url>
    </paper>
    <paper id="602">
      <title>Don’t Invite <fixed-case>BERT</fixed-case> to Drink a Bottle: Modeling the Interpretation of Metonymies Using <fixed-case>BERT</fixed-case> and Distributional Representations</title>
      <author><first>Paolo</first><last>Pedinotti</last></author>
      <author><first>Alessandro</first><last>Lenci</last></author>
      <pages>6831–6837</pages>
      <abstract>In this work, we carry out two experiments in order to assess the ability of BERT to capture the meaning shift associated with metonymic expressions. We test the model on a new dataset that is representative of the most common types of metonymy. We compare BERT with the Structured Distributional Model (SDM), a model for the representation of words in context which is based on the notion of Generalized Event Knowledge. The results reveal that, while BERT ability to deal with metonymy is quite limited, SDM is good at predicting the meaning of metonymic expressions, providing support for an account of metonymy based on event knowledge.</abstract>
      <url hash="51018f51">2020.coling-main.602</url>
    </paper>
    <paper id="603">
      <title>Neural Unsupervised Domain Adaptation in <fixed-case>NLP</fixed-case>—<fixed-case>A</fixed-case> Survey</title>
      <author><first>Alan</first><last>Ramponi</last></author>
      <author><first>Barbara</first><last>Plank</last></author>
      <pages>6838–6855</pages>
      <abstract>Deep neural networks excel at learning from labeled data and achieve state-of-the-art results on a wide array of Natural Language Processing tasks. In contrast, learning from unlabeled data, especially under domain shift, remains a challenge. Motivated by the latest advances, in this survey we review neural unsupervised domain adaptation techniques which do not require labeled target domain data. This is a more challenging yet a more widely applicable setup. We outline methods, from early traditional non-neural methods to pre-trained model transfer. We also revisit the notion of domain, and we uncover a bias in the type of Natural Language Processing tasks which received most attention. Lastly, we outline future directions, particularly the broader need for out-of-distribution generalization of future NLP.</abstract>
      <url hash="e69dceef">2020.coling-main.603</url>
    </paper>
    <paper id="604">
      <title>Exploring the Value of Personalized Word Embeddings</title>
      <author><first>Charles</first><last>Welch</last></author>
      <author><first>Jonathan K.</first><last>Kummerfeld</last></author>
      <author><first>Verónica</first><last>Pérez-Rosas</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <pages>6856–6862</pages>
      <abstract>In this paper, we introduce personalized word embeddings, and examine their value for language modeling. We compare the performance of our proposed prediction model when using personalized versus generic word representations, and study how these representations can be leveraged for improved performance. We provide insight into what types of words can be more accurately predicted when building personalized models. Our results show that a subset of words belonging to specific psycholinguistic categories tend to vary more in their representations across users and that combining generic and personalized word embeddings yields the best performance, with a 4.7% relative reduction in perplexity. Additionally, we show that a language model using personalized word embeddings can be effectively used for authorship attribution.</abstract>
      <url hash="5b24a38e">2020.coling-main.604</url>
    </paper>
    <paper id="605">
      <title>Do Neural Language Models Overcome Reporting Bias?</title>
      <author><first>Vered</first><last>Shwartz</last></author>
      <author><first>Yejin</first><last>Choi</last></author>
      <pages>6863–6870</pages>
      <abstract>Mining commonsense knowledge from corpora suffers from reporting bias, over-representing the rare at the expense of the trivial (Gordon and Van Durme, 2013). We study to what extent pre-trained language models overcome this issue. We find that while their generalization capacity allows them to better estimate the plausibility of frequent but unspoken of actions, outcomes, and properties, they also tend to overestimate that of the very rare, amplifying the bias that already exists in their training corpus.</abstract>
      <url hash="2b7236c3">2020.coling-main.605</url>
    </paper>
    <paper id="606">
      <title>Interpretable Multi-headed Attention for Abstractive Summarization at Controllable Lengths</title>
      <author><first>Ritesh</first><last>Sarkhel</last></author>
      <author><first>Moniba</first><last>Keymanesh</last></author>
      <author><first>Arnab</first><last>Nandi</last></author>
      <author><first>Srinivasan</first><last>Parthasarathy</last></author>
      <pages>6871–6882</pages>
      <abstract>Abstractive summarization at controllable lengths is a challenging task in natural language processing. It is even more challenging for domains where limited training data is available or scenarios in which the length of the summary is not known beforehand. At the same time, when it comes to trusting machine-generated summaries, explaining how a summary was constructed in human-understandable terms may be critical. We propose Multi-level Summarizer (MLS), a supervised method to construct abstractive summaries of a text document at controllable lengths. The key enabler of our method is an interpretable multi-headed attention mechanism that computes attention distribution over an input document using an array of timestep independent semantic kernels. Each kernel optimizes a human-interpretable syntactic or semantic property. Exhaustive experiments on two low-resource datasets in English show that MLS outperforms strong baselines by up to 14.70% in the METEOR score. Human evaluation of the summaries also suggests that they capture the key concepts of the document at various length-budgets.</abstract>
      <url hash="c4338c21">2020.coling-main.606</url>
    </paper>
    <paper id="607">
      <title>Scale down Transformer by Grouping Features for a Lightweight Character-level Language Model</title>
      <author><first>Sungrae</first><last>Park</last></author>
      <author><first>Geewook</first><last>Kim</last></author>
      <author><first>Junyeop</first><last>Lee</last></author>
      <author><first>Junbum</first><last>Cha</last></author>
      <author><first>Ji-Hoon</first><last>Kim</last></author>
      <author><first>Hwalsuk</first><last>Lee</last></author>
      <pages>6883–6893</pages>
      <abstract>This paper introduces a method that efficiently reduces the computational cost and parameter size of Transformer. The proposed model, refer to as Group-Transformer, splits feature space into multiple groups, factorizes the calculation paths, and reduces computations for the group interaction. Extensive experiments on two benchmark tasks, enwik8 and text8, prove our model’s effectiveness and efficiency in small-scale Transformers. To the best of our knowledge, Group-Transformer is the first attempt to design Transformer with the group strategy, widely used for efficient CNN architectures.</abstract>
      <url hash="c97cf3d1">2020.coling-main.607</url>
    </paper>
    <paper id="608">
      <title>Attention Word Embedding</title>
      <author><first>Shashank</first><last>Sonkar</last></author>
      <author><first>Andrew</first><last>Waters</last></author>
      <author><first>Richard</first><last>Baraniuk</last></author>
      <pages>6894–6902</pages>
      <abstract>Word embedding models learn semantically rich vector representations of words and are widely used to initialize natural processing language (NLP) models. The popular continuous bag-of-words (CBOW) model of word2vec learns a vector embedding by masking a given word in a sentence and then using the other words as a context to predict it. A limitation of CBOW is that it equally weights the context words when making a prediction, which is inefficient, since some words have higher predictive value than others. We tackle this inefficiency by introducing the Attention Word Embedding (AWE) model, which integrates the attention mechanism into the CBOW model. We also propose AWE-S, which incorporates subword information. We demonstrate that AWE and AWE-S outperform the state-of-the-art word embedding models both on a variety of word similarity datasets and when used for initialization of NLP models.</abstract>
      <url hash="b671b785">2020.coling-main.608</url>
    </paper>
    <paper id="609">
      <title><fixed-case>C</fixed-case>haracter<fixed-case>BERT</fixed-case>: Reconciling <fixed-case>ELM</fixed-case>o and <fixed-case>BERT</fixed-case> for Word-Level Open-Vocabulary Representations From Characters</title>
      <author><first>Hicham</first><last>El Boukkouri</last></author>
      <author><first>Olivier</first><last>Ferret</last></author>
      <author><first>Thomas</first><last>Lavergne</last></author>
      <author><first>Hiroshi</first><last>Noji</last></author>
      <author><first>Pierre</first><last>Zweigenbaum</last></author>
      <author><first>Jun’ichi</first><last>Tsujii</last></author>
      <pages>6903–6915</pages>
      <abstract>Due to the compelling improvements brought by BERT, many recent representation models adopted the Transformer architecture as their main building block, consequently inheriting the wordpiece tokenization system despite it not being intrinsically linked to the notion of Transformers. While this system is thought to achieve a good balance between the flexibility of characters and the efficiency of full words, using predefined wordpiece vocabularies from the general domain is not always suitable, especially when building models for specialized domains (e.g., the medical domain). Moreover, adopting a wordpiece tokenization shifts the focus from the word level to the subword level, making the models conceptually more complex and arguably less convenient in practice. For these reasons, we propose CharacterBERT, a new variant of BERT that drops the wordpiece system altogether and uses a Character-CNN module instead to represent entire words by consulting their characters. We show that this new model improves the performance of BERT on a variety of medical domain tasks while at the same time producing robust, word-level, and open-vocabulary representations.</abstract>
      <url hash="9b77793f">2020.coling-main.609</url>
    </paper>
    <paper id="610">
      <title>Autoregressive Reasoning over Chains of Facts with Transformers</title>
      <author><first>Ruben</first><last>Cartuyvels</last></author>
      <author><first>Graham</first><last>Spinks</last></author>
      <author><first>Marie-Francine</first><last>Moens</last></author>
      <pages>6916–6930</pages>
      <abstract>This paper proposes an iterative inference algorithm for multi-hop explanation regeneration, that retrieves relevant factual evidence in the form of text snippets, given a natural language question and its answer. Combining multiple sources of evidence or facts for multi-hop reasoning becomes increasingly hard when the number of sources needed to make an inference grows. Our algorithm copes with this by decomposing the selection of facts from a corpus autoregressively, conditioning the next iteration on previously selected facts. This allows us to use a pairwise learning-to-rank loss. We validate our method on datasets of the TextGraphs 2019 and 2020 Shared Tasks for explanation regeneration. Existing work on this task either evaluates facts in isolation or artificially limits the possible chains of facts, thus limiting multi-hop inference. We demonstrate that our algorithm, when used with a pre-trained transformer model, outperforms the previous state-of-the-art in terms of precision, training time and inference efficiency.</abstract>
      <url hash="c97d241b">2020.coling-main.610</url>
    </paper>
    <paper id="611">
      <title>Augmenting <fixed-case>NLP</fixed-case> models using Latent Feature Interpolations</title>
      <author><first>Amit</first><last>Jindal</last></author>
      <author><first>Arijit</first><last>Ghosh Chowdhury</last></author>
      <author><first>Aniket</first><last>Didolkar</last></author>
      <author><first>Di</first><last>Jin</last></author>
      <author><first>Ramit</first><last>Sawhney</last></author>
      <author><first>Rajiv Ratn</first><last>Shah</last></author>
      <pages>6931–6936</pages>
      <abstract>Models with a large number of parameters are prone to over-fitting and often fail to capture the underlying input distribution. We introduce Emix, a data augmentation method that uses interpolations of word embeddings and hidden layer representations to construct virtual examples. We show that Emix shows significant improvements over previously used interpolation based regularizers and data augmentation techniques. We also demonstrate how our proposed method is more robust to sparsification. We highlight the merits of our proposed methodology by performing thorough quantitative and qualitative assessments.</abstract>
      <url hash="5f0a0218">2020.coling-main.611</url>
    </paper>
    <paper id="612">
      <title>Neural Language Modeling for Named Entity Recognition</title>
      <author><first>Zhihong</first><last>Lei</last></author>
      <author><first>Weiyue</first><last>Wang</last></author>
      <author><first>Christian</first><last>Dugast</last></author>
      <author><first>Hermann</first><last>Ney</last></author>
      <pages>6937–6941</pages>
      <abstract>Named entity recognition is a key component in various natural language processing systems, and neural architectures provide significant improvements over conventional approaches. Regardless of different word embedding and hidden layer structures of the networks, a conditional random field layer is commonly used for the output. This work proposes to use a neural language model as an alternative to the conditional random field layer, which is more flexible for the size of the corpus. Experimental results show that the proposed system has a significant advantage in terms of training speed, with a marginal performance degradation.</abstract>
      <url hash="5746d362">2020.coling-main.612</url>
    </paper>
  </volume>
  <volume id="demos" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the 28th International Conference on Computational Linguistics: System Demonstrations</booktitle>
      <editor><first>Michal</first><last>Ptaszynski</last></editor>
      <editor><first>Bartosz</first><last>Ziolko</last></editor>
      <publisher>International Committee on Computational Linguistics (ICCL)</publisher>
      <address>Barcelona, Spain (Online)</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="40ccfbdf">2020.coling-demos.0</url>
    </frontmatter>
    <paper id="1">
      <title>Ve’rdd. Narrowing the Gap between Paper Dictionaries, Low-Resource <fixed-case>NLP</fixed-case> and Community Involvement</title>
      <author><first>Khalid</first><last>Alnajjar</last></author>
      <author><first>Mika</first><last>Hämäläinen</last></author>
      <author><first>Jack</first><last>Rueter</last></author>
      <author><first>Niko</first><last>Partanen</last></author>
      <pages>1–6</pages>
      <abstract>We present an open-source online dictionary editing system, Ve′rdd, that offers a chance to re-evaluate and edit grassroots dictionaries that have been exposed to multiple amateur editors. The idea is to incorporate community activities into a state-of-the-art finite-state language description of a seriously endangered minority language, Skolt Sami. Problems involve getting the community to take part in things above the pencil-and-paper level. At times, it seems that the native speakers and the dictionary oriented are lacking technical understanding to utilize the infrastructures which might make their work more meaningful in the future, i.e. multiple reuse of all of their input. Therefore, our system integrates with the existing tools and infrastructures for Uralic language masking the technical complexities behind a user-friendly UI.</abstract>
      <url hash="00733352">2020.coling-demos.1</url>
    </paper>
    <paper id="2">
      <title><fixed-case>M</fixed-case>aint<fixed-case>N</fixed-case>et: A Collaborative Open-Source Library for Predictive Maintenance Language Resources</title>
      <author><first>Farhad</first><last>Akhbardeh</last></author>
      <author><first>Travis</first><last>Desell</last></author>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <pages>7–11</pages>
      <abstract>Maintenance record logbooks are an emerging text type in NLP. An important part of them typically consist of free text with many domain specific technical terms, abbreviations, and non-standard spelling and grammar. This poses difficulties for NLP pipelines trained on standard corpora. Analyzing and annotating such documents is of particular importance in the development of predictive maintenance systems, which aim to improve operational efficiency, reduce costs, prevent accidents, and save lives. In order to facilitate and encourage research in this area, we have developed MaintNet, a collaborative open-source library of technical and domain-specific language resources. MaintNet provides novel logbook data from the aviation, automotive, and facility maintenance domains along with tools to aid in their (pre-)processing and clustering. Furthermore, it provides a way to encourage discussion on and sharing of new datasets and tools for logbook data analysis.</abstract>
      <url hash="57a55044">2020.coling-demos.2</url>
    </paper>
    <paper id="3">
      <title><fixed-case>DART</fixed-case>: A Lightweight Quality-Suggestive Data-to-Text Annotation Tool</title>
      <author><first>Ernie</first><last>Chang</last></author>
      <author><first>Jeriah</first><last>Caplinger</last></author>
      <author><first>Alex</first><last>Marin</last></author>
      <author><first>Xiaoyu</first><last>Shen</last></author>
      <author><first>Vera</first><last>Demberg</last></author>
      <pages>12–17</pages>
      <abstract>We present a lightweight annotation tool, the Data AnnotatoR Tool (DART), for the general task of labeling structured data with textual descriptions. The tool is implemented as an interactive application that reduces human efforts in annotating large quantities of structured data, e.g. in the format of a table or tree structure. By using a backend sequence-to-sequence model, our system iteratively analyzes the annotated labels in order to better sample unlabeled data. In a simulation experiment performed on annotating large quantities of structured data, DART has been shown to reduce the total number of annotations needed with active learning and automatically suggesting relevant labels.</abstract>
      <url hash="03f41b66">2020.coling-demos.3</url>
    </paper>
    <paper id="4">
      <title>Demo Application for the <fixed-case>A</fixed-case>uto<fixed-case>GOAL</fixed-case> Framework</title>
      <author><first>Suilan</first><last>Estevez-Velarde</last></author>
      <author><first>Alejandro</first><last>Piad-Morffis</last></author>
      <author><first>Yoan</first><last>Gutiérrez</last></author>
      <author><first>Andres</first><last>Montoyo</last></author>
      <author><first>Rafael</first><last>Muñoz-Guillena</last></author>
      <author><first>Yudivián</first><last>Almeida Cruz</last></author>
      <pages>18–22</pages>
      <abstract>This paper introduces a web demo that showcases the main characteristics of the AutoGOAL framework. AutoGOAL is a framework in Python for automatically finding the best way to solve a given task. It has been designed mainly for automatic machine learning(AutoML) but it can be used in any scenario where several possible strategies are available to solve a given computational task. In contrast with alternative frameworks, AutoGOAL can be applied seamlessly to Natural Language Processing as well as structured classification problems. This paper presents an overview of the framework’s design and experimental evaluation in several machine learning problems, including two recent NLP challenges. The accompanying software demo is available online (https://autogoal.github.io/demo) and full source code is provided under the MIT open-source license (https://autogoal.github.io).</abstract>
      <url hash="bb13551f">2020.coling-demos.4</url>
    </paper>
    <paper id="5">
      <title>Fast Word Predictor for On-Device Application</title>
      <author><first>Huy Tien</first><last>Nguyen</last></author>
      <author><first>Khoi Tuan</first><last>Nguyen</last></author>
      <author><first>Anh Tuan</first><last>Nguyen</last></author>
      <author><first>Thanh Lac Thi</first><last>Tran</last></author>
      <pages>23–27</pages>
      <abstract>Learning on large text corpora, deep neural networks achieve promising results in the next word prediction task. However, deploying these huge models on devices has to deal with constraints of low latency and a small binary size. To address these challenges, we propose a fast word predictor performing efficiently on mobile devices. Compared with a standard neural network which has a similar word prediction rate, the proposed model obtains 60% reduction in memory size and 100X faster inference time on a middle-end mobile device. The method is developed as a feature for a chat application which serves more than 100 million users.</abstract>
      <url hash="8808a273">2020.coling-demos.5</url>
    </paper>
    <paper id="6">
      <title>Semantic search with domain-specific word-embedding and production monitoring in Fintech</title>
      <author><first>Mojtaba</first><last>Farmanbar</last></author>
      <author><first>Nikki</first><last>Van Ommeren</last></author>
      <author><first>Boyang</first><last>Zhao</last></author>
      <pages>28–33</pages>
      <abstract>We present an end-to-end information retrieval system with domain-specific custom language models for accurate search terms expansion. The text mining pipeline tackles several challenges faced in an industry-setting, including multi-lingual jargon-rich unstructured text and privacy compliance. Combined with a novel statistical approach for word embedding evaluations, the models can be monitored in a production setting. Our approach is used in the real world in risk management in the financial sector and has wide applicability to other domains.</abstract>
      <url hash="7c91be4a">2020.coling-demos.6</url>
    </paper>
    <paper id="7">
      <title><fixed-case>C</fixed-case>ogni<fixed-case>V</fixed-case>al in Action: An Interface for Customizable Cognitive Word Embedding Evaluation</title>
      <author><first>Nora</first><last>Hollenstein</last></author>
      <author><first>Adrian</first><last>van der Lek</last></author>
      <author><first>Ce</first><last>Zhang</last></author>
      <pages>34–40</pages>
      <abstract>We demonstrate the functionalities of the new user interface for CogniVal. CogniVal is a framework for the cognitive evaluation of English word embeddings, which evaluates the quality of the embeddings based on their performance to predict human lexical representations from cognitive language processing signals from various sources. In this paper, we present an easy-to-use command line interface for CogniVal with multiple improvements over the original work, including the possibility to evaluate custom embeddings against custom cognitive data sources.</abstract>
      <url hash="55527b09">2020.coling-demos.7</url>
    </paper>
    <paper id="8">
      <title>A Multilingual Reading Comprehension System for more than 100 Languages</title>
      <author><first>Anthony</first><last>Ferritto</last></author>
      <author><first>Sara</first><last>Rosenthal</last></author>
      <author><first>Mihaela</first><last>Bornea</last></author>
      <author><first>Kazi</first><last>Hasan</last></author>
      <author><first>Rishav</first><last>Chakravarti</last></author>
      <author><first>Salim</first><last>Roukos</last></author>
      <author><first>Radu</first><last>Florian</last></author>
      <author><first>Avi</first><last>Sil</last></author>
      <pages>41–47</pages>
      <abstract>This paper presents M-GAAMA, a Multilingual Question Answering architecture and demo system. This is the first multilingual machine reading comprehension (MRC) demo which is able to answer questions in over 100 languages. M-GAAMA answers questions from a given passage in the same or different language. It incorporates several existing multilingual models that can be used interchangeably in the demo such as M-BERT and XLM-R. The M-GAAMA demo also improves language accessibility by incorporating the IBM Watson machine translation widget to provide additional capabilities to the user to see an answer in their desired language. We also show how M-GAAMA can be used in downstream tasks by incorporating it into an END-TO-END-QA system using CFO (Chakravarti et al., 2019). We experiment with our system architecture on the Multi-Lingual Question Answering (MLQA) and the COVID-19 CORD (Wang et al., 2020; Tang et al., 2020) datasets to provide insights into the performance of the system.</abstract>
      <url hash="154239fb">2020.coling-demos.8</url>
    </paper>
    <paper id="9">
      <title><fixed-case>X</fixed-case>plai<fixed-case>NLI</fixed-case>: Explainable Natural Language Inference through Visual Analytics</title>
      <author><first>Aikaterini-Lida</first><last>Kalouli</last></author>
      <author><first>Rita</first><last>Sevastjanova</last></author>
      <author><first>Valeria</first><last>de Paiva</last></author>
      <author><first>Richard</first><last>Crouch</last></author>
      <author><first>Mennatallah</first><last>El-Assady</last></author>
      <pages>48–52</pages>
      <abstract>Advances in Natural Language Inference (NLI) have helped us understand what state-of-the-art models really learn and what their generalization power is. Recent research has revealed some heuristics and biases of these models. However, to date, there is no systematic effort to capitalize on those insights through a system that uses these to explain the NLI decisions. To this end, we propose XplaiNLI, an eXplainable, interactive, visualization interface that computes NLI with different methods and provides explanations for the decisions made by the different approaches.</abstract>
      <url hash="05a2adf5">2020.coling-demos.9</url>
    </paper>
    <paper id="10">
      <title>Discussion Tracker: Supporting Teacher Learning about Students’ Collaborative Argumentation in High School Classrooms</title>
      <author><first>Luca</first><last>Lugini</last></author>
      <author><first>Christopher</first><last>Olshefski</last></author>
      <author><first>Ravneet</first><last>Singh</last></author>
      <author><first>Diane</first><last>Litman</last></author>
      <author><first>Amanda</first><last>Godley</last></author>
      <pages>53–58</pages>
      <abstract>Teaching collaborative argumentation is an advanced skill that many K-12 teachers struggle to develop. To address this, we have developed Discussion Tracker, a classroom discussion analytics system based on novel algorithms for classifying argument moves, specificity, and collaboration. Results from a classroom deployment indicate that teachers found the analytics useful, and that the underlying classifiers perform with moderate to substantial agreement with humans.</abstract>
      <url hash="e8730ac2">2020.coling-demos.10</url>
    </paper>
    <paper id="11">
      <title>An Online Readability Leveled <fixed-case>A</fixed-case>rabic Thesaurus</title>
      <author><first>Zhengyang</first><last>Jiang</last></author>
      <author><first>Nizar</first><last>Habash</last></author>
      <author><first>Muhamed</first><last>Al Khalil</last></author>
      <pages>59–63</pages>
      <abstract>This demo paper introduces the online Readability Leveled Arabic Thesaurus interface. For a given user input word, this interface provides the word’s possible lemmas, roots, English glosses, related Arabic words and phrases, and readability on a five-level readability scale. This interface builds on and connects multiple existing Arabic resources and processing tools. This one-of-a-kind system enables Arabic speakers and learners to benefit from advances in Arabic computational linguistics technologies. Feedback from users of the system will help the developers to identify lexical coverage gaps and errors. A live link to the demo is available at: http://samer.camel-lab.com/.</abstract>
      <url hash="1ac24895">2020.coling-demos.11</url>
    </paper>
    <paper id="12">
      <title><fixed-case>T</fixed-case>rain<fixed-case>X</fixed-case> – Named Entity Linking with Active Sampling and Bi-Encoders</title>
      <author><first>Tom</first><last>Oberhauser</last></author>
      <author><first>Tim</first><last>Bischoff</last></author>
      <author><first>Karl</first><last>Brendel</last></author>
      <author><first>Maluna</first><last>Menke</last></author>
      <author><first>Tobias</first><last>Klatt</last></author>
      <author><first>Amy</first><last>Siu</last></author>
      <author><first>Felix Alexander</first><last>Gers</last></author>
      <author><first>Alexander</first><last>Löser</last></author>
      <pages>64–69</pages>
      <abstract>We demonstrate TrainX, a system for Named Entity Linking for medical experts. It combines state-of-the-art entity recognition and linking architectures, such as Flair and fine-tuned Bi-Encoders based on BERT, with an easy-to-use interface for healthcare professionals. We support medical experts in annotating training data by using active sampling strategies to forward informative samples to the annotator. We demonstrate that our model is capable of linking against large knowledge bases, such as UMLS (3.6 million entities), and supporting zero-shot cases, where the linker has never seen the entity before. Those zero-shot capabilities help to mitigate the problem of rare and expensive training data that is a common issue in the medical domain.</abstract>
      <url hash="d8771307">2020.coling-demos.12</url>
    </paper>
    <paper id="13">
      <title><fixed-case>B</fixed-case>ull<fixed-case>S</fixed-case>top: A Mobile App for Cyberbullying Prevention</title>
      <author><first>Semiu</first><last>Salawu</last></author>
      <author><first>Yulan</first><last>He</last></author>
      <author><first>Jo</first><last>Lumsden</last></author>
      <pages>70–74</pages>
      <abstract>Social media has become the new playground for bullies. Young people are now regularly exposed to a wide range of abuse online. In response to the increasing prevalence of cyberbullying, online social networks have increased efforts to clamp down on online abuse but unfortunately, the nature, complexity and sheer volume of cyberbullying means that many cyberbullying incidents go undetected. BullStop is a mobile app for detecting and preventing cyberbullying and online abuse on social media platforms. It uses deep learning models to identify instances of cyberbullying and can automatically initiate actions such as deleting offensive messages and blocking bullies on behalf of the user. Our system not only achieves impressive prediction results but also demonstrates excellent potential for use in real-world scenarios and is freely available on the Google Play Store.</abstract>
      <url hash="a6888304">2020.coling-demos.13</url>
    </paper>
    <paper id="14">
      <title>Annobot: Platform for Annotating and Creating Datasets through Conversation with a Chatbot</title>
      <author><first>Rafał</first><last>Poświata</last></author>
      <author><first>Michał</first><last>Perełkiewicz</last></author>
      <pages>75–79</pages>
      <abstract>In this paper, we introduce Annobot: a platform for annotating and creating datasets through conversation with a chatbot. This natural form of interaction has allowed us to create a more accessible and flexible interface, especially for mobile devices. Our solution has a wide range of applications such as data labelling for binary, multi-class/label classification tasks, preparing data for regression problems, or creating sets for issues such as machine translation, question answering or text summarization. Additional features include pre-annotation, active sampling, online learning and real-time inter-annotator agreement. The system is integrated with the popular messaging platform: Facebook Messanger. Usability experiment showed the advantages of the proposed platform compared to other labelling tools. The source code of Annobot is available under the GNU LGPL license at https://github.com/rafalposwiata/annobot.</abstract>
      <url hash="f12f29c1">2020.coling-demos.14</url>
    </paper>
    <paper id="15">
      <title><fixed-case>A</fixed-case>rabic Curriculum Analysis</title>
      <author><first>Hamdy</first><last>Mubarak</last></author>
      <author><first>Shimaa</first><last>Amer</last></author>
      <author><first>Ahmed</first><last>Abdelali</last></author>
      <author><first>Kareem</first><last>Darwish</last></author>
      <pages>80–86</pages>
      <abstract>Developing a platform that analyzes the content of curricula can help identify their shortcomings and whether they are tailored to specific desired outcomes. In this paper, we present a system to analyze Arabic curricula and provide insights into their content. It allows users to explore word presence, surface-forms used, as well as contrasting statistics between different countries from which the curricula were selected. Also, it provides a facility to grade text in reference to given grade-level and gives users feedback about the complexity or difficulty of words used in a text.</abstract>
      <url hash="3430d207">2020.coling-demos.15</url>
    </paper>
    <paper id="16">
      <title>Epistolary Education in 21st Century: A System to Support Composition of <fixed-case>E</fixed-case>-mails by Students to Superiors in <fixed-case>J</fixed-case>apanese</title>
      <author><first>Kenji</first><last>Ryu</last></author>
      <author><first>Michal</first><last>Ptaszynski</last></author>
      <pages>87–92</pages>
      <abstract>E-mail is a communication tool widely used by people of all ages on the Internet today, often in business and formal situations, especially in Japan. Moreover, Japanese E-mail communication has a set of specific rules taught using specialized guidebooks. E-mail literacy education for many Japanese students is typically provided in a traditional, yet inefficient lecture-based way. We propose a system to support Japanese students in writing E-mails to superiors (teachers, job hunting representatives, etc.). We firstly make an investigation into the importance of formal E-mails in Japan, and what is needed to successfully write a formal E-mail. Next, we develop the system with accordance to those rules. Finally, we evaluated the system twofold. The results, although performed on a small number of samples, were generally positive, and clearly indicated additional ways to improve the system.</abstract>
      <url hash="f09773cb">2020.coling-demos.16</url>
    </paper>
  </volume>
  <volume id="tutorials" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the 28th International Conference on Computational Linguistics: Tutorial Abstracts</booktitle>
      <editor><first>Lucia</first><last>Specia</last></editor>
      <editor><first>Daniel</first><last>Beck</last></editor>
      <publisher>International Committee for Computational Linguistics</publisher>
      <address>Barcelona, Spain (Online)</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="da2c5756">2020.coling-tutorials.0</url>
    </frontmatter>
    <paper id="1">
      <title>Cross-lingual Semantic Representation for <fixed-case>NLP</fixed-case> with <fixed-case>UCCA</fixed-case></title>
      <author><first>Omri</first><last>Abend</last></author>
      <author><first>Dotan</first><last>Dvir</last></author>
      <author><first>Daniel</first><last>Hershcovich</last></author>
      <author><first>Jakob</first><last>Prange</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>1–9</pages>
      <abstract>This is an introductory tutorial to UCCA (Universal Conceptual Cognitive Annotation), a cross-linguistically applicable framework for semantic representation, with corpora annotated in English, German and French, and ongoing annotation in Russian and Hebrew. UCCA builds on extensive typological work and supports rapid annotation. The tutorial will provide a detailed introduction to the UCCA annotation guidelines, design philosophy and the available resources; and a comparison to other meaning representations. It will also survey the existing parsing work, including the findings of three recent shared tasks, in SemEval and CoNLL, that addressed UCCA parsing. Finally, the tutorial will present recent applications and extensions to the scheme, demonstrating its value for natural language processing in a range of languages and domains.</abstract>
      <url hash="687393cd">2020.coling-tutorials.1</url>
    </paper>
    <paper id="2">
      <title>Embeddings in Natural Language Processing</title>
      <author><first>Jose</first><last>Camacho-Collados</last></author>
      <author><first>Mohammad Taher</first><last>Pilehvar</last></author>
      <pages>10–15</pages>
      <abstract>Embeddings have been one of the most important topics of interest in NLP for the past decade. Representing knowledge through a low-dimensional vector which is easily integrable in modern machine learning models has played a central role in the development of the field. Embedding techniques initially focused on words but the attention soon started to shift to other forms. This tutorial will provide a high-level synthesis of the main embedding techniques in NLP, in the broad sense. We will start by conventional word embeddings (e.g., Word2Vec and GloVe) and then move to other types of embeddings, such as sense-specific and graph alternatives. We will finalize with an overview of the trending contextualized representations (e.g., ELMo and BERT) and explain their potential and impact in NLP.</abstract>
      <url hash="a4d7b4f2">2020.coling-tutorials.2</url>
    </paper>
    <paper id="3">
      <title>Multilingual Neural Machine Translation</title>
      <author><first>Raj</first><last>Dabre</last></author>
      <author><first>Chenhui</first><last>Chu</last></author>
      <author><first>Anoop</first><last>Kunchukuttan</last></author>
      <pages>16–21</pages>
      <abstract>The advent of neural machine translation (NMT) has opened up exciting research in building multilingual translation systems i.e. translation models that can handle more than one language pair. Many advances have been made which have enabled (1) improving translation for low-resource languages via transfer learning from high resource languages; and (2) building compact translation models spanning multiple languages. In this tutorial, we will cover the latest advances in NMT approaches that leverage multilingualism, especially to enhance low-resource translation. In particular, we will focus on the following topics: modeling parameter sharing for multi-way models, massively multilingual models, training protocols, language divergence, transfer learning, zero-shot/zero-resource learning, pivoting, multilingual pre-training and multi-source translation.</abstract>
      <url hash="96fc7373">2020.coling-tutorials.3</url>
    </paper>
    <paper id="4">
      <title>Detection and Resolution of Rumors and Misinformation with <fixed-case>NLP</fixed-case></title>
      <author><first>Leon</first><last>Derczynski</last></author>
      <author><first>Arkaitz</first><last>Zubiaga</last></author>
      <pages>22–26</pages>
      <abstract>Detecting and grounding false and misleading claims on the web has grown to form a substantial sub-field of NLP. The sub-field addresses problems at multiple different levels of misinformation detection: identifying check-worthy claims; tracking claims and rumors; rumor collection and annotation; grounding claims against knowledge bases; using stance to verify claims; and applying style analysis to detect deception. This half-day tutorial presents the theory behind each of these steps as well as the state-of-the-art solutions.</abstract>
      <url hash="5f13312a">2020.coling-tutorials.4</url>
    </paper>
    <paper id="5">
      <title>A guide to the dataset explosion in <fixed-case>QA</fixed-case>, <fixed-case>NLI</fixed-case>, and commonsense reasoning</title>
      <author><first>Anna</first><last>Rogers</last></author>
      <author><first>Anna</first><last>Rumshisky</last></author>
      <pages>27–32</pages>
      <abstract>Question answering, natural language inference and commonsense reasoning are increasingly popular as general NLP system benchmarks, driving both modeling and dataset work. Only for question answering we already have over 100 datasets, with over 40 published after 2018. However, most new datasets get “solved” soon after publication, and this is largely due not to the verbal reasoning capabilities of our models, but to annotation artifacts and shallow cues in the data that they can exploit. This tutorial aims to (1) provide an up-to-date guide to the recent datasets, (2) survey the old and new methodological issues with dataset construction, and (3) outline the existing proposals for overcoming them. The target audience is the NLP practitioners who are lost in dozens of the recent datasets, and would like to know what these datasets are actually measuring. Our overview of the problems with the current datasets and the latest tips and tricks for overcoming them will also be useful to the researchers working on future benchmarks.</abstract>
      <url hash="393c1f5e">2020.coling-tutorials.5</url>
    </paper>
    <paper id="6">
      <title>A Crash Course in Automatic Grammatical Error Correction</title>
      <author><first>Roman</first><last>Grundkiewicz</last></author>
      <author><first>Christopher</first><last>Bryant</last></author>
      <author><first>Mariano</first><last>Felice</last></author>
      <pages>33–38</pages>
      <abstract>Grammatical Error Correction (GEC) is the task of automatically detecting and correcting all types of errors in written text. Although most research has focused on correcting errors in the context of English as a Second Language (ESL), GEC can also be applied to other languages and native text. The main application of a GEC system is thus to assist humans with their writing. Academic and commercial interest in GEC has grown significantly since the Helping Our Own (HOO) and Conference on Natural Language Learning (CoNLL) shared tasks in 2011-14, and a record-breaking 24 teams took part in the recent Building Educational Applications (BEA) shared task. Given this interest, and the recent shift towards neural approaches, we believe the time is right to offer a tutorial on GEC for researchers who may be new to the field or who are interested in the current state of the art and future challenges. With this in mind, the main goal of this tutorial is not only to bring attendees up to speed with GEC in general, but also examine the development of neural-based GEC systems.</abstract>
      <url hash="efadd770">2020.coling-tutorials.6</url>
    </paper>
    <paper id="7">
      <title>Endangered Languages meet <fixed-case>M</fixed-case>odern <fixed-case>NLP</fixed-case></title>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <author><first>Christopher</first><last>Cox</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Hilaria</first><last>Cruz</last></author>
      <pages>39–45</pages>
      <abstract>This tutorial will focus on NLP for endangered languages documentation and revitalization. First, we will acquaint the attendees with the process and the challenges of language documentation, showing how the needs of the language communities and the documentary linguists map to specific NLP tasks. We will then present the state-of-the-art in NLP applied in this particularly challenging setting (extremely low-resource datasets, noisy transcriptions, limited annotations, non-standard orthographies). In doing so, we will also analyze the challenges of working in this domain and expand on both the capabilities and the limitations of current NLP approaches. Our ultimate goal is to motivate more NLP practitioners to work towards this very important direction, and also provide them with the tools and understanding of the limitations/challenges, both of which are needed in order to have an impact.</abstract>
      <url hash="0305a57d">2020.coling-tutorials.7</url>
    </paper>
  </volume>
  <volume id="industry" ingest-date="2020-11-29">
    <meta>
      <booktitle>Proceedings of the 28th International Conference on Computational Linguistics: Industry Track</booktitle>
      <editor><first>Ann</first><last>Clifton</last></editor>
      <editor><first>Courtney</first><last>Napoles</last></editor>
      <publisher>International Committee on Computational Linguistics</publisher>
      <address>Online</address>
      <month>December</month>
      <year>2020</year>
    </meta>
    <frontmatter>
      <url hash="397be4de">2020.coling-industry.0</url>
    </frontmatter>
    <paper id="1">
      <title>Evaluating Cross-Lingual Transfer Learning Approaches in Multilingual Conversational Agent Models</title>
      <author><first>Lizhen</first><last>Tan</last></author>
      <author><first>Olga</first><last>Golovneva</last></author>
      <pages>1–9</pages>
      <abstract>With the recent explosion in popularity of voice assistant devices, there is a growing interest in making them available to user populations in additional countries and languages. However, to provide the highest accuracy and best performance for specific user populations, most existing voice assistant models are developed individually for each region or language, which requires linear investment of effort. In this paper, we propose a general multilingual model framework for Natural Language Understanding (NLU) models, which can help bootstrap new language models faster and reduce the amount of effort required to develop each language separately. We explore how different deep learning architectures affect multilingual NLU model performance. Our experimental results show that these multilingual models can reach same or better performance compared to monolingual models across language-specific test data while require less effort in creating features and model maintenance.</abstract>
      <url hash="856b499f">2020.coling-industry.1</url>
    </paper>
    <paper id="2">
      <title>Data-Efficient Paraphrase Generation to Bootstrap Intent Classification and Slot Labeling for New Features in Task-Oriented Dialog Systems</title>
      <author><first>Shailza</first><last>Jolly</last></author>
      <author><first>Tobias</first><last>Falke</last></author>
      <author><first>Caglar</first><last>Tirkaz</last></author>
      <author><first>Daniil</first><last>Sorokin</last></author>
      <pages>10–20</pages>
      <abstract>Recent progress through advanced neural models pushed the performance of task-oriented dialog systems to almost perfect accuracy on existing benchmark datasets for intent classification and slot labeling. However, in evolving real-world dialog systems, where new functionality is regularly added, a major additional challenge is the lack of annotated training data for such new functionality, as the necessary data collection efforts are laborious and time-consuming. A potential solution to reduce the effort is to augment initial seed data by paraphrasing existing utterances automatically. In this paper, we propose a new, data-efficient approach following this idea. Using an interpretation-to-text model for paraphrase generation, we are able to rely on existing dialog system training data, and, in combination with shuffling-based sampling techniques, we can obtain diverse and novel paraphrases from small amounts of seed data. In experiments on a public dataset and with a real-world dialog system, we observe improvements for both intent classification and slot labeling, demonstrating the usefulness of our approach.</abstract>
      <url hash="1084a9e2">2020.coling-industry.2</url>
    </paper>
    <paper id="3">
      <title>Leveraging User Paraphrasing Behavior In Dialog Systems To Automatically Collect Annotations For Long-Tail Utterances</title>
      <author><first>Tobias</first><last>Falke</last></author>
      <author><first>Markus</first><last>Boese</last></author>
      <author><first>Daniil</first><last>Sorokin</last></author>
      <author><first>Caglar</first><last>Tirkaz</last></author>
      <author><first>Patrick</first><last>Lehnen</last></author>
      <pages>21–32</pages>
      <abstract>In large-scale commercial dialog systems, users express the same request in a wide variety of alternative ways with a long tail of less frequent alternatives. Handling the full range of this distribution is challenging, in particular when relying on manual annotations. However, the same users also provide useful implicit feedback as they often paraphrase an utterance if the dialog system failed to understand it. We propose MARUPA, a method to leverage this type of feedback by creating annotated training examples from it. MARUPA creates new data in a fully automatic way, without manual intervention or effort from annotators, and specifically for currently failing utterances. By re-training the dialog system on this new data, accuracy and coverage for long-tail utterances can be improved. In experiments, we study the effectiveness of this approach in a commercial dialog system across various domains and three languages.</abstract>
      <url hash="c621a40b">2020.coling-industry.3</url>
    </paper>
    <paper id="4">
      <title>Query Distillation: <fixed-case>BERT</fixed-case>-based Distillation for Ensemble Ranking</title>
      <author><first>Wangshu</first><last>Zhang</last></author>
      <author><first>Junhong</first><last>Liu</last></author>
      <author><first>Zujie</first><last>Wen</last></author>
      <author><first>Yafang</first><last>Wang</last></author>
      <author><first>Gerard</first><last>de Melo</last></author>
      <pages>33–43</pages>
      <abstract>Recent years have witnessed substantial progress in the development of neural ranking networks, but also an increasingly heavy computational burden due to growing numbers of parameters and the adoption of model ensembles. Knowledge Distillation (KD) is a common solution to balance the effectiveness and efficiency. However, it is not straightforward to apply KD to ranking problems. Ranking Distillation (RD) has been proposed to address this issue, but only shows effectiveness on recommendation tasks. We present a novel two-stage distillation method for ranking problems that allows a smaller student model to be trained while benefitting from the better performance of the teacher model, providing better control of the inference latency and computational burden. We design a novel BERT-based ranking model structure for list-wise ranking to serve as our student model. All ranking candidates are fed to the BERT model simultaneously, such that the self-attention mechanism can enable joint inference to rank the document list. Our experiments confirm the advantages of our method, not just with regard to the inference latency but also in terms of higher-quality rankings compared to the original teacher model.</abstract>
      <url hash="844b65d2">2020.coling-industry.4</url>
    </paper>
    <paper id="5">
      <title>Semantic Diversity for Natural Language Understanding Evaluation in Dialog Systems</title>
      <author><first>Enrico</first><last>Palumbo</last></author>
      <author><first>Andrea</first><last>Mezzalira</last></author>
      <author><first>Cristina</first><last>Marco</last></author>
      <author><first>Alessandro</first><last>Manzotti</last></author>
      <author><first>Daniele</first><last>Amberti</last></author>
      <pages>44–49</pages>
      <abstract>The quality of Natural Language Understanding (NLU) models is typically evaluated using aggregated metrics on a large number of utterances. In a dialog system, though, the manual analysis of failures on specific utterances is a time-consuming and yet critical endeavor to guarantee a high-quality customer experience. A crucial question for this analysis is how to create a test set of utterances that covers a diversity of possible customer requests. In this paper, we introduce the task of generating a test set with high semantic diversity for NLU evaluation in dialog systems and we describe an approach to address it. The approach starts by extracting high-traffic utterance patterns. Then, for each pattern, it achieves high diversity selecting utterances from different regions of the utterance embedding space. We compare three selection strategies based on clustering of utterances in the embedding space, on solving the maximum distance optimization problem and on simple heuristics such as random uniform sampling and popularity. The evaluation shows that the highest semantic and lexicon diversity is obtained by a greedy maximum sum of distance solver in a comparable runtime with the clustering and the heuristics approaches.</abstract>
      <url hash="508d0d52">2020.coling-industry.5</url>
    </paper>
    <paper id="6">
      <title>An Empirical Study on Multi-Task Learning for Text Style Transfer and Paraphrase Generation</title>
      <author><first>Pawel</first><last>Bujnowski</last></author>
      <author><first>Kseniia</first><last>Ryzhova</last></author>
      <author><first>Hyungtak</first><last>Choi</last></author>
      <author><first>Katarzyna</first><last>Witkowska</last></author>
      <author><first>Jaroslaw</first><last>Piersa</last></author>
      <author><first>Tymoteusz</first><last>Krumholc</last></author>
      <author><first>Katarzyna</first><last>Beksa</last></author>
      <pages>50–63</pages>
      <abstract>The topic of this paper is neural multi-task training for text style transfer. We present an efficient method for neutral-to-style transformation using the transformer framework. We demonstrate how to prepare a robust model utilizing large paraphrases corpora together with a small parallel style transfer corpus. We study how much style transfer data is needed for a model on the example of two transformations: neutral-to-cute on internal corpus and modern-to-antique on publicly available Bible corpora. Additionally, we propose a synthetic measure for the automatic evaluation of style transfer models. We hope our research is a step towards replacing common but limited rule-based style transfer systems by more flexible machine learning models for both public and commercial usage.</abstract>
      <url hash="97ef6979">2020.coling-industry.6</url>
    </paper>
    <paper id="7">
      <title>Best Practices for Data-Efficient Modeling in <fixed-case>NLG</fixed-case>:How to Train Production-Ready Neural Models with Less Data</title>
      <author><first>Ankit</first><last>Arun</last></author>
      <author><first>Soumya</first><last>Batra</last></author>
      <author><first>Vikas</first><last>Bhardwaj</last></author>
      <author><first>Ashwini</first><last>Challa</last></author>
      <author><first>Pinar</first><last>Donmez</last></author>
      <author><first>Peyman</first><last>Heidari</last></author>
      <author><first>Hakan</first><last>Inan</last></author>
      <author><first>Shashank</first><last>Jain</last></author>
      <author><first>Anuj</first><last>Kumar</last></author>
      <author><first>Shawn</first><last>Mei</last></author>
      <author><first>Karthik</first><last>Mohan</last></author>
      <author><first>Michael</first><last>White</last></author>
      <pages>64–77</pages>
      <abstract>Natural language generation (NLG) is a critical component in conversational systems, owing to its role of formulating a correct and natural text response. Traditionally, NLG components have been deployed using template-based solutions. Although neural network solutions recently developed in the research community have been shown to provide several benefits, deployment of such model-based solutions has been challenging due to high latency, correctness issues, and high data needs. In this paper, we present approaches that have helped us deploy data-efficient neural solutions for NLG in conversational systems to production. We describe a family of sampling and modeling techniques to attain production quality with light-weight neural network models using only a fraction of the data that would be necessary otherwise, and show a thorough comparison between each. Our results show that domain complexity dictates the appropriate approach to achieve high data efficiency. Finally, we distill the lessons from our experimental findings into a list of best practices for production-level NLG model development, and present them in a brief runbook. Importantly, the end products of all of the techniques are small sequence-to-sequence models (~2Mb) that we can reliably deploy in production. These models achieve the same quality as large pretrained models (~1Gb) as judged by human raters.</abstract>
      <url hash="79e6b2fa">2020.coling-industry.7</url>
    </paper>
    <paper id="8">
      <title>Interactive Question Clarification in Dialogue via Reinforcement Learning</title>
      <author><first>Xiang</first><last>Hu</last></author>
      <author><first>Zujie</first><last>Wen</last></author>
      <author><first>Yafang</first><last>Wang</last></author>
      <author><first>Xiaolong</first><last>Li</last></author>
      <author><first>Gerard</first><last>de Melo</last></author>
      <pages>78–89</pages>
      <abstract>Coping with ambiguous questions has been a perennial problem in real-world dialogue systems. Although clarification by asking questions is a common form of human interaction, it is hard to define appropriate questions to elicit more specific intents from a user. In this work, we propose a reinforcement model to clarify ambiguous questions by suggesting refinements of the original query. We first formulate a collection partitioning problem to select a set of labels enabling us to distinguish potential unambiguous intents. We list the chosen labels as intent phrases to the user for further confirmation. The selected label along with the original user query then serves as a refined query, for which a suitable response can more easily be identified. The model is trained using reinforcement learning with a deep policy network. We evaluate our model based on real-world user clicks and demonstrate significant improvements across several different experiments.</abstract>
      <url hash="a9390190">2020.coling-industry.8</url>
    </paper>
    <paper id="9">
      <title>Towards building a Robust Industry-scale Question Answering System</title>
      <author><first>Rishav</first><last>Chakravarti</last></author>
      <author><first>Anthony</first><last>Ferritto</last></author>
      <author><first>Bhavani</first><last>Iyer</last></author>
      <author><first>Lin</first><last>Pan</last></author>
      <author><first>Radu</first><last>Florian</last></author>
      <author><first>Salim</first><last>Roukos</last></author>
      <author><first>Avi</first><last>Sil</last></author>
      <pages>90–101</pages>
      <abstract>Industry-scale NLP systems necessitate two features. 1. Robustness: “zero-shot transfer learning” (ZSTL) performance has to be commendable and 2. Efficiency: systems have to train efficiently and respond instantaneously. In this paper, we introduce the development of a production model called GAAMA (Go Ahead Ask Me Anything) which possess the above two characteristics. For robustness, it trains on the recently introduced Natural Questions (NQ) dataset. NQ poses additional challenges over older datasets like SQuAD: (a) QA systems need to read and comprehend an entire Wikipedia article rather than a small passage, and (b) NQ does not suffer from observation bias during construction, resulting in less lexical overlap between the question and the article. GAAMA consists of Attention-over-Attention, diversity among attention heads, hierarchical transfer learning, and synthetic data augmentation while being computationally inexpensive. Building on top of the powerful BERTQA model, GAAMA provides a ∼2.0% absolute boost in F1 over the industry-scale state-of-the-art (SOTA) system on NQ. Further, we show that GAAMA transfers zero-shot to unseen real life and important domains as it yields respectable performance on two benchmarks: the BioASQ and the newly introduced CovidQA datasets.</abstract>
      <url hash="53c12c0e">2020.coling-industry.9</url>
    </paper>
    <paper id="10">
      <title>Delexicalized Paraphrase Generation</title>
      <author><first>Boya</first><last>Yu</last></author>
      <author><first>Konstantine</first><last>Arkoudas</last></author>
      <author><first>Wael</first><last>Hamza</last></author>
      <pages>102–112</pages>
      <abstract>We present a neural model for paraphrasing and train it to generate delexicalized sentences. We achieve this by creating training data in which each input is paired with a number of reference paraphrases. These sets of reference paraphrases represent a weak type of semantic equivalence based on annotated slots and intents. To understand semantics from different types of slots, other than anonymizing slots, we apply convolutional neural networks (CNN) prior to pooling on slot values and use pointers to locate slots in the output. We show empirically that the generated paraphrases are of high quality, leading to an additional 1.29% exact match on live utterances. We also show that natural language understanding (NLU) tasks, such as intent classification and named entity recognition, can benefit from data augmentation using automatically generated paraphrases.</abstract>
      <url hash="301e068f">2020.coling-industry.10</url>
    </paper>
    <paper id="11">
      <title>Multi-task Learning of Spoken Language Understanding by Integrating N-Best Hypotheses with Hierarchical Attention</title>
      <author><first>Mingda</first><last>Li</last></author>
      <author><first>Xinyue</first><last>Liu</last></author>
      <author><first>Weitong</first><last>Ruan</last></author>
      <author><first>Luca</first><last>Soldaini</last></author>
      <author><first>Wael</first><last>Hamza</last></author>
      <author><first>Chengwei</first><last>Su</last></author>
      <pages>113–123</pages>
      <abstract>Currently, in spoken language understanding (SLU) systems, the automatic speech recognition (ASR) module produces multiple interpretations (or hypotheses) for the input audio signal and the natural language understanding (NLU) module takes the one with the highest confidence score for domain or intent classification. However, the interpretations can be noisy, and solely relying on one interpretation can cause information loss. To address the problem, many research works attempt to rerank the interpretations for a better choice while some recent works get better performance by integrating all the hypotheses during prediction. In this paper, we follow the way of integrating hypotheses but strengthen the training mode by involving more tasks, some of which may be not in existing tasks of NLU but relevant, via multi-task learning or transfer learning. Moreover, we propose the Hierarchical Attention Mechanism (HAM) to further improve the performance with the acoustic-model features like confidence scores, which are ignored in the current hypotheses integration models. The experimental results show that compared to the standard estimation with one hypothesis, the multi-task learning with HAM can improve the domain and intent classification by relatively 19% and 37%, which are much higher than improvements with current integration or reranking methods. To illustrate the cause of improvements brought by our model, we decode the hidden representations of some utterance examples and compare the generated texts with hypotheses and transcripts. The comparison shows that our model could recover the transcription by integrating the fragmented information among hypotheses and identifying the frequent error patterns of the ASR module, and even rewrite the query for a better understanding, which reveals the characteristic of multi-task learning of broadcasting knowledge.</abstract>
      <url hash="ff965f8d">2020.coling-industry.11</url>
    </paper>
    <paper id="12">
      <title>Misspelling Detection from Noisy Product Images</title>
      <author><first>Varun</first><last>Nagaraj Rao</last></author>
      <author><first>Mingwei</first><last>Shen</last></author>
      <pages>124–135</pages>
      <abstract>Misspellings are introduced on products either due to negligence or as an attempt to deliberately deceive stakeholders. This leads to a revenue loss for online sellers and fosters customer mistrust. Existing spelling research has primarily focused on advancement in misspelling correction and the approach for misspelling detection has remained the use of a large dictionary. The dictionary lookup results in the incorrect detection of several non-dictionary words as misspellings. In this paper, we propose a method to automatically detect misspellings from product images in an attempt to reduce false positive detections. We curate a large scale corpus, define a rich set of features and propose a novel model that leverages importance weighting to account for within class distributional variance. Finally, we experimentally validate this approach on both the curated corpus and an out-of-domain public dataset and show that it leads to a relative improvement of up to 20% in F1 score. The approach thus creates a more robust, generalized deployable solution and reduces reliance on large scale custom dictionaries used today.</abstract>
      <url hash="993f044b">2020.coling-industry.12</url>
    </paper>
    <paper id="13">
      <title>hinglish<fixed-case>N</fixed-case>orm - A Corpus of <fixed-case>H</fixed-case>indi-<fixed-case>E</fixed-case>nglish Code Mixed Sentences for Text Normalization</title>
      <author><first>Piyush</first><last>Makhija</last></author>
      <author><first>Ankit</first><last>Kumar</last></author>
      <author><first>Anuj</first><last>Gupta</last></author>
      <pages>136–145</pages>
      <abstract>We present hinglishNorm - a human annotated corpus of Hindi-English code-mixed sentences for text normalization task. Each sentence in the corpus is aligned to its corresponding human annotated normalized form. To the best of our knowledge, there is no corpus of Hindi-English code-mixed sentences for text normalization task that is publicly available. Our work is the first attempt in this direction. The corpus contains 13494 segments annotated for text normalization. Further, we present baseline normalization results on this corpus. We obtain a Word Error Rate (WER) of 15.55, BiLingual Evaluation Understudy (BLEU) score of 71.2, and Metric for Evaluation of Translation with Explicit ORdering (METEOR) score of 0.50.</abstract>
      <url hash="df813f83">2020.coling-industry.13</url>
    </paper>
    <paper id="14">
      <title>Assessing Social License to Operate from the Public Discourse on Social Media</title>
      <author><first>Chang</first><last>Xu</last></author>
      <author><first>Cecile</first><last>Paris</last></author>
      <author><first>Ross</first><last>Sparks</last></author>
      <author><first>Surya</first><last>Nepal</last></author>
      <author><first>Keith</first><last>VanderLinden</last></author>
      <pages>146–159</pages>
      <abstract>Organisations are monitoring their Social License to Operate (SLO) with increasing regularity. SLO, the level of support organisations gain from the public, is typically assessed through surveys or focus groups, which require expensive manual efforts and yield quickly-outdated results. In this paper, we present SIRTA (Social Insight via Real-Time Text Analytics), a novel real-time text analytics system for assessing and monitoring organisations’ SLO levels by analysing the public discourse from social posts. To assess SLO levels, our insight is to extract and transform peoples’ stances towards an organisation into SLO levels. SIRTA achieves this by performing a chain of three text classification tasks, where it identifies task-relevant social posts, discovers key SLO risks discussed in the posts, and infers stances specific to the SLO risks. We leverage recent language understanding techniques (e.g., BERT) for building our classifiers. To monitor SLO levels over time, SIRTA employs quality control mechanisms to reliably identify SLO trends and variations of multiple organisations in a market. These are derived from the smoothed time series of their SLO levels based on exponentially-weighted moving average (EWMA) calculation. Our experimental results show that SIRTA is highly effective in distilling stances from social posts for SLO level assessment, and that the continuous monitoring of SLO levels afforded by SIRTA enables the early detection of critical SLO changes.</abstract>
      <url hash="f42b01fa">2020.coling-industry.14</url>
    </paper>
    <paper id="15">
      <title>Extreme Model Compression for On-device Natural Language Understanding</title>
      <author><first>Kanthashree</first><last>Mysore Sathyendra</last></author>
      <author><first>Samridhi</first><last>Choudhary</last></author>
      <author><first>Leah</first><last>Nicolich-Henkin</last></author>
      <pages>160–171</pages>
      <abstract>In this paper, we propose and experiment with techniques for extreme compression of neural natural language understanding (NLU) models, making them suitable for execution on resource-constrained devices. We propose a task-aware, end-to-end compression approach that performs word-embedding compression jointly with NLU task learning. We show our results on a large-scale, commercial NLU system trained on a varied set of intents with huge vocabulary sizes. Our approach outperforms a range of baselines and achieves a compression rate of 97.4% with less than 3.7% degradation in predictive performance. Our analysis indicates that the signal from the downstream task is important for effective compression with minimal degradation in performance.</abstract>
      <url hash="dd687f79">2020.coling-industry.15</url>
    </paper>
    <paper id="16">
      <title>Scalable Cross-lingual Treebank Synthesis for Improved Production Dependency Parsers</title>
      <author><first>Yousef</first><last>El-Kurdi</last></author>
      <author><first>Hiroshi</first><last>Kanayama</last></author>
      <author><first>Efsun</first><last>Sarioglu Kayi</last></author>
      <author><first>Vittorio</first><last>Castelli</last></author>
      <author><first>Todd</first><last>Ward</last></author>
      <author><first>Radu</first><last>Florian</last></author>
      <pages>172–178</pages>
      <abstract>We present scalable Universal Dependency (UD) treebank synthesis techniques that exploit advances in language representation modeling which leverage vast amounts of unlabeled general-purpose multilingual text. We introduce a data augmentation technique that uses synthetic treebanks to improve production-grade parsers. The synthetic treebanks are generated using a state-of-the-art biaffine parser adapted with pretrained Transformer models, such as Multilingual BERT (M-BERT). The new parser improves LAS by up to two points on seven languages. The production models’ LAS performance improves as the augmented treebanks scale in size, surpassing performance of production models trained on originally annotated UD treebanks.</abstract>
      <url hash="bb42e85f">2020.coling-industry.16</url>
    </paper>
    <paper id="17">
      <title>An Industry Evaluation of Embedding-based Entity Alignment</title>
      <author><first>Ziheng</first><last>Zhang</last></author>
      <author><first>Hualuo</first><last>Liu</last></author>
      <author><first>Jiaoyan</first><last>Chen</last></author>
      <author><first>Xi</first><last>Chen</last></author>
      <author><first>Bo</first><last>Liu</last></author>
      <author><first>YueJia</first><last>Xiang</last></author>
      <author><first>Yefeng</first><last>Zheng</last></author>
      <pages>179–189</pages>
      <abstract>Embedding-based entity alignment has been widely investigated in recent years, but most proposed methods still rely on an ideal supervised learning setting with a large number of unbiased seed mappings for training and validation, which significantly limits their usage. In this study, we evaluate those state-of-the-art methods in an industrial context, where the impact of seed mappings with different sizes and different biases is explored. Besides the popular benchmarks from DBpedia and Wikidata, we contribute and evaluate a new industrial benchmark that is extracted from two heterogeneous knowledge graphs (KGs) under deployment for medical applications. The experimental results enable the analysis of the advantages and disadvantages of these alignment methods and the further discussion of suitable strategies for their industrial deployment.</abstract>
      <url hash="eefd3552">2020.coling-industry.17</url>
    </paper>
    <paper id="18">
      <title>Learning Domain Terms - Empirical Methods to Enhance Enterprise Text Analytics Performance</title>
      <author><first>Gargi</first><last>Roy</last></author>
      <author><first>Lipika</first><last>Dey</last></author>
      <author><first>Mohammad</first><last>Shakir</last></author>
      <author><first>Tirthankar</first><last>Dasgupta</last></author>
      <pages>190–201</pages>
      <abstract>Performance of standard text analytics algorithms are known to be substantially degraded on consumer generated data, which are often very noisy. These algorithms also do not work well on enterprise data which has a very different nature from News repositories, storybooks or Wikipedia data. Text cleaning is a mandatory step which aims at noise removal and correction to improve performance. However, enterprise data need special cleaning methods since it contains many domain terms which appear to be noise against a standard dictionary, but in reality are not so. In this work we present detailed analysis of characteristics of enterprise data and suggest unsupervised methods for cleaning these repositories after domain terms have been automatically segregated from true noise terms. Noise terms are thereafter corrected in a contextual fashion. The effectiveness of the method is established through careful manual evaluation of error corrections over several standard data sets, including those available for hate speech detection, where there is deliberate distortion to avoid detection. We also share results to show enhancement in classification accuracy after noise correction.</abstract>
      <url hash="51fb6fa3">2020.coling-industry.18</url>
    </paper>
    <paper id="19">
      <title>Model-agnostic Methods for Text Classification with Inherent Noise</title>
      <author><first>Kshitij</first><last>Tayal</last></author>
      <author><first>Rahul</first><last>Ghosh</last></author>
      <author><first>Vipin</first><last>Kumar</last></author>
      <pages>202–213</pages>
      <abstract>Text classification is a fundamental problem, and recently, deep neural networks (DNN) have shown promising results in many natural language tasks. However, their human-level performance relies on high-quality annotations, which are time-consuming and expensive to collect. As we move towards large inexpensive datasets, the inherent label noise degrades the generalization of DNN. While most machine learning literature focuses on building complex networks to handle noise, in this work, we evaluate model-agnostic methods to handle inherent noise in large scale text classification that can be easily incorporated into existing machine learning workflows with minimal interruption. Specifically, we conduct a point-by-point comparative study between several noise-robust methods on three datasets encompassing three popular classification models. To our knowledge, this is the first time such a comprehensive study in text classification encircling popular models and model-agnostic loss methods has been conducted. In this study, we describe our learning and demonstrate the application of our approach, which outperformed baselines by up to 10 % in classification accuracy while requiring no network modifications.</abstract>
      <url hash="2d5936ad">2020.coling-industry.19</url>
    </paper>
    <paper id="20">
      <title><fixed-case>S</fixed-case>cope<fixed-case>I</fixed-case>t: Scoping Task Relevant Sentences in Documents</title>
      <author><first>Barun</first><last>Patra</last></author>
      <author><first>Vishwas</first><last>Suryanarayanan</last></author>
      <author><first>Chala</first><last>Fufa</last></author>
      <author><first>Pamela</first><last>Bhattacharya</last></author>
      <author><first>Charles</first><last>Lee</last></author>
      <pages>214–227</pages>
      <abstract>A prominent problem faced by conversational agents working with large documents (Eg: email-based assistants) is the frequent presence of information in the document that is irrelevant to the assistant. This in turn makes it harder for the agent to accurately detect intents, extract entities relevant to those intents and perform the desired action. To address this issue we present a neural model for scoping relevant information for the agent from a large document. We show that when used as the first step in a popularly used email-based assistant for helping users schedule meetings, our proposed model helps improve the performance of the intent detection and entity extraction tasks required by the agent for correctly scheduling meetings: across a suite of 6 downstream tasks, by using our proposed method, we observe an average gain of 35% in precision without any drop in recall. Additionally, we demonstrate that the same approach can be used for component level analysis in large documents, such as signature block identification.</abstract>
      <url hash="d262d9a1">2020.coling-industry.20</url>
    </paper>
    <paper id="21">
      <title>Uncertainty Modeling for Machine Comprehension Systems using Efficient <fixed-case>B</fixed-case>ayesian Neural Networks</title>
      <author><first>Zhengyuan</first><last>Liu</last></author>
      <author><first>Pavitra</first><last>Krishnaswamy</last></author>
      <author><first>Ai Ti</first><last>Aw</last></author>
      <author><first>Nancy</first><last>Chen</last></author>
      <pages>228–235</pages>
      <abstract>While neural approaches have achieved significant improvement in machine comprehension tasks, models often work as a black-box, resulting in lower interpretability, which requires special attention in domains such as healthcare or education. Quantifying uncertainty helps pave the way towards more interpretable neural networks. In classification and regression tasks, Bayesian neural networks have been effective in estimating model uncertainty. However, inference time increases linearly due to the required sampling process in Bayesian neural networks. Thus speed becomes a bottleneck in tasks with high system complexity such as question-answering or dialogue generation. In this work, we propose a hybrid neural architecture to quantify model uncertainty using Bayesian weight approximation but boosts up the inference speed by 80% relative at test time, and apply it for a clinical dialogue comprehension task. The proposed approach is also used to enable active learning so that an updated model can be trained more optimally with new incoming data by selecting samples that are not well-represented in the current training scheme.</abstract>
      <url hash="3bd8bc98">2020.coling-industry.21</url>
    </paper>
    <paper id="22">
      <title>Regularized Graph Convolutional Networks for Short Text Classification</title>
      <author><first>Kshitij</first><last>Tayal</last></author>
      <author><first>Nikhil</first><last>Rao</last></author>
      <author><first>Saurabh</first><last>Agarwal</last></author>
      <author><first>Xiaowei</first><last>Jia</last></author>
      <author><first>Karthik</first><last>Subbian</last></author>
      <author><first>Vipin</first><last>Kumar</last></author>
      <pages>236–242</pages>
      <abstract>Short text classification is a fundamental problem in natural language processing, social network analysis, and e-commerce. The lack of structure in short text sequences limits the success of popular NLP methods based on deep learning. Simpler methods that rely on bag-of-words representations tend to perform on par with complex deep learning methods. To tackle the limitations of textual features in short text, we propose a Graph-regularized Graph Convolution Network (GR-GCN), which augments graph convolution networks by incorporating label dependencies in the output space. Our model achieves state-of-the-art results on both proprietary and external datasets, outperforming several baseline methods by up to 6% . Furthermore, we show that compared to baseline methods, GR-GCN is more robust to noise in textual features.</abstract>
      <url hash="27be5593">2020.coling-industry.22</url>
    </paper>
  </volume>
</collection>
