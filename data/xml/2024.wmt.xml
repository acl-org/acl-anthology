<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.wmt">
  <volume id="1" ingest-date="2024-11-05" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Ninth Conference on Machine Translation</booktitle>
      <editor><first>Barry</first><last>Haddow</last></editor>
      <editor><first>Tom</first><last>Kocmi</last></editor>
      <editor><first>Philipp</first><last>Koehn</last></editor>
      <editor><first>Christof</first><last>Monz</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Miami, Florida, USA</address>
      <month>November</month>
      <year>2024</year>
      <url hash="3ce11c7c">2024.wmt-1</url>
      <venue>wmt</venue>
      <doi>10.18653/v1/2024.wmt-1</doi>
    </meta>
    <frontmatter>
      <url hash="b3f3605b">2024.wmt-1.0</url>
      <bibkey>wmt-2024-1</bibkey>
      <doi>10.18653/v1/2024.wmt-1.0</doi>
    </frontmatter>
    <paper id="1">
      <title>Findings of the <fixed-case>WMT</fixed-case>24 General Machine Translation Shared Task: The <fixed-case>LLM</fixed-case> Era Is Here but <fixed-case>MT</fixed-case> Is Not Solved Yet</title>
      <author><first>Tom</first><last>Kocmi</last><affiliation>Cohere</affiliation></author>
      <author><first>Eleftherios</first><last>Avramidis</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Rachel</first><last>Bawden</last><affiliation>Inria</affiliation></author>
      <author><first>Ondřej</first><last>Bojar</last><affiliation>Charles University, MFF UFAL</affiliation></author>
      <author><first>Anton</first><last>Dvorkovich</last><affiliation>Yandex</affiliation></author>
      <author><first>Christian</first><last>Federmann</last><affiliation>Microsoft</affiliation></author>
      <author><first>Mark</first><last>Fishel</last><affiliation>University of Tartu</affiliation></author>
      <author><first>Markus</first><last>Freitag</last><affiliation>Google Research</affiliation></author>
      <author><first>Thamme</first><last>Gowda</last><affiliation>Microsoft</affiliation></author>
      <author><first>Roman</first><last>Grundkiewicz</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Barry</first><last>Haddow</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Marzena</first><last>Karpinska</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <author><first>Philipp</first><last>Koehn</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Benjamin</first><last>Marie</last><affiliation>The Kaitchup</affiliation></author>
      <author><first>Christof</first><last>Monz</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Kenton</first><last>Murray</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Masaaki</first><last>Nagata</last><affiliation>NTT Corporation</affiliation></author>
      <author><first>Martin</first><last>Popel</last><affiliation>Charles University, Faculty of Mathematics and Physics, UFAL</affiliation></author>
      <author><first>Maja</first><last>Popović</last><affiliation>ADAPT, Dublin City University</affiliation></author>
      <author><first>Mariya</first><last>Shmatova</last><affiliation>Dubformer</affiliation></author>
      <author><first>Steinthór</first><last>Steingrímsson</last><affiliation>The Árni Magnússon Institute for Icelandic Studies</affiliation></author>
      <author><first>Vilém</first><last>Zouhar</last><affiliation>ETH Zurich, Charles University</affiliation></author>
      <pages>1-46</pages>
      <abstract>This overview paper presents the results of the General Machine Translation Task organised as part of the 2024 Conference on Machine Translation (WMT). In the general MT task, participants were asked to build machine translation systems for any of 11 language pairs, to be evaluated on test sets consisting of three to five different domains. In addition to participating systems, we collected translations from 8 different large language models (LLMs) and 4 online translation providers. We evaluate system outputs with professional human annotators using a new protocol called Error Span Annotations (ESA).</abstract>
      <url hash="9467deaf">2024.wmt-1.1</url>
      <bibkey>kocmi-etal-2024-findings</bibkey>
      <doi>10.18653/v1/2024.wmt-1.1</doi>
    </paper>
    <paper id="2">
      <title>Are <fixed-case>LLM</fixed-case>s Breaking <fixed-case>MT</fixed-case> Metrics? Results of the <fixed-case>WMT</fixed-case>24 Metrics Shared Task</title>
      <author><first>Markus</first><last>Freitag</last><affiliation>Google Research</affiliation></author>
      <author><first>Nitika</first><last>Mathur</last><affiliation>The University of Melbourne</affiliation></author>
      <author><first>Daniel</first><last>Deutsch</last><affiliation>Google</affiliation></author>
      <author><first>Chi-Kiu</first><last>Lo</last><affiliation>National Research Council of Canada</affiliation></author>
      <author><first>Eleftherios</first><last>Avramidis</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Ricardo</first><last>Rei</last><affiliation>Unbabel/INESC-ID</affiliation></author>
      <author><first>Brian</first><last>Thompson</last><affiliation>Amazon</affiliation></author>
      <author><first>Frederic</first><last>Blain</last><affiliation>Tilburg University</affiliation></author>
      <author><first>Tom</first><last>Kocmi</last><affiliation>Cohere</affiliation></author>
      <author><first>Jiayi</first><last>Wang</last><affiliation>University College London</affiliation></author>
      <author><first>David Ifeoluwa</first><last>Adelani</last><affiliation>McGill University / MILA</affiliation></author>
      <author><first>Marianna</first><last>Buchicchio</last><affiliation>Unbabel</affiliation></author>
      <author><first>Chrysoula</first><last>Zerva</last><affiliation>Instituto de Instituto de Telecomunicações, Instituto Superior Técnico, University of Lisbon</affiliation></author>
      <author><first>Alon</first><last>Lavie</last><affiliation>Unbabel/Carnegie Mellon University</affiliation></author>
      <pages>47-81</pages>
      <abstract>The WMT24 Metrics Shared Task evaluated the performance of automatic metrics for machine translation (MT), with a major focus on LLM-based translations that were generated as part of the WMT24 General MT Shared Task. As LLMs become increasingly popular in MT, it is crucial to determine whether existing evaluation metrics can accurately assess the output of these systems.To provide a robust benchmark for this evaluation, human assessments were collected using Multidimensional Quality Metrics (MQM), continuing the practice from recent years. Furthermore, building on the success of the previous year, a challenge set subtask was included, requiring participants to design contrastive test suites that specifically target a metric’s ability to identify and penalize different types of translation errors.Finally, the meta-evaluation procedure was refined to better reflect real-world usage of MT metrics, focusing on pairwise accuracy at both the system- and segment-levels.We present an extensive analysis on how well metrics perform on three language pairs: English to Spanish (Latin America), Japanese to Chinese, and English to German. The results strongly confirm the results reported last year, that fine-tuned neural metrics continue to perform well, even when used to evaluate LLM-based translation systems.</abstract>
      <url hash="fcac57cd">2024.wmt-1.2</url>
      <bibkey>freitag-etal-2024-llms</bibkey>
      <doi>10.18653/v1/2024.wmt-1.2</doi>
    </paper>
    <paper id="3">
      <title>Findings of the Quality Estimation Shared Task at <fixed-case>WMT</fixed-case> 2024: Are <fixed-case>LLM</fixed-case>s Closing the Gap in <fixed-case>QE</fixed-case>?</title>
      <author><first>Chrysoula</first><last>Zerva</last><affiliation>Instituto de Instituto de Telecomunicações, Instituto Superior Técnico, University of Lisbon</affiliation></author>
      <author><first>Frederic</first><last>Blain</last><affiliation>Tilburg University</affiliation></author>
      <author><first>José G.</first><last>C. De Souza</last><affiliation>Unbabel</affiliation></author>
      <author><first>Diptesh</first><last>Kanojia</last><affiliation>University of Surrey</affiliation></author>
      <author><first>Sourabh</first><last>Deoghare</last><affiliation>IIT Bombay</affiliation></author>
      <author><first>Nuno M.</first><last>Guerreiro</last><affiliation>Instituto de Telecomunicacoes, University of Lisbon</affiliation></author>
      <author><first>Giuseppe</first><last>Attanasio</last><affiliation>Instituto de Telecomunicacoes</affiliation></author>
      <author><first>Ricardo</first><last>Rei</last><affiliation>Unbabel/INESC-ID</affiliation></author>
      <author><first>Constantin</first><last>Orasan</last><affiliation>University of Surrey</affiliation></author>
      <author><first>Matteo</first><last>Negri</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Marco</first><last>Turchi</last><affiliation>Zoom Video Communications</affiliation></author>
      <author><first>Rajen</first><last>Chatterjee</last><affiliation>Apple Inc.</affiliation></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last><affiliation>Indian Institute of Technology Bombay and Patna</affiliation></author>
      <author><first>Markus</first><last>Freitag</last><affiliation>Google Research</affiliation></author>
      <author><first>André</first><last>Martins</last><affiliation>Unbabel, Instituto de Telecomunicacoes</affiliation></author>
      <pages>82-109</pages>
      <abstract>We report the results of the WMT 2024 shared task on Quality Estimation, in which the challenge is to predict the quality of the output of neural machine translation systems at the word and sentence levels, without access to reference translations. In this edition, we expanded our scope to assess the potential for quality estimates to help in the correction of translated outputs, hence including an automated post-editing (APE) direction. We publish new test sets with human annotations that target two directions: providing new Multidimensional Quality Metrics (MQM) annotations for three multi-domain language pairs (English to German, Spanish and Hindi) and extending the annotations on Indic languages providing direct assessments and post edits for translation from English into Hindi, Gujarati, Tamil and Telugu. We also perform a detailed analysis of the behaviour of different models with respect to different phenomena including gender bias, idiomatic language, and numerical and entity perturbations. We received submissions based both on traditional, encoder-based approaches as well as large language model (LLM) based ones.</abstract>
      <url hash="35fc381e">2024.wmt-1.3</url>
      <bibkey>zerva-etal-2024-findings</bibkey>
      <doi>10.18653/v1/2024.wmt-1.3</doi>
    </paper>
    <paper id="4">
      <title>Findings of the <fixed-case>WMT</fixed-case> 2024 Shared Task of the Open Language Data Initiative</title>
      <author><first>Jean</first><last>Maillard</last><affiliation>Meta AI</affiliation></author>
      <author><first>Laurie</first><last>Burchell</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Antonios</first><last>Anastasopoulos</last><affiliation>George Mason University</affiliation></author>
      <author><first>Christian</first><last>Federmann</last><affiliation>Microsoft</affiliation></author>
      <author><first>Philipp</first><last>Koehn</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Skyler</first><last>Wang</last><affiliation>FAIR, Meta</affiliation></author>
      <pages>110-117</pages>
      <abstract>We present the results of the WMT 2024 shared task of the Open Language Data Initiative. Participants were invited to contribute to the FLORES+ and MT Seed multilingual datasets, two foundational open resources that facilitate the organic expansion of language technology’s reach. We accepted ten submissions covering 16 languages, which extended the range of languages included in the datasets and improved the quality of existing data.</abstract>
      <url hash="fb5520d0">2024.wmt-1.4</url>
      <bibkey>maillard-etal-2024-findings</bibkey>
      <doi>10.18653/v1/2024.wmt-1.4</doi>
    </paper>
    <paper id="5">
      <title>Results of the <fixed-case>WAT</fixed-case>/<fixed-case>WMT</fixed-case> 2024 Shared Task on Patent Translation</title>
      <author><first>Shohei</first><last>Higashiyama</last><affiliation>National Institute of Information and Communications Technology</affiliation></author>
      <pages>118-123</pages>
      <abstract>This paper presents the results of the patent translation shared task at the 11th Workshop on Asian Translation and 9th Conference on Machine Translation. Two teams participated in this task, and their submitted translation results for one or more of the six language directions were automatically and manually evaluated. The evaluation results demonstrate the strong performance of large language model-based systems from both participants.</abstract>
      <url hash="9e8af8b3">2024.wmt-1.5</url>
      <bibkey>higashiyama-2024-results</bibkey>
      <doi>10.18653/v1/2024.wmt-1.5</doi>
    </paper>
    <paper id="6">
      <title>Findings of the <fixed-case>WMT</fixed-case> 2024 Biomedical Translation Shared Task: Test Sets on Abstract Level</title>
      <author><first>Mariana</first><last>Neves</last><affiliation>German Federal Institute for Risk Assessment</affiliation></author>
      <author><first>Cristian</first><last>Grozea</last><affiliation>Fraunhofer Institute FOKUS</affiliation></author>
      <author><first>Philippe</first><last>Thomas</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Roland</first><last>Roller</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Rachel</first><last>Bawden</last><affiliation>Inria</affiliation></author>
      <author><first>Aurélie</first><last>Névéol</last><affiliation>Université Paris-Saclay, CNRS, LISN</affiliation></author>
      <author><first>Steffen</first><last>Castle</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Vanessa</first><last>Bonato</last><affiliation>Dept. of Linguistic and Literary Studies University of Padua</affiliation></author>
      <author><first>Giorgio Maria</first><last>Di Nunzio</last><affiliation>Dept. of Linguistic and Literary Studies University of Padua</affiliation></author>
      <author><first>Federica</first><last>Vezzani</last><affiliation>Dept. of Linguistic and Literary Studies University of Padua</affiliation></author>
      <author><first>Maika</first><last>Vicente Navarro</last><affiliation>Leica Biosystems</affiliation></author>
      <author><first>Lana</first><last>Yeganova</last><affiliation>NCBI/NLM/NIH</affiliation></author>
      <author><first>Antonio</first><last>Jimeno Yepes</last><affiliation>RMIT University</affiliation></author>
      <pages>124-138</pages>
      <abstract>We present the results of the ninth edition of the Biomedical Translation Task at WMT’24. We released test sets for six language pairs, namely, French, German, Italian, Portuguese, Russian, and Spanish, from and into English. Eachtest set consists of 50 abstracts from PubMed. Differently from previous years, we did not split abstracts into sentences. We received submissions from five teams, and for almost all language directions. We used a baseline/comparison system based on Llama 3.1 and share the source code at https://github.com/cgrozea/wmt24biomed-ref.</abstract>
      <url hash="8fea0ae5">2024.wmt-1.6</url>
      <bibkey>neves-etal-2024-findings</bibkey>
      <doi>10.18653/v1/2024.wmt-1.6</doi>
    </paper>
    <paper id="7">
      <title><fixed-case>MSLC</fixed-case>24 Submissions to the General Machine Translation Task</title>
      <author><first>Samuel</first><last>Larkin</last><affiliation>National Research Council Canada</affiliation></author>
      <author><first>Chi-Kiu</first><last>Lo</last><affiliation>National Research Council of Canada</affiliation></author>
      <author><first>Rebecca</first><last>Knowles</last><affiliation>National Research Council Canada</affiliation></author>
      <pages>139-146</pages>
      <abstract>The MSLC (Metric Score Landscape Challenge) submissions for English-German, English-Spanish, and Japanese-Chinese are constrained systems built using Transformer models for the purpose of better evaluating metric performance in the WMT24 Metrics Task. They are intended to be representative of the performance of systems that can be built relatively simply using constrained data and with minimal modifications to the translation training pipeline.</abstract>
      <url hash="f6313103">2024.wmt-1.7</url>
      <bibkey>larkin-etal-2024-mslc24</bibkey>
      <doi>10.18653/v1/2024.wmt-1.7</doi>
    </paper>
    <paper id="8">
      <title><fixed-case>IOL</fixed-case> Research Machine Translation Systems for <fixed-case>WMT</fixed-case>24 General Machine Translation Shared Task</title>
      <author><first>Wenbo</first><last>Zhang</last><affiliation>Transn</affiliation></author>
      <pages>147-154</pages>
      <abstract>This paper illustrates the submission system of the IOL Research team for the WMT24 General Machine Translation shared task. We submitted translations for all translation directions in the general machine translation task. According to the official track categorization, our system qualifies as an open system due to the utilization of open-source resources in developing our machine translation model. With the growing prevalence of large language models (LLMs) as a conventional approach for managing diverse NLP tasks, we have developed our machine translation system by leveraging the capabilities of LLMs. Overall, we first performed continued pretraining using the open-source LLMs with tens of billions of parameters to enhance the model’s multilingual capabilities. Subsequently, we employed open-source Large Language Models, equipped with hundreds of billions of parameters, to generate synthetic data. This data was then blended with a modest quantity of additional open-source data for precise supervised fine-tuning. In the final stage, we also used ensemble learning to improve translation quality. Based on the official automated evaluation metrics, our system excelled by securing the top position in 8 out of the total 11 translation directions, spanning both open and constrained system categories.</abstract>
      <url hash="e1c0a8bc">2024.wmt-1.8</url>
      <bibkey>zhang-2024-iol</bibkey>
      <doi>10.18653/v1/2024.wmt-1.8</doi>
    </paper>
    <paper id="9">
      <title>Choose the Final Translation from <fixed-case>NMT</fixed-case> and <fixed-case>LLM</fixed-case> Hypotheses Using <fixed-case>MBR</fixed-case> Decoding: <fixed-case>HW</fixed-case>-<fixed-case>TSC</fixed-case>’s Submission to the <fixed-case>WMT</fixed-case>24 General <fixed-case>MT</fixed-case> Shared Task</title>
      <author><first>Zhanglin</first><last>Wu</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Daimeng</first><last>Wei</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Zongyao</first><last>Li</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Hengchao</first><last>Shang</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Jiaxin</first><last>Guo</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Shaojun</first><last>Li</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Zhiqiang</first><last>Rao</last><affiliation>Huawei Translation Service Center, Beijing, China</affiliation></author>
      <author><first>Yuanchang</first><last>Luo</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Ning</first><last>Xie</last><affiliation>HuaweiTechnologiesCo.,Ltd.</affiliation></author>
      <author><first>Hao</first><last>Yang</last><affiliation>Huawei Co. Ltd</affiliation></author>
      <pages>155-164</pages>
      <abstract>This paper presents the submission of Huawei Translate Services Center (HW-TSC) to the WMT24 general machine translation (MT) shared task, where we participate in the English to Chinese (en→zh) language pair. Similar to previous years’ work, we use training strategies such as regularized dropout, bidirectional training, data diversification, forward translation, back translation, alternated training, curriculum learning, and transductive ensemble learning to train the neural machine translation (NMT) model based on the deep Transformer-big architecture. The difference is that we also use continue pre-training, supervised fine-tuning, and contrastive preference optimization to train the large language model (LLM) based MT model. By using Minimum Bayesian risk (MBR) decoding to select the final translation from multiple hypotheses for NMT and LLM-based MT models, our submission receives competitive results in the final evaluation.</abstract>
      <url hash="a75f7339">2024.wmt-1.9</url>
      <bibkey>wu-etal-2024-choose</bibkey>
      <doi>10.18653/v1/2024.wmt-1.9</doi>
    </paper>
    <paper id="10">
      <title><fixed-case>C</fixed-case>ycle<fixed-case>GN</fixed-case>: A Cycle Consistent Approach for Neural Machine Translation</title>
      <author><first>Sören</first><last>Dreano</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Derek</first><last>Molloy</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Noel</first><last>Murphy</last><affiliation>Dublin City University</affiliation></author>
      <pages>165-175</pages>
      <abstract>CycleGN is a fully self-supervised Neural Machine Translation framework relying on the Transformer architecture that does not require parallel data. Its approach is similar to a Discriminator-less CycleGAN, hence the “non-adversarial” name, specifically tailored for non-parallel text datasets. The foundational concept of our research posits that in an ideal scenario, retro-translations of generated translations should revert to the original source sentences. Consequently, a pair of models can be trained using a Cycle Consistency Loss (CCL) only, with one model translating in one direction and the second model in the opposite direction.In the context of this research, two sub-categories of non-parallel datasets are introduced. A “permuted” dataset is defined as a parallel dataset wherein the sentences of one language have been systematically rearranged. Consequently, this results in a non-parallel corpus where it is guaranteed that each sentence has a corresponding translation located at an unspecified index within the dataset. A “non-intersecting” dataset is a non-parallel dataset for which it is guaranteed that no sentence has an exact translation.Masked Language Modeling (MLM) is a pre-training strategy implemented in BERT, where a specified proportion of the input tokens are substituted with a unique $mask$ token. The objective of the neural network under this paradigm is to accurately reconstruct the original sentence from this degraded input.In inference mode, Transformers are able to generate sentences without labels. Thus, the first step is to generate pseudo-labels in inference, that are then used as labels during training. However, the models consistently converge towards a trivial solution in which the input, the generated pseudo-labels and the output are identical, achieving an optimal outcome on the CCL function, registering a value of zero. CycleGN demonstrates how MLM pre-training can be leveraged to move away from this trivial path and perform actual text translation.As a contribution to the WMT24 challenge, this study explores the efficacy of the CycleGN architectural framework in learning translation tasks across eleven language pairs under the permuted condition and four under the non-intersecting condition. Moreover, two additional language pairs from the previous WMT edition were trained and the evaluations demonstrate the robust adaptability of CycleGN in learning translation tasks.</abstract>
      <url hash="9d474aaa">2024.wmt-1.10</url>
      <bibkey>dreano-etal-2024-cyclegn</bibkey>
      <doi>10.18653/v1/2024.wmt-1.10</doi>
    </paper>
    <paper id="11">
      <title><fixed-case>U</fixed-case>v<fixed-case>A</fixed-case>-<fixed-case>MT</fixed-case>’s Participation in the <fixed-case>WMT</fixed-case>24 General Translation Shared Task</title>
      <author><first>Shaomu</first><last>Tan</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>David</first><last>Stap</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Seth</first><last>Aycock</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Christof</first><last>Monz</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Di</first><last>Wu</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>176-184</pages>
      <abstract>Fine-tuning Large Language Models (FT-LLMs) with parallel data has emerged as a promising paradigm in recent machine translation research. In this paper, we explore the effectiveness of FT-LLMs and compare them to traditional encoder-decoder Neural Machine Translation (NMT) systems under the WMT24 general MT shared task for English to Chinese direction. We implement several techniques, including Quality Estimation (QE) data filtering, supervised fine-tuning, and post-editing that integrate NMT systems with LLMs. We demonstrate that fine-tuning LLaMA2 on a high-quality but relatively small bitext dataset (100K) yields COMET results comparable to much smaller encoder-decoder NMT systems trained on over 22 million bitexts. However, this approach largely underperforms on surface-level metrics like BLEU and ChrF. We further control the data quality using the COMET-based quality estimation method. Our experiments show that 1) filtering low COMET scores largely improves encoder-decoder systems, but 2) no clear gains are observed for LLMs when further refining the fine-tuning set. Finally, we show that combining NMT systems with LLMs via post-editing generally yields the best performance for the WMT24 official test set.</abstract>
      <url hash="58324efe">2024.wmt-1.11</url>
      <bibkey>tan-etal-2024-uva</bibkey>
      <doi>10.18653/v1/2024.wmt-1.11</doi>
    </paper>
    <paper id="12">
      <title>Tower v2: Unbabel-<fixed-case>IST</fixed-case> 2024 Submission for the General <fixed-case>MT</fixed-case> Shared Task</title>
      <author><first>Ricardo</first><last>Rei</last><affiliation>Unbabel/INESC-ID</affiliation></author>
      <author><first>Jose</first><last>Pombal</last><affiliation>Unbabel</affiliation></author>
      <author><first>Nuno M.</first><last>Guerreiro</last><affiliation>Instituto de Telecomunicacoes, University of Lisbon</affiliation></author>
      <author><first>João</first><last>Alves</last><affiliation>Unbabel</affiliation></author>
      <author><first>Pedro Henrique</first><last>Martins</last><affiliation>Unbabel</affiliation></author>
      <author><first>Patrick</first><last>Fernandes</last><affiliation>Carnegie Mellon University, Instituto de Telecomunicações</affiliation></author>
      <author><first>Helena</first><last>Wu</last><affiliation>University of Lisbon</affiliation></author>
      <author><first>Tania</first><last>Vaz</last><affiliation>Unbabel</affiliation></author>
      <author><first>Duarte</first><last>Alves</last><affiliation>Instituto Superior Técnico / IT</affiliation></author>
      <author><first>Amin</first><last>Farajian</last><affiliation>Unbabel</affiliation></author>
      <author><first>Sweta</first><last>Agrawal</last><affiliation>Instituto de Telecomunicações</affiliation></author>
      <author><first>Antonio</first><last>Farinhas</last><affiliation>Instituto de Telecomunicacoes, IST</affiliation></author>
      <author><first>José G.</first><last>C. De Souza</last><affiliation>Unbabel</affiliation></author>
      <author><first>André</first><last>Martins</last><affiliation>Unbabel, Instituto de Telecomunicacoes</affiliation></author>
      <pages>185-204</pages>
      <abstract>In this work, we present Tower v2, an improved iteration of the state-of-the-art open-weight Tower models, and the backbone of our submission to the WMT24 General Translation shared task. Tower v2 introduces key improvements including expanded language coverage, enhanced data quality, and increased model capacity up to 70B parameters. Our final submission combines these advancements with quality-aware decoding strategies, selecting translations based on multiple translation quality signals. The resulting system demonstrates significant improvement over previous versions, outperforming closed commercial systems like GPT-4o, Claude 3.5, and DeepL even at a smaller 7B scale.</abstract>
      <url hash="f2eaf28b">2024.wmt-1.12</url>
      <bibkey>rei-etal-2024-tower</bibkey>
      <doi>10.18653/v1/2024.wmt-1.12</doi>
    </paper>
    <paper id="13">
      <title><fixed-case>TSU</fixed-case> <fixed-case>HITS</fixed-case>’s Submissions to the <fixed-case>WMT</fixed-case> 2024 General Machine Translation Shared Task</title>
      <author><first>Vladimir</first><last>Mynka</last><affiliation>Higher IT School of Tomsk State University</affiliation></author>
      <author><first>Nikolay</first><last>Mikhaylovskiy</last><affiliation>NTR Labs / Higher IT School of Tomsk State University</affiliation></author>
      <pages>205-209</pages>
      <abstract>This paper describes the TSU HITS team’s submission system for the WMT’24 general translation task. We focused on exploring the capabilities of discrete diffusion models for the English-to-{Russian, German, Czech, Spanish} translation tasks in the constrained track. Our submission system consists of a set of discrete diffusion models for each language pair. The main advance is using a separate length regression model to determine the length of the output sequence more precisely.</abstract>
      <url hash="e353209e">2024.wmt-1.13</url>
      <bibkey>mynka-mikhaylovskiy-2024-tsu</bibkey>
      <doi>10.18653/v1/2024.wmt-1.13</doi>
    </paper>
    <paper id="14">
      <title>Document-level Translation with <fixed-case>LLM</fixed-case> Reranking: Team-<fixed-case>J</fixed-case> at <fixed-case>WMT</fixed-case> 2024 General Translation Task</title>
      <author><first>Keito</first><last>Kudo</last><affiliation>Tohoku University / RIKEN Center for AIP</affiliation></author>
      <author><first>Hiroyuki</first><last>Deguchi</last><affiliation>Nara Institute of Science and Technology</affiliation></author>
      <author><first>Makoto</first><last>Morishita</last><affiliation>Future Corporation</affiliation></author>
      <author><first>Ryo</first><last>Fujii</last><affiliation>Future Corporation</affiliation></author>
      <author><first>Takumi</first><last>Ito</last><affiliation>Langsmith Inc. / Tohoku University</affiliation></author>
      <author><first>Shintaro</first><last>Ozaki</last><affiliation>Nara Institute of Science and Technology</affiliation></author>
      <author><first>Koki</first><last>Natsumi</last><affiliation>NAIST</affiliation></author>
      <author><first>Kai</first><last>Sato</last><affiliation>Tohoku university</affiliation></author>
      <author><first>Kazuki</first><last>Yano</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Ryosuke</first><last>Takahashi</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Subaru</first><last>Kimura</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Tomomasa</first><last>Hara</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Yusuke</first><last>Sakai</last><affiliation>Nara Institute of Science and Technology</affiliation></author>
      <author><first>Jun</first><last>Suzuki</last><affiliation>Tohoku University / RIKEN Center for AIP</affiliation></author>
      <pages>210-226</pages>
      <abstract>We participated in the constrained track for English-Japanese and Japanese-Chinese translations at the WMT 2024 General Machine Translation Task. Our approach was to generate a large number of sentence-level translation candidates and select the most probable translation using minimum Bayes risk (MBR) decoding and document-level large language model (LLM) re-ranking. We first generated hundreds of translation candidates from multiple translation models and retained the top 30 candidates using MBR decoding. In addition, we continually pre-trained LLMs on the target language corpora to leverage document-level information. We utilized LLMs to select the most probable sentence sequentially in context from the beginning of the document.</abstract>
      <url hash="aa7d87b8">2024.wmt-1.14</url>
      <bibkey>kudo-etal-2024-document</bibkey>
      <doi>10.18653/v1/2024.wmt-1.14</doi>
    </paper>
    <paper id="15">
      <title><fixed-case>DLUT</fixed-case> and <fixed-case>GTCOM</fixed-case>’s Neural Machine Translation Systems for <fixed-case>WMT</fixed-case>24</title>
      <author><first>Hao</first><last>Zong</last><affiliation>Global Tone Communication Technology Co., Ltd</affiliation></author>
      <author><first>Chao</first><last>Bei</last><affiliation>Global Tone Communication Technology Co.,Ltd.</affiliation></author>
      <author><first>Huan</first><last>Liu</last><affiliation>Dalian University of Technology</affiliation></author>
      <author><first>Conghu</first><last>Yuan</last><affiliation>Global Tone Communication Technology Co., Ltd</affiliation></author>
      <author><first>Wentao</first><last>Chen</last><affiliation>Global Tone Communication Technology Co., Ltd</affiliation></author>
      <author><first>Degen</first><last>Huang</last><affiliation>Dalian University of Technology</affiliation></author>
      <pages>227-231</pages>
      <abstract>This paper presents the submission from Global Tone Communication Co., Ltd. and Dalian University of Technology for the WMT24 shared general Machine Translation (MT) task at the Conference on Empirical Methods in Natural Language Processing (EMNLP). Our participation encompasses two language pairs: English to Japanese and Japanese to Chinese. The systems are developed without particular constraints or requirements, facilitating extensive research in machine translation. We emphasize back-translation, utilize multilingual translation models, and apply fine-tuning strategies to improve performance. Additionally, we integrate both human-generated and machine-generated data to fine-tune our models, leading to enhanced translation accuracy. The automatic evaluation results indicate that our system ranks first in terms of BLEU score for the Japanese to Chinese translation.</abstract>
      <url hash="05a48a69">2024.wmt-1.15</url>
      <bibkey>zong-etal-2024-dlut</bibkey>
      <doi>10.18653/v1/2024.wmt-1.15</doi>
    </paper>
    <paper id="16">
      <title><fixed-case>CUNI</fixed-case> at <fixed-case>WMT</fixed-case>24 General Translation Task: <fixed-case>LLM</fixed-case>s, (<fixed-case>Q</fixed-case>)<fixed-case>L</fixed-case>o<fixed-case>RA</fixed-case>, <fixed-case>CPO</fixed-case> and Model Merging</title>
      <author><first>Miroslav</first><last>Hrabal</last><affiliation>Charles University</affiliation></author>
      <author><first>Josef</first><last>Jon</last><affiliation>Charles University</affiliation></author>
      <author><first>Martin</first><last>Popel</last><affiliation>Charles University, Faculty of Mathematics and Physics, UFAL</affiliation></author>
      <author><first>Nam</first><last>Luu</last><affiliation>Charles University</affiliation></author>
      <author><first>Danil</first><last>Semin</last><affiliation>MFF UK</affiliation></author>
      <author><first>Ondřej</first><last>Bojar</last><affiliation>Charles University, MFF UFAL</affiliation></author>
      <pages>232-246</pages>
      <abstract>This paper presents the contributions of Charles University teams to the WMT24 General Translation task (English to Czech, German and Russian, and Czech to Ukrainian), and the WMT24 Translation into Low-Resource Languages of Spain task.Our most elaborate submission, CUNI-MH for en2cs, is the result of fine-tuning Mistral 7B v0.1 for translation using a three-stage process: Supervised fine-tuning using QLoRA, Contrastive Preference Optimization, and merging of model checkpoints. We also describe the CUNI-GA, CUNI-Transformer and CUNI-DocTransformer submissions, which are based on our systems from the previous year.Our en2ru system CUNI-DS uses a similar first stage as CUNI-MH (QLoRA for en2cs) and follows with transferring to en2ru.For en2de (CUNI-NL), we experimented with a LLM-based speech translation system, to translate without the speech input.For the Translation into Low-Resource Languages of Spain task, we performed QLoRA fine-tuning of a large LLM on a small amount of synthetic (backtranslated) data.</abstract>
      <url hash="64a7ce85">2024.wmt-1.16</url>
      <bibkey>hrabal-etal-2024-cuni</bibkey>
      <doi>10.18653/v1/2024.wmt-1.16</doi>
    </paper>
    <paper id="17">
      <title>From General <fixed-case>LLM</fixed-case> to Translation: How We Dramatically Improve Translation Quality Using Human Evaluation Data for <fixed-case>LLM</fixed-case> Finetuning</title>
      <author><first>Denis</first><last>Elshin</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Nikolay</first><last>Karpachev</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Boris</first><last>Gruzdev</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Ilya</first><last>Golovanov</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Georgy</first><last>Ivanov</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Alexander</first><last>Antonov</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Nickolay</first><last>Skachkov</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Ekaterina</first><last>Latypova</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Vladimir</first><last>Layner</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Ekaterina</first><last>Enikeeva</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Dmitry</first><last>Popov</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Anton</first><last>Chekashev</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Vladislav</first><last>Negodin</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Vera</first><last>Frantsuzova</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Alexander</first><last>Chernyshev</last><affiliation>Yandex LLC</affiliation></author>
      <author><first>Kirill</first><last>Denisov</last><affiliation>Yandex LLC</affiliation></author>
      <pages>247-252</pages>
      <abstract>In this paper, we present the methodology employed by the NLP team at Yandex LLC for participating in the WMT 2024 General MT Translation track, focusing on English-to-Russian translation. Our approach involves training a YandexGPT LLM-based model for translation tasks using a multi-stage process to ensure high-quality and contextually accurate translations.Initially, we utilize a pre-trained model, trained on a large corpus of high-quality monolingual texts in various languages, crawled from various open sources, not limited to English and Russian. This extensive pre-training allows the model to capture a broad spectrum of linguistic nuances and structures. Following this, the model is fine-tuned on a substantial parallel corpus of high-quality texts collected from diverse open sources, including websites, books, and subtitles. These texts are meticulously aligned at both the sentence and paragraph levels to enhance the model’s contextual understanding and translation accuracy.In the subsequent stage, we employ p-tuning on an internal high-quality corpus of paragraph-aligned data. This step ensures that the model is finely adjusted to handle complex paragraph-level translations with greater fluency and coherence.Next, we apply the Contrastive Pretraining Objective (CPO) method, as described in the paper CPO, using a human-annotated translation corpus. This stage focuses on refining the model’s performance based on metrics evaluated at the paragraph level, emphasizing both the accuracy of the translation and the fluency of the resulting texts. The CPO method helps the model to better distinguish between subtle contextual differences, thereby improving translation quality.In the final stage, we address the importance of preserving the content structure in translations, which is crucial for the General MT test set. To achieve this, we introduce a synthetic corpus based on web pages and video subtitles, and use it during HE markup finetune training. This encourages the model to maintain the original text’s tag structure. This step ensures that the translated output retains the structural integrity of the source web pages, providing a seamless user experience.Our multi-stage approach, combining extensive pre-training, targeted fine-tuning, advanced p-tuning, and structure-preserving techniques, ensures that our model delivers high-quality, fluent, and structurally consistent translations suitable for practical applications and competitive benchmarks.</abstract>
      <url hash="f89a7a66">2024.wmt-1.17</url>
      <bibkey>elshin-etal-2024-general</bibkey>
      <doi>10.18653/v1/2024.wmt-1.17</doi>
    </paper>
    <paper id="18">
      <title>Cogs in a Machine, Doing What They’re Meant to Do – the <fixed-case>AMI</fixed-case> Submission to the <fixed-case>WMT</fixed-case>24 General Translation Task</title>
      <author><first>Atli</first><last>Jasonarson</last><affiliation>The Árni Magnússon Institute</affiliation></author>
      <author><first>Hinrik</first><last>Hafsteinsson</last><affiliation>University of Iceland</affiliation></author>
      <author><first>Bjarki</first><last>Ármannsson</last><affiliation>The Árni Magnússon Institute</affiliation></author>
      <author><first>Steinthór</first><last>Steingrímsson</last><affiliation>The Árni Magnússon Institute for Icelandic Studies</affiliation></author>
      <pages>253-262</pages>
      <abstract>This paper presents the submission of the Arni Magnusson Institute’s team to the WMT24 General translation task. We work on the English→Icelandic translation direction. Our system comprises four translation models and a grammar correction model. For training our systems we carefully curate our datasets, aggressively filtering out sentence pairs that may detrimentally affect the quality of our systems output. Some of our data are collected from human translations and some are synthetically generated. A part of the synthetic data is generated using an LLM, and we find that it increases the translation capability of our system significantly.</abstract>
      <url hash="8da5f4fd">2024.wmt-1.18</url>
      <bibkey>jasonarson-etal-2024-cogs</bibkey>
      <doi>10.18653/v1/2024.wmt-1.18</doi>
    </paper>
    <paper id="19">
      <title><fixed-case>IKUN</fixed-case> for <fixed-case>WMT</fixed-case>24 General <fixed-case>MT</fixed-case> Task: <fixed-case>LLM</fixed-case>s Are Here for Multilingual Machine Translation</title>
      <author><first>Baohao</first><last>Liao</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Christian</first><last>Herold</last><affiliation>eBay Inc.</affiliation></author>
      <author><first>Shahram</first><last>Khadivi</last><affiliation>eBay</affiliation></author>
      <author><first>Christof</first><last>Monz</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>263-269</pages>
      <abstract>This paper introduces two multilingual systems, IKUN and IKUN-C, developed for the general machine translation task in WMT24. IKUN and IKUN-C represent an open system and a constrained system, respectively, built on Llama-3-8b and Mistral-7B-v0.3. Both systems are designed to handle all 11 language directions using a single model. According to automatic evaluation metrics, IKUN-C achieved 6 first-place and 3 second-place finishes among all constrained systems, while IKUN secured 1 first-place and 2 second-place finishes across both open and constrained systems. These encouraging results suggest that large language models (LLMs) are nearing the level of proficiency required for effective multilingual machine translation. The systems are based on a two-stage approach: first, continuous pre-training on monolingual data in 10 languages, followed by fine-tuning on high-quality parallel data for 11 language directions. The primary difference between IKUN and IKUN-C lies in their monolingual pre-training strategy. IKUN-C is pre-trained using constrained monolingual data, whereas IKUN leverages monolingual data from the OSCAR dataset. In the second phase, both systems are fine-tuned on parallel data sourced from NTREX, Flores, and WMT16-23 for all 11 language pairs.</abstract>
      <url hash="6ac739b1">2024.wmt-1.19</url>
      <bibkey>liao-etal-2024-ikun</bibkey>
      <doi>10.18653/v1/2024.wmt-1.19</doi>
    </paper>
    <paper id="20">
      <title><fixed-case>NTTSU</fixed-case> at <fixed-case>WMT</fixed-case>2024 General Translation Task</title>
      <author><first>Minato</first><last>Kondo</last><affiliation>University of Tsukuba</affiliation></author>
      <author><first>Ryo</first><last>Fukuda</last><affiliation>NTT Communication Science Laboratories</affiliation></author>
      <author><first>Xiaotian</first><last>Wang</last><affiliation>University of Tsukuba</affiliation></author>
      <author><first>Katsuki</first><last>Chousa</last><affiliation>NTT</affiliation></author>
      <author><first>Masato</first><last>Nishimura</last><affiliation>University of Tsukuba</affiliation></author>
      <author><first>Kosei</first><last>Buma</last><affiliation>University of Tsukuba</affiliation></author>
      <author><first>Takatomo</first><last>Kano</last><affiliation>NTT</affiliation></author>
      <author><first>Takehito</first><last>Utsuro</last><affiliation>University of Tsukuba</affiliation></author>
      <pages>270-279</pages>
      <abstract>The NTTSU team’s submission leverages several large language models developed through a training procedure that includes continual pre-training and supervised fine-tuning. For paragraph-level translation, we generated synthetic paragraph-aligned data and utilized this data for training.In the task of translating Japanese to Chinese, we particularly focused on the speech domain translation. Specifically, we built Whisper models for Japanese automatic speech recognition (ASR). We used YODAS dataset for Whisper training. Since this data contained many noisy data pairs, we combined the Whisper outputs using ROVER for polishing the transcriptions. Furthermore, to enhance the robustness of the translation model against errors in the transcriptions, we performed data augmentation by forward translation from audio, using both ASR and base translation models.To select the best translation from multiple hypotheses of the models, we applied Minimum Bayes Risk decoding + reranking, incorporating scores such as COMET-QE, COMET, and cosine similarity by LaBSE.</abstract>
      <url hash="b7277d4c">2024.wmt-1.20</url>
      <bibkey>kondo-etal-2024-nttsu</bibkey>
      <doi>10.18653/v1/2024.wmt-1.20</doi>
    </paper>
    <paper id="21">
      <title><fixed-case>SCIR</fixed-case>-<fixed-case>MT</fixed-case>’s Submission for <fixed-case>WMT</fixed-case>24 General Machine Translation Task</title>
      <author><first>Baohang</first><last>Li</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Zekai</first><last>Ye</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Yichong</first><last>Huang</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Xiaocheng</first><last>Feng</last><affiliation>Harbin Institute of Technology,SCIR lab</affiliation></author>
      <author><first>Bing</first><last>Qin</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <pages>280-285</pages>
      <abstract>This paper introduces the submission of SCIR research center of Harbin Institute of Technology participating in the WMT24 machine translation evaluation task of constrained track for English to Czech. Our approach involved a rigorous process of cleaning and deduplicating both monolingual and bilingual data, followed by a three-stage model training recipe. During the testing phase, we used the beam serach decoding method to generate a large number of candidate translations. Furthermore, we employed COMET-MBR decoding to identify optimal translations.</abstract>
      <url hash="232a6e24">2024.wmt-1.21</url>
      <bibkey>li-etal-2024-scir</bibkey>
      <doi>10.18653/v1/2024.wmt-1.21</doi>
    </paper>
    <paper id="22">
      <title><fixed-case>AIST</fixed-case> <fixed-case>AIRC</fixed-case> Systems for the <fixed-case>WMT</fixed-case> 2024 Shared Tasks</title>
      <author><first>Matiss</first><last>Rikters</last><affiliation>AIST</affiliation></author>
      <author><first>Makoto</first><last>Miwa</last><affiliation>Toyota Technological Institute</affiliation></author>
      <pages>286-291</pages>
      <abstract>At WMT 2024 AIST AIRC participated in the General Machine Translation shared task and the Biomedical Translation task. We trained constrained track models for translation between English, German, and Japanese. Before training the final models, we first filtered the parallel data, then performed iterative back-translation as well as parallel data distillation. We experimented with training baseline Transformer models, Mega models, and fine-tuning open-source T5 and Gemma model checkpoints using the filtered parallel data. Our primary submissions contain translations from ensembles of two Mega model checkpoints and our contrastive submissions are generated by our fine-tuned T5 model checkpoints.</abstract>
      <url hash="f50413f7">2024.wmt-1.22</url>
      <bibkey>rikters-miwa-2024-aist</bibkey>
      <doi>10.18653/v1/2024.wmt-1.22</doi>
    </paper>
    <paper id="23">
      <title>Occiglot at <fixed-case>WMT</fixed-case>24: <fixed-case>E</fixed-case>uropean Open-source Large Language Models Evaluated on Translation</title>
      <author><first>Eleftherios</first><last>Avramidis</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Annika</first><last>Grützner-Zahn</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Manuel</first><last>Brack</last><affiliation>DFKI, TU Darmstadt</affiliation></author>
      <author><first>Patrick</first><last>Schramowski</last><affiliation>TU Darmstadt</affiliation></author>
      <author><first>Pedro</first><last>Ortiz Suarez</last><affiliation>Common Crawl Foundation</affiliation></author>
      <author><first>Malte</first><last>Ostendorff</last><affiliation>German Research Center for Artificial Intelligence</affiliation></author>
      <author><first>Fabio</first><last>Barth</last><affiliation>DFKI</affiliation></author>
      <author><first>Shushen</first><last>Manakhimova</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Vivien</first><last>Macketanz</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Georg</first><last>Rehm</last><affiliation>DFKI</affiliation></author>
      <author><first>Kristian</first><last>Kersting</last><affiliation>TU Darmstadt</affiliation></author>
      <pages>292-298</pages>
      <abstract>This document describes the submission of the very first version of the Occiglot open-source large language model to the General MT Shared Task of the 9th Conference of Machine Translation (WMT24). Occiglot is an open-source, community-based LLM based on Mistral-7B, which went through language-specific continual pre-training and subsequent instruction tuning, including instructions relevant to machine translation.We examine the automatic metric scores for translating the WMT24 test set and provide a detailed linguistically-motivated analysis.Despite Occiglot performing worse than many of the other system submissions, we observe that it performs better than Mistral7B, which has been based upon, which indicates the positive effect of the language specific continual-pretraining and instruction tuning. We see the submission of this very early version of the model as a motivation to unite community forces and pursue future LLM research on the translation task.</abstract>
      <url hash="e5c8daf6">2024.wmt-1.23</url>
      <bibkey>avramidis-etal-2024-occiglot</bibkey>
      <doi>10.18653/v1/2024.wmt-1.23</doi>
    </paper>
    <paper id="24">
      <title><fixed-case>C</fixed-case>o<fixed-case>ST</fixed-case> of breaking the <fixed-case>LLM</fixed-case>s</title>
      <author><first>Ananya</first><last>Mukherjee</last><affiliation>International Institute of Information Technology Hyderabad</affiliation></author>
      <author><first>Saumitra</first><last>Yadav</last><affiliation>International Institute of Information Technology, Hyderabad</affiliation></author>
      <author><first>Manish</first><last>Shrivastava</last><affiliation>International Institute of Information Technology Hyderabad</affiliation></author>
      <pages>299-306</pages>
      <abstract>This paper presents an evaluation of 16 machine translation systems submitted to the Shared Task of the 9th Conference of Machine Translation (WMT24) for the English-Hindi (en-hi) language pair using our Complex Structures Test (CoST) suite. Aligning with this year’s test suite sub-task theme, “Help us break LLMs”, we curated a comprehensive test suite encompassing diverse datasets across various categories, including autobiography, poetry, legal, conversation, play, narration, technical, and mixed genres. Our evaluation reveals that all the systems struggle significantly with the archaic style of text like legal and technical writings or text with creative twist like conversation and poetry datasets, highlighting their weaknesses in handling complex linguistic structures and stylistic nuances inherent in these text types. Our evaluation identifies the strengths and limitations of the submitted models, pointing to specific areas where further research and development are needed to enhance their performance. Our test suite is available at <url>https://github.com/AnanyaCoder/CoST-WMT-24-Test-Suite-Task</url>.</abstract>
      <url hash="eb1387d6">2024.wmt-1.24</url>
      <bibkey>mukherjee-etal-2024-cost</bibkey>
      <doi>10.18653/v1/2024.wmt-1.24</doi>
    </paper>
    <paper id="25">
      <title><fixed-case>WMT</fixed-case>24 Test Suite: Gender Resolution in Speaker-Listener Dialogue Roles</title>
      <author><first>Hillary</first><last>Dawkins</last><affiliation>National Research Council Canada</affiliation></author>
      <author><first>Isar</first><last>Nejadgholi</last><affiliation>National Research Council Canada</affiliation></author>
      <author><first>Chi-Kiu</first><last>Lo</last><affiliation>National Research Council of Canada</affiliation></author>
      <pages>307-326</pages>
      <abstract>We assess the difficulty of gender resolution in literary-style dialogue settings and the influence of gender stereotypes. Instances of the test suite contain spoken dialogue interleaved with external meta-context about the characters and the manner of speaking. We find that character and manner stereotypes outside of the dialogue significantly impact the gender agreement of referents within the dialogue.</abstract>
      <url hash="015cd23e">2024.wmt-1.25</url>
      <bibkey>dawkins-etal-2024-wmt24</bibkey>
      <doi>10.18653/v1/2024.wmt-1.25</doi>
    </paper>
    <paper id="26">
      <title>The <fixed-case>G</fixed-case>ender<fixed-case>Q</fixed-case>ueer Test Suite</title>
      <author><first>Steinunn Rut</first><last>Friidhriksdóttir</last><affiliation>University of Iceland</affiliation></author>
      <pages>327-340</pages>
      <abstract>This paper introduces the GenderQueer Test Suite, an evaluation set for assessing machine translation (MT) systems’ capabilities in handling gender-diverse and queer-inclusive content, focusing on English to Icelandic translation. The suite evaluates MT systems on various aspects of gender-inclusive translation, including pronoun and adjective agreement, LGBTQIA+ terminology, and the impact of explicit gender specifications.The 17 MT systems submitted to the WMT24 English-Icelandic track were evaluated. Key findings reveal significant performance differences between large language model-based systems (LLMs) and lightweight models in handling context for gender agreement. Challenges in translating the singular “they” were widespread, while most systems performed relatively well in translating LGBTQIA+ terminology. Accuracy in adjective gender agreement is quite low, with some models struggling particularly with the feminine form.This evaluation set contributes to the ongoing discussion about inclusive language in MT and natural language processing. By providing a tool for assessing MT systems’ handling of gender-diverse content, it aims to enhance the inclusivity of language technology. The methodology and evaluation scripts are made available for adaptation to other languages, promoting further research in this area.</abstract>
      <url hash="753e5ff1">2024.wmt-1.26</url>
      <bibkey>friidhriksdottir-2024-genderqueer</bibkey>
      <doi>10.18653/v1/2024.wmt-1.26</doi>
      <revision id="1" href="2024.wmt-1.26v1" hash="93d4b87a"/>
      <revision id="2" href="2024.wmt-1.26v2" hash="753e5ff1" date="2024-11-29">Minor update.</revision>
    </paper>
    <paper id="27">
      <title>Domain Dynamics: Evaluating Large Language Models in <fixed-case>E</fixed-case>nglish-<fixed-case>H</fixed-case>indi Translation</title>
      <author><first>Soham</first><last>Bhattacharjee</last><affiliation>Indian Institute of Technology Patna</affiliation></author>
      <author><first>Baban</first><last>Gain</last><affiliation>Indian Institute of Technology, Patna</affiliation></author>
      <author><first>Asif</first><last>Ekbal</last><affiliation>IIT Patna</affiliation></author>
      <pages>341-354</pages>
      <abstract>Large Language Models (LLMs) have demonstrated impressive capabilities in machine translation, leveraging extensive pre-training on vast amounts of data. However, this generalist training often overlooks domain-specific nuances, leading to potential difficulties when translating specialized texts. In this study, we present a multi-domain test suite, collated from previously published datasets, designed to challenge and evaluate the translation abilities of LLMs. The test suite encompasses diverse domains such as judicial, education, literature (specifically religious texts), and noisy user-generated content from online product reviews and forums like Reddit. Each domain consists of approximately 250-300 sentences, carefully curated and randomized in the final compilation. This English-to-Hindi dataset aims to evaluate and expose the limitations of LLM-based translation systems, offering valuable insights into areas requiring further research and development. We have submitted the dataset to WMT24 Break the LLM subtask. In this paper, we present our findings. We have made the code and the dataset publicly available at <url>https://github.com/sohamb37/wmt24-test-suite</url></abstract>
      <url hash="ddd3f00a">2024.wmt-1.27</url>
      <bibkey>bhattacharjee-etal-2024-domain</bibkey>
      <doi>10.18653/v1/2024.wmt-1.27</doi>
    </paper>
    <paper id="28">
      <title>Investigating the Linguistic Performance of Large Language Models in Machine Translation</title>
      <author><first>Shushen</first><last>Manakhimova</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Vivien</first><last>Macketanz</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Eleftherios</first><last>Avramidis</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Ekaterina</first><last>Lapshinova-Koltunski</last><affiliation>University of Hildesheim</affiliation></author>
      <author><first>Sergei</first><last>Bagdasarov</last><affiliation>Saarland University</affiliation></author>
      <author><first>Sebastian</first><last>Möller</last><affiliation>Quality and Usability Lab, TU Berlin</affiliation></author>
      <pages>355-371</pages>
      <abstract>This paper summarizes the results of our test suite evaluation on 39 machine translation systems submitted at the Shared Task of the Ninth Conference of Machine Translation (WMT24). It offers a fine-grained linguistic evaluation of machine translation outputs for English–German and English–Russian, resulting from significant manual linguistic effort. Based on our results, LLMs are inferior to NMT in English–German, both in overall scores and when translating specific linguistic phenomena, such as punctuation, complex future verb tenses, and stripping. LLMs show quite a competitive performance in English-Russian, although top-performing systems might struggle with some cases of named entities and terminology, function words, mediopassive voice, and semantic roles. Additionally, some LLMs generate very verbose or empty outputs, posing challenges to the evaluation process.</abstract>
      <url hash="9d2544ec">2024.wmt-1.28</url>
      <bibkey>manakhimova-etal-2024-investigating</bibkey>
      <doi>10.18653/v1/2024.wmt-1.28</doi>
    </paper>
    <paper id="29">
      <title><fixed-case>I</fixed-case>so<fixed-case>C</fixed-case>hrono<fixed-case>M</fixed-case>eter: A Simple and Effective Isochronic Translation Evaluation Metric</title>
      <author><first>Nikolai</first><last>Rozanov</last><affiliation>Imperial College London</affiliation></author>
      <author><first>Vikentiy</first><last>Pankov</last><affiliation>Rask AI</affiliation></author>
      <author><first>Dmitrii</first><last>Mukhutdinov</last><affiliation>Rask AI</affiliation></author>
      <author><first>Dima</first><last>Vypirailenko</last><affiliation>Rask Ai</affiliation></author>
      <pages>372-379</pages>
      <abstract>Machine translation (MT) has come a long way and is readily employed in production systems to serve millions of users daily. With the recent advances in generative AI, a new form of translation is becoming possible - video dubbing. This work motivates the importance of isochronic translation, especially in the context of automatic dubbing, and introduces ‘IsoChronoMeter’ (ICM). ICM is a simple yet effective metric to measure isochrony of translations in a scalable and resource-efficient way without the need for gold data, based on state-of-the-art text-to-speech (TTS) duration predictors. We motivate IsoChronoMeter and demonstrate its effectiveness. Using ICM we demonstrate the shortcomings of state-of-the-art translation systems and show the need for new methods. We release the code at this URL: <url>https://github.com/braskai/isochronometer</url>.</abstract>
      <url hash="48e780db">2024.wmt-1.29</url>
      <bibkey>rozanov-etal-2024-isochronometer</bibkey>
      <doi>10.18653/v1/2024.wmt-1.29</doi>
    </paper>
    <paper id="30">
      <title>A Test Suite of Prompt Injection Attacks for <fixed-case>LLM</fixed-case>-based Machine Translation</title>
      <author><first>Antonio Valerio</first><last>Miceli Barone</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Zhifan</first><last>Sun</last><affiliation>Technische Universität Darmstadt</affiliation></author>
      <pages>380-450</pages>
      <abstract>LLM-based NLP systems typically work by embedding their input data into prompt templates which contain instructions and/or in-context examples, creating queries which are submitted to a LLM, then parse the LLM response in order to generate the system outputs. Prompt Injection Attacks (PIAs) are a type of subversion of these systems where a malicious user crafts special inputs which interfer with the prompt templates, causing the LLM to respond in ways unintended by the system designer.Recently, Sun and Miceli-Barone (2024) proposed a class of PIAs against LLM-based machine translation. Specifically, the task is to translate questions from the TruthfulQA test suite, where an adversarial prompt is prepended to the questions, instructing the system to ignore the translation instruction and answer the questions instead.In this test suite we extend this approach to all the language pairs of the WMT 2024 General Machine Translation task. Moreover, we include additional attack formats in addition to the one originally studied.</abstract>
      <url hash="132cb636">2024.wmt-1.30</url>
      <bibkey>miceli-barone-sun-2024-test</bibkey>
      <doi>10.18653/v1/2024.wmt-1.30</doi>
    </paper>
    <paper id="31">
      <title>Killing Two Flies with One Stone: An Attempt to Break <fixed-case>LLM</fixed-case>s Using <fixed-case>E</fixed-case>nglish-<fixed-case>I</fixed-case>celandic Idioms and Proper Names</title>
      <author><first>Bjarki</first><last>Ármannsson</last><affiliation>The Árni Magnússon Institute for Icelandic Studies</affiliation></author>
      <author><first>Hinrik</first><last>Hafsteinsson</last><affiliation>University of Iceland</affiliation></author>
      <author><first>Atli</first><last>Jasonarson</last><affiliation>The Árni Magnússon Institute</affiliation></author>
      <author><first>Steinthor</first><last>Steingrimsson</last><affiliation>The Arni Magnusson Institute for Icelandic Studies</affiliation></author>
      <pages>451-458</pages>
      <abstract>The submission of the Árni Magnússon Institute’s team to the WMT24 test suite subtask focuses on idiomatic expressions and proper names for the English→Icelandic translation direction. Intuitively and empirically, idioms and proper names are known to be a significant challenge for neural translation models. We create two different test suites. The first evaluates the competency of MT systems in translating common English idiomatic expressions, as well as testing whether systems can distinguish between those expressions and the same phrases when used in a literal context. The second test suite consists of place names that should be translated into their Icelandic exonyms (and correctly inflected) and pairs of Icelandic names that share a surface form between the male and female variants, so that incorrect translations impact meaning as well as readibility. The scores reported are relatively low, especially for idiomatic expressions and place names, and indicate considerable room for improvement.</abstract>
      <url hash="e8d09aa7">2024.wmt-1.31</url>
      <bibkey>armannsson-etal-2024-killing</bibkey>
      <doi>10.18653/v1/2024.wmt-1.31</doi>
    </paper>
    <paper id="32">
      <title><fixed-case>M</fixed-case>eta<fixed-case>M</fixed-case>etrics-<fixed-case>MT</fixed-case>: Tuning Meta-Metrics for Machine Translation via Human Preference Calibration</title>
      <author><first>David</first><last>Anugraha</last><affiliation>University of Toronto</affiliation></author>
      <author><first>Garry</first><last>Kuwanto</last><affiliation>Boston University</affiliation></author>
      <author><first>Lucky</first><last>Susanto</last><affiliation>Universitas Indonesia</affiliation></author>
      <author><first>Derry Tanti</first><last>Wijaya</last><affiliation>Boston University</affiliation></author>
      <author><first>Genta</first><last>Winata</last><affiliation>Capital One AI Foundations</affiliation></author>
      <pages>459-469</pages>
      <abstract>We present MetaMetrics-MT, an innovative metric designed to evaluate machine translation (MT) tasks by aligning closely with human preferences through Bayesian optimization with Gaussian Processes. MetaMetrics-MT enhances existing MT metrics by optimizing their correlation with human judgments. Our experiments on the WMT24 metric shared task dataset demonstrate that MetaMetrics-MT outperforms all existing baselines, setting a new benchmark for state-of-the-art performance in the reference-based setting. Furthermore, it achieves comparable results to leading metrics in the reference-free setting, offering greater efficiency.</abstract>
      <url hash="63d12b50">2024.wmt-1.32</url>
      <bibkey>anugraha-etal-2024-metametrics</bibkey>
      <doi>10.18653/v1/2024.wmt-1.32</doi>
    </paper>
    <paper id="33">
      <title>chr<fixed-case>F</fixed-case>-<fixed-case>S</fixed-case>: Semantics Is All You Need</title>
      <author><first>Ananya</first><last>Mukherjee</last><affiliation>International Institute of Information Technology Hyderabad</affiliation></author>
      <author><first>Manish</first><last>Shrivastava</last><affiliation>International Institute of Information Technology Hyderabad</affiliation></author>
      <pages>470-474</pages>
      <abstract>Machine translation (MT) evaluation metrics like BLEU and chrF++ are widely used reference-based metrics that do not require training and are language-independent. However, these metrics primarily focus on n-gram matching and often overlook semantic depth and contextual understanding. To address this gap, we introduce chrF-S (Semantic chrF++), an enhanced metric that integrates sentence embeddings to evaluate translation quality more comprehensively. By combining traditional character and word n-gram analysis with semantic information derived from embeddings, chrF-S captures both syntactic accuracy and sentence-level semantics. This paper presents our contributions to the WMT24 shared metrics task, showcasing our participation and the development of chrF-S. We also demonstrate that, according to preliminary results on the leaderboard, our metric performs on par with other supervised and LLM-based metrics. By merging semantic insights with n-gram precision, chrF-S offers a significant enhancement in the assessment of machine-generated translations, advancing the field of MT evaluation. Our code and data will be made available at <url>https://github.com/AnanyaCoder/chrF-S</url>.</abstract>
      <url hash="214509a6">2024.wmt-1.33</url>
      <bibkey>mukherjee-shrivastava-2024-chrf</bibkey>
      <doi>10.18653/v1/2024.wmt-1.33</doi>
    </paper>
    <paper id="34">
      <title><fixed-case>MSLC</fixed-case>24: Further Challenges for Metrics on a Wide Landscape of Translation Quality</title>
      <author><first>Rebecca</first><last>Knowles</last><affiliation>National Research Council Canada</affiliation></author>
      <author><first>Samuel</first><last>Larkin</last><affiliation>National Research Council Canada</affiliation></author>
      <author><first>Chi-Kiu</first><last>Lo</last><affiliation>National Research Council of Canada</affiliation></author>
      <pages>475-491</pages>
      <abstract>In this second edition of the Metric Score Landscape Challenge (MSLC), we examine how automatic metrics for machine translation perform on a wide variety of machine translation output, ranging from very low quality systems to the types of high-quality systems submitted to the General MT shared task at WMT. We also explore metric results on specific types of data, such as empty strings, wrong- or mixed-language text, and more. We raise several alarms about inconsistencies in metric scores, some of which can be resolved by increasingly explicit instructions for metric use, while others highlight technical flaws.</abstract>
      <url hash="e7962357">2024.wmt-1.34</url>
      <bibkey>knowles-etal-2024-mslc24</bibkey>
      <doi>10.18653/v1/2024.wmt-1.34</doi>
    </paper>
    <paper id="35">
      <title><fixed-case>M</fixed-case>etric<fixed-case>X</fixed-case>-24: The <fixed-case>G</fixed-case>oogle Submission to the <fixed-case>WMT</fixed-case> 2024 Metrics Shared Task</title>
      <author><first>Juraj</first><last>Juraska</last><affiliation>Google</affiliation></author>
      <author><first>Daniel</first><last>Deutsch</last><affiliation>Google</affiliation></author>
      <author><first>Mara</first><last>Finkelstein</last><affiliation>Google</affiliation></author>
      <author><first>Markus</first><last>Freitag</last><affiliation>Google Research</affiliation></author>
      <pages>492-504</pages>
      <abstract>In this paper, we present the MetricX-24 submissions to the WMT24 Metrics Shared Task and provide details on the improvements we made over the previous version of MetricX. Our primary submission is a hybrid reference-based/-free metric, which can score a translation irrespective of whether it is given the source segment, the reference, or both. The metric is trained on previous WMT data in a two-stage fashion, first on the DA ratings only, then on a mixture of MQM and DA ratings. The training set in both stages is augmented with synthetic examples that we created to make the metric more robust to several common failure modes, such as fluent but unrelated translation, or undertranslation. We demonstrate the benefits of the individual modifications via an ablation study, and show a significant performance increase over MetricX-23 on the WMT23 MQM ratings, as well as our new synthetic challenge set.</abstract>
      <url hash="68844997">2024.wmt-1.35</url>
      <bibkey>juraska-etal-2024-metricx</bibkey>
      <doi>10.18653/v1/2024.wmt-1.35</doi>
    </paper>
    <paper id="36">
      <title>Evaluating <fixed-case>WMT</fixed-case> 2024 Metrics Shared Task Submissions on <fixed-case>A</fixed-case>fri<fixed-case>MTE</fixed-case> (the <fixed-case>A</fixed-case>frican Challenge Set)</title>
      <author><first>Jiayi</first><last>Wang</last><affiliation>University College London</affiliation></author>
      <author><first>David Ifeoluwa</first><last>Adelani</last><affiliation>McGill University / MILA</affiliation></author>
      <author><first>Pontus</first><last>Stenetorp</last><affiliation>University College London</affiliation></author>
      <pages>505-516</pages>
      <abstract>The AfriMTE challenge set from WMT 2024 Metrics Shared Task aims to evaluate the capabilities of evaluation metrics for machine translation on low-resource African languages, which primarily assesses cross-lingual transfer learning and generalization of machine translation metrics across a wide range of under-resourced languages. In this paper, we analyze the submissions to WMT 2024 Metrics Shared Task. Our findings indicate that language-specific adaptation, cross-lingual transfer learning, and larger language model sizes contribute significantly to improved metric performance. Moreover, supervised models with relatively moderate sizes demonstrate robust performance, when augmented with specific language adaptation for low-resource African languages. Finally, submissions show promising results for language pairs including Darija-French, English-Egyptian Arabic, and English-Swahili. However, significant challenges persist for extremely low-resource languages such as English-Luo and English-Twi, highlighting areas for future research and improvement in machine translation metrics for African languages.</abstract>
      <url hash="62262108">2024.wmt-1.36</url>
      <bibkey>wang-etal-2024-evaluating</bibkey>
      <doi>10.18653/v1/2024.wmt-1.36</doi>
    </paper>
    <paper id="37">
      <title>Machine Translation Metrics Are Better in Evaluating Linguistic Errors on <fixed-case>LLM</fixed-case>s than on Encoder-Decoder Systems</title>
      <author><first>Eleftherios</first><last>Avramidis</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Shushen</first><last>Manakhimova</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Vivien</first><last>Macketanz</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Sebastian</first><last>Möller</last><affiliation>Quality and Usability Lab, TU Berlin</affiliation></author>
      <pages>517-528</pages>
      <abstract>This year’s MT metrics challenge set submission by DFKI expands on previous years’ linguistically motivated challenge sets. It includes 137,000 items extracted from 100 MT systems for the two language directions (English to German, English to Russian), covering more than 100 linguistically motivated phenomena organized into 14 linguistic categories. The metrics with the statistically significant best performance in our linguistically motivated analysis are MetricX-24-Hybrid and MetricX-24 for English to German, and MetricX-24 for English to Russian. Metametrics and XCOMET are in the next ranking positions in both language pairs. Metrics are more accurate in detecting linguistic errors in translations by large language models (LLMs) than in translations based on the encoder-decoder neural machine translation (NMT) architecture. Some of the most difficult phenomena for the metrics to score are the transitive past progressive, multiple connectors, and the ditransitive simple future I for English to German, and pseudogapping, contact clauses, and cleft sentences for English to Russian. Despite its overall low performance, the LLM-based metric Gemba performs best in scoring German negation errors.</abstract>
      <url hash="3d307882">2024.wmt-1.37</url>
      <bibkey>avramidis-etal-2024-machine</bibkey>
      <doi>10.18653/v1/2024.wmt-1.37</doi>
    </paper>
    <paper id="38">
      <title><fixed-case>TMU</fixed-case>-<fixed-case>HIT</fixed-case>’s Submission for the <fixed-case>WMT</fixed-case>24 Quality Estimation Shared Task: Is <fixed-case>GPT</fixed-case>-4 a Good Evaluator for Machine Translation?</title>
      <author><first>Ayako</first><last>Sato</last><affiliation>tokyo metropolitan university</affiliation></author>
      <author><first>Kyotaro</first><last>Nakajima</last><affiliation>TMU</affiliation></author>
      <author><first>Hwichan</first><last>Kim</last><affiliation>Tokyo Metropolitan University</affiliation></author>
      <author><first>Zhousi</first><last>Chen</last><affiliation>Hitotsubashi University</affiliation></author>
      <author><first>Mamoru</first><last>Komachi</last><affiliation>Hitotsubashi University</affiliation></author>
      <pages>529-534</pages>
      <abstract>In machine translation quality estimation (QE), translation quality is evaluated automatically without the need for reference translations. This paper describes our contribution to the sentence-level subtask of Task 1 at the Ninth Machine Translation Conference (WMT24), which predicts quality scores for neural MT outputs without reference translations. We fine-tune GPT-4o mini, a large-scale language model (LLM), with limited data for QE.We report results for the direct assessment (DA) method for four language pairs: English-Gujarati (En-Gu), English-Hindi (En-Hi), English-Tamil (En-Ta), and English-Telugu (En-Te).Experiments under zero-shot, few-shot prompting, and fine-tuning settings revealed significantly low performance in the zero-shot, while fine-tuning achieved accuracy comparable to last year’s best scores. Our system demonstrated the effectiveness of this approach in low-resource language QE, securing 1st place in both En-Gu and En-Hi, and 4th place in En-Ta and En-Te.</abstract>
      <url hash="1a452a9a">2024.wmt-1.38</url>
      <bibkey>sato-etal-2024-tmu</bibkey>
      <doi>10.18653/v1/2024.wmt-1.38</doi>
    </paper>
    <paper id="39">
      <title><fixed-case>HW</fixed-case>-<fixed-case>TSC</fixed-case> 2024 Submission for the Quality Estimation Shared Task</title>
      <author><first>Weiqiao</first><last>Shan</last><affiliation>HW-TSC</affiliation></author>
      <author><first>Ming</first><last>Zhu</last><affiliation>HW-TSC</affiliation></author>
      <author><first>Yuang</first><last>Li</last><affiliation>Huawei</affiliation></author>
      <author><first>Mengyao</first><last>Piao</last><affiliation>HW-TSC</affiliation></author>
      <author><first>Xiaofeng</first><last>Zhao</last><affiliation>HW-TSC</affiliation></author>
      <author><first>Chang</first><last>Su</last><affiliation>HW-TSC</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>HW-TSC</affiliation></author>
      <author><first>Hao</first><last>Yang</last><affiliation>HW-TSC</affiliation></author>
      <author><first>Yanfei</first><last>Jiang</last><affiliation>HW-TSC</affiliation></author>
      <pages>535-540</pages>
      <abstract>Quality estimation (QE) is a crucial technique for evaluating the quality of machine translations without the need for reference translations. This paper focuses on Huawei Translation Services Center’s (HW-TSC’s) submission to the sentence-level QE shared task, named LLMs-enhanced-CrossQE. Our system builds upon the CrossQE architecture from our submission from last year, which consists of a multilingual base model and a task-specific downstream layer. The model input is a concatenation of the source and the translated sentences. To enhance performance, we fine-tuned and ensembled multiple base models, including XLM-R, InfoXLM, RemBERT, and CometKiwi. Specifically, we employed two pseudo-data generation methods: 1) a diverse pseudo-data generation method based on the corruption-based data augmentation technique introduced last year, and 2) a pseudo-data generation method that simulates machine translation errors using large language models (LLMs). Our results demonstrate that the system achieves outstanding performance on sentence-level QE test sets.</abstract>
      <url hash="f238cdc0">2024.wmt-1.39</url>
      <bibkey>shan-etal-2024-hw</bibkey>
      <doi>10.18653/v1/2024.wmt-1.39</doi>
    </paper>
    <paper id="40">
      <title><fixed-case>HW</fixed-case>-<fixed-case>TSC</fixed-case>’s Participation in the <fixed-case>WMT</fixed-case> 2024 <fixed-case>QEAPE</fixed-case> Task</title>
      <author><first>Jiawei</first><last>Yu</last><affiliation>Xiamen university</affiliation></author>
      <author><first>Xiaofeng</first><last>Zhao</last><affiliation>Huawei Technologies Co Ltd</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>Huawei</affiliation></author>
      <author><first>Zhao</first><last>Yanqing</last><affiliation>Huawei</affiliation></author>
      <author><first>Yuang</first><last>Li</last><affiliation>Huawei</affiliation></author>
      <author><first>Su</first><last>Chang</last><affiliation>Huawei TSC</affiliation></author>
      <author><first>Xiaosong</first><last>Qiao</last><affiliation>Huawei Technologies Co Ltd</affiliation></author>
      <author><first>Ma</first><last>Miaomiao</last><affiliation>Huawei TSC</affiliation></author>
      <author><first>Hao</first><last>Yang</last><affiliation>Huawei Co. Ltd</affiliation></author>
      <pages>541-546</pages>
      <abstract>The paper presents the submission by HW-TSC in the WMT 2024 Quality-informed Automatic Post Editing (QEAPE) shared task for the English-Hindi (En-Hi) and English-Tamil (En-Ta) language pair. We use LLM for En-Hi and Transformer for EN-ta respectively. For LLM, we first continue pertrain the Llama3, and then use the real APE data to SFT the pre-trained LLM. As for the transformer in En-Ta, we first pre-train a Machine Translation (MT) model by utilizing MT data collected from the web. Then, we fine-tune the model by employing real APE data.We also use the data augmentation method to enhance our model. Specifically, we incorporate candidate translations obtained from an external Machine Translation (MT) system.Given that APE systems tend to exhibit a tendency of ‘over-correction’, we employ a sentence-level Quality Estimation (QE) system to select the final output, deciding between the original translation and the corresponding output generated by the APE model. Our experiments demonstrate that pre-trained MT models are effective when being fine-tuned with the APE corpus of a limited size, and the performance can be further improved with external MT augmentation. our approach improves the HTER by -15.99 points and -0.47 points on En-Hi and En-Ta, respectively.</abstract>
      <url hash="dd0f0ebb">2024.wmt-1.40</url>
      <bibkey>yu-etal-2024-hw</bibkey>
      <doi>10.18653/v1/2024.wmt-1.40</doi>
    </paper>
    <paper id="41">
      <title>Expanding the <fixed-case>FLORES</fixed-case>+ Multilingual Benchmark with Translations for <fixed-case>A</fixed-case>ragonese, Aranese, <fixed-case>A</fixed-case>sturian, and <fixed-case>V</fixed-case>alencian</title>
      <author><first>Juan Antonio</first><last>Perez-Ortiz</last><affiliation>Departament de Llenguatges i Sistemes Informatics, Universitat d’Alacant</affiliation></author>
      <author><first>Felipe</first><last>Sánchez-Martínez</last><affiliation>Universitat d’Alacant</affiliation></author>
      <author><first>Víctor M.</first><last>Sánchez-Cartagena</last><affiliation>Universitat d’Alacant</affiliation></author>
      <author><first>Miquel</first><last>Esplà-Gomis</last><affiliation>Universitat d’Alacant</affiliation></author>
      <author><first>Aaron</first><last>Galiano Jimenez</last><affiliation>Universitat d’Alacant</affiliation></author>
      <author><first>Antoni</first><last>Oliver</last><affiliation>Universitat Oberta de Catalunya</affiliation></author>
      <author><first>Claudi</first><last>Aventín-Boya</last><affiliation>Universitat Oberta de Catalunya</affiliation></author>
      <author><first>Alejandro</first><last>Pardos</last><affiliation>Universidad de Zaragoza</affiliation></author>
      <author><first>Cristina</first><last>Valdés</last><affiliation>Academia de la Llingua Asturiana / Universidad de Oviedo</affiliation></author>
      <author><first>Jusèp Loís</first><last>Sans Socasau</last><affiliation>Institut d’Estudis Aranesi – Acadèmia Aranesa dera Lengua Occitana</affiliation></author>
      <author><first>Juan Pablo</first><last>Martínez</last><affiliation>Academia Aragonesa de la Lengua / Universidad de Zaragoza</affiliation></author>
      <pages>547-555</pages>
      <abstract>In this paper, we describe the process of creating the FLORES+ datasets for several Romance languages spoken in Spain, namely Aragonese, Aranese, Asturian, and Valencian. The Aragonese and Aranese datasets are entirely new additions to the FLORES+ multilingual benchmark. An initial version of the Asturian dataset was already available in FLORES+, and our work focused on a thorough revision. Similarly, FLORES+ included a Catalan dataset, which we adapted to the Valencian variety spoken in the Valencian Community. The development of the Aragonese, Aranese, and revised Asturian FLORES+ datasets was undertaken as part of a WMT24 shared task on translation into low-resource languages of Spain.</abstract>
      <url hash="27528a96">2024.wmt-1.41</url>
      <bibkey>perez-ortiz-etal-2024-expanding</bibkey>
      <doi>10.18653/v1/2024.wmt-1.41</doi>
    </paper>
    <paper id="42">
      <title>The <fixed-case>B</fixed-case>angla/<fixed-case>B</fixed-case>engali Seed Dataset Submission to the <fixed-case>WMT</fixed-case>24 Open Language Data Initiative Shared Task</title>
      <author><first>Firoz</first><last>Ahmed</last><affiliation>University of Florida</affiliation></author>
      <author><first>Nitin</first><last>Venkateswaran</last><affiliation>University of Florida</affiliation></author>
      <author><first>Sarah</first><last>Moeller</last><affiliation>University of Florida</affiliation></author>
      <pages>556-566</pages>
      <abstract>We contribute a seed dataset for the Bangla/Bengali language as part of the WMT24 Open Language Data Initiative shared task. We validate the quality of the dataset against a mined and automatically aligned dataset (NLLBv1) and two other existing datasets of crowdsourced manual translations. The validation is performed by investigating the performance of state-of-the-art translation models fine-tuned on the different datasets after controlling for training set size. Machine translation models fine-tuned on our dataset outperform models tuned on the other datasets in both translation directions (English-Bangla and Bangla-English). These results confirm the quality of our dataset. We hope our dataset will support machine translation for the Bangla/Bengali community and related low-resource languages.</abstract>
      <url hash="ef5bd7c9">2024.wmt-1.42</url>
      <bibkey>ahmed-etal-2024-bangla</bibkey>
      <doi>10.18653/v1/2024.wmt-1.42</doi>
    </paper>
    <paper id="43">
      <title>A High-quality Seed Dataset for <fixed-case>I</fixed-case>talian Machine Translation</title>
      <author><first>Edoardo</first><last>Ferrante</last><affiliation>Conseggio pe-o patrimonio linguistico ligure</affiliation></author>
      <pages>567-569</pages>
      <abstract>This paper describes the submission of a high-quality translation of the OLDI Seed datasetinto Italian for the WMT 2023 Open LanguageData Initiative shared task.The base of this submission is a previous ver-sion of an Italian OLDI Seed dataset releasedby Haberland et al. (2024) via machine trans-lation and partial post-editing. This data wassubsequently reviewed in its entirety by twonative speakers of Italian, who carried out ex-tensive post-editing with particular attention tothe idiomatic translation of named entities.</abstract>
      <url hash="e1ac1e22">2024.wmt-1.43</url>
      <bibkey>ferrante-2024-high</bibkey>
      <doi>10.18653/v1/2024.wmt-1.43</doi>
    </paper>
    <paper id="44">
      <title>Correcting <fixed-case>FLORES</fixed-case> Evaluation Dataset for Four <fixed-case>A</fixed-case>frican Languages</title>
      <author><first>Idris</first><last>Abdulmumin</last><affiliation>University of Pretoria</affiliation></author>
      <author><first>Sthembiso</first><last>Mkhwanazi</last><affiliation>CSIR</affiliation></author>
      <author><first>Mahlatse</first><last>Mbooi</last><affiliation>Council for Scientific and Industrial Research</affiliation></author>
      <author><first>Shamsuddeen Hassan</first><last>Muhammad</last><affiliation>Bayero University, Kano</affiliation></author>
      <author><first>Ibrahim Said</first><last>Ahmad</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Neo</first><last>Putini</last><affiliation>University of KwaZulu-Natal</affiliation></author>
      <author><first>Miehleketo</first><last>Mathebula</last><affiliation>University of Pretoria</affiliation></author>
      <author><first>Matimba</first><last>Shingange</last><affiliation>University of Pretoria</affiliation></author>
      <author><first>Tajuddeen</first><last>Gwadabe</last><affiliation>Masakhane Research Foundation</affiliation></author>
      <author><first>Vukosi</first><last>Marivate</last><affiliation>University of Pretoria, Lelapa AI</affiliation></author>
      <pages>570-578</pages>
      <abstract>This paper describes the corrections made to the FLORES evaluation (dev and devtest) dataset for four African languages, namely Hausa, Northern Sotho (Sepedi), Xitsonga, and isiZulu. The original dataset, though groundbreaking in its coverage of low-resource languages, exhibited various inconsistencies and inaccuracies in the reviewed languages that could potentially hinder the integrity of the evaluation of downstream tasks in natural language processing (NLP), especially machine translation. Through a meticulous review process by native speakers, several corrections were identified and implemented, improving the dataset’s overall quality and reliability. For each language, we provide a concise summary of the errors encountered and corrected and also present some statistical analysis that measures the difference between the existing and corrected datasets. We believe that our corrections enhance the linguistic accuracy and reliability of the data and, thereby, contribute to a more effective evaluation of NLP tasks involving the four African languages. Finally, we recommend that future translation efforts, particularly in low-resource languages, prioritize the active involvement of native speakers at every stage of the process to ensure linguistic accuracy and cultural relevance.</abstract>
      <url hash="a4ae5888">2024.wmt-1.44</url>
      <bibkey>abdulmumin-etal-2024-correcting</bibkey>
      <doi>10.18653/v1/2024.wmt-1.44</doi>
    </paper>
    <paper id="45">
      <title>Expanding <fixed-case>FLORES</fixed-case>+ Benchmark for More Low-Resource Settings: <fixed-case>P</fixed-case>ortuguese-Emakhuwa Machine Translation Evaluation</title>
      <author><first>Felermino Dario Mario</first><last>Ali</last><affiliation>Lurio University</affiliation></author>
      <author><first>Henrique</first><last>Lopes Cardoso</last><affiliation>University of Porto</affiliation></author>
      <author><first>Rui</first><last>Sousa-Silva</last><affiliation>University of Porto - Faculty of Arts and Humanities</affiliation></author>
      <pages>579-592</pages>
      <abstract>As part of the Open Language Data Initiative shared tasks, we have expanded the FLORES+ evaluation set to include Emakhuwa, a low-resource language widely spoken in Mozambique. We translated the <i>dev</i> and <i>devtest</i> sets from Portuguese into Emakhuwa, and we detail the translation process and quality assurance measures used. Our methodology involved various quality checks, including post-editing and adequacy assessments. The resulting datasets consist of multiple reference sentences for each source. We present baseline results from training a Neural Machine Translation system and fine-tuning existing multilingual translation models. Our findings suggest that spelling inconsistencies remain a challenge in Emakhuwa. Additionally, the baseline models underperformed on this evaluation set, underscoring the necessity for further research to enhance machine translation quality for Emakhuwa.The data is publicly available at <url>https://huggingface.co/datasets/LIACC/Emakhuwa-FLORES</url></abstract>
      <url hash="ee8f8df2">2024.wmt-1.45</url>
      <bibkey>ali-etal-2024-expanding</bibkey>
      <doi>10.18653/v1/2024.wmt-1.45</doi>
    </paper>
    <paper id="46">
      <title>Enhancing Tuvan Language Resources through the <fixed-case>FLORES</fixed-case> Dataset</title>
      <author><first>Ali</first><last>Kuzhuget</last><affiliation>tyvan.ru</affiliation></author>
      <author><first>Airana</first><last>Mongush</last><affiliation>Algebras AI</affiliation></author>
      <author><first>Nachyn-Enkhedorzhu</first><last>Oorzhak</last><affiliation>www.tyvan.ru</affiliation></author>
      <pages>593-599</pages>
      <abstract>FLORES is a benchmark dataset designed for evaluating machine translation systems, partic- ularly for low-resource languages. This paper, conducted as a part of Open Language Data Ini- tiative (OLDI) shared task, presents our contri- bution to expanding the FLORES dataset with high-quality translations from Russian to Tu- van, an endangered Turkic language. Our ap- proach combined the linguistic expertise of na- tive speakers to ensure both accuracy and cul- tural relevance in the translations. This project represents a significant step forward in support- ing Tuvan as a low-resource language in the realm of natural language processing (NLP) and machine translation (MT).</abstract>
      <url hash="ee2433cf">2024.wmt-1.46</url>
      <bibkey>kuzhuget-etal-2024-enhancing</bibkey>
      <doi>10.18653/v1/2024.wmt-1.46</doi>
    </paper>
    <paper id="47">
      <title>Machine Translation Evaluation Benchmark for <fixed-case>W</fixed-case>u <fixed-case>C</fixed-case>hinese: Workflow and Analysis</title>
      <author><first>Hongjian</first><last>Yu</last><affiliation>University of Washington</affiliation></author>
      <author><first>Yiming</first><last>Shi</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Zherui</first><last>Zhou</last><affiliation>Shanghai Normal University</affiliation></author>
      <author><first>Christopher</first><last>Haberland</last><affiliation>University of Washington</affiliation></author>
      <pages>600-605</pages>
      <abstract>We introduce a FLORES+ dataset as an evaluation benchmark for modern Wu Chinese machine translation models and showcase its compatibility with existing Wu data. Wu Chinese is mutually unintelligible with other Sinitic languages such as Mandarin and Yue (Cantonese), but uses a set of Hanzi (Chinese characters) that profoundly overlaps with others. The population of Wu speakers is the second largest among languages in China, but the language has been suffering from significant drop in usage especially among the younger generations. We identify Wu Chinese as a textually low-resource language and address challenges for its machine translation models. Our contributions include: (1) an open-source, manually translated dataset, (2) full documentations on the process of dataset creation and validation experiments, (3) preliminary tools for Wu Chinese normalization and segmentation, and (4) benefits and limitations of our dataset, as well as implications to other low-resource languages.</abstract>
      <url hash="075c046a">2024.wmt-1.47</url>
      <bibkey>yu-etal-2024-machine</bibkey>
      <doi>10.18653/v1/2024.wmt-1.47</doi>
    </paper>
    <paper id="48">
      <title>Open Language Data Initiative: Advancing Low-Resource Machine Translation for <fixed-case>K</fixed-case>arakalpak</title>
      <author><first>Mukhammadsaid</first><last>Mamasaidov</last><affiliation>Tahrirchi</affiliation></author>
      <author><first>Abror</first><last>Shopulatov</last><affiliation>Tahrirchi</affiliation></author>
      <pages>606-613</pages>
      <abstract>This study presents several contributions for the Karakalpak language: a FLORES+ devtest dataset translated to Karakalpak, parallel corpora for Uzbek-Karakalpak, Russian-Karakalpak and English-Karakalpak of 100,000 pairs each and open-sourced fine-tuned neural models for translation across these languages. Our experiments compare different model variants and training approaches, demonstrating improvements over existing baselines. This work, conducted as part of the Open Language Data Initiative (OLDI) shared task, aims to advance machine translation capabilities for Karakalpak and contribute to expanding linguistic diversity in NLP technologies.</abstract>
      <url hash="a09673a1">2024.wmt-1.48</url>
      <bibkey>mamasaidov-shopulatov-2024-open</bibkey>
      <doi>10.18653/v1/2024.wmt-1.48</doi>
    </paper>
    <paper id="49">
      <title><fixed-case>FLORES</fixed-case>+ Translation and Machine Translation Evaluation for the <fixed-case>E</fixed-case>rzya Language</title>
      <author><first>Isai</first><last>Gordeev</last><affiliation>École Polytechnique</affiliation></author>
      <author><first>Sergey</first><last>Kuldin</last><affiliation>Independent Researcher</affiliation></author>
      <author><first>David</first><last>Dale</last><affiliation>Meta AI</affiliation></author>
      <pages>614-623</pages>
      <abstract>This paper introduces a translation of the FLORES+ dataset into the endangered Erzya language, with the goal of evaluating machine translation between this language and any of the other 200 languages already included into FLORES+. This translation was carried out as a part of the Open Language Data shared task at WMT24. We also present a benchmark of existing translation models bases on this dataset and a new translation model that achieves the state-of-the-art quality of translation into Erzya from Russian and English.</abstract>
      <url hash="6ca87a5b">2024.wmt-1.49</url>
      <bibkey>gordeev-etal-2024-flores</bibkey>
      <doi>10.18653/v1/2024.wmt-1.49</doi>
    </paper>
    <paper id="50">
      <title><fixed-case>S</fixed-case>panish Corpus and Provenance with Computer-Aided Translation for the <fixed-case>WMT</fixed-case>24 <fixed-case>OLDI</fixed-case> Shared Task</title>
      <author><first>Jose</first><last>Cols</last><affiliation>University of Washington</affiliation></author>
      <pages>624-635</pages>
      <abstract>This paper presents the Seed-CAT submission to the WMT24 Open Language Data Initiative shared task. We detail our data collection method, which involves a computer-aided translation tool developed explicitly for translating Seed corpora. We release a professionally translated Spanish corpus and a provenance dataset documenting the translation process. The quality of the data was validated on the FLORES+ benchmark with English-Spanish neural machine translation models, achieving an average chrF++ score of 34.9.</abstract>
      <url hash="6e1a3b7e">2024.wmt-1.50</url>
      <bibkey>cols-2024-spanish</bibkey>
      <doi>10.18653/v1/2024.wmt-1.50</doi>
    </paper>
    <paper id="51">
      <title>Efficient Terminology Integration for <fixed-case>LLM</fixed-case>-based Translation in Specialized Domains</title>
      <author><first>Sejoon</first><last>Kim</last><affiliation>Yonsei University, PwC Korea</affiliation></author>
      <author><first>Mingi</first><last>Sung</last><affiliation>Yonsei University</affiliation></author>
      <author><first>Jeonghwan</first><last>Lee</last><affiliation>Yonsei University</affiliation></author>
      <author><first>Hyunkuk</first><last>Lim</last><affiliation>Yonsei University</affiliation></author>
      <author><first>Jorge</first><last>Gimenez Perez</last><affiliation>Korea University</affiliation></author>
      <pages>636-642</pages>
      <abstract>Traditional machine translation methods typically involve training models directly on large parallel corpora, with limited emphasis on specialized terminology. However, In specialized fields such as patents, finance, biomedical domains, terminology is crucial for translation, with many terminologies that should not be translated based on semantics of the sentence but should be translated following agreed-upon conventions. In this paper we introduce a methodology that efficiently trains models with a smaller amount of data while preserving the accuracy of terminology translation. The terminology extraction model generates a glossary from existing training datasets and further refines the LLM by instructing it to effectively incorporate these terms into translations. We achieve this through a systematic process of term extraction and glossary creation using the Trie Tree algorithm, followed by data reconstruction to teach the LLM how to integrate these specialized terms. This methodology enhances the model’s ability to handle specialized terminology and ensures high-quality translations, particularly in fields where term consistency is crucial. Our approach has demonstrated exceptional performance, achieving the highest translation score among participants in the WMT patent task to date, showcasing its effectiveness and broad applicability in specialized translation domains where general methods often fall short.</abstract>
      <url hash="9a3dfea2">2024.wmt-1.51</url>
      <bibkey>kim-etal-2024-efficient</bibkey>
      <doi>10.18653/v1/2024.wmt-1.51</doi>
    </paper>
    <paper id="52">
      <title>Rakuten’s Participation in <fixed-case>WMT</fixed-case> 2024 Patent Translation Task</title>
      <author><first>Ohnmar</first><last>Htun</last><affiliation>Rakuten Institute of Technology-Singapore, Rakuten Asia Pte.Ltd.</affiliation></author>
      <author><first>Alberto</first><last>Poncelas</last><affiliation>Rakuten Institute of Technology</affiliation></author>
      <pages>643-646</pages>
      <abstract>This paper introduces our machine transla- tion system (team sakura), developed for the 2024 WMT Patent Translation Task. Our sys- tem focuses on translations between Japanese- English, Japanese-Korean, and Japanese- Chinese. As large language models have shown good results for various natural language pro- cessing tasks, we have adopted the RakutenAI- 7B-chat model, which has demonstrated effec- tiveness in English and Japanese. We fine-tune this model with patent-domain parallel texts and translate using multiple prompts.</abstract>
      <url hash="0390d84b">2024.wmt-1.52</url>
      <bibkey>htun-poncelas-2024-rakutens</bibkey>
      <doi>10.18653/v1/2024.wmt-1.52</doi>
    </paper>
    <paper id="53">
      <title>The <fixed-case>SETU</fixed-case>-<fixed-case>ADAPT</fixed-case> Submission for <fixed-case>WMT</fixed-case> 24 Biomedical Shared Task</title>
      <author><first>Antonio</first><last>Castaldo</last><affiliation>University of Naples “L’Orientale”</affiliation></author>
      <author><first>Maria</first><last>Zafar</last><affiliation>South East Technological University</affiliation></author>
      <author><first>Prashanth</first><last>Nayak</last><affiliation>KantanAI</affiliation></author>
      <author><first>Rejwanul</first><last>Haque</last><affiliation>South East Technological University</affiliation></author>
      <author><first>Andy</first><last>Way</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Johanna</first><last>Monti</last><affiliation>University of Naples “L’Orientale”</affiliation></author>
      <pages>647-653</pages>
      <abstract>This system description paper presents SETU-ADAPT’s submission to the WMT 2024 Biomedical Shared Task, where we participated for the language pairs English-to-French and English-to-German. Our approach focused on fine-tuning Large Language Models, using in-domain and synthetic data, employing different data augmentation and data retrieval strategies. We introduce a novel MT framework, involving three autonomous agents: a Translator Agent, an Evaluator Agent and a Reviewer Agent. We present our findings and report the quality of the outputs.</abstract>
      <url hash="d27ec0e3">2024.wmt-1.53</url>
      <bibkey>castaldo-etal-2024-setu</bibkey>
      <doi>10.18653/v1/2024.wmt-1.53</doi>
    </paper>
    <paper id="54">
      <title>Findings of <fixed-case>WMT</fixed-case> 2024 Shared Task on Low-Resource <fixed-case>I</fixed-case>ndic Languages Translation</title>
      <author><first>Partha</first><last>Pakray</last><affiliation>National Institute of Technology Silchar</affiliation></author>
      <author><first>Santanu</first><last>Pal</last><affiliation>Wipro</affiliation></author>
      <author><first>Advaitha</first><last>Vetagiri</last><affiliation>National Institute of Technology Silchar</affiliation></author>
      <author><first>Reddi</first><last>Krishna</last><affiliation>National Institute of Technology Silchar</affiliation></author>
      <author><first>Arnab Kumar</first><last>Maji</last><affiliation>North-Eastern Hill University</affiliation></author>
      <author><first>Sandeep</first><last>Dash</last><affiliation>Assistant Professor</affiliation></author>
      <author><first>Lenin</first><last>Laitonjam</last><affiliation>IIT Guwahati, NIT Mizoram</affiliation></author>
      <author><first>Lyngdoh</first><last>Sarah</last><affiliation>North-Eastern Hill University</affiliation></author>
      <author><first>Riyanka</first><last>Manna</last><affiliation>Amrita Vishwa Vidyapeetham Amaravati</affiliation></author>
      <pages>654-668</pages>
      <abstract>This paper presents the results of the low-resource Indic language translation task, organized in conjunction with the Ninth Conference on Machine Translation (WMT) 2024. In this edition, participants were challenged to develop machine translation models for four distinct language pairs: English–Assamese, English-Mizo, English-Khasi, and English-Manipuri. The task utilized the enriched IndicNE-Corp1.0 dataset, which includes an extensive collection of parallel and monolingual corpora for northeastern Indic languages. The evaluation was conducted through a comprehensive suite of automatic metrics—BLEU, TER, RIBES, METEOR, and ChrF—supplemented by meticulous human assessment to measure the translation systems’ performance and accuracy. This initiative aims to drive advancements in low-resource machine translation and make a substantial contribution to the growing body of knowledge in this dynamic field.</abstract>
      <url hash="0b7634c3">2024.wmt-1.54</url>
      <bibkey>pakray-etal-2024-findings</bibkey>
      <doi>10.18653/v1/2024.wmt-1.54</doi>
    </paper>
    <paper id="55">
      <title>Findings of <fixed-case>WMT</fixed-case> 2024’s <fixed-case>M</fixed-case>ulti<fixed-case>I</fixed-case>ndic22<fixed-case>MT</fixed-case> Shared Task for Machine Translation of 22 <fixed-case>I</fixed-case>ndian Languages</title>
      <author><first>Raj</first><last>Dabre</last><affiliation>NICT</affiliation></author>
      <author><first>Anoop</first><last>Kunchukuttan</last><affiliation>Microsoft AI and Research</affiliation></author>
      <pages>669-676</pages>
      <abstract>This paper presents the findings of the WMT 2024’s MultiIndic22MT Shared Task, focusing on Machine Translation (MT) of 22 Indian Languages. In this task, we challenged participants with building MT systems which could translate between any or all of 22 Indian languages in the 8th schedule of the Indian constitution and English. For evaluation, we focused on automatic metrics, namely, chrF, chrF++ and BLEU.</abstract>
      <url hash="4bf75d48">2024.wmt-1.55</url>
      <bibkey>dabre-kunchukuttan-2024-findings</bibkey>
      <doi>10.18653/v1/2024.wmt-1.55</doi>
    </paper>
    <paper id="56">
      <title>Findings of <fixed-case>WMT</fixed-case>2024 <fixed-case>E</fixed-case>nglish-to-Low Resource Multimodal Translation Task</title>
      <author><first>Shantipriya</first><last>Parida</last><affiliation>Silo AI</affiliation></author>
      <author><first>Ondřej</first><last>Bojar</last><affiliation>Charles University, MFF UFAL</affiliation></author>
      <author><first>Idris</first><last>Abdulmumin</last><affiliation>University of Pretoria</affiliation></author>
      <author><first>Shamsuddeen Hassan</first><last>Muhammad</last><affiliation>Bayero University, Kano</affiliation></author>
      <author><first>Ibrahim Said</first><last>Ahmad</last><affiliation>Northeastern University</affiliation></author>
      <pages>677-683</pages>
      <abstract>This paper presents the results of the English-to-Low Resource Multimodal Translation shared tasks from the Ninth Conference on Machine Translation (WMT2024). This year, 7 teams submitted their translation results for the automatic and human evaluation.</abstract>
      <url hash="c3a77efb">2024.wmt-1.56</url>
      <bibkey>parida-etal-2024-findings</bibkey>
      <doi>10.18653/v1/2024.wmt-1.56</doi>
    </paper>
    <paper id="57">
      <title>Findings of the <fixed-case>WMT</fixed-case> 2024 Shared Task Translation into Low-Resource Languages of <fixed-case>S</fixed-case>pain: Blending Rule-Based and Neural Systems</title>
      <author><first>Felipe</first><last>Sánchez-Martínez</last><affiliation>Universitat d’Alacant</affiliation></author>
      <author><first>Juan Antonio</first><last>Perez-Ortiz</last><affiliation>Departament de Llenguatges i Sistemes Informatics, Universitat d’Alacant</affiliation></author>
      <author><first>Aaron</first><last>Galiano Jimenez</last><affiliation>Universitat d’Alacant</affiliation></author>
      <author><first>Antoni</first><last>Oliver</last><affiliation>Universitat Oberta de Catalunya</affiliation></author>
      <pages>684-698</pages>
      <abstract>This paper presents the results of the Ninth Conference on Machine Translation (WMT24) Shared Task “Translation into Low-Resource Languages of Spain”’. The task focused on the development of machine translation systems for three language pairs: Spanish-Aragonese, Spanish-Aranese, and Spanish-Asturian. 17 teams participated in the shared task with a total of 87 submissions. The baseline system for all language pairs was Apertium, a rule-based machine translation system that still performs competitively well, even in an era dominated by more advanced non-symbolic approaches. We report and discuss the results of the submitted systems, highlighting the strengths of both neural and rule-based approaches.</abstract>
      <url hash="6c151d70">2024.wmt-1.57</url>
      <bibkey>sanchez-martinez-etal-2024-findings</bibkey>
      <doi>10.18653/v1/2024.wmt-1.57</doi>
    </paper>
    <paper id="58">
      <title>Findings of the <fixed-case>WMT</fixed-case> 2024 Shared Task on Discourse-Level Literary Translation</title>
      <author><first>Longyue</first><last>Wang</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Siyou</first><last>Liu</last><affiliation>University of Macau</affiliation></author>
      <author><first>Chenyang</first><last>Lyu</last><affiliation>MBZUAI</affiliation></author>
      <author><first>Wenxiang</first><last>Jiao</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Xing</first><last>Wang</last><affiliation>Tencent</affiliation></author>
      <author><first>Jiahao</first><last>Xu</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Zhaopeng</first><last>Tu</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Yan</first><last>Gu</last><affiliation>China Literature Ltd.</affiliation></author>
      <author><first>Weiyu</first><last>Chen</last><affiliation>China Literature Ltd.</affiliation></author>
      <author><first>Minghao</first><last>Wu</last><affiliation>Monash University</affiliation></author>
      <author><first>Liting</first><last>Zhou</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Philipp</first><last>Koehn</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Andy</first><last>Way</last><affiliation>ADAPT, Dublin City University</affiliation></author>
      <author><first>Yulin</first><last>Yuan</last><affiliation>Chinese Language and Literature, Peking University.</affiliation></author>
      <pages>699-700</pages>
      <abstract>Translating literary works has perennially stood as an elusive dream in machine translation (MT), a journey steeped in intricate challenges. To foster progress in this domain, we hold a new shared task at WMT 2023, the second edition of the <i>Discourse-Level Literary Translation</i>. First, we (Tencent AI Lab and China Literature Ltd.) release a copyrighted and document-level Chinese-English web novel corpus. Furthermore, we put forth an industry-endorsed criteria to guide human evaluation process. This year, we totally received 10 submissions from 5 academia and industry teams. We employ both automatic and human evaluations to measure the performance of the submitted systems. The official ranking of the systems is based on the overall human judgments. In addition, our extensive analysis reveals a series of interesting findings on literary and discourse-aware MT. We release data, system outputs, and leaderboard at <url>https://www2.statmt.org/wmt24/literary-translation-task.html</url>.</abstract>
      <url hash="b2ab39c8">2024.wmt-1.58</url>
      <bibkey>wang-etal-2024-findings</bibkey>
      <doi>10.18653/v1/2024.wmt-1.58</doi>
    </paper>
    <paper id="59">
      <title>Findings of the <fixed-case>WMT</fixed-case> 2024 Shared Task on Chat Translation</title>
      <author><first>Wafaa</first><last>Mohammed</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Sweta</first><last>Agrawal</last><affiliation>Instituto de Telecomunicações</affiliation></author>
      <author><first>Amin</first><last>Farajian</last><affiliation>Unbabel</affiliation></author>
      <author><first>Vera</first><last>Cabarrão</last><affiliation>Unbabel</affiliation></author>
      <author><first>Bryan</first><last>Eikema</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Ana C</first><last>Farinha</last><affiliation>Unbabel</affiliation></author>
      <author><first>José G.</first><last>C. De Souza</last><affiliation>Unbabel</affiliation></author>
      <pages>701-714</pages>
      <abstract>This paper presents the findings from the third edition of the Chat Translation Shared Task. As with previous editions, the task involved translating bilingual customer support conversations, specifically focusing on the impact of conversation context in translation quality and evaluation. We also include two new language pairs: English-Korean and English-Dutch, in addition to the set of language pairs from previous editions: English-German, English-French, and English-Brazilian Portuguese.We received 22 primary submissions and 32 contrastive submissions from eight teams, with each language pair having participation from at least three teams. We evaluated the systems comprehensively using both automatic metrics and human judgments via a direct assessment framework.The official rankings for each language pair were determined based on human evaluation scores, considering performance in both translation directions—agent and customer. Our analysis shows that while the systems excelled at translating individual turns, there is room for improvement in overall conversation-level translation quality.</abstract>
      <url hash="24742440">2024.wmt-1.59</url>
      <bibkey>mohammed-etal-2024-findings</bibkey>
      <doi>10.18653/v1/2024.wmt-1.59</doi>
    </paper>
    <paper id="60">
      <title>Findings of the <fixed-case>WMT</fixed-case> 2024 Shared Task on Non-Repetitive Translation</title>
      <author><first>Kazutaka</first><last>Kinugawa</last><affiliation>NHK Science &amp; Technology Research Laboratories</affiliation></author>
      <author><first>Hideya</first><last>Mino</last><affiliation>NHK Science &amp; Technology Research Laboratories</affiliation></author>
      <author><first>Isao</first><last>Goto</last><affiliation>Ehime University</affiliation></author>
      <author><first>Naoto</first><last>Shirai</last><affiliation>NHK Science &amp; Technology Research Laboratories</affiliation></author>
      <pages>715-727</pages>
      <abstract>The repetition of words in an English sentence can create a monotonous or awkward impression. In such cases, repetition should be avoided appropriately. To evaluate the performance of machine translation (MT) systems in avoiding such repetition and outputting more polished translations, we presented the shared task of controlling the lexical choice of MT systems. From Japanese–English parallel news articles, we collected several hundred sentence pairs in which the source sentences containing repeated words were translated in a style that avoided repetition. Participants were required to encourage the MT system to output tokens in a non-repetitive manner while maintaining translation quality. We conducted human and automatic evaluations of systems submitted by two teams based on an encoder-decoder Transformer and a large language model, respectively. From the experimental results and analysis, we report a series of findings on this task.</abstract>
      <url hash="e124944d">2024.wmt-1.60</url>
      <bibkey>kinugawa-etal-2024-findings</bibkey>
      <doi>10.18653/v1/2024.wmt-1.60</doi>
    </paper>
    <paper id="61">
      <title>A3-108 Controlling Token Generation in Low Resource Machine Translation Systems</title>
      <author><first>Saumitra</first><last>Yadav</last><affiliation>International Institute of Information Technology, Hyderabad</affiliation></author>
      <author><first>Ananya</first><last>Mukherjee</last><affiliation>International Institute of Information Technology Hyderabad</affiliation></author>
      <author><first>Manish</first><last>Shrivastava</last><affiliation>International Institute of Information Technology Hyderabad</affiliation></author>
      <pages>728-734</pages>
      <abstract>Translating for languages with limited resources poses a persistent challenge due to the scarcity of high-quality training data. To enhance translation accuracy, we explored controlled generation mechanisms, focusing on the importance of control tokens. In our experiments, while training, we encoded the target sentence length as a control token to the source sentence, treating it as an additional feature for the source sentence. We developed various NMT models using transformer architecture and conducted experiments across 8 language directions (English = Assamese, Manipuri, Khasi, and Mizo), exploring four variations of length encoding mechanisms. Through comparative analysis against the baseline model, we submitted two systems for each language direction. We report our findings for the same in this work.</abstract>
      <url hash="876d74ff">2024.wmt-1.61</url>
      <bibkey>yadav-etal-2024-a3</bibkey>
      <doi>10.18653/v1/2024.wmt-1.61</doi>
    </paper>
    <paper id="62">
      <title><fixed-case>S</fixed-case>amsung <fixed-case>R</fixed-case>&amp;<fixed-case>D</fixed-case> Institute <fixed-case>P</fixed-case>hilippines @ <fixed-case>WMT</fixed-case> 2024 <fixed-case>I</fixed-case>ndic <fixed-case>MT</fixed-case> Task</title>
      <author><first>Matthew Theodore</first><last>Roque</last><affiliation>Samsung Research Philippines (SRPH)</affiliation></author>
      <author><first>Carlos Rafael</first><last>Catalan</last><affiliation>Samsung Research Philippines (SRPH)</affiliation></author>
      <author><first>Dan John</first><last>Velasco</last><affiliation>Samsung Research Philippines (SRPH)</affiliation></author>
      <author><first>Manuel Antonio</first><last>Rufino</last><affiliation>Samsung Research Philippines (SRPH)</affiliation></author>
      <author><first>Jan Christian Blaise</first><last>Cruz</last><affiliation>Samsung Research Philippines (SRPH)</affiliation></author>
      <pages>735-741</pages>
      <abstract>This paper presents the methodology developed by the Samsung R&amp;D Institute Philippines (SRPH) Language Intelligence Team (LIT) for the WMT 2024 Shared Task on Low-Resource Indic Language Translation. We trained standard sequence-to-sequence Transformer models from scratch for both English-to-Indic and Indic-to-English translation directions. Additionally, we explored data augmentation through backtranslation and the application of noisy channel reranking to improve translation quality. A multilingual model trained across all language pairs was also investigated. Our results demonstrate the effectiveness of the multilingual model, with significant performance improvements observed in most language pairs, highlighting the potential of shared language representations in low-resource translation scenarios.</abstract>
      <url hash="b170e2c6">2024.wmt-1.62</url>
      <bibkey>roque-etal-2024-samsung</bibkey>
      <doi>10.18653/v1/2024.wmt-1.62</doi>
    </paper>
    <paper id="63">
      <title><fixed-case>DLUT</fixed-case>-<fixed-case>NLP</fixed-case> Machine Translation Systems for <fixed-case>WMT</fixed-case>24 Low-Resource <fixed-case>I</fixed-case>ndic Language Translation</title>
      <author><first>Chenfei</first><last>Ju</last><affiliation>Dalian University of Technology</affiliation></author>
      <author><first>Junpeng</first><last>Liu</last><affiliation>Dalian University of Technology</affiliation></author>
      <author><first>Kaiyu</first><last>Huang</last><affiliation>Beijing Jiaotong University</affiliation></author>
      <author><first>Degen</first><last>Huang</last><affiliation>Dalian University of Technology</affiliation></author>
      <pages>742-746</pages>
      <abstract>This paper describes the submission systems of DLUT-NLP team for the WMT24 low-resource Indic language translation shared task. We participated in the translation task of four language pairs, including en-as, en-mz, en-kha, en-mni.</abstract>
      <url hash="492dfea7">2024.wmt-1.63</url>
      <bibkey>ju-etal-2024-dlut</bibkey>
      <doi>10.18653/v1/2024.wmt-1.63</doi>
    </paper>
    <paper id="64">
      <title><fixed-case>SRIB</fixed-case>-<fixed-case>NMT</fixed-case>’s Submission to the <fixed-case>I</fixed-case>ndic <fixed-case>MT</fixed-case> Shared Task in <fixed-case>WMT</fixed-case> 2024</title>
      <author><first>Pranamya</first><last>Patil</last><affiliation>Samsung Research</affiliation></author>
      <author><first>Raghavendra</first><last>Hr</last><affiliation>Samsung Research</affiliation></author>
      <author><first>Aditya</first><last>Raghuwanshi</last><affiliation>Samsung Research</affiliation></author>
      <author><first>Kushal</first><last>Verma</last><affiliation>Samsung Research</affiliation></author>
      <pages>747-750</pages>
      <abstract>In the context of the Indic Low Resource Ma-chine Translation (MT) challenge at WMT-24, we participated in four language pairs:English-Assamese (en-as), English-Mizo (en-mz), English-Khasi (en-kh), and English-Manipuri (en-mn). To address these tasks,we employed a transformer-based sequence-to-sequence architecture (Vaswani et al., 2017).In the PRIMARY system, which did not uti-lize external data, we first pretrained languagemodels (low resource languages) using avail-able monolingual data before finetuning themon small parallel datasets for translation. Forthe CONTRASTIVE submission approach, weutilized pretrained translation models like In-dic Trans2 (Gala et al., 2023) and appliedLoRA Fine-tuning (Hu et al., 2021) to adaptthem to smaller, low-resource languages, aim-ing to leverage cross-lingual language transfercapabilities (CONNEAU and Lample, 2019).These approaches resulted in significant im-provements in SacreBLEU scores(Post, 2018)for low-resource languages.</abstract>
      <url hash="44a70947">2024.wmt-1.64</url>
      <bibkey>patil-etal-2024-srib</bibkey>
      <doi>10.18653/v1/2024.wmt-1.64</doi>
    </paper>
    <paper id="65">
      <title><fixed-case>MTNLP</fixed-case>-<fixed-case>IIITH</fixed-case>: Machine Translation for Low-Resource <fixed-case>I</fixed-case>ndic Languages</title>
      <author><first>Abhinav</first><last>P M</last><affiliation>International Institute of Information Technology</affiliation></author>
      <author><first>Ketaki</first><last>Shetye</last><affiliation>International Institute of Information Technology</affiliation></author>
      <author><first>Parameswari</first><last>Krishnamurthy</last><affiliation>International Institute of Information Technology</affiliation></author>
      <pages>751-755</pages>
      <abstract>Machine Translation for low-resource languages presents significant challenges, primarily due to limited data availability. We have a baseline model and a primary model. For the baseline model, we first fine-tune the mBART model (mbart-large-50-many-to-many-mmt) for the language pairs English-Khasi, Khasi-English, English-Manipuri, and Manipuri-English. We then augment the dataset by back-translating from Indic languages to English. To enhance data quality, we fine-tune the LaBSE model specifically for Khasi and Manipuri, generating sentence embeddings and applying a cosine similarity threshold of 0.84 to filter out low-quality back-translations. The filtered data is combined with the original training data and used to further fine-tune the mBART model, creating our primary model. The results show that the primary model slightly outperforms the baseline model, with the best performance achieved by the English-to-Khasi (en-kh) primary model, which recorded a BLEU score of 0.0492, a chrF score of 0.3316, and a METEOR score of 0.2589 (on a scale of 0 to 1), with similar results for other language pairs.</abstract>
      <url hash="9b449da8">2024.wmt-1.65</url>
      <bibkey>p-m-etal-2024-mtnlp</bibkey>
      <doi>10.18653/v1/2024.wmt-1.65</doi>
    </paper>
    <paper id="66">
      <title>Exploration of the <fixed-case>C</fixed-case>ycle<fixed-case>GN</fixed-case> Framework for Low-Resource Languages</title>
      <author><first>Sören</first><last>Dreano</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Derek</first><last>Molloy</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Noel</first><last>Murphy</last><affiliation>Dublin City University</affiliation></author>
      <pages>756-761</pages>
      <abstract>CycleGN is a Neural Machine Translation framework relying on the Transformer architecture. The foundational concept of our research posits that in an ideal scenario, retro-translations of generated translations should revert to the original source sentences. Consequently, a pair of models can be trained using a Cycle Consistency Loss only, with one model translating in one direction and the second model in the opposite direction.</abstract>
      <url hash="aa7a57e8">2024.wmt-1.66</url>
      <bibkey>dreano-etal-2024-exploration</bibkey>
      <doi>10.18653/v1/2024.wmt-1.66</doi>
    </paper>
    <paper id="67">
      <title>The <fixed-case>SETU</fixed-case>-<fixed-case>ADAPT</fixed-case> Submissions to the <fixed-case>WMT</fixed-case>24 Low-Resource <fixed-case>I</fixed-case>ndic Language Translation Task</title>
      <author><first>Neha</first><last>Gajakos</last><affiliation>ADAPT Centre</affiliation></author>
      <author><first>Prashanth</first><last>Nayak</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Rejwanul</first><last>Haque</last><affiliation>South East Technological University</affiliation></author>
      <author><first>Andy</first><last>Way</last><affiliation>ADAPT Centre</affiliation></author>
      <pages>762-769</pages>
      <abstract>This paper presents the SETU-ADAPT’s submissions to the WMT 2024 Low-Resource Indic Language Translation task. We participated in the unconstrained segment of the task, focusing on the Assamese-to-English and English-to-Assamese language pairs. Our approach involves leveraging Large Language Models (LLMs) as the baseline systems for all our MT tasks. Furthermore, we applied various strategies to improve the baseline systems. In our first approach, we fine-tuned LLMs using all the data provided by the task organisers. Our second approach explores in-context learning by focusing on few-shot prompting. In our final approach we explore an efficient data extraction technique based on a fuzzy match-based similarity measure for fine-tuning. We evaluated our systems using BLEU, chrF, WER, and COMET. The experimental results showed that our strategies can effectively improve the quality of translations in low-resource scenarios.</abstract>
      <url hash="6f4f0249">2024.wmt-1.67</url>
      <bibkey>gajakos-etal-2024-setu</bibkey>
      <doi>10.18653/v1/2024.wmt-1.67</doi>
    </paper>
    <paper id="68">
      <title><fixed-case>SPRING</fixed-case> Lab <fixed-case>IITM</fixed-case>’s Submission to Low Resource <fixed-case>I</fixed-case>ndic Language Translation Shared Task</title>
      <author><first>Hamees</first><last>Sayed</last><affiliation>Indian Institute of Technology Madras</affiliation></author>
      <author><first>Advait</first><last>Joglekar</last><affiliation>Indian Institute of Technology Madras</affiliation></author>
      <author><first>Srinivasan</first><last>Umesh</last><affiliation>Indian Institute of Technology Madras</affiliation></author>
      <pages>770-774</pages>
      <abstract>We develop a robust translation model for four low-resource Indic languages: Khasi, Mizo, Manipuri, and Assamese. Our approach includes a comprehensive pipeline from data collection and preprocessing to training and evaluation, leveraging data from WMT task datasets, BPCC, PMIndia, and OpenLanguageData. To address the scarcity of bilingual data, we use back-translation techniques on monolingual datasets for Mizo and Khasi, significantly expanding our training corpus. We fine-tune the pre-trained NLLB 3.3B model for Assamese, Mizo, and Manipuri, achieving improved performance over the baseline. For Khasi, which is not supported by the NLLB model, we introduce special tokens and train the model on our Khasi corpus. Our training involves masked language modelling, followed by fine-tuning for English-to-Indic and Indic-to-English translations.</abstract>
      <url hash="3026b775">2024.wmt-1.68</url>
      <bibkey>sayed-etal-2024-spring</bibkey>
      <doi>10.18653/v1/2024.wmt-1.68</doi>
    </paper>
    <paper id="69">
      <title>Machine Translation Advancements of Low-Resource <fixed-case>I</fixed-case>ndian Languages by Transfer Learning</title>
      <author><first>Bin</first><last>Wei</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Zheng</first><last>Jiawei</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Zongyao</first><last>Li</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Zhanglin</first><last>Wu</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Jiaxin</first><last>Guo</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Daimeng</first><last>Wei</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Zhiqiang</first><last>Rao</last><affiliation>Huawei Translation Service Center, Beijing, China</affiliation></author>
      <author><first>Shaojun</first><last>Li</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Yuanchang</first><last>Luo</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Hengchao</first><last>Shang</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Jinlong</first><last>Yang</last><affiliation>Huawei Technologies Co., Ltd</affiliation></author>
      <author><first>Yuhao</first><last>Xie</last><affiliation>HW-TSC</affiliation></author>
      <author><first>Hao</first><last>Yang</last><affiliation>Huawei Co. Ltd</affiliation></author>
      <pages>775-780</pages>
      <abstract>This paper introduces the submission by Huawei Translation Center (HW-TSC) to the WMT24 Indian Languages Machine Translation (MT) Shared Task. To develop a reliable machine translation system for low-resource Indian languages, we employed two distinct knowledge transfer strategies, taking into account the characteristics of the language scripts and the support available from existing open-source models for Indian languages. For Assamese(as) and Manipuri(mn), we fine-tuned the existing IndicTrans2 open-source model to enable bidirectional translation between English and these languages. For Khasi(kh) and Mizo(mz), we trained a multilingual model as the baseline using bilingual data from this four language pairs as well as additional Bengali data, which share the same language family. This was followed by fine-tuning to achieve bidirectional translation between English and Khasi, as well as English and Mizo. Our transfer learning experiments produced significant results: 23.5 BLEU for en→as, 31.8 BLEU for en→mn, 36.2 BLEU for as→en, and 47.9 BLEU for mn→en on their respective test sets. Similarly, the multilingual model transfer learning experiments yielded impressive outcomes, achieving 19.7 BLEU for en→kh, 32.8 BLEU for en→mz, 16.1 BLEU for kh→en, and 33.9 BLEU for mz→en on their respective test sets. These results not only highlight the effectiveness of transfer learning techniques for low-resource languages but also contribute to advancing machine translation capabilities for low-resource Indian languages.</abstract>
      <url hash="e8c1fc38">2024.wmt-1.69</url>
      <bibkey>wei-etal-2024-machine</bibkey>
      <doi>10.18653/v1/2024.wmt-1.69</doi>
    </paper>
    <paper id="70">
      <title><fixed-case>NLIP</fixed-case>_<fixed-case>L</fixed-case>ab-<fixed-case>IITH</fixed-case> Low-Resource <fixed-case>MT</fixed-case> System for <fixed-case>WMT</fixed-case>24 <fixed-case>I</fixed-case>ndic <fixed-case>MT</fixed-case> Shared Task</title>
      <author><first>Pramit</first><last>Sahoo</last><affiliation>Indian Institute of Technology Hyderabad</affiliation></author>
      <author><first>Maharaj</first><last>Brahma</last><affiliation>Indian Institute of Technology Hyderabad</affiliation></author>
      <author><first>Maunendra Sankar</first><last>Desarkar</last><affiliation>IIT Hyderabad</affiliation></author>
      <pages>781-787</pages>
      <abstract>In this paper, we describe our system for the WMT 24 shared task of Low-Resource Indic Language Translation. We consider eng↔{as, kha, lus, mni} as participating language pairs. In this shared task, we explore the fine-tuning of a pre-trained model motivated by the pre-trained objective of aligning embeddings closer by alignment augmentation (Lin et al.,2020) for 22 scheduled Indian languages. Our primary system is based on language-specific finetuning on a pre-trained model. We achieve chrF2 scores of 50.6, 42.3, 54.9, and 66.3 on the official public test set for eng→as, eng→kha, eng→lus, eng→mni respectively. We also explore multilingual training with/without language grouping and layer-freezing.</abstract>
      <url hash="65f717b1">2024.wmt-1.70</url>
      <bibkey>sahoo-etal-2024-nlip</bibkey>
      <doi>10.18653/v1/2024.wmt-1.70</doi>
    </paper>
    <paper id="71">
      <title>Yes-<fixed-case>MT</fixed-case>’s Submission to the Low-Resource <fixed-case>I</fixed-case>ndic Language Translation Shared Task in <fixed-case>WMT</fixed-case> 2024</title>
      <author><first>Yash</first><last>Bhaskar</last><affiliation>IIIT Hyderabad</affiliation></author>
      <author><first>Parameswari</first><last>Krishnamurthy</last><affiliation>Assistant Professor, IIIT Hyderabad</affiliation></author>
      <pages>788-792</pages>
      <abstract>This paper presents the systems submitted by the Yes-MT team for the Low-Resource Indic Language Translation Shared Task at WMT 2024, focusing on translating between English and the Assamese, Mizo, Khasi, and Manipuri languages. The experiments explored various approaches, including fine-tuning pre-trained models like mT5 and IndicBart in both Multilingual and Monolingual settings, LoRA finetune IndicTrans2, zero-shot and few-shot prompting with large language models (LLMs) like Llama 3 and Mixtral 8x7b, LoRA Supervised Fine Tuning Llama 3, and training Transformers from scratch. The results were evaluated on the WMT23 Low-Resource Indic Language Translation Shared Task’s test data using SacreBLEU and CHRF highlighting the challenges of low-resource translation and show the potential of LLMs for these tasks, particularly with fine-tuning.</abstract>
      <url hash="3d405a41">2024.wmt-1.71</url>
      <bibkey>bhaskar-krishnamurthy-2024-yes</bibkey>
      <doi>10.18653/v1/2024.wmt-1.71</doi>
    </paper>
    <paper id="72">
      <title>System Description of <fixed-case>BV</fixed-case>-<fixed-case>SLP</fixed-case> for <fixed-case>S</fixed-case>indhi-<fixed-case>E</fixed-case>nglish Machine Translation in <fixed-case>M</fixed-case>ulti<fixed-case>I</fixed-case>ndic22<fixed-case>MT</fixed-case> 2024 Shared Task</title>
      <author><first>Nisheeth</first><last>Joshi</last><affiliation>Banasthali Vidyapith</affiliation></author>
      <author><first>Pragya</first><last>Katyayan</last><affiliation>University of Petroleum and Energy Studies</affiliation></author>
      <author><first>Palak</first><last>Arora</last><affiliation>Banasthali Vidyapith</affiliation></author>
      <author><first>Bharti</first><last>Nathani</last><affiliation>Banasthali Vidyapith</affiliation></author>
      <pages>793-796</pages>
      <abstract>This paper presents our machine translation system that was developed for the WAT2024 MultiInidc MT shared task. We built our system for the Sindhi-English language pair. We developed two MT systems. The first system was our baseline system where Sindhi was translated into English. In the second system we used Hindi as a pivot for the translation of text. In both the cases we had identified the name entities and translated them into English as a preprocessing step. Once this was done, the standard NMT process was followed to train and generate MT outputs for the task. The systems were tested on the hidden dataset of the shared task</abstract>
      <url hash="0f716706">2024.wmt-1.72</url>
      <bibkey>joshi-etal-2024-system</bibkey>
      <doi>10.18653/v1/2024.wmt-1.72</doi>
    </paper>
    <paper id="73">
      <title><fixed-case>WMT</fixed-case>24 System Description for the <fixed-case>M</fixed-case>ulti<fixed-case>I</fixed-case>ndic22<fixed-case>MT</fixed-case> Shared Task on <fixed-case>M</fixed-case>anipuri Language</title>
      <author><first>Ningthoujam Justwant</first><last>Singh</last><affiliation>National Institute Of Technology, Silchar</affiliation></author>
      <author><first>Kshetrimayum Boynao</first><last>Singh</last><affiliation>National Institute of Technology Silchar</affiliation></author>
      <author><first>Ningthoujam Avichandra</first><last>Singh</last><affiliation>National Institute of Technology Silchar</affiliation></author>
      <author><first>Sanjita</first><last>Phijam</last><affiliation>National Institute of Technology Silchar</affiliation></author>
      <author><first>Thoudam Doren</first><last>Singh</last><affiliation>National Institute of Technology Silchar</affiliation></author>
      <pages>797-803</pages>
      <abstract>This paper presents a Transformer-based Neural Machine Translation (NMT) system developed by the Centre for Natural Language Processing and the Department of Computer Science and Engineering at the National Institute of Technology Silchar, India (NITS-CNLP) for the MultiIndic22MT 2024 Shared Task. The system focused on the English-Manipuri language pair for the WMT24 shared task. The proposed WMT system shows a BLEU score of 6.4, a chrF score of 28.6, and a chrF++ score of 26.6 on the public test set Indic-Conv dataset. Further, in the public test set Indic-Gen dataset, it achieved a BLEU score of 8.1, a chrF score of 32.1, and a chrF++ score of 29.4 on the English-to-Manipuri translation.</abstract>
      <url hash="9247b052">2024.wmt-1.73</url>
      <bibkey>singh-etal-2024-wmt24</bibkey>
      <doi>10.18653/v1/2024.wmt-1.73</doi>
    </paper>
    <paper id="74">
      <title><fixed-case>NLIP</fixed-case>-Lab-<fixed-case>IITH</fixed-case> Multilingual <fixed-case>MT</fixed-case> System for <fixed-case>WAT</fixed-case>24 <fixed-case>MT</fixed-case> Shared Task</title>
      <author><first>Maharaj</first><last>Brahma</last><affiliation>Indian Institute of Technology Hyderabad</affiliation></author>
      <author><first>Pramit</first><last>Sahoo</last><affiliation>Indian Institute of Technology Hyderabad</affiliation></author>
      <author><first>Maunendra Sankar</first><last>Desarkar</last><affiliation>IIT Hyderabad</affiliation></author>
      <pages>804-809</pages>
      <abstract>This paper describes NLIP Lab’s multilingual machine translation system for the WAT24 shared task on multilingual Indic MT task for 22 scheduled languages belonging to 4 language families. We explore pre-training for Indic languages using alignment agreement objectives. We utilize bi-lingual dictionaries to substitute words from source sentences. Furthermore, we fine-tuned language direction-specific multilingual translation models using small and high-quality seed data. Our primary submission is a 243M parameters multilingual translation model covering 22 Indic languages. In the IN22-Gen benchmark, we achieved an average chrF++ score of 46.80 and 18.19 BLEU score for the En-Indic direction. In the Indic-En direction, we achieved an average chrF++ score of 56.34 and 30.82 BLEU score. In the In22-Conv benchmark, we achieved an average chrF++ score of 43.43 and BLEU score of 16.58 in the En-Indic direction, and in the Indic-En direction, we achieved an average of 52.44 and 29.77 for chrF++ and BLEU respectively. Our model is competitive with IndicTransv1 (474M parameter model).</abstract>
      <url hash="8841977b">2024.wmt-1.74</url>
      <bibkey>brahma-etal-2024-nlip</bibkey>
      <doi>10.18653/v1/2024.wmt-1.74</doi>
    </paper>
    <paper id="75">
      <title><fixed-case>DCU</fixed-case> <fixed-case>ADAPT</fixed-case> at <fixed-case>WMT</fixed-case>24: <fixed-case>E</fixed-case>nglish to Low-resource Multi-Modal Translation Task</title>
      <author><first>Sami</first><last>Haq</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Rudali</first><last>Huidrom</last><affiliation>ADAPT Research Centre, Dublin City University</affiliation></author>
      <author><first>Sheila</first><last>Castilho</last><affiliation>Dublin City University</affiliation></author>
      <pages>810-814</pages>
      <abstract>This paper presents the system description of “DCU_NMT’s” submission to the WMT-WAT24 English-to-Low-Resource Multimodal Translation Task. We participated in the English-to-Hindi track, developing both text-only and multimodal neural machine translation (NMT) systems. The text-only systems were trained from scratch on constrained data and augmented with back-translated data. For the multimodal approach, we implemented a context-aware transformer model that integrates visual features as additional contextual information. Specifically, image descriptions generated by an image captioning model were encoded using BERT and concatenated with the textual input.The results indicate that our multimodal system, trained solely on limited data, showed improvements over the text-only baseline in both the challenge and evaluation sets, suggesting the potential benefits of incorporating visual information.</abstract>
      <url hash="0659d57b">2024.wmt-1.75</url>
      <bibkey>haq-etal-2024-dcu</bibkey>
      <doi>10.18653/v1/2024.wmt-1.75</doi>
    </paper>
    <paper id="76">
      <title><fixed-case>E</fixed-case>nglish-to-Low-Resource Translation: A Multimodal Approach for <fixed-case>H</fixed-case>indi, <fixed-case>M</fixed-case>alayalam, <fixed-case>B</fixed-case>engali, and <fixed-case>H</fixed-case>ausa</title>
      <author><first>Ali</first><last>Hatami</last><affiliation>University of Galway</affiliation></author>
      <author><first>Shubhanker</first><last>Banerjee</last><affiliation>University of Galway</affiliation></author>
      <author><first>Mihael</first><last>Arcan</last><affiliation>Lua Health</affiliation></author>
      <author><first>Bharathi</first><last>Raja Chakravarthi</last><affiliation>University of Galway</affiliation></author>
      <author><first>Paul</first><last>Buitelaar</last><affiliation>University of Galway</affiliation></author>
      <author><first>John</first><last>Philip McCrae</last><affiliation>University of Galway</affiliation></author>
      <pages>815-822</pages>
      <abstract>Multimodal machine translation leverages multiple data modalities to enhance translation quality, particularly for low-resourced languages. This paper uses a Multimodal model that integrates visual information with textual data to improve translation accuracy from English to Hindi, Malayalam, Bengali, and Hausa. This approach employs a gated fusion mechanism to effectively combine the outputs of textual and visual encoders, enabling more nuanced translations that consider both language and contextual visual cues. The performance of the multimodal model was evaluated against the text-only machine translation model based on BLEU, ChrF2 and TER. Experimental results demonstrate that the multimodal approach consistently outperforms the text-only baseline, highlighting the potential of integrating visual information in low-resourced language translation tasks.</abstract>
      <url hash="c3962ba9">2024.wmt-1.76</url>
      <bibkey>hatami-etal-2024-english</bibkey>
      <doi>10.18653/v1/2024.wmt-1.76</doi>
      <revision id="1" href="2024.wmt-1.76v1" hash="516807e4"/>
      <revision id="2" href="2024.wmt-1.76v2" hash="c3962ba9" date="2024-11-29">This revision corrects the author names.</revision>
    </paper>
    <paper id="77">
      <title><fixed-case>O</fixed-case>dia<fixed-case>G</fixed-case>en<fixed-case>AI</fixed-case>’s Participation in <fixed-case>WMT</fixed-case>2024 <fixed-case>E</fixed-case>nglish-to-Low Resource Multimodal Translation Task</title>
      <author><first>Shantipriya</first><last>Parida</last><affiliation>Silo AI</affiliation></author>
      <author><first>Shashikanta</first><last>Sahoo</last><affiliation>Government College of Engineering Kalahandi, India</affiliation></author>
      <author><first>Sambit</first><last>Sekhar</last><affiliation>Odia Generative AI</affiliation></author>
      <author><first>Upendra</first><last>Jena</last><affiliation>Creanovation Technologies Pvt Ltd., India</affiliation></author>
      <author><first>Sushovan</first><last>Jena</last><affiliation>IIT Mandi, India</affiliation></author>
      <author><first>Kusum</first><last>Lata</last><affiliation>Sharda University, India</affiliation></author>
      <pages>823-828</pages>
      <abstract>This paper covers the system description of the team “ODIAGEN’s” submission to the WMT~2024 English-to-Low-Resource Multimodal Translation Task. We participated in the English-to-Low Resource Multimodal Translation Task, in two of the tasks, i.e. Text-only Translation and Multi-modal Translation. For Text-only Translation, we trained the Mistral-7B model for English to Multi-lingual (Hindi, Bengali, Malayalam, Hausa). For Multi-modal Translation (using both image and text), we trained the PaliGemma-3B model for English to Hindi translation.</abstract>
      <url hash="1d4d2b7f">2024.wmt-1.77</url>
      <bibkey>parida-etal-2024-odiagenais</bibkey>
      <doi>10.18653/v1/2024.wmt-1.77</doi>
    </paper>
    <paper id="78">
      <title>Arewa <fixed-case>NLP</fixed-case>’s Participation at <fixed-case>WMT</fixed-case>24</title>
      <author><first>Mahmoud</first><last>Ahmad</last><affiliation>Federal University of Technology Babura(FUTB)</affiliation></author>
      <author><first>Auwal</first><last>Khalid</last><affiliation>Bayero University Kano</affiliation></author>
      <author><first>Lukman</first><last>Aliyu</last><affiliation>Arewa data Science</affiliation></author>
      <author><first>Babangida</first><last>Sani</last><affiliation>Arewa data Science</affiliation></author>
      <author><first>Mariya</first><last>Abdullahi</last><affiliation>Bayero University Kano</affiliation></author>
      <pages>829-832</pages>
      <abstract>This paper presents the work of our team, “ArewaNLP,” for the WMT 2024 shared task. The paper describes the system submitted to the Ninth Conference on Machine Translation (WMT24). We participated in the English-Hausa text-only translation task. We fine-tuned the OPUS-MT-en-ha transformer model and our submission achieved competitive results in this task. We achieve a BLUE score of 27.76, 40.31 and 5.85 on the Development Test, Evaluation Test and Challenge Test respectively.</abstract>
      <url hash="5e0e7777">2024.wmt-1.78</url>
      <bibkey>ahmad-etal-2024-arewa</bibkey>
      <doi>10.18653/v1/2024.wmt-1.78</doi>
    </paper>
    <paper id="79">
      <title>Multimodal Machine Translation for Low-Resource <fixed-case>I</fixed-case>ndic Languages: A Chain-of-Thought Approach Using Large Language Models</title>
      <author><first>Pawan</first><last>Rajpoot</last><affiliation>Self</affiliation></author>
      <author><first>Nagaraj</first><last>Bhat</last><affiliation>Self</affiliation></author>
      <author><first>Ashish</first><last>Shrivastava</last><affiliation>Self</affiliation></author>
      <pages>833-838</pages>
      <abstract>This paper presents the approach and results of team v036 in the English-to-Low-Resource Multi-Modal Translation Task at the Ninth Conference on Machine Translation (WMT24). Our team tackled the challenge of translating English source text to low-resource Indic languages, specifically Hindi, Malayalam, and Bengali, while leveraging visual context provided alongside the text data. We used InternVL2 for extracting the image context along with Knowledge Distillation from bigger LLMs to train Small Language Model on the tranlsation task. During current shared task phase, we submitted best models (for this task), and overall we got rank 3 on Hindi, Bengali, and Malyalam datasets. We also open source our models on huggingface.</abstract>
      <url hash="cde9a1d1">2024.wmt-1.79</url>
      <bibkey>rajpoot-etal-2024-multimodal</bibkey>
      <doi>10.18653/v1/2024.wmt-1.79</doi>
    </paper>
    <paper id="80">
      <title>Chitranuvad: Adapting Multi-lingual <fixed-case>LLM</fixed-case>s for Multimodal Translation</title>
      <author><first>Shaharukh</first><last>Khan</last><affiliation>Krutrim AI</affiliation></author>
      <author><first>Ayush</first><last>Tarun</last><affiliation>Krutrim AI</affiliation></author>
      <author><first>Ali</first><last>Faraz</last><affiliation>Krutrim AI</affiliation></author>
      <author><first>Palash</first><last>Kamble</last><affiliation>Krutrim AI</affiliation></author>
      <author><first>Vivek</first><last>Dahiya</last><affiliation>Krutrim AI</affiliation></author>
      <author><first>Praveen</first><last>Pokala</last><affiliation>Krutrim AI</affiliation></author>
      <author><first>Ashish</first><last>Kulkarni</last><affiliation>Krutrim</affiliation></author>
      <author><first>Chandra</first><last>Khatri</last><affiliation>Krutrim AI</affiliation></author>
      <author><first>Abhinav</first><last>Ravi</last><affiliation>Krutrim AI</affiliation></author>
      <author><first>Shubham</first><last>Agarwal</last><affiliation>Krutrim AI</affiliation></author>
      <pages>839-851</pages>
      <abstract>In this work, we provide the system description of our submission as part of the English-to-Lowres Multimodal Translation Task at theWorkshop on Asian Translation (WAT2024). We introduce Chitranuvad, a multimodal model that effectively integrates Multilingual LLMand a vision module for Multimodal Translation. Our method uses a ViT image encoder to extract visual representations as visual tokenembeddings which are projected to the LLM space by an adapter layer and generates translation in an autoregressive fashion. We participated in all the three tracks (Image Captioning, Text-only and Multimodal translationtasks) for Indic languages (ie. English translation to Hindi, Bengali and Malyalam) and achieved SOTA results for Hindi in all of themon the Challenge set while remaining competitive for the other languages in the shared task.</abstract>
      <url hash="44ddae4b">2024.wmt-1.80</url>
      <bibkey>khan-etal-2024-chitranuvad</bibkey>
      <doi>10.18653/v1/2024.wmt-1.80</doi>
    </paper>
    <paper id="81">
      <title>Brotherhood at <fixed-case>WMT</fixed-case> 2024: Leveraging <fixed-case>LLM</fixed-case>-Generated Contextual Conversations for Cross-Lingual Image Captioning</title>
      <author><first>Siddharth</first><last>Betala</last><affiliation>Indian Institute of Technology Madras</affiliation></author>
      <author><first>Ishan</first><last>Chokshi</last><affiliation>Indian Institute of Technology Madras</affiliation></author>
      <pages>852-861</pages>
      <abstract>In this paper, we describe our system under the team name Brotherhood for the English-to-Lowres Multi-Modal Translation Task. We participate in the multi-modal translation tasks for English-Hindi, English-Hausa, English-Bengali, and English-Malayalam language pairs. We present a method leveraging multi-modal Large Language Models (LLMs), specifically GPT-4o and Claude 3.5 Sonnet, to enhance cross-lingual image captioning without traditional training or fine-tuning.Our approach utilizes instruction-tuned prompting to generate rich, contextual conversations about cropped images, using their English captions as additional context. These synthetic conversations are then translated into the target languages. Finally, we employ a weighted prompting strategy, balancing the original English caption with the translated conversation to generate captions in the target language.This method achieved competitive results, scoring 37.90 BLEU on the English-Hindi Challenge Set and ranking first and second for English-Hausa on the Challenge and Evaluation Leaderboards, respectively. We conduct additional experiments on a subset of 250 images, exploring the trade-offs between BLEU scores and semantic similarity across various weighting schemes.</abstract>
      <url hash="d37ca6eb">2024.wmt-1.81</url>
      <bibkey>betala-chokshi-2024-brotherhood</bibkey>
      <doi>10.18653/v1/2024.wmt-1.81</doi>
    </paper>
    <paper id="82">
      <title><fixed-case>TIM</fixed-case>-<fixed-case>UNIGE</fixed-case> Translation into Low-Resource Languages of <fixed-case>S</fixed-case>pain for <fixed-case>WMT</fixed-case>24</title>
      <author><first>Jonathan</first><last>Mutal</last><affiliation>Unige</affiliation></author>
      <author><first>Lucía</first><last>Ormaechea</last><affiliation>Université de Genève</affiliation></author>
      <pages>862-870</pages>
      <abstract>We present the results of our constrained submission to the WMT 2024 shared task, which focuses on translating from Spanish into two low-resource languages of Spain: Aranese (spa-arn) and Aragonese (spa-arg). Our system integrates real and synthetic data generated by large language models (e.g., BLOOMZ) and rule-based Apertium translation systems. Built upon the pre-trained NLLB system, our translation model utilizes a multistage approach, progressively refining the initial model through the sequential use of different datasets, starting with large-scale synthetic or crawled data and advancing to smaller, high-quality parallel corpora. This approach resulted in BLEU scores of 30.1 for Spanish to Aranese and 61.9 for Spanish to Aragonese.</abstract>
      <url hash="0f88a7cd">2024.wmt-1.82</url>
      <bibkey>mutal-ormaechea-2024-tim</bibkey>
      <doi>10.18653/v1/2024.wmt-1.82</doi>
    </paper>
    <paper id="83">
      <title><fixed-case>TAN</fixed-case>-<fixed-case>IBE</fixed-case> Participation in the Shared Task: Translation into Low-Resource Languages of <fixed-case>S</fixed-case>pain</title>
      <author><first>Antoni</first><last>Oliver</last><affiliation>Universitat Oberta de Catalunya</affiliation></author>
      <pages>871-877</pages>
      <abstract>This paper describes the systems presented by the TAN-IBE team into the WMT24 Shared task Translation into Low-Resource Languages of Spain. The aim of this joint task was to train systems for Spanish-Asturian, Spanish-Aragonese and Spanish-Aranesian. Our team presented systems for all three language pairs and for two types of submission: for Spanish-Aragonese and Spanish-Aranese we participated with constrained submissions, and for Spanish-Asturian with an open submission.</abstract>
      <url hash="7b63f60f">2024.wmt-1.83</url>
      <bibkey>oliver-2024-tan</bibkey>
      <doi>10.18653/v1/2024.wmt-1.83</doi>
    </paper>
    <paper id="84">
      <title>Enhaced Apertium System: Translation into Low-Resource Languages of <fixed-case>S</fixed-case>pain <fixed-case>S</fixed-case>panish–<fixed-case>A</fixed-case>sturian</title>
      <author><first>Sofía</first><last>García</last><affiliation>imaxin|software</affiliation></author>
      <pages>878-884</pages>
      <abstract>We present the Spanish–Asturian Apertium translation system, which has been enhanced and refined by our team of linguists for the shared task: Low Resource Languages of Spain of this WMT24 under the closed submission. While our system did not rank among the top 10 in terms of results, we believe that Apertium’s translations are of a commendable standard and demonstrate competitiveness with respect to the other systems.</abstract>
      <url hash="2c190741">2024.wmt-1.84</url>
      <bibkey>garcia-2024-enhaced</bibkey>
      <doi>10.18653/v1/2024.wmt-1.84</doi>
    </paper>
    <paper id="85">
      <title><fixed-case>U</fixed-case>niversitat d’Alacant’s Submission to the <fixed-case>WMT</fixed-case> 2024 Shared Task on Translation into Low-Resource Languages of <fixed-case>S</fixed-case>pain</title>
      <author><first>Aaron</first><last>Galiano Jimenez</last><affiliation>Universitat d’Alacant</affiliation></author>
      <author><first>Víctor M.</first><last>Sánchez-Cartagena</last><affiliation>Universitat d’Alacant</affiliation></author>
      <author><first>Juan Antonio</first><last>Perez-Ortiz</last><affiliation>Departament de Llenguatges i Sistemes Informatics, Universitat d’Alacant</affiliation></author>
      <author><first>Felipe</first><last>Sánchez-Martínez</last><affiliation>Universitat d’Alacant</affiliation></author>
      <pages>885-891</pages>
      <abstract>This paper describes the submissions of the Transducens group of the Universitat d’Alacant to the WMT 2024 Shared Task on Translation into Low-Resource Languages of Spain; in particular, the task focuses on the translation from Spanish into Aragonese, Aranese and Asturian. Our submissions use parallel and monolingual data to fine-tune the NLLB-1.3B model and to investigate the effectiveness of synthetic corpora and transfer-learning between related languages such as Catalan, Galician and Valencian. We also present a many-to-many multilingual neural machine translation model focused on the Romance languages of Spain.</abstract>
      <url hash="8ec4ed77">2024.wmt-1.85</url>
      <bibkey>galiano-jimenez-etal-2024-universitat</bibkey>
      <doi>10.18653/v1/2024.wmt-1.85</doi>
    </paper>
    <paper id="86">
      <title><fixed-case>S</fixed-case>amsung <fixed-case>R</fixed-case>&amp;<fixed-case>D</fixed-case> Institute <fixed-case>P</fixed-case>hilippines @ <fixed-case>WMT</fixed-case> 2024 Low-resource Languages of <fixed-case>S</fixed-case>pain Shared Task</title>
      <author><first>Dan John</first><last>Velasco</last><affiliation>Samsung Research Philippines (SRPH)</affiliation></author>
      <author><first>Manuel Antonio</first><last>Rufino</last><affiliation>Samsung Research Philippines (SRPH)</affiliation></author>
      <author><first>Jan Christian Blaise</first><last>Cruz</last><affiliation>Samsung Research Philippines (SRPH)</affiliation></author>
      <pages>892-900</pages>
      <abstract>This paper details the submission of Samsung R&amp;D Institute Philippines (SRPH) Language Intelligence Team (LIT) to the WMT 2024 Low-resource Languages of Spain shared task. We trained translation models for Spanish to Aragonese, Spanish to Aranese/Occitan, and Spanish to Asturian using a standard sequence-to-sequence Transformer architecture, augmenting it with a noisy-channel reranking strategy to select better outputs during decoding. For Spanish to Asturian translation, our method reaches comparable BLEU scores to a strong commercial baseline translation system using only constrained data, backtranslations, noisy channel reranking, and a shared vocabulary spanning all four languages.</abstract>
      <url hash="97e91c61">2024.wmt-1.86</url>
      <bibkey>velasco-etal-2024-samsung</bibkey>
      <doi>10.18653/v1/2024.wmt-1.86</doi>
    </paper>
    <paper id="87">
      <title>Back to the Stats: Rescuing Low Resource Neural Machine Translation with Statistical Methods</title>
      <author><first>Menan</first><last>Velayuthan</last><affiliation>University of Moratuwa</affiliation></author>
      <author><first>Dilith</first><last>Jayakody</last><affiliation>University of Moratuwa</affiliation></author>
      <author><first>Nisansa</first><last>De Silva</last><affiliation>University of Moratuwa</affiliation></author>
      <author><first>Aloka</first><last>Fernando</last><affiliation>University of Moratuwa</affiliation></author>
      <author><first>Surangika</first><last>Ranathunga</last><affiliation>Massey University</affiliation></author>
      <pages>901-907</pages>
      <abstract>This paper describes our submission to the WMT24 shared task for Low-Resource Languages of Spain in the Constrained task category. Due to the lack of deep learning-based data filtration methods for these languages, we propose a purely statistical-based, two-stage pipeline for data filtration. In the primary stage, we begin by removing spaces and punctuation from the source sentences (Spanish) and deduplicating them. We then filter out sentence pairs with inconsistent language predictions by the language identification model, followed by the removal of pairs with anomalous sentence length and word count ratios, using the development set statistics as the threshold. In the secondary stage, for corpora of significant size, we employ a Jensen Shannon divergence-based method to curate training data of the desired size. Our filtered data allowed us to complete a two-step training process in under 3 hours, with GPU power consumption kept below 1 kWh, making our system both economical and eco-friendly. The source code, training data, and best models are available on the project’s GitHub page.</abstract>
      <url hash="774d49e9">2024.wmt-1.87</url>
      <bibkey>velayuthan-etal-2024-back</bibkey>
      <doi>10.18653/v1/2024.wmt-1.87</doi>
    </paper>
    <paper id="88">
      <title>Hybrid Distillation from <fixed-case>RBMT</fixed-case> and <fixed-case>NMT</fixed-case>: <fixed-case>H</fixed-case>elsinki-<fixed-case>NLP</fixed-case>’s Submission to the Shared Task on Translation into Low-Resource Languages of <fixed-case>S</fixed-case>pain</title>
      <author><first>Ona</first><last>De Gibert</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Mikko</first><last>Aulamo</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Yves</first><last>Scherrer</last><affiliation>University of Oslo</affiliation></author>
      <author><first>Jörg</first><last>Tiedemann</last><affiliation>University of Helsinki</affiliation></author>
      <pages>908-917</pages>
      <abstract>The Helsinki-NLP team participated in the 2024 Shared Task on Translation into Low-Resource languages of Spain with four multilingual systems covering all language pairs. The task consists in developing Machine Translation (MT) models to translate from Spanish into Aragonese, Aranese and Asturian. Our models leverage known approaches for multilingual MT, namely, data filtering, fine-tuning, data tagging, and distillation. We use distillation to merge the knowledge from neural and rule-based systems and explore the trade-offs between translation quality and computational efficiency. We demonstrate that our distilled models can achieve competitive results while significantly reducing computational costs. Our best models ranked 4th, 5th, and 2nd in the open submission track for Spanish–Aragonese, Spanish–Aranese, and Spanish–Asturian, respectively. We release our code and data publicly at https://github.com/Helsinki-NLP/lowres-spain-st.</abstract>
      <url hash="3c9a5bf6">2024.wmt-1.88</url>
      <bibkey>de-gibert-etal-2024-hybrid</bibkey>
      <doi>10.18653/v1/2024.wmt-1.88</doi>
    </paper>
    <paper id="89">
      <title>Robustness of Fine-Tuned Models for Machine Translation with Varying Noise Levels: Insights for <fixed-case>A</fixed-case>sturian, <fixed-case>A</fixed-case>ragonese and Aranese</title>
      <author><first>Martin</first><last>Bär</last><affiliation>University of the Basque Country</affiliation></author>
      <author><first>Elisa</first><last>Forcada Rodríguez</last><affiliation>University of the Basque Country</affiliation></author>
      <author><first>María</first><last>García-Abadillo Velasco</last><affiliation>University of the Basque Country</affiliation></author>
      <pages>918-924</pages>
      <abstract>We present the LCT-LAP proposal for the shared task on Translation into Low-Resource Languages of Spain at WMT24 within the constrained submission category. Our work harnesses encoder-decoder models pretrained on higher-resource Iberian languages to facilitate MT model training for Asturian, Aranese and Aragonese. Furthermore, we explore the robustness of these models when fine-tuned on datasets with varying levels of alignment noise. We fine-tuned a Spanish-Galician model using Asturian data filtered by BLEU score thresholds of 5, 15, 30 and 60, identifying BLEU 15 as the most effective. This threshold was then applied to the Aranese and Aragonese datasets. Our findings indicate that filtering the corpora reduces computational costs and improves performance compared to using nearly raw data or data filtered with language identification. However, it still falls short of the performance achieved by the rule-based system Apertium in Aranese and Aragonese.</abstract>
      <url hash="df247c4c">2024.wmt-1.89</url>
      <bibkey>bar-etal-2024-robustness</bibkey>
      <doi>10.18653/v1/2024.wmt-1.89</doi>
    </paper>
    <paper id="90">
      <title>Training and Fine-Tuning <fixed-case>NMT</fixed-case> Models for Low-Resource Languages Using Apertium-Based Synthetic Corpora</title>
      <author><first>Aleix</first><last>Sant</last><affiliation>Barcelona Supercomputing Center</affiliation></author>
      <author><first>Daniel</first><last>Bardanca</last><affiliation>CITIUS</affiliation></author>
      <author><first>José Ramom</first><last>Pichel Campos</last><affiliation>CITIUS</affiliation></author>
      <author><first>Francesca</first><last>De Luca Fornaciari</last><affiliation>BSC Barcelona Supercomputing Center</affiliation></author>
      <author><first>Carlos</first><last>Escolano</last><affiliation>Universitat PolitÃ ̈cnica de Catalunya, Barcelona Supercomputing Center</affiliation></author>
      <author><first>Javier</first><last>Garcia Gilabert</last><affiliation>Barcelona Super Computing Center</affiliation></author>
      <author><first>Pablo</first><last>Gamallo</last><affiliation>CITIUS, University of Santiago de Compostela</affiliation></author>
      <author><first>Audrey</first><last>Mash</last><affiliation>BSC</affiliation></author>
      <author><first>Xixian</first><last>Liao</last><affiliation>Barcelona Supercomputing Center</affiliation></author>
      <author><first>Maite</first><last>Melero</last><affiliation>BSC</affiliation></author>
      <pages>925-933</pages>
      <abstract>In this paper, we present the two strategies employed for the WMT24 Shared Task on Translation into Low-Resource Languages of Spain. We participated in the language pairs of Spanish-to-Aragonese, Spanish-to-Aranese, and Spanish-to-Asturian, developing neural-based translation systems and moving away from rule-based approaches for these language directions. To create these models, two distinct strategies were employed. The first strategy involved a thorough cleaning process and curation of the limited provided data, followed by fine-tuning the multilingual NLLB-200-600M model (Constrained Submission). The other strategy involved training a transformer from scratch using a vast amount of synthetic data (Open Submission). Both approaches relied on generated synthetic data and resulted in high ChrF and BLEU scores. However, given the characteristics of the task, the strategy used in the Constrained Submission resulted in higher scores that surpassed the baselines across the three translation directions, whereas the strategy employed in the Open Submission yielded slightly lower scores than the highest baseline.</abstract>
      <url hash="34e2fc39">2024.wmt-1.90</url>
      <bibkey>sant-etal-2024-training</bibkey>
      <doi>10.18653/v1/2024.wmt-1.90</doi>
    </paper>
    <paper id="91">
      <title>Vicomtech@<fixed-case>WMT</fixed-case> 2024: Shared Task on Translation into Low-Resource Languages of <fixed-case>S</fixed-case>pain</title>
      <author><first>David</first><last>Ponce</last><affiliation>Vicomtech</affiliation></author>
      <author><first>Harritxu</first><last>Gete</last><affiliation>Vicomtech</affiliation></author>
      <author><first>Thierry</first><last>Etchegoyhen</last><affiliation>Vicomtech</affiliation></author>
      <pages>934-942</pages>
      <abstract>We describe Vicomtech’s participation in the WMT 2024 Shared Task on translation into low-resource languages of Spain. We addressed all three languages of the task, namely Aragonese, Aranese and Asturian, in both constrained and open settings. Our work mainly centred on exploiting different types of corpora via data filtering, selection and combination methods, along with synthetic data generated with translation models based on rules, neural sequence-to-sequence or large language models. We improved or matched the best baselines in all three language pairs and present complementary results on additional test sets.</abstract>
      <url hash="57fc9787">2024.wmt-1.91</url>
      <bibkey>ponce-etal-2024-vicomtech</bibkey>
      <doi>10.18653/v1/2024.wmt-1.91</doi>
    </paper>
    <paper id="92">
      <title><fixed-case>SJTU</fixed-case> System Description for the <fixed-case>WMT</fixed-case>24 Low-Resource Languages of <fixed-case>S</fixed-case>pain Task</title>
      <author><first>Tianxiang</first><last>Hu</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Haoxiang</first><last>Sun</last><affiliation>ShanghaiJiaotong University</affiliation></author>
      <author><first>Ruize</first><last>Gao</last><affiliation>SJTU</affiliation></author>
      <author><first>Jialong</first><last>Tang</last><affiliation>Institute of Software, Chinese Academy of Sciences</affiliation></author>
      <author><first>Pei</first><last>Zhang</last><affiliation>Alibaba-inc</affiliation></author>
      <author><first>Baosong</first><last>Yang</last><affiliation>Alibaba Damo Academy, Alibaba Inc.</affiliation></author>
      <author><first>Rui</first><last>Wang</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>943-948</pages>
      <abstract>We participate in the translation task on Spanish to Aragonese, Spanish to Aranese and Spanish to Asturian. Initially, we conduct preliminary experiments to assess the basic translation capabilities of various models and evaluate the impact of fine-tuning with different data types. We then choose to fine-tune the Qwen2-0.5B model using a forward synthesized pseudo-corpus from the Apertium translation system to replicate its fundamental performance. Building on this distillation model, we explore three optimization strategies across the three language directions: (1) Assembling the provided FLORES+ dev sets into a 5-shot format translation training dataset and performing few-shot fine-tuning to enhance model performance. (2) Utilizing the FLORES+ dev sets as training data and applying the Contrastive Preference Optimization (CPO) strategy for further refinement. (3) Retrieving the 20 most similar translation examples from the FLORES+ dev sets using the BM25 algorithm and performing 20-shot translations with the Claude 3.5-sonnet model. After evaluating these strategies, we select the best-performing approach for each language pair as our submission result.</abstract>
      <url hash="cb45df37">2024.wmt-1.92</url>
      <bibkey>hu-etal-2024-sjtu</bibkey>
      <doi>10.18653/v1/2024.wmt-1.92</doi>
    </paper>
    <paper id="93">
      <title>Multilingual Transfer and Domain Adaptation for Low-Resource Languages of <fixed-case>S</fixed-case>pain</title>
      <author><first>Yuanchang</first><last>Luo</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Zhanglin</first><last>Wu</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Daimeng</first><last>Wei</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Hengchao</first><last>Shang</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Zongyao</first><last>Li</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Jiaxin</first><last>Guo</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Zhiqiang</first><last>Rao</last><affiliation>Huawei Translation Service Center, Beijing, China</affiliation></author>
      <author><first>Shaojun</first><last>Li</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Jinlong</first><last>Yang</last><affiliation>Huawei Technologies Co., Ltd</affiliation></author>
      <author><first>Yuhao</first><last>Xie</last><affiliation>HW-TSC</affiliation></author>
      <author><first>Zheng</first><last>Jiawei</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Bin</first><last>Wei</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Hao</first><last>Yang</last><affiliation>Huawei Co. Ltd</affiliation></author>
      <pages>949-954</pages>
      <abstract>This article introduces the submission status of the Translation into Low-Resource Languages of Spain task at (WMT 2024) by Huawei Translation Service Center (HW-TSC). We participated in three translation tasks: spanish to aragonese (es2arg), spanish to aranese (es2arn), and spanish to asturian (es2ast). For these three translation tasks, we use training strategies such as multilingual transfer, regularized dropout, forward translation and back translation, labse denoising, transduction ensemble learning and other strategies to neural machine translation (NMT) model based on training deep transformer-big architecture. By using these enhancement strategies, our submission achieved a competitive result in the final evaluation.</abstract>
      <url hash="d7317150">2024.wmt-1.93</url>
      <bibkey>luo-etal-2024-multilingual</bibkey>
      <doi>10.18653/v1/2024.wmt-1.93</doi>
    </paper>
    <paper id="94">
      <title><fixed-case>TRIBBLE</fixed-case> - <fixed-case>TR</fixed-case>anslating <fixed-case>IB</fixed-case>erian languages Based on Limited <fixed-case>E</fixed-case>-resources</title>
      <author><first>Igor</first><last>Kuzmin</last><affiliation>Universitat Pompeu Fabra</affiliation></author>
      <author><first>Piotr</first><last>Przybyła</last><affiliation>Universitat Pompeu Fabra</affiliation></author>
      <author><first>Euan</first><last>Mcgill</last><affiliation>Universitat Pompeu Fabra</affiliation></author>
      <author><first>Horacio</first><last>Saggion</last><affiliation>Universitat Pompeu Fabra</affiliation></author>
      <pages>955-959</pages>
      <abstract>In this short overview paper, we describe our system submission for the language pairs Spanish to Aragonese (spa-arg), Spanish to Aranese (spa-arn), and Spanish to Asturian (spa-ast). We train a unified model for all language pairs in the constrained scenario. In addition, we add two language control tokens for Aragonese and Aranese Occitan, as there is already one present for Asturian. We take the distilled NLLB-200 model with 600M parameters and extend special tokens with 2 tokens that denote target languages (arn_Latn, arg_Latn) because Asturian was already presented in NLLB-200 model. We adapt the model by training on a special regime of data augmentation with both monolingual and bilingual training data for the language pairs in this challenge.</abstract>
      <url hash="5e2f0999">2024.wmt-1.94</url>
      <bibkey>kuzmin-etal-2024-tribble</bibkey>
      <doi>10.18653/v1/2024.wmt-1.94</doi>
    </paper>
    <paper id="95">
      <title><fixed-case>C</fixed-case>loud<fixed-case>S</fixed-case>heep System for <fixed-case>WMT</fixed-case>24 Discourse-Level Literary Translation</title>
      <author><first>Lisa</first><last>Liu</last><affiliation>University of California, San Diego</affiliation></author>
      <author><first>Ryan</first><last>Liu</last><affiliation>University of California, San Diego</affiliation></author>
      <author><first>Angela</first><last>Tsai</last><affiliation>University of California, San Diego</affiliation></author>
      <author><first>Jingbo</first><last>Shang</last><affiliation>University of California, San Diego</affiliation></author>
      <pages>960-966</pages>
      <abstract>This paper describes the CloudSheep translation system for WMT24 Discourse-Level Literary Translation shared task. We participated in the Chinese-English direction on the unconstrained track. Our approach to the task used a pipeline of different tools in order to maximize the translation accuracy and flow of the text by combining the strengths of each tool. In particular, our focus was to translate names consistently and idioms correctly. To achieve consistent names throughout a text, a custom name dictionary was generated for each text, containing person and place names, along with their translations. A common honorific dictionary was applied for consistency with titles, especially in historical or cultivation novels. The names were found and translated with GPT 3.5-turbo. To achieve accurate and concise translations of idioms, which are often translated literally and verbosely, we integrated the CC-CEDICT library to provide official definitions. Then, we used GPT-4 to pick the best dictionary definition that fit the context and rephrase it to fit grammatically within a sentence. For the translation of non-name and non-idiom terms, we used Google Translate. We compared our approach’s performance with Google Translate as a baseline using BLEU, chrF, and COMET, as well as A/B testing.</abstract>
      <url hash="38dc3663">2024.wmt-1.95</url>
      <bibkey>liu-etal-2024-cloudsheep</bibkey>
      <doi>10.18653/v1/2024.wmt-1.95</doi>
    </paper>
    <paper id="96">
      <title>Final Submission of <fixed-case>SJTUL</fixed-case>ove<fixed-case>F</fixed-case>iction to Literary Task</title>
      <author><first>Haoxiang</first><last>Sun</last><affiliation>ShanghaiJiaotong University</affiliation></author>
      <author><first>Tianxiang</first><last>Hu</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <author><first>Ruize</first><last>Gao</last><affiliation>SJTU</affiliation></author>
      <author><first>Jialong</first><last>Tang</last><affiliation>Institute of Software, Chinese Academy of Sciences</affiliation></author>
      <author><first>Pei</first><last>Zhang</last><affiliation>Alibaba-inc</affiliation></author>
      <author><first>Baosong</first><last>Yang</last><affiliation>Alibaba Damo Academy, Alibaba Inc.</affiliation></author>
      <author><first>Rui</first><last>Wang</last><affiliation>Shanghai Jiao Tong University</affiliation></author>
      <pages>967-972</pages>
      <abstract>This paper describes Shanghai Jiao Tong University (SJTU LoveFiction) Discourse-Level Literary Translation systems for the WMT24shared task. We participate in the literary translation task on Chinese → English, Chinese →German and Chinese → Russian with uncon-strained tack.Check our paper for detail.</abstract>
      <url hash="30366acf">2024.wmt-1.96</url>
      <bibkey>sun-etal-2024-final</bibkey>
      <doi>10.18653/v1/2024.wmt-1.96</doi>
    </paper>
    <paper id="97">
      <title>Context-aware and Style-related Incremental Decoding Framework for Discourse-Level Literary Translation</title>
      <author><first>Yuanchang</first><last>Luo</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Jiaxin</first><last>Guo</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Daimeng</first><last>Wei</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Hengchao</first><last>Shang</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Zongyao</first><last>Li</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Zhanglin</first><last>Wu</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Zhiqiang</first><last>Rao</last><affiliation>Huawei Translation Service Center, Beijing, China</affiliation></author>
      <author><first>Shaojun</first><last>Li</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Jinlong</first><last>Yang</last><affiliation>Huawei Technologies Co., Ltd</affiliation></author>
      <author><first>Hao</first><last>Yang</last><affiliation>Huawei Co. Ltd</affiliation></author>
      <pages>973-979</pages>
      <abstract>This report outlines our approach for the WMT24 Discourse-Level Literary Translation Task, focusing on the Chinese-English language pair in the Constrained Track. Translating literary texts poses significant challenges due to the nuanced meanings, idiomatic expressions, and intricate narrative structures inherent in such works. To address these challenges, we leveraged the Chinese-Llama2 model, specifically enhanced for this task through a combination of Continual Pre-training (CPT) and Supervised Fine-Tuning (SFT). Our methodology includes a novel Incremental Decoding framework, which ensures that each sentence is translated with consideration of its broader context, maintaining coherence and consistency throughout the text. This approach allows the model to capture long-range dependencies and stylistic elements, producing translations that faithfully preserve the original literary quality. Our experiments demonstrate significant improvements in both sentence-level and document-level BLEU scores, underscoring the effectiveness of our proposed framework in addressing the complexities of document-level literary translation.</abstract>
      <url hash="9d6cac1a">2024.wmt-1.97</url>
      <bibkey>luo-etal-2024-context</bibkey>
      <doi>10.18653/v1/2024.wmt-1.97</doi>
    </paper>
    <paper id="98">
      <title><fixed-case>N</fixed-case>ovel<fixed-case>T</fixed-case>rans: System for <fixed-case>WMT</fixed-case>24 Discourse-Level Literary Translation</title>
      <author><first>Yuchen</first><last>Liu</last><affiliation>nlp2ct,University of Macau</affiliation></author>
      <author><first>Yutong</first><last>Yao</last><affiliation>University of Macau</affiliation></author>
      <author><first>Runzhe</first><last>Zhan</last><affiliation>University of Macau</affiliation></author>
      <author><first>Yuchu</first><last>Lin</last><affiliation>DeepTranx</affiliation></author>
      <author><first>Derek F.</first><last>Wong</last><affiliation>University of Macau</affiliation></author>
      <pages>980-986</pages>
      <abstract>This paper describes our submission system, NovelTrans, from NLP²CT and DeepTranx for the WMT24 Discourse-Level Literary Translation Task in Chinese-English, Chinese-German, and Chinese-Russian language pairs under unconstrained conditions. For our primary system, three translations are done by GPT4o using three different settings of additional information and a terminology table generated by online models. The final result is composed of sentences that have the highest xCOMET score compared with the corresponding sentences in other results. Our system achieved an xCOMET score of 79.14 which is higher than performing a direct chapter-level translation on our dataset.</abstract>
      <url hash="c198e4f6">2024.wmt-1.98</url>
      <bibkey>liu-etal-2024-noveltrans</bibkey>
      <doi>10.18653/v1/2024.wmt-1.98</doi>
    </paper>
    <paper id="99">
      <title><fixed-case>L</fixed-case>in<fixed-case>C</fixed-case>hance-<fixed-case>NTU</fixed-case> for Unconstrained <fixed-case>WMT</fixed-case>2024 Literary Translation</title>
      <author><first>Kechen</first><last>Li</last><affiliation>Jiangsu Linchance Technology Co., Ltd.</affiliation></author>
      <author><first>Yaotian</first><last>Tao</last><affiliation>Jiangsu Linchance Technology Co., Ltd.</affiliation></author>
      <author><first>Hongyi</first><last>Huang</last><affiliation>Jiangsu Linchance Technology Co., Ltd.</affiliation></author>
      <author><first>Tianbo</first><last>Ji</last><affiliation>Nantong University</affiliation></author>
      <pages>987-992</pages>
      <abstract>The rapid growth of deep learning has spurred significant advancements across industries, par- ticularly in machine translation through large language models (LLMs). However, translat- ing literary still presents challenges, including cross-cultural nuances, complex language struc- tures, metaphorical expressions, and cultural differences. To address these issues, this study utilizes the Llama and Phi models using both LoRA and full-parameter techniques, along-side a prompt-based translation system. Full-parameter tuning of the Llama-3-Chinese-8B-Instruct model was unsuccessful due to mem-ory constraints. In terms of the WMT task, the fully fine-tuned Phi 3 model was selected for submission due to its more natural and flu-ent translations. Nonetheless, results showed that LoRA and the prompt-based system sig- nificantly improved the Llama3 model’s perfor- mance, surpassing other models in BLEU and ROUGE evaluations.</abstract>
      <url hash="bcac2b64">2024.wmt-1.99</url>
      <bibkey>li-etal-2024-linchance</bibkey>
      <doi>10.18653/v1/2024.wmt-1.99</doi>
    </paper>
    <paper id="100">
      <title>Improving Context Usage for Translating Bilingual Customer Support Chat with Large Language Models</title>
      <author><first>Jose</first><last>Pombal</last><affiliation>Unbabel</affiliation></author>
      <author><first>Sweta</first><last>Agrawal</last><affiliation>Instituto de Telecomunicações</affiliation></author>
      <author><first>André</first><last>Martins</last><affiliation>Unbabel, Instituto de Telecomunicacoes</affiliation></author>
      <pages>993-1003</pages>
      <abstract>This paper describes Unbabel+IT’s submission to the Chat Shared Task held at the Workshop of Machine Translation 2024. The task focuses on translating customer support chats between agents and customers communicating in different languages. We present two strategies for adapting state-of-the-art language models to better utilize contextual information when translating such conversations. Our training strategy involves finetuning the model on chat datasets with context-augmented instructions, resulting in a specialized model, TOWERCHAT. For inference, we propose a novel quality-aware decoding approach that leverages a context-aware metric, CONTEXTCOMET, to select the optimal translation from a pool of candidates. We evaluate our proposed approach on the official shared task datasets for ten language pairs, showing that our submission consistently outperforms baselines on all and competing systems on 8 out of 10 language pairs across multiple automated metrics. Remarkably, TOWERCHAT outperforms our contrastive submission based on the much larger TOWER-V2-70B model while being 10× smaller. According to human evaluation, our system outperforms all other systems and baselines across all language pairs. These results underscore the importance of context-aware training and inference in handling complex bilingual dialogues.</abstract>
      <url hash="a6dc869d">2024.wmt-1.100</url>
      <bibkey>pombal-etal-2024-improving</bibkey>
      <doi>10.18653/v1/2024.wmt-1.100</doi>
    </paper>
    <paper id="101">
      <title>Optimising <fixed-case>LLM</fixed-case>-Driven Machine Translation with Context-Aware Sliding Windows</title>
      <author><first>Xinye</first><last>Yang</last><affiliation>The University of Sheffield</affiliation></author>
      <author><first>Yida</first><last>Mu</last><affiliation>The University of Sheffield</affiliation></author>
      <author><first>Kalina</first><last>Bontcheva</last><affiliation>The University of Sheffield</affiliation></author>
      <author><first>Xingyi</first><last>Song</last><affiliation>University of Sheffield</affiliation></author>
      <pages>1004-1010</pages>
      <abstract>This paper describes SheffieldGATE’s submission to WMT 2024 Chat Shared Translation Task. We participate in three language pairs: English-German, English-Dutch, and English-Portuguese (Brazil). In this work, we introduce a context-aware sliding window decoding method to track dependencies between chat messages. We fine-tune a large pre-trained language model based on the training data provided by the shared task Our experiments (i) compare the model performance between multilingual and bilingual fine-tuning and (ii) assess the impact of different window sizes. Our experimental results demonstrate that utilising contextual information yields superior performance in document-level translation compared to translating documents as isolated text segments, and that models fine-tuned with multilingual data perform better than those fine-tuned with bilingual data.</abstract>
      <url hash="cd04d7a6">2024.wmt-1.101</url>
      <bibkey>yang-etal-2024-optimising</bibkey>
      <doi>10.18653/v1/2024.wmt-1.101</doi>
    </paper>
    <paper id="102">
      <title>Context-Aware <fixed-case>LLM</fixed-case> Translation System Using Conversation Summarization and Dialogue History</title>
      <author><first>Mingi</first><last>Sung</last><affiliation>Yonsei University</affiliation></author>
      <author><first>Seungmin</first><last>Lee</last><affiliation>Yonsei University</affiliation></author>
      <author><first>Jiwon</first><last>Kim</last><affiliation>Yonsei University</affiliation></author>
      <author><first>Sejoon</first><last>Kim</last><affiliation>Yonsei University, PwC Korea</affiliation></author>
      <pages>1011-1015</pages>
      <abstract>Translating conversational text, particularly in customer support contexts, presents unique challenges due to its informal and unstructured nature. We propose a context-aware LLM translation system that leverages conversation summarization and dialogue history to enhance translation quality for the English-Korean language pair. Our approach incorporates the two most recent dialogues as raw data and a summary of earlier conversations to manage context length effectively. We demonstrate that this method significantly improves translation accuracy, maintaining coherence and consistency across conversations. This system offers a practical solution for customer support translation tasks, addressing the complexities of conversational text.</abstract>
      <url hash="15111700">2024.wmt-1.102</url>
      <bibkey>sung-etal-2024-context</bibkey>
      <doi>10.18653/v1/2024.wmt-1.102</doi>
    </paper>
    <paper id="103">
      <title>Enhancing Translation Quality: A Comparative Study of Fine-Tuning and Prompt Engineering in Dialog-Oriented Machine Translation Systems. Insights from the <fixed-case>MULTITAN</fixed-case>-<fixed-case>GML</fixed-case> Team</title>
      <author><first>Lichao</first><last>Zhu</last><affiliation>Paris Cité University</affiliation></author>
      <author><first>Maria</first><last>Zimina</last><affiliation>CLILLAC-ARP, Paris Diderot</affiliation></author>
      <author><first>Behnoosh</first><last>Namdarzadeh</last><affiliation>Université Paris Cité</affiliation></author>
      <author><first>Nicolas</first><last>Ballier</last><affiliation>Université de Paris</affiliation></author>
      <author><first>Jean-Baptiste</first><last>Yunès</last><affiliation>Université Paris Cité</affiliation></author>
      <pages>1016-1022</pages>
      <abstract>For this shared task, we have used several machine translation engines to produce translations (en ⇔ fr) by fine-tuning a dialog-oriented NMT engine and having NMT baseline translations post-edited with prompt engineering. Our objectives are to test the effectiveness of a fine-tuning strategy with help of a robust NMT model, to draw out a from-translation-to-post-editing pipeline, and to evaluate the strong and weak points of NMT systems.</abstract>
      <url hash="1743e109">2024.wmt-1.103</url>
      <bibkey>zhu-etal-2024-enhancing</bibkey>
      <doi>10.18653/v1/2024.wmt-1.103</doi>
    </paper>
    <paper id="104">
      <title>The <fixed-case>SETU</fixed-case>-<fixed-case>ADAPT</fixed-case> Submissions to <fixed-case>WMT</fixed-case> 2024 Chat Translation Tasks</title>
      <author><first>Maria</first><last>Zafar</last><affiliation>South East Technological University</affiliation></author>
      <author><first>Antonio</first><last>Castaldo</last><affiliation>University of Naples “L’Orientale”</affiliation></author>
      <author><first>Prashanth</first><last>Nayak</last><affiliation>KantanAI</affiliation></author>
      <author><first>Rejwanul</first><last>Haque</last><affiliation>South East Technological University</affiliation></author>
      <author><first>Andy</first><last>Way</last><affiliation>Dubin City University</affiliation></author>
      <pages>1023-1030</pages>
      <abstract>This paper presents the SETU-ADAPT submissions to the WMT24 Chat Translation Task. Large language models (LLM) currently provides the state-of-the-art solutions in many natural language processing (NLP) problems including machine translation (MT). For the WMT24 Chat Translation Task we leveraged LLMs for their MT capabilities. In order to adapt the LLMs for a specific domain of interest, we explored different fine-tuning and prompting strategies. We also employed efficient data retrieval methods to curate the data used for fine-tuning. We carried out experiments for two language pairs: German-to-English and French-to-English. Our MT models were evaluated using three metrics: BLEU, chrF and COMET. In this paper we describes our experiments including training setups, results and findings.</abstract>
      <url hash="05dd1b9b">2024.wmt-1.104</url>
      <bibkey>zafar-etal-2024-setu-adapt</bibkey>
      <doi>10.18653/v1/2024.wmt-1.104</doi>
    </paper>
    <paper id="105">
      <title>Exploring the Traditional <fixed-case>NMT</fixed-case> Model and Large Language Model for Chat Translation</title>
      <author><first>Jinlong</first><last>Yang</last><affiliation>Huawei Technologies Co., Ltd</affiliation></author>
      <author><first>Hengchao</first><last>Shang</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Daimeng</first><last>Wei</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Jiaxin</first><last>Guo</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Zongyao</first><last>Li</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Zhanglin</first><last>Wu</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Zhiqiang</first><last>Rao</last><affiliation>Huawei Translation Service Center, Beijing, China</affiliation></author>
      <author><first>Shaojun</first><last>Li</last><affiliation>Huawei Technologies Co., Ltd.</affiliation></author>
      <author><first>Yuhao</first><last>Xie</last><affiliation>HW-TSC</affiliation></author>
      <author><first>Yuanchang</first><last>Luo</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Zheng</first><last>Jiawei</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Bin</first><last>Wei</last><affiliation>Huawei Translation Services Center</affiliation></author>
      <author><first>Hao</first><last>Yang</last><affiliation>Huawei Co. Ltd</affiliation></author>
      <pages>1031-1037</pages>
      <abstract>This paper describes the submissions of Huawei Translation Services Center(HW-TSC) to WMT24 chat translation shared task on English↔Germany (en-de) bidirection. The experiments involved fine-tuning models using chat data and exploring various strategies, including Minimum Bayesian Risk (MBR) decoding and self-training. The results show significant performance improvements in certain directions, with the MBR self-training method achieving the best results. The Large Language Model also discusses the challenges and potential avenues for further research in the field of chat translation.</abstract>
      <url hash="e64570d8">2024.wmt-1.105</url>
      <bibkey>yang-etal-2024-exploring-traditional</bibkey>
      <doi>10.18653/v1/2024.wmt-1.105</doi>
    </paper>
    <paper id="106">
      <title>Graph Representations for Machine Translation in Dialogue Settings</title>
      <author><first>Lea</first><last>Krause</last><affiliation>Vrije Universiteit Amsterdam</affiliation></author>
      <author><first>Selene</first><last>Baez Santamaria</last><affiliation>Vrije Universiteit Amsterdam</affiliation></author>
      <author><first>Jan-Christoph</first><last>Kalo</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>1038-1046</pages>
      <abstract>In this paper, we present our approach to the WMT24 - Chat Task, addressing the challenge of translating chat conversations.Chat conversations are characterised by their informal, ungrammatical nature and strong reliance on context posing significant challenges for machine translation systems. To address these challenges, we augment large language models with explicit memory mechanisms designed to enhance coherence and consistency across dialogues. Specifically, we employ graph representations to capture and utilise dialogue context, leveraging concept connectivity as a compressed memory. Our approach ranked second place for Dutch and French, and third place for Portuguese and German, based on COMET-22 scores and human evaluation.</abstract>
      <url hash="aea2dbe4">2024.wmt-1.106</url>
      <bibkey>krause-etal-2024-graph</bibkey>
      <doi>10.18653/v1/2024.wmt-1.106</doi>
    </paper>
    <paper id="107">
      <title>Reducing Redundancy in <fixed-case>J</fixed-case>apanese-to-<fixed-case>E</fixed-case>nglish Translation: A Multi-Pipeline Approach for Translating Repeated Elements in <fixed-case>J</fixed-case>apanese</title>
      <author><first>Qiao</first><last>Wang</last><affiliation>Waseda University</affiliation></author>
      <author><first>Yixuan</first><last>Huang</last><affiliation>Graduate School of International Culture and Communication Studies Waseda University</affiliation></author>
      <author><first>Zheng</first><last>Yuan</last><affiliation>King’s College London</affiliation></author>
      <pages>1047-1055</pages>
      <abstract>This paper presents a multi-pipeline Japanese-to-English machine translation (MT) system designed to address the challenge of translating repeated elements from Japanese into fluent and lexically diverse English. The system is developed as part of the Non-Repetitive Translation Task at WMT24, which focuses on minimizing redundancy while maintaining high translation quality. Our approach utilizes MeCab, the de facto NLP tool for Japanese, for the identification of repeated elements, and Claude Sonnet 3.5, a large language model (LLM), for translation and proofreading. The system effectively accomplishes the shared task by identifying and translating in a diversified manner 89.79% of the 470 repeated instances in the testing dataset, and achieving an average translation quality score of 4.60 out of 5, significantly surpassing the baseline score of 3.88. Analysis also revealed the challenges encountered, particularly in identifying standalone noun-suffix elements and occasional cases of consistent translations or mistranslations.</abstract>
      <url hash="3fd17baf">2024.wmt-1.107</url>
      <bibkey>wang-etal-2024-reducing</bibkey>
      <doi>10.18653/v1/2024.wmt-1.107</doi>
    </paper>
    <paper id="108">
      <title><fixed-case>SYSTRAN</fixed-case> @ <fixed-case>WMT</fixed-case>24 Non-Repetitive Translation Task</title>
      <author><first>Marko</first><last>Avila</last><affiliation>CHAPSVISION</affiliation></author>
      <author><first>Josep</first><last>Crego</last><affiliation>CHAPSVISION</affiliation></author>
      <pages>1056-1062</pages>
      <abstract>Many contemporary NLP systems rely on neural decoders for text generation, which demonstrate an impressive ability to generate text approaching human fluency levels. However, in the case of neural machine translation networks, they often grapple with the production of repetitive content, also known as repetitive diction or word repetition, an aspect they weren’t explicitly trained to address. While not inherently negative, this repetition can make writing seem monotonous or awkward if not used intentionally for emphasis or stylistic purposes. This paper presents our submission to the WMT 2024 Non-Repetitive Translation Task, for which we adopt a repetition penalty method applied at learning inspired by the principles of label smoothing. No additional work is needed at inference time. We modify the ground-truth distribution to steer the model towards discouraging repetitions. Experiments show the ability of the proposed methods in reducing repetitions within neural machine translation engines, without compromising efficiency or translation quality.</abstract>
      <url hash="725c0945">2024.wmt-1.108</url>
      <bibkey>avila-crego-2024-systran</bibkey>
      <doi>10.18653/v1/2024.wmt-1.108</doi>
    </paper>
    <paper id="109">
      <title>Mitigating Metric Bias in Minimum <fixed-case>B</fixed-case>ayes Risk Decoding</title>
      <author><first>Geza</first><last>Kovacs</last><affiliation>Google</affiliation></author>
      <author><first>Daniel</first><last>Deutsch</last><affiliation>Google</affiliation></author>
      <author><first>Markus</first><last>Freitag</last><affiliation>Google Research</affiliation></author>
      <pages>1063-1094</pages>
      <abstract>While Minimum Bayes Risk (MBR) decoding using metrics such as COMET or MetricX has outperformed traditional decoding methods such as greedy or beam search, it introduces a challenge we refer to as metric bias. As MBR decoding aims to produce translations that score highly according to a specific utility metric, this very process makes it impossible to use the same metric for both decoding and evaluation, as any improvement might simply be due to reward hacking rather than reflecting real quality improvements. In this work we demonstrate that compared to human ratings, neural metrics not only overestimate the quality of MBR decoding when the same metric is used as the utility metric, but they also overestimate the quality of MBR/QE decoding with other neural utility metrics as well. We also show that the metric bias issue can be mitigated by using an ensemble of utility metrics during MBR decoding: human evaluations show that MBR decoding using an ensemble of utility metrics outperforms a single utility metric.</abstract>
      <url hash="40bdc032">2024.wmt-1.109</url>
      <bibkey>kovacs-etal-2024-mitigating</bibkey>
      <doi>10.18653/v1/2024.wmt-1.109</doi>
    </paper>
    <paper id="110">
      <title>Beyond Human-Only: Evaluating Human-Machine Collaboration for Collecting High-Quality Translation Data</title>
      <author><first>Zhongtao</first><last>Liu</last><affiliation>Google</affiliation></author>
      <author><first>Parker</first><last>Riley</last><affiliation>Google Translate</affiliation></author>
      <author><first>Daniel</first><last>Deutsch</last><affiliation>Google</affiliation></author>
      <author><first>Alison</first><last>Lui</last><affiliation>Google Translate</affiliation></author>
      <author><first>Mengmeng</first><last>Niu</last><affiliation>Google Translate</affiliation></author>
      <author><first>Apurva</first><last>Shah</last><affiliation>Google Inc</affiliation></author>
      <author><first>Markus</first><last>Freitag</last><affiliation>Google Research</affiliation></author>
      <pages>1095-1106</pages>
      <abstract>Collecting high-quality translations is crucial for the development and evaluation of machine translation systems. However, traditional human-only approaches are costly and slow. This study presents a comprehensive investigation of 11 approaches for acquiring translation data, including human-only, machine-only, and hybrid approaches. Our findings demonstrate that human-machine collaboration can match or even exceed the quality of human-only translations, while being more cost-efficient. Error analysis reveals the complementary strengths between human and machine contributions, highlighting the effectiveness of collaborative methods. Cost analysis further demonstrates the economic benefits of human-machine collaboration methods, with some approaches achieving top-tier quality at around 60% of the cost of traditional methods. We release a publicly available dataset containing nearly 18,000 segments of varying translation quality with corresponding human ratings to facilitate future research.</abstract>
      <url hash="5daaf200">2024.wmt-1.110</url>
      <bibkey>liu-etal-2024-beyond-human</bibkey>
      <doi>10.18653/v1/2024.wmt-1.110</doi>
    </paper>
    <paper id="111">
      <title>How Effective Are State Space Models for Machine Translation?</title>
      <author><first>Hugo</first><last>Pitorro</last><affiliation>Technical University of Munich</affiliation></author>
      <author><first>Pavlo</first><last>Vasylenko</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Marcos</first><last>Treviso</last><affiliation>Instituto de Telecomunicacoes</affiliation></author>
      <author><first>André</first><last>Martins</last><affiliation>Unbabel, Instituto de Telecomunicacoes</affiliation></author>
      <pages>1107-1124</pages>
      <abstract>Transformers are the current architecture of choice for NLP, but their attention layers do not scale well to long contexts. Recent works propose to replace attention with linear recurrent layers - this is the case for state space models, which enjoy efficient training and inference. However, it remains unclear whether these models are competitive with transformers in machine translation (MT). In this paper, we provide a rigorous and comprehensive experimental comparison between transformers and linear recurrent models for MT. Concretely, we experiment with RetNet, Mamba, and hybrid versions of Mamba which incorporate attention mechanisms. Our findings demonstrate that Mamba is highly competitive with transformers on sentence and paragraph-level datasets, where in the latter both models benefit from shifting the training distribution towards longer sequences. Further analysis show that integrating attention into Mamba improves translation quality, robustness to sequence length extrapolation, and the ability to recall named entities.</abstract>
      <url hash="9ff7414c">2024.wmt-1.111</url>
      <bibkey>pitorro-etal-2024-effective</bibkey>
      <doi>10.18653/v1/2024.wmt-1.111</doi>
    </paper>
    <paper id="112">
      <title>Evaluation and Large-scale Training for Contextual Machine Translation</title>
      <author><first>Matt</first><last>Post</last><affiliation>Microsoft</affiliation></author>
      <author><first>Marcin</first><last>Junczys-Dowmunt</last><affiliation>Microsoft</affiliation></author>
      <pages>1125-1139</pages>
      <abstract>Despite the fact that context is known to be vital for resolving a range of translation ambiguities, most traditional machine translation systems continue to be trained and to operate at the sentence level. A common explanation is the lack of document-level annotations for existing training data. This work investigates whether having such annotations would be helpful for training traditional MT systems at scale. We build large-scale, state-of-the-art contextual MT systems into German, French, and Russian, fixing the datasets while comparing the effect of sourcing contextual training samples from both parallel and back-translated data. We then evaluate these contextual models across a range of contextual test sets from the literature, where we find that (a) document annotations from both mined parallel and back-translated monolingual data are helpful, but that the best contextual MT systems do not draw contextual samples from the parallel data. We also make two points related to evaluation: (b) contrastive score-based metrics on challenge sets are not discriminative; instead, models must be tested directly on their ability to generate correct outputs, and (c) standard corpus-level metrics such as COMET work best in settings that are dense in contextual phenomena.</abstract>
      <url hash="8006c2ea">2024.wmt-1.112</url>
      <bibkey>post-junczys-dowmunt-2024-evaluation</bibkey>
      <doi>10.18653/v1/2024.wmt-1.112</doi>
    </paper>
    <paper id="113">
      <title>A Multi-task Learning Framework for Evaluating Machine Translation of Emotion-loaded User-generated Content</title>
      <author><first>Shenbin</first><last>Qian</last><affiliation>University of Surrey</affiliation></author>
      <author><first>Constantin</first><last>Orasan</last><affiliation>University of Surrey</affiliation></author>
      <author><first>Diptesh</first><last>Kanojia</last><affiliation>University of Surrey</affiliation></author>
      <author><first>Félix</first><last>Do Carmo</last><affiliation>University of Surrey</affiliation></author>
      <pages>1140-1154</pages>
      <abstract>Machine translation (MT) of user-generated content (UGC) poses unique challenges, including handling slang, emotion, and literary devices like irony and sarcasm. Evaluating the quality of these translations is challenging as current metrics do not focus on these ubiquitous features of UGC. To address this issue, we utilize an existing emotion-related dataset that includes emotion labels and human-annotated translation errors based on Multi-dimensional Quality Metrics. We extend it with sentence-level evaluation scores and word-level labels, leading to a dataset suitable for sentence- and word-level translation evaluation and emotion classification, in a multi-task setting. We propose a new architecture to perform these tasks concurrently, with a novel combined loss function, which integrates different loss heuristics, like the Nash and Aligned losses. Our evaluation compares existing fine-tuning and multi-task learning approaches, assessing generalization with ablative experiments over multiple datasets. Our approach achieves state-of-the-art performance and we present a comprehensive analysis for MT evaluation of UGC.</abstract>
      <url hash="c378a55b">2024.wmt-1.113</url>
      <bibkey>qian-etal-2024-multi</bibkey>
      <doi>10.18653/v1/2024.wmt-1.113</doi>
    </paper>
    <paper id="114">
      <title>On Instruction-Finetuning Neural Machine Translation Models</title>
      <author><first>Vikas</first><last>Raunak</last><affiliation>Microsoft</affiliation></author>
      <author><first>Roman</first><last>Grundkiewicz</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Marcin</first><last>Junczys-Dowmunt</last><affiliation>Microsoft</affiliation></author>
      <pages>1155-1166</pages>
      <abstract>In this work, we introduce instruction finetuning for Neural Machine Translation (NMT) models, which distills instruction following capabilities from Large Language Models (LLMs) into orders-of-magnitude smaller NMT models. Our instruction-finetuning recipe for NMT models enables customization of translations for a limited but disparate set of translation-specific tasks.We show that NMT models are capable of following multiple instructions simultaneously and demonstrate capabilities of zero-shot composition of instructions.We also show that through instruction finetuning, traditionally disparate tasks such as formality-controlled machine translation, multi-domain adaptation as well as multi-modal translations can be tackled jointly by a single instruction finetuned NMT model, at a performance level comparable to LLMs such as GPT-3.5-Turbo.To the best of our knowledge, our work is among the first to demonstrate the instruction-following capabilities of traditional NMT models, which allows for faster, cheaper and more efficient serving of customized translations.</abstract>
      <url hash="1fe02a59">2024.wmt-1.114</url>
      <bibkey>raunak-etal-2024-instruction</bibkey>
      <doi>10.18653/v1/2024.wmt-1.114</doi>
    </paper>
    <paper id="115">
      <title>Benchmarking Visually-Situated Translation of Text in Natural Images</title>
      <author><first>Elizabeth</first><last>Salesky</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Philipp</first><last>Koehn</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Matt</first><last>Post</last><affiliation>Microsoft</affiliation></author>
      <pages>1167-1182</pages>
      <abstract>We introduce a benchmark, Vistra, for visually-situated translation of English text in natural images to four target languages. We describe the dataset construction and composition. We benchmark open-source and commercial OCR and MT models on Vistra, and present both quantitative results and a taxonomy of common OCR error classes with their effect on downstream MT. Finally, we assess direct image-to-text translation with a multimodal LLM, and show that it is able in some cases but not yet consistently to disambiguate possible translations with visual context. We show that this is an unsolved and challenging task even for strong commercial models. We hope that the creation and release of this benchmark which is the first of its kind for these language pairs will encourage further research in this direction.</abstract>
      <url hash="befd90c5">2024.wmt-1.115</url>
      <bibkey>salesky-etal-2024-benchmarking</bibkey>
      <doi>10.18653/v1/2024.wmt-1.115</doi>
    </paper>
    <paper id="116">
      <title>Analysing Translation Artifacts: A Comparative Study of <fixed-case>LLM</fixed-case>s, <fixed-case>NMT</fixed-case>s, and Human Translations</title>
      <author><first>Fedor</first><last>Sizov</last><affiliation>Saarland University</affiliation></author>
      <author><first>Cristina</first><last>España-Bonet</last><affiliation>DFKI GmbH</affiliation></author>
      <author><first>Josef</first><last>Van Genabith</last><affiliation>DFKI</affiliation></author>
      <author><first>Roy</first><last>Xie</last><affiliation>Duke University</affiliation></author>
      <author><first>Koel</first><last>Dutta Chowdhury</last><affiliation>Saarland Informatics Campus,Saarland University</affiliation></author>
      <pages>1183-1199</pages>
      <abstract>Translated texts exhibit a range of characteristics that make them appear distinct from texts originally written in the same target language. With the rise of Large Language Models (LLMs), which are designed for a wide range of language generation and understanding tasks, there has been significant interest in their application to Machine Translation. While several studies have focused on improving translation quality through fine-tuning or few-shot prompting techniques, there has been limited exploration of how LLM-generated translations qualitatively differ from those produced by Neural Machine Translation (NMT) models, and human translations. Our study employs explainability methods such as Leave-One-Out (LOO) and Integrated Gradients (IG) to analyze the lexical features distinguishing human translations from those produced by LLMs and NMT systems. Specifically, we apply a two-stage approach: first, classifying texts based on their origin – whether they are original or translations – and second, extracting significant lexical features (highly attributed input words) using post-hoc interpretability methods. Our analysis shows that different methods of feature extraction vary in their effectiveness, with LOO being generally better at pinpointing critical input words and IG capturing a broader range of important words. Finally, our results show that while LLMs and NMT systems can produce translations of a good quality, they still differ from texts originally written by native speakers. Specifically, we find that while some LLMs often align closely with human translations, traditional NMT systems exhibit distinct characteristics, particularly in their use of certain linguistic features.</abstract>
      <url hash="c463ec29">2024.wmt-1.116</url>
      <bibkey>sizov-etal-2024-analysing</bibkey>
      <doi>10.18653/v1/2024.wmt-1.116</doi>
    </paper>
    <paper id="117">
      <title>How Grammatical Features Impact Machine Translation: A New Test Suite for <fixed-case>C</fixed-case>hinese-<fixed-case>E</fixed-case>nglish <fixed-case>MT</fixed-case> Evaluation</title>
      <author><first>Huacheng</first><last>Song</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Yi</first><last>Li</last><affiliation>Shanghai International Studies University</affiliation></author>
      <author><first>Yiwen</first><last>Wu</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Yu</first><last>Liu</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Jingxia</first><last>Lin</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Hongzhi</first><last>Xu</last><affiliation>Shanghai International Studies University</affiliation></author>
      <pages>1200-1221</pages>
      <abstract>Machine translation (MT) evaluation has evolved toward a trend of fine-grained granularity, enabling a more precise diagnosis of hidden flaws and weaknesses of MT systems from various perspectives. This paper examines how MT systems are potentially affected by certain grammatical features, offering insights into the challenges these features pose and suggesting possible directions for improvement. We develop a new test suite by extracting 7,848 sentences from a multi-domain Chinese-English parallel corpus. All the Chinese text was further annotated with 43 grammatical features using a semi-automatic method. This test suite was subsequently used to evaluate eight state-of-the-art MT systems according to six different automatic evaluation metrics. The results reveal intriguing patterns of MT performance associated with different domains and various grammatical features, highlighting the test suite’s effectiveness. The test suite was made publicly available and it will serve as an important benchmark for evaluating and diagnosing Chinese-English MT systems.</abstract>
      <url hash="677514bd">2024.wmt-1.117</url>
      <bibkey>song-etal-2024-grammatical</bibkey>
      <doi>10.18653/v1/2024.wmt-1.117</doi>
    </paper>
    <paper id="118">
      <title>Improving Statistical Significance in Human Evaluation of Automatic Metrics via Soft Pairwise Accuracy</title>
      <author><first>Brian</first><last>Thompson</last><affiliation>Amazon</affiliation></author>
      <author><first>Nitika</first><last>Mathur</last><affiliation>The University of Melbourne</affiliation></author>
      <author><first>Daniel</first><last>Deutsch</last><affiliation>Google</affiliation></author>
      <author><first>Huda</first><last>Khayrallah</last><affiliation>Microsoft</affiliation></author>
      <pages>1222-1234</pages>
      <abstract>Selecting an automatic metric that best emulates human annotators is often non-trivial, because there is no clear definition of “best emulates.” A meta-metric is required to compare the human judgments to the automatic metric scores, and metric rankings depend on the choice of meta-metric. We propose Soft Pairwise Accuracy (SPA), a new meta-metric that builds on Pairwise Accuracy (PA) but incorporates the statistical significance of both the human judgments and the metric scores. We show that SPA is more stable than PA with respect to changes in the number of systems/segments used for evaluation. We also show that PA can only assign a small set of distinct output values to metrics, and this results in many metrics being artificially assigned the exact same PA score. We demonstrate that SPA fixes this issue. Finally, we show that SPA is more discriminative than PA, producing more statistically significant comparisons between metrics. SPA was selected as the official system-level metric for the 2024 WMT Metrics Shared Task.</abstract>
      <url hash="69654eb0">2024.wmt-1.118</url>
      <bibkey>thompson-etal-2024-improving</bibkey>
      <doi>10.18653/v1/2024.wmt-1.118</doi>
    </paper>
    <paper id="119">
      <title>Speech Is More than Words: Do Speech-to-Text Translation Systems Leverage Prosody?</title>
      <author><first>Ioannis</first><last>Tsiamas</last><affiliation>Polytechnic University of Catalonia (UPC)</affiliation></author>
      <author><first>Matthias</first><last>Sperber</last><affiliation>Apple</affiliation></author>
      <author><first>Andrew</first><last>Finch</last><affiliation>Apple Inc.</affiliation></author>
      <author><first>Sarthak</first><last>Garg</last><affiliation>Apple</affiliation></author>
      <pages>1235-1257</pages>
      <abstract>The prosody of a spoken utterance, including features like stress, intonation and rhythm, can significantly affect the underlying semantics, and as a consequence can also affect its textual translation. Nevertheless, prosody is rarely studied within the context of speech-to-text translation (S2TT) systems. In particular, end-to-end (E2E) systems have been proposed as well-suited for prosody-aware translation because they have direct access to the speech signal when making translation decisions, but the understanding of whether this is successful in practice is still limited. A main challenge is the difficulty of evaluating prosody awareness in translation. To address this challenge, we introduce an evaluation methodology and a focused benchmark (named ContraProSt) aimed at capturing a wide range of prosodic phenomena. Our methodology uses large language models and controllable text-to-speech (TTS) to generate contrastive examples. Through experiments in translating English speech into German, Spanish, and Japanese, we find that (a) S2TT models possess some internal representation of prosody, but the prosody signal is often not strong enough to affect the translations, (b) E2E systems outperform cascades of speech recognition and text translation systems, confirming their theoretical advantage in this regard, and (c) certain cascaded systems also capture prosodic information in the translation, but only to a lesser extent that depends on the particulars of the transcript’s surface form.</abstract>
      <url hash="84609d32">2024.wmt-1.119</url>
      <bibkey>tsiamas-etal-2024-speech</bibkey>
      <doi>10.18653/v1/2024.wmt-1.119</doi>
    </paper>
    <paper id="120">
      <title>Cultural Adaptation of Menus: A Fine-Grained Approach</title>
      <author><first>Zhonghe</first><last>Zhang</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Xiaoyu</first><last>He</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Vivek</first><last>Iyer</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Alexandra</first><last>Birch</last><affiliation>University of Edinburgh</affiliation></author>
      <pages>1258-1271</pages>
      <abstract>Machine Translation of Culture-Specific Items (CSIs) poses significant challenges. Recent work on CSI translation has shown some success using Large Language Models (LLMs) to adapt to different languages and cultures; however, a deeper analysis is needed to examine the benefits and pitfalls of each method. In this paper, we introduce the ChineseMenuCSI dataset, the largest for Chinese-English menu corpora, annotated with CSI vs Non-CSI labels and a fine-grained test set. We define three levels of CSI figurativeness for a more nuanced analysis and develop a novel methodology for automatic CSI identification, which outperforms GPT-based prompts in most categories. Importantly, we are the first to integrate human translation theories into LLM-driven translation processes, significantly improving translation accuracy, with COMET scores increasing by up to 7 points. The code and dataset are available at https://github.com/Henry8772/ChineseMenuCSI.</abstract>
      <url hash="ee243c75">2024.wmt-1.120</url>
      <bibkey>zhang-etal-2024-cultural</bibkey>
      <doi>10.18653/v1/2024.wmt-1.120</doi>
    </paper>
    <paper id="121">
      <title>Pitfalls and Outlooks in Using <fixed-case>COMET</fixed-case></title>
      <author><first>Vilém</first><last>Zouhar</last><affiliation>ETH Zurich, Charles University</affiliation></author>
      <author><first>Pinzhen</first><last>Chen</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Tsz Kin</first><last>Lam</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Nikita</first><last>Moghe</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Barry</first><last>Haddow</last><affiliation>University of Edinburgh</affiliation></author>
      <pages>1272-1288</pages>
      <abstract>The COMET metric has blazed a trail in the machine translation community, given its strong correlation with human judgements of translation quality.Its success stems from being a modified pre-trained multilingual model finetuned for quality assessment.However, it being a machine learning model also gives rise to a new set of pitfalls that may not be widely known. We investigate these unexpected behaviours from three aspects:1) technical: obsolete software versions and compute precision; 2) data: empty content, language mismatch, and translationese at test time as well as distribution and domain biases in training; 3) usage and reporting: multi-reference support and model referencing in the literature. All of these problems imply that COMET scores are not comparable between papers or even technical setups and we put forward our perspective on fixing each issue.Furthermore, we release the sacreCOMET package that can generate a signature for the software and model configuration as well as an appropriate citation.The goal of this work is to help the community make more sound use of the COMET metric.</abstract>
      <url hash="9f7bfa0f">2024.wmt-1.121</url>
      <bibkey>zouhar-etal-2024-pitfalls</bibkey>
      <doi>10.18653/v1/2024.wmt-1.121</doi>
    </paper>
    <paper id="122">
      <title>Post-edits Are Preferences Too</title>
      <author><first>Nathaniel</first><last>Berger</last><affiliation>Heidelberg University</affiliation></author>
      <author><first>Stefan</first><last>Riezler</last><affiliation>Heidelberg University</affiliation></author>
      <author><first>Miriam</first><last>Exel</last><affiliation>SAP SE</affiliation></author>
      <author><first>Matthias</first><last>Huck</last><affiliation>SAP SE</affiliation></author>
      <pages>1289-1300</pages>
      <abstract>Preference Optimization (PO) techniques are currently one of the state of the art techniques for fine-tuning large language models (LLMs) on pairwise preference feedback from human annotators. However, in machine translation, this sort of feedback can be difficult to solicit. Additionally, Kreuzer et al. (2018) have shown that, for machine translation, pairwise preferences are less reliable than other forms of human feedback, such as 5-point ratings.We examine post-edits to see if they can be a source of reliable human preferences by construction. In PO, a human annotator is shown sequences $s_1$ and $s_2$ and asked for a preference judgment, while for post-editing, editors create $s_1$ and know that it should be better than $s_2$. We attempt to use these implicit preferences for PO and show that it helps the model move towards post-edit like hypotheses and away from machine translation-like hypotheses. Furthermore, we show that best results are obtained by pre-training the model with supervised fine-tuning (SFT) on post-edits in order to promote post-edit like hypotheses to the top output ranks.</abstract>
      <url hash="c65f8d6e">2024.wmt-1.122</url>
      <bibkey>berger-etal-2024-post</bibkey>
      <doi>10.18653/v1/2024.wmt-1.122</doi>
    </paper>
    <paper id="123">
      <title>Translating Step-by-Step: Decomposing the Translation Process for Improved Translation Quality of Long-Form Texts</title>
      <author><first>Eleftheria</first><last>Briakou</last><affiliation>Google</affiliation></author>
      <author><first>Jiaming</first><last>Luo</last><affiliation>Google</affiliation></author>
      <author><first>Colin</first><last>Cherry</last><affiliation>Google</affiliation></author>
      <author><first>Markus</first><last>Freitag</last><affiliation>Google Research</affiliation></author>
      <pages>1301-1317</pages>
      <abstract>In this paper we present a step-by-step approach to long-form text translation, drawing on established processes in translation studies. Instead of viewing machine translation as a single, monolithic task, we propose a framework that engages language models in a multi-turn interaction, encompassing pre-translation research, drafting, refining, and proofreading, resulting in progressively improved translations.Extensive automatic evaluations using Gemini 1.5 Pro across ten language pairs show that translating step-by-step yields large translation quality improvements over conventional zero-shot prompting approaches and earlier human-like baseline strategies, resulting in state-of-the-art results on WMT 2024.</abstract>
      <url hash="0b8c3a56">2024.wmt-1.123</url>
      <bibkey>briakou-etal-2024-translating</bibkey>
      <doi>10.18653/v1/2024.wmt-1.123</doi>
    </paper>
    <paper id="124">
      <title>Scaling Laws of Decoder-Only Models on the Multilingual Machine Translation Task</title>
      <author><first>Gaëtan</first><last>Caillaut</last><affiliation>Lingua Custodia</affiliation></author>
      <author><first>Mariam</first><last>Nakhlé</last><affiliation>Lingua Custodia</affiliation></author>
      <author><first>Raheel</first><last>Qader</last><affiliation>Lingua Custodia</affiliation></author>
      <author><first>Jingshu</first><last>Liu</last><affiliation>Lingua Custodia</affiliation></author>
      <author><first>Jean-Gabriel</first><last>Barthélemy</last><affiliation>Lingua Custodia</affiliation></author>
      <pages>1318-1331</pages>
      <abstract>Recent studies have showcased remarkable capabilities of decoder-only models in many NLP tasks, including translation. Yet, the machine translation field has been largely dominated by encoder-decoder models based on the Transformer architecture. As a consequence, scaling laws of encoder-decoder models for neural machine translation have already been well studied, but decoder-only models have received less attention.This work explores the scaling laws of decoder-only models on the multilingual and multidomain translation task. We trained a collection of six decoder-only models, ranging from 70M to 7B parameters, on a sentence-level, multilingual (8 languages) and multidomain (9 domains) dataset. We conducted a series of experiments showing that the loss of decoder-only models can be estimated using a scaling law similar to the one discovered for large language models, but we also show that this scaling law has difficulties to generalize to too large models or to a different data distribution. We also study different scaling methods and show that scaling the depth and the width of a model lead to similar test loss improvements, but with different impact on the model’s efficiency.</abstract>
      <url hash="5a4691b8">2024.wmt-1.124</url>
      <bibkey>caillaut-etal-2024-scaling</bibkey>
      <doi>10.18653/v1/2024.wmt-1.124</doi>
    </paper>
    <paper id="125">
      <title>Shortcomings of <fixed-case>LLM</fixed-case>s for Low-Resource Translation: Retrieval and Understanding Are Both the Problem</title>
      <author><first>Sara</first><last>Court</last><affiliation>The Ohio State University</affiliation></author>
      <author><first>Micha</first><last>Elsner</last><affiliation>The Ohio State University</affiliation></author>
      <pages>1332-1354</pages>
      <abstract>This work investigates the in-context learning abilities of pretrained large language models (LLMs) when instructed to translate text from a low-resource language into a high-resource language as part of an automated machine translation pipeline. We conduct a set of experiments translating Southern Quechua to Spanish and examine the informativity of various types of information retrieved from a constrained database of digitized pedagogical materials (dictionaries and grammar lessons) and parallel corpora. Using both automatic and human evaluation of model output, we conduct ablation studies that manipulate (1) context type (morpheme translations, grammar descriptions, and corpus examples), (2) retrieval methods (automated vs. manual), and (3) model type. Our results suggest that even relatively small LLMs are capable of utilizing prompt context for zero-shot low-resource translation when provided a minimally sufficient amount of relevant linguistic information. However, the variable effects of prompt type, retrieval method, model type, and language community-specific factors highlight the limitations of using even the best LLMs as translation systems for the majority of the world’s 7,000+ languages and their speakers.</abstract>
      <url hash="01f59d35">2024.wmt-1.125</url>
      <bibkey>court-elsner-2024-shortcomings</bibkey>
      <doi>10.18653/v1/2024.wmt-1.125</doi>
    </paper>
    <paper id="126">
      <title>Introducing the <fixed-case>N</fixed-case>ews<fixed-case>P</fixed-case>a<fixed-case>LM</fixed-case> <fixed-case>MBR</fixed-case> and <fixed-case>QE</fixed-case> Dataset: <fixed-case>LLM</fixed-case>-Generated High-Quality Parallel Data Outperforms Traditional Web-Crawled Data</title>
      <author><first>Mara</first><last>Finkelstein</last><affiliation>Google</affiliation></author>
      <author><first>David</first><last>Vilar</last><affiliation>Google</affiliation></author>
      <author><first>Markus</first><last>Freitag</last><affiliation>Google Research</affiliation></author>
      <pages>1355-1372</pages>
      <abstract>Recent research in neural machine translation (NMT) has shown that training on high-quality machine-generated data can outperform training on human-generated data. This work accompanies the first-ever release of a LLM-generated, MBR-decoded and QE-reranked dataset with both sentence-level and multi-sentence examples. We perform extensive experiments to demonstrate the quality of our dataset in terms of its downstream impact on NMT model performance. We find that training from scratch on our (machine-generated) dataset outperforms training on the (web-crawled) WMT’23 training dataset (which is 300 times larger), and also outperforms training on the top-quality subset of the WMT’23 training dataset. We also find that performing self-distillation by finetuning the LLM which generated this dataset outperforms the LLM’s strong few-shot baseline. These findings corroborate the quality of our dataset, and demonstrate the value of high-quality machine-generated data in improving performance of NMT models.</abstract>
      <url hash="7cb443f3">2024.wmt-1.126</url>
      <bibkey>finkelstein-etal-2024-introducing</bibkey>
      <doi>10.18653/v1/2024.wmt-1.126</doi>
    </paper>
    <paper id="127">
      <title>Is Preference Alignment Always the Best Option to Enhance <fixed-case>LLM</fixed-case>-Based Translation? An Empirical Analysis</title>
      <author><first>Hippolyte</first><last>Gisserot-Boukhlef</last><affiliation>MICS-CentraleSupelec/Artefact</affiliation></author>
      <author><first>Ricardo</first><last>Rei</last><affiliation>Unbabel/INESC-ID</affiliation></author>
      <author><first>Emmanuel</first><last>Malherbe</last><affiliation>Artefact</affiliation></author>
      <author><first>Céline</first><last>Hudelot</last><affiliation>MICS-CentraleSupelec</affiliation></author>
      <author><first>Pierre</first><last>Colombo</last><affiliation>L2S CentraleSupelec</affiliation></author>
      <author><first>Nuno M.</first><last>Guerreiro</last><affiliation>Instituto de Telecomunicacoes, University of Lisbon</affiliation></author>
      <pages>1373-1392</pages>
      <abstract>Neural metrics for machine translation (MT) evaluation have become increasingly prominent due to their superior correlation with human judgments compared to traditional lexical metrics. Researchers have therefore utilized neural metrics through quality-informed decoding strategies, achieving better results than likelihood-based methods. With the rise of Large Language Models (LLMs), preference-based alignment techniques have gained attention for their potential to enhance translation quality by optimizing model weights directly on preferences induced by quality estimators. This study focuses on Contrastive Preference Optimization (CPO) and conducts extensive experiments to evaluate the impact of preference-based alignment on translation quality. Our findings indicate that while CPO consistently outperforms Supervised Fine-Tuning (SFT) on high-quality data with regard to the alignment metric, it may lead to instability across downstream evaluation metrics, particularly between neural and lexical ones. Additionally, we demonstrate that relying solely on the base model for generating candidate translations achieves performance comparable to using multiple external systems, while ensuring better consistency across downstream metrics.</abstract>
      <url hash="1eaac882">2024.wmt-1.127</url>
      <bibkey>gisserot-boukhlef-etal-2024-preference</bibkey>
      <doi>10.18653/v1/2024.wmt-1.127</doi>
    </paper>
    <paper id="128">
      <title>Quality or Quantity? On Data Scale and Diversity in Adapting Large Language Models for Low-Resource Translation</title>
      <author><first>Vivek</first><last>Iyer</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Bhavitvya</first><last>Malik</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Pavel</first><last>Stepachev</last><affiliation>The University of Edinburgh</affiliation></author>
      <author><first>Pinzhen</first><last>Chen</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Barry</first><last>Haddow</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Alexandra</first><last>Birch</last><affiliation>University of Edinburgh</affiliation></author>
      <pages>1393-1409</pages>
      <abstract>Despite the recent popularity of Large Language Models (LLMs) in Machine Translation (MT), their performance in low-resource languages (LRLs) still lags significantly behind Neural Machine Translation (NMT) models. In this work, we explore what it would take to adapt LLMs for the low-resource setting. Particularly, we re-examine the role of two factors: a) the importance and application of parallel data, and b) diversity in Supervised Fine-Tuning (SFT). Recently, parallel data has seen reduced use in adapting LLMs for MT, while data diversity has been embraced to promote transfer across languages and tasks. However, for low-resource LLM-MT, we show that the opposite is true for both considerations: a) <i>parallel data</i> is critical during both pre-training and SFT; b) diversity tends to cause <i>interference</i> instead of transfer. Our experiments with three LLMs across two low-resourced language groups—Indigenous American and North-East Indian—reveal consistent trends, underscoring the generalizability of our findings. We believe these insights will be valuable for scaling to massively multilingual LLM-MT models that can effectively serve LRLs.</abstract>
      <url hash="ae1619c1">2024.wmt-1.128</url>
      <bibkey>iyer-etal-2024-quality</bibkey>
      <doi>10.18653/v1/2024.wmt-1.128</doi>
    </paper>
    <paper id="129">
      <title>Efficient Technical Term Translation: A Knowledge Distillation Approach for Parenthetical Terminology Translation</title>
      <author><first>Myung</first><last>Jiyoon</last><affiliation>Modulabs</affiliation></author>
      <author><first>Jihyeon</first><last>Park</last><affiliation>Modulabs</affiliation></author>
      <author><first>Jungki</first><last>Son</last><affiliation>Modulabs</affiliation></author>
      <author><first>Kyungro</first><last>Lee</last><affiliation>Modulabs</affiliation></author>
      <author><first>Joohyung</first><last>Han</last><affiliation>Modulabs</affiliation></author>
      <pages>1410-1427</pages>
      <abstract>This paper addresses the challenge of accurately translating technical terms, which are crucial for clear communication in specialized fields. We introduce the Parenthetical Terminology Translation (PTT) task, designed to mitigate potential inaccuracies by displaying the original term in parentheses alongside its translation. To implement this approach, we generated a representative PTT dataset using a collaborative approach with large language models and applied knowledge distillation to fine-tune traditional Neural Machine Translation (NMT) models and small-sized Large Language Models (sLMs). Additionally, we developed a novel evaluation metric to assess both overall translation accuracy and the correct parenthetical presentation of terms. Our findings indicate that sLMs did not consistently outperform NMT models, with fine-tuning proving more effective than few-shot prompting, particularly in models with continued pre-training in the target language. These insights contribute to the advancement of more reliable terminology translation methodologies.</abstract>
      <url hash="0e19a1bb">2024.wmt-1.129</url>
      <bibkey>jiyoon-etal-2024-efficient</bibkey>
      <doi>10.18653/v1/2024.wmt-1.129</doi>
    </paper>
    <paper id="130">
      <title>Assessing the Role of Imagery in Multimodal Machine Translation</title>
      <author><first>Nicholas</first><last>Kashani Motlagh</last><affiliation>Ohio State University</affiliation></author>
      <author><first>Jim</first><last>Davis</last><affiliation>Ohio State University</affiliation></author>
      <author><first>Jeremy</first><last>Gwinnup</last><affiliation>Air Force Research Laboratory</affiliation></author>
      <author><first>Grant</first><last>Erdmann</last><affiliation>Air Force Research Laboratory</affiliation></author>
      <author><first>Tim</first><last>Anderson</last><affiliation>Air Force Research Laboratory</affiliation></author>
      <pages>1428-1439</pages>
      <abstract>In Multimodal Machine Translation (MMT), the use of visual data has shown only marginal improvements compared to text-only models. Previously, the CoMMuTE dataset and associated metric were proposed to score models on tasks where the imagery is necessary to disambiguate between two possible translations for each ambiguous source sentence. In this work, we introduce new metrics within the CoMMuTE domain to provide deeper insights into image-aware translation models. Our proposed metrics differ from the previous CoMMuTE scoring method by 1) assessing the impact of multiple images on individual translations and 2) evaluating a model’s ability to jointly select each translation for each image context. Our results challenge the conventional views of poor visual comprehension capabilities of MMT models and show that models can indeed meaningfully interpret visual information, though they may not leverage it sufficiently in the final decision.</abstract>
      <url hash="dcac855a">2024.wmt-1.130</url>
      <bibkey>kashani-motlagh-etal-2024-assessing</bibkey>
      <doi>10.18653/v1/2024.wmt-1.130</doi>
    </paper>
    <paper id="131">
      <title>Error Span Annotation: A Balanced Approach for Human Evaluation of Machine Translation</title>
      <author><first>Tom</first><last>Kocmi</last><affiliation>Cohere</affiliation></author>
      <author><first>Vilém</first><last>Zouhar</last><affiliation>ETH Zurich, Charles University</affiliation></author>
      <author><first>Eleftherios</first><last>Avramidis</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Roman</first><last>Grundkiewicz</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Marzena</first><last>Karpinska</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <author><first>Maja</first><last>Popović</last><affiliation>ADAPT, Dublin City University</affiliation></author>
      <author><first>Mrinmaya</first><last>Sachan</last><affiliation>ETH Zurich</affiliation></author>
      <author><first>Mariya</first><last>Shmatova</last><affiliation>Dubformer</affiliation></author>
      <pages>1440-1453</pages>
      <abstract>High-quality Machine Translation (MT) evaluation relies heavily on human judgments.Comprehensive error classification methods, such as Multidimensional Quality Metrics (MQM), are expensive as they are time-consuming and can only be done by experts, whose availability may be limited especially for low-resource languages.On the other hand, just assigning overall scores, like Direct Assessment (DA), is simpler and faster and can be done by translators of any level, but is less reliable.In this paper, we introduce Error Span Annotation (ESA), a human evaluation protocol which combines the continuous rating of DA with the high-level error severity span marking of MQM.We validate ESA by comparing it to MQM and DA for 12 MT systems and one human reference translation (English to German) from WMT23. The results show that ESA offers faster and cheaper annotations than MQM at the same quality level, without the requirement of expensive MQM experts.</abstract>
      <url hash="73e11508">2024.wmt-1.131</url>
      <bibkey>kocmi-etal-2024-error</bibkey>
      <doi>10.18653/v1/2024.wmt-1.131</doi>
    </paper>
    <paper id="132">
      <title>Neural Methods for Aligning Large-Scale Parallel Corpora from the Web for South and <fixed-case>E</fixed-case>ast <fixed-case>A</fixed-case>sian Languages</title>
      <author><first>Philipp</first><last>Koehn</last><affiliation>Johns Hopkins University</affiliation></author>
      <pages>1454-1466</pages>
      <abstract>We introduce neural methods and a toxicity filtering step to the hierarchical web mining approach of Paracrawl (Bañón et al., 2020), showing large improvements. We apply these methods to web-scale parallel corpus mining for 9 South and East Asian national languages, creating training resources for machine translation that yield better translation quality for most of these languages than existing publicly available datasets in OPUS. Our methods also generally lead to better results than the global mining approach of Schwenk et al. (2021).</abstract>
      <url hash="29cf9a1d">2024.wmt-1.132</url>
      <bibkey>koehn-2024-neural</bibkey>
      <doi>10.18653/v1/2024.wmt-1.132</doi>
    </paper>
    <paper id="133">
      <title>Plug, Play, and Fuse: Zero-Shot Joint Decoding via Word-Level Re-ranking across Diverse Vocabularies</title>
      <author><first>Sai</first><last>Koneru</last><affiliation>Karlsruhe Institute of Technology</affiliation></author>
      <author><first>Matthias</first><last>Huck</last><affiliation>SAP SE</affiliation></author>
      <author><first>Miriam</first><last>Exel</last><affiliation>SAP SE</affiliation></author>
      <author><first>Jan</first><last>Niehues</last><affiliation>Karlsruhe Institut of Technology</affiliation></author>
      <pages>1467-1481</pages>
      <abstract>Recent advancements in NLP have resulted in models with specialized strengths, such as processing multimodal inputs or excelling in specific domains. However, real-world tasks, like multimodal translation, often require a combination of these strengths, such as handling both translation and image processing. While individual translation and vision models are powerful, they typically lack the ability to perform both tasks in a single system. Combining these models poses challenges, particularly due to differences in their vocabularies, which limit the effectiveness of traditional ensemble methods to post-generation techniques like N-best list re-ranking. In this work, we propose a novel zero-shot ensembling strategy that allows for the integration of different models during the decoding phase without the need for additional training. Our approach re-ranks beams during decoding by combining scores at the word level, using heuristics to predict when a word is completed. We demonstrate the effectiveness of this method in machine translation scenarios, showing that it enables the generation of translations that are both speech- and image-aware while also improving overall translation quality.</abstract>
      <url hash="692ec7c0">2024.wmt-1.133</url>
      <bibkey>koneru-etal-2024-plug</bibkey>
      <doi>10.18653/v1/2024.wmt-1.133</doi>
    </paper>
  </volume>
</collection>
