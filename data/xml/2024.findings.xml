<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.findings">
  <volume id="eacl" ingest-date="2024-03-03" type="proceedings">
    <meta>
      <booktitle>Findings of the Association for Computational Linguistics: EACL 2024</booktitle>
      <editor><first>Yvette</first><last>Graham</last></editor>
      <editor><first>Matthew</first><last>Purver</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>St. Julian’s, Malta</address>
      <month>March</month>
      <year>2024</year>
      <url hash="f35e73f5">2024.findings-eacl</url>
      <venue>findings</venue>
    </meta>
    <frontmatter>
      <url hash="24d75a3c">2024.findings-eacl.0</url>
      <bibkey>findings-2024-findings</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Chem-<fixed-case>FINESE</fixed-case>: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction</title>
      <author><first>Qingyun</first><last>Wang</last><affiliation>University of Illinois, Urbana Champaign</affiliation></author>
      <author><first>Zixuan</first><last>Zhang</last></author>
      <author><first>Hongxiang</first><last>Li</last><affiliation>UIUC</affiliation></author>
      <author><first>Xuan</first><last>Liu</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <author><first>Jiawei</first><last>Han</last></author>
      <author><first>Huimin</first><last>Zhao</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author><first>Heng</first><last>Ji</last><affiliation>University of Illinois, Urbana-Champaign</affiliation></author>
      <pages>1-16</pages>
      <abstract>Fine-grained few-shot entity extraction in the chemical domain faces two unique challenges. First, compared with entity extraction tasks in the general domain, sentences from chemical papers usually contain more entities. Moreover, entity extraction models usually have difficulty extracting entities of long-tailed types. In this paper, we propose Chem-FINESE, a novel sequence-to-sequence (seq2seq) based few-shot entity extraction approach, to address these two challenges. Our Chem-FINESE has two components: a seq2seq entity extractor to extract named entities from the input sentence and a seq2seq self-validation module to reconstruct the original input sentence from extracted entities. Inspired by the fact that a good entity extraction system needs to extract entities faithfully, our new self-validation module leverages entity extraction results to reconstruct the original input sentence. Besides, we design a new contrastive loss to reduce excessive copying during the extraction process. Finally, we release ChemNER+, a new fine-grained chemical entity extraction dataset that is annotated by domain experts with the ChemNER schema. Experiments in few-shot settings with both ChemNER+ and CHEMET datasets show that our newly proposed framework has contributed up to 8.26% and 6.84% absolute F1-score gains respectively.</abstract>
      <url hash="b832457e">2024.findings-eacl.1</url>
      <attachment type="software" hash="4203c223">2024.findings-eacl.1.software.zip</attachment>
      <attachment type="note" hash="c244f46e">2024.findings-eacl.1.note.zip</attachment>
      <bibkey>wang-etal-2024-chem</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>GPT</fixed-case>s Are Multilingual Annotators for Sequence Generation Tasks</title>
      <author><first>Juhwan</first><last>Choi</last><affiliation>Chung-Ang University</affiliation></author>
      <author><first>Eunju</first><last>Lee</last><affiliation>Chung-Ang University</affiliation></author>
      <author><first>Kyohoon</first><last>Jin</last><affiliation>Chung-Ang University</affiliation></author>
      <author><first>YoungBin</first><last>Kim</last><affiliation>ChungAng University</affiliation></author>
      <pages>17-40</pages>
      <abstract>Data annotation is an essential step for constructing new datasets. However, the conventional approach of data annotation through crowdsourcing is both time-consuming and expensive. In addition, the complexity of this process increases when dealing with low-resource languages owing to the difference in the language pool of crowdworkers. To address these issues, this study proposes an autonomous annotation method by utilizing large language models, which have been recently demonstrated to exhibit remarkable performance. Through our experiments, we demonstrate that the proposed method is not just cost-efficient but also applicable for low-resource language annotation. Additionally, we constructed an image captioning dataset using our approach and are committed to open this dataset for future study. We have opened our source code for further study and reproducibility.</abstract>
      <url hash="d0582eb1">2024.findings-eacl.2</url>
      <attachment type="software" hash="fff5e2cf">2024.findings-eacl.2.software.zip</attachment>
      <attachment type="note" hash="cce955c1">2024.findings-eacl.2.note.zip</attachment>
      <bibkey>choi-etal-2024-gpts</bibkey>
    </paper>
    <paper id="3">
      <title>Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive <fixed-case>EHR</fixed-case> Modelling with Hierarchical Regularisation</title>
      <author><first>Heejoon</first><last>Koo</last></author>
      <pages>41-55</pages>
      <abstract>Predicting next visit diagnosis using Electronic Health Records (EHR) is an essential task in healthcare, critical for devising proactive future plans for both healthcare providers and patients. Nonetheless, many preceding studies have not sufficiently addressed the heterogeneous and hierarchical characteristics inherent in EHR data, inevitably leading to sub-optimal performance. To this end, we propose NECHO, a novel medical code-centric multimodal contrastive EHR learning framework with hierarchical regularisation. First, we integrate multifaceted information encompassing medical codes, demographics, and clinical notes using a tailored network design and a pair of bimodal contrastive losses, all of which pivot around a medical codes representation. We also regularise modality-specific encoders using a parental level information in medical ontology to learn hierarchical structure of EHR data. A series of experiments on MIMIC-III data demonstrates effectiveness of our approach.</abstract>
      <url hash="27b828b0">2024.findings-eacl.3</url>
      <bibkey>koo-2024-next</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>F</fixed-case>lexi<fixed-case>QA</fixed-case>: Leveraging <fixed-case>LLM</fixed-case>’s Evaluation Capabilities for Flexible Knowledge Selection in Open-domain Question Answering</title>
      <author><first>Yuhan</first><last>Chen</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Shuqi</first><last>Li</last></author>
      <author><first>Rui</first><last>Yan</last><affiliation>Renmin University of China</affiliation></author>
      <pages>56-66</pages>
      <abstract>Nowadays, large language models (LLMs) have demonstrated their ability to be a powerful knowledge generator of generate-then-read paradigm for open-domain question answering (ODQA). However this new paradigm mainly suffers from the “hallucination” and struggles to handle time-sensitive issue because of its expensive knowledge update costs. On the other hand, retrieve-then-read, as a traditional paradigm, is more limited by the relevance of acquired knowledge to the given question. In order to combine the strengths of both paradigms, and overcome their respective shortcomings, we design a new pipeline called “FlexiQA”, in which we utilize the diverse evaluation capabilities of LLMs to select knowledge effectively and flexibly. First, given a question, we prompt a LLM as a discriminator to identify whether it is time-sensitive. For time-sensitive questions, we follow the retrieve-then-read paradigm to obtain the answer. For the non time-sensitive questions, we further prompt the LLM as an evaluator to select a better document from two perspectives: factuality and relevance. Based on the selected document, we leverage a reader to get the final answer. We conduct extensive experiments on three widely-used ODQA benchmarks, the experimental results fully confirm the effectiveness of our approach.</abstract>
      <url hash="cbe0ec51">2024.findings-eacl.4</url>
      <bibkey>chen-etal-2024-flexiqa</bibkey>
    </paper>
    <paper id="5">
      <title>Hyper-<fixed-case>BTS</fixed-case> Dataset: Scalability and Enhanced Analysis of Back <fixed-case>T</fixed-case>ran<fixed-case>S</fixed-case>cription (<fixed-case>BTS</fixed-case>) for <fixed-case>ASR</fixed-case> Post-Processing</title>
      <author><first>Chanjun</first><last>Park</last><affiliation>Upstage</affiliation></author>
      <author><first>Jaehyung</first><last>Seo</last></author>
      <author><first>Seolhwa</first><last>Lee</last><affiliation>University of Copenhagen</affiliation></author>
      <author><first>Junyoung</first><last>Son</last></author>
      <author><first>Hyeonseok</first><last>Moon</last><affiliation>Korea University</affiliation></author>
      <author><first>Sugyeong</first><last>Eo</last><affiliation>Korea University</affiliation></author>
      <author><first>Chanhee</first><last>Lee</last><affiliation>NAVER</affiliation></author>
      <author><first>Heuiseok</first><last>Lim</last><affiliation>Korea University</affiliation></author>
      <pages>67-78</pages>
      <abstract>The recent advancements in the realm of Automatic Speech Recognition (ASR) post-processing have been primarily driven by sequence-to-sequence paradigms. Despite their effectiveness, these methods often demand substantial amounts of data, necessitating the expensive recruitment of phonetic transcription experts to rectify the erroneous outputs of ASR systems, thereby creating the desired training data. Back TranScription (BTS) alleviates this issue by generating ASR inputs from clean text via a Text-to-Speech (TTS) system. While initial studies on BTS exhibited promise, they were constrained by a limited dataset of just 200,000 sentence pairs, leaving the scalability of this method in question. In this study, we delve into the potential scalability of BTS. We introduce the “Hyper-BTS” dataset, a corpus approximately five times larger than that utilized in prior research. Additionally, we present innovative criteria for categorizing error types within ASR post-processing. This not only facilitates a more comprehensive qualitative analysis, which was absent in preceding studies, but also enhances the understanding of ASR error patterns. Our empirical results, both quantitative and qualitative, suggest that the enlarged scale of the Hyper-BTS dataset sufficiently addresses a vast majority of the ASR error categories. We make the Hyper-BTS dataset publicly available.</abstract>
      <url hash="822de166">2024.findings-eacl.5</url>
      <bibkey>park-etal-2024-hyper</bibkey>
    </paper>
    <paper id="6">
      <title><fixed-case>P</fixed-case>arrot<fixed-case>TTS</fixed-case>: Text-to-speech synthesis exploiting disentangled self-supervised representations</title>
      <author><first>Neil</first><last>Shah</last><affiliation>Tata Consultancy Services Limited, India</affiliation></author>
      <author><first>Saiteja</first><last>Kosgi</last></author>
      <author><first>Vishal</first><last>Tambrahalli</last><affiliation>International Institute of Information Technology, Hyderabad, International Institute of Information Technology Hyderabad</affiliation></author>
      <author><first>Neha</first><last>S</last><affiliation>International Institute of Information Technology Hyderabad, Dhirubhai Ambani Institute Of Information and Communication Technology</affiliation></author>
      <author><first>Anil</first><last>Nelakanti</last></author>
      <author><first>Vineet</first><last>Gandhi</last><affiliation>International Institute of Information Technology Hyderabad</affiliation></author>
      <pages>79-91</pages>
      <abstract>We present ParrotTTS, a modularized text-to-speech synthesis model leveraging disentangled self-supervised speech representations. It can train a multi-speaker variant effectively using transcripts from a single speaker. ParrotTTS adapts to a new language in low resource setup and generalizes to languages not seen while training the self-supervised backbone. Moreover, without training on bilingual or parallel examples, ParrotTTS can transfer voices across languages while preserving the speaker-specific characteristics, e.g., synthesizing fluent Hindi speech using a French speaker’s voice and accent. We present extensive results in monolingual and multi-lingual scenarios. ParrotTTS outperforms state-of-the-art multi-lingual text-to-speech (TTS) models using only a fraction of paired data as latter. Speech samples from ParrotTTS and code can be found at https://parrot-tts.github.io/tts/</abstract>
      <url hash="1104692c">2024.findings-eacl.6</url>
      <bibkey>shah-etal-2024-parrottts</bibkey>
    </paper>
    <paper id="7">
      <title><fixed-case>N</fixed-case>av<fixed-case>H</fixed-case>int: Vision and Language Navigation Agent with a Hint Generator</title>
      <author><first>Yue</first><last>Zhang</last><affiliation>Michigan State University</affiliation></author>
      <author><first>Quan</first><last>Guo</last><affiliation>Sichuan University</affiliation></author>
      <author><first>Parisa</first><last>Kordjamshidi</last><affiliation>Michigan State University</affiliation></author>
      <pages>92-103</pages>
      <abstract>The existing work on vision and language navigation mainly relies on navigation-related losses to establish the connection between vision and language modalities, neglecting aspects of helping the navigation agent build a deep understanding of the visual environment.In our work, we provide indirect supervision to the navigation agent through a hint generator that provides detailed visual descriptions.The hint generator assists the navigation agent in developing a global understanding of the visual environment. It directs the agent’s attention toward related navigation details, including the relevant sub-instruction, potential challenges in recognition and ambiguities in grounding, and the targeted viewpoint description. To train the hint generator, we construct a synthetic dataset based on landmarks in the instructions and visible and distinctive objects in the visual environment.We evaluate our method on the R2R and R4R datasets and achieve state-of-the-art on several metrics. The experimental results demonstrate that generating hints not only enhances the navigation performance but also helps improve the agent’s interpretability.</abstract>
      <url hash="63815ab4">2024.findings-eacl.7</url>
      <bibkey>zhang-etal-2024-navhint</bibkey>
    </paper>
    <paper id="8">
      <title>Text or Image? What is More Important in Cross-Domain Generalization Capabilities of Hate Meme Detection Models?</title>
      <author><first>Piush</first><last>Aggarwal</last><affiliation>Fernuniversität Gesamthochschule Hagen and Fernuniversität Gesamthochschule Hagen</affiliation></author>
      <author><first>Jawar</first><last>Mehrabanian</last></author>
      <author><first>Weigang</first><last>Huang</last><affiliation>Universität Duisburg-Essen</affiliation></author>
      <author><first>Özge</first><last>Alacam</last><affiliation>Bielefeld University</affiliation></author>
      <author><first>Torsten</first><last>Zesch</last><affiliation>Fernuniversität in Hagen</affiliation></author>
      <pages>104-117</pages>
      <abstract>This paper delves into the formidable challenge of cross-domain generalization in multimodal hate meme detection, presenting compelling findings. We provide evidence supporting the hypothesis that only the textual component of hateful memes enables the multimodal classifier to generalize across different domains, while the image component proves highly sensitive to a specific training dataset. The evidence includes demonstrations showing that hate-text classifiers perform similarly to hate-meme classifiers in a zero-shot setting. Simultaneously, the introduction of captions generated from images of memes to the hate-meme classifier worsens performance by an average F1 of 0.02. Through blackbox explanations, we identify a substantial contribution of the text modality (average of 83%), which diminishes with the introduction of meme’s image captions (52%). Additionally, our evaluation on a newly created confounder dataset reveals higher performance on text confounders as compared to image confounders with average ∆F1 of 0.18.</abstract>
      <url hash="38939fde">2024.findings-eacl.8</url>
      <bibkey>aggarwal-etal-2024-text</bibkey>
    </paper>
    <paper id="9">
      <title>Where are we Still Split on Tokenization?</title>
      <author><first>Rob</first><last>Goot</last></author>
      <pages>118-137</pages>
      <abstract>Many Natural Language Processing (NLP) tasks are labeled on the token level, forthese tasks, the first step is to identify the tokens (tokenization). Becausethis step is often considered to be a solved problem, gold tokenization iscommonly assumed. In this paper, we propose an efficient method fortokenization with subword-based language models, and reflect on the status ofperformance on the tokenization task by evaluating on 122 languages in 20different scripts. We show that our proposed model performs on par with thestate-of-the-art, and that tokenization performance is mainly dependent on theamount and consistency of annotated data. We conclude that besidesinconsistencies in the data and exceptional cases the task can be consideredsolved for Latin languages for in-dataset settings (&gt;99.5 F1). However,performance is 0.75 F1 point lower on average for datasets in other scripts andperformance deteriorates in cross-dataset setups.</abstract>
      <url hash="e9d06d61">2024.findings-eacl.9</url>
      <attachment type="software" hash="4898d0e8">2024.findings-eacl.9.software.tgz</attachment>
      <bibkey>goot-2024-still</bibkey>
    </paper>
    <paper id="10">
      <title>A Methodology for Generative Spelling Correction via Natural Spelling Errors Emulation across Multiple Domains and Languages</title>
      <author><first>Nikita</first><last>Martynov</last><affiliation>New Economic School</affiliation></author>
      <author><first>Mark</first><last>Baushenko</last></author>
      <author><first>Anastasia</first><last>Kozlova</last></author>
      <author><first>Katerina</first><last>Kolomeytseva</last></author>
      <author><first>Aleksandr</first><last>Abramov</last></author>
      <author><first>Alena</first><last>Fenogenova</last></author>
      <pages>138-155</pages>
      <abstract>Large language models excel in text generation and generalization, however they face challenges in text editing tasks, especially in correcting spelling errors and mistyping.In this paper, we present a methodology for generative spelling correction (SC), tested on English and Russian languages and potentially can be extended to any language with minor changes. Our research mainly focuses on exploring natural spelling errors and mistyping in texts and studying how those errors can be emulated in correct sentences to enrich generative models’ pre-train procedure effectively. We investigate the effects of emulations in various text domains and examine two spelling corruption techniques: 1) first one mimics human behavior when making a mistake through leveraging statistics of errors from a particular dataset, and 2) second adds the most common spelling errors, keyboard miss clicks, and some heuristics within the texts.We conducted experiments employing various corruption strategies, models’ architectures, and sizes in the pre-training and fine-tuning stages and evaluated the models using single-domain and multi-domain test sets. As a practical outcome of our work, we introduce SAGE (Spell checking via Augmentation and Generative distribution Emulation).</abstract>
      <url hash="86d5f92e">2024.findings-eacl.10</url>
      <attachment type="software" hash="41b27f50">2024.findings-eacl.10.software.zip</attachment>
      <attachment type="note" hash="72e71561">2024.findings-eacl.10.note.zip</attachment>
      <bibkey>martynov-etal-2024-methodology</bibkey>
    </paper>
    <paper id="11">
      <title>How Does In-Context Learning Help Prompt Tuning?</title>
      <author><first>Simeng</first><last>Sun</last><affiliation>University of Massachusetts, Amherst</affiliation></author>
      <author id="yang-liu"><first>Yang</first><last>Liu</last></author>
      <author><first>Dan</first><last>Iter</last></author>
      <author><first>Chenguang</first><last>Zhu</last><affiliation>Zoom</affiliation></author>
      <author><first>Mohit</first><last>Iyyer</last><affiliation>University of Massachusetts Amherst</affiliation></author>
      <pages>156-165</pages>
      <abstract>Fine-tuning large language models is becoming ever more impractical due to their rapidly-growing scale. This motivates the use of parameter-efficient adaptation methods such as prompt tuning (PT), which adds a small number of tunable embeddings to an otherwise frozen model, and in-context learning (ICL), in which demonstrations of the task are provided to the model in natural language without any additional training. Recently, (CITATION) propose “instruction prompt tuning” (IPT), which combines PT with ICL by concatenating a natural language demonstration with learned prompt embeddings. While all of these methods have proven effective on different tasks, how they interact with each other remains unexplored. In this paper, we empirically study when and how in-context examples improve prompt tuning by measuring the effectiveness of ICL, PT, and IPT on five text generation tasks with multiple base language models. We observe that (1) IPT does <i>not</i> always outperform PT, and in fact requires the in-context demonstration to be semantically similar to the test input to yield improvements; (2) PT is unstable and exhibits high variance, but combining PT and ICL (into IPT) consistently reduces variance across all five tasks; and(3) prompts learned for a specific source task via PT exhibit positive transfer when paired with in-context examples of a different target task. Our results offer actionable insights on choosing a suitable parameter-efficient adaptation method for a given task.</abstract>
      <url hash="a17235c9">2024.findings-eacl.11</url>
      <bibkey>sun-etal-2024-context</bibkey>
    </paper>
    <paper id="12">
      <title>Large Language Models for Psycholinguistic Plausibility Pretesting</title>
      <author><first>Samuel</first><last>Amouyal</last></author>
      <author><first>Aya</first><last>Meltzer-Asscher</last><affiliation>Tel Aviv University</affiliation></author>
      <author><first>Jonathan</first><last>Berant</last><affiliation>Google and Tel Aviv University</affiliation></author>
      <pages>166-181</pages>
      <abstract>In psycholinguistics, the creation of controlled materials is crucial to ensure that research outcomes are solely attributed to the intended manipulations and not influenced by extraneous factors. To achieve this, psycholinguists typically pretest linguistic materials, where a common pretest is to solicit plausibility judgments from human evaluators on specific sentences. In this work, we investigate whether Language Models (LMs) can be used to generate these plausibility judgements. We investigate a wide range of LMs across multiple linguistic structures and evaluate whether their plausibility judgements correlate with human judgements. We find that GPT-4 plausibility judgements highly correlate with human judgements across the structures we examine, whereas other LMs correlate well with humans on commonly used syntactic structures. We then test whether this correlation implies that LMs can be used instead of humans for pretesting. We find that when coarse-grained plausibility judgements are needed, this works well, but when fine-grained judgements are necessary, even GPT-4 does not provide satisfactory discriminative power.</abstract>
      <url hash="08a290d1">2024.findings-eacl.12</url>
      <attachment type="software" hash="d5b10b6a">2024.findings-eacl.12.software.zip</attachment>
      <attachment type="note" hash="6832e347">2024.findings-eacl.12.note.zip</attachment>
      <bibkey>amouyal-etal-2024-large</bibkey>
    </paper>
    <paper id="13">
      <title>Modeling Aspect Sentiment Coherency via Local Sentiment Aggregation</title>
      <author><first>Heng</first><last>Yang</last></author>
      <author><first>Ke</first><last>Li</last><affiliation>University of Exeter</affiliation></author>
      <pages>182-195</pages>
      <abstract>Aspect sentiment coherency is an intriguing yet underexplored topic in the field of aspect-based sentiment classification. This concept reflects the common pattern where adjacent aspects often share similar sentiments. Despite its prevalence, current studies have not fully recognized the potential of modeling aspect sentiment coherency, including its implications in adversarial defense. To model aspect sentiment coherency, we propose a novel local sentiment aggregation (LSA) paradigm based on constructing a differential-weighted sentiment aggregation window. We have rigorously evaluated our model through experiments, and the results affirm the proficiency of LSA in terms of aspect coherency prediction and aspect sentiment classification. For instance, it outperforms existing models and achieves state-of-the-art sentiment classification performance across five public datasets. Furthermore, we demonstrate the promising ability of LSA in ABSC adversarial defense, thanks to its sentiment coherency modeling. To encourage further exploration and application of this concept, we have made our code publicly accessible. This will provide researchers with a valuable tool to delve into sentiment coherency modeling in future research.</abstract>
      <url hash="e0ee34c5">2024.findings-eacl.13</url>
      <attachment type="software" hash="7abddaeb">2024.findings-eacl.13.software.zip</attachment>
      <attachment type="note" hash="7abddaeb">2024.findings-eacl.13.note.zip</attachment>
      <bibkey>yang-li-2024-modeling</bibkey>
    </paper>
    <paper id="14">
      <title>An Examination of the Robustness of Reference-Free Image Captioning Evaluation Metrics</title>
      <author><first>Saba</first><last>Ahmadi</last></author>
      <author><first>Aishwarya</first><last>Agrawal</last><affiliation>Université de Montréal, Mila – Quebec AI Institute and Google DeepMind</affiliation></author>
      <pages>196-208</pages>
      <abstract>Recently, reference-free metrics such as CLIPScore (Hessel et al., 2021), UMIC (Lee et al., 2021), and PAC-S (Sarto et al., 2023) have been proposed for automatic reference-free evaluation of image captions. Our focus lies in evaluating the robustness of these metrics in scenarios that require distinguishing between two captions with high lexical overlap but very different meanings. Our findings reveal that despite their high correlation with human judgments, CLIPScore, UMIC, and PAC-S struggle to identify fine-grained errors. While all metrics exhibit strong sensitivity to visual grounding errors, their sensitivity to caption implausibility errors is limited. Furthermore, we found that all metrics are sensitive to variations in the size of image-relevant objects mentioned in the caption, while CLIPScore and PAC-S are also sensitive to the number of mentions of image-relevant objects in the caption. Regarding linguistic aspects of a caption, all metrics show weak comprehension of negation, and CLIPScore and PAC-S are insensitive to the structure of the caption to a great extent. We hope our findings will guide further improvements in reference-free evaluation of image captioning.</abstract>
      <url hash="98d0754c">2024.findings-eacl.14</url>
      <bibkey>ahmadi-agrawal-2024-examination</bibkey>
    </paper>
    <paper id="15">
      <title>Barriers to Effective Evaluation of Simultaneous Interpretation</title>
      <author><first>Shira</first><last>Wein</last><affiliation>Georgetown University</affiliation></author>
      <author><first>Te</first><last>I</last><affiliation>Google</affiliation></author>
      <author><first>Colin</first><last>Cherry</last><affiliation>Google</affiliation></author>
      <author><first>Juraj</first><last>Juraska</last><affiliation>Google</affiliation></author>
      <author><first>Dirk</first><last>Padfield</last><affiliation>Google</affiliation></author>
      <author><first>Wolfgang</first><last>Macherey</last><affiliation>Google</affiliation></author>
      <pages>209-219</pages>
      <abstract>Simultaneous interpretation is an especially challenging form of translation because it requires converting speech from one language to another in real-time. Though prior work has relied on out-of-the-box machine translation metrics to evaluate interpretation data, we hypothesize that strategies common in high-quality human interpretations, such as summarization, may not be handled well by standard machine translation metrics. In this work, we examine both qualitatively and quantitatively four potential barriers to evaluation of interpretation: disfluency, summarization, paraphrasing, and segmentation. Our experiments reveal that, while some machine translation metrics correlate fairly well with human judgments of interpretation quality, much work is still needed to account for strategies of interpretation during evaluation. As a first step to address this, we develop a fine-tuned model for interpretation evaluation, and achieve better correlation with human judgments than the state-of-the-art machine translation metrics.</abstract>
      <url hash="2ec8040a">2024.findings-eacl.15</url>
      <bibkey>wein-etal-2024-barriers</bibkey>
    </paper>
    <paper id="16">
      <title>Inconsistent dialogue responses and how to recover from them</title>
      <author><first>Mian</first><last>Zhang</last></author>
      <author><first>Lifeng</first><last>Jin</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Linfeng</first><last>Song</last></author>
      <author><first>Haitao</first><last>Mi</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Dong</first><last>Yu</last><affiliation>Tencent AI Lab</affiliation></author>
      <pages>220-230</pages>
      <abstract>One critical issue for chat systems is to stay consistent about preferences, opinions, beliefs and facts of itself, which has been shown a difficult problem. In this work, we study methods to assess and bolster utterance consistency of chat systems. A dataset is first developed for studying the inconsistencies, where inconsistent dialogue responses, explanations of the inconsistencies, and recovery utterances are authored by annotators. This covers the life span of inconsistencies, namely introduction, understanding, and resolution. Building on this, we introduce a set of tasks centered on dialogue consistency, specifically focused on its detection and resolution. Our experimental findings indicate that our dataset significantly helps the progress in identifying and resolving conversational inconsistencies, and current popular large language models like ChatGPT which are good at resolving inconsistencies however still struggle with detection.</abstract>
      <url hash="def387c7">2024.findings-eacl.16</url>
      <bibkey>zhang-etal-2024-inconsistent</bibkey>
    </paper>
    <paper id="17">
      <title><fixed-case>MUG</fixed-case>: Interactive Multimodal Grounding on User Interfaces</title>
      <author><first>Tao</first><last>Li</last><affiliation>Google</affiliation></author>
      <author><first>Gang</first><last>Li</last><affiliation>Google</affiliation></author>
      <author><first>Jingjie</first><last>Zheng</last></author>
      <author><first>Purple</first><last>Wang</last><affiliation>Google</affiliation></author>
      <author><first>Yang</first><last>Li</last><affiliation>Google</affiliation></author>
      <pages>231-251</pages>
      <abstract>We present MUG, a novel interactive task for multimodal grounding where a user and an agent work collaboratively on an interface screen. Prior works modeled multimodal UI grounding in one round: the user gives a command and the agent responds to the command. Yet, in a realistic scenario, a user command can be ambiguous when the target action is inherently difficult to articulate in natural language. MUG allows multiple rounds of interactions such that upon seeing the agent responses, the user can give further commands for the agent to refine or even correct its actions. Such interaction is critical for improving grounding performances in real-world use cases. To investigate the problem, we create a new dataset that consists of 77,820 sequences of human user-agent interaction on mobile interfaces in which 20% involves multiple rounds of interactions. To establish benchmark, we experiment with a range of modeling variants and evaluation strategies, including both offline and online evaluation—the online strategy consists of both human evaluation and automatic with simulators. Our experiments show that iterative interaction significantly improves the absolute task completion by 18% over the entire test set and 31% over the challenging split. Our results lay the foundation for further investigation of the problem.</abstract>
      <url hash="ba7f75c0">2024.findings-eacl.17</url>
      <bibkey>li-etal-2024-mug</bibkey>
    </paper>
    <paper id="18">
      <title><fixed-case>PRIL</fixed-case>o<fixed-case>RA</fixed-case>: Pruned and Rank-Increasing Low-Rank Adaptation</title>
      <author><first>Nadav</first><last>Benedek</last></author>
      <author><first>Lior</first><last>Wolf</last><affiliation>Tel Aviv University, Tel Aviv University and Tel Aviv University</affiliation></author>
      <pages>252-263</pages>
      <abstract>With the proliferation of large pre-trained language models (PLMs), fine-tuning all model parameters becomes increasingly inefficient, particularly when dealing with numerous downstream tasks that entail substantial training and storage costs. Several approaches aimed at achieving parameter-efficient fine-tuning (PEFT) have been proposed. Among them, Low-Rank Adaptation (LoRA) stands out as an archetypal method, incorporating trainable rank decomposition matrices into each target module. Nevertheless, LoRA does not consider the varying importance of each layer. To address these challenges, we introduce PRILoRA, which linearly allocates a different rank for each layer, in an increasing manner, and performs pruning throughout the training process, considering both the temporary magnitude of weights and the accumulated statistics of the input to any given layer. We validate the effectiveness of PRILoRA through extensive experiments on eight GLUE benchmarks, setting a new state of the art.</abstract>
      <url hash="b7def7f3">2024.findings-eacl.18</url>
      <attachment type="software" hash="300fc956">2024.findings-eacl.18.software.zip</attachment>
      <bibkey>benedek-wolf-2024-prilora</bibkey>
    </paper>
    <paper id="19">
      <title>Revamping Multilingual Agreement Bidirectionally via Switched Back-translation for Multilingual Neural Machine Translation</title>
      <author><first>Hongyuan</first><last>Lu</last></author>
      <author><first>Haoyang</first><last>Huang</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Dongdong</first><last>Zhang</last><affiliation>Microsoft Research Asia</affiliation></author>
      <author><first>Furu</first><last>Wei</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Wai</first><last>Lam</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <pages>264-275</pages>
      <abstract>Despite the fact that multilingual agreement (MA) has shown its importance for multilingual neural machine translation (MNMT), current methodologies in the field have two shortages: (i) require parallel data between multiple language pairs, which is not always realistic and (ii) optimize the agreement in an ambiguous direction, which hampers the translation performance. We present <b>B</b>idirectional <b>M</b>ultilingual <b>A</b>greement via <b>S</b>witched <b>B</b>ack-<b>t</b>ranslation (<b>BMA-SBT</b>), a novel and universal multilingual agreement framework for fine-tuning pre-trained MNMT models, which (i) exempts the need for aforementioned parallel data by using a novel method called switched BT that creates synthetic text written in another source language using the translation target and (ii) optimizes the agreement bidirectionally with the Kullback-Leibler Divergence loss. Experiments indicate that BMA-SBT clearly improves the strong baselines on the task of MNMT with three benchmarks: TED Talks, News, and Europarl. In-depth analyzes indicate that BMA-SBT brings additive improvements to the conventional BT method.</abstract>
      <url hash="05159d1d">2024.findings-eacl.19</url>
      <bibkey>lu-etal-2024-revamping</bibkey>
    </paper>
    <paper id="20">
      <title>m<fixed-case>PLM</fixed-case>-Sim: Better Cross-Lingual Similarity and Transfer in Multilingual Pretrained Language Models</title>
      <author><first>Peiqin</first><last>Lin</last><affiliation>Institut für Informatik</affiliation></author>
      <author><first>Chengzhi</first><last>Hu</last></author>
      <author><first>Zheyu</first><last>Zhang</last><affiliation>Center for Information and Language Processing</affiliation></author>
      <author><first>Andre</first><last>Martins</last><affiliation>Instituto Superior Técnico and Unbabel</affiliation></author>
      <author><first>Hinrich</first><last>Schuetze</last></author>
      <pages>276-310</pages>
      <abstract>Recent multilingual pretrained language models (mPLMs) have been shown to encode strong language-specific signals, which are not explicitly provided during pretraining. It remains an open question whether it is feasible to employ mPLMs to measure language similarity, and subsequently use the similarity results to select source languages for boosting cross-lingual transfer. To investigate this, we propose mPLM-Sim, a language similarity measure that induces the similarities across languages from mPLMs using multi-parallel corpora. Our study shows that mPLM-Sim exhibits moderately high correlations with linguistic similarity measures, such as lexicostatistics, genealogical language family, and geographical sprachbund. We also conduct a case study on languages with low correlation and observe that mPLM-Sim yields more accurate similarity results. Additionally, we find that similarity results vary across different mPLMs and different layers within an mPLM. We further investigate whether mPLM-Sim is effective for zero-shot cross-lingual transfer by conducting experiments on both low-level syntactic tasks and high-level semantic tasks. The experimental results demonstrate that mPLM-Sim is capable of selecting better source languages than linguistic measures, resulting in a 1%-2% improvement in zero-shot cross-lingual transfer performance.</abstract>
      <url hash="accddcb1">2024.findings-eacl.20</url>
      <bibkey>lin-etal-2024-mplm</bibkey>
    </paper>
    <paper id="21">
      <title><fixed-case>OYXOY</fixed-case>: A <fixed-case>M</fixed-case>odern <fixed-case>NLP</fixed-case> Test Suite for <fixed-case>M</fixed-case>odern <fixed-case>G</fixed-case>reek</title>
      <author><first>Konstantinos</first><last>Kogkalidis</last></author>
      <author><first>Stergios</first><last>Chatzikyriakidis</last><affiliation>University of Gothenburg</affiliation></author>
      <author><first>Eirini</first><last>Giannikouri</last><affiliation>University of Crete</affiliation></author>
      <author><first>Vasiliki</first><last>Katsouli</last><affiliation>University of Crete</affiliation></author>
      <author><first>Christina</first><last>Klironomou</last></author>
      <author><first>Christina</first><last>Koula</last></author>
      <author><first>Dimitris</first><last>Papadakis</last></author>
      <author><first>Thelka</first><last>Pasparaki</last></author>
      <author><first>Erofili</first><last>Psaltaki</last><affiliation>University of Crete</affiliation></author>
      <author><first>Efthymia</first><last>Sakellariou</last><affiliation>University of Crete</affiliation></author>
      <author><first>Charikleia</first><last>Soupiona</last></author>
      <pages>311-322</pages>
      <abstract>This paper serves as a foundational step towards the development of a linguistically motivated and technically relevant evaluation suite for Greek NLP. We initiate this endeavor by introducing four expert-verified evaluation tasks, specifically targeted at natural language inference, word sense disambiguation (through example comparison or sense selection) and metaphor detection. More than language-adapted replicas of existing tasks, we contribute two innovations which will resonate with the broader resource and evaluation community. Firstly, our inference dataset is the first of its kind, marking not just one, but rather all possible inference labels, accounting for possible shifts due to e.g. ambiguity or polysemy. Secondly, we demonstrate a cost-efficient method to obtain datasets for under-resourced languages. Using ChatGPT as a language-neutral parser, we transform the Dictionary of Standard Modern Greek into a structured format, from which we derive the other three tasks through simple projections. Alongside each task, we conduct experiments using currently available state of the art machinery. Our experimental baselines affirm the challenging nature of our tasks and highlight the need for expedited progress in order for the Greek NLP ecosystem to keep pace with contemporary mainstream research.</abstract>
      <url hash="e3c361c4">2024.findings-eacl.21</url>
      <attachment type="software" hash="5bafd75d">2024.findings-eacl.21.software.zip</attachment>
      <attachment type="note" hash="eb900342">2024.findings-eacl.21.note.zip</attachment>
      <bibkey>kogkalidis-etal-2024-oyxoy</bibkey>
    </paper>
    <paper id="22">
      <title>A Comprehensive Evaluation of Inductive Reasoning Capabilities and Problem Solving in Large Language Models</title>
      <author><first>Chen</first><last>Bowen</last></author>
      <author><first>Rune</first><last>Sætre</last><affiliation>Norwegian University of Science and Technology</affiliation></author>
      <author><first>Yusuke</first><last>Miyao</last><affiliation>The University of Tokyo</affiliation></author>
      <pages>323-339</pages>
      <abstract>Inductive reasoning is fundamental to both human and artificial intelligence. The inductive reasoning abilities of current Large Language Models (LLMs) are evaluated in this research.We argue that only considering induction of rules is too narrow and unrealistic, since inductive reasoning is usually mixed with other abilities, like rules application, results/rules validation, and updated information integration.We probed the LLMs with a set of designed symbolic tasks and found that even state-of-the-art (SotA) LLMs fail significantly, showing the inability of LLMs to perform these intuitively simple tasks.Furthermore, we found that perfect accuracy in a small-size problem does not guarantee the same accuracy in a larger-size version of the same problem, provoking the question of how we can assess the LLMs’ actual problem-solving capabilities.We also argue that Chain-of-Thought prompts help the LLMs by decomposing the problem-solving process, but the LLMs still learn limitedly.Furthermore, we reveal that few-shot examples assist LLM generalization in out-of-domain (OOD) cases, albeit limited. The LLM starts to fail when the problem deviates from the provided few-shot examples.</abstract>
      <url hash="85cb68ea">2024.findings-eacl.22</url>
      <attachment type="software" hash="2f3e1abc">2024.findings-eacl.22.software.zip</attachment>
      <bibkey>bowen-etal-2024-comprehensive</bibkey>
    </paper>
    <paper id="23">
      <title>Towards efficient self-supervised representation learning in speech processing</title>
      <author><first>Luis</first><last>Lugo</last></author>
      <author><first>Valentin</first><last>Vielzeuf</last><affiliation>Orange-labs</affiliation></author>
      <pages>340-346</pages>
      <abstract>Self-supervised learning has achieved impressive results in speech processing, but current models are computationally expensive, generating environmental concerns because of their high energy consumption. Therefore, we propose an efficient self-supervised approach to address high computational costs, using a single GPU during 24 to 48 hours of pretraining. The proposed approach combines linear, convolutional, and self-attention layers with several optimizations, including dynamic batching, flash attention, mixed-precision training, gradient accumulation, and acoustic feature extraction with input preprocessing. Computational cost estimations for our proposed model represent up to two orders of magnitude improvements in computational efficiency against existing speech models.</abstract>
      <url hash="7d046408">2024.findings-eacl.23</url>
      <bibkey>lugo-vielzeuf-2024-towards</bibkey>
    </paper>
    <paper id="24">
      <title>Improving Cross-Domain Low-Resource Text Generation through <fixed-case>LLM</fixed-case> Post-Editing: A Programmer-Interpreter Approach</title>
      <author><first>Zhuang</first><last>Li</last><affiliation>Monash University</affiliation></author>
      <author><first>Levon</first><last>Haroutunian</last><affiliation>Openstream, Inc.</affiliation></author>
      <author><first>Raj</first><last>Tumuluri</last><affiliation>Openstream Inc</affiliation></author>
      <author><first>Philip</first><last>Cohen</last></author>
      <author><first>Reza</first><last>Haf</last><affiliation>Monash University</affiliation></author>
      <pages>347-354</pages>
      <abstract>Post-editing has proven effective in improving the quality of text generated by large language models (LLMs) such as GPT-3.5 or GPT-4, particularly when direct updating of their parameters to enhance text quality is infeasible or expensive. However, relying solely on smaller language models for post-editing can limit the LLMs’ ability to generalize across domains. Moreover, the editing strategies in these methods are not optimally designed for text generation tasks. To address these limitations, we propose a neural programmer-interpreter approach that preserves the domain generalization ability of LLMs while editing their output. The editing actions in this framework are specifically devised for text generation. Extensive experiments demonstrate that the programmer-interpreter significantly enhances GPT-3.5’s performance in logical form-to-text conversion and low-resource machine translation, surpassing other state-of-the-art (SOTA) LLM post-editing methods in cross-domain settings.</abstract>
      <url hash="f39ab06e">2024.findings-eacl.24</url>
      <bibkey>li-etal-2024-improving-cross</bibkey>
    </paper>
    <paper id="25">
      <title>Noise Contrastive Estimation-based Matching Framework for Low-Resource Security Attack Pattern Recognition</title>
      <author><first>Tu</first><last>Nguyen</last><affiliation>Huawei R&amp;D Munich</affiliation></author>
      <author><first>Nedim</first><last>Šrndić</last><affiliation>Huawei Technologies Duesseldorf GmbH</affiliation></author>
      <author><first>Alexander</first><last>Neth</last><affiliation>Huawei Technologies Ltd.</affiliation></author>
      <pages>355-373</pages>
      <abstract>Techniques, Tactics and Procedures (TTP) mapping is an important and difficult task in the application of cyber threat intelligence (CTI) extraction for threat reports. TTPs are typically expressed in semantic forms within security knowledge bases like MITRE ATT&amp;CK, serving as textual high-level descriptions for sophisticated attack patterns. Conversely, attacks in CTI threat reports are detailed in a combination of natural and technical language forms, presenting a significant challenge even for security experts to establish correlations or mappings with the corresponding TTPs.Conventional learning approaches often target the TTP mapping problem in the classical multiclass/label classification setting. This setting hinders the learning capabilities of the model, due to the large number of classes (i.e., TTPs), the inevitable skewness of the label distribution and the complex hierarchical structure of the label space. In this work, we approach the problem in a different learning paradigm, such that the assignment of a text to a TTP label is essentially decided by the direct semantic similarity between the two, thus, reducing the complexity of competing solely over the large labeling space. In order that, we propose a neural matching architecture that incorporates a sampling based learn-to-compare mechanism, facilitating the learning process of the matching model despite constrained resources.</abstract>
      <url hash="5bf9f38e">2024.findings-eacl.25</url>
      <attachment type="note" hash="c0b2ed72">2024.findings-eacl.25.note.tgz</attachment>
      <bibkey>nguyen-etal-2024-noise</bibkey>
    </paper>
    <paper id="26">
      <title>Large Language Models for Scientific Information Extraction: An Empirical Study for Virology</title>
      <author><first>Mahsa</first><last>Shamsabadi</last><affiliation>TIB Hannover</affiliation></author>
      <author><first>Jennifer</first><last>D’Souza</last><affiliation>TIB Hannover</affiliation></author>
      <author><first>Sören</first><last>Auer</last><affiliation>Leibniz Universität Hannover</affiliation></author>
      <pages>374-392</pages>
      <abstract>In this paper, we champion the use of structured and semantic content representation of discourse-based scholarly communication, inspired by tools like Wikipedia infoboxes or structured Amazon product descriptions. These representations provide users with a concise overview, aiding scientists in navigating the dense academic landscape. Our novel automated approach leverages the robust text generation capabilities of LLMs to produce structured scholarly contribution summaries, offering both a practical solution and insights into LLMs’ emergent abilities.For LLMs, the prime focus is on improving their general intelligence as conversational agents. We argue that these models can also be applied effectively in information extraction (IE), specifically in complex IE tasks within terse domains like Science. This paradigm shift replaces the traditional modular, pipelined machine learning approach with a simpler objective expressed through instructions. Our results show that finetuned FLAN-T5 with 1000x fewer parameters than the state-of-the-art GPT-davinci is competitive for the task.</abstract>
      <url hash="41888965">2024.findings-eacl.26</url>
      <attachment type="software" hash="bce15d0c">2024.findings-eacl.26.software.zip</attachment>
      <attachment type="note" hash="27bd030b">2024.findings-eacl.26.note.zip</attachment>
      <bibkey>shamsabadi-etal-2024-large</bibkey>
    </paper>
    <paper id="27">
      <title>Re3val: Reinforced and Reranked Generative Retrieval</title>
      <author><first>EuiYul</first><last>Song</last><affiliation>Samsung Electronics</affiliation></author>
      <author><first>Sangryul</first><last>Kim</last><affiliation>Korea Advanced Institute of Science &amp; Technology</affiliation></author>
      <author><first>Haeju</first><last>Lee</last><affiliation>LG Corporation</affiliation></author>
      <author><first>Joonkee</first><last>Kim</last><affiliation>Korea Advanced Institute of Science &amp; Technology</affiliation></author>
      <author><first>James</first><last>Thorne</last><affiliation>KAIST</affiliation></author>
      <pages>393-409</pages>
      <abstract>Generative retrieval models encode pointers to information in a corpus as an index within the model’s parameters. These models serve as part of a larger pipeline, where retrieved information conditions generation for knowledge-intensive NLP tasks. However, we identify two limitations: the generative retrieval does not account for contextual information. Secondly, the retrieval can’t be tuned for the downstream readers as decoding the page title is a non-differentiable operation. This paper introduces Re3val, trained with generative reranking and reinforcement learning using limited data. Re3val leverages context acquired via Dense Passage Retrieval to rerank the retrieved page titles and utilizes REINFORCE to maximize rewards generated by constrained decoding. Additionally, we generate questions from our pre-training dataset to mitigate epistemic uncertainty and bridge the domain gap between the pre-training and fine-tuning datasets. Subsequently, we extract and rerank contexts from the KILT database using the rerank page titles. Upon grounding the top five reranked contexts, Re3val demonstrates the Top 1 KILT scores compared to all other generative retrieval models across five KILT datasets.</abstract>
      <url hash="9e63f5ec">2024.findings-eacl.27</url>
      <bibkey>song-etal-2024-re3val</bibkey>
    </paper>
    <paper id="28">
      <title>Entity Linking in the Job Market Domain</title>
      <author><first>Mike</first><last>Zhang</last><affiliation>IT University of Copenhagen</affiliation></author>
      <author><first>Rob</first><last>Goot</last></author>
      <author><first>Barbara</first><last>Plank</last><affiliation>Ludwig-Maximilians-Universität München and IT University of Copenhagen</affiliation></author>
      <pages>410-419</pages>
      <abstract>In Natural Language Processing, entity linking (EL) has centered around Wikipedia, but yet remains underexplored for the job market domain. Disambiguating skill mentions can help us get insight into the current labor market demands. In this work, we are the first to explore EL in this domain, specifically targeting the linkage of occupational skills to the ESCO taxonomy (le Vrang et al., 2014). Previous efforts linked coarse-grained (full) sentences to a corresponding ESCO skill. In this work, we link more fine-grained span-level mentions of skills. We tune two high-performing neural EL models, a bi-encoder (Wu et al., 2020) and an autoregressive model (Cao et al., 2021), on a synthetically generated mention–skill pair dataset and evaluate them on a human-annotated skill-linking benchmark. Our findings reveal that both models are capable of linking implicit mentions of skills to their correct taxonomy counterparts. Empirically, BLINK outperforms GENRE in strict evaluation, but GENRE performs better in loose evaluation (accuracy@k).</abstract>
      <url hash="21d3a5dd">2024.findings-eacl.28</url>
      <bibkey>zhang-etal-2024-entity</bibkey>
    </paper>
    <paper id="29">
      <title>(Chat)<fixed-case>GPT</fixed-case> v <fixed-case>BERT</fixed-case> Dawn of Justice for Semantic Change Detection</title>
      <author><first>Francesco</first><last>Periti</last><affiliation>University of Milan</affiliation></author>
      <author><first>Haim</first><last>Dubossarsky</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Nina</first><last>Tahmasebi</last><affiliation>Göteborg University</affiliation></author>
      <pages>420-436</pages>
      <abstract>In the universe of Natural Language Processing, Transformer-based language models like BERT and (Chat)GPT have emerged as lexical superheroes with great power to solve open research problems. In this paper, we specifically focus on the temporal problem of semantic change, and evaluate their ability to solve two diachronic extensions of the Word-in-Context (WiC) task: TempoWiC and HistoWiC. In particular, we investigate the potential of a novel, off-the-shelf technology like ChatGPT (and GPT) 3.5 compared to BERT, which represents a family of models that currently stand as the state-of-the-art for modeling semantic change. Our experiments represent the first attempt to assess the use of (Chat)GPT for studying semantic change. Our results indicate that ChatGPT performs significantly worse than the foundational GPT version. Furthermore, our results demonstrate that (Chat)GPT achieves slightly lower performance than BERT in detecting long-term changes but performs significantly worse in detecting short-term changes.</abstract>
      <url hash="248fa74e">2024.findings-eacl.29</url>
      <attachment type="software" hash="58309920">2024.findings-eacl.29.software.zip</attachment>
      <attachment type="note" hash="6ee98e73">2024.findings-eacl.29.note.zip</attachment>
      <bibkey>periti-etal-2024-chat</bibkey>
    </paper>
    <paper id="30">
      <title>Towards Unified Uni- and Multi-modal News Headline Generation</title>
      <author><first>Mateusz</first><last>Krubiński</last><affiliation>Charles University</affiliation></author>
      <author><first>Pavel</first><last>Pecina</last><affiliation>Charles University, Prague</affiliation></author>
      <pages>437-450</pages>
      <abstract>Thanks to the recent progress in vision-language modeling and the evolving nature of news consumption, the tasks of automatic summarization and headline generation based on multimodal news articles have been gaining popularity. One of the limitations of the current approaches is caused by the commonly used sophisticated modular architectures built upon hierarchical cross-modal encoders and modality-specific decoders, which restrict the model’s applicability to specific data modalities – once trained on, e.g., text+video pairs there is no straightforward way to apply the model to text+image or text-only data. In this work, we propose a unified task formulation that utilizes a simple encoder-decoder model to generate headlines from uni- and multi-modal news articles. This model is trained jointly on data of several modalities and extends the textual decoder to handle the multimodal output.</abstract>
      <url hash="3aed0449">2024.findings-eacl.30</url>
      <bibkey>krubinski-pecina-2024-towards</bibkey>
    </paper>
    <paper id="31">
      <title>On the Relationship between Sentence Analogy Identification and Sentence Structure Encoding in Large Language Models</title>
      <author><first>Thilini</first><last>Wijesiriwardene</last></author>
      <author><first>Ruwan</first><last>Wickramarachchi</last><affiliation>University of South Carolina</affiliation></author>
      <author><first>Aishwarya Naresh</first><last>Reganti</last><affiliation>Amazon</affiliation></author>
      <author><first>Vinija</first><last>Jain</last><affiliation>Stanford University</affiliation></author>
      <author><first>Aman</first><last>Chadha</last><affiliation>Amazon</affiliation></author>
      <author><first>Amit</first><last>Sheth</last><affiliation>University of South Carolina</affiliation></author>
      <author><first>Amitava</first><last>Das</last><affiliation>University of South Carolina</affiliation></author>
      <pages>451-457</pages>
      <abstract>The ability of Large Language Models (LLMs) to encode syntactic and semantic structures of language is well examined in NLP. Additionally, analogy identification, in the form of word analogies are extensively studied in the last decade of language modeling literature. In this work we specifically look at how LLMs’ abilities to capture sentence analogies (sentences that convey analogous meaning to each other) vary with LLMs’ abilities to encode syntactic and semantic structures of sentences. Through our analysis, we find that LLMs’ ability to identify sentence analogies is positively correlated with their ability to encode syntactic and semantic structures of sentences. Specifically, we find that the LLMs which capture syntactic structures better, also have higher abilities in identifying sentence analogies.</abstract>
      <url hash="6fe2b6ac">2024.findings-eacl.31</url>
      <bibkey>wijesiriwardene-etal-2024-relationship</bibkey>
    </paper>
    <paper id="32">
      <title>Contextualization Distillation from Large Language Model for Knowledge Graph Completion</title>
      <author><first>Dawei</first><last>Li</last></author>
      <author><first>Zhen</first><last>Tan</last></author>
      <author><first>Tianlong</first><last>Chen</last></author>
      <author><first>Huan</first><last>Liu</last><affiliation>Arizona State University</affiliation></author>
      <pages>458-477</pages>
      <abstract>While textual information significantly enhances the performance of pre-trained language models (PLMs) in knowledge graph completion (KGC), the static and noisy nature of existing corpora collected from Wikipedia articles or synsets definitions often limits the potential of PLM-based KGC models. To surmount these challenges, we introduce the <i>Contextualization Distillation</i> strategy, a versatile plug-in-and-play approach compatible with both discriminative and generative KGC frameworks. Our method begins by instructing large language models (LLMs) to transform compact, structural triplets into context-rich segments. Subsequently, we introduce two tailored auxiliary tasks—reconstruction and contextualization—allowing smaller KGC models to assimilate insights from these enriched triplets. Comprehensive evaluations across diverse datasets and KGC techniques highlight the efficacy and adaptability of our approach, revealing consistent performance enhancements irrespective of underlying pipelines or architectures. Moreover, our analysis makes our method more explainable and provides insight into how to generate high-quality corpora for KGC, as well as the selection of suitable distillation tasks.</abstract>
      <url hash="4b81611d">2024.findings-eacl.32</url>
      <bibkey>li-etal-2024-contextualization</bibkey>
      <revision id="1" href="2024.findings-eacl.32v1" hash="7f273319"/>
      <revision id="2" href="2024.findings-eacl.32v2" hash="4b81611d" date="2024-03-30">This revision corrects the citation display problem in the Appendix.</revision>
    </paper>
    <paper id="33">
      <title>Differentially Private Natural Language Models: Recent Advances and Future Directions</title>
      <author><first>Lijie</first><last>Hu</last><affiliation>KAUST</affiliation></author>
      <author><first>Ivan</first><last>Habernal</last><affiliation>Universität Paderborn</affiliation></author>
      <author><first>Lei</first><last>Shen</last><affiliation>JD AI Research, Beijing, China</affiliation></author>
      <author><first>Di</first><last>Wang</last><affiliation>KAUST</affiliation></author>
      <pages>478-499</pages>
      <abstract>Recent developments in deep learning have led to great success in various natural language processing (NLP) tasks. However, these applications may involve data that contain sensitive information. Therefore, how to achieve good performance while also protecting the privacy of sensitive data is a crucial challenge in NLP. To preserve privacy, Differential Privacy (DP), which can prevent reconstruction attacks and protect against potential side knowledge, is becoming a de facto technique for private data analysis. In recent years, NLP in DP models (DP-NLP) has been studied from different perspectives, which deserves a comprehensive review. In this paper, we provide the first systematic review of recent advances in DP deep learning models in NLP. In particular, we first discuss some differences and additional challenges of DP-NLP compared with the standard DP deep learning. Then, we investigate some existing work on DP-NLP andpresent its recent developments from three aspects: gradient perturbation based methods, embedding vector perturbation based methods, and ensemble model based methods. We also discuss some challenges and future directions.</abstract>
      <url hash="25234848">2024.findings-eacl.33</url>
      <bibkey>hu-etal-2024-differentially</bibkey>
    </paper>
    <paper id="34">
      <title>Learning to Compare Financial Reports for Financial Forecasting</title>
      <author><first>Ross</first><last>Koval</last><affiliation>University of California, Santa Barbara</affiliation></author>
      <author><first>Nicholas</first><last>Andrews</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Xifeng</first><last>Yan</last><affiliation>UC Santa Barbara</affiliation></author>
      <pages>500-512</pages>
      <abstract>Public companies in the US are required to publish annual reports that detail their recent financial performance, present the current state of ongoing business operations, and discuss future prospects. However, they typically contain over 25,000 words across all sections, large amounts of industry and legal jargon, and a high percentage of boilerplate content that does not change much year-to-year. These unique characteristics present challenges for many generic pretrained language models because it is likely that only a small percentage of the long report that reflects salient information contains meaningful signal about the future prospects of the company. In this work, we curate a large-scale dataset of paired financial reports and introduce two novel, challenging tasks of predicting long-horizon company risk and correlation that evaluate the ability of the model to recognize cross-document relationships with complex, nuanced signals. We explore and present a comprehensive set of methods and experiments, and establish strong baselines designed to learn to identify subtle similarities and differences between long documents. Furthermore, we demonstrate that it is possible to predict company risk and correlation solely from the text of their financial reports and further that modeling the cross-document interactions at a fine-grained level provides significant benefit. Finally, we probe the best performing model through quantitative and qualitative interpretability methods to reveal some insight into the underlying task signal.</abstract>
      <url hash="d6898770">2024.findings-eacl.34</url>
      <bibkey>koval-etal-2024-learning</bibkey>
    </paper>
    <paper id="35">
      <title>Arukikata Travelogue Dataset with Geographic Entity Mention, Coreference, and Link Annotation</title>
      <author><first>Shohei</first><last>Higashiyama</last><affiliation>Nara Institute of Science and Technology, Japan and National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology</affiliation></author>
      <author><first>Hiroki</first><last>Ouchi</last><affiliation>NAIST</affiliation></author>
      <author><first>Hiroki</first><last>Teranishi</last><affiliation>RIKEN</affiliation></author>
      <author><first>Hiroyuki</first><last>Otomo</last><affiliation>CyberAgent, Inc.</affiliation></author>
      <author><first>Yusuke</first><last>Ide</last></author>
      <author><first>Aitaro</first><last>Yamamoto</last><affiliation>Nara Institute of Science and Technology, Japan</affiliation></author>
      <author><first>Hiroyuki</first><last>Shindo</last><affiliation>Nara Institute of Science and Technology, Japan</affiliation></author>
      <author><first>Yuki</first><last>Matsuda</last><affiliation>Nara Institute of Science and Technology, Japan</affiliation></author>
      <author><first>Shoko</first><last>Wakamiya</last><affiliation>Nara Institute of Science and Technology</affiliation></author>
      <author><first>Naoya</first><last>Inoue</last><affiliation>RIKEN and Japan Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Ikuya</first><last>Yamada</last><affiliation>RIKEN and Studio Ousia</affiliation></author>
      <author><first>Taro</first><last>Watanabe</last><affiliation>Nara Institute of Science and Technology, Japan</affiliation></author>
      <pages>513-532</pages>
      <abstract>Geoparsing is a fundamental technique for analyzing geo-entity information in text, which is useful for geographic applications, e.g., tourist spot recommendation. We focus on document-level geoparsing that considers geographic relatedness among geo-entity mentions and present a Japanese travelogue dataset designed for training and evaluating document-level geoparsing systems. Our dataset comprises 200 travelogue documents with rich geo-entity information: 12,171 mentions, 6,339 coreference clusters, and 2,551 geo-entities linked to geo-database entries.</abstract>
      <url hash="feb0bd10">2024.findings-eacl.35</url>
      <bibkey>higashiyama-etal-2024-arukikata</bibkey>
    </paper>
    <paper id="36">
      <title>Knowledge Generation for Zero-shot Knowledge-based <fixed-case>VQA</fixed-case></title>
      <author><first>Rui</first><last>Cao</last></author>
      <author><first>Jing</first><last>Jiang</last><affiliation>Singapore Management University</affiliation></author>
      <pages>533-549</pages>
      <abstract>Previous solutions to knowledge-based visual question answering (K-VQA) retrieve knowledge from external knowledge bases and use supervised learning to train the K-VQA model.Recently pre-trained LLMs have been used as both a knowledge source and a zero-shot QA model for K-VQA and demonstrated promising results.However, these recent methods do not explicitly show the knowledge needed to answer the questions and thus lack interpretability.Inspired by recent work on knowledge generation from LLMs for text-based QA, in this work we propose and test a similar knowledge-generation-based K-VQA method, which first generates knowledge from an LLM and then incorporates the generated knowledge for K-VQA in a zero-shot manner. We evaluate our method on two K-VQA benchmarks and found that our method performs better than previous zero-shot K-VQA methods and our generated knowledge is generally relevant and helpful.</abstract>
      <url hash="fbd74890">2024.findings-eacl.36</url>
      <attachment type="software" hash="6164d06c">2024.findings-eacl.36.software.zip</attachment>
      <bibkey>cao-jiang-2024-knowledge</bibkey>
    </paper>
    <paper id="37">
      <title>Simple Temperature Cool-down in Contrastive Framework for Unsupervised Sentence Representation Learning</title>
      <author><first>Yoo Hyun</first><last>Jeong</last><affiliation>Hanyang University</affiliation></author>
      <author><first>Myeong Soo</first><last>Han</last><affiliation>Hanyang University</affiliation></author>
      <author><first>Dong-Kyu</first><last>Chae</last><affiliation>Hanyang University</affiliation></author>
      <pages>550-559</pages>
      <abstract>In this paper, we proposes a simple, tricky method to improve sentence representation of unsupervised contrastive learning. Even though contrastive learning has achieved great performances in both visual representation learning (VRL) and sentence representation learning (SRL) fields, we focus on the fact that there is a gap between characteristics and training dynamics of VRL and SRL. We first examine the role of temperature to bridge the gap between VRL and SRL, and find some temperature-dependent elements in SRL; <i>i.e.</i>, a higher temperature causes overfitting of the uniformity while improving the alignment in earlier phase of training. Then, we design a <i>temperature cool-down</i> technique based on this observation, which helps PLMs to be more suitable for contrastive learning via preparation of uniform representation space. Our experimental results on widely-utilized benchmarks demonstrate the effectiveness and extensiblity of our method.</abstract>
      <url hash="13d445d4">2024.findings-eacl.37</url>
      <bibkey>jeong-etal-2024-simple</bibkey>
    </paper>
    <paper id="38">
      <title>Bootstrap Your Own <fixed-case>PLM</fixed-case>: Boosting Semantic Features of <fixed-case>PLM</fixed-case>s for Unsuperivsed Contrastive Learning</title>
      <author><first>Yoo Hyun</first><last>Jeong</last><affiliation>Hanyang University</affiliation></author>
      <author><first>Myeong Soo</first><last>Han</last><affiliation>Hanyang University</affiliation></author>
      <author><first>Dong-Kyu</first><last>Chae</last><affiliation>Hanyang University</affiliation></author>
      <pages>560-569</pages>
      <abstract>This paper aims to investigate the possibility of exploiting original semantic features of PLMs (pre-trained language models) during contrastive learning in the context of SRL (sentence representation learning). In the context of feature modification, we identified a method called IFM (implicit feature modification), which reduces the tendency of contrastive models for VRL (visual representation learning) to rely on feature-suppressing shortcut solutions. We observed that IFM did not work well for SRL, which may be due to differences between the nature of VRL and SRL. We propose BYOP, which boosts well-represented features, taking the opposite idea of IFM, under the assumption that SimCSE’s dropout-noise-based augmentation may be too simple to modify high-level semantic features, and that the features learned by PLMs are semantically meaningful and should be boosted, rather than removed. Extensive experiments lend credence to the logic of BYOP, which considers the nature of SRL.</abstract>
      <url hash="10ca921c">2024.findings-eacl.38</url>
      <bibkey>jeong-etal-2024-bootstrap</bibkey>
    </paper>
    <paper id="39">
      <title>Personalized Abstractive Summarization by Tri-agent Generation Pipeline</title>
      <author><first>Wen</first><last>Xiao</last><affiliation>Microsoft</affiliation></author>
      <author><first>Yujia</first><last>Xie</last><affiliation>Microsoft</affiliation></author>
      <author><first>Giuseppe</first><last>Carenini</last><affiliation>, University of British Columbia</affiliation></author>
      <author><first>Pengcheng</first><last>He</last><affiliation>Microsoft</affiliation></author>
      <pages>570-581</pages>
      <abstract>Tailoring outputs from large language models, like ChatGPT, to implicit user preferences remains a challenge despite their impressive generative capabilities. In this paper, we propose a tri-agent generation pipeline comprising a generator, an instructor, and an editor to enhance output personalization. The generator produces an initial output, the instructor automatically generates editing instructions based on user preferences, and the editor refines the output to align with those preferences. The inference-only large language model (ChatGPT) serves as both the generator and editor, with a smaller model acting as the instructor to guide output generation. We train the instructor using editor-steered reinforcement learning, leveraging feedback from a large-scale editor model to optimize instruction generation. Experimental results on two abstractive summarization datasets demonstrate the effectiveness of our approach in generating outputs that better meet user expectations.</abstract>
      <url hash="17757746">2024.findings-eacl.39</url>
      <bibkey>xiao-etal-2024-personalized</bibkey>
    </paper>
    <paper id="40">
      <title>Revisiting the <fixed-case>M</fixed-case>arkov Property for Machine Translation</title>
      <author><first>Cunxiao</first><last>Du</last><affiliation>Singapore Management University</affiliation></author>
      <author><first>Hao</first><last>Zhou</last></author>
      <author><first>Zhaopeng</first><last>Tu</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Jing</first><last>Jiang</last><affiliation>Singapore Management University</affiliation></author>
      <pages>582-588</pages>
      <abstract>In this paper, we re-examine the Markov property in the context of neural machine translation. We design a Markov Autoregressive Transformer (MAT) and undertake a comprehensive assessment of its performance across four WMT benchmarks. Our findings indicate that MAT with an order larger than 4 can generate translations with quality on par with that of conventional autoregressive transformers. In addition, counter-intuitively, we also find that the advantages of utilizing a higher-order MAT do not specifically contribute to the translation of longer sentences.</abstract>
      <url hash="df419ec5">2024.findings-eacl.40</url>
      <bibkey>du-etal-2024-revisiting</bibkey>
    </paper>
    <paper id="41">
      <title>Reward Engineering for Generating Semi-structured Explanation</title>
      <author><first>Jiuzhou</first><last>Han</last></author>
      <author><first>Wray</first><last>Buntine</last><affiliation>VinUniversity</affiliation></author>
      <author><first>Ehsan</first><last>Shareghi</last><affiliation>Monash University and University of Cambridge</affiliation></author>
      <pages>589-602</pages>
      <abstract>Semi-structured explanation depicts the implicit process of a reasoner with an explicit representation. This explanation highlights how available information in a specific query is utilised and supplemented with information a reasoner produces from its internal weights towards generating an answer. Despite the recent improvements in generative capabilities of language models, producing structured explanations to verify a model’s true reasoning capabilities remains a challenge. This issue is particularly pronounced for not-so-large LMs (e.g., FLAN-T5-XXL). In this work, we first underscore the limitations of supervised fine-tuning (SFT) in tackling this challenge, and then introduce a carefully crafted reward engineering method in reinforcement learning (RL) to better address this problem. We investigate multiple reward aggregation methods and provide a detailed discussion which sheds light on the promising potential of RL for future research. Our proposed method on two semi-structured explanation generation benchmarks (ExplaGraph and COPA-SSE) achieves new state-of-the-art results.</abstract>
      <url hash="b3d3ccc3">2024.findings-eacl.41</url>
      <bibkey>han-etal-2024-reward</bibkey>
    </paper>
    <paper id="42">
      <title>Towards Context-Based Violence Detection: A <fixed-case>K</fixed-case>orean Crime Dialogue Dataset</title>
      <author><first>Minju</first><last>Kim</last></author>
      <author><first>Heuiyeen</first><last>Yeen</last></author>
      <author><first>Myoung-Wan</first><last>Koo</last><affiliation>Sogang University</affiliation></author>
      <pages>603-623</pages>
      <abstract>In order to enhance the security of society, there is rising interest in artificial intelligence (AI) to help detect and classify in advanced violence in daily life. The field of violence detection has introduced various datasets, yet context-based violence detection predominantly focuses on vision data, with a notable lack of NLP datasets. To overcome this, this paper presents the first Korean dialogue dataset for classifying violence that occurs in online settings: the Korean Crime Dialogue Dataset (KCDD). KCDD contains 22,249 dialogues created by crowd workers assuming offline scenarios. It has four criminal classes that meet international legal standards and one clean class (Serious Threats, Extortion or Blackmail, Harassment in the Workplace, Other Harassment, and Clean Dialogue). Plus, we propose a strong baseline for the proposed dataset, Relationship-Aware BERT. The model shows that understanding varying relationships among interlocutors improves the performance of crime dialogue classification. We hope that the proposed dataset will be used to detect cases of violence and aid people in danger. The KCDD dataset and corresponding baseline implementations can be found at the following link: <url>https://sites.google.com/view/kcdd</url>.</abstract>
      <url hash="f6301672">2024.findings-eacl.42</url>
      <attachment type="software" hash="e13f50ad">2024.findings-eacl.42.software.zip</attachment>
      <attachment type="note" hash="0af93109">2024.findings-eacl.42.note.zip</attachment>
      <bibkey>kim-etal-2024-towards</bibkey>
    </paper>
    <paper id="43">
      <title>Capturing the Relationship Between Sentence Triplets for <fixed-case>LLM</fixed-case> and Human-Generated Texts to Enhance Sentence Embeddings</title>
      <author><first>Na Min</first><last>An</last><affiliation>KAIST</affiliation></author>
      <author><first>Sania</first><last>Waheed</last><affiliation>Korea Advanced Institute of Science &amp; Technology</affiliation></author>
      <author><first>James</first><last>Thorne</last><affiliation>KAIST</affiliation></author>
      <pages>624-638</pages>
      <abstract>Deriving meaningful sentence embeddings is crucial in capturing the semantic relationship between texts. Recent advances in building sentence embedding models have centered on replacing traditional human-generated text datasets with those generated by LLMs. However, the properties of these widely used LLM-generated texts remain largely unexplored. Here, we evaluate the quality of the LLM-generated texts from four perspectives (Positive Text Repetition, Length Difference Penalty, Positive Score Compactness, and Negative Text Implausibility) and find that there exists an inherent difference between human and LLM-generated datasets. To further enhance sentence embeddings using both human and LLM-generated datasets, we propose a novel loss function that incorporates Positive-Negative sample Augmentation (PNA) within the contrastive learning objective. Our results demonstrate that PNA effectively mitigates the sentence anisotropy problem in Wikipedia corpus (-7% compared to CLHAIF) and simultaneously improves the Spearman’s correlation in standard Semantic Textual Similarity (STS) tasks (+1.47% compared to CLHAIF).</abstract>
      <url hash="5023b599">2024.findings-eacl.43</url>
      <bibkey>an-etal-2024-capturing</bibkey>
    </paper>
    <paper id="44">
      <title>Harmonizing Code-mixed Conversations: Personality-assisted Code-mixed Response Generation in Dialogues</title>
      <author><first>Shivani</first><last>Kumar</last><affiliation>Indraprastha Institute of Information Technology, Delhi, Dhirubhai Ambani Institute Of Information and Communication Technology</affiliation></author>
      <author><first>Tanmoy</first><last>Chakraborty</last><affiliation>Indian Institute of Technology, Delhi</affiliation></author>
      <pages>639-653</pages>
      <abstract>Code-mixing, the blending of multiple languages within a single conversation, introduces a distinctive challenge, particularly in the context of response generation. Capturing the intricacies of code-mixing proves to be a formidable task, given the wide-ranging variations influenced by individual speaking styles and cultural backgrounds. In this study, we explore response generation within code-mixed conversations. We introduce a novel approach centered on harnessing the Big Five personality traits acquired in an unsupervised manner from the conversations to bolster the performance of response generation. These inferred personality attributes are seamlessly woven into the fabric of the dialogue context, using a novel fusion mechanism, . It uses an effective two-step attention formulation to fuse the dialogue and personality information. This fusion not only enhances the contextual relevance of generated responses but also elevates the overall performance of the model. Our experimental results, grounded in a dataset comprising of multi-party Hindi-English code-mix conversations, highlight the substantial advantages offered by personality-infused models over their conventional counterparts. This is evident in the increase observed in ROUGE and BLUE scores for the response generation task when the identified personality is seamlessly integrated into the dialogue context. Qualitative assessment for personality identification and response generation aligns well with our quantitative results.</abstract>
      <url hash="6210c1f5">2024.findings-eacl.44</url>
      <bibkey>kumar-chakraborty-2024-harmonizing</bibkey>
    </paper>
    <paper id="45">
      <title>Morality is Non-Binary: Building a Pluralist Moral Sentence Embedding Space using Contrastive Learning</title>
      <author><first>Jeongwoo</first><last>Park</last></author>
      <author><first>Enrico</first><last>Liscio</last></author>
      <author><first>Pradeep</first><last>Murukannaiah</last><affiliation>Delft University of Technology</affiliation></author>
      <pages>654-673</pages>
      <abstract>Recent advances in NLP show that language models retain a discernible level of knowledge in deontological ethics and moral norms. However, existing works often treat morality as binary, ranging from right to wrong. This simplistic view does not capture the nuances of moral judgment. Pluralist moral philosophers argue that human morality can be deconstructed into a finite number of elements, respecting individual differences in moral judgment. In line with this view, we build a pluralist moral sentence embedding space via a state-of-the-art contrastive learning approach. We systematically investigate the embedding space by studying the emergence of relationships among moral elements, both quantitatively and qualitatively. Our results show that a pluralist approach to morality can be captured in an embedding space. However, moral pluralism is challenging to deduce via self-supervision alone and requires a supervised approach with human labels.</abstract>
      <url hash="7a5007bf">2024.findings-eacl.45</url>
      <attachment type="software" hash="935b473d">2024.findings-eacl.45.software.zip</attachment>
      <bibkey>park-etal-2024-morality</bibkey>
    </paper>
    <paper id="46">
      <title>Prosody in Cascade and Direct Speech-to-Text Translation: a case study on <fixed-case>K</fixed-case>orean Wh-Phrases</title>
      <author><first>Giulio</first><last>Zhou</last><affiliation>University of Edinburgh, University of Edinburgh</affiliation></author>
      <author><first>Tsz Kin</first><last>Lam</last><affiliation>University of Edinburgh, University of Edinburgh</affiliation></author>
      <author><first>Alexandra</first><last>Birch</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Barry</first><last>Haddow</last></author>
      <pages>674-683</pages>
      <abstract>Speech-to-Text Translation (S2TT) has typically been addressed with cascade systems, where speech recognition systems generate a transcription that is subsequently passed to a translation model. While there has been a growing interest in developing direct speech translation systems to avoid propagating errors and losing non-verbal content, prior work in direct S2TT has struggled to conclusively establish the advantages of integrating the acoustic signal directly into the translation process. This work proposes using contrastive evaluation to quantitatively measure the ability of direct S2TT systems to disambiguate utterances where prosody plays a crucial role. Specifically, we evaluated Korean-English translation systems on a test set containing wh-phrases, for which prosodic features are necessary to produce translations with the correct intent, whether it’s a statement, a yes/no question, a wh-question, and more. Our results clearly demonstrate the value of direct translation systems over cascade translation models, with a notable 12.9% improvement in overall accuracy in ambiguous cases, along with up to a 15.6% increase in F1 scores for one of the major intent categories. To the best of our knowledge, this work stands as the first to provide quantitative evidence that direct S2TT models can effectively leverage prosody. The code for our evaluation is openly accessible and freely available for review and utilisation.</abstract>
      <url hash="5135cf37">2024.findings-eacl.46</url>
      <bibkey>zhou-etal-2024-prosody</bibkey>
    </paper>
    <paper id="47">
      <title>Exploring the Potential of <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations</title>
      <author><first>Chunkit</first><last>Chan</last></author>
      <author><first>Cheng</first><last>Jiayang</last><affiliation>Department of Computer Science and Engineering, Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Weiqi</first><last>Wang</last></author>
      <author><first>Yuxin</first><last>Jiang</last></author>
      <author><first>Tianqing</first><last>Fang</last></author>
      <author><first>Xin</first><last>Liu</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Yangqiu</first><last>Song</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <pages>684-721</pages>
      <abstract>This paper aims to quantitatively evaluate the performance of ChatGPT, an interactive large language model, on inter-sentential relations such as temporal relations, causal relations, and discourse relations. Given ChatGPT’s promising performance across various tasks, we proceed to carry out thorough evaluations on the whole test sets of 11 datasets, including temporal and causal relations, PDTB2.0-based, and dialogue-based discourse relations. To ensure the reliability of our findings, we employ three tailored prompt templates for each task, including the zero-shot prompt template, zero-shot prompt engineering (PE) template, and in-context learning (ICL) prompt template, to establish the initial baseline scores for all popular sentence-pair relation classification tasks for the first time. Through our study, we discover that ChatGPT exhibits exceptional proficiency in detecting and reasoning about causal relations, albeit it may not possess the same level of expertise in identifying the temporal order between two events. While it is capable of identifying the majority of discourse relations with existing explicit discourse connectives, the implicit discourse relation remains a formidable challenge. Concurrently, ChatGPT demonstrates subpar performance in the dialogue discourse parsing task that requires structural understanding in a dialogue before being aware of the discourse relation.</abstract>
      <url hash="375a167d">2024.findings-eacl.47</url>
      <bibkey>chan-etal-2024-exploring</bibkey>
    </paper>
    <paper id="48">
      <title>Backtracing: Retrieving the Cause of the Query</title>
      <author><first>Rose</first><last>Wang</last><affiliation>Stanford University</affiliation></author>
      <author><first>Pawan</first><last>Wirawarn</last></author>
      <author><first>Omar</first><last>Khattab</last></author>
      <author><first>Noah</first><last>Goodman</last><affiliation>Stanford University</affiliation></author>
      <author><first>Dorottya</first><last>Demszky</last><affiliation>Stanford University</affiliation></author>
      <pages>722-735</pages>
      <abstract>Many online content portals allow users to ask questions to supplement their understanding (e.g., of lectures). While information retrieval (IR) systems may provide answers for such user queries, they do not directly assist content creators—such as lecturers who want to improve their content—identify segments that caused a user to ask those questions.We introduce the task of backtracing, in which systems retrieve the text segment that most likely caused a user query.We formalize three real-world domains for which backtracing is important in improving content delivery and communication: understanding the cause of (a) student confusion in the Lecture domain, (b) reader curiosity in the News Article domain, and (c) user emotion in the Conversation domain.We evaluate the zero-shot performance of popular information retrieval methods and language modeling methods, including bi-encoder, re-ranking and likelihood-based methods and ChatGPT.While traditional IR systems retrieve semantically relevant information (e.g., details on “projection matrices” for a query “does projecting multiple times still lead to the same point?”), they often miss the causally relevant context (e.g., the lecturer states “projecting twice gets me the same answer as one projection”). Our results show that there is room for improvement on backtracing and it requires new retrieval approaches.We hope our benchmark serves to improve future retrieval systems for backtracing, spawning systems that refine content generation and identify linguistic triggers influencing user queries.</abstract>
      <url hash="b176d238">2024.findings-eacl.48</url>
      <bibkey>wang-etal-2024-backtracing</bibkey>
    </paper>
    <paper id="49">
      <title>Unsupervised Multilingual Dense Retrieval via Generative Pseudo Labeling</title>
      <author><first>Chao-Wei</first><last>Huang</last><affiliation>National Taiwan University</affiliation></author>
      <author><first>Chen-An</first><last>Li</last><affiliation>Department of computer science and informational engineering, National Taiwan University</affiliation></author>
      <author><first>Tsu-Yuan</first><last>Hsu</last></author>
      <author><first>Chen-Yu</first><last>Hsu</last><affiliation>National Taiwan University</affiliation></author>
      <author><first>Yun-Nung</first><last>Chen</last><affiliation>Department of Computer Science and Informational Engineering, National Taiwan University</affiliation></author>
      <pages>736-746</pages>
      <abstract>Dense retrieval methods have demonstrated promising performance in multilingual information retrieval, where queries and documents can be in different languages. However, dense retrievers typically require a substantial amount of paired data, which poses even greater challenges in multilingual scenarios. This paper introduces <tex-math>\textbf{UMR}</tex-math>, an <tex-math>\underline{U}</tex-math>nsupervised <tex-math>\underline{M}</tex-math>ultilingual dense <tex-math>\underline{R}</tex-math>etriever trained without any paired data. Our approach leverages the sequence likelihood estimation capabilities of multilingual language models to acquire pseudo labels for training dense retrievers. We propose a two-stage framework which iteratively improves the performance of multilingual dense retrievers. Experimental results on two benchmark datasets show that UMR outperforms supervised baselines, showcasing the potential of training multilingual retrievers without paired data, thereby enhancing their practicality. All of our source code, data, and models are available: https://github.com/MiuLab/UMR</abstract>
      <url hash="9afec971">2024.findings-eacl.49</url>
      <attachment type="software" hash="a6b3b82e">2024.findings-eacl.49.software.zip</attachment>
      <bibkey>huang-etal-2024-unsupervised</bibkey>
    </paper>
    <paper id="50">
      <title>Investigating grammatical abstraction in language models using few-shot learning of novel noun gender</title>
      <author><first>Priyanka</first><last>Sukumaran</last></author>
      <author><first>Conor</first><last>Houghton</last><affiliation>University of Bristol</affiliation></author>
      <author><first>Nina</first><last>Kazanina</last><affiliation>University of Bristol</affiliation></author>
      <pages>747-765</pages>
      <abstract>Humans can learn a new word and infer its grammatical properties from very few examples. They have an abstract notion of linguistic properties like grammatical gender and agreement rules that can be applied to novel syntactic contexts and words. Drawing inspiration from psycholinguistics, we conduct a noun learning experiment to assess whether an LSTM and a decoder-only transformer can achieve human-like abstraction of grammatical gender in French. Language models were tasked with learning the gender of a novel noun embedding from a few examples in one grammatical agreement context and predicting agreement in another, unseen context. We find that both language models effectively generalise novel noun gender from one to two learning examples and apply the learnt gender across agreement contexts, albeit with a bias for the masculine gender category. Importantly, the few-shot updates were only applied to the embedding layers, demonstrating that models encode sufficient gender information within the word-embedding space. While the generalisation behaviour of models suggests that they represent grammatical gender as an abstract category, like humans, further work is needed to explore the details of how exactly this is implemented. For a comparative perspective with human behaviour, we conducted an analogous one-shot novel noun gender learning experiment, which revealed that native French speakers, like language models, also exhibited a masculine gender bias and are not excellent one-shot learners either.</abstract>
      <url hash="8b217871">2024.findings-eacl.50</url>
      <bibkey>sukumaran-etal-2024-investigating</bibkey>
    </paper>
    <paper id="51">
      <title>On-the-fly Denoising for Data Augmentation in Natural Language Understanding</title>
      <author><first>Tianqing</first><last>Fang</last></author>
      <author><first>Wenxuan</first><last>Zhou</last><affiliation>Zoom</affiliation></author>
      <author><first>Fangyu</first><last>Liu</last><affiliation>Google DeepMind</affiliation></author>
      <author><first>Hongming</first><last>Zhang</last></author>
      <author><first>Yangqiu</first><last>Song</last><affiliation>The Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Muhao</first><last>Chen</last><affiliation>University of California, Davis and University of Southern California</affiliation></author>
      <pages>766-781</pages>
      <abstract>Data Augmentation (DA) is frequently used to provide additional training data without extra human annotation automatically.However, data augmentation may introduce noisy data that impairs training.To guarantee the quality of augmented data,existing methods either assume no noise exists in the augmented data and adopt consistency training or use simple heuristics such as training loss and diversity constraints to filter out “noisy” data.However, those filtered examples may still contain useful information, and dropping them completely causes a loss of supervision signals.In this paper, based on the assumption that the original dataset is cleaner than the augmented data, we propose an on-the-fly denoising technique for data augmentation that learns from soft augmented labels provided by an organic teacher model trained on the cleaner original data.To further prevent overfitting on noisy labels, a simple self-regularization module is applied to force the model prediction to be consistent across two distinct dropouts.Our method can be applied to general augmentation techniques and consistently improve the performance on both text classification and question-answering tasks.</abstract>
      <url hash="def6cbc2">2024.findings-eacl.51</url>
      <attachment type="software" hash="f0ea4f26">2024.findings-eacl.51.software.zip</attachment>
      <attachment type="note" hash="7205c223">2024.findings-eacl.51.note.zip</attachment>
      <bibkey>fang-etal-2024-fly</bibkey>
    </paper>
    <paper id="52">
      <title>Style Vectors for Steering Generative Large Language Models</title>
      <author><first>Kai</first><last>Konen</last><affiliation>Universität Bielefeld</affiliation></author>
      <author><first>Sophie</first><last>Jentzsch</last><affiliation>German Aerospace Center (DLR)</affiliation></author>
      <author><first>Diaoulé</first><last>Diallo</last><affiliation>German Aerospace Center (DLR)</affiliation></author>
      <author><first>Peer</first><last>Schütt</last><affiliation>German Aerospace Center</affiliation></author>
      <author><first>Oliver</first><last>Bensch</last><affiliation>German Aerospace Center (DLR)</affiliation></author>
      <author><first>Roxanne</first><last>El Baff</last><affiliation>German Aerospace Center and Bauhaus-University Weimar</affiliation></author>
      <author><first>Dominik</first><last>Opitz</last><affiliation>German Aerospace Center (DLR)</affiliation></author>
      <author><first>Tobias</first><last>Hecking</last><affiliation>German Aerospace Center</affiliation></author>
      <pages>782-802</pages>
      <abstract>This research explores strategies for steering the output of large language models (LLMs) towards specific styles, such as sentiment, emotion, or writing style, by adding style vectors to the activations of hidden layers during text generation. We show that style vectors can be simply computed from recorded layer activations for input texts in a specific style in contrast to more complex training-based approaches. Through a series of experiments, we demonstrate the effectiveness of activation engineering using such style vectors to influence the style of generated text in a nuanced and parameterisable way, distinguishing it from prompt engineering. The presented research constitutes a significant step towards developing more adaptive and effective AI-empowered interactive systems.</abstract>
      <url hash="a02d4eb5">2024.findings-eacl.52</url>
      <attachment type="software" hash="29f876dd">2024.findings-eacl.52.software.zip</attachment>
      <bibkey>konen-etal-2024-style</bibkey>
    </paper>
    <paper id="53">
      <title>Consistent Joint Decision-Making with Heterogeneous Learning Models</title>
      <author><first>Hossein</first><last>Rajaby Faghihi</last></author>
      <author><first>Parisa</first><last>Kordjamshidi</last><affiliation>Michigan State University</affiliation></author>
      <pages>803-813</pages>
      <abstract>This paper introduces a novel decision-making framework that promotes consistency among decisions made by diverse models while utilizing external knowledge. Leveraging the Integer Linear Programming(ILP) framework, we map predictions from various models into globally normalized and comparable values by incorporating information about decisions’ prior probability, confidence (uncertainty), and the models’ expected accuracy. Our empirical study demonstrates the superiority of our approach over conventional baselines on multiple datasets.</abstract>
      <url hash="4dc934db">2024.findings-eacl.53</url>
      <bibkey>rajaby-faghihi-kordjamshidi-2024-consistent</bibkey>
    </paper>
    <paper id="54">
      <title>Quantifying Association Capabilities of Large Language Models and Its Implications on Privacy Leakage</title>
      <author><first>Hanyin</first><last>Shao</last></author>
      <author><first>Jie</first><last>Huang</last><affiliation>University of Illinois, Urbana Champaign</affiliation></author>
      <author><first>Shen</first><last>Zheng</last><affiliation>Department of Computer Science</affiliation></author>
      <author><first>Kevin</first><last>Chang</last><affiliation>University of Illinois, Urbana Champaign</affiliation></author>
      <pages>814-825</pages>
      <abstract>The advancement of large language models (LLMs) brings notable improvements across various applications, while simultaneously raising concerns about potential private data exposure. One notable capability of LLMs is their ability to form associations between different pieces of information, but this raises concerns when it comes to personally identifiable information (PII). This paper delves into the association capabilities of language models, aiming to uncover the factors that influence their proficiency in associating information. Our study reveals that as models scale up, their capacity to associate entities/information intensifies, particularly when target pairs demonstrate shorter co-occurrence distances or higher co-occurrence frequencies. However, there is a distinct performance gap when associating commonsense knowledge versus PII, with the latter showing lower accuracy. Despite the proportion of accurately predicted PII being relatively small, LLMs still demonstrate the capability to predict specific instances of email addresses and phone numbers when provided with appropriate prompts. These findings underscore the potential risk to PII confidentiality posed by the evolving capabilities of LLMs, especially as they continue to expand in scale and power.</abstract>
      <url hash="0e1d4951">2024.findings-eacl.54</url>
      <bibkey>shao-etal-2024-quantifying</bibkey>
    </paper>
    <paper id="55">
      <title>Probing Critical Learning Dynamics of <fixed-case>PLM</fixed-case>s for Hate Speech Detection</title>
      <author><first>Sarah</first><last>Masud</last><affiliation>Indraprastha Institute of Information Technology Delhi (IIIT-Delhi)</affiliation></author>
      <author><first>Mohammad Aflah</first><last>Khan</last></author>
      <author><first>Vikram</first><last>Goyal</last><affiliation>Indraprastha Institute of Information Technology, Delhi</affiliation></author>
      <author><first>Md Shad</first><last>Akhtar</last><affiliation>Indraprastha Institute of Information Technology, Delhi</affiliation></author>
      <author><first>Tanmoy</first><last>Chakraborty</last><affiliation>Indian Institute of Technology, Delhi</affiliation></author>
      <pages>826-845</pages>
      <abstract>Despite the widespread adoption, there is a lack of research into how various critical aspects of pretrained language models (PLMs) affect their performance in hate speech detection. Through five research questions, our findings and recommendations lay the groundwork for empirically investigating different aspects of PLMs’ use in hate speech detection. We deep dive into comparing different pretrained models, evaluating their seed robustness, finetuning settings, and the impact of pretraining data collection time. Our analysis reveals early peaks for downstream tasks during pretraining, the limited benefit of employing a more recent pretraining corpus, and the significance of specific layers during finetuning. We further call into question the use of domain-specific models and highlight the need for dynamic datasets for benchmarking hate speech detection.</abstract>
      <url hash="9b9e33fb">2024.findings-eacl.55</url>
      <attachment type="software" hash="5e4d61a2">2024.findings-eacl.55.software.zip</attachment>
      <bibkey>masud-etal-2024-probing</bibkey>
    </paper>
    <paper id="56">
      <title>Embible: Reconstruction of <fixed-case>A</fixed-case>ncient <fixed-case>H</fixed-case>ebrew and <fixed-case>A</fixed-case>ramaic Texts Using Transformers</title>
      <author><first>Niv</first><last>Fono</last></author>
      <author><first>Harel</first><last>Moshayof</last></author>
      <author><first>Eldar</first><last>Karol</last></author>
      <author><first>Itai</first><last>Assraf</last></author>
      <author><first>Mark</first><last>Last</last><affiliation>Ben-Gurion University of the Negev</affiliation></author>
      <pages>846-852</pages>
      <abstract>Hebrew and Aramaic inscriptions serve as an essential source of information on the ancient history of the Near East. Unfortunately, some parts of the inscribed texts become illegible over time. Special experts, called epigraphists, use time-consuming manual procedures to estimate the missing content. This problem can be considered an extended masked language modeling task, where the damaged content can comprise single characters, character n-grams (partial words), single complete words, and multi-word n-grams.This study is the first attempt to apply the masked language modeling approach to corrupted inscriptions in Hebrew and Aramaic languages, both using the Hebrew alphabet consisting mostly of consonant symbols. In our experiments, we evaluate several transformer-based models, which are fine-tuned on the Biblical texts and tested on three different percentages of randomly masked parts in the testing corpus. For any masking percentage, the highest text completion accuracy is obtained with a novel ensemble of word and character prediction models.</abstract>
      <url hash="a4fcfdf5">2024.findings-eacl.56</url>
      <bibkey>fono-etal-2024-embible</bibkey>
    </paper>
    <paper id="57">
      <title>Stateful Memory-Augmented Transformers for Efficient Dialogue Modeling</title>
      <author><first>Qingyang</first><last>Wu</last><affiliation>Columbia University</affiliation></author>
      <author><first>Zhou</first><last>Yu</last><affiliation>Columbia University</affiliation></author>
      <pages>853-867</pages>
      <abstract>Transformer models have achieved great performance in dialogue generation tasks. However, their inability to process long dialogue history often leads to truncation of the context. To address this problem, we propose a novel memory-augmented transformer that is compatible with existing pre-trained encoder-decoder models and enables efficient preservation of the dialogue history information. The new model incorporates a separate memory module alongside the pre-trained transformer, which can effectively interchange information between the memory states and the current input context. We evaluate the efficiency of our model on three dialogue datasets and two language modeling datasets. Experimental results show that our method has achieved superior efficiency and performance compared to other pre-trained Transformer baselines.</abstract>
      <url hash="98a3579c">2024.findings-eacl.57</url>
      <attachment type="software" hash="83a1986c">2024.findings-eacl.57.software.zip</attachment>
      <bibkey>wu-yu-2024-stateful</bibkey>
    </paper>
    <paper id="58">
      <title>The Shape of Learning: Anisotropy and Intrinsic Dimensions in Transformer-Based Models</title>
      <author><first>Anton</first><last>Razzhigaev</last><affiliation>Skolkovo Institute of Science and Technology</affiliation></author>
      <author><first>Matvey</first><last>Mikhalchuk</last><affiliation>Artificial Intelligence Research Institute (AIRI) and Lomonosov Moscow State University</affiliation></author>
      <author><first>Elizaveta</first><last>Goncharova</last></author>
      <author><first>Ivan</first><last>Oseledets</last><affiliation>Artificial Intelligence Research Institute and Skolkovo Institute of Science and Technology</affiliation></author>
      <author><first>Denis</first><last>Dimitrov</last><affiliation>AIRI and Sber</affiliation></author>
      <author><first>Andrey</first><last>Kuznetsov</last><affiliation>Samara National Research University</affiliation></author>
      <pages>868-874</pages>
      <abstract>In this study, we present an investigation into the anisotropy dynamics and intrinsic dimension of embeddings in transformer architectures, focusing on the dichotomy between encoders and decoders. Our findings reveal that the anisotropy profile in transformer decoders exhibits a distinct bell-shaped curve, with the highest anisotropy concentrations in the middle layers. This pattern diverges from the more uniformly distributed anisotropy observed in encoders. In addition, we found that the intrinsic dimension of embeddings increases in the initial phases of training, indicating an expansion into higher-dimensional space. This fact is then followed by a compression phase towards the end of training with dimensionality decrease, suggesting a refinement into more compact representations. Our results provide fresh insights to the understanding of encoders and decoders embedding properties.</abstract>
      <url hash="3436b782">2024.findings-eacl.58</url>
      <bibkey>razzhigaev-etal-2024-shape</bibkey>
    </paper>
    <paper id="59">
      <title><fixed-case>MED</fixed-case>s for <fixed-case>PET</fixed-case>s: Multilingual Euphemism Disambiguation for Potentially Euphemistic Terms</title>
      <author><first>Patrick</first><last>Lee</last></author>
      <author><first>Alain</first><last>Chirino Trujillo</last><affiliation>Montclair State University</affiliation></author>
      <author><first>Diana</first><last>Cuevas Plancarte</last></author>
      <author><first>Olumide</first><last>Ojo</last></author>
      <author><first>Xinyi</first><last>Liu</last><affiliation>Montclair State University</affiliation></author>
      <author><first>Iyanuoluwa</first><last>Shode</last></author>
      <author><first>Yuan</first><last>Zhao</last><affiliation>Montclair State University</affiliation></author>
      <author><first>Anna</first><last>Feldman</last><affiliation>Montclair State University</affiliation></author>
      <author><first>Jing</first><last>Peng</last><affiliation>Montclair State University</affiliation></author>
      <pages>875-881</pages>
      <abstract>Euphemisms are found across the world’s languages, making them a universal linguistic phenomenon. As such, euphemistic data may have useful properties for computational tasks across languages. In this study, we explore this premise by training a multilingual transformer model (XLM-RoBERTa) to disambiguate potentially euphemistic terms (PETs) in multilingual and cross-lingual settings. In line with current trends, we demonstrate that zero-shot learning across languages takes place. We also show cases where multilingual models perform better on the task compared to monolingual models by a statistically significant margin, indicating that multilingual data presents additional opportunities for models to learn about cross-lingual, computational properties of euphemisms. In a follow-up analysis, we focus on universal euphemistic “categories” such as death and bodily functions among others. We test to see whether cross-lingual data of the same domain is more important than within-language data of other domains to further understand the nature of the cross-lingual transfer.</abstract>
      <url hash="23037a84">2024.findings-eacl.59</url>
      <bibkey>lee-etal-2024-meds</bibkey>
    </paper>
    <paper id="60">
      <title><fixed-case>P</fixed-case>rompt<fixed-case>E</fixed-case>xplainer: Explaining Language Models through Prompt-based Learning</title>
      <author><first>Zijian</first><last>Feng</last></author>
      <author><first>Hanzhang</first><last>Zhou</last></author>
      <author><first>Zixiao</first><last>Zhu</last></author>
      <author><first>Kezhi</first><last>Mao</last><affiliation>Nanyang Technological University</affiliation></author>
      <pages>882-895</pages>
      <abstract>Pretrained language models have become workhorses for various natural language processing (NLP) tasks, sparking a growing demand for enhanced interpretability and transparency. However, prevailing explanation methods, such as attention-based and gradient-based strategies, largely rely on linear approximations, potentially causing inaccuracies such as accentuating irrelevant input tokens. To mitigate the issue, we develop PromptExplainer, a novel method for explaining language models through prompt-based learning. PromptExplainer aligns the explanation process with the masked language modeling (MLM) task of pretrained language models and leverages the prompt-based learning framework for explanation generation. It disentangles token representations into the explainable embedding space using the MLM head and extracts discriminative features with a verbalizer to generate class-dependent explanations. Extensive experiments demonstrate that PromptExplainer significantly outperforms state-of-the-art explanation methods.</abstract>
      <url hash="fd7afc75">2024.findings-eacl.60</url>
      <attachment type="software" hash="e7e35714">2024.findings-eacl.60.software.zip</attachment>
      <bibkey>feng-etal-2024-promptexplainer</bibkey>
    </paper>
    <paper id="61">
      <title>Do-Not-Answer: Evaluating Safeguards in <fixed-case>LLM</fixed-case>s</title>
      <author><first>Yuxia</first><last>Wang</last></author>
      <author><first>Haonan</first><last>Li</last></author>
      <author><first>Xudong</first><last>Han</last><affiliation>University of Melbourne</affiliation></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <author><first>Timothy</first><last>Baldwin</last><affiliation>Mohamed bin Zayed University of Artificial Intelligence and The University of Melbourne</affiliation></author>
      <pages>896-911</pages>
      <abstract>With the rapid evolution of large language models (LLMs), new and hard-to-predict harmful capabilities are emerging. This requires developers to identify potential risks through the evaluation of “dangerous capabilities” in order to responsibly deploy LLMs. Here we aim to facilitate this process. In particular, we collect an open-source dataset to evaluate the safeguards in LLMs, to facilitate the deployment of safer open-source LLMs at a low cost. Our dataset is curated and filtered to consist only of instructions that responsible language models should not follow. We assess the responses of six popular LLMs to these instructions, and we find that simple BERT-style classifiers can achieve results that are comparable to GPT-4 on automatic safety evaluation. Our data and code are available at https://github.com/Libr-AI/do-not-answer</abstract>
      <url hash="3329c299">2024.findings-eacl.61</url>
      <bibkey>wang-etal-2024-answer</bibkey>
    </paper>
    <paper id="62">
      <title>Do Language Models Know When They’re Hallucinating References?</title>
      <author><first>Ayush</first><last>Agrawal</last><affiliation>Microsoft</affiliation></author>
      <author><first>Mirac</first><last>Suzgun</last><affiliation>Stanford University</affiliation></author>
      <author><first>Lester</first><last>Mackey</last><affiliation>Microsoft Research New England</affiliation></author>
      <author><first>Adam</first><last>Kalai</last></author>
      <pages>912-928</pages>
      <abstract>State-of-the-art language models (LMs) are notoriously susceptible to generating hallucinated information. Such inaccurate outputs not only undermine the reliability of these models but also limit their use and raise serious concerns about misinformation and propaganda. In this work, we focus on hallucinated book and article references and present them as the “model organism” of language model hallucination research, due to their frequent and easy-to-discern nature. We posit that if a language model cites a particular reference in its output, then it should ideally possess sufficient information about its authors and content, among other relevant details. Using this basic insight, we illustrate that one can identify hallucinated references without ever consulting any external resources, by asking a set of direct or indirect queries to the language model about the references. These queries can be considered as “consistency checks.” Our findings highlight that while LMs, including GPT-4, often produce inconsistent author lists for hallucinated references, they also often accurately recall the authors of real references. In this sense, the LM can be said to “know” when it is hallucinating references. Furthermore, these findings show how hallucinated references can be dissected to shed light on their nature.</abstract>
      <url hash="1d49754a">2024.findings-eacl.62</url>
      <attachment type="software" hash="2c355a56">2024.findings-eacl.62.software.zip</attachment>
      <attachment type="note" hash="35db54a9">2024.findings-eacl.62.note.zip</attachment>
      <bibkey>agrawal-etal-2024-language</bibkey>
    </paper>
    <paper id="63">
      <title>Bridging Cultural Nuances in Dialogue Agents through Cultural Value Surveys</title>
      <author><first>Yong</first><last>Cao</last></author>
      <author><first>Min</first><last>Chen</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Daniel</first><last>Hershcovich</last><affiliation>University of Copenhagen</affiliation></author>
      <pages>929-945</pages>
      <abstract>The cultural landscape of interactions with dialogue agents is a compelling yet relatively unexplored territory. It’s clear that various sociocultural aspects—from communication styles and beliefs to shared metaphors and knowledge—profoundly impact these interactions. To delve deeper into this dynamic, we introduce cuDialog, a first-of-its-kind benchmark for dialogue generation with a cultural lens. We also develop baseline models capable of extracting cultural attributes from dialogue exchanges, with the goal of enhancing the predictive accuracy and quality of dialogue agents. To effectively co-learn cultural understanding and multi-turn dialogue predictions, we propose to incorporate cultural dimensions with dialogue encoding features. Our experimental findings highlight that incorporating cultural value surveys boosts alignment with references and cultural markers, demonstrating its considerable influence on personalization and dialogue quality. To facilitate further exploration in this exciting domain, we publish our benchmark publicly accessible at https://github.com/yongcaoplus/cuDialog.</abstract>
      <url hash="37d09e4b">2024.findings-eacl.63</url>
      <bibkey>cao-etal-2024-bridging</bibkey>
    </paper>
    <paper id="64">
      <title><fixed-case>CEO</fixed-case>: Corpus-based Open-Domain Event Ontology Induction</title>
      <author><first>Nan</first><last>Xu</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Hongming</first><last>Zhang</last></author>
      <author><first>Jianshu</first><last>Chen</last><affiliation>Tencent AI Lab</affiliation></author>
      <pages>946-964</pages>
      <abstract>Existing event-centric NLP models often only apply to the pre-defined ontology, which significantly restricts their generalization capabilities.This paper presents CEO, a novel Corpus-based Event Ontology induction model to relax the restriction imposed by pre-defined event ontologies. Without direct supervision, CEO leverages distant supervision from available summary datasets to detect corpus-wise salient events and exploits external event knowledge to force events within a short distance to have close embeddings. Experiments on three popular event datasets show that the schema induced by CEO has better coverage and higher accuracy than previous methods. Moreover, CEO is the first event ontology induction model that can induce a hierarchical event ontology with meaningful names on eleven open-domain corpora, making the induced schema more trustworthy and easier to be further curated. We anonymously release our dataset, codes, and induced ontology.</abstract>
      <url hash="6a6fd189">2024.findings-eacl.64</url>
      <bibkey>xu-etal-2024-ceo</bibkey>
    </paper>
    <paper id="65">
      <title>Rethinking <fixed-case>STS</fixed-case> and <fixed-case>NLI</fixed-case> in Large Language Models</title>
      <author><first>Yuxia</first><last>Wang</last></author>
      <author><first>Minghan</first><last>Wang</last><affiliation>Monash University</affiliation></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <pages>965-982</pages>
      <abstract>Recent years, have seen the rise of large language models (LLMs), where practitioners use task-specific prompts; this was shown to be effective for a variety of tasks. However, when applied to semantic textual similarity (STS) and natural language inference (NLI), the effectiveness of LLMs turns out to be limited by low-resource domain accuracy, model overconfidence, and difficulty to capture the disagreements between human judgements. With this in mind, here we try to rethink STS and NLI in the era of LLMs. We first evaluate the performance of STS and NLI in the clinical/biomedical domain, and then we assess LLMs’ predictive confidence and their capability of capturing collective human opinions. We find that these old problems are still to be properly addressed in the era of LLMs.</abstract>
      <url hash="4cbaa3d3">2024.findings-eacl.65</url>
      <bibkey>wang-etal-2024-rethinking</bibkey>
    </paper>
    <paper id="66">
      <title>Learning High-Quality and General-Purpose Phrase Representations</title>
      <author><first>Lihu</first><last>Chen</last></author>
      <author><first>Gael</first><last>Varoquaux</last><affiliation>INRIA</affiliation></author>
      <author><first>Fabian</first><last>Suchanek</last><affiliation>Telecom Paris</affiliation></author>
      <pages>983-994</pages>
      <abstract>Phrase representations play an important role in data science and natural language processing, benefiting various tasks like Entity Alignment, Record Linkage, Fuzzy Joins, and Paraphrase Classification.The current state-of-the-art method involves fine-tuning pre-trained language models for phrasal embeddings using contrastive learning. However, we have identified areas for improvement. First, these pre-trained models tend to be unnecessarily complex and require to be pre-trained on a corpus with context sentences.Second, leveraging the phrase type and morphology gives phrase representations that are both more precise and more flexible.We propose an improved framework to learn phrase representations in a context-free fashion.The framework employs phrase type classification as an auxiliary task and incorporates character-level information more effectively into the phrase representation.Furthermore, we design three granularities of data augmentation to increase the diversity of training samples.Our experiments across a wide range of tasks reveal that our approach generates superior phrase embeddings compared to previous methods while requiring a smaller model size.</abstract>
      <url hash="da034f83">2024.findings-eacl.66</url>
      <attachment type="software" hash="55439295">2024.findings-eacl.66.software.zip</attachment>
      <bibkey>chen-etal-2024-learning</bibkey>
    </paper>
    <paper id="67">
      <title>Explaining Language Model Predictions with High-Impact Concepts</title>
      <author><first>Ruochen</first><last>Zhao</last></author>
      <author><first>Tan</first><last>Wang</last></author>
      <author><first>Yongjie</first><last>Wang</last><affiliation>School of Computer Science and Engineering, Nanyang Technological University</affiliation></author>
      <author><first>Shafiq</first><last>Joty</last><affiliation>SalesForce.com and Nanyang Technological University</affiliation></author>
      <pages>995-1012</pages>
      <abstract>To encourage fairness and transparency, there exists an urgent demand for deriving reliable explanations for large language models (LLMs). One promising solution is concept-based explanations, i.e., human-understandable concepts from internal representations. However, due to the compositional nature of languages, current methods mostly discover correlational explanations instead of causal features. Therefore, we propose a novel framework to provide impact-aware explanations for users to understand the LLM’s behavior, which are robust to feature changes and influential to the model’s predictions. Specifically, we extract predictive high-level features (concepts) from the model’s hidden layer activations. Then, we innovatively optimize for features whose existence causes the output predictions to change substantially. Extensive experiments on real and synthetic tasks demonstrate that our method achieves superior results on predictive impact, explainability, and faithfulness compared to the baselines, especially for LLMs.</abstract>
      <url hash="5970a8fc">2024.findings-eacl.67</url>
      <bibkey>zhao-etal-2024-explaining</bibkey>
    </paper>
    <paper id="68">
      <title>Understanding and Mitigating Spurious Correlations in Text Classification with Neighborhood Analysis</title>
      <author><first>Oscar</first><last>Chew</last></author>
      <author><first>Hsuan-Tien</first><last>Lin</last><affiliation>National Taiwan University</affiliation></author>
      <author><first>Kai-Wei</first><last>Chang</last><affiliation>University of California, Los Angeles</affiliation></author>
      <author><first>Kuan-Hao</first><last>Huang</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <pages>1013-1025</pages>
      <abstract>Recent research has revealed that machine learning models have a tendency to leverage spurious correlations that exist in the training set but may not hold true in general circumstances. For instance, a sentiment classifier may erroneously learn that the token “performances” is commonly associated with positive movie reviews.Relying on these spurious correlations degrades the classifier’s performance when it deploys on out-of-distribution data.In this paper, we examine the implications of spurious correlations through a novel perspective called neighborhood analysis. The analysis uncovers how spurious correlations lead unrelated words to erroneously cluster together in the embedding space. Driven by the analysis, we design a metric to detect spurious tokens and also propose a family of regularization methods, NFL (doN’t Forget your Language) to mitigate spurious correlations in text classification.Experiments show that NFL can effectively prevent erroneous clusters and significantly improve the robustness of classifiers without auxiliary data. The code is publicly available at https://github.com/oscarchew/doNt-Forget-your-Language.</abstract>
      <url hash="ac912e09">2024.findings-eacl.68</url>
      <bibkey>chew-etal-2024-understanding</bibkey>
    </paper>
    <paper id="69">
      <title>On the Intractability to Synthesize Factual Inconsistencies in Summarization</title>
      <author><first>Ge</first><last>Luo</last><affiliation>Iowa State University</affiliation></author>
      <author><first>Weisi</first><last>Fan</last></author>
      <author><first>Miaoran</first><last>Li</last><affiliation>Iowa State University</affiliation></author>
      <author><first>Youbiao</first><last>He</last><affiliation>Iowa State University</affiliation></author>
      <author><first>Yinfei</first><last>Yang</last><affiliation>Apple</affiliation></author>
      <author><first>Forrest</first><last>Bao</last><affiliation>Iowa State University, Iowa State University and Iowa State University</affiliation></author>
      <pages>1026-1037</pages>
      <abstract>Factual consistency detection has gotten raised attention in the task of abstractive summarization. Many existing works rely on synthetic training data, which may not accurately reflect or match the inconsistencies produced by summarization models. In this paper, we first systematically analyze the shortcomings of the current methods in synthesizing inconsistent summaries. Current synthesis methods may fail to produce inconsistencies of coreference errors and discourse errors, per our quantitative and qualitative study. Then, employing the parameter-efficient finetuning (PEFT) technique, we discover that a competitive factual consistency detector can be achieved using thousands of real model-generated summaries with human annotations. Our study demonstrates the importance of real machine-generated texts with human annotation in NLG evaluation as our model outperforms the SOTA on the CoGenSumm, FactCC, Frank, and SummEval datasets.</abstract>
      <url hash="814be2d6">2024.findings-eacl.69</url>
      <bibkey>luo-etal-2024-intractability</bibkey>
    </paper>
    <paper id="70">
      <title><fixed-case>I</fixed-case>ndi<fixed-case>V</fixed-case>ec: An Exploration of Leveraging Large Language Models for Media Bias Detection with Fine-Grained Bias Indicators</title>
      <author><first>Luyang</first><last>Lin</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <author><first>Lingzhi</first><last>Wang</last></author>
      <author><first>Xiaoyan</first><last>Zhao</last><affiliation>Chinese University of Hong Kong, The Chinese University of Hong Kong</affiliation></author>
      <author><first>Jing</first><last>Li</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <pages>1038-1050</pages>
      <abstract>This study focuses on media bias detection, crucial in today’s era of influential social media platforms shaping individual attitudes and opinions. In contrast to prior work that primarily relies on training specific models tailored to particular datasets, resulting in limited adaptability and subpar performance on out-of-domain data, we introduce a general bias detection framework, IndiVec, built upon large language models. IndiVec begins by constructing a fine-grained media bias database, leveraging the robust instruction-following capabilities of large language models and vector database techniques. When confronted with new input for bias detection, our framework automatically selects the most relevant indicator from the vector database and employs majority voting to determine the input’s bias label. IndiVec excels compared to previous methods due to its adaptability (demonstrating consistent performance across diverse datasets from various sources) and explainability (providing explicit top-k indicators to interpret bias predictions). Experimental results on four political bias datasets highlight IndiVec’s significant superiority over baselines. Furthermore, additional experiments and analysis provide profound insights into the framework’s effectiveness.</abstract>
      <url hash="05911d09">2024.findings-eacl.70</url>
      <bibkey>lin-etal-2024-indivec</bibkey>
    </paper>
    <paper id="71">
      <title>Are Large Language Model-based Evaluators the Solution to Scaling Up Multilingual Evaluation?</title>
      <author><first>Rishav</first><last>Hada</last><affiliation>Microsoft Research India</affiliation></author>
      <author><first>Varun</first><last>Gumma</last><affiliation>Microsoft</affiliation></author>
      <author><first>Adrian</first><last>Wynter</last></author>
      <author><first>Harshita</first><last>Diddee</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Mohamed</first><last>Ahmed</last><affiliation>Research, Microsoft</affiliation></author>
      <author><first>Monojit</first><last>Choudhury</last><affiliation>Mohamed bin Zayed University of Artificial Intelligence</affiliation></author>
      <author><first>Kalika</first><last>Bali</last><affiliation>Microsoft Research Labs</affiliation></author>
      <author><first>Sunayana</first><last>Sitaram</last><affiliation>Microsoft</affiliation></author>
      <pages>1051-1070</pages>
      <abstract>Large Language Models (LLMs) excel in various Natural Language Processing (NLP) tasks, yet their evaluation, particularly in languages beyond the top 20, remains inadequate due to existing benchmarks and metrics limitations. Employing LLMs as evaluators to rank or score other models’ outputs emerges as a viable solution, addressing the constraints tied to human annotators and established benchmarks. In this study, we explore the potential of LLM-based evaluators in enhancing multilingual evaluation by calibrating them against 20K human judgments across three text-generation tasks, five metrics, and eight languages. Our analysis reveals a bias in LLM-based evaluators towards higher scores, underscoring the necessity of calibration with native speaker judgments, especially in low-resource and non-Latin script languages, to ensure accurate evaluation of LLM performance across diverse languages.</abstract>
      <url hash="24bd4a12">2024.findings-eacl.71</url>
      <bibkey>hada-etal-2024-large</bibkey>
    </paper>
    <paper id="72">
      <title>Computational Morphology and Lexicography Modeling of <fixed-case>M</fixed-case>odern <fixed-case>S</fixed-case>tandard <fixed-case>A</fixed-case>rabic Nominals</title>
      <author><first>Christian</first><last>Khairallah</last><affiliation>New York University</affiliation></author>
      <author><first>Reham</first><last>Marzouk</last><affiliation>Alexandria University and New York University, Abu Dhabi</affiliation></author>
      <author><first>Salam</first><last>Khalifa</last><affiliation>State University of New York, Stony Brook</affiliation></author>
      <author><first>Mayar</first><last>Nassar</last><affiliation>Ain Shams University</affiliation></author>
      <author><first>Nizar</first><last>Habash</last><affiliation>New York University Abu Dhabi</affiliation></author>
      <pages>1071-1084</pages>
      <abstract>Modern Standard Arabic (MSA) nominals present many morphological and lexical modeling challenges that have not been consistently addressed previously. This paper attempts to define the space of such challenges, and leverage a recently proposed morphological framework to build a comprehensive and extensible model for MSA nominals. Our model design addresses the nominals’ intricate morphotactics, as well as their paradigmatic irregularities. Our implementation showcases enhanced accuracy and consistency compared to a commonly used MSA morphological analyzer and generator. We make our models publicly available.</abstract>
      <url hash="4372130f">2024.findings-eacl.72</url>
      <bibkey>khairallah-etal-2024-computational</bibkey>
    </paper>
    <paper id="73">
      <title>Relabeling Minimal Training Subset to Flip a Prediction</title>
      <author><first>Jinghan</first><last>Yang</last></author>
      <author><first>Linjie</first><last>Xu</last></author>
      <author><first>Lequan</first><last>Yu</last><affiliation>The University of Hong Kong</affiliation></author>
      <pages>1085-1098</pages>
      <abstract>When facing an unsatisfactory prediction from a machine learning model, users can be interested in investigating the underlying reasons and exploring the potential for reversing the outcome. We ask: To flip the prediction on a test point <tex-math>x_t</tex-math>, how to identify the smallest training subset <tex-math>\mathcal{S}_t</tex-math> that we need to relabel?We propose an efficient algorithm to identify and relabel such a subset via an extended influence function for binary classification models with convex loss.We find that relabeling fewer than 2% of the training points can always flip a prediction.This mechanism can serve multiple purposes: (1) providing an approach to challenge a model prediction by altering training points; (2) evaluating model robustness with the cardinality of the subset (i.e., <tex-math>|\mathcal{S}_t|</tex-math>); we show that <tex-math>|\mathcal{S}_t|</tex-math> is highly related to the noise ratio in the training set and <tex-math>|\mathcal{S}_t|</tex-math> is correlated with but complementary to predicted probabilities; and (3) revealing training points lead to group attribution bias. To the best of our knowledge, we are the first to investigate identifying and relabeling the minimal training subset required to flip a given prediction.</abstract>
      <url hash="57da3035">2024.findings-eacl.73</url>
      <bibkey>yang-etal-2024-relabeling</bibkey>
    </paper>
    <paper id="74">
      <title>Why Generate When You Can Discriminate? A Novel Technique for Text Classification using Language Models</title>
      <author><first>Sachin</first><last>Pawar</last></author>
      <author><first>Nitin</first><last>Ramrakhiyani</last><affiliation>International Institute of Information Technology, Hyderabad and Tata Consultancy Services Limited, India</affiliation></author>
      <author><first>Anubhav</first><last>Sinha</last><affiliation>Tata Consultancy Services Limited, India</affiliation></author>
      <author><first>Manoj</first><last>Apte</last></author>
      <author><first>Girish</first><last>Palshikar</last></author>
      <pages>1099-1114</pages>
      <abstract>In this paper, we propose a novel two-step technique for text classification using autoregressive Language Models (LM). In the first step, a set of perplexity and log-likelihood based numeric features are elicited from an LM for a text instance to be classified. Then, in the second step, a classifier based on these features is trained to predict the final label. The classifier used is usually a simple machine learning classifier like Support Vector Machine (SVM) or Logistic Regression (LR) and it is trained using a small set of training examples. We believe, our technique presents a whole new way of exploiting the available training instances, in addition to the existing ways like fine-tuning LMs or in-context learning. Our approach stands out by eliminating the need for parameter updates in LMs, as required in fine-tuning, and does not impose limitations on the number of training examples faced while building prompts for in-context learning. We evaluate our technique across 5 different datasets and compare with multiple competent baselines.</abstract>
      <url hash="c83c1003">2024.findings-eacl.74</url>
      <bibkey>pawar-etal-2024-generate</bibkey>
    </paper>
    <paper id="75">
      <title>Autism Detection in Speech – A Survey</title>
      <author><first>Nadine</first><last>Probol</last></author>
      <author><first>Margot</first><last>Mieskes</last><affiliation>University of Applied Sciences Darmstadt</affiliation></author>
      <pages>1115-1125</pages>
      <abstract>There has been a range of studies of how autism is displayed in voice, speech, and language. We analyse studies from the biomedical, as well as the psychological domain, but also from the NLP domain in order to find linguistic, prosodic and acoustic cues. Our survey looks at all three domains. We define autism and which comorbidities might influence the correct detection of the disorder. We especially look at observations such as verbal and semantic fluency, prosodic features, but also disfluencies and speaking rate. We also show word-based approaches and describe machine learning and transformer-based approaches both on the audio data as well as the transcripts. Lastly, we conclude, while there already is a lot of research, female patients seem to be severely under-researched. Also, most NLP research focuses on traditional machine learning methods instead of transformers. Additionally, we were unable to find research combining both features from audio and transcripts.</abstract>
      <url hash="51af6a1c">2024.findings-eacl.75</url>
      <bibkey>probol-mieskes-2024-autism</bibkey>
    </paper>
    <paper id="76">
      <title>Improving Multimodal Classification of Social Media Posts by Leveraging Image-Text Auxiliary Tasks</title>
      <author><first>Danae</first><last>Sanchez Villegas</last></author>
      <author><first>Daniel</first><last>Preotiuc-Pietro</last><affiliation>Bloomberg</affiliation></author>
      <author><first>Nikolaos</first><last>Aletras</last><affiliation>University of Sheffield, University of Sheffield and Amazon</affiliation></author>
      <pages>1126-1137</pages>
      <abstract>Effectively leveraging multimodal information from social media posts is essential to various downstream tasks such as sentiment analysis, sarcasm detection or hate speech classification. Jointly modeling text and images is challenging because cross-modal semantics might be hidden or the relation between image and text is weak. However, prior work on multimodal classification of social media posts has not yet addressed these challenges. In this work, we present an extensive study on the effectiveness of using two auxiliary losses jointly with the main task during fine-tuning multimodal models. First, Image-Text Contrastive (ITC) is designed to minimize the distance between image-text representations within a post, thereby effectively bridging the gap between posts where the image plays an important role in conveying the post’s meaning. Second, Image-Text Matching (ITM) enhances the model’s ability to understand the semantic relationship between images and text, thus improving its capacity to handle ambiguous or loosely related posts. We combine these objectives with five multimodal models, demonstrating consistent improvements of up to 2.6 F1 score across five diverse social media datasets. Our comprehensive analysis shows the specific scenarios where each auxiliary task is most effective.</abstract>
      <url hash="43ecdf60">2024.findings-eacl.76</url>
      <bibkey>sanchez-villegas-etal-2024-improving</bibkey>
    </paper>
    <paper id="77">
      <title>What the Weight?! A Unified Framework for Zero-Shot Knowledge Composition</title>
      <author><first>Carolin</first><last>Holtermann</last><affiliation>Universität Hamburg</affiliation></author>
      <author><first>Markus</first><last>Frohmann</last></author>
      <author><first>Navid</first><last>Rekabsaz</last></author>
      <author><first>Anne</first><last>Lauscher</last><affiliation>Universität Hamburg</affiliation></author>
      <pages>1138-1157</pages>
      <abstract>The knowledge encapsulated in a model is the core factor determining its final performance on downstream tasks. Much research in NLP has focused on efficient methods for storing and adapting different types of knowledge, e.g., in dedicated modularized structures, and on how to effectively combine these, e.g., by learning additional parameters. However, given the many possible options, a thorough understanding of the mechanisms involved in these compositions is missing, and hence it remains unclear which strategies to utilize. To address this research gap, we propose a novel framework for zero-shot module composition, which encompasses existing and some novel variations for selecting, weighting, and combining parameter modules under a single unified notion. Focusing on the scenario of domain knowledge and adapter layers, our framework provides a systematic unification of concepts, allowing us to conduct the first comprehensive benchmarking study of various zero-shot knowledge composition strategies. In particular, we test two module combination methods and five selection and weighting strategies for their effectiveness and efficiency in an extensive experimental setup. Our results highlight the efficacy of ensembling but also hint at the power of simple though often-ignored weighting methods. Further in-depth analyses allow us to understand the role of weighting vs. top-k selection, and show that, to a certain extent, the performance of adapter composition can even be predicted.</abstract>
      <url hash="1265d531">2024.findings-eacl.77</url>
      <attachment type="software" hash="a178fa2c">2024.findings-eacl.77.software.zip</attachment>
      <bibkey>holtermann-etal-2024-weight</bibkey>
    </paper>
    <paper id="78">
      <title><fixed-case>I</fixed-case>ndi<fixed-case>F</fixed-case>ood<fixed-case>VQA</fixed-case>: Advancing Visual Question Answering and Reasoning with a Knowledge-Infused Synthetic Data Generation Pipeline</title>
      <author><first>Pulkit</first><last>Agarwal</last><affiliation>Indian Institute of Technology Bombay</affiliation></author>
      <author><first>Settaluri</first><last>Sravanthi</last><affiliation>Indian Institute of Technology Bombay, Indian Institute of Technology, Bombay</affiliation></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last><affiliation>Indian Institute of Technology, Bombay, Dhirubhai Ambani Institute Of Information and Communication Technology</affiliation></author>
      <pages>1158-1176</pages>
      <abstract>Large Vision Language Models (VLMs) like GPT-4, LLaVA, and InstructBLIP exhibit extraordinary capabilities for both knowledge understanding and reasoning. However, the reasoning capabilities of such models on sophisticated problems that require external knowledge of a specific domain have not been assessed well, due to the unavailability of necessary datasets. In this work, we release a first-of-its-kind dataset called IndiFoodVQA with around 16.7k data samples, consisting of explicit knowledge-infused questions, answers, and reasons. We also release IndiFoodKG, a related Knowledge Graph (KG) with 79k triples. The data has been created with minimal human intervention via an automated pipeline based on InstructBlip and GPT-3.5. We also present a methodology to extract knowledge from the KG and use it to both answer and reason upon the questions. We employ different models to report baseline zero-shot and fine-tuned results. Fine-tuned VLMs on our data showed an improvement of ~25% over the corresponding base model, highlighting the fact that current VLMs need domain-specific fine-tuning to excel in specialized settings. Our findings reveal that (1) explicit knowledge infusion during question generation helps in making questions that have more grounded knowledge, and (2) proper knowledge retrieval can often lead to better-answering potential in such cases. The data and code is available at https://github.com/SLSravanthi/IndifoodVQA.</abstract>
      <url hash="f3aa97e4">2024.findings-eacl.78</url>
      <attachment type="note" hash="c8051c81">2024.findings-eacl.78.note.zip</attachment>
      <bibkey>agarwal-etal-2024-indifoodvqa</bibkey>
    </paper>
    <paper id="79">
      <title><fixed-case>MAPLE</fixed-case>: Micro Analysis of Pairwise Language Evolution for Few-Shot Claim Verification</title>
      <author><first>Xia</first><last>Zeng</last><affiliation>Queen Mary University London</affiliation></author>
      <author><first>Arkaitz</first><last>Zubiaga</last><affiliation>Queen Mary University of London</affiliation></author>
      <pages>1177-1196</pages>
      <abstract>Claim verification is an essential step in the automated fact-checking pipeline which assesses the veracity of a claim against a piece of evidence. In this work, we explore the potential of few-shot claim verification, where only very limited data is available for supervision. We propose MAPLE (Micro Analysis of Pairwise Language Evolution), a pioneering approach that explores the alignment between a claim and its evidence with a small seq2seq model and a novel semantic measure. Its innovative utilization of micro language evolution path leverages unlabelled pairwise data to facilitate claim verification while imposing low demand on data annotations and computing resources. MAPLE demonstrates significant performance improvements over SOTA baselines SEED, PET and LLaMA 2 across three fact-checking datasets: FEVER, Climate FEVER, and SciFact. Data and code are available.</abstract>
      <url hash="07de59b9">2024.findings-eacl.79</url>
      <attachment type="software" hash="19d09dc0">2024.findings-eacl.79.software.zip</attachment>
      <attachment type="note" hash="60b3c1f3">2024.findings-eacl.79.note.zip</attachment>
      <bibkey>zeng-zubiaga-2024-maple</bibkey>
    </paper>
    <paper id="80">
      <title>Leveraging Open Information Extraction for More Robust Domain Transfer of Event Trigger Detection</title>
      <author><first>David</first><last>Dukić</last><affiliation>Faculty of Electrical Engineering and Computing, University of Zagreb</affiliation></author>
      <author><first>Kiril</first><last>Gashteovski</last><affiliation>NEC Laboratories Europe, St.Cyril and Methodius University and NEC Laboratories Europe</affiliation></author>
      <author><first>Goran</first><last>Glavaš</last><affiliation>Julius-Maximilians-Universität Würzburg</affiliation></author>
      <author><first>Jan</first><last>Snajder</last><affiliation>UniZg-FER, University of Zagreb</affiliation></author>
      <pages>1197-1213</pages>
      <abstract>Event detection is a crucial information extraction task in many domains, such as Wikipedia or news. The task typically relies on trigger detection (TD) – identifying token spans in the text that evoke specific events. While the notion of triggers should ideally be universal across domains, domain transfer for TD from high- to low-resource domains results in significant performance drops. We address the problem of negative transfer in TD by coupling triggers between domains using subject-object relations obtained from a rule-based open information extraction (OIE) system. We demonstrate that OIE relations injected through multi-task training can act as mediators between triggers in different domains, enhancing zero- and few-shot TD domain transfer and reducing performance drops, in particular when transferring from a high-resource source domain (Wikipedia) to a low(er)-resource target domain (news). Additionally, we combine this improved transfer with masked language modeling on the target domain, observing further TD transfer gains. Finally, we demonstrate that the gains are robust to the choice of the OIE system.</abstract>
      <url hash="32442344">2024.findings-eacl.80</url>
      <bibkey>dukic-etal-2024-leveraging</bibkey>
    </paper>
    <paper id="81">
      <title>Exploring efficient zero-shot synthetic dataset generation for Information Retrieval</title>
      <author><first>Tiago</first><last>Almeida</last></author>
      <author><first>Sérgio</first><last>Matos</last><affiliation>Universidade de Aveiro</affiliation></author>
      <pages>1214-1231</pages>
      <abstract>The broad integration of neural retrieval models into Information Retrieval (IR) systems is significantly impeded by the high cost and laborious process associated with the manual labelling of training data. Similarly, synthetic training data generation, a potential workaround, often requires expensive computational resources due to the reliance on large language models. This work explored the potential of small language models for efficiently creating high-quality synthetic datasets to train neural retrieval models. We aim to identify an optimal method to generate synthetic datasets, enabling training neural reranking models in document collections where annotated data is unavailable. We introduce a novel methodology, grounded in the principles of information theory, to select the most appropriate documents to be used as context for question generation. Then, we employ a small language model for zero-shot conditional question generation, supplemented by a filtering mechanism to ensure the quality of generated questions. Extensive evaluation on five datasets unveils the potential of our approach, outperforming unsupervised retrieval methods such as BM25 and pretrained monoT5. Our findings indicate that an efficiently generated “silver-standard” dataset allows effective training of neural rerankers in unlabeled scenarios. To ensure reproducibility and facilitate wider application, we will release a code repository featuring an accessible API for zero-shot synthetic question generation.</abstract>
      <url hash="a7485aef">2024.findings-eacl.81</url>
      <bibkey>almeida-matos-2024-exploring</bibkey>
    </paper>
    <paper id="82">
      <title>Clustering-based Sampling for Few-Shot Cross-Domain Keyphrase Extraction</title>
      <author><first>Prakamya</first><last>Mishra</last><affiliation>AMD AI</affiliation></author>
      <author><first>Lincy</first><last>Pattanaik</last></author>
      <author><first>Arunima</first><last>Sundar</last></author>
      <author><first>Nishant</first><last>Yadav</last><affiliation>Department of Computer Science, University of Massachusetts, Amherst</affiliation></author>
      <author><first>Mayank</first><last>Kulkarni</last><affiliation>Amazon</affiliation></author>
      <pages>1232-1250</pages>
      <abstract>Keyphrase extraction is the task of identifying a set of keyphrases present in a document that captures its most salient topics. Scientific domain-specific pre-training has led to achieving state-of-the-art keyphrase extraction performance with a majority of benchmarks being within the domain. In this work, we explore how to effectively enable the cross-domain generalization capabilities of such models without requiring the same scale of data. We primarily focus on the few-shot setting in non-scientific domain datasets such as OpenKP from the Web domain &amp; StackEx from the StackExchange forum. We propose to leverage topic information intrinsically available in the data, to build a novel clustering-based sampling approach that facilitates selecting a few samples to label from the target domain facilitating building robust and performant models. This approach leads to large gains in performance of up to 26.35 points in F1 when compared to selecting few-shot samples uniformly at random. We also explore the setting where we have access to labeled data from the model’s pretraining domain corpora and perform gradual training which involves slowly folding in target domain data to the source domain data. Here we demonstrate further improvements in the model performance by up to 12.76 F1 points.</abstract>
      <url hash="91306589">2024.findings-eacl.82</url>
      <bibkey>mishra-etal-2024-clustering</bibkey>
    </paper>
    <paper id="83">
      <title>Random Smooth-based Certified Defense against Text Adversarial Attack</title>
      <author><first>Zeliang</first><last>Zhang</last><affiliation>University of Rochester</affiliation></author>
      <author><first>Wei</first><last>Yao</last></author>
      <author><first>Susan</first><last>Liang</last><affiliation>University of Rochester</affiliation></author>
      <author><first>Chenliang</first><last>Xu</last><affiliation>University of Rochester, University of Rochester and University of Rochester</affiliation></author>
      <pages>1251-1265</pages>
      <abstract>Certified defense methods have identified their effectiveness against textual adversarial examples, which train models on the worst-case text generated by substituting words in original texts with synonyms. However, due to the discrete word embedding representations, the large search space hinders the robust training efficiency, resulting in significant time consumption. To overcome this challenge, motivated by the observation that synonym embedding has a small distance, we propose to treat the word substitution as a continuous perturbation on the word embedding representation. The proposed method Text-RS applies random smooth techniques to approximate the word substitution operation, offering a computationally efficient solution that outperforms conventional discrete methods and improves the robustness in training. The evaluation results demonstrate its effectiveness in defending against multiple textual adversarial attacks.</abstract>
      <url hash="563c62a2">2024.findings-eacl.83</url>
      <bibkey>zhang-etal-2024-random</bibkey>
    </paper>
    <paper id="84">
      <title>Clarifying the Path to User Satisfaction: An Investigation into Clarification Usefulness</title>
      <author><first>Hossein A.</first><last>Rahmani</last></author>
      <author><first>Xi</first><last>Wang</last></author>
      <author><first>Mohammad</first><last>Aliannejadi</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Mohammadmehdi</first><last>Naghiaei</last></author>
      <author><first>Emine</first><last>Yilmaz</last></author>
      <pages>1266-1277</pages>
      <abstract>Clarifying questions are an integral component of modern information retrieval systems, directly impacting user satisfaction and overall system performance. Poorly formulated questions can lead to user frustration and confusion, negatively affecting the system’s performance. This research addresses the urgent need to identify and leverage key features that contribute to the classification of clarifying questions, enhancing user satisfaction. To gain deeper insights into how different features influence user satisfaction, we conduct a comprehensive analysis, considering a broad spectrum of lexical, semantic, and statistical features, such as question length and sentiment polarity. Our empirical results provide three main insights into the qualities of effective query clarification: (1) specific questions are more effective than generic ones; (2) the subjectivity and emotional tone of a question play a role; and (3) shorter and more ambiguous queries benefit significantly from clarification. Based on these insights, we implement feature-integrated user satisfaction prediction using various classifiers, both traditional and neural-based, including random forest, BERT, and large language models. Our experiments show a consistent and significant improvement, particularly in traditional classifiers, with a minimum performance boost of 45%. This study presents invaluable guidelines for refining the formulation of clarifying questions and enhancing both user satisfaction and system performance.</abstract>
      <url hash="25b6e579">2024.findings-eacl.84</url>
      <bibkey>rahmani-etal-2024-clarifying</bibkey>
    </paper>
    <paper id="85">
      <title>Efficiently Aligned Cross-Lingual Transfer Learning for Conversational Tasks using Prompt-Tuning</title>
      <author><first>Lifu</first><last>Tu</last><affiliation>Salesforce AI Research</affiliation></author>
      <author><first>Jin</first><last>Qu</last><affiliation>Salesforce AI Research</affiliation></author>
      <author><first>Semih</first><last>Yavuz</last><affiliation>SalesForce.com</affiliation></author>
      <author><first>Shafiq</first><last>Joty</last><affiliation>SalesForce.com and Nanyang Technological University</affiliation></author>
      <author><first>Wenhao</first><last>Liu</last><affiliation>Faire</affiliation></author>
      <author><first>Caiming</first><last>Xiong</last><affiliation>Salesforce Research</affiliation></author>
      <author><first>Yingbo</first><last>Zhou</last><affiliation>Salesforce Research</affiliation></author>
      <pages>1278-1294</pages>
      <abstract>Cross-lingual transfer of language models trained on high-resource languages like English has been widely studied for many NLP tasks, but focus on conversational tasks has been rather limited. This is partly due to the high cost of obtaining non-English conversational data, which results in limited coverage. In this work, we introduce for cross-lingual alignment pretraining, a parallel and large-scale multilingual conversation dataset that we created by translating the English-only Schema-Guided Dialogue (SGD) dataset (Rastogi et al., 2020) into 105 other languages. XSGD contains about 330k utterances per language. To facilitate aligned cross-lingual representations, we develop an efficient prompt-tuning-based method for learning alignment prompts. We also investigate two different classifiers: NLI-based and vanilla classifiers, and test cross-lingual capability enabled by the aligned prompts. We evaluate our model’s cross-lingual generalization capabilities on two conversation tasks: slot-filling and intent classification. Our results demonstrate strong and efficient modeling ability of NLI-based classifiers and the large cross-lingual transfer improvements achieved by our aligned prompts, particularly in few-shot settings. We also conduct studies on large language models (LLMs) such as text-davinci-003 and ChatGPT in both zero- and few-shot settings. While LLMs exhibit impressive performance in English, their cross-lingual capabilities in other languages, particularly low-resource ones, are limited.</abstract>
      <url hash="26a32271">2024.findings-eacl.85</url>
      <bibkey>tu-etal-2024-efficiently</bibkey>
    </paper>
    <paper id="86">
      <title>Correcting Language Model Outputs by Editing Salient Layers</title>
      <author><first>Kshitij</first><last>Mishra</last><affiliation>Indian Institute of Technology, Patna</affiliation></author>
      <author><first>Tamer</first><last>Soliman</last><affiliation>Amazon</affiliation></author>
      <author><first>Anil</first><last>Ramakrishna</last><affiliation>Amazon</affiliation></author>
      <author><first>Aram</first><last>Galstyan</last><affiliation>Information Sciences Institute, University of Southern California and Amazon Alexa</affiliation></author>
      <author><first>Anoop</first><last>Kumar</last><affiliation>Amazon</affiliation></author>
      <pages>1295-1305</pages>
      <abstract>Large language models can accumulate incorrect or outdated knowledge as the real world evolves. Compared to typical solutions such as retraining, retrieval augmented generation, model editing offers an effective yet low cost solution to address this issue. However, existing model editing algorithms employ manual selection of edit layers, which requires prior domain knowledge or expensive architecture-specific empirical layer selection methods, such as causal tracing. In this work, we propose SaLEM (Salient Layers Editing Model), an efficient solution for data driven layer selection for the model editing task. Our solution utilizes layer-wise saliency maps for layer selection, and matches the accuracy of prior approaches but with only 1/3 of their edits, enabling efficient updates to the parametric knowledge in large language models.</abstract>
      <url hash="d27cffde">2024.findings-eacl.86</url>
      <bibkey>mishra-etal-2024-correcting</bibkey>
    </paper>
    <paper id="87">
      <title>Improving Grounded Language Understanding in a Collaborative Environment by Interacting with Agents Through Help Feedback</title>
      <author><first>Nikhil</first><last>Mehta</last></author>
      <author><first>Milagro</first><last>Teruel</last><affiliation>Microsoft</affiliation></author>
      <author><first>Xin</first><last>Deng</last></author>
      <author><first>Sergio</first><last>Figueroa Sanz</last></author>
      <author><first>Ahmed</first><last>Awadallah</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Julia</first><last>Kiseleva</last><affiliation>Research, Microsoft</affiliation></author>
      <pages>1306-1321</pages>
      <abstract>Many approaches to Natural Language Processing tasks often treat them as single-step problems, where an agent receives an instruction, executes it, and is evaluated based on the final outcome. However, language is inherently interactive, as evidenced by the back-and-forth nature of human conversations. In light of this, we posit that human-AI collaboration should also be interactive, with humans monitoring the work of AI agents and providing feedback that the agent can understand and utilize. Further, the AI agent should be able to detect when it needs additional information and proactively ask for help. Enabling this scenario would lead to more natural, efficient, and engaging human-AI collaboration.In this paper, we investigate these directions using the challenging task established by the IGLU competition, an interactive grounded language understanding task in a MineCraft-like world. We delve into multiple types of help players can give to the AI to guide it and analyze the impact of this help on behavior, resulting in performance improvements and an end-to-end interactive system.</abstract>
      <url hash="49597c49">2024.findings-eacl.87</url>
      <bibkey>mehta-etal-2024-improving</bibkey>
    </paper>
    <paper id="88">
      <title>Goodhart’s Law Applies to <fixed-case>NLP</fixed-case>’s Explanation Benchmarks</title>
      <author><first>Jennifer</first><last>Hsia</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Danish</first><last>Pruthi</last><affiliation>Indian Institute of Science, Bangalore</affiliation></author>
      <author><first>Aarti</first><last>Singh</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Zachary</first><last>Lipton</last><affiliation>Carnegie Mellon University</affiliation></author>
      <pages>1322-1335</pages>
      <abstract>Despite the rising popularity of saliency-based explanations, the research community remains at an impasse, facing doubts concerning their purpose, efficacy, and tendency to contradict each other. Seeking to unite the community’s efforts around common goals, several recent works have proposed evaluation metrics. In this paper, we critically examine two sets of metrics: the ERASER metrics (comprehensiveness and sufficiency) and the EVAL-X metrics, focusing our inquiry on natural language processing. First, we show that we can inflate a model’s comprehensiveness and sufficiency scores dramatically without altering its predictions or explanations on in-distribution test inputs. Our strategy exploits the tendency for extracted explanations and their complements to be “out-of-support” relative to each other and in-distribution inputs. Next, we demonstrate that the EVAL-X metrics can be inflated arbitrarily by a simple method that encodes the label, even though EVAL-X is precisely motivated to address such exploits. Our results raise doubts about the ability of current metrics to guide explainability research, underscoring the need for a broader reassessment of what precisely these metrics are intended to capture.</abstract>
      <url hash="e6cc8838">2024.findings-eacl.88</url>
      <bibkey>hsia-etal-2024-goodharts</bibkey>
    </paper>
    <paper id="89">
      <title>Syllable-level lyrics generation from melody exploiting character-level language model</title>
      <author><first>Zhe</first><last>Zhang</last><affiliation>NII, SOKENDAI</affiliation></author>
      <author><first>Karol</first><last>Lasocki</last></author>
      <author><first>Yi</first><last>Yu</last><affiliation>NII, National Institute of Informatics</affiliation></author>
      <author><first>Atsuhiro</first><last>Takasu</last><affiliation>SOKENDAI</affiliation></author>
      <pages>1336-1346</pages>
      <abstract>The generation of lyrics tightly connected to accompanying melodies involves establishing a mapping between musical notes and syllables of lyrics. This process requires a deep understanding of music constraints and semantic patterns at syllable-level, word-level, and sentence-level semantic meanings. However, pre-trained language models specifically designed at the syllable level are publicly unavailable. To solve these challenging issues, we propose to exploit fine-tuning character-level language models for syllable-level lyrics generation from symbolic melody. In particular, our method aims to fine-tune a character-level pre-trained language model, allowing to incorporation of linguistic knowledge of the language model into the beam search process of a syllable-level Transformer generator network. Besides, by exploring ChatGPT-based evaluation of generated lyrics in addition to human subjective evaluation, we prove that our approach improves the coherence and correctness of generated lyrics, without the need to train expensive new language models.</abstract>
      <url hash="5a393d93">2024.findings-eacl.89</url>
      <bibkey>zhang-etal-2024-syllable</bibkey>
    </paper>
    <paper id="90">
      <title>Monolingual or Multilingual Instruction Tuning: Which Makes a Better Alpaca</title>
      <author><first>Pinzhen</first><last>Chen</last><affiliation>University of Edinburgh and University of Edinburgh</affiliation></author>
      <author><first>Shaoxiong</first><last>Ji</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Nikolay</first><last>Bogoychev</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Andrey</first><last>Kutuzov</last><affiliation>University of Oslo</affiliation></author>
      <author><first>Barry</first><last>Haddow</last></author>
      <author><first>Kenneth</first><last>Heafield</last></author>
      <pages>1347-1356</pages>
      <abstract>Foundational large language models (LLMs) can be instruction-tuned to perform open-domain question answering, facilitating applications like chat assistants. While such efforts are often carried out in a single language, we empirically analyze cost-efficient strategies for multilingual scenarios. Our study employs the Alpaca dataset and machine translations of it to form multilingual data, which is then used to tune LLMs through either low-rank adaptation or full-parameter training. Under a controlled computation budget, comparisons show that multilingual tuning is on par or better than tuning a model for each language. Furthermore, multilingual tuning with downsampled data can be as powerful and more robust. Our findings serve as a guide for expanding language support through instruction tuning.</abstract>
      <url hash="f30017a2">2024.findings-eacl.90</url>
      <bibkey>chen-etal-2024-monolingual</bibkey>
    </paper>
    <paper id="91">
      <title>Prompt Perturbation Consistency Learning for Robust Language Models</title>
      <author><first>Yao</first><last>Qiang</last><affiliation>Wayne State University</affiliation></author>
      <author><first>Subhrangshu</first><last>Nandi</last><affiliation>Amazon</affiliation></author>
      <author><first>Ninareh</first><last>Mehrabi</last><affiliation>Amazon</affiliation></author>
      <author><first>Greg</first><last>Ver Steeg</last><affiliation>University of California, Riverside, Amazon and USC/ISI</affiliation></author>
      <author><first>Anoop</first><last>Kumar</last><affiliation>Amazon</affiliation></author>
      <author><first>Anna</first><last>Rumshisky</last><affiliation>University of Massachusetts, Lowell, University of Massachusetts at Lowell and Amazon</affiliation></author>
      <author><first>Aram</first><last>Galstyan</last><affiliation>Information Sciences Institute, University of Southern California and Amazon Alexa</affiliation></author>
      <pages>1357-1370</pages>
      <abstract>Large language models (LLMs) have demonstrated impressive performance on a number of natural language processing tasks, such as question answering and text summarization. However, their performance on sequence labeling tasks such as intent classification and slot filling (IC-SF), which is a central component in personal assistant systems, lags significantly behind discriminative models. Furthermore, there is a lack of substantive research on robustness of LLMs to various perturbations in the input prompts. The contributions of this paper are three-fold. First, we show that fine-tuning sufficiently large LLMs can produce IC-SF performance comparable to discriminative models. Next, we systematically analyze the performance deterioration of those fine-tuned models due to three distinct yet relevant types of input perturbations - oronyms, synonyms, and paraphrasing. Finally, we propose an efficient mitigation approach, Prompt Perturbation Consistency Learning (PPCL), which works by regularizing the divergence between losses from clean and perturbed samples. Our experiments show that PPCL can recover on an average 59% and 69% of the performance drop for IC and SF tasks, respectively. Furthermore, PPCL beats data augmentation approach while using ten times fewer augmented data samples.</abstract>
      <url hash="90de46fe">2024.findings-eacl.91</url>
      <bibkey>qiang-etal-2024-prompt</bibkey>
    </paper>
    <paper id="92">
      <title>Enhancing Society-Undermining Disinformation Detection through Fine-Grained Sentiment Analysis Pre-Finetuning</title>
      <author><first>Tsung-Hsuan</first><last>Pan</last><affiliation>National Taiwan University</affiliation></author>
      <author><first>Chung-Chi</first><last>Chen</last><affiliation>AIST, National Institute of Advanced Industrial Science and Technology</affiliation></author>
      <author><first>Hen-Hsen</first><last>Huang</last><affiliation>Institute of Information Science, Academia Sinica</affiliation></author>
      <author><first>Hsin-Hsi</first><last>Chen</last><affiliation>National Taiwan University</affiliation></author>
      <pages>1371-1377</pages>
      <abstract>In the era of the digital world, while freedom of speech has been flourishing, it has also paved the way for disinformation, causing detrimental effects on society. Legal and ethical criteria are insufficient to address this concern, thus necessitating technological intervention. This paper presents a novel method leveraging pre-finetuning concept for efficient detection and removal of disinformation that may undermine society, as deemed by judicial entities. We argue the importance of detecting this type of disinformation and validate our approach with real-world data derived from court orders. Following a study that highlighted four areas of interest for rumor analysis, our research proposes the integration of a fine-grained sentiment analysis task in the pre-finetuning phase of language models, using the GoEmotions dataset. Our experiments validate the effectiveness of our approach in enhancing performance significantly. Furthermore, we explore the application of our approach across different languages using multilingual language models, showing promising results. To our knowledge, this is the first study that investigates the role of sentiment analysis pre-finetuning in disinformation detection.</abstract>
      <url hash="64499bf9">2024.findings-eacl.92</url>
      <bibkey>pan-etal-2024-enhancing</bibkey>
    </paper>
    <paper id="93">
      <title>Minimal Distillation Schedule for Extreme Language Model Compression</title>
      <author><first>Chen</first><last>Zhang</last><affiliation>Beijing Institute of Technology</affiliation></author>
      <author><first>Yang</first><last>Yang</last></author>
      <author><first>Qifan</first><last>Wang</last><affiliation>Meta AI</affiliation></author>
      <author><first>Jiahao</first><last>Liu</last></author>
      <author><first>Jingang</first><last>Wang</last><affiliation>Meituan</affiliation></author>
      <author><first>Wei</first><last>Wu</last><affiliation>Ant Research</affiliation></author>
      <author><first>Dawei</first><last>Song</last><affiliation>Beijing Institute of Technology and Open University</affiliation></author>
      <pages>1378-1394</pages>
      <abstract>Recent studies have revealed that language model distillation can become less effective when there is a significant capacity gap between the teacher and the student models. In order to bridge the gap, teacher assistant-based distillation has been introduced, in which the selection of the teacher assistant plays a crucial role in transferring knowledge from the teacher to the student. However, existing approaches for teacher assistant-based distillation require numerous trials to find the optimal teacher assistant.In this paper, we propose a novel approach called Minimal Distillation Schedule (MiniDisc), which enables the scheduling of an optimal teacher assistant in just one trial for extreme model compression (e.g, to 5% scale). In particular, we empirically show that the performance of the student is positively correlated with the scale-performance tradeoff of the teacher assistant. We then introduce a new <tex-math>\lambda</tex-math>-tradeoff metric that quantifies the optimality of the teacher assistant without the need for trial distillation to the student. By employing a sandwich framework, MiniDisc can select the optimal teacher assistant with the best <tex-math>\lambda</tex-math>-tradeoff.We extensively evaluate MiniDisc through a series of experiments on the GLUE benchmark. The results demonstrate that our approach achieved an improved efficiency compared to various state-of-the-art baselines. Furthermore, we showcase the scalability of MiniDisc by applying it to a language model with billions of parameters.</abstract>
      <url hash="036b40bb">2024.findings-eacl.93</url>
      <bibkey>zhang-etal-2024-minimal</bibkey>
    </paper>
    <paper id="94">
      <title>Event Semantic Classification in Context</title>
      <author><first>Haoyu</first><last>Wang</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Hongming</first><last>Zhang</last></author>
      <author><first>Kaiqiang</first><last>Song</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Dong</first><last>Yu</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Dan</first><last>Roth</last><affiliation>Amazon and University of Pennsylvania</affiliation></author>
      <pages>1395-1407</pages>
      <abstract>In this work, we focus on a fundamental yet underexplored problem, event semantic classification in context, to help machines gain a deeper understanding of events. We classify events from six perspectives: modality, affirmation, specificity, telicity, durativity, and kinesis. These properties provide essential cues regarding the occurrence and grounding of events, changes of status that events can bring about, and the connection between events and time. To this end, this paper introduces a novel dataset collected for the semantic classification tasks and several effective models. By incorporating these event properties into downstream tasks, we demonstrate that understanding the fine-grained event semantics benefits downstream event understanding and reasoning via experiments on event extraction, temporal relation extraction, and subevent relation extraction.</abstract>
      <url hash="a9fb504c">2024.findings-eacl.94</url>
      <bibkey>wang-etal-2024-event</bibkey>
    </paper>
    <paper id="95">
      <title>Local and Global Contexts for Conversation</title>
      <author><first>Zuoquan</first><last>Lin</last><affiliation>Peking University</affiliation></author>
      <author><first>Xinyi</first><last>Shen</last><affiliation>Peking University</affiliation></author>
      <pages>1408-1418</pages>
      <abstract>The context in conversation is the dialog history crucial for multi-turn dialogue. Learning from the relevant contexts in dialog history for grounded conversation is a challenging problem. Local context is the most neighbor and more sensitive to the subsequent response, and global context is relevant to a whole conversation far beyond neighboring utterances. Currently, pretrained transformer models for conversation challenge capturing the correlation and connection between local and global contexts. We introduce a local and global conversation model (LGCM) for general-purpose conversation in open domain. It is a local-global hierarchical transformer model that excels at accurately discerning and assimilating the relevant contexts necessary for generating responses. It employs a local encoder to grasp the local context at the level of individual utterances and a global encoder to understand the broader context at the dialogue level. The seamless fusion of these locally and globally contextualized encodings ensures a comprehensive comprehension of the conversation. Experiments on popular datasets show that LGCM outperforms the existing conversation models on the performance of automatic metrics with significant margins.</abstract>
      <url hash="070044b6">2024.findings-eacl.95</url>
      <bibkey>lin-shen-2024-local</bibkey>
    </paper>
    <paper id="96">
      <title>Aspect-based Key Point Analysis for Quantitative Summarization of Reviews</title>
      <author><first>An</first><last>Tang</last></author>
      <author><first>Xiuzhen</first><last>Zhang</last><affiliation>Royal Melbourne Institute of Technology</affiliation></author>
      <author><first>Minh</first><last>Dinh</last></author>
      <pages>1419-1433</pages>
      <abstract>Key Point Analysis (KPA) is originally for summarizing arguments, where short sentences containing salient viewpoints are extracted as key points (KPs) and quantified for their prevalence as salience scores. Recently, KPA was applied to summarize reviews, but the study still relies on sentence-based KP extraction and matching, which leads to two issues: sentence-based extraction can result in KPs of overlapping opinions on the same aspects, and sentence-based matching of KP to review comment can be inaccurate, resulting in inaccurate salience scores. To address the above issues, in this paper, we propose Aspect-based Key Point Analysis (ABKPA), a novel framework for quantitative review summarization. Leveraging the readily available aspect-based sentiment analysis (ABSA) resources of reviews to automatically annotate silver labels for matching aspect-sentiment pairs, we propose a contrastive learning model to effectively match KPs to reviews and quantify KPs at the aspect level. Especially, the framework ensures extracting KP of distinct aspects and opinions, leading to more accurate opinion quantification. Experiments on five business categories of the popular Yelp review dataset show that ABKPA outperforms state-of-the-art baselines. Source code and data are available at: https://github.com/antangrocket1312/ABKPA</abstract>
      <url hash="a8a88d1d">2024.findings-eacl.96</url>
      <bibkey>tang-etal-2024-aspect</bibkey>
    </paper>
    <paper id="97">
      <title>Improving Semantic Control in Discrete Latent Spaces with Transformer Quantized Variational Autoencoders</title>
      <author><first>Yingji</first><last>Zhang</last></author>
      <author><first>Danilo</first><last>Carvalho</last><affiliation>University of Manchester</affiliation></author>
      <author><first>Marco</first><last>Valentino</last></author>
      <author><first>Ian</first><last>Pratt-Hartmann</last><affiliation>University of Manchester, University of Manchester</affiliation></author>
      <author><first>Andre</first><last>Freitas</last><affiliation>University of Manchester</affiliation></author>
      <pages>1434-1450</pages>
      <abstract>Achieving precise semantic control over the latent spaces of Variational AutoEncoders (VAEs) holds significant value for downstream tasks in NLP as the underlying generative mechanisms could be better localised, explained and improved upon. Recent research, however, has struggled to achieve consistent results, primarily due to the inevitable loss of semantic information in the variational bottleneck and limited control over the decoding mechanism. To overcome these challenges, we investigate discrete latent spaces in Vector Quantized Variational AutoEncoder (VQVAE) to improve semantic control and generation in Transformer-based VAEs. In particular, We propose T5VQVAE, a novel model that leverages the controllability of VQVAE to guide the self-attention mechanism in T5, exploiting its full generalization capabilities. Experimental results indicate that T5VQVAE outperforms existing state-of-the-art VAE models, including Optimus, in terms of control and preservation of semantic information across different tasks such as auto-encoding of sentences and mathematical expressions, text transfer, and inference. Moreover, T5VQVAE exhibits improved reasoning capabilities, suggesting potential applications for downstream natural language and symbolic inference tasks.</abstract>
      <url hash="170b94f0">2024.findings-eacl.97</url>
      <bibkey>zhang-etal-2024-improving</bibkey>
    </paper>
    <paper id="98">
      <title>High-quality Data-to-Text Generation for Severely Under-Resourced Languages with Out-of-the-box Large Language Models</title>
      <author><first>Michela</first><last>Lorandi</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Anya</first><last>Belz</last><affiliation>Dublin City University and University of Aberdeen</affiliation></author>
      <pages>1451-1461</pages>
      <abstract>The performance of NLP methods for severely under-resourced languages cannot currently hope to match the state of the art in NLP methods for well resourced languages. We explore the extent to which pretrained large language models (LLMs) can bridge this gap, via the example of data-to-text generation for Irish, Welsh, Breton and Maltese. We test LLMs on these under-resourced languages and English, in a range of scenarios. We find that LLMs easily set the state of the art for the under-resourced languages by substantial margins, as measured by both automatic and human evaluations. For all our languages, human evaluation shows on-a-par performance with humans for our best systems, but BLEU scores collapse compared to English, casting doubt on the metric’s suitability for evaluating non-task-specific systems. Overall, our results demonstrate the great potential of LLMs to bridge the performance gap for under-resourced languages.</abstract>
      <url hash="6a16680d">2024.findings-eacl.98</url>
      <bibkey>lorandi-belz-2024-high</bibkey>
    </paper>
    <paper id="99">
      <title>Antonym vs Synonym Distinction using <fixed-case>I</fixed-case>nterla<fixed-case>C</fixed-case>ed Encoder <fixed-case>NET</fixed-case>works (<fixed-case>ICE</fixed-case>-<fixed-case>NET</fixed-case>)</title>
      <author><first>Muhammad</first><last>Ali</last><affiliation>King Abdullah University of Science and Technology</affiliation></author>
      <author><first>Yan</first><last>Hu</last><affiliation>King Abdullah University of Science and Technology</affiliation></author>
      <author><first>Jianbin</first><last>Qin</last><affiliation>Shenzhen University</affiliation></author>
      <author><first>Di</first><last>Wang</last><affiliation>KAUST</affiliation></author>
      <pages>1462-1473</pages>
      <abstract>Antonyms vs synonyms distinction is a core challenge in lexico-semantic analysis and automated lexical resource construction. These pairs share a similar distributional context which makes it harder to distinguish them. Leading research in this regard attempts to capture the properties of the relation pairs, i.e., symmetry, transitivity, and trans-transitivity. However, the inability of existing research to appropriately model the relation-specific properties limits their end performance. In this paper, we propose InterlaCed Encoder NETworks (i.e., ICE-NET) for antonym vs synonym distinction, that aim to capture and model the relation-specific properties of the antonyms and synonyms pairs in order to perform the classification task in a performance-enhanced manner. Experimental evaluation using the benchmark datasets shows that ICE-NET outperforms the existing research by a relative score of upto 1.8% in F1-measure.</abstract>
      <url hash="a7dca423">2024.findings-eacl.99</url>
      <bibkey>ali-etal-2024-antonym</bibkey>
    </paper>
    <paper id="100">
      <title>Predicting Machine Translation Performance on Low-Resource Languages: The Role of Domain Similarity</title>
      <author><first>Eric</first><last>Khiu</last></author>
      <author><first>Hasti</first><last>Toossi</last></author>
      <author><first>Jinyu</first><last>Liu</last></author>
      <author><first>Jiaxu</first><last>Li</last></author>
      <author><first>David</first><last>Anugraha</last></author>
      <author><first>Juan</first><last>Flores</last><affiliation>Universidad de Guanajuato</affiliation></author>
      <author><first>Leandro</first><last>Roman</last></author>
      <author><first>A. Seza</first><last>Doğruöz</last><affiliation>Ghent University</affiliation></author>
      <author><first>En-Shiun</first><last>Lee</last></author>
      <pages>1474-1486</pages>
      <abstract>Fine-tuning and testing a multilingual large language model is a challenge for low-resource languages (LRLs) since it is an expensive process. While previous studies have predicted the performance of natural language processing (NLP) tasks using machine learning methods, they primarily focus on high-resource languages, overlooking LRLs and shifts across domains. Focusing on LRLs, we investigate three factors (the size of the fine-tuning corpus, domain similarity between fine-tuning and testing corpora, and language similarity between source and target languages), which can potentially impact the model performance by using classical regression models. Our results indicate that domain similarity has the most important impact on predicting the performance of Machine Translation models.</abstract>
      <url hash="144d271f">2024.findings-eacl.100</url>
      <attachment type="software" hash="6c430bf7">2024.findings-eacl.100.software.zip</attachment>
      <attachment type="note" hash="6b714bab">2024.findings-eacl.100.note.zip</attachment>
      <bibkey>khiu-etal-2024-predicting</bibkey>
      <revision id="1" href="2024.findings-eacl.100v1" hash="02411aaa"/>
      <revision id="2" href="2024.findings-eacl.100v2" hash="144d271f" date="2024-03-25">Include authors email address.</revision>
    </paper>
    <paper id="101">
      <title>Does <fixed-case>CLIP</fixed-case> Bind Concepts? Probing Compositionality in Large Image Models</title>
      <author><first>Martha</first><last>Lewis</last><affiliation>University of Bristol and University of Bristol</affiliation></author>
      <author><first>Nihal</first><last>Nayak</last><affiliation>Brown University</affiliation></author>
      <author><first>Peilin</first><last>Yu</last><affiliation>Brown University</affiliation></author>
      <author><first>Jack</first><last>Merullo</last><affiliation>Brown University</affiliation></author>
      <author><first>Qinan</first><last>Yu</last></author>
      <author><first>Stephen</first><last>Bach</last><affiliation>Computer Science Department, Brown University and Snorkel AI</affiliation></author>
      <author><first>Ellie</first><last>Pavlick</last><affiliation>Brown University</affiliation></author>
      <pages>1487-1500</pages>
      <abstract>Large-scale neural network models combining text and images have made incredible progress in recent years. However, it remains an open question to what extent such models encode compositional representations of the concepts over which they operate, such as correctly identifying ‘red cube’ by reasoning over the constituents ‘red’ and ‘cube’. In this work, we focus on the ability of a large pretrained vision and language model (CLIP) to encode compositional concepts and to bind variables in a structure-sensitive way (e.g., differentiating ‘cube behind sphere’ from ‘sphere behind cube’). To inspect the performance of CLIP, we compare several architectures from research on compositional distributional semantics models (CDSMs), a line of research that attempts to implement traditional compositional linguistic structures within embedding spaces. We benchmark them on three synthetic datasets – single-object, two-object, and relational – designed to test concept binding. We find that CLIP can compose concepts in a single-object setting, but in situations where concept binding is needed, performance drops dramatically. At the same time, CDSMs also perform poorly, with best performance at chance level.</abstract>
      <url hash="88b32c5a">2024.findings-eacl.101</url>
      <attachment type="software" hash="88b0c508">2024.findings-eacl.101.software.zip</attachment>
      <bibkey>lewis-etal-2024-clip</bibkey>
    </paper>
    <paper id="102">
      <title>Code-Switching and Back-Transliteration Using a Bilingual Model</title>
      <author><first>Daniel</first><last>Weisberg Mitelman</last><affiliation>Reichman University</affiliation></author>
      <author><first>Nachum</first><last>Dershowitz</last><affiliation>Tel Aviv University, Technion</affiliation></author>
      <author><first>Kfir</first><last>Bar</last><affiliation>Reichman University</affiliation></author>
      <pages>1501-1511</pages>
      <abstract>The challenges of automated transliteration and code-switching–detection in Judeo-Arabic texts are addressed. We introduce two novel machine-learning models, one focused on transliterating Judeo-Arabic into Arabic, and another aimed at identifying non-Arabic words, predominantly Hebrew and Aramaic. Unlike prior work, our models are based on a bilingual Arabic-Hebrew language model, providing a unique advantage in capturing shared linguistic nuances. Evaluation results show that our models outperform prior solutions for the same tasks. As a practical contribution, we present a comprehensive pipeline capable of taking Judeo-Arabic text, identifying non-Arabic words, and then transliterating the Arabic portions into Arabic script. This work not only advances the state of the art but also offers a valuable toolset for making Judeo-Arabic texts more accessible to a broader Arabic-speaking audience.</abstract>
      <url hash="d7cc1bdf">2024.findings-eacl.102</url>
      <bibkey>weisberg-mitelman-etal-2024-code</bibkey>
    </paper>
    <paper id="103">
      <title>Tsetlin Machine Embedding: Representing Words Using Logical Expressions</title>
      <author><first>Bimal</first><last>Bhattarai</last></author>
      <author><first>Ole-Christoffer</first><last>Granmo</last></author>
      <author><first>Lei</first><last>Jiao</last><affiliation>University of Agder</affiliation></author>
      <author><first>Rohan</first><last>Yadav</last></author>
      <author><first>Jivitesh</first><last>Sharma</last><affiliation>Norwegian Institute for Air Research</affiliation></author>
      <pages>1512-1522</pages>
      <abstract>Embedding words in vector space is a fundamental first step in state-of-the-art natural language processing (NLP). Typical NLP solutions employ pre-defined vector representations to improve generalization by co-locating similar words in vector space. For instance, Word2Vec is a self-supervised predictive model that captures the context of words using a neural network. Similarly, GLoVe is a popular unsupervised model incorporating corpus-wide word co-occurrence statistics. Such word embedding has significantly boosted important NLP tasks, including sentiment analysis, document classification, and machine translation. However, the embeddings are dense floating-point vectors, making them expensive to compute and difficult to interpret. In this paper, we instead propose to represent the semantics of words with a few defining words that are related using propositional logic. To produce such logical embeddings, we introduce a Tsetlin Machine-based autoencoder that learns logical clauses self-supervised. The clauses consist of contextual words like <tex-math>\textit{black}</tex-math>, <tex-math>\textit{cup}</tex-math>, and <tex-math>\textit{hot}</tex-math> to define other words like <tex-math>\textit{coffee}</tex-math>, thus being human-understandable. We evaluate our embedding approach on several intrinsic and extrinsic benchmarks, outperforming GLoVe on six classification tasks. Furthermore, we investigate the interpretability of our embedding using the logical representations acquired during training. We also visualize word clusters in vector space, demonstrating how our logical embedding co-locate similar words.</abstract>
      <url hash="e635de69">2024.findings-eacl.103</url>
      <attachment type="software" hash="fe2bb58c">2024.findings-eacl.103.software.zip</attachment>
      <bibkey>bhattarai-etal-2024-tsetlin</bibkey>
    </paper>
    <paper id="104">
      <title>Reading Between the Tweets: Deciphering Ideological Stances of Interconnected Mixed-Ideology Communities</title>
      <author><first>Zihao</first><last>He</last></author>
      <author><first>Ashwin</first><last>Rao</last></author>
      <author><first>Siyi</first><last>Guo</last></author>
      <author><first>Negar</first><last>Mokhberian</last></author>
      <author><first>Kristina</first><last>Lerman</last><affiliation>University of Southern California and USC Information Sciences Institute</affiliation></author>
      <pages>1523-1536</pages>
      <abstract>Recent advances in NLP have improved our ability to understand the nuanced worldviews of online communities. Existing research focused on probing ideological stances treats liberals and conservatives as separate groups. However, this fails to account for the nuanced views of the organically formed online communities and the connections between them. In this paper, we study discussions of the 2020 U.S. election on Twitter to identify complex interacting communities. Capitalizing on this interconnectedness, we introduce a novel approach that harnesses message passing when finetuning language models (LMs) to probe the nuanced ideologies of these communities. By comparing the responses generated by LMs and real-world survey results, our method shows higher alignment than existing baselines, highlighting the potential of using LMs in revealing complex ideologies within and across interconnected mixed-ideology communities.</abstract>
      <url hash="f8386119">2024.findings-eacl.104</url>
      <attachment type="software" hash="9c7db982">2024.findings-eacl.104.software.zip</attachment>
      <attachment type="note" hash="f185d42a">2024.findings-eacl.104.note.zip</attachment>
      <bibkey>he-etal-2024-reading</bibkey>
    </paper>
    <paper id="105">
      <title>Unified Embeddings for Multimodal Retrieval via Frozen <fixed-case>LLM</fixed-case>s</title>
      <author><first>Ziyang</first><last>Wang</last><affiliation>Department of Computer Science, University of North Carolina at Chapel Hill</affiliation></author>
      <author><first>Heba</first><last>Elfardy</last><affiliation>Amazon</affiliation></author>
      <author><first>Markus</first><last>Dreyer</last><affiliation>Amazon</affiliation></author>
      <author><first>Kevin</first><last>Small</last><affiliation>Amazon</affiliation></author>
      <author><first>Mohit</first><last>Bansal</last><affiliation>University of North Carolina at Chapel Hill</affiliation></author>
      <pages>1537-1547</pages>
      <abstract>In this work, We present Unified Embeddings for Multimodal Retrieval (UniMuR), a simple but effective approach that embeds multimodal inputs and retrieves visual and textual outputs via frozen Large Language Models (LLMs). Specifically, UniMuR jointly retrieves multimodal outputs via a unified multimodal embedding and applies dual alignment training to account for both visual and textual semantics. Thus, unlike previous approaches, UniMuR significantly reduces LLM’s modality bias towards generating text-only outputs. Meanwhile, the proposed unified multimodal embedding mitigates the inconsistency between visual and textual outputs and provides coherent multimodal outputs. Furthermore, benefiting from the joint training of visual and textual semantics, UniMuR also achieves strong image/text retrieval ability. Compared to existing approaches, UniMuR achieves better zero-shot multimodal response retrieval performance on MMDialog, improving the overall R@1 by 6.5% while boosting the image retrieval rate and having better cross-modal consistency on multimodal outputs. UniMuR also achieves 2.4% and 3.9% improvement on context-based image retrieval tasks on MMDialog and VisDial respectively when compared to previous approaches, validating its generalization ability across multiple tasks.</abstract>
      <url hash="7ee77965">2024.findings-eacl.105</url>
      <bibkey>wang-etal-2024-unified</bibkey>
    </paper>
    <paper id="106">
      <title>Assessing the Portability of Parameter Matrices Trained by Parameter-Efficient Finetuning Methods</title>
      <author><first>Mohammed</first><last>Mohammed</last></author>
      <author><first>Anya</first><last>Belz</last><affiliation>Dublin City University and University of Aberdeen</affiliation></author>
      <pages>1548-1556</pages>
      <abstract>As the cost of training ever larger language models has grown, so has the interest in reusing previously learnt knowledge. Transfer learning methods have shown how reusing non-task-specific knowledge can help in subsequent task-specific learning.In this paper, we investigate the inverse: porting whole functional modules that encode task-specific knowledge from one model to another. We designed a study comprising 1,440 training/testing runs to test the portability of modules trained by parameter-efficient finetuning (PEFT) techniques, using sentiment analysis as an example task. We test portability in a wide range of scenarios, involving different PEFT techniques and different pretrained host models, among other dimensions. We compare the performance of ported modules with that of equivalent modules trained (i) from scratch, and (ii) from parameters sampled from the same distribution as the ported module.We find that the ported modules far outperform the two alternatives tested, but that there are interesting differences between the four PEFT techniques tested.We conclude that task-specific knowledge in the form of structurally modular sets of parameters as produced by PEFT techniques is highly portable, but that degree of success depends on type of PEFT and on differences between originating and receiving pretrained models.</abstract>
      <url hash="4e5f93e8">2024.findings-eacl.106</url>
      <bibkey>mohammed-belz-2024-assessing</bibkey>
    </paper>
    <paper id="107">
      <title>Exploiting Class Probabilities for Black-box Sentence-level Attacks</title>
      <author><first>Raha</first><last>Moraffah</last><affiliation>Arizona State University</affiliation></author>
      <author><first>Huan</first><last>Liu</last><affiliation>Arizona State University</affiliation></author>
      <pages>1557-1568</pages>
      <abstract>Sentence-level attacks craft adversarial sentences that are synonymous with correctly-classified sentences but are misclassified by the text classifiers. Under the black-box setting, classifiers are only accessible through their feedback to queried inputs, which is predominately available in the form of class probabilities. Even though utilizing class probabilities results in stronger attacks, due to the challenges of using them for sentence-level attacks, existing attacks use either no feedback or only the class labels. Overcoming the challenges, we develop a novel algorithm that uses class probabilities for black-box sentence-level attacks, investigate the effectiveness of using class probabilities on the attack’s success, and examine the question if it is worthy or practical to use class probabilities by black-box sentence-level attacks. We conduct extensive evaluations of the proposed attack comparing with the baselines across various classifiers and benchmark datasets.</abstract>
      <url hash="973ff83c">2024.findings-eacl.107</url>
      <bibkey>moraffah-liu-2024-exploiting</bibkey>
    </paper>
    <paper id="108">
      <title>Learning Label Hierarchy with Supervised Contrastive Learning</title>
      <author><first>Ruixue</first><last>Lian</last><affiliation>University of Wisconsin - Madison</affiliation></author>
      <author><first>William</first><last>Sethares</last><affiliation>University of Wisconsin - Madison</affiliation></author>
      <author><first>Junjie</first><last>Hu</last><affiliation>University of Wisconsin, Madison</affiliation></author>
      <pages>1569-1581</pages>
      <abstract>Supervised contrastive learning (SCL) frameworks treat each class as independent and thus consider all classes to be equally important. This neglects the common scenario in which label hierarchy exists, where fine-grained classes under the same category show more similarity than very different ones. This paper introduces a family of Label-Aware SCL methods (LA-SCL) that incorporates hierarchical information to SCL by leveraging similarities between classes, resulting in creating a more well-structured and discriminative feature space. This is achieved by first adjusting the distance between instances based on measures of the proximity of their classes with the scaled instance-instance-wise contrastive. An additional instance-center-wise contrastive is introduced to move within-class examples closer to their centers, which are represented by a set of learnable label parameters. The learned label parameters can be directly used as a nearest neighbor classifier without further finetuning. In this way, a better feature representation is generated with improvements of intra-cluster compactness and inter-cluster separation. Experiments on three datasets show that the proposed LA-SCL works well on text classification of distinguishing a single label among multi-labels, outperforming the baseline supervised approaches. Our code is publicly available <tex-math>^1</tex-math>.</abstract>
      <url hash="2d0f13d7">2024.findings-eacl.108</url>
      <bibkey>lian-etal-2024-learning</bibkey>
    </paper>
    <paper id="109">
      <title><fixed-case>G</fixed-case>roun<fixed-case>D</fixed-case>ial: Human-norm Grounded Safe Dialog Response Generation</title>
      <author><first>Siwon</first><last>Kim</last></author>
      <author><first>Shuyang</first><last>Dai</last><affiliation>Amazon</affiliation></author>
      <author><first>Mohammad</first><last>Kachuee</last><affiliation>Amazon</affiliation></author>
      <author><first>Shayan</first><last>Ray</last></author>
      <author><first>Tara</first><last>Taghavi</last></author>
      <author><first>Sungroh</first><last>Yoon</last><affiliation>Seoul National University</affiliation></author>
      <pages>1582-1588</pages>
      <abstract>Current conversational AI systems based on large language models (LLMs) are known to generate unsafe responses agreeing to offensive user input or including toxic content. Previous research aimed to alleviate the toxicity by fine-tuning LLM with manually annotated safe dialogue histories. However, the dependency on additional tuning requires substantial costs. To remove the dependency, we propose GrounDial, where response safety is achieved by grounding responses to commonsense social rules without requiring fine-tuning. A hybrid approach of in-context learning and human-norm-guided decoding of GrounDial enables the response to be quantitatively and qualitatively safer even without additional data or tuning.</abstract>
      <url hash="fd648be5">2024.findings-eacl.109</url>
      <bibkey>kim-etal-2024-groundial</bibkey>
    </paper>
    <paper id="110">
      <title>Trainable Hard Negative Examples in Contrastive Learning for Unsupervised Abstractive Summarization</title>
      <author><first>Haojie</first><last>Zhuang</last><affiliation>University of Adelaide</affiliation></author>
      <author><first>Wei Emma</first><last>Zhang</last><affiliation>The University of Adelaide</affiliation></author>
      <author><first>Chang</first><last>Dong</last><affiliation>University of Adelaide</affiliation></author>
      <author><first>Jian</first><last>Yang</last><affiliation>Macquarie University</affiliation></author>
      <author><first>Quan</first><last>Sheng</last><affiliation>Macquarie University</affiliation></author>
      <pages>1589-1600</pages>
      <abstract>Contrastive learning has demonstrated promising results in unsupervised abstractive summarization. However, existing methods rely on manually crafted negative examples, demanding substantial human effort and domain knowledge. Moreover, these human-generated negative examples may be poor in quality and lack adaptability during model training. To address these issues, we propose a novel approach that learns trainable negative examples for contrastive learning in unsupervised abstractive summarization, which eliminates the need for manual negative example design. Our framework introduces an adversarial optimization process between a negative example network and a representation network (including the summarizer and encoders). The negative example network is trained to synthesize hard negative examples that are close to the positive examples, driving the representation network to improve the quality of the generated summaries. We evaluate our method on two benchmark datasets for unsupervised abstractive summarization and observe significant performance improvements compared to strong baseline models.</abstract>
      <url hash="fc891a5c">2024.findings-eacl.110</url>
      <bibkey>zhuang-etal-2024-trainable</bibkey>
    </paper>
    <paper id="111">
      <title>Low-Resource Counterspeech Generation for <fixed-case>I</fixed-case>ndic Languages: The Case of <fixed-case>B</fixed-case>engali and <fixed-case>H</fixed-case>indi</title>
      <author><first>Mithun</first><last>Das</last><affiliation>Indian Institute of Technology Kharagpur</affiliation></author>
      <author><first>Saurabh</first><last>Pandey</last></author>
      <author><first>Shivansh</first><last>Sethi</last></author>
      <author><first>Punyajoy</first><last>Saha</last><affiliation>Indian Institute of Technology Kharagpur</affiliation></author>
      <author><first>Animesh</first><last>Mukherjee</last><affiliation>Indian Institute of Technology Kharagpur</affiliation></author>
      <pages>1601-1614</pages>
      <abstract>With the rise of online abuse, the NLP community has begun investigating the use of neural architectures to generate counterspeech that can “counter” the vicious tone of such abusive speech and dilute/ameliorate their rippling effect over the social network. However, most of the efforts so far have been primarily focused on English. To bridge the gap for low-resource languages such as Bengali and Hindi, we create a benchmark dataset of 5,062 abusive speech/counterspeech pairs, of which 2,460 pairs are in Bengali, and 2,602 pairs are in Hindi. We implement several baseline models considering various interlingual transfer mechanisms with different configurations to generate suitable counterspeech to set up an effective benchmark. We observe that the monolingual setup yields the best performance. Further, using synthetic transfer, language models can generate counterspeech to some extent; specifically, we notice that transferability is better when languages belong to the same language family.</abstract>
      <url hash="419ea91d">2024.findings-eacl.111</url>
      <attachment type="note" hash="8bdbf9b3">2024.findings-eacl.111.note.zip</attachment>
      <bibkey>das-etal-2024-low</bibkey>
    </paper>
    <paper id="112">
      <title>Teaching Probabilistic Logical Reasoning to Transformers</title>
      <author><first>Aliakbar</first><last>Nafar</last></author>
      <author><first>K. Brent</first><last>Venable</last><affiliation>University of West Florida and Florida Institute of Human and Machine Cognition</affiliation></author>
      <author><first>Parisa</first><last>Kordjamshidi</last><affiliation>Michigan State University</affiliation></author>
      <pages>1615-1632</pages>
      <abstract>In this paper, we evaluate the capability of transformer-based language models in making inferences over uncertain text that includes uncertain rules of reasoning. We cover both Pre-trained Language Models (PLMs) and generative Large Language Models (LLMs). Our evaluation results show that both generations of language models struggle with reasoning over uncertain text. We propose a novel end-to-end fine-tuning approach, Probabilistic Constraint Training (PCT), that utilizes probabilistic logical rules as constraints in the fine-tuning phase without relying on these rules in the inference stage. To assess the effectiveness of PCT, we utilize the related corpora and, additionally, create a new and more challenging benchmark that, unlike the previous ones, uses instance-specific rules. Our study demonstrates that PCT improves the transformer-based language model’s intrinsic reasoning and makes their probabilistic logical reasoning process more explicit and explainable. Furthermore, PCT equips these models to effectively handle novel situations, including higher reasoning depth, new domains, and complex probabilistic structures.</abstract>
      <url hash="e83b6dd5">2024.findings-eacl.112</url>
      <attachment type="software" hash="ea1e1ac9">2024.findings-eacl.112.software.zip</attachment>
      <attachment type="note" hash="ea47095c">2024.findings-eacl.112.note.zip</attachment>
      <bibkey>nafar-etal-2024-teaching</bibkey>
    </paper>
    <paper id="113">
      <title>On Measuring Context Utilization in Document-Level <fixed-case>MT</fixed-case> Systems</title>
      <author><first>Wafaa</first><last>Mohammed</last></author>
      <author><first>Vlad</first><last>Niculae</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>1633-1643</pages>
      <abstract>Document-level translation models are usually evaluated using general metrics such as BLEU, which are not informative about the benefits of context. Current work on context-aware evaluation, such as contrastive methods, only measure translation accuracy on words that need context for disambiguation. Such measures cannot reveal whether the translation model uses the correct supporting context. We propose to complement accuracy-based evaluation with measures of context utilization. We find that perturbation-based analysis (comparing models’ performance when provided with correct versus random context) is an effective measure of overall context utilization. For a finer-grained phenomenon-specific evaluation, we propose to measure how much the supporting context contributes to handling context-dependent discourse phenomena. We show that automatically-annotated supporting context gives similar conclusions to human-annotated context and can be used as alternative for cases where human annotations are not available. Finally, we highlight the importance of using discourse-rich datasets when assessing context utilization.</abstract>
      <url hash="d45369b7">2024.findings-eacl.113</url>
      <bibkey>mohammed-niculae-2024-measuring</bibkey>
    </paper>
    <paper id="114">
      <title>Solving <fixed-case>NLP</fixed-case> Problems through Human-System Collaboration: A Discussion-based Approach</title>
      <author><first>Masahiro</first><last>Kaneko</last><affiliation>Tokyo Institute of Technology</affiliation></author>
      <author><first>Graham</first><last>Neubig</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Naoaki</first><last>Okazaki</last><affiliation>Tokyo Institute of Technology</affiliation></author>
      <pages>1644-1658</pages>
      <abstract>Humans work together to solve common problems by having discussions, explaining, and agreeing or disagreeing with each other.Similarly, if a system can have discussions with human partners when solving tasks, it has the potential to improve the system’s performance and reliability.In previous research on explainability, it has only been possible for systems to make predictions and for humans to ask questions about them, rather than having a mutual exchange of opinions.This research aims to create a dataset and computational framework for systems that discuss and refine their predictions through dialogue. Through experiments, we show that the proposed system can have beneficial discussions with humans, improving the accuracy by up to 25 points on a natural language inference task.</abstract>
      <url hash="e5d679ba">2024.findings-eacl.114</url>
      <attachment type="note" hash="e94e1232">2024.findings-eacl.114.note.zip</attachment>
      <bibkey>kaneko-etal-2024-solving</bibkey>
    </paper>
    <paper id="115">
      <title>Autoregressive Score Generation for Multi-trait Essay Scoring</title>
      <author><first>Heejin</first><last>Do</last><affiliation>Pohang University of Science and Technology</affiliation></author>
      <author><first>Yunsu</first><last>Kim</last><affiliation>aiXplain, Inc.</affiliation></author>
      <author><first>Gary</first><last>Lee</last></author>
      <pages>1659-1666</pages>
      <abstract>Recently, encoder-only pre-trained models such as BERT have been successfully applied in automated essay scoring (AES) to predict a single overall score. However, studies have yet to explore these models in multi-trait AES, possibly due to the inefficiency of replicating BERT-based models for each trait. Breaking away from the existing sole use of *encoder*, we propose an autoregressive prediction of multi-trait scores (ArTS), incorporating a *decoding* process by leveraging the pre-trained T5. Unlike prior regression or classification methods, we redefine AES as a score-generation task, allowing a single model to predict multiple scores. During decoding, the subsequent trait prediction can benefit by conditioning on the preceding trait scores. Experimental results proved the efficacy of ArTS, showing over 5% average improvements in both prompts and traits.</abstract>
      <url hash="ae5946d1">2024.findings-eacl.115</url>
      <bibkey>do-etal-2024-autoregressive</bibkey>
    </paper>
    <paper id="116">
      <title><fixed-case>CMA</fixed-case>-<fixed-case>R</fixed-case>: Causal Mediation Analysis for Explaining Rumour Detection</title>
      <author><first>Lin</first><last>Tian</last><affiliation>Royal Melbourne Institute of Technology</affiliation></author>
      <author><first>Xiuzhen</first><last>Zhang</last><affiliation>Royal Melbourne Institute of Technology</affiliation></author>
      <author><first>Jey Han</first><last>Lau</last><affiliation>The University of Melbourne</affiliation></author>
      <pages>1667-1675</pages>
      <abstract>We apply causal mediation analysis to explain the decision-making process of neural models for rumour detection on Twitter.Interventions at the input and network level reveal the causal impacts of tweets and words in the model output.We find that our approach CMA-R – Causal Mediation Analysis for Rumour detection – identifies salient tweets that explain model predictions and show strong agreement with human judgements for critical tweets determining the truthfulness of stories.CMA-R can further highlight causally impactful words in the salient tweets, providing another layer of interpretability and transparency into these blackbox rumour detection systems. Code is available at: https://github.com/ltian678/cma-r.</abstract>
      <url hash="c2bab0c1">2024.findings-eacl.116</url>
      <bibkey>tian-etal-2024-cma</bibkey>
    </paper>
    <paper id="117">
      <title>Morphology Aware Source Term Masking for Terminology-Constrained <fixed-case>NMT</fixed-case></title>
      <author><first>Ander</first><last>Corral</last><affiliation>Orai NLP Technologies</affiliation></author>
      <author><first>Xabier</first><last>Saralegi</last></author>
      <pages>1676-1688</pages>
      <abstract>Terminology-constrained NMT systems facilitate the forced translation of domain-specific vocabulary. A notable method in this context is the “copy-and-inflect” approach, which appends the target term lemmas of constraints to their corresponding source terms in the input sentence. In this work, we propose a novel adaptation of the “copy-and-inflect” method, referred to as “morph-masking”. Our method involves masking the source terms of the constraints from the input sentence while retaining essential grammatical information. Our approach is based on the hypothesis that “copy-and-inflect” systems have access to both source and target terms, allowing them to generate the correct surface form of the constraint by either translating the source term itself or properly inflecting the target term lemma. Through extensive validation of our method in two translation directions with different levels of source morphological complexity, Basque to Spanish and English to German, we have demonstrated that “morph-masking” is capable of providing a harder constraint signal, resulting in a notable improvement over the “copy-and-inflect” method (up to 38% in term accuracy), especially in challenging constraint scenarios.</abstract>
      <url hash="f037957d">2024.findings-eacl.117</url>
      <bibkey>corral-saralegi-2024-morphology</bibkey>
    </paper>
    <paper id="118">
      <title>Improving Backchannel Prediction Leveraging Sequential and Attentive Context Awareness</title>
      <author><first>Yo-Han</first><last>Park</last><affiliation>Chungnam National University and Chungnam National University</affiliation></author>
      <author><first>Wencke</first><last>Liermann</last><affiliation>Chungnam National University</affiliation></author>
      <author><first>Yong-Seok</first><last>Choi</last><affiliation>Chungnam National University</affiliation></author>
      <author><first>Kong Joo</first><last>Lee</last><affiliation>Chungnam National University</affiliation></author>
      <pages>1689-1694</pages>
      <abstract>Backchannels, which refer to short and often affirmative or empathetic responses from a listener during a conversation, play a crucial role in effective communication. In this paper, we introduce CABP(Context-Aware Backchannel Prediction), a sequential and attentive context approach aimed at enhancing backchannel prediction performance. Additionally, CABP leverages the pretrained wav2vec model for encoding audio signal. Experimental results show that CABP performs better than context-free models, with performance improvements of 1.3% and 1.8% in Korean and English datasets, respectively. Furthermore, when utilizing the pretrained wav2vec model, CABP consistently demonstrates the best performance, achieving performance improvements of 4.4% and 3.1% in Korean and English datasets.</abstract>
      <url hash="0120613a">2024.findings-eacl.118</url>
      <attachment type="software" hash="747f9bcc">2024.findings-eacl.118.software.zip</attachment>
      <bibkey>park-etal-2024-improving</bibkey>
    </paper>
    <paper id="119">
      <title><fixed-case>SENSE</fixed-case>-<fixed-case>LM</fixed-case> : A Synergy between a Language Model and Sensorimotor Representations for Auditory and Olfactory Information Extraction</title>
      <author><first>Cédric</first><last>Boscher</last></author>
      <author><first>Christine</first><last>Largeron</last><affiliation>Université Jean Monnet</affiliation></author>
      <author><first>Véronique</first><last>Eglin</last><affiliation>Institut National des Sciences Appliquées de Lyon</affiliation></author>
      <author><first>Elöd</first><last>Egyed-Zsigmond</last><affiliation>Institut National des Sciences Appliquées de Lyon</affiliation></author>
      <pages>1695-1711</pages>
      <abstract>The five human senses – vision, taste, smell, hearing, and touch – are key concepts that shape human perception of the world. The extraction of sensory references (i.e., expressions that evoke the presence of a sensory experience) in textual corpus is a challenge of high interest, with many applications in various areas. In this paper, we propose SENSE-LM, an information extraction system tailored for the discovery of sensory references in large collections of textual documents. Based on the novel idea of combining the strength of large language models and linguistic resources such as sensorimotor norms, it addresses the task of sensory information extraction at a coarse-grained (sentence binary classification) and fine-grained (sensory term extraction) level.Our evaluation of SENSE-LM for two sensory functions, Olfaction and Audition, and comparison with state-of-the-art methods emphasize a significant leap forward in automating these complex tasks.</abstract>
      <url hash="1b5a5d95">2024.findings-eacl.119</url>
      <bibkey>boscher-etal-2024-sense</bibkey>
    </paper>
    <paper id="120">
      <title>Analyzing the Role of Part-of-Speech in Code-Switching: A Corpus-Based Study</title>
      <author><first>Jie</first><last>Chi</last></author>
      <author><first>Peter</first><last>Bell</last><affiliation>University of Edinburgh, University of Edinburgh</affiliation></author>
      <pages>1712-1721</pages>
      <abstract>Code-switching (CS) is a common linguistic phenomenon wherein speakers fluidly transition between languages in conversation. While the cognitive processes driving CS remain a complex domain, earlier investigations have shed light on its multifaceted triggers. This study delves into the influence of Part-of-Speech (POS) on the propensity of bilinguals to engage in CS, employing a comprehensive analysis of Spanish-English and Mandarin-English corpora. Compared with prior research, our findings not only affirm the existence of a statistically significant connection between POS and the likelihood of CS across language pairs, but notably find this relationship exhibits its maximum strength in proximity to CS instances, progressively diminishing as tokens distance themselves from these CS points.</abstract>
      <url hash="cdc4e20a">2024.findings-eacl.120</url>
      <bibkey>chi-bell-2024-analyzing</bibkey>
    </paper>
    <paper id="121">
      <title>In-Contextual Gender Bias Suppression for Large Language Models</title>
      <author><first>Daisuke</first><last>Oba</last><affiliation>Institute of Industrial Science, The University of Tokyo</affiliation></author>
      <author><first>Masahiro</first><last>Kaneko</last><affiliation>Tokyo Institute of Technology</affiliation></author>
      <author><first>Danushka</first><last>Bollegala</last><affiliation>Amazon and University of Liverpool</affiliation></author>
      <pages>1722-1742</pages>
      <abstract>Despite their impressive performance in a wide range of NLP tasks, Large Language Models (LLMs) have been reported to encode worrying-levels of gender biases. Prior work has proposed debiasing methods that require human labelled examples, data augmentation and fine-tuning of LLMs, which are computationally costly. Moreover, one might not even have access to the model parameters for performing debiasing such as in the case of closed LLMs such as GPT-4. To address this challenge, we propose bias suppression that prevents biased generations of LLMs by simply providing textual preambles constructed from manually designed templates and real-world statistics, without accessing to model parameters. We show that, using CrowsPairs dataset, our textual preambles covering counterfactual statements can suppress gender biases in English LLMs such as LLaMA2. Moreover, we find that gender-neutral descriptions of gender-biased objects can also suppress their gender biases. Moreover, we show that bias suppression has acceptable adverse effect on downstream task performance with HellaSwag and COPA.</abstract>
      <url hash="5dd0284b">2024.findings-eacl.121</url>
      <bibkey>oba-etal-2024-contextual</bibkey>
    </paper>
    <paper id="122">
      <title>Parameter-Efficient Fine-Tuning: Is There An Optimal Subset of Parameters to Tune?</title>
      <author><first>Max</first><last>Ploner</last><affiliation>Humboldt Universität Berlin</affiliation></author>
      <author><first>Alan</first><last>Akbik</last><affiliation>Humboldt Universität Berlin</affiliation></author>
      <pages>1743-1759</pages>
      <abstract>The ever-growing size of pretrained language models (PLM) presents a significant challenge for efficiently fine-tuning and deploying these models for diverse sets of tasks within memory-constrained environments.In light of this, recent research has illuminated the possibility of selectively updating only a small subset of a model’s parameters during the fine-tuning process.Since no new parameters or modules are added, these methods retain the inference speed of the original model and come at no additional computational cost. However, an open question pertains to which subset of parameters should best be tuned to maximize task performance and generalizability. To investigate, this paper presents comprehensive experiments covering a large spectrum of subset selection strategies. We comparatively evaluate their impact on model performance as well as the resulting model’s capability to generalize to different tasks.Surprisingly, we find that the gains achieved in performance by elaborate selection strategies are, at best, marginal when compared to the outcomes obtained by tuning a random selection of parameter subsets. Our experiments also indicate that selection-based tuning impairs generalizability to new tasks.</abstract>
      <url hash="da50d04e">2024.findings-eacl.122</url>
      <bibkey>ploner-akbik-2024-parameter</bibkey>
    </paper>
    <paper id="123">
      <title>Contextualized Topic Coherence Metrics</title>
      <author><first>Hamed</first><last>Rahimi</last></author>
      <author><first>David</first><last>Mimno</last><affiliation>Cornell University and Cornell University</affiliation></author>
      <author><first>Jacob</first><last>Hoover</last><affiliation>McGill University</affiliation></author>
      <author><first>Hubert</first><last>Naacke</last><affiliation>Sorbonne Université</affiliation></author>
      <author><first>Camelia</first><last>Constantin</last></author>
      <author><first>Bernd</first><last>Amann</last><affiliation>Sorbonne Université</affiliation></author>
      <pages>1760-1773</pages>
      <abstract>This article proposes a new family of LLM-based topic coherence metrics called Contextualized Topic Coherence (CTC) and inspired by standard human topic evaluation methods. CTC metrics simulate human-centered coherence evaluation while maintaining the efficiency of other automated methods. We compare the performance of our CTC metrics and five other baseline metrics on seven topic models and show that CTC metrics better reflect human judgment, particularly for topics extracted from short text collections by avoiding highly scored topics that are meaningless to humans.</abstract>
      <url hash="f7168365">2024.findings-eacl.123</url>
      <attachment type="software" hash="3868254e">2024.findings-eacl.123.software.zip</attachment>
      <bibkey>rahimi-etal-2024-contextualized</bibkey>
    </paper>
    <paper id="124">
      <title><fixed-case>P</fixed-case>ro<fixed-case>MIS</fixed-case>e: A Proactive Multi-turn Dialogue Dataset for Information-seeking Intent Resolution</title>
      <author><first>Yash</first><last>Butala</last></author>
      <author><first>Siddhant</first><last>Garg</last><affiliation>Meta</affiliation></author>
      <author><first>Pratyay</first><last>Banerjee</last><affiliation>Amazon</affiliation></author>
      <author><first>Amita</first><last>Misra</last><affiliation>Amazon</affiliation></author>
      <pages>1774-1789</pages>
      <abstract>Users of AI-based virtual assistants and search systems encounter challenges in articulating their intents while seeking information on unfamiliar topics, possibly due to complexity of the user’s intent or the lack of meta-information on the topic. We posit that an iterative suggested question-answering (SQA) conversation can improve the trade-off between the satisfaction of the user’s intent while keeping the information exchange natural and cognitive load of the interaction minimal on the users. In this paper, we evaluate a novel setting ProMISe by means of a sequence of interactions between a user, having a predefined information-seeking intent, and an agent that generates a set of SQA pairs at each step to aid the user to get closer to their intent. We simulate this two-player setting to create a multi-turn conversational dataset of SQAs and user choices (1025 dialogues comprising 4453 turns and 17812 SQAs) using human-feedback, chain-of-thought prompting and web-retrieval augmented large language models. We evaluate the quality of the SQs in the dataset on attributes such as diversity, specificity, grounding, etc, and benchmark the performance of different language models for the task of replicating user behavior.</abstract>
      <url hash="f2aec2e2">2024.findings-eacl.124</url>
      <attachment type="note" hash="551af5d6">2024.findings-eacl.124.note.zip</attachment>
      <bibkey>butala-etal-2024-promise</bibkey>
    </paper>
    <paper id="125">
      <title><fixed-case>CODET</fixed-case>: A Benchmark for Contrastive Dialectal Evaluation of Machine Translation</title>
      <author><first>Md Mahfuz Ibn</first><last>Alam</last></author>
      <author><first>Sina</first><last>Ahmadi</last><affiliation>George Mason University</affiliation></author>
      <author><first>Antonios</first><last>Anastasopoulos</last><affiliation>Athena Research Center and George Mason University</affiliation></author>
      <pages>1790-1859</pages>
      <abstract>Neural machine translation (NMT) systems exhibit limited robustness in handling source-side linguistic variations. Their performance tends to degrade when faced with even slight deviations in language usage, such as different domains or variations introduced by second-language speakers. It is intuitive to extend this observation to encompass dialectal variations as well, but the work allowing the community to evaluate MT systems on this dimension is limited. To alleviate this issue, we compile and release CODET, a contrastive dialectal benchmark encompassing 891 different variations from twelve different languages. We also quantitatively demonstrate the challenges large MT models face in effectively translating dialectal variants. All the data and code have been released.</abstract>
      <url hash="9e3000f0">2024.findings-eacl.125</url>
      <bibkey>alam-etal-2024-codet</bibkey>
    </paper>
    <paper id="126">
      <title><fixed-case>QAEVENT</fixed-case>: Event Extraction as Question-Answer Pairs Generation</title>
      <author><first>Milind</first><last>Choudhary</last><affiliation>University of Texas at Dallas</affiliation></author>
      <author><first>Xinya</first><last>Du</last><affiliation>University of Texas at Dallas</affiliation></author>
      <pages>1860-1873</pages>
      <abstract>We propose a novel representation of document-level events as question and answer pairs (QAEVENT). Under this paradigm: (1) questions themselves can define argument roles without the need for predefined schemas, which will cover a comprehensive list of event arguments from the document; (2) it allows for more scalable and faster annotations from crowdworkers without linguistic expertise. Based on our new paradigm, we collect a novel and wide-coverage dataset. Our examinations show that annotations with the QA representations produce high-quality data for document-level event extraction, both in terms of human agreement level and high coverage of roles comparing to the pre-defined schema. We present and compare representative approaches for generating event question answer pairs on our benchmark.</abstract>
      <url hash="43e68930">2024.findings-eacl.126</url>
      <bibkey>choudhary-du-2024-qaevent</bibkey>
    </paper>
    <paper id="127">
      <title>Sequence Shortening for Context-Aware Machine Translation</title>
      <author><first>Paweł</first><last>Maka</last><affiliation>Maastricht University</affiliation></author>
      <author><first>Yusuf</first><last>Semerci</last><affiliation>Maastricht University</affiliation></author>
      <author><first>Jan</first><last>Scholtes</last><affiliation>Maastricht University</affiliation></author>
      <author><first>Gerasimos</first><last>Spanakis</last><affiliation>Maastricht University</affiliation></author>
      <pages>1874-1894</pages>
      <abstract>Context-aware Machine Translation aims to improve translations of sentences by incorporating surrounding sentences as context. Towards this task, two main architectures have been applied, namely single-encoder (based on concatenation) and multi-encoder models. In this study, we show that a special case of multi-encoder architecture, where the latent representation of the source sentence is cached and reused as the context in the next step, achieves higher accuracy on the contrastive datasets (where the models have to rank the correct translation among the provided sentences) and comparable BLEU and COMET scores as the single- and multi-encoder approaches. Furthermore, we investigate the application of Sequence Shortening to the cached representations. We test three pooling-based shortening techniques and introduce two novel methods - Latent Grouping and Latent Selecting, where the network learns to group tokens or selects the tokens to be cached as context. Our experiments show that the two methods achieve competitive BLEU and COMET scores and accuracies on the contrastive datasets to the other tested methods while potentially allowing for higher interpretability and reducing the growth of memory requirements with increased context size.</abstract>
      <url hash="774a45f4">2024.findings-eacl.127</url>
      <bibkey>maka-etal-2024-sequence</bibkey>
    </paper>
    <paper id="128">
      <title>Jigsaw Pieces of Meaning: Modeling Discourse Coherence with Informed Negative Sample Synthesis</title>
      <author><first>Shubhankar</first><last>Singh</last></author>
      <pages>1895-1908</pages>
      <abstract>Coherence in discourse is fundamental for comprehension and perception. Much research on coherence modeling has focused on better model architectures and training setups optimizing on the permuted document task, where random permutations of a coherent document are considered incoherent. However, there’s very limited work on creating “informed” synthetic incoherent samples that better represent or mimic incoherence. We source a diverse positive corpus for local coherence and propose six rule-based methods leveraging information from Constituency trees, Part-of-speech, semantic overlap and more, for “informed” negative sample synthesis for better representation of incoherence. We keep a straightforward training setup for local coherence modeling by fine-tuning popular transformer models, and aggregate local scores for global coherence. We evaluate on a battery of independent downstream tasks to assess the impact of improved negative sample quality. We assert that a step towards optimality for coherence modeling requires better negative sample synthesis in tandem with model improvements.</abstract>
      <url hash="7d14f3f1">2024.findings-eacl.128</url>
      <bibkey>singh-2024-jigsaw</bibkey>
    </paper>
    <paper id="129">
      <title>Non-Exchangeable Conformal Language Generation with Nearest Neighbors</title>
      <author><first>Dennis</first><last>Ulmer</last></author>
      <author><first>Chrysoula</first><last>Zerva</last><affiliation>Instituto Superior Técnico</affiliation></author>
      <author><first>Andre</first><last>Martins</last><affiliation>Instituto Superior Técnico and Unbabel</affiliation></author>
      <pages>1909-1929</pages>
      <abstract>Quantifying uncertainty in automatically generated text is important for letting humans check potential hallucinations and making systems more reliable. Conformal prediction is an attractive framework to provide predictions imbued with statistical guarantees, however, its application to text generation is challenging since any i.i.d. assumptions are not realistic. In this paper, we bridge this gap by leveraging recent results on *non-exchangeable* conformal prediction, which still ensures bounds on coverage. The result, *non-exchangeable conformal nucleus sampling*, is a novel extension of the conformal prediction framework to generation based on nearest neighbors. Our method can be used post-hoc for an arbitrary model without extra training and supplies token-level, calibrated prediction sets equipped with statistical guarantees. Experiments in machine translation and language modeling show encouraging results in generation quality. By also producing tighter prediction sets with good coverage, we thus give a more theoretically principled way to perform sampling with conformal guarantees.</abstract>
      <url hash="74ae0a2d">2024.findings-eacl.129</url>
      <bibkey>ulmer-etal-2024-non</bibkey>
    </paper>
    <paper id="130">
      <title>Evidentiality-aware Retrieval for Overcoming Abstractiveness in Open-Domain Question Answering</title>
      <author><first>Yongho</first><last>Song</last><affiliation>Yonsei University</affiliation></author>
      <author><first>Dahyun</first><last>Lee</last></author>
      <author><first>Myungha</first><last>Jang</last><affiliation>Pinterest Inc.</affiliation></author>
      <author><first>Seung-won</first><last>Hwang</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Kyungjae</first><last>Lee</last></author>
      <author><first>Dongha</first><last>Lee</last><affiliation>Yonsei University</affiliation></author>
      <author><first>Jinyoung</first><last>Yeo</last><affiliation>Yonsei University</affiliation></author>
      <pages>1930-1943</pages>
      <abstract>The long-standing goal of dense retrievers in abtractive open-domain question answering (ODQA) tasks is to learn to capture evidence passages among relevant passages for any given query, such that the reader produce factually correct outputs from evidence passages. One of the key challenge is the insufficient amount of training data with the supervision of the answerability of the passages. Recent studies rely on iterative pipelines to annotate answerability using signals from the reader, but their high computational costs hamper practical applications. In this paper, we instead focus on a data-driven approach and propose Evidentiality-Aware Dense Passage Retrieval (EADPR), which leverages synthetic distractor samples to learn to discriminate evidence passages from distractors. We conduct extensive experiments to validate the effectiveness of our proposed method on multiple abstractive ODQA tasks.</abstract>
      <url hash="021372bf">2024.findings-eacl.130</url>
      <bibkey>song-etal-2024-evidentiality</bibkey>
    </paper>
    <paper id="131">
      <title>Self-training Strategies for Sentiment Analysis: An Empirical Study</title>
      <author><first>Haochen</first><last>Liu</last><affiliation>Fidelity Investments</affiliation></author>
      <author><first>Sai</first><last>Rallabandi</last></author>
      <author><first>Yijing</first><last>Wu</last></author>
      <author><first>Parag</first><last>Dakle</last></author>
      <author><first>Preethi</first><last>Raghavan</last><affiliation>Fidelity</affiliation></author>
      <pages>1944-1954</pages>
      <abstract>Sentiment analysis is a crucial task in natural language processing that involves identifying and extracting subjective sentiment from text. Self-training has recently emerged as an economical and efficient technique for developing sentiment analysis models by leveraging a small amount of labeled data and a large amount of unlabeled data. However, given a set of training data, how to utilize them to conduct self-training makes a significant difference in the final performance of the model. We refer to this methodology as the self-training strategy. In this paper, we present an empirical study of various self-training strategies for sentiment analysis. First, we investigate the influence of the self-training strategy and hyper-parameters on the performance of traditional small language models (SLMs) in various few-shot settings. Second, we also explore the feasibility of leveraging large language models (LLMs) to help self-training. We propose and empirically compare several self-training strategies with the intervention of LLMs. Extensive experiments are conducted on three real-world sentiment analysis datasets.</abstract>
      <url hash="10c2026e">2024.findings-eacl.131</url>
      <bibkey>liu-etal-2024-self</bibkey>
    </paper>
    <paper id="132">
      <title>Language is All a Graph Needs</title>
      <author><first>Ruosong</first><last>Ye</last><affiliation>Rutgers University</affiliation></author>
      <author><first>Caiqi</first><last>Zhang</last></author>
      <author><first>Runhui</first><last>Wang</last></author>
      <author><first>Shuyuan</first><last>Xu</last><affiliation>Rutgers University</affiliation></author>
      <author><first>Yongfeng</first><last>Zhang</last><affiliation>Rutgers University</affiliation></author>
      <pages>1955-1973</pages>
      <abstract>The emergence of large-scale pre-trained language models has revolutionized various AI research domains. Transformers-based Large Language Models (LLMs) have gradually replaced CNNs and RNNs to unify fields of computer vision and natural language processing. Compared with independent data like images, videos or texts, graphs usually contain rich structural and relational information. Meanwhile, languages, especially natural language, being one of the most expressive mediums, excels in describing complex structures. However, existing work on incorporating graph problems into the generative language modeling framework remains very limited. Considering the rising prominence of LLMs, it becomes essential to explore whether LLMs can also replace GNNs as the foundation model for graphs. In this paper, we propose InstructGLM (Instruction-finetuned Graph Language Model) with highly scalable prompts based on natural language instructions. We use natural language to describe multi-scale geometric structure of the graph and then instruction finetune an LLM to perform graph tasks, which enables Generative Graph Learning. Our method surpasses all GNN baselines on ogbn-arxiv, Cora and PubMed datasets, underscoring its effectiveness and sheds light on generative LLMs as new foundation model for graph machine learning. Our code is available at https://github.com/agiresearch/InstructGLM.</abstract>
      <url hash="8ec9c9ff">2024.findings-eacl.132</url>
      <bibkey>ye-etal-2024-language</bibkey>
    </paper>
    <paper id="133">
      <title>Unraveling the Dynamics of Semi-Supervised Hate Speech Detection: The Impact of Unlabeled Data Characteristics and Pseudo-Labeling Strategies</title>
      <author><first>Florian</first><last>Ludwig</last><affiliation>Universität Duisburg-Essen</affiliation></author>
      <author><first>Klara</first><last>Dolos</last><affiliation>ZITiS</affiliation></author>
      <author><first>Ana</first><last>Alves-Pinto</last><affiliation>Central Office for Information Technology in the Security Sector</affiliation></author>
      <author><first>Torsten</first><last>Zesch</last><affiliation>Fernuniversität in Hagen</affiliation></author>
      <pages>1974-1986</pages>
      <abstract>Despite advances in machine learning based hate speech detection, the need for larges amounts of labeled training data for state-of-the-art approaches remains a challenge for their application. Semi-supervised learning addresses this problem by leveraging unlabeled data and thus reducing the amount of annotated data required. Underlying this approach is the assumption that labeled and unlabeled data follow similar distributions. This assumption however may not always hold, with consequences for real world applications. We address this problem by investigating the dynamics of pseudo-labeling, a commonly employed form of semi-supervised learning, in the context of hate speech detection. Concretely we analysed the influence of data characteristics and of two strategies for selecting pseudo-labeled samples: threshold- and ratio-based. The results show that the influence of data characteristics on the pseudo-labeling performances depends on other factors, such as pseudo-label selection strategies or model biases. Furthermore, the effectiveness of pseudo-labeling in classification performance is determined by the interaction between the number, hate ratio and accuracy of the selected pseudo-labels. Analysis of the results suggests an advantage of the threshold-based approach when labeled and unlabeled data arise from the same domain, whilst the ratio-based approach may be recommended in the opposite situation.</abstract>
      <url hash="e98ff5b9">2024.findings-eacl.133</url>
      <attachment type="software" hash="faa4add9">2024.findings-eacl.133.software.zip</attachment>
      <bibkey>ludwig-etal-2024-unraveling</bibkey>
    </paper>
    <paper id="134">
      <title>When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets</title>
      <author><first>Orion</first><last>Weller</last></author>
      <author><first>Kyle</first><last>Lo</last><affiliation>Allen Institute for Artificial Intelligence</affiliation></author>
      <author><first>David</first><last>Wadden</last><affiliation>Allen Institute for Artificial Intelligence</affiliation></author>
      <author><first>Dawn</first><last>Lawrie</last><affiliation>Johns Hopkins University</affiliation></author>
      <author><first>Benjamin</first><last>Van Durme</last><affiliation>Johns Hopkins University, Johns Hopkins University, Johns Hopkins University and Microsoft</affiliation></author>
      <author><first>Arman</first><last>Cohan</last><affiliation>Yale University and Allen Institute for Artificial Intelligence</affiliation></author>
      <author><first>Luca</first><last>Soldaini</last><affiliation>Allen Institute for Artificial Intelligence</affiliation></author>
      <pages>1987-2003</pages>
      <abstract>Using large language models (LMs) for query or document expansion can improve generalization in information retrieval. However, it is unknown whether these techniques are universally beneficial or only effective in specific settings, such as for particular retrieval models, dataset domains, or query types. To answer this, we conduct the first comprehensive analysis of LM-based expansion. We find that there exists a strong negative correlation between retriever performance and gains from expansion: expansion improves scores for weaker models, but generally harms stronger models. We show this trend holds across a set of eleven expansion techniques, twelve datasets with diverse distribution shifts, and twenty-four retrieval models. Through qualitative error analysis, we hypothesize that although expansions provide extra information (potentially improving recall), they add additional noise that makes it difficult to discern between the top relevant documents (thus introducing false positives). Our results suggest the following recipe: use expansions for weaker models or when the target dataset significantly differs from training corpus in format; otherwise, avoid expansions to keep the relevance signal clear.</abstract>
      <url hash="74f3c4d7">2024.findings-eacl.134</url>
      <bibkey>weller-etal-2024-generative</bibkey>
    </paper>
    <paper id="135">
      <title>Can Large Language Models Understand Context?</title>
      <author><first>Yilun</first><last>Zhu</last></author>
      <author><first>Joel</first><last>Moniz</last><affiliation>Apple</affiliation></author>
      <author><first>Shruti</first><last>Bhargava</last><affiliation>Apple</affiliation></author>
      <author><first>Jiarui</first><last>Lu</last><affiliation>Apple</affiliation></author>
      <author><first>Dhivya</first><last>Piraviperumal</last></author>
      <author><first>Site</first><last>Li</last></author>
      <author><first>Yuan</first><last>Zhang</last><affiliation>Apple</affiliation></author>
      <author><first>Hong</first><last>Yu</last><affiliation>Apple</affiliation></author>
      <author><first>Bo-Hsiang</first><last>Tseng</last></author>
      <pages>2004-2018</pages>
      <abstract>Understanding context is key to understanding human language, an ability which Large Language Models (LLMs) have been increasingly seen to demonstrate to an impressive extent. However, though the evaluation of LLMs encompasses various domains within the realm of Natural Language Processing, limited attention has been paid to probing their linguistic capability of understanding contextual features. This paper introduces a context understanding benchmark by adapting existing datasets to suit the evaluation of generative models. This benchmark comprises of four distinct tasks and nine datasets, all featuring prompts designed to assess the models’ ability to understand context. First, we evaluate the performance of LLMs under the in-context learning pretraining scenario. Experimental results indicate that pre-trained dense models struggle with understanding more nuanced contextual features when compared to state-of-the-art fine-tuned models. Second, as LLM compression holds growing significance in both research and real-world applications, we assess the context understanding of quantized models under in-context-learning settings. We find that 3-bit post-training quantization leads to varying degrees of performance reduction on our benchmark. We conduct an extensive analysis of these scenarios to substantiate our experimental results.</abstract>
      <url hash="400d0d77">2024.findings-eacl.135</url>
      <bibkey>zhu-etal-2024-large</bibkey>
    </paper>
    <paper id="136">
      <title>Let’s Negotiate! A Survey of Negotiation Dialogue Systems</title>
      <author><first>Haolan</first><last>Zhan</last><affiliation>Monash University</affiliation></author>
      <author><first>Yufei</first><last>Wang</last></author>
      <author><first>Zhuang</first><last>Li</last><affiliation>Monash University</affiliation></author>
      <author><first>Tao</first><last>Feng</last><affiliation>Monash University</affiliation></author>
      <author><first>Yuncheng</first><last>Hua</last></author>
      <author><first>Suraj</first><last>Sharma</last></author>
      <author><first>Lizhen</first><last>Qu</last><affiliation>Monash University</affiliation></author>
      <author><first>Zhaleh</first><last>Semnani Azad</last><affiliation>California State University, Northridge</affiliation></author>
      <author><first>Ingrid</first><last>Zukerman</last><affiliation>Monash University</affiliation></author>
      <author><first>Reza</first><last>Haf</last><affiliation>Monash University</affiliation></author>
      <pages>2019-2031</pages>
      <abstract>Negotiation is a crucial ability in human communication. Recently, there has been a resurgent research interest in negotiation dialogue systems, whose goal is to create intelligent agents that can assist people in resolving conflicts or reaching agreements. Although there have been many explorations into negotiation dialogue systems, a systematic review of this task has not been performed to date. We aim to fill this gap by investigating recent studies in the field of negotiation dialogue systems, and covering benchmarks, evaluations and methodologies within the literature. We also discuss potential future directions, including multi-modal, multi-party and cross-cultural negotiation scenarios. Our goal is to provide the community with a systematic overview of negotiation dialogue systems and to inspire future research.</abstract>
      <url hash="5722240a">2024.findings-eacl.136</url>
      <bibkey>zhan-etal-2024-lets</bibkey>
    </paper>
    <paper id="137">
      <title>Towards Understanding Counseling Conversations: Domain Knowledge and Large Language Models</title>
      <author><first>Younghun</first><last>Lee</last></author>
      <author><first>Dan</first><last>Goldwasser</last><affiliation>Purdue University</affiliation></author>
      <author><first>Laura Schwab</first><last>Reese</last><affiliation>Purdue University</affiliation></author>
      <pages>2032-2047</pages>
      <abstract>Understanding the dynamics of counseling conversations is an important task, yet it is a challenging NLP problem regardless of the recent advance of Transformer-based pre-trained language models. This paper proposes a systematic approach to examine the efficacy of domain knowledge and large language models (LLMs) in better representing conversations between a crisis counselor and a help seeker. We empirically show that state-of-the-art language models such as Transformer-based models and GPT models fail to predict the conversation outcome. To provide richer context to conversations, we incorporate human-annotated domain knowledge and LLM-generated features; simple integration of domain knowledge and LLM features improves the model performance by approximately 15%. We argue that both domain knowledge and LLM-generated features can be exploited to better characterize counseling conversations when they are used as an additional context to conversations.</abstract>
      <url hash="000711a7">2024.findings-eacl.137</url>
      <attachment type="software" hash="62e740c5">2024.findings-eacl.137.software.zip</attachment>
      <bibkey>lee-etal-2024-towards</bibkey>
    </paper>
    <paper id="138">
      <title>Better Explain Transformers by Illuminating Important Information</title>
      <author><first>Linxin</first><last>Song</last></author>
      <author><first>Yan</first><last>Cui</last></author>
      <author><first>Ao</first><last>Luo</last></author>
      <author><first>Freddy</first><last>Lecue</last><affiliation>INRIA</affiliation></author>
      <author><first>Irene</first><last>Li</last></author>
      <pages>2048-2062</pages>
      <abstract>Transformer-based models excel in various natural language processing (NLP) tasks, attracting countless efforts to explain their inner workings. Prior methods explain Transformers by focusing on the raw gradient and attention as token attribution scores, where non-relevant information is often considered during explanation computation, resulting in confusing results. In this work, we propose highlighting the important information and eliminating irrelevant information by a refined information flow on top of the layer-wise relevance propagation (LRP) method. Specifically, we consider identifying syntactic and positional heads as important attention heads and focus on the relevance obtained from these important heads. Experimental results demonstrate that irrelevant information does distort output attribution scores and then should be masked during explanation computation. Compared to eight baselines on both classification and question-answering datasets, our method consistently outperforms with over 3% to 33% improvement on explanation metrics, providing superior explanation performance. Our anonymous code repository is available at: https://anonymous.4open.science/r/MLRP-E676/</abstract>
      <url hash="ffb0def1">2024.findings-eacl.138</url>
      <bibkey>song-etal-2024-better</bibkey>
    </paper>
    <paper id="139">
      <title>Testing the Depth of <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case>’s Comprehension via Cross-Modal Tasks Based on <fixed-case>ASCII</fixed-case>-Art: <fixed-case>GPT</fixed-case>3.5’s Abilities in Regard to Recognizing and Generating <fixed-case>ASCII</fixed-case>-Art Are Not Totally Lacking</title>
      <author><first>David</first><last>Bayani</last><affiliation>Inpleo, Inc.</affiliation></author>
      <pages>2063-2077</pages>
      <abstract>In the months since its release, ChatGPT and its underlying model, GPT3.5, have garnered massive attention, due to their potent mix of capability and accessibility. While a niche industry of papers have emerged examining the scope of capabilities these models possess, language — whether natural or stylized like code — has been the vehicle to exchange information with the network. Drawing inspiration from the multi-modal knowledge we’d expect an agent with true understanding to possess, we examine GPT3.5’s aptitude for visual tasks, where the inputs feature ASCII-art without overt distillation into a lingual summary. In particular, we scrutinize its performance on carefully designed image recognition and generation tasks. An extended version of this write-up is available at: https://arxiv.org/abs/2307.16806 .</abstract>
      <url hash="f92e7ca9">2024.findings-eacl.139</url>
      <bibkey>bayani-2024-testing</bibkey>
    </paper>
    <paper id="140">
      <title>Cross-lingual Editing in Multilingual Language Models</title>
      <author><first>Himanshu</first><last>Beniwal</last><affiliation>Indian Institute of Technology Gandhinagar</affiliation></author>
      <author><first>Kowsik</first><last>D</last></author>
      <author><first>Mayank</first><last>Singh</last><affiliation>Indian Institute of Technology Gandhinagar</affiliation></author>
      <pages>2078-2128</pages>
      <abstract>The training of large language models (LLMs) necessitates substantial data and computational resources, and updating outdated LLMs entails significant efforts and resources. While numerous model editing techniques (METs) have emerged to efficiently update model outputs without retraining, their effectiveness in multilingual LLMs, where knowledge is stored in diverse languages, remains an underexplored research area. This research paper introduces the cross-lingual model editing (XME) paradigm, wherein a fact is edited in one language, and the subsequent update propagation is observed across other languages. To investigate the XME paradigm, we conducted experiments using BLOOM, mBERT, and XLM-RoBERTa using the two writing scripts: Latin (English, French, and Spanish) and Indic (Hindi, Gujarati, and Bengali). The results reveal notable performance limitations of state-of-the-art METs under the XME setting, mainly when the languages involved belong to two distinct script families. These findings highlight the need for further research and development of XME techniques to address these challenges. For more comprehensive information, the dataset used in this research and the associated code are publicly available at the following [URL](https://github.com/lingo-iitgn/XME).</abstract>
      <url hash="4343bb32">2024.findings-eacl.140</url>
      <bibkey>beniwal-etal-2024-cross</bibkey>
    </paper>
    <paper id="141">
      <title>Sorted <fixed-case>LL</fixed-case>a<fixed-case>MA</fixed-case>: Unlocking the Potential of Intermediate Layers of Large Language Models for Dynamic Inference</title>
      <author><first>Parsa</first><last>Kavehzadeh</last><affiliation>Huawei Technologies Ltd.</affiliation></author>
      <author><first>Mojtaba</first><last>Valipour</last></author>
      <author><first>Marzieh</first><last>Tahaei</last></author>
      <author><first>Ali</first><last>Ghodsi</last></author>
      <author><first>Boxing</first><last>Chen</last><affiliation>Huawei Technologies Ltd.</affiliation></author>
      <author><first>Mehdi</first><last>Rezagholizadeh</last></author>
      <pages>2129-2145</pages>
      <abstract>Large language models (LLMs) have revolutionized natural language processing (NLP) by excelling at understanding and generating human-like text. However, their widespread deployment can be prohibitively expensive. SortedNet is a recent training technique for enabling dynamic inference by leveraging the modularity in networks and sorting sub-models based on computation/accuracy in a nested manner. We extend SortedNet to generative NLP tasks, making large language models dynamic without any Pre-Training and by only replacing Standard Fine-Tuning (SFT) with Sorted Fine-Tuning (SoFT). Our approach boosts model efficiency, eliminating the need for multiple models for various scenarios during inference. We show that this approach can unlock the potential of intermediate layers of transformers in generating the target output. Our sub-models remain integral components of the original model, minimizing storage requirements and transition costs between different computational/latency budgets. The efficacy of our proposed method was demonstrated by applying it to tune LLaMA 2 13B on the Stanford Alpaca dataset for instruction following and TriviaQA for closed-book question answering. Our results show the superior performance of sub-models in comparison to Standard Fine-Tuning and SFT+ICT (Early-Exit), all achieved with very efficient tuning and without additional memory usage during inference.</abstract>
      <url hash="7cadd98a">2024.findings-eacl.141</url>
      <bibkey>kavehzadeh-etal-2024-sorted</bibkey>
    </paper>
    <paper id="142">
      <title><fixed-case>A</fixed-case>ccent<fixed-case>F</fixed-case>old: A Journey through <fixed-case>A</fixed-case>frican Accents for Zero-Shot <fixed-case>ASR</fixed-case> Adaptation to Target Accents</title>
      <author><first>Abraham</first><last>Owodunni</last><affiliation>Masakhane</affiliation></author>
      <author><first>Aditya</first><last>Yadavalli</last><affiliation>Karya Inc</affiliation></author>
      <author><first>Chris</first><last>Emezue</last></author>
      <author><first>Tobi</first><last>Olatunji</last></author>
      <author><first>Clinton</first><last>Mbataku</last></author>
      <pages>2146-2161</pages>
      <abstract>Despite advancements in speech recognition, accented speech remains challenging. While previous approaches have focused on modeling techniques or creating accented speech datasets, gathering sufficient data for the multitude of accents, particularly in the African context, remains impractical due to their sheer diversity and associated budget constraints. To address these challenges, we propose AccentFold, a method that exploits spatial relationships between learned accent embeddings to improve downstream Automatic Speech Recognition (ASR). Our exploratory analysis of speech embeddings representing 100+ African accents reveals interesting spatial accent relationships highlighting geographic and genealogical similarities, capturing consistent phonological, and morphological regularities, all learned empirically from speech. Furthermore, we discover accent relationships previously uncharacterized by the Ethnologue. Through empirical evaluation, we demonstrate the effectiveness of AccentFold by showing that, for out-of-distribution (OOD) accents, sampling accent subsets for training based on AccentFold information outperforms strong baselines a relative WER improvement of 4.6%. AccentFold presents a promising approach for improving ASR performance on accented speech, particularly in the context of African accents, where data scarcity and budget constraints pose significant challenges. Our findings emphasize the potential of leveraging linguistic relationships to improve zero-shot ASR adaptation to target accents.</abstract>
      <url hash="057ef8c0">2024.findings-eacl.142</url>
      <bibkey>owodunni-etal-2024-accentfold</bibkey>
    </paper>
    <paper id="143">
      <title>Hierarchical and Dynamic Prompt Compression for Efficient Zero-shot <fixed-case>API</fixed-case> Usage</title>
      <author><first>Yichen</first><last>Jiang</last></author>
      <author><first>Marco</first><last>Vecchio</last></author>
      <author><first>Mohit</first><last>Bansal</last><affiliation>University of North Carolina at Chapel Hill</affiliation></author>
      <author><first>Anders</first><last>Johannsen</last></author>
      <pages>2162-2174</pages>
      <abstract>Long prompts present a significant challenge for practical LLM-based systems that need to operate with low latency and limited resources. We investigate prompt compression for zero-shot dialogue systems that learn to use unseen APIs directly in-context from their documentation, which may take up hundreds of prompt tokens per API. We start from a recently introduced approach (Mu et al., 2023) that learns to compress the prompt into a few “gist token” activations during finetuning. However, this simple idea is ineffective in compressing API documentation, resulting in low accuracy compared to the baseline using an uncompressed prompt. In this work, we introduce two major improvements. First, we specialize gist tokens for different hierarchies within an API: we use one <tex-math>\mathrm{Gist}_{\mathrm{arg}}</tex-math> token for compressing an argument and one <tex-math>\mathrm{Gist}_{\mathrm{value}}</tex-math> token for compressing an acceptable value of a categorical argument. We then dynamically reveal <tex-math>\mathrm{Gist}_{\mathrm{value}}</tex-math> tokens only when they are needed. Second, we add a reconstruction loss to predict the API documentation from the gist tokens. On multiple API-calling tasks, our proposed system keeps the simplicity, efficiency, and large compression factor (20x on SGD) of the gist token approach while achieving significantly better accuracy.</abstract>
      <url hash="8c1adec3">2024.findings-eacl.143</url>
      <bibkey>jiang-etal-2024-hierarchical</bibkey>
    </paper>
    <paper id="144">
      <title>Fine-tuning <fixed-case>CLIP</fixed-case> Text Encoders with Two-step Paraphrasing</title>
      <author><first>Hyunjae</first><last>Kim</last><affiliation>Korea University</affiliation></author>
      <author><first>Seunghyun</first><last>Yoon</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Trung</first><last>Bui</last><affiliation>Adobe Research</affiliation></author>
      <author><first>Handong</first><last>Zhao</last><affiliation>Adobe Systems</affiliation></author>
      <author><first>Quan</first><last>Tran</last><affiliation>servicenow</affiliation></author>
      <author><first>Franck</first><last>Dernoncourt</last><affiliation>Adobe Systems</affiliation></author>
      <author><first>Jaewoo</first><last>Kang</last><affiliation>Korea University</affiliation></author>
      <pages>2175-2184</pages>
      <abstract>Contrastive language-image pre-training (CLIP) models have demonstrated considerable success across various vision-language tasks, such as text-to-image retrieval, where the model is required to effectively process natural language input to produce an accurate visual output. However, current models still face limitations in dealing with linguistic variations in input queries, such as paraphrases, making it challenging to handle a broad range of user queries in real-world applications. In this study, we introduce a straightforward fine-tuning approach to enhance the representations of CLIP models for paraphrases. Our approach involves a two-step paraphrase generation process, where we automatically create two categories of paraphrases from web-scale image captions by leveraging large language models. Subsequently, we fine-tune the CLIP text encoder using these generated paraphrases while freezing the image encoder. Our resulting model, which we call ParaCLIP, exhibits significant improvements over baseline CLIP models across various tasks, including paraphrased retrieval (with rank similarity scores improved by up to 7.6% and 9.6%), Visual Genome Relation and Attribution, as well as seven semantic textual similarity tasks.</abstract>
      <url hash="25c91d2e">2024.findings-eacl.144</url>
      <bibkey>kim-etal-2024-fine</bibkey>
    </paper>
    <paper id="145">
      <title>Generative Interpretation: Toward Human-Like Evaluation for Educational Question-Answer Pair Generation</title>
      <author><first>Hyeonseok</first><last>Moon</last><affiliation>Korea University</affiliation></author>
      <author><first>Jaewook</first><last>Lee</last><affiliation>Korea University</affiliation></author>
      <author><first>Sugyeong</first><last>Eo</last><affiliation>Korea University</affiliation></author>
      <author><first>Chanjun</first><last>Park</last><affiliation>Upstage</affiliation></author>
      <author><first>Jaehyung</first><last>Seo</last></author>
      <author><first>Heuiseok</first><last>Lim</last><affiliation>Korea University</affiliation></author>
      <pages>2185-2196</pages>
      <abstract>Educational question-answer generation has been extensively researched owing to its practical applicability. However, we have identified a persistent challenge concerning the evaluation of such systems. Existing evaluation methods often fail to produce objective results and instead exhibit a bias towards favoring high similarity to the ground-truth question-answer pairs. In this study, we demonstrate that these evaluation methods yield low human alignment and propose an alternative approach called Generative Interpretation (GI) to achieve more objective evaluations. Through experimental analysis, we reveal that GI outperforms existing evaluation methods in terms of human alignment, and even shows comparable performance with GPT3.5, only with BART-large.</abstract>
      <url hash="7a40f6e9">2024.findings-eacl.145</url>
      <attachment type="software" hash="0e3e8735">2024.findings-eacl.145.software.zip</attachment>
      <bibkey>moon-etal-2024-generative</bibkey>
    </paper>
    <paper id="146">
      <title>Dive into the Chasm: Probing the Gap between In- and Cross-Topic Generalization</title>
      <author><first>Andreas</first><last>Waldis</last><affiliation>Technische Universität Darmstadt and Lucerne University of Applied Sciences and Arts</affiliation></author>
      <author><first>Yufang</first><last>Hou</last></author>
      <author><first>Iryna</first><last>Gurevych</last><affiliation>Mohamed bin Zayed University of Artificial Intelligence and Technical University of Darmstadt</affiliation></author>
      <pages>2197-2214</pages>
      <abstract>Pre-trained language models (PLMs) perform well in In-Topic setups, where training and testing data come from the same topics. However, they face challenges in Cross-Topic scenarios where testing data is derived from distinct topics. This paper analyzes various PLMs with three probing-based experiments to better understand the reasons behind such generalization gaps. For the first time, we demonstrate that the extent of these generalization gaps and the sensitivity to token-level interventions vary significantly across PLMs. By evaluating large language models (LLMs), we show the usefulness of our analysis for these recent models. Overall, we observe diverse pre-training objectives and architectural regularization contribute to more robust PLMs and mitigate generalization gaps. Our research contributes to a deeper understanding and comparison of language models across different generalization scenarios.</abstract>
      <url hash="a4646e90">2024.findings-eacl.146</url>
      <bibkey>waldis-etal-2024-dive</bibkey>
    </paper>
    <paper id="147">
      <title><fixed-case>LLM</fixed-case>-<fixed-case>GE</fixed-case>m: Large Language Model-Guided Prediction of People’s Empathy Levels towards Newspaper Article</title>
      <author><first>Md Rakibul</first><last>Hasan</last><affiliation>Curtin University of Technology and BRAC University, Bangladesh</affiliation></author>
      <author><first>Md Zakir</first><last>Hossain</last><affiliation>CSIRO and Australian National University</affiliation></author>
      <author><first>Tom</first><last>Gedeon</last></author>
      <author><first>Shafin</first><last>Rahman</last><affiliation>North South University</affiliation></author>
      <pages>2215-2231</pages>
      <abstract>Empathy – encompassing the understanding and supporting others’ emotions and perspectives – strengthens various social interactions, including written communication in healthcare, education and journalism. Detecting empathy using AI models by relying on self-assessed ground truth through crowdsourcing is challenging due to the inherent noise in such annotations. To this end, we propose a novel system, named Large Language Model-Guided Empathy _(LLM-GEm)_ prediction system. It rectifies annotation errors based on our defined annotation selection threshold and makes the annotations reliable for conventional empathy prediction models, e.g., BERT-based pre-trained language models (PLMs). Previously, demographic information was often integrated numerically into empathy detection models. In contrast, our _LLM-GEm_ leverages GPT-3.5 LLM to convert numerical data into semantically meaningful textual sequences, enabling seamless integration into PLMs. We experiment with three _NewsEmpathy_ datasets involving people’s empathy levels towards newspaper articles and achieve state-of-the-art test performance using a RoBERTa-based PLM. Code and evaluations are publicly available at [https://github.com/hasan-rakibul/LLM-GEm](https://github.com/hasan-rakibul/LLM-GEm).</abstract>
      <url hash="d405c649">2024.findings-eacl.147</url>
      <attachment type="software" hash="b41c778e">2024.findings-eacl.147.software.zip</attachment>
      <attachment type="note" hash="291dcb66">2024.findings-eacl.147.note.zip</attachment>
      <bibkey>hasan-etal-2024-llm</bibkey>
    </paper>
    <paper id="148">
      <title><fixed-case>ICE</fixed-case>-Score: Instructing Large Language Models to Evaluate Code</title>
      <author><first>Terry Yue</first><last>Zhuo</last></author>
      <pages>2232-2242</pages>
      <abstract>Recent advancements in the field of natural language generation have facilitated the use of large language models to assess the quality of generated text. Although these models have shown promising results in tasks such as machine translation and summarization, their applicability in code intelligence tasks remains limited without human involvement. The complexity of programming concepts required for such tasks makes it difficult to develop evaluation metrics that align with human judgment. Token-matching-based metrics, such as BLEU, have demonstrated weak correlations with human practitioners in code intelligence tasks. Moreover, utilizing human-written test suites to evaluate functional correctness can be challenging in domains with low resources. To overcome these obstacles, we propose ICE-Score, a new evaluation metric via instructing large language models (LLMs) for code assessments. Our metric addresses the limitations of existing approaches by achieving superior correlations with functional correctness and human preferences, without the need for test oracles or references. We evaluate the efficacy of our metric on two different aspects (<i>human preference</i> and <i>execution success</i>) and four programming languages. Our results demonstrate that our metric surpasses state-of-the-art metrics for code generation, delivering high levels of accuracy and consistency across various programming languages and tasks. We also make our evaluation metric and datasets available to the public, encouraging further research in evaluating code intelligence tasks.</abstract>
      <url hash="f121a28a">2024.findings-eacl.148</url>
      <bibkey>zhuo-2024-ice</bibkey>
    </paper>
    <paper id="149">
      <title><fixed-case>CR</fixed-case>e<fixed-case>SE</fixed-case>: Benchmark Data and Automatic Evaluation Framework for Recommending Eligibility Criteria from Clinical Trial Information</title>
      <author><first>Siun</first><last>Kim</last></author>
      <author><first>Jung-Hyun</first><last>Won</last><affiliation>Seoul National University</affiliation></author>
      <author><first>David</first><last>Lee</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Renqian</first><last>Luo</last><affiliation>Microsoft</affiliation></author>
      <author><first>Lijun</first><last>Wu</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Tao</first><last>Qin</last></author>
      <author><first>Howard</first><last>Lee</last><affiliation>Seoul National University</affiliation></author>
      <pages>2243-2273</pages>
      <abstract>Eligibility criteria (EC) refer to a set of conditions an individual must meet to participate in a clinical trial, defining the study population and minimizing potential risks to patients. Previous research in clinical trial design has been primarily focused on searching for similar trials and generating EC within manual instructions, employing similarity-based performance metrics, which may not fully reflect human judgment. In this study, we propose a novel task of recommending EC based on clinical trial information, including trial titles, and introduce an automatic evaluation framework to assess the clinical validity of the EC recommendation model. Our new approach, known as CReSE (Contrastive learning and Rephrasing-based and Clinical Relevance-preserving Sentence Embedding), represents EC through contrastive learning and rephrasing via large language models (LLMs). The CReSE model outperforms existing language models pre-trained on the biomedical domain in EC clustering. Additionally, we have curated a benchmark dataset comprising 3.2M high-quality EC-title pairs extracted from 270K clinical trials available on ClinicalTrials.gov. The EC recommendation models achieve commendable performance metrics, with 49.0% precision@1 and 44.2% MAP@5 on our evaluation framework. We expect that our evaluation framework built on the CReSE model will contribute significantly to the development and assessment of the EC recommendation models in terms of clinical validity.</abstract>
      <url hash="9b808224">2024.findings-eacl.149</url>
      <attachment type="note" hash="a01f614e">2024.findings-eacl.149.note.zip</attachment>
      <bibkey>kim-etal-2024-crese</bibkey>
    </paper>
    <paper id="150">
      <title><fixed-case>BMX</fixed-case>: Boosting Natural Language Generation Metrics with Explainability</title>
      <author><first>Christoph</first><last>Leiter</last><affiliation>Universität Mannheim</affiliation></author>
      <author><first>Hoa</first><last>Nguyen</last></author>
      <author><first>Steffen</first><last>Eger</last><affiliation>Universität Bielefeld</affiliation></author>
      <pages>2274-2288</pages>
      <abstract>State-of-the-art natural language generation evaluation metrics are based on black-box language models. Hence, recent works consider their explainability with the goals of better understandability for humans and better metric analysis, including failure cases. In contrast, we explicitly leverage explanations to boost the metrics’ performance. In particular, we perceive feature importance explanations as word-level scores, which we convert, via power means, into a segment-level score. We then combine this segment-level score with the original metric to obtain a better metric. Our tests show improvements for multiple metrics across MT and summarization datasets. While improvements on machine translation are small, they are strong for summarization. Notably, BMX with the LIME explainer and preselected parameters achieves an average improvement of 0.087 points in Spearman correlation on the system-level evaluation of SummEval.</abstract>
      <url hash="98e48521">2024.findings-eacl.150</url>
      <attachment type="software" hash="bb92b528">2024.findings-eacl.150.software.zip</attachment>
      <attachment type="note" hash="8c28b8db">2024.findings-eacl.150.note.zip</attachment>
      <bibkey>leiter-etal-2024-bmx</bibkey>
    </paper>
    <paper id="151">
      <title>Joint Inference of Retrieval and Generation for Passage Re-ranking</title>
      <author><first>Wei</first><last>Fang</last><affiliation>Massachusetts Institute of Technology</affiliation></author>
      <author><first>Yung-Sung</first><last>Chuang</last><affiliation>Massachusetts Institute of Technology</affiliation></author>
      <author><first>James</first><last>Glass</last></author>
      <pages>2289-2298</pages>
      <abstract>Passage retrieval is a crucial component of modern open-domain question answering (QA) systems, providing information for downstream QA components to generate accurate and transparent answers. In this study we focus on passage re-ranking, proposing a simple yet effective method, Joint Passage Re-ranking (JPR), that optimizes the mutual information between query and passage distributions, integrating both cross-encoders and generative models in the re-ranking process. Experimental results demonstrate that JPR outperforms conventional re-rankers and language model scorers in both open-domain QA retrieval settings and diverse retrieval benchmarks under zero-shot settings.</abstract>
      <url hash="b861c24e">2024.findings-eacl.151</url>
      <attachment type="software" hash="45613d80">2024.findings-eacl.151.software.zip</attachment>
      <bibkey>fang-etal-2024-joint</bibkey>
    </paper>
    <paper id="152">
      <title><fixed-case>D</fixed-case>ialog<fixed-case>S</fixed-case>tudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational <fixed-case>AI</fixed-case></title>
      <author><first>Jianguo</first><last>Zhang</last><affiliation>SalesForce AI Research</affiliation></author>
      <author><first>Kun</first><last>Qian</last></author>
      <author><first>Zhiwei</first><last>Liu</last><affiliation>SalesForce.com</affiliation></author>
      <author><first>Shelby</first><last>Heinecke</last><affiliation>Salesforce Research</affiliation></author>
      <author><first>Rui</first><last>Meng</last><affiliation>SalesForce Research</affiliation></author>
      <author><first>Ye</first><last>Liu</last><affiliation>SalesForce.com</affiliation></author>
      <author><first>Zhou</first><last>Yu</last><affiliation>Columbia University</affiliation></author>
      <author><first>Huan</first><last>Wang</last></author>
      <author><first>Silvio</first><last>Savarese</last><affiliation>Salesforce and Stanford University</affiliation></author>
      <author><first>Caiming</first><last>Xiong</last><affiliation>Salesforce Research</affiliation></author>
      <pages>2299-2315</pages>
      <abstract>Despite advancements in conversational AI, language models encounter challenges to handle diverse conversational tasks, and existing dialogue dataset collections often lack diversity and comprehensiveness. To tackle these issues, we introduce DialogStudio: the largest and most diverse collection of dialogue datasets, unified under a consistent format while preserving their original information. Our collection encompasses data from open-domain dialogues, task-oriented dialogues, natural language understanding, conversational recommendation, dialogue summarization, and knowledge-grounded dialogues, making it an incredibly rich and diverse resource for dialogue research and model training.To further enhance the utility of DialogStudio, we identify the licenses for each dataset, design external knowledge and domain-aware prompts for selected dialogues to facilitate instruction-aware fine-tuning. To improve transparency and support dataset and task-based research, as well as language model pre-training, all datasets, licenses, codes, and models associated with DialogStudio will be made publicly accessible.</abstract>
      <url hash="152de025">2024.findings-eacl.152</url>
      <attachment type="note" hash="81f074a6">2024.findings-eacl.152.note.zip</attachment>
      <bibkey>zhang-etal-2024-dialogstudio</bibkey>
    </paper>
    <paper id="153">
      <title>Exploring hybrid approaches to readability: experiments on the complementarity between linguistic features and transformers</title>
      <author><first>Rodrigo</first><last>Wilkens</last><affiliation>UCL</affiliation></author>
      <author><first>Patrick</first><last>Watrin</last><affiliation>UCL</affiliation></author>
      <author><first>Rémi</first><last>Cardon</last><affiliation>Cental, ILC - UCLouvain</affiliation></author>
      <author><first>Alice</first><last>Pintard</last></author>
      <author><first>Isabelle</first><last>Gribomont</last><affiliation>UCLouvain</affiliation></author>
      <author><first>Thomas</first><last>François</last><affiliation>UCL</affiliation></author>
      <pages>2316-2331</pages>
      <abstract>Linguistic features have a strong contribution in the context of the automatic assessment of text readability (ARA). They have been one of the anchors between the computational and theoretical models. With the development in the ARA field, the research moved to Deep Learning (DL). In an attempt to reconcile the mixed results reported in this context, we present a systematic comparison of 6 hybrid approaches along with standard Machine Learning and DL approaches, on 4 corpora (different languages and target audiences). The various experiments clearly highlighted two rather simple hybridization methods (soft label and simple concatenation). They also appear to be the most robust on smaller datasets and across various tasks and languages. This study stands out as the first to systematically compare different architectures and approaches to feature hybridization in DL, as well as comparing performance in terms of two languages and two target audiences of the text, which leads to a clearer pattern of results.</abstract>
      <url hash="4f4857c4">2024.findings-eacl.153</url>
      <bibkey>wilkens-etal-2024-exploring</bibkey>
    </paper>
    <paper id="154">
      <title>Establishing degrees of closeness between audio recordings along different dimensions using large-scale cross-lingual models</title>
      <author><first>Maxime</first><last>Fily</last></author>
      <author><first>Guillaume</first><last>Wisniewski</last><affiliation>LLF / Université Paris Cité</affiliation></author>
      <author><first>Severine</first><last>Guillaume</last><affiliation>CNRS</affiliation></author>
      <author><first>Gilles</first><last>Adda</last><affiliation>CNRS</affiliation></author>
      <author><first>Alexis</first><last>Michaud</last><affiliation>CNRS</affiliation></author>
      <pages>2332-2341</pages>
      <abstract>In the highly constrained context of low-resource language studies, we explore vector representations of speech from a pretrained model to determine their level of abstraction with regard to the audio signal. We propose a new unsupervised method using ABX tests on audio recordings with carefully curated metadata to shed light on the type of information present in the representations. ABX tests determine whether the representations computed by a multilingual speech model encode a given characteristic. Three experiments are devised: one on room acoustics aspects, one on linguistic genre, and one on phonetic aspects. The results confirm that the representations extracted from recordings with different linguistic/extra-linguistic characteristics differ along the same lines. Embedding more audio signal in one vector better discriminates extra-linguistic characteristics, whereas shorter snippets are better to distinguish segmental information. The method is fully unsupervised, potentially opening new research avenues for comparative work on under-documented languages.</abstract>
      <url hash="be4bc756">2024.findings-eacl.154</url>
      <bibkey>fily-etal-2024-establishing</bibkey>
    </paper>
    <paper id="155">
      <title>The Queen of <fixed-case>E</fixed-case>ngland is not <fixed-case>E</fixed-case>ngland’s Queen: On the Lack of Factual Coherency in <fixed-case>PLM</fixed-case>s</title>
      <author><first>Paul</first><last>Youssef</last><affiliation>Phillips-Universität Marburg</affiliation></author>
      <author><first>Jörg</first><last>Schlötterer</last><affiliation>Universität Mannheim and Phillips-Universität Marburg</affiliation></author>
      <author><first>Christin</first><last>Seifert</last><affiliation>Phillips-Universität Marburg and University of Twente</affiliation></author>
      <pages>2342-2354</pages>
      <abstract>Factual knowledge encoded in Pre-trained Language Models (PLMs) enriches their representations and justifies their use as knowledge bases. Previous work has focused on probing PLMs for factual knowledge by measuring how often they can correctly predict an _object_ entity given a subject and a relation, and improving fact retrieval by optimizing the prompts used for querying PLMs. In this work, we consider a complementary aspect, namely the coherency of factual knowledge in PLMs, i.e., how often can PLMs predict the _subject_ entity given its initial prediction of the object entity. This goes beyond evaluating how much PLMs know, and focuses on the internal state of knowledge inside them. Our results indicate that PLMs have low coherency using manually written, optimized and paraphrased prompts, but including an evidence paragraph leads to substantial improvement. This shows that PLMs fail to model inverse relations and need further enhancements to be able to handle retrieving facts from their parameters in a coherent manner, and to be considered as knowledge bases.</abstract>
      <url hash="5a44cdb4">2024.findings-eacl.155</url>
      <bibkey>youssef-etal-2024-queen</bibkey>
    </paper>
    <paper id="156">
      <title><fixed-case>H</fixed-case>ierarchy<fixed-case>N</fixed-case>et: Learning to Summarize Source Code with Heterogeneous Representations</title>
      <author><first>Minh</first><last>Nguyen</last><affiliation>FPT Software AI Center</affiliation></author>
      <author><first>Nghi</first><last>Bui</last></author>
      <author><first>Truong Son</first><last>Hy</last><affiliation>Indiana State University</affiliation></author>
      <author><first>Long</first><last>Tran-Thanh</last><affiliation>The university of Warwick</affiliation></author>
      <author><first>Tien</first><last>Nguyen</last><affiliation>university of texas at dallas</affiliation></author>
      <pages>2355-2367</pages>
      <abstract>Code representation is important to machine learning models in the code-related applications. Existing code summarization approaches primarily leverage Abstract Syntax Trees (ASTs) and sequential information from source code to generate code summaries while often overlooking the critical consideration of the interplay of dependencies among code elements and code hierarchy. However, effective summarization necessitates a holistic analysis of code snippets from three distinct aspects: lexical, syntactic, and semantic information. In this paper, we propose a novel code summarization approach utilizing Heterogeneous Code Representations (HCRs) and our specially designed HierarchyNet. HCRs adeptly capture essential code features at lexical, syntactic, and semantic levels within a hierarchical structure. HierarchyNet processes each layer of the HCR separately, employing a Heterogeneous Graph Transformer, a Tree-based CNN, and a Transformer Encoder. In addition, HierarchyNet demonstrates superior performance compared to fine-tuned pre-trained models, including CodeT5, and CodeBERT, as well as large language models that employ zero/few-shot settings, such as CodeLlama, StarCoder, and CodeGen. Implementation details can be found at https://github.com/FSoft-AI4Code/HierarchyNet.</abstract>
      <url hash="3eef3fbe">2024.findings-eacl.156</url>
      <bibkey>nguyen-etal-2024-hierarchynet</bibkey>
    </paper>
    <paper id="157">
      <title>Understanding the effects of language-specific class imbalance in multilingual fine-tuning</title>
      <author><first>Vincent</first><last>Jung</last><affiliation>Idiap Research Institute</affiliation></author>
      <author><first>Lonneke</first><last>Plas</last><affiliation>Idiap Research Institute</affiliation></author>
      <pages>2368-2376</pages>
      <abstract>We study the effect of one type of imbalance often present in real-life multilingual classification datasets: an uneven distribution of labels across languages. We show evidence that fine-tuning a transformer-based Large Language Model (LLM) on a dataset with this imbalance leads to worse performance, a more pronounced separation of languages in the latent space, and the promotion of uninformative features. We modify the traditional class weighing approach to imbalance by calculating class weights separately for each language and show that this helps mitigate those detrimental effects. These results create awareness of the negative effects of language-specific class imbalance in multilingual fine-tuning and the way in which the model learns to rely on the separation of languages to perform the task.</abstract>
      <url hash="a17b7cc2">2024.findings-eacl.157</url>
      <bibkey>jung-plas-2024-understanding</bibkey>
    </paper>
    <paper id="158">
      <title><fixed-case>NL</fixed-case>2<fixed-case>F</fixed-case>ormula: Generating Spreadsheet Formulas from Natural Language Queries</title>
      <author><first>Wei</first><last>Zhao</last><affiliation>Huazhong University of Science and Technology</affiliation></author>
      <author><first>Zhitao</first><last>Hou</last></author>
      <author><first>Siyuan</first><last>Wu</last></author>
      <author><first>Yan</first><last>Gao</last></author>
      <author><first>Haoyu</first><last>Dong</last></author>
      <author><first>Yao</first><last>Wan</last><affiliation>Huazhong University of Science and Technology</affiliation></author>
      <author><first>Hongyu</first><last>Zhang</last><affiliation>University of Newcastle, Australia</affiliation></author>
      <author><first>Yulei</first><last>Sui</last><affiliation>University of New South Wales</affiliation></author>
      <author><first>Haidong</first><last>Zhang</last><affiliation>Microsoft Research Asia</affiliation></author>
      <pages>2377-2388</pages>
      <abstract>Writing formulas on spreadsheets, such as Microsoft Excel and Google Sheets, is a widespread practice among users performing data analysis. However, crafting formulas on spreadsheets remains a tedious and error-prone task for many end-users, particularly when dealing with complex operations. To alleviate the burden associated with writing spreadsheet formulas, this paper introduces a novel benchmark task called NL2Formula, with the aim to generate executable formulas that are grounded on a spreadsheet table, given a Natural Language (NL) query as input. To accomplish this, we construct a comprehensive dataset consisting of 70,799 paired NL queries and corresponding spreadsheet formulas, covering 21,670 tables and 37 types of formula functions. We realize the NL2Formula task by providing a sequence-to-sequence baseline implementation called fCoder. Experimental results validate the effectiveness of fCoder, demonstrating its superior performance compared to the baseline models. Furthermore, we also compare fCoder with an initial GPT-3.5 model (i.e., text-davinci-003). Lastly, through in-depth error analysis, we identify potential challenges in the NL2Formula task and advocate for further investigation.</abstract>
      <url hash="310ef33c">2024.findings-eacl.158</url>
      <bibkey>zhao-etal-2024-nl2formula</bibkey>
    </paper>
  </volume>
</collection>
