<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.games">
  <volume id="1" ingest-date="2024-05-18" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 10th Workshop on Games and Natural Language Processing @ LREC-COLING 2024</booktitle>
      <editor><first>Chris</first><last>Madge</last></editor>
      <editor><first>Jon</first><last>Chamberlain</last></editor>
      <editor><first>Karen</first><last>Fort</last></editor>
      <editor><first>Udo</first><last>Kruschwitz</last></editor>
      <editor><first>Stephanie</first><last>Lukin</last></editor>
      <publisher>ELRA and ICCL</publisher>
      <address>Torino, Italia</address>
      <month>May</month>
      <year>2024</year>
      <url hash="f3bd4f2e">2024.games-1</url>
      <venue>games</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="7eec2185">2024.games-1.0</url>
      <bibkey>games-2024-games</bibkey>
    </frontmatter>
    <paper id="1">
      <title>“Actors Challenge”: Collecting Data to Study Prosodic Patterns and Their Mappings to Meanings Across Languages</title>
      <author><first>Sia V.</first><last>Sepanta</last></author>
      <pages>1–5</pages>
      <abstract>In this paper we describe “Actors Challenge”: a web-based interactive game designed to collect massively multi-speaker, multi-lingual oral data on the connection between prosody and various aspects of meaning. Game participants take on the two roles of auditioners and casting directors. Auditioners are asked to record certain target phrases modulated according to the emotional or attitudinal profiles that correspond to contexts or stage cues given to them. They then switch roles and become Casting Directors. Now they have to listen to other participants’ recordings, guess the corresponding context/stage cue that the auditioner tried to convey, and evaluate how good the performance was. By having the players alternate between these two roles we obtain both data creation and data validation from the same set of participants. We expect that the final dataset of labeled recordings will be valuable for a range of applications: training multilingual Speech Emotion Recognition classifiers; discovering correlations and variations in prosodic patterns among unrelated languages; examining correlations between prosodic patterns and emotion recognizability; probing the possibility that some prosodic patterns are universal.</abstract>
      <url hash="67c9eb88">2024.games-1.1</url>
      <bibkey>sepanta-2024-actors</bibkey>
    </paper>
    <paper id="2">
      <title>Empowering Adaptive Digital Game-Based Language Learning for Under-Resourced Languages Through Text Analysis</title>
      <author><first>Elaine</first><last>Uí Dhonnchadha</last></author>
      <author><first>Sally</first><last>Bruen</last></author>
      <author><first>Liang</first><last>Xu</last></author>
      <author><first>Monica</first><last>Ward</last></author>
      <pages>6–13</pages>
      <abstract>This study explores Cipher, an adaptive language learning game tailored for the under-resourced Irish language, aimed mainly at primary school students. By integrating text analysis techniques, Cipher dynamically adjusts its difficulty based on the player’s language proficiency, offering a customised learning experience. The game’s narrative involves decoding spells to access Irish myths and stories, combining language learning with cultural elements. Development involved collaboration with educators to align the game content with curriculum standards and incorporate culturally relevant materials. This paper outlines the game’s development process, emphasising the use of text analysis for difficulty adjustment and the importance of engaging, educational gameplay. Preliminary results indicate that adaptive games like Cipher can enhance language learning by providing immersive, personalised experiences that maintain player motivation and engagement.</abstract>
      <url hash="8de4f751">2024.games-1.2</url>
      <bibkey>ui-dhonnchadha-etal-2024-empowering</bibkey>
    </paper>
    <paper id="3">
      <title>Hostomytho: A <fixed-case>GWAP</fixed-case> for Synthetic Clinical Texts Evaluation and Annotation</title>
      <author><first>Nicolas</first><last>Hiebel</last></author>
      <author><first>Bertrand</first><last>Remy</last></author>
      <author><first>Bruno</first><last>Guillaume</last></author>
      <author><first>Olivier</first><last>Ferret</last></author>
      <author><first>Aurélie</first><last>Névéol</last></author>
      <author><first>Karen</first><last>Fort</last></author>
      <pages>14–20</pages>
      <abstract>This paper presents the creation of Hostomytho, a game with a purpose intended for evaluating the quality of synthetic biomedical texts through multiple mini-games. Hostomytho was developed entirely using open source technologies both for internet browser and mobile platforms (IOS &amp; Android). The code and the annotations created for synthetic clinical cases in French will be made freely available.</abstract>
      <url hash="e0d957be">2024.games-1.3</url>
      <bibkey>hiebel-etal-2024-hostomytho</bibkey>
    </paper>
    <paper id="4">
      <title>Using In-context Learning to Automate <fixed-case>AI</fixed-case> Image Generation for a Gamified Text Labelling Task</title>
      <author><first>Fatima</first><last>Althani</last></author>
      <author><first>Chris</first><last>Madge</last></author>
      <author><first>Massimo</first><last>Poesio</last></author>
      <pages>21–31</pages>
      <abstract>This paper explores a novel automated method to produce AI-generated images for a text-labelling gamified task. By leveraging the in-context learning capabilities of GPT-4, we automate the optimisation of text-to-image prompts to align with the text being labelled in the part-of-speech tagging task. As an initial evaluation, we compare the optimised prompts to the original sentences based on imageability and concreteness scores. Our results revealed that optimised prompts had significantly higher imageability and concreteness scores. Moreover, to evaluate text-to-image outputs, we generate images using Stable Diffusion XL based on the two prompt types, optimised prompts and the original sentences. Using the automated LIAON-Aesthetic predictor model, we assigned aesthetic scores for the generated images. This resulted in the outputs using optimised prompts scoring significantly higher in predicted aesthetics than those using original sentences as prompts. Our preliminary findings suggest that this methodology provides significantly more aesthetic text-to-image outputs than using the original sentence as a prompt. While the initial results are promising, the text labelling task and AI-generated images presented in this paper have yet to undergo human evaluation.</abstract>
      <url hash="5441d1ac">2024.games-1.4</url>
      <bibkey>althani-etal-2024-using</bibkey>
    </paper>
    <paper id="5">
      <title>Aspect-based Sentiment Evaluation of Chess Moves (<fixed-case>ASSESS</fixed-case>): an <fixed-case>NLP</fixed-case>-based Method for Evaluating Chess Strategies from Textbooks</title>
      <author><first>Haifa</first><last>Alrdahi</last></author>
      <author><first>Riza</first><last>Batista-Navarro</last></author>
      <pages>32–42</pages>
      <abstract>The chess domain is well-suited for creating an artificial intelligence (AI) system that mimics real-world challenges, including decision-making. Throughout the years, minimal attention has been paid to investigating insights derived from unstructured chess data sources. In this study, we examine the complicated relationships between multiple referenced moves in a chess-teaching textbook, and propose a novel method designed to encapsulate chess knowledge derived from move-action phrases. This study investigates the feasibility of using a modified sentiment analysis method as a means for evaluating chess moves based on text. Our proposed Aspect-Based Sentiment Analysis (ABSA) method represents an advancement in evaluating the sentiment associated with referenced chess moves. By extracting insights from move-action phrases, our approach aims to provide a more fine-grained and contextually aware ‘chess move’-based sentiment classification. Through empirical experiments and analysis, we evaluate the performance of our fine-tuned ABSA model, presenting results that confirm the efficiency of our approach in advancing aspect-based sentiment classification within the chess domain. This research contributes to the area of game-playing by machines and shows the practical applicability of leveraging NLP techniques to understand the context of strategic games. Keywords: Natural Language Processing, Chess, Aspect-based Sentiment Analysis (ABSA), Chess Move Evaluation.</abstract>
      <url hash="3912b899">2024.games-1.5</url>
      <bibkey>alrdahi-batista-navarro-2024-aspect</bibkey>
    </paper>
    <paper id="6">
      <title>Generating Converging Narratives for Games with Large Language Models</title>
      <author><first>Douglas</first><last>Summers-Stay</last></author>
      <author><first>Clare R.</first><last>Voss</last></author>
      <pages>43–60</pages>
      <abstract>We explore methods of combining the probability distributions generated by two LLM prompts in order to generate a continuation that is appropriate for both prompts at once. This is a new capability that extends the possibilities for branching and rejoining narratives in games.</abstract>
      <url hash="a99520ac">2024.games-1.6</url>
      <bibkey>summers-stay-voss-2024-generating</bibkey>
    </paper>
    <paper id="7">
      <title>Leveraging Large Language Models for Spell-Generation in Dungeons &amp; Dragons</title>
      <author><first>Elio</first><last>Musacchio</last></author>
      <author><first>Lucia</first><last>Siciliani</last></author>
      <author><first>Pierpaolo</first><last>Basile</last></author>
      <author><first>Giovanni</first><last>Semeraro</last></author>
      <pages>61–69</pages>
      <abstract>Dungeons &amp; Dragons (D&amp;D) is a classic tabletop game with a 50-year history. Its intricate and customizable gameplay allows players to create endless worlds and stories. Due to the highly narrative component of this game, D&amp;D and many other interactive games represent a challenging setting for the Natural Language Generation (NLG) capabilities of LLMs. This paper explores using LLMs to generate new spells, which are one of the most captivating aspects of D&amp;D gameplay. Due to the scarcity of resources available for such a specific task, we build a dataset of 3,259 instances by combining official and fan-made D&amp;D spells. We considered several LLMs in generating spells, which underwent a quantitative and qualitative evaluation. Metrics including Bleu and BertScore were computed for quantitative assessments. Subsequently, we also conducted an in-vivo evaluation with a survey involving D&amp;D players, which could assess the quality of the generated spells as well as their adherence to the rules. Furthermore, the paper emphasizes the open-sourcing of all models, datasets, and findings, aiming to catalyze further research on this topic.</abstract>
      <url hash="ab9590b2">2024.games-1.7</url>
      <bibkey>musacchio-etal-2024-leveraging</bibkey>
    </paper>
    <paper id="8">
      <title>Branching Narratives: Character Decision Points Detection</title>
      <author><first>Alexey</first><last>Tikhonov</last></author>
      <pages>70–75</pages>
      <abstract>This paper presents the Character Decision Points Detection (CHADPOD) task, a task of identification of points within narratives where characters make decisions that may significantly influence the story’s direction. We propose a novel dataset based on Choose Your Own Adventure (a registered trademark of Chooseco LLC) games graphs to be used as a benchmark for such a task. We provide a comparative analysis of different models’ performance on this task, including a couple of LLMs and several MLMs as baselines, achieving up to 89% accuracy. This underscores the complexity of narrative analysis, showing the challenges associated with understanding character-driven story dynamics. Additionally, we show how such a model can be applied to the existing text to produce linear segments divided by potential branching points, demonstrating the practical application of our findings in narrative analysis.</abstract>
      <url hash="75820dec">2024.games-1.8</url>
      <bibkey>tikhonov-2024-branching</bibkey>
    </paper>
    <paper id="9">
      <title>Utilizing <fixed-case>GPT</fixed-case>-4 to Solve <fixed-case>T</fixed-case>ext<fixed-case>W</fixed-case>orld Commonsense Games Efficiently</title>
      <author><first>Binggang</first><last>Zhuo</last></author>
      <author><first>Masaki</first><last>Murata</last></author>
      <pages>76–84</pages>
      <abstract>Most artificial intelligence agents in interactive fiction games are implemented using reinforcement learning. Considering the recent rapid development of large language models, we propose an approach that utilizes a large language model to tackle interactive fiction game tasks. The chosen test dataset is TextWorld Commonsense, an interactive fiction game environment designed for artificial intelligence agents. In these games, the AI agent’s task is to organize rooms and place items in appropriate locations. To achieve a high score in the game, common sense knowledge about “which items belong to which locations” is important. Our approach is based on GPT-4 and a carefully designed prompt. Experimental results demonstrate that our approach outperforms prior research. Specifically, GPT-4 with feedback-augmented prompt successfully completed all tasks in both simple and medium level game environments without fine-tuning. In hard level game environments, our approach achieved a normalized score of 0.70, surpassing the best baseline score of 0.57.</abstract>
      <url hash="c312976d">2024.games-1.9</url>
      <bibkey>zhuo-murata-2024-utilizing</bibkey>
    </paper>
    <paper id="10">
      <title>Linguistic Acceptability and Usability Enhancement: A Case Study of <fixed-case>GWAP</fixed-case> Evaluation and Redesign</title>
      <author><first>Wateen Abdullah</first><last>Aliady</last></author>
      <author><first>Massimo</first><last>Poesio</last></author>
      <pages>85–96</pages>
      <abstract>Collecting high-quality annotations for Natural Language Processing (NLP) tasks poses challenges. Gamified annotation systems, like Games-with-a-Purpose (GWAP), have become popular tools for data annotation. For GWAPs to be effective, they must be user-friendly and produce high-quality annotations to ensure the collected data’s usefulness. This paper investigates the effectiveness of a gamified approach through two specific studies on an existing GWAP designed for collecting NLP coreference judgments. The first study involved preliminary usability testing using the concurrent think-aloud method to gather open-ended feedback. This feedback was crucial in pinpointing design issues. Following this, we conducted semi-structured interviews with our participants, and the insights collected from these interviews were instrumental in crafting player personas, which informed design improvements aimed at enhancing user experience. The outcomes of our research have been generalized to benefit other GWAP implementations. The second study evaluated the linguistic acceptability and reliability of the data collected through our GWAP. Our findings indicate that our GWAP produced reliable corpora with 91.49% accuracy and 0.787 Cohen’s kappa.</abstract>
      <url hash="82eb90e1">2024.games-1.10</url>
      <bibkey>aliady-poesio-2024-linguistic</bibkey>
    </paper>
    <paper id="11">
      <title>Riddle Me This: Evaluating Large Language Models in Solving Word-Based Games</title>
      <author><first>Raffaele</first><last>Manna</last></author>
      <author><first>Maria Pia</first><last>di Buono</last></author>
      <author><first>Johanna</first><last>Monti</last></author>
      <pages>97–106</pages>
      <abstract>In this contribution, we examine the proficiency of Large Language Models (LLMs) in solving the linguistic game “La Ghigliottina,” the final game of the popular Italian TV quiz show “L’Eredità”. This game is particularly challenging as it requires LLMs to engage in semantic inference reasoning for identifying the solutions of the game. Our experiment draws inspiration from Ghigliottin-AI, a task of EVALITA 2020, an evaluation campaign focusing on Natural Language Processing (NLP) and speech tools designed for the Italian language. To benchmark our experiment, we use the results of the most successful artificial player in this task, namely Il Mago della Ghigliottina. The paper describes the experimental setting and the results which show that LLMs perform poorly.</abstract>
      <url hash="42a1ccb6">2024.games-1.11</url>
      <bibkey>manna-etal-2024-riddle</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>LLM</fixed-case>s of Catan: Exploring Pragmatic Capabilities of Generative Chatbots Through Prediction and Classification of Dialogue Acts in Boardgames’ Multi-party Dialogues</title>
      <author><first>Andrea</first><last>Martinenghi</last></author>
      <author><first>Gregor</first><last>Donabauer</last></author>
      <author><first>Simona</first><last>Amenta</last></author>
      <author><first>Sathya</first><last>Bursic</last></author>
      <author><first>Mathyas</first><last>Giudici</last></author>
      <author><first>Udo</first><last>Kruschwitz</last></author>
      <author><first>Franca</first><last>Garzotto</last></author>
      <author><first>Dimitri</first><last>Ognibene</last></author>
      <pages>107–118</pages>
      <abstract>Human language interactions involve complex processes beyond pure information exchange, for example, actions aimed at influencing beliefs and behaviors within a communicative context. In this paper, we propose to investigate the dialogue understanding capabilities of large language models (LLMs), particularly in multi-party settings, where challenges like speaker identification and turn-taking are common. Through experiments on the game-based STAC dataset, we explore zero and few-shot learning approaches for dialogue act classification in a multi-party game setting. Our intuition is that LLMs may excel in tasks framed through examples rather than formal descriptions, influenced by a range of pragmatic features like information presentation order in prompts and others. We also explore the models’ predictive abilities regarding future dialogue acts and study integrating information on dialogue act sequences to improve predictions. Our findings suggest that ChatGPT can keep up with baseline models trained from scratch for classification of certain dialogue act types but also reveal biases and limitations associated with the approach. These insights can be valuable for the development of multi-party chatbots and we try to point out directions for future research towards nuanced understanding and adaptation in diverse conversational contexts</abstract>
      <url hash="8acdee56">2024.games-1.12</url>
      <bibkey>martinenghi-etal-2024-llms</bibkey>
    </paper>
  </volume>
</collection>
