<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.eamt">
  <volume id="1" ingest-date="2024-09-22" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 25th Annual Conference of the European Association for Machine Translation (Volume 1)</booktitle>
      <editor><first>Carolina</first><last>Scarton</last></editor>
      <editor><first>Charlotte</first><last>Prescott</last></editor>
      <editor><first>Chris</first><last>Bayliss</last></editor>
      <editor><first>Chris</first><last>Oakley</last></editor>
      <editor><first>Joanna</first><last>Wright</last></editor>
      <editor><first>Stuart</first><last>Wrigley</last></editor>
      <editor><first>Xingyi</first><last>Song</last></editor>
      <editor><first>Edward</first><last>Gow-Smith</last></editor>
      <editor><first>Rachel</first><last>Bawden</last></editor>
      <editor><first>Víctor M</first><last>Sánchez-Cartagena</last></editor>
      <editor><first>Patrick</first><last>Cadwell</last></editor>
      <editor><first>Ekaterina</first><last>Lapshinova-Koltunski</last></editor>
      <editor><first>Vera</first><last>Cabarrão</last></editor>
      <editor><first>Konstantinos</first><last>Chatzitheodorou</last></editor>
      <editor><first>Mary</first><last>Nurminen</last></editor>
      <editor><first>Diptesh</first><last>Kanojia</last></editor>
      <editor><first>Helena</first><last>Moniz</last></editor>
      <publisher>European Association for Machine Translation (EAMT)</publisher>
      <address>Sheffield, UK</address>
      <month>June</month>
      <year>2024</year>
      <url hash="56737504">2024.eamt-1</url>
      <venue>eamt</venue>
    </meta>
    <frontmatter>
      <url hash="13a2e9f8">2024.eamt-1.0</url>
      <bibkey>eamt-2024-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Thesis Award</title>
      <author><first>Page</first><last>Break</last></author>
      <pages>1-1</pages>
      <abstract>Thesis Award</abstract>
      <url hash="9613a15d">2024.eamt-1.1</url>
      <bibkey>break-2024-thesis</bibkey>
    </paper>
    <paper id="2">
      <title>Direct Speech Translation Toward High-Quality, Inclusive, and Augmented Systems</title>
      <author><first>Marco</first><last>Gaido</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <pages>2-3</pages>
      <abstract>When this PhD started, the translation of speech into text in a different language was mainly tackled with a cascade of automatic speech recognition (ASR) and machine translation (MT) models, as the emerging direct speech translation (ST) models were not yet competitive. To close this gap, part of the PhD has been devoted to improving the quality of direct models, both in the simplified condition of test sets where the audio is split into well-formed sentences, and in the realistic condition in which the audio is automatically segmented. First, we investigated how to transfer knowledge from MT models trained on large corpora. Then, we defined encoder architectures that give different weights to the vectors in the input sequence, reflecting the variability of the amount of information over time in speech. Finally, we reduced the adverse effects caused by the suboptimal automatic audio segmentation in two ways: on one side, we created models robust to this condition; on the other, we enhanced the audio segmentation itself. The good results achieved in terms of overall translation quality allowed us to investigate specific behaviors of direct ST systems, which are crucial to satisfy real users’ needs. On one side, driven by the ethical goal of inclusive systems, we disclosed that established technical choices geared toward high general performance (statistical word segmentation of the target text, knowledge distillation from MT) cause an exacerbation of the gender representational disparities in the training data. Along this line of work, we proposed mitigation techniques that reduce the gender bias of ST models, and showed how gender-specific systems can be used to control the translation of gendered words related to the speakers, regardless of their vocal traits. On the other side, motivated by the practical needs of interpreters and translators, we evaluated the potential of direct ST systems in the “augmented translation” scenario, focusing on the translation and recognition of named entities (NEs). Along this line of work, we proposed solutions to cope with the major weakness of ST models (handling person names), and introduced direct models that jointly perform ST and NE recognition showing their superiority over a pipeline of dedicated tools for the two tasks. Overall, we believe that this thesis moves a step forward toward adopting direct ST systems in real applications, increasing the awareness of their strengths and weaknesses compared to the traditional cascade paradigm.</abstract>
      <url hash="6c46f377">2024.eamt-1.2</url>
      <bibkey>gaido-2024-direct</bibkey>
    </paper>
    <paper id="3">
      <title>Streaming Neural Speech Translation</title>
      <author><first>Javier</first><last>Iranzo-Sánchez</last><affiliation>AppTek</affiliation></author>
      <pages>4-5</pages>
      <abstract>EAMT 2023 Thesis Award submission for Javier Iranzo-Sánchez.</abstract>
      <url hash="21d1c7ed">2024.eamt-1.3</url>
      <bibkey>iranzo-sanchez-2024-streaming</bibkey>
    </paper>
    <paper id="4">
      <title>Thesis: Model-based Evaluation of Multilinguality</title>
      <author><first>Jannis</first><last>Vamvas</last><affiliation>University of Zurich</affiliation></author>
      <pages>6-7</pages>
      <abstract>The aim of this thesis was to extend the methodological toolbox for evaluating the ability of natural language processing systems to handle multiple languages. Neural machine translation (NMT) took the central role in this endeavour: NMT is inherently cross-lingual, and multilingual NMT systems, which translate from many source languages into many target languages, embody the concept of multilinguality in a very tangible way. In addition, NMT and specifically the perplexity of NMT systems can themselves be used as a tool for evaluating multilinguality.</abstract>
      <url hash="8c1bc369">2024.eamt-1.4</url>
      <bibkey>vamvas-2024-thesis</bibkey>
    </paper>
    <paper id="5">
      <title>Research: Technical</title>
      <author><first>Page</first><last>Break</last></author>
      <pages>8-8</pages>
      <abstract>Research: Technical</abstract>
      <url hash="57a7ad9e">2024.eamt-1.5</url>
      <bibkey>break-2024-research</bibkey>
    </paper>
    <paper id="6">
      <title>Promoting Target Data in Context-aware Neural Machine Translation</title>
      <author><first>Harritxu</first><last>Gete</last><affiliation>University of the Basque Country and Vicomtech Foundation</affiliation></author>
      <author><first>Thierry</first><last>Etchegoyhen</last><affiliation>Vicomtech</affiliation></author>
      <pages>9-23</pages>
      <abstract>Standard context-aware neural machine translation (NMT) typically relies on parallel document-level data, exploiting both source and target contexts. Concatenation-based approaches in particular, still a strong baseline for document-level NMT, prepend source and/or target context sentences to the sentences to be translated, with model variants that exploit equal amounts of source and target data on each side achieving state-of-the-art results. In this work, we investigate whether target data should be further promoted within standard concatenation-based approaches, as most document-level phenomena rely on information that is present on the target language side. We evaluate novel concatenation-based variants where the target context is prepended to the source language, either in isolation or in combination with the source context. Experimental results in English-Russian and Basque-Spanish show that including target context in the source leads to large improvements on target language phenomena. On source-dependent phenomena, using only target language context in the source achieves parity with state-of-the-art concatenation approaches, or slightly underperforms, whereas combining source and target context on the source side leads to significant gains across the board.</abstract>
      <url hash="6c5bf3f1">2024.eamt-1.6</url>
      <bibkey>gete-etchegoyhen-2024-promoting</bibkey>
    </paper>
    <paper id="7">
      <title>A Human Perspective on <fixed-case>GPT</fixed-case>-4 Translations: Analysing <fixed-case>F</fixed-case>aroese to <fixed-case>E</fixed-case>nglish News and Blog Text Translations</title>
      <author><first>Annika</first><last>Simonsen</last></author>
      <author><first>Hafsteinn</first><last>Einarsson</last><affiliation>deCODE genetics and University of Iceland</affiliation></author>
      <pages>24-36</pages>
      <abstract>This study investigates the potential of Generative Pre-trained Transformer models, specifically GPT-4, to generate machine translation resources for the low-resource language, Faroese. Given the scarcity of high-quality, human-translated data for such languages, Large Language Models’ capabilities to produce native-sounding text offer a practical solution. This approach is particularly valuable for generating paired translation examples where one is in natural, authentic Faroese as opposed to traditional approaches that went from English to Faroese, addressing a common limitation in such approaches. By creating such a synthetic parallel dataset and evaluating it through the Multidimensional Quality Metrics framework, this research assesses the translation quality offered by GPT-4. The findings reveal GPT-4’s strengths in general translation tasks, while also highlighting its limitations in capturing cultural nuances.</abstract>
      <url hash="8bed45cd">2024.eamt-1.7</url>
      <bibkey>simonsen-einarsson-2024-human</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>R</fixed-case>e<fixed-case>S</fixed-case>e<fixed-case>TOX</fixed-case>: Re-learning attention weights for toxicity mitigation in machine translation</title>
      <author><first>Javier</first><last>García Gilabert</last></author>
      <author><first>Carlos</first><last>Escolano</last></author>
      <author><first>Marta</first><last>Costa-jussà</last><affiliation>Meta</affiliation></author>
      <pages>37-58</pages>
      <abstract>Our proposed method, RESETOX (REdoSEarch if TOXic), addresses the issue ofNeural Machine Translation (NMT) gener-ating translation outputs that contain toxicwords not present in the input. The ob-jective is to mitigate the introduction oftoxic language without the need for re-training. In the case of identified addedtoxicity during the inference process, RE-SETOX dynamically adjusts the key-valueself-attention weights and re-evaluates thebeam search hypotheses. Experimental re-sults demonstrate that RESETOX achievesa remarkable 57% reduction in added tox-icity while maintaining an average trans-lation quality of 99.5% across 164 lan-guages. Our code is available at: https://github.com</abstract>
      <url hash="6fcadc8d">2024.eamt-1.8</url>
      <bibkey>garcia-gilabert-etal-2024-resetox</bibkey>
    </paper>
    <paper id="9">
      <title>Using Machine Translation to Augment Multilingual Classification</title>
      <author><first>Adam</first><last>King</last></author>
      <pages>59-67</pages>
      <abstract>An all-too-present bottleneck for text classification model development is the need to annotate training data and this need is multiplied for multilingual classifiers. Fortunately, contemporary machine translation models are both easily accessible and have dependable translation quality, making it possible to translate labeled training data from one language into another. Here, we explore the effects of using machine translation to fine-tune a multilingual model for a classification task across multiple languages. We also investigate the benefits of using a novel technique, originally proposed in the field of image captioning, to account for potential negative effects of tuning models on translated data. We show that translated data are of sufficient quality to tune multilingual classifiers and that this novel loss technique is able to offer some improvement over models tuned without it.</abstract>
      <url hash="f051c926">2024.eamt-1.9</url>
      <bibkey>king-2024-using</bibkey>
    </paper>
    <paper id="10">
      <title>Recovery Should Never Deviate from Ground Truth: Mitigating Exposure Bias in Neural Machine Translation</title>
      <author><first>Jianfei</first><last>He</last><affiliation>City University of Hong Kong</affiliation></author>
      <author><first>Shichao</first><last>Sun</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author><first>Xiaohua</first><last>Jia</last></author>
      <author><first>Wenjie</first><last>Li</last><affiliation>The Hong Kong Polytechnic University, The Hong Kong Polytechnic University</affiliation></author>
      <pages>68-79</pages>
      <abstract>In Neural Machine Translation, models are often trained with teacher forcing and suffer from exposure bias due to the discrepancy between training and inference. Current token-level solutions, such as scheduled sampling, aim to maximize the model’s capability to recover from errors. Their loss functions have a side effect: a sequence with errors may have a larger probability than the ground truth. The consequence is that the generated sequences may recover too much and deviate from the ground truth. This side effect is verified in our experiments. To address this issue, we propose using token-level contrastive learning to coordinate three training objectives: the usual MLE objective, an objective for recovery from errors, and a new objective to explicitly constrain the recovery in a scope that does not impact the ground truth. Our empirical analysis shows that this method effectively achieves these objectives in training and reduces the frequency with which the third objective is violated. We conduct experiments on three language pairs: German-English, Russian-English, and English-Russian. Results show that our method outperforms the vanilla Transformer and other methods addressing the exposure bias.</abstract>
      <url hash="adb37e0c">2024.eamt-1.10</url>
      <bibkey>he-etal-2024-recovery</bibkey>
    </paper>
    <paper id="11">
      <title>Chasing <fixed-case>COMET</fixed-case>: Leveraging Minimum <fixed-case>B</fixed-case>ayes Risk Decoding for Self-Improving Machine Translation</title>
      <author><first>Kamil</first><last>Guttmann</last><affiliation>Laniqo</affiliation></author>
      <author><first>Mikołaj</first><last>Pokrywka</last><affiliation>NA</affiliation></author>
      <author><first>Adrian</first><last>Charkiewicz</last><affiliation>NA</affiliation></author>
      <author><first>Artur</first><last>Nowakowski</last><affiliation>Laniqo</affiliation></author>
      <pages>80-99</pages>
      <abstract>This paper explores Minimum Bayes Risk (MBR) decoding for self-improvement in machine translation (MT), particularly for domain adaptation and low-resource languages. We implement the self-improvement process by fine-tuning the model on its MBR-decoded forward translations. By employing COMET as the MBR utility metric, we aim to achieve the reranking of translations that better aligns with human preferences. The paper explores the iterative application of this approach and the potential need for language-specific MBR utility metrics. The results demonstrate significant enhancements in translation quality for all examined language pairs, including successful application to domain-adapted models and generalisation to low-resource settings. This highlights the potential of COMET-guided MBR for efficient MT self-improvement in various scenarios.</abstract>
      <url hash="27a3e97e">2024.eamt-1.11</url>
      <bibkey>guttmann-etal-2024-chasing</bibkey>
    </paper>
    <paper id="12">
      <title>Mitra: Improving Terminologically Constrained Translation Quality with Backtranslations and Flag Diacritics</title>
      <author><first>Iikka</first><last>Hauhio</last><affiliation>University of Helsinki and Kielikone Oy</affiliation></author>
      <author><first>Théo</first><last>Friberg</last><affiliation>Kielikone</affiliation></author>
      <pages>100-115</pages>
      <abstract>Terminologically constrained machine translation is a hot topic in the field of neural machine translation. One major way to categorize constrained translation methods is to divide them into “hard” constraints that are forced into the target language sentence using a special decoding algorithm, and “soft” constraints that are included in the input given to the model.We present a constrained translation pipeline that combines soft and hard constraints while being completely model-agnostic, i.e. our method can be used with any NMT or LLM model. In the “soft” part, we substitute the source language terms in the input sentence for the backtranslations of their target language equivalents. This causes the source sentence to be more similar to the intended translation, thus making it easier to translate for the model. In the “hard” part, we use a novel nondeterministic finite state transducer-based (NDFST) constraint recognition algorithm utilizing flag diacritics to force the model to use the desired target language terms.We test our model with both Finnish–English and English–Finnish real-world vocabularies. We find that our methods consistently improve the translation quality when compared to previous constrained decoding algorithms, while the improvement over unconstrained translations depends on the familiarity of the model over the subject vocabulary and the quality of the vocabulary.</abstract>
      <url hash="ce8393bb">2024.eamt-1.12</url>
      <bibkey>hauhio-friberg-2024-mitra</bibkey>
    </paper>
    <paper id="13">
      <title>Bootstrapping Pre-trained Word Embedding Models for Sign Language Gloss Translation</title>
      <author><first>Euan</first><last>McGill</last><affiliation>Universitat Pompeu Fabra</affiliation></author>
      <author><first>Luis</first><last>Chiruzzo</last><affiliation>Facultad de Ingeniería - Universidad de la República - Uruguay</affiliation></author>
      <author><first>Horacio</first><last>Saggion</last><affiliation>Universitat Pompeu Fabra and Universitat Pompeu Fabra</affiliation></author>
      <pages>116-132</pages>
      <abstract>This paper explores a novel method to modify existing pre-trained word embedding models of spoken languages for Sign Language glosses. These newly-generated embeddings are described, visualised, and then used in the encoder and/or decoder of models for the Text2Gloss and Gloss2Text task of machine translation. In two translation settings (one including data augmentation-based pre-training and a baseline), we find that bootstrapped word embeddings for glosses improve translation across four Signed/spoken language pairs. Many improvements are statistically significant, including those where the bootstrapped gloss embedding models are used.Languages included: American Sign Language, Finnish Sign Language, Spanish Sign Language, Sign Language of The Netherlands.</abstract>
      <url hash="e4e55a0c">2024.eamt-1.13</url>
      <bibkey>mcgill-etal-2024-bootstrapping</bibkey>
    </paper>
    <paper id="14">
      <title>Quality Estimation with <tex-math>k</tex-math>-nearest Neighbors and Automatic Evaluation for Model-specific Quality Estimation</title>
      <author><first>Tu</first><last>Anh Dinh</last><affiliation>Karlsruhe Institut für Technologie</affiliation></author>
      <author><first>Tobias</first><last>Palzer</last><affiliation>Technische Universität München</affiliation></author>
      <author><first>Jan</first><last>Niehues</last></author>
      <pages>133-146</pages>
      <abstract>Providing quality scores along with Machine Translation (MT) output, so-called reference-free Quality Estimation (QE), is crucial to inform users about the reliability of the translation. We propose a model-specific, unsupervised QE approach, termed <tex-math>k</tex-math>NN-QE, that extracts information from the MT model’s training data using <tex-math>k</tex-math>-nearest neighbors. Measuring the performance of model-specific QE is not straightforward, since they provide quality scores on their own MT output, thus cannot be evaluated using benchmark QE test sets containing human quality scores on premade MT output. Therefore, we propose an automatic evaluation method that uses quality scores from reference-based metrics as gold standard instead of human-generated ones. We are the first to conduct detailed analyses and conclude that this automatic method is sufficient, and the reference-based MetricX-23 is best for the task.</abstract>
      <url hash="653cdfd5">2024.eamt-1.14</url>
      <bibkey>dinh-etal-2024-quality</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>S</fixed-case>ub<fixed-case>M</fixed-case>erge: Merging Equivalent Subword Tokenizations for Subword Regularized Models in Neural Machine Translation</title>
      <author><first>Haiyue</first><last>Song</last><affiliation>National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology</affiliation></author>
      <author><first>Francois</first><last>Meyer</last><affiliation>University of Cape Town</affiliation></author>
      <author><first>Raj</first><last>Dabre</last><affiliation>National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology</affiliation></author>
      <author><first>Hideki</first><last>Tanaka</last><affiliation>National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology</affiliation></author>
      <author><first>Chenhui</first><last>Chu</last><affiliation>Kyoto University</affiliation></author>
      <author><first>Sadao</first><last>Kurohashi</last><affiliation>Kyoto University, Tokyo Institute of Technology</affiliation></author>
      <pages>147-163</pages>
      <abstract>Subword regularized models leverage multiple subword tokenizations of one target sentence during training. However, selecting one tokenization during inference leads to the underutilization of knowledge learned about multiple tokenizations.We propose the SubMerge algorithm to rescue the ignored Subword tokenizations through merging equivalent ones during inference.SubMerge is a nested search algorithm where the outer beam search treats the word as the minimal unit, and the inner beam search provides a list of word candidates and their probabilities, merging equivalent subword tokenizations. SubMerge estimates the probability of the next word more precisely, providing better guidance during inference.Experimental results on six low-resource to high-resource machine translation datasets show that SubMerge utilizes a greater proportion of a model’s probability weight during decoding (lower word perplexities for hypotheses). It also improves BLEU and chrF++ scores for many translation directions, most reliably for low-resource scenarios. We investigate the effect of different beam sizes, training set sizes, dropout rates, and whether it is effective on non-regularized models.</abstract>
      <url hash="2a9dd693">2024.eamt-1.15</url>
      <bibkey>song-etal-2024-submerge</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>FAME</fixed-case>-<fixed-case>MT</fixed-case> Dataset: Formality Awareness Made Easy for Machine Translation Purposes</title>
      <author><first>Dawid</first><last>Wisniewski</last><affiliation>Technical University of Poznan</affiliation></author>
      <author><first>Zofia</first><last>Rostek</last><affiliation>NA</affiliation></author>
      <author><first>Artur</first><last>Nowakowski</last><affiliation>Laniqo</affiliation></author>
      <pages>164-180</pages>
      <abstract>People use language for various purposes. Apart from sharing information, individuals may use it to express emotions or to show respect for another person. In this paper, we focus on the formality level of machine-generated translations and present <tex-math>\textbf{FAME-MT}</tex-math> – a dataset consisting of 11.2 million translations between 15 European source languages and 8 European target languages classified to formal and informal classes according to target sentence formality. This dataset can be used to fine-tune machine translation models to ensure a given formality level for 8 European target languages considered. We describe the dataset creation procedure, the analysis of the dataset’s quality showing that <tex-math>\textbf{FAME-MT}</tex-math> is a reliable source of language register information, and we construct a publicly available proof-of-concept machine translation model that uses the dataset to steer the formality level of the translation. Currently, it is the largest dataset of formality annotations, with examples expressed in 112 European language pairs. The dataset is made available online.</abstract>
      <url hash="b5b8f3f4">2024.eamt-1.16</url>
      <bibkey>wisniewski-etal-2024-fame</bibkey>
    </paper>
    <paper id="17">
      <title>Iterative Translation Refinement with Large Language Models</title>
      <author><first>Pinzhen</first><last>Chen</last><affiliation>University of Edinburgh</affiliation></author>
      <author id="zhicheng-guo-tsinghua"><first>Zhicheng</first><last>Guo</last><affiliation>Tsinghua University, Tsinghua University</affiliation></author>
      <author><first>Barry</first><last>Haddow</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Kenneth</first><last>Heafield</last><affiliation>Facebook</affiliation></author>
      <pages>181-190</pages>
      <abstract>We propose iteratively prompting a large language model to self-correct a translation, with inspiration from their strong language capability as well as a human-like translation approach. Interestingly, multi-turn querying reduces the output’s string-based metric scores, but neural metrics suggest comparable or improved quality after two or more iterations. Human evaluations indicate better fluency and naturalness compared to initial translations and even human references, all while maintaining quality. Ablation studies underscore the importance of anchoring the refinement to the source and a reasonable seed translation for quality considerations. We also discuss the challenges in evaluation and relation to human performance and translationese.</abstract>
      <url hash="464ab660">2024.eamt-1.17</url>
      <bibkey>chen-etal-2024-iterative</bibkey>
    </paper>
    <paper id="18">
      <title>Detector–Corrector: Edit-Based Automatic Post Editing for Human Post Editing</title>
      <author><first>Hiroyuki</first><last>Deguchi</last><affiliation>Nara Institute of Science and Technology, Japan and National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology</affiliation></author>
      <author><first>Masaaki</first><last>Nagata</last><affiliation>NTT Corporation</affiliation></author>
      <author><first>Taro</first><last>Watanabe</last><affiliation>Nara Institute of Science and Technology, Japan</affiliation></author>
      <pages>191-206</pages>
      <abstract>Post-editing is crucial in the real world because neural machine translation (NMT) sometimes makes errors.Automatic post-editing (APE) attempts to correct the outputs of an MT model for better translation quality.However, many APE models are based on sequence generation, and thus their decisions are harder to interpret for actual users.In this paper, we propose “detector–corrector”, an edit-based post-editing model, which breaks the editing process into two steps, error detection and error correction.The detector model tags each MT output token whether it should be corrected and/or reordered while the corrector model generates corrected words for the spans identified as errors by the detector.Experiments on the WMT’20 English–German and English–Chinese APE tasks showed that our detector–corrector improved the translation edit rate (TER) compared to the previous edit-based model and a black-box sequence-to-sequence APE model, in addition, our model is more explainable because it is based on edit operations.</abstract>
      <url hash="0bb0598b">2024.eamt-1.18</url>
      <bibkey>deguchi-etal-2024-detector</bibkey>
    </paper>
    <paper id="19">
      <title>Assessing Translation Capabilities of Large Language Models involving <fixed-case>E</fixed-case>nglish and <fixed-case>I</fixed-case>ndian Languages</title>
      <author><first>Vandan</first><last>Mujadia</last></author>
      <author><first>Ashok</first><last>Urlana</last><affiliation>Tata Consultancy Services Limited, India</affiliation></author>
      <author><first>Yash</first><last>Bhaskar</last><affiliation>NA</affiliation></author>
      <author><first>Penumalla</first><last>Aditya Pavani</last><affiliation>NA</affiliation></author>
      <author><first>Kukkapalli</first><last>Shravya</last><affiliation>NA</affiliation></author>
      <author><first>Parameswari</first><last>Krishnamurthy</last><affiliation>NA</affiliation></author>
      <author><first>Dipti</first><last>Sharma</last><affiliation>IIIT Hyderabad</affiliation></author>
      <pages>207-228</pages>
      <abstract>Generative Large Language Models (LLMs) have achieved remarkable advances in various NLP tasks. In this work, our aim is to explore the multilingual capabilities of large language models by using machine translation as a task involving English and 22 Indian languages. We first investigate the translation capabilities of raw large-language models, followed by exploring the in-context learning capabilities of the same raw models. We fine-tune these large language models using parameter-efficient fine-tuning methods such as LoRA and additionally with full fine-tuning. Through our study, we have identified the model that performs best among the large language models available for the translation task.Our results demonstrate significant progress, with average BLEU scores of 13.42, 15.93, 12.13, 12.30, and 12.07, as well as chrF scores of 43.98, 46.99, 42.55, 42.42, and 45.39, respectively, using two-stage fine-tuned LLaMA-13b for English to Indian languages on IN22 (conversational), IN22 (general), flores200-dev, flores200-devtest, and newstest2019 testsets. Similarly, for Indian languages to English, we achieved average BLEU scores of 14.03, 16.65, 16.17, 15.35 and 12.55 along with chrF scores of 36.71, 40.44, 40.26, 39.51, and 36.20, respectively, using fine-tuned LLaMA-13b on IN22 (conversational), IN22 (general), flores200-dev, flores200-devtest and newstest2019 testsets. Overall, our findings highlight the potential and strength of large language models for machine translation capabilities, including languages that are currently underrepresented in LLMs.</abstract>
      <url hash="94e60415">2024.eamt-1.19</url>
      <bibkey>mujadia-etal-2024-assessing</bibkey>
    </paper>
    <paper id="20">
      <title>Improving <fixed-case>NMT</fixed-case> from a Low-Resource Source Language: A Use Case from <fixed-case>C</fixed-case>atalan to <fixed-case>C</fixed-case>hinese via <fixed-case>S</fixed-case>panish</title>
      <author><first>Yongjian</first><last>Chen</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Antonio</first><last>Toral</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Zhijian</first><last>Li</last><affiliation>NA</affiliation></author>
      <author><first>Mireia</first><last>Farrús</last></author>
      <pages>229-245</pages>
      <abstract>The effectiveness of neural machine translation is markedly constrained in low-resource scenarios, where the scarcity of parallel data hampers the development of robust models. This paper focuses on the scenario where the source language is low-resourceand there exists a related high-resource language, for which we introduce a novel approach that combines pivot translation and multilingual training. As a use case we tackle the automatic translation from Catalan to Chinese, using Spanish as an additional language. Our evaluation, conducted on the FLORES-200 benchmark, compares our new approach against a vanilla baseline alongside other models representing various low-resource techniques in the Catalan-to-Chinese context. Experimental results highlight the efficacy of our proposed method, which outperforms existing models, notably demonstrating significant improvements both in translation quality and in lexical diversity.</abstract>
      <url hash="6941b46f">2024.eamt-1.20</url>
      <bibkey>chen-etal-2024-improving-nmt</bibkey>
    </paper>
    <paper id="21">
      <title>A Case Study on Context-Aware Neural Machine Translation with Multi-Task Learning</title>
      <author><first>Ramakrishna</first><last>Appicharla</last></author>
      <author><first>Baban</first><last>Gain</last><affiliation>Indian Institute of Technology, Patna</affiliation></author>
      <author><first>Santanu</first><last>Pal</last><affiliation>Wipro</affiliation></author>
      <author><first>Asif</first><last>Ekbal</last><affiliation>IIT Patna</affiliation></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last><affiliation>Indian Institute of Technology, Bombay, Dhirubhai Ambani Institute Of Information and Communication Technology</affiliation></author>
      <pages>246-257</pages>
      <abstract>In document-level neural machine translation (DocNMT), multi-encoder approaches are common in encoding context and source sentences. Recent studies (CITATION) have shown that the context encoder generates noise and makes the model robust to the choice of context. This paper further investigates this observation by explicitly modelling context encoding through multi-task learning (MTL) to make the model sensitive to the choice of context. We conduct experiments on cascade MTL architecture, which consists of one encoder and two decoders. Generation of the source from the context is considered an auxiliary task, and generation of the target from the source is the main task. We experimented with German–English language pairs on News, TED, and Europarl corpora. Evaluation results show that the proposed MTL approach performs better than concatenation-based and multi-encoder DocNMT models in low-resource settings and is sensitive to the choice of context. However, we observe that the MTL models are failing to generate the source from the context. These observations align with the previous studies, and this might suggest that the available document-level parallel corpora are not context-aware, and a robust sentence-level model can outperform the context-aware models.</abstract>
      <url hash="494f6c85">2024.eamt-1.21</url>
      <bibkey>appicharla-etal-2024-case</bibkey>
    </paper>
    <paper id="22">
      <title>Aligning Neural Machine Translation Models: Human Feedback in Training and Inference</title>
      <author><first>Miguel</first><last>Ramos</last></author>
      <author><first>Patrick</first><last>Fernandes</last></author>
      <author><first>António</first><last>Farinhas</last><affiliation>Instituto Superior Técnico</affiliation></author>
      <author><first>Andre</first><last>Martins</last><affiliation>Instituto Superior Técnico and Unbabel</affiliation></author>
      <pages>258-274</pages>
      <abstract>Reinforcement learning from human feedback (RLHF) is a recent technique to improve the quality of the text generated by a language model, making it closer to what humans would generate.A core ingredient in RLHF’s success in aligning and improving large language models (LLMs) is its <tex-math>\textit{reward model}</tex-math>, trained using human feedback on model outputs. In machine translation (MT), where metrics trained from human annotations can readily be used as reward models, recent methods using <tex-math>\textit{minimum Bayes risk}</tex-math> decoding and reranking have succeeded in improving the final quality of translation.In this study, we comprehensively explore and compare techniques for integrating quality metrics as reward models into the MT pipeline. This includes using the reward model for data filtering, during the training phase through RL, and at inference time by employing reranking techniques, and we assess the effects of combining these in a unified approach.Our experimental results, conducted across multiple translation tasks, underscore the crucial role of effective data filtering, based on estimated quality, in harnessing the full potential of RL in enhancing MT quality.Furthermore, our findings demonstrate the effectiveness of combining RL training with reranking techniques, showcasing substantial improvements in translation quality.</abstract>
      <url hash="530ff16f">2024.eamt-1.22</url>
      <bibkey>ramos-etal-2024-aligning</bibkey>
    </paper>
    <paper id="23">
      <title>Enhancing Scientific Discourse: Machine Translation for the Scientific Domain</title>
      <author><first>Dimitris</first><last>Roussis</last><affiliation>ILSP - “Athena” Research Center</affiliation></author>
      <author><first>Sokratis</first><last>Sofianopoulos</last><affiliation>ILSP - “Athena” Research Center</affiliation></author>
      <author><first>Stelios</first><last>Piperidis</last></author>
      <pages>275-285</pages>
      <abstract>The increasing volume of scientific research necessitates effective communication across language barriers. Machine translation (MT) offers a promising solution for accessing international publications. However, the scientific domain presents unique challenges due to its specialized vocabulary and complex sentence structures. In this paper, we present the development of a collection of parallel and monolingual corpora from the scientific domain. The corpora target the language pairs Spanish-English, French-English, and Portuguese-English. For each language pair, we create a large general scientific corpus as well as four smaller corpora focused on the research domains of: Energy Research, Neuroscience, Cancer and Transportation. To evaluate the quality of these corpora, we utilize them for fine-tuning general-purpose neural machine translation (NMT) systems. We provide details regarding the corpus creation process, the fine-tuning strategies employed, and we conclude with the evaluation results.</abstract>
      <url hash="b37bce1a">2024.eamt-1.23</url>
      <bibkey>roussis-etal-2024-enhancing</bibkey>
    </paper>
    <paper id="24">
      <title>Towards Tailored Recovery of Lexical Diversity in Literary Machine Translation</title>
      <author><first>Esther</first><last>Ploeger</last></author>
      <author><first>Huiyuan</first><last>Lai</last><affiliation>University of Groningen and University of Groningen</affiliation></author>
      <author><first>Rik</first><last>Van Noord</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Antonio</first><last>Toral</last><affiliation>University of Groningen</affiliation></author>
      <pages>286-299</pages>
      <abstract>Machine translations are found to be lexically poorer than human translations. The loss of lexical diversity through MT poses an issue in the automatic translation of litrature, where it matters not only what is written, but also how it is written. Current methods for increasing lexical diversity in MT are rigid. Yet, as we demonstrate, the degree of lexical diversity can vary considerably across different novels. Thus, rather than aiming for the rigid increase of lexical diversity, we reframe the task as recovering what is lost in the machine translation process. We propose a novel approach that consists of reranking translation candidates with a classifier that distinguishes between original and translated text. We evaluate our approach on 31 English-to-Dutch book translations, and find that, for certain books, our approach retrieves lexical diversity scores that are close to human translation.</abstract>
      <url hash="be34c15b">2024.eamt-1.24</url>
      <bibkey>ploeger-etal-2024-towards</bibkey>
    </paper>
    <paper id="25">
      <title>Enhancing Gender-Inclusive Machine Translation with Neomorphemes and Large Language Models</title>
      <author><first>Andrea</first><last>Piergentili</last><affiliation>University of Trento and Fondazione Bruno Kessler</affiliation></author>
      <author><first>Beatrice</first><last>Savoldi</last></author>
      <author><first>Matteo</first><last>Negri</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Luisa</first><last>Bentivogli</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <pages>300-314</pages>
      <abstract>Machine translation (MT) models are known to suffer from gender bias, especially when translating into languages with extensive gendered morphology. Accordingly, they still fall short in using gender-inclusive language, also representative of non-binary identities. In this paper, we look at gender-inclusive neomorphemes, neologistic elements that avoid binary gender markings as an approach towards fairer MT. In this direction, we explore prompting techniques with large language models (LLMs) to translate from English into Italian using neomorphemes. So far, this area has been under-explored due to its novelty and the lack of publicly available evaluation resources. We fill this gap by releasing NEO-GATE, a resource designed to evaluate gender-inclusive en→it translation with neomorphemes. With NEO-GATE, we assess four LLMs of different families and sizes and different prompt formats, identifying strengths and weaknesses of each on this novel task for MT.</abstract>
      <url hash="e6235cad">2024.eamt-1.25</url>
      <bibkey>piergentili-etal-2024-enhancing</bibkey>
    </paper>
    <paper id="26">
      <title>Research: Translators &amp; Users</title>
      <author><first>Page</first><last>Break</last></author>
      <pages>315-315</pages>
      <abstract>Research: Translators &amp; Users</abstract>
      <url hash="955309a4">2024.eamt-1.26</url>
      <bibkey>break-2024-research-translators</bibkey>
    </paper>
    <paper id="27">
      <title>Prompting <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> for Translation: A Comparative Analysis of Translation Brief and Persona Prompts</title>
      <author><first>Sui</first><last>He</last><affiliation>Swansea University</affiliation></author>
      <pages>316-326</pages>
      <abstract>Prompt engineering has shown potential for improving translation quality in LLMs. However, the possibility of using translation concepts in prompt design remains largely underexplored. Against this backdrop, the current paper discusses the effectiveness of incorporating the conceptual tool of “translation brief” and the personas of “translator” and “author” into prompt design for translation tasks in ChatGPT. Findings suggest that, although certain elements are constructive in facilitating human-to-human communication for translation tasks, their effectiveness is limited for improving translation quality in ChatGPT. This accentuates the need for explorative research on how translation theorists and practitioners can develop the current set of conceptual tools rooted in the human-to-human communication paradigm for translation purposes in this emerging workflow involving human-machine interaction, and how translation concepts developed in translation studies can inform the training of GPT models for translation tasks.</abstract>
      <url hash="c2a09c91">2024.eamt-1.27</url>
      <bibkey>he-2024-prompting</bibkey>
    </paper>
    <paper id="28">
      <title>Exploring the Correlation between Human and Machine Evaluation of Simultaneous Speech Translation</title>
      <author><first>Claudio</first><last>Fantinuoli</last><affiliation>Johannes-Gutenberg Universität Mainz</affiliation></author>
      <author><first>Xiaoman</first><last>Wang</last><affiliation>NA</affiliation></author>
      <pages>327-336</pages>
      <abstract>Assessing the performance of interpreting services is a complex task, given the nuanced nature of spoken language translation, the strategies that interpreters apply, and the diverse expectations of users. The complexity of this task become even more pronounced when automated evaluation methods are applied. This is particularly true because interpreted texts exhibit less linearity between the source and target languages due to the strategies employed by the interpreter.This study aims to assess the reliability of automatic metrics in evaluating simultaneous interpretations by analyzing their correlation with human evaluations. We focus on a particular feature of interpretation quality, namely translation accuracy or faithfulness. As a benchmark we use human assessments performed by language experts, and evaluate how well sentence embeddings and Large Language Models correlate with them. We quantify semantic similarity between the source and translated texts without relying on a reference translation. The results suggest GPT models, particularly GPT-3.5 with direct prompting, demonstrate the strongest correlation with human judgment in terms of semantic similarity between source and target texts, even when evaluating short textual segments. Additionally, the study reveals that the size of the context window has a notable impact on this correlation.</abstract>
      <url hash="b908dbb4">2024.eamt-1.28</url>
      <bibkey>fantinuoli-wang-2024-exploring</bibkey>
    </paper>
    <paper id="29">
      <title><fixed-case>MTU</fixed-case>ncertainty: Assessing the Need for Post-editing of Machine Translation Outputs by Fine-tuning <fixed-case>O</fixed-case>pen<fixed-case>AI</fixed-case> <fixed-case>LLM</fixed-case>s</title>
      <author><first>Serge</first><last>Gladkoff</last><affiliation>Logrus Global AI Lab</affiliation></author>
      <author><first>Lifeng</first><last>Han</last></author>
      <author><first>Gleb</first><last>Erofeev</last></author>
      <author><first>Irina</first><last>Sorokina</last></author>
      <author><first>Goran</first><last>Nenadic</last><affiliation>University of Manchester</affiliation></author>
      <pages>337-346</pages>
      <abstract>Translation Quality Evaluation (TQE) is an essential step of the modern translation production process. TQE is critical in assessing both machine translation (MT) and human translation (HT) quality without reference translations. The ability to evaluate or even simply estimate the quality of translation automatically may open significant efficiency gains through process optimisation.This work examines whether the state-of-the-art large language models (LLMs) can be used for this uncertainty estimation of MT output quality. We take OpenAI models as an example technology and approach TQE as a binary classification task.On <b>eight language pairs</b> including English to Italian, German, French, Japanese, Dutch, Portuguese, Turkish, and Chinese, our experimental results show that fine-tuned <b>
          <i>gpt3.5</i></b> can demonstrate good performance on translation quality prediction tasks, i.e. <i>whether the translation needs to be edited</i>.Another finding is that simply increasing the sizes of LLMs does not lead to apparent better performances on this task by comparing the performance of three different versions of OpenAI models: <b>
          <i>curie</i></b>, <b>
          <i>davinci</i></b>, and <b>
          <i>gpt3.5</i></b> with 13B, 175B, and 175B parameters, respectively.</abstract>
      <url hash="2b96325f">2024.eamt-1.29</url>
      <bibkey>gladkoff-etal-2024-mtuncertainty</bibkey>
    </paper>
    <paper id="30">
      <title>Translators’ perspectives on machine translation uses and impacts in the <fixed-case>S</fixed-case>wiss <fixed-case>C</fixed-case>onfederation: Navigating technological change in an institutional setting</title>
      <author><first>Paolo</first><last>Canavese</last></author>
      <author><first>Patrick</first><last>Cadwell</last><affiliation>Dublin City University</affiliation></author>
      <pages>347-359</pages>
      <abstract>New language technologies are driving major changes in the language services of institutions worldwide, including the Swiss Confederation. Based on a definition of change management as a combination of adaptation measures at both the organisation and individual levels, this study used a survey to gather unprecedented quantitative data on the use and qualitative data on the perceptions of machine translation (MT) by federal in-house translators. The results show that more than half of the respondents use MT regularly and that translators are largely free to use it as they see fit. In terms of perceptions, they mostly anticipate negative evolutions along five dimensions: work processes, translators, translated texts, the future of their language services and job, and the place of translators within their institution and society. Their apprehensions concern MT per se, but even more the way it is seen and used within their organisation. However, positive perspectives regarding efficiency gains or usefulness of MT as a translation aid were also discussed. Building on these human factors is key to successful change management. Academic research has a contribution to make, and the coming together of translation and organisation studies offers promising avenues for further research.</abstract>
      <url hash="929109d4">2024.eamt-1.30</url>
      <bibkey>canavese-cadwell-2024-translators</bibkey>
    </paper>
    <paper id="31">
      <title>Added Toxicity Mitigation at Inference Time for Multimodal and Massively Multilingual Translation</title>
      <author><first>Marta</first><last>Costa-jussà</last><affiliation>Meta</affiliation></author>
      <author><first>David</first><last>Dale</last><affiliation>FAIR at Meta</affiliation></author>
      <author><first>Maha</first><last>Elbayad</last><affiliation>FAIR</affiliation></author>
      <author><first>Bokai</first><last>Yu</last><affiliation>Meta AI</affiliation></author>
      <pages>360-372</pages>
      <abstract>Machine translation models sometimes lead to added toxicity: translated outputs may contain more toxic content that the original input. In this paper, we introduce MinTox, a novel pipeline to automatically identify and mitigate added toxicity at inference time, without further model training. MinTox leverages a multimodal (speech and text) toxicity classifier that can scale across languages.We demonstrate the capabilities of MinTox when applied to SEAMLESSM4T, a multi-modal and massively multilingual machine translation system. MinTox significantly reduces added toxicity: across all domains, modalities and language directions, 25% to95% of added toxicity is successfully filtered out, while preserving translation quality</abstract>
      <url hash="76abf348">2024.eamt-1.31</url>
      <bibkey>costa-jussa-etal-2024-added</bibkey>
    </paper>
    <paper id="32">
      <title><fixed-case>LLM</fixed-case>s in Post-Translation Workflows: Comparing Performance in Post-Editing and Error Analysis</title>
      <author><first>Celia</first><last>Uguet</last></author>
      <author><first>Fred</first><last>Bane</last><affiliation>TransPerfect</affiliation></author>
      <author><first>Mahmoud</first><last>Aymo</last><affiliation>NA</affiliation></author>
      <author><first>João</first><last>Torres</last><affiliation>NA</affiliation></author>
      <author><first>Anna</first><last>Zaretskaya</last></author>
      <author><first>Tània Blanch Miró</first><last>Blanch Miró</last><affiliation>NA</affiliation></author>
      <pages>373-386</pages>
      <abstract>This study conducts a comprehensive comparison of three leading LLMs—GPT-4, Claude 3, and Gemini—in two translation-related tasks: automatic post-editing and MQM error annotation, across four languages. Utilizing the pharmaceutical EMEA corpus to maintain domain specificity and minimize data contamination, the research examines the models’ performance in these two tasks. Our findings reveal the nuanced capabilities of LLMs in handling MTPE and MQM tasks, hinting at the potential of these models in streamlining and optimizing translation workflows. Future directions include fine-tuning LLMs for task-specific improvements and exploring the integration of style guides for enhanced translation quality.</abstract>
      <url hash="b7111f1b">2024.eamt-1.32</url>
      <bibkey>uguet-etal-2024-llms</bibkey>
    </paper>
    <paper id="33">
      <title>Post-editors as Gatekeepers of Lexical and Syntactic Diversity: Comparative Analysis of Human Translation and Post-editing in Professional Settings</title>
      <author><first>Lise</first><last>Volkart</last></author>
      <author><first>Pierrette</first><last>Bouillon</last><affiliation>University of Geneva</affiliation></author>
      <pages>387-395</pages>
      <abstract>This paper presents a comparative analysis between human translation (HT) and post-edited machine translation (PEMT) from a lexical and syntactic perspective to verify whether the tendency of neural machine translation (NMT) systems to produce lexically and syntactically poorer translations shines through after post-editing (PE). The analysis focuses on three datasets collected in professional contexts containing translations from English into French and German into French. Through a comparison of word translation entropy (HTRa) scores, we observe a lower degree of lexical diversity in PEMT compared to HT. Additionally, metrics of syntactic equivalence indicate that PEMT is more likely to mirror the syntactic structure of the source text in contrast to HT. By incorporating raw machine translation (MT) output into our analysis, we underline the important role post-editors play in adding lexical and syntactic diversity to MT output. Our findings provide relevant input for MT users and decision-makers in language services as well as for MT and PE trainers and advisers.</abstract>
      <url hash="520e5904">2024.eamt-1.33</url>
      <bibkey>volkart-bouillon-2024-post</bibkey>
    </paper>
    <paper id="34">
      <title>Exploring <fixed-case>NMT</fixed-case> Explainability for Translators Using <fixed-case>NMT</fixed-case> Visualising Tools</title>
      <author><first>Gabriela</first><last>Gonzalez-Saez</last></author>
      <author><first>Mariam</first><last>Nakhle</last></author>
      <author><first>James</first><last>Turner</last><affiliation>Swansea University</affiliation></author>
      <author><first>Fabien</first><last>Lopez</last><affiliation>Université Grenoble Alpes</affiliation></author>
      <author><first>Nicolas</first><last>Ballier</last></author>
      <author><first>Marco</first><last>Dinarelli</last><affiliation>CNRS</affiliation></author>
      <author><first>Emmanuelle</first><last>Esperança-Rodier</last><affiliation>University of Grenoble-Alpes</affiliation></author>
      <author><first>Sui</first><last>He</last><affiliation>Swansea University</affiliation></author>
      <author><first>Raheel</first><last>Qader</last></author>
      <author><first>Caroline</first><last>Rossi</last><affiliation>Université Grenoble Alpes</affiliation></author>
      <author><first>Didier</first><last>Schwab</last><affiliation>Université Grenoble Alpes</affiliation></author>
      <author><first>Jun</first><last>Yang</last><affiliation>Swansea University</affiliation></author>
      <pages>396-410</pages>
      <abstract>This paper describes work in progress on Visualisation tools to foster collaborations between translators and computational scientists. We aim to describe how visualisation features can be used to explain translation and NMT outputs. We tested several visualisation functionalities with three NMT models based on Chinese-English, Spanish-English and French-English language pairs. We created three demos containing different visualisation tools and analysed them within the framework of performance-explainability, focusing on the translator’s perspective.</abstract>
      <url hash="6e51dca9">2024.eamt-1.34</url>
      <bibkey>gonzalez-saez-etal-2024-exploring</bibkey>
    </paper>
    <paper id="35">
      <title>Mitigating Translationese with <fixed-case>GPT</fixed-case>-4: Strategies and Performance</title>
      <author><first>Maria</first><last>Kunilovskaya</last><affiliation>Universität des Saarlandes and Tyumen State University</affiliation></author>
      <author><first>Koel</first><last>Dutta Chowdhury</last></author>
      <author><first>Heike</first><last>Przybyl</last><affiliation>Universität des Saarlandes</affiliation></author>
      <author><first>Cristina</first><last>España-Bonet</last><affiliation>German Research Center for AI</affiliation></author>
      <author><first>Josef</first><last>Genabith</last><affiliation>German Research Center for AI and Universität des Saarlandes</affiliation></author>
      <pages>411-430</pages>
      <abstract>Translations differ in systematic ways from texts originally authored in the same language.These differences, collectively known as translationese, can pose challenges in cross-lingual natural language processing: models trained or tested on translated input might struggle when presented with non-translated language. Translationese mitigation can alleviate this problem. This study investigates the generative capacities of GPT-4 to reduce translationese in human-translated texts. The task is framed as a rewriting process aimed at modified translations indistinguishable from the original text in the target language. Our focus is on prompt engineering that tests the utility of linguistic knowledge as part of the instruction for GPT-4. Through a series of prompt design experiments, we show that GPT4-generated revisions are more similar to originals in the target language when the prompts incorporate specific linguistic instructions instead of relying solely on the model’s internal knowledge. Furthermore, we release the segment-aligned bidirectional German-English data built from the Europarl corpus that underpins this study.</abstract>
      <url hash="351ed8d3">2024.eamt-1.35</url>
      <bibkey>kunilovskaya-etal-2024-mitigating</bibkey>
    </paper>
    <paper id="36">
      <title>Translate your Own: a Post-Editing Experiment in the <fixed-case>NLP</fixed-case> domain</title>
      <author><first>Rachel</first><last>Bawden</last><affiliation>Inria</affiliation></author>
      <author><first>Ziqian</first><last>Peng</last><affiliation>Université Pierre et Marie Curie - Paris 6, Sorbonne Université - Faculté des Sciences (Paris VI)</affiliation></author>
      <author><first>Maud</first><last>Bénard</last><affiliation>NA</affiliation></author>
      <author><first>Éric</first><last>Clergerie</last></author>
      <author><first>Raphaël</first><last>Esamotunu</last><affiliation>NA</affiliation></author>
      <author><first>Mathilde</first><last>Huguin</last><affiliation>NA</affiliation></author>
      <author><first>Natalie</first><last>Kübler</last><affiliation>NA</affiliation></author>
      <author><first>Alexandra</first><last>Mestivier</last><affiliation>NA</affiliation></author>
      <author><first>Mona</first><last>Michelot</last><affiliation>NA</affiliation></author>
      <author><first>Laurent</first><last>Romary</last><affiliation>INRIA</affiliation></author>
      <author><first>Lichao</first><last>Zhu</last><affiliation>Université Paris Cité</affiliation></author>
      <author><first>François</first><last>Yvon</last><affiliation>Université Pierre et Marie Curie - Paris 6, Sorbonne Université - Faculté des Sciences (Paris VI)</affiliation></author>
      <pages>431-443</pages>
      <abstract>The improvements in neural machine translation make translation and post-editing pipelines ever more effective for a wider range of applications. In this paper, we evaluate the effectiveness of such a pipeline for the translation of scientific documents (limited here to article abstracts). Using a dedicated interface, we collect, then analyse the post-edits of approximately 350 abstracts (English→French) in the Natural Language Processing domain for two groups of post-editors: domain experts (academics encouraged to post-edit their own articles) on the one hand and trained translators on the other. Our results confirm that such pipelines can be effective, at least for high-resource language pairs. They also highlight the difference in the post-editing strategy of the two subgroups. Finally, they suggest that working on term translation is the most pressing issue to improve fully automatic translations, but that in a post-editing setup, other error types can be equally annoying for post-editors.</abstract>
      <url hash="9078698f">2024.eamt-1.36</url>
      <bibkey>bawden-etal-2024-translate</bibkey>
    </paper>
    <paper id="37">
      <title>Pre-task perceptions of <fixed-case>MT</fixed-case> influence quality and productivity: the importance of better translator-computer interactions and implications for training</title>
      <author><first>Vicent</first><last>Briva-Iglesias</last></author>
      <author><first>Sharon</first><last>O’Brien</last><affiliation>NA</affiliation></author>
      <pages>444-454</pages>
      <abstract>This paper presents a user study with 11 professional English-Spanish translators in the legal domain. We analysed whether negative or positive translators’ pre-task perceptions of machine translation (MT) being an aid or a threat had any relationship with final translation quality and productivity in a post-editing workflow. Pre-task perceptions of MT were collected in a questionnaire before translators conducted post-editing tasks and were then correlated with translation productivity and translation quality after an Adequacy-Fluency evaluation. Each participant translated 13 texts over two consecutive weeks, accounting for 120,102 words in total. Results show that translators who had higher levels of trust in MT and thought that MT was not a threat to the translation profession reported higher translation quality and productivity. These results have critical implications: improving translator-computer interactions and fostering MT literacy in translation training may be crucial to reducing negative translators’ pre-task perceptions, resulting in better translation productivity and quality, especially adequacy.</abstract>
      <url hash="565fe087">2024.eamt-1.37</url>
      <bibkey>briva-iglesias-obrien-2024-pre</bibkey>
    </paper>
    <paper id="38">
      <title><fixed-case>B</fixed-case>ayesian Hierarchical Modelling for Analysing the Effect of Speech Synthesis on Post-Editing Machine Translation</title>
      <author><first>Miguel</first><last>Rios</last><affiliation>Universität Vienna</affiliation></author>
      <author><first>Justus</first><last>Brockmann</last><affiliation>Universität Vienna</affiliation></author>
      <author><first>Claudia</first><last>Wiesinger</last><affiliation>NA</affiliation></author>
      <author><first>Raluca</first><last>Chereji</last></author>
      <author><first>Alina</first><last>Secară</last><affiliation>Universität Vienna</affiliation></author>
      <author><first>Dragoș</first><last>Ciobanu</last><affiliation>Universität Vienna</affiliation></author>
      <pages>455-468</pages>
      <abstract>Automatic speech synthesis has seen rapid development and integration in domains as diverse as accessibility services, translation, or language learning platforms. We analyse its integration in a post-editing machine translation (PEMT) environment and the effect this has on quality, productivity, and cognitive effort. We use Bayesian hierarchical modelling to analyse eye-tracking, time-tracking, and error annotation data resulting from an experiment involving 21 professional translators post-editing from English into German in a customised cloud-based CAT environment and listening to the source and/or target texts via speech synthesis. Using speech synthesis in a PEMT task has a non-substantial positive effect on quality, a substantial negative effect on productivity, and a substantial negative effect on the cognitive effort expended on the target text, signifying that participants need to allocate less cognitive effort to the target text.</abstract>
      <url hash="b5ce5c8f">2024.eamt-1.38</url>
      <bibkey>rios-etal-2024-bayesian</bibkey>
    </paper>
    <paper id="39">
      <title>Evaluation of intralingual machine translation for health communication</title>
      <author><first>Silvana</first><last>Deilen</last><affiliation>Universität Hildesheim</affiliation></author>
      <author><first>Ekaterina</first><last>Lapshinova-Koltunski</last><affiliation>Universität Hildesheim</affiliation></author>
      <author><first>Sergio</first><last>Garrido</last><affiliation>Universität Hildesheim, Universität Hildesheim and Universität Hildesheim</affiliation></author>
      <author><first>Julian</first><last>Hörner</last><affiliation>NA</affiliation></author>
      <author><first>Christiane</first><last>Maaß</last><affiliation>NA</affiliation></author>
      <author><first>Vanessa</first><last>Theel</last><affiliation>NA</affiliation></author>
      <author><first>Sophie</first><last>Ziemer</last><affiliation>Johannes-Gutenberg Universität Mainz and SUMM AI</affiliation></author>
      <pages>469-479</pages>
      <abstract>In this paper, we describe results of a study on evaluation of intralingual machine translation. The study focuses on machine translations of medical texts into Plain German. The automatically simplified texts were compared with manually simplified texts (i.e., simplified by human experts) as well as with the underlying, unsimplified source texts. We analyse the quality of outputs from three models based on different criteria, such as correctness, readability, and syntactic complexity. We compare the outputs of the three models under analysis between each other, as well as with the existing human translations. The study revealed that system performance depends on the evaluation criteria used and that only one of the three models showed strong similarities to the human translations. Furthermore, we identified various types of errors in all three models. These included not only grammatical mistakes and misspellings, but also incorrect explanations of technical terms and false statements, which in turn led to serious content-related mistakes.</abstract>
      <url hash="7b2a4925">2024.eamt-1.39</url>
      <bibkey>deilen-etal-2024-evaluation</bibkey>
    </paper>
    <paper id="40">
      <title>Using Machine Learning to Validate a Novel Taxonomy of Phenomenal Translation States</title>
      <author><first>Michael</first><last>Carl</last><affiliation>Stevenson University</affiliation></author>
      <author><first>Sheng</first><last>Lu</last><affiliation>TU Darmstadt</affiliation></author>
      <author><first>Ali</first><last>Al-Ramadan</last><affiliation>Kent State University</affiliation></author>
      <pages>480-491</pages>
      <abstract>We report an experiment in which we use machine learning to validate the empirical objectivity of a novel annotation taxonomy for behavioral translation data. The HOF taxonomy defines three translation states according to which a human translator can be in a state of Orientation (O), Hesitation (H) or in a Flow state (F). We aim at validating the taxonomy based on a manually annotated dataset that consists of six English-Spanish translation sessions (approx 900 words) and 1813 HOF-annotated Activity Units (AUs). Two annotators annotated the data and obtain high average inter-annotator accuracy 0.76 (kappa 0.88). We train two classifiers, a Multi-layer Perceptron (MLP) and a Random Forest (RF) on the annotated data and tested on held-out data. The classifiers perform well on the annotated data and thus confirm the epistemological objectivity of the annotation taxonomy. Interestingly, inter-classifier accuracy scores are higher than between the two human annotators.</abstract>
      <url hash="42e23ffd">2024.eamt-1.40</url>
      <bibkey>carl-etal-2024-using</bibkey>
    </paper>
    <paper id="41">
      <title>Perceptions of Educators on <fixed-case>MTQA</fixed-case> Curriculum and Instruction</title>
      <author><first>João</first><last>Camargo</last></author>
      <author><first>Sheila</first><last>Castilho</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Joss</first><last>Moorkens</last></author>
      <pages>492-506</pages>
      <abstract>This paper reports the preliminary resultsof a survey aimed at identifying and ex-ploring the attitudes and recommendationsof machine translation quality assessment(MTQA) educators. Drawing upon ele-ments from the literature on MTQA teach-ing, the survey explores themes that maypose a challenge or lead to successful im-plementation of human evaluation, as theliterature shows that there has not beenenough design and reporting. Results show educators’ awareness ofthe topic, awareness stemming from therecommendations of the literature on MTevaluation, and reports new challenges andissues.</abstract>
      <url hash="87982d35">2024.eamt-1.41</url>
      <bibkey>camargo-etal-2024-perceptions</bibkey>
    </paper>
    <paper id="42">
      <title>Comparative Quality Assessment of Human and Machine Translation with Best-Worst Scaling</title>
      <author><first>Bettina</first><last>Hiebl</last><affiliation>Universität Vienna</affiliation></author>
      <author><first>Dagmar</first><last>Gromann</last></author>
      <pages>507-536</pages>
      <abstract>Translation quality and its assessment are of great importance in the context of human as well as machine translation. Methods range from human annotation and assessment to quality metrics and estimation, where the former are rather time-consuming. Furthermore, assessing translation quality is a subjective process. Best-Worst Scaling (BWS) represents a time-efficient annotation method to obtain subjective preferences, the best and the worst in a given set and their ratings. In this paper, we propose to use BWS for a comparative translation quality assessment of one human and three machine translations to German of the same source text in English. As a result, ten participants with a translation background selected the human translation most frequently and rated it overall as best closely followed by DeepL. Participants showed an overall positive attitude towards this assessment method.</abstract>
      <url hash="a9de37db">2024.eamt-1.42</url>
      <bibkey>hiebl-gromann-2024-comparative</bibkey>
    </paper>
    <paper id="43">
      <title>Quantifying the Contribution of <fixed-case>MWE</fixed-case>s and Polysemy in Translation Errors for <fixed-case>E</fixed-case>nglish–<fixed-case>I</fixed-case>gbo <fixed-case>MT</fixed-case></title>
      <author><first>Adaeze</first><last>Ohuoba</last><affiliation>University of Leeds and Abia State University</affiliation></author>
      <author><first>Serge</first><last>Sharoff</last></author>
      <author><first>Callum</first><last>Walker</last><affiliation>University of Leeds</affiliation></author>
      <pages>537-547</pages>
      <abstract>In spite of recent successes in improving Machine Translation (MT) quality overall, MT engines require a large amount of resources, which leads to markedly lower quality for lesser-resourced languages. This study explores the case of translation from English into Igbo, a very low resource language spoken by about 45 million speakers. With the aim of improving MT quality in this scenario, we investigate methods for guided detection of critical/harmful MT errors, more specifically those caused by non-compositional multi-word expressions and polysemy. We have designed diagnostic tests for these cases and applied them to collections of medical texts from CDC, Cochrane, NCDC, NHS and WHO.</abstract>
      <url hash="03ad7dd0">2024.eamt-1.43</url>
      <bibkey>ohuoba-etal-2024-quantifying</bibkey>
    </paper>
    <paper id="44">
      <title>Analysis of the Annotations from a Crowd <fixed-case>MT</fixed-case> Evaluation Initiative: Case Study for the <fixed-case>S</fixed-case>panish-<fixed-case>B</fixed-case>asque Pair</title>
      <author><first>Nora</first><last>Aranberri</last><affiliation>Universidad del País Vasco</affiliation></author>
      <pages>548-559</pages>
      <abstract>With the advent and success of trainable automatic evaluation metrics, creating annotated machine translation evaluation data sets is increasingly relevant. However, for low-resource languages, gathering such data can be challenging and further insights into evaluation design for opportunistic scenarios are necessary. In this work we explore an evaluation initiative that targets the Spanish—-Basque language pair to study the impact of design decisions and the reliability of volunteer contributions. To do that, we compare the work carried out by volunteers and a translation professional in terms of evaluation results and evaluator agreement and examine the control measures used to ensure reliability. Results show similar behaviour regarding general quality assessment but underscore the need for more informative working environments to make evaluation processes more reliable as well as the need for carefully crafted control cases.</abstract>
      <url hash="2180a1f9">2024.eamt-1.44</url>
      <bibkey>aranberri-2024-analysis</bibkey>
    </paper>
    <paper id="45">
      <title>Implementations &amp; Case Studies</title>
      <author><first>Page</first><last>Break</last></author>
      <pages>560-560</pages>
      <abstract>Implementations &amp; Case Studies</abstract>
      <url hash="4cedac26">2024.eamt-1.45</url>
      <bibkey>break-2024-implementations</bibkey>
    </paper>
    <paper id="46">
      <title>A Case Study on Contextual Machine Translation in a Professional Scenario of Subtitling</title>
      <author><first>Sebastian</first><last>Vincent</last><affiliation>ZOO Digital PLC</affiliation></author>
      <author><first>Charlotte</first><last>Prescott</last><affiliation>NA</affiliation></author>
      <author><first>Chris</first><last>Bayliss</last><affiliation>NA</affiliation></author>
      <author><first>Chris</first><last>Oakley</last><affiliation>NA</affiliation></author>
      <author><first>Carolina</first><last>Scarton</last><affiliation>University of Sheffield</affiliation></author>
      <pages>561-572</pages>
      <abstract>Incorporating extra-textual context such as film metadata into the machine translation (MT) pipeline can enhance translation quality, as indicated by automatic evaluation in recent work. However, the positive impact of such systems in industry remains unproven. We report on an industrial case study carried out to investigate the benefit of MT in a professional scenario of translating TV subtitles with a focus on how leveraging extra-textual context impacts post-editing. We found that post-editors marked significantly fewer context-related errors when correcting the outputs of MTCue, the context-aware model, as opposed to non-contextual models. We also present the results of a survey of the employed post-editors, which highlights contextual inadequacy as a significant gap consistently observed in MT. Our findings strengthen the motivation for further work within fully contextual MT.</abstract>
      <url hash="6236d5b7">2024.eamt-1.46</url>
      <bibkey>vincent-etal-2024-case</bibkey>
    </paper>
    <paper id="47">
      <title>Training an <fixed-case>NMT</fixed-case> system for legal texts of a low-resource language variety South Tyrolean <fixed-case>G</fixed-case>erman - <fixed-case>I</fixed-case>talian</title>
      <author><first>Antoni</first><last>Oliver</last><affiliation>Universitat Oberta de Catalunya</affiliation></author>
      <author><first>Sergi</first><last>Alvarez-Vidal</last><affiliation>Universitat Pompeu Fabra and Universitat Oberta de Catalunya</affiliation></author>
      <author><first>Egon</first><last>Stemle</last><affiliation>Masaryk University and Eurac Research</affiliation></author>
      <author><first>Elena</first><last>Chiocchetti</last><affiliation>NA</affiliation></author>
      <pages>573-579</pages>
      <abstract>This paper illustrates the process of training and evaluating NMT systems for a language pair that includes a low-resource language variety.A parallel corpus of legal texts for Italian and South Tyrolean German has been compiled, with South Tyrolean German being the low-resourced language variety. As the size of the compiled corpus is insufficient for the training, we have combined the corpus with several parallel corpora using data weighting at sentence level. We then performed an evaluation of each combination and of two popular commercial systems.</abstract>
      <url hash="6b0ab372">2024.eamt-1.47</url>
      <bibkey>oliver-etal-2024-training</bibkey>
    </paper>
    <paper id="48">
      <title>Implementing Gender-Inclusivity in <fixed-case>MT</fixed-case> Output using Automatic Post-Editing with <fixed-case>LLM</fixed-case>s</title>
      <author><first>Mara</first><last>Nunziatini</last></author>
      <author><first>Sara</first><last>Diego</last><affiliation>NA</affiliation></author>
      <pages>580-589</pages>
      <abstract>This paper investigates the effectiveness of combining machine translation (MT) systems and large language models (LLMs) to produce gender-inclusive translations from English to Spanish. The study uses a multi-step approach where a translation is first generated by an MT engine and then reviewed by an LLM. The results suggest that while LLMs, particularly GPT-4, are successful in generating gender-inclusive post-edited translations and show potential in enhancing fluency, they often introduce unnecessary changes and inconsistencies. The findings underscore the continued necessity for human review in the translation process, highlighting the current limitations of AI systems in handling nuanced tasks like gender-inclusive translation. Also, the study highlights that while the combined approach can improve translation fluency, the effectiveness and reliability of the post-edited translations can vary based on the language of the prompts used.</abstract>
      <url hash="901d8c9c">2024.eamt-1.48</url>
      <bibkey>nunziatini-diego-2024-implementing</bibkey>
    </paper>
    <paper id="49">
      <title><fixed-case>CantonMT</fixed-case>: <fixed-case>C</fixed-case>antonese to <fixed-case>E</fixed-case>nglish <fixed-case>NMT</fixed-case> Platform with Fine-Tuned Models using Real and Synthetic Back-Translation Data</title>
      <author><first>Kung</first><last>Hong</last></author>
      <author><first>Lifeng</first><last>Han</last></author>
      <author><first>Riza</first><last>Batista-Navarro</last><affiliation>University of Manchester</affiliation></author>
      <author><first>Goran</first><last>Nenadic</last><affiliation>University of Manchester</affiliation></author>
      <pages>590-599</pages>
      <abstract>Neural Machine Translation (NMT) for low-resource languages remains a challenge for many NLP researchers. In this work, we deploy a standard data augmentation methodology by back-translation to a new language translation direction, i.e., Cantonese-to-English. We present the models we fine-tuned using the limited amount of real data and the synthetic data we generated using back-translation by three models: OpusMT, NLLB, and mBART.We carried out automatic evaluation using a range of different metrics including those that are lexical-based and embedding-based.Furthermore, we create a user-friendly interface for the models we included in this project, CantonMT, and make it available to facilitate Cantonese-to-English MT research. Researchers can add more models to this platform via our open-source CantonMT toolkit, available at <url>https://github.com/kenrickkung/CantoneseTranslation</url>.</abstract>
      <url hash="db0854f2">2024.eamt-1.49</url>
      <bibkey>hong-etal-2024-cantonmt</bibkey>
    </paper>
    <paper id="50">
      <title>Advancing Digital Language Equality in <fixed-case>E</fixed-case>urope: A Market Study and Open-Source Solutions for Multilingual Websites</title>
      <author><first>Andrejs</first><last>Vasiljevs</last><affiliation>Tilde</affiliation></author>
      <author><first>Rinalds</first><last>Vīksna</last><affiliation>University of Latvia</affiliation></author>
      <author><first>Neil</first><last>Vacheva</last><affiliation>NA</affiliation></author>
      <author><first>Andis</first><last>Lagzdiņš</last><affiliation>NA</affiliation></author>
      <pages>600-609</pages>
      <abstract>The paper presents findings from a comprehensive market study commissioned by the European Commission, aimed at analysing multilinguality of European websites and automated website translation services across various sectors. The findings show that the majority of websites offer content in one or two languages, while only less than 25% of European websites provide content in 3 or more languages. Additionally, we introduce Web-T, a collection of open-source solutions facilitating automated website translation with a help of free MT service eTranslation provided by the European Commission and possibility to integrate other MT providers. Web-T solutions include local plug-ins for Content Management Systems, universal plug-ins, and an MT API Integrator, thus contributing to the broader goal of digital language equality in Europe.</abstract>
      <url hash="11211fed">2024.eamt-1.50</url>
      <bibkey>vasiljevs-etal-2024-advancing</bibkey>
    </paper>
    <paper id="51">
      <title>Exploring the Effectiveness of <fixed-case>LLM</fixed-case> Domain Adaptation for Business <fixed-case>IT</fixed-case> Machine Translation</title>
      <author><first>Johannes</first><last>Eschbach-Dymanus</last><affiliation>SAP SE and Institute for Computational Linguistics, Heidelberg University, Ruprecht-Karls-Universität Heidelberg</affiliation></author>
      <author><first>Frank</first><last>Essenberger</last><affiliation>SAP SE</affiliation></author>
      <author><first>Bianka</first><last>Buschbeck</last></author>
      <author><first>Miriam</first><last>Exel</last><affiliation>SAP SE</affiliation></author>
      <pages>610-622</pages>
      <abstract>In this paper, we study the translation abilities of Large Language Models (LLMs) for business IT texts.We are strongly interested in domain adaptation of translation systems, which is essential for accurate and lexically appropriate translation of such texts.Among the open-source models evaluated in a zero- and few-shot setting, we find Llama-2 13B the most promising for domain-specific translation fine-tuning.We investigate the full range of adaptation techniques for LLMs: from prompting, over parameter-efficient fine-tuning to full fine-tuning, and compare to classic neural machine translation (MT) models trained internally at SAP.We provide guidance how to use training budget most effectively for different fine-tuning approaches.We observe that while LLMs can translate on-par with SAP’s MT models on general domain data, it is difficult to close the gap on SAP’s domain-specific data, even with extensive training and carefully curated data.</abstract>
      <url hash="671453f3">2024.eamt-1.51</url>
      <bibkey>eschbach-dymanus-etal-2024-exploring</bibkey>
    </paper>
    <paper id="52">
      <title>Creating and Evaluating a Multilingual Corpus of <fixed-case>UN</fixed-case> General Assembly Debates</title>
      <author><first>Hannah</first><last>Bechara</last></author>
      <author><first>Krishnamoorthy</first><last>Manohara</last><affiliation>NA</affiliation></author>
      <author><first>Slava</first><last>Jankin</last><affiliation>Hertie School of Governance</affiliation></author>
      <pages>623-627</pages>
      <abstract>This paper presents a multilingual aligned corpus of political debates from the United Nations (UN) General Assembly sessions between 1978 and 2021, which covers five of the six official UN languages: Arabic, Chinese, English, French, Russian, and Spanish. We explain the preprocessing steps we applied to the corpus. We align the sentences by using word vectors to numerically represent the meaning of each sentence and then calculating the Euclidean distance between them. To validate our alignment methods, we conducted an evaluation study with crowd-sourced human annotators using Scale AI, an online platform for data labelling. The final dataset consists of around 300,000 aligned sentences for En-Es, En-Fr, En-Zh and En-Ru. It is publicly available for download.</abstract>
      <url hash="30fba51b">2024.eamt-1.52</url>
      <bibkey>bechara-etal-2024-creating</bibkey>
    </paper>
    <paper id="53">
      <title>Generating subject-matter expertise assessment questions with <fixed-case>GPT</fixed-case>-4: a medical translation use-case</title>
      <author><first>Diana</first><last>Silveira</last></author>
      <author><first>Marina</first><last>Torrón</last></author>
      <author><first>Helena</first><last>Moniz</last><affiliation>Universidade de Lisboa</affiliation></author>
      <pages>628-635</pages>
      <abstract>This paper examines the suitability of a large language model (LLM), GPT-4, for generating multiple choice questions (MCQs) aimed at assessing subject matter expertise (SME) in the domain of medical translation. The main objective of these questions is to model the skills of potential subject matter experts in a human-in-the-loop machine translation (MT) flow, to ensure that tasks are matched to the individuals with the right skill profile. The investigation was conducted at Unbabel, an artificial intelligence-powered human translation platform. Two medical translation experts evaluated the GPT-4-generated questions and answers, one focusing on English–European Portuguese, and the other on English–German. We present a methodology for creating prompts to elicit high-quality GPT-4 outputs for this use case, as well as for designing evaluation scorecards for human review of such output. Our findings suggest that GPT-4 has the potential to generate suitable items for subject matter expertise tests, providing a more efficient approach compared to relying solely on humans. Furthermore, we propose recommendations for future research to build on our approach and refine the quality of the outputs generated by LLMs.</abstract>
      <url hash="4b9c9b41">2024.eamt-1.53</url>
      <bibkey>silveira-etal-2024-generating</bibkey>
    </paper>
    <paper id="54">
      <title>Prompting Large Language Models with Human Error Markings for Self-Correcting Machine Translation</title>
      <author><first>Nathaniel</first><last>Berger</last></author>
      <author><first>Stefan</first><last>Riezler</last><affiliation>Heidelberg University, Germany</affiliation></author>
      <author><first>Miriam</first><last>Exel</last><affiliation>SAP SE</affiliation></author>
      <author><first>Matthias</first><last>Huck</last><affiliation>SAP SE</affiliation></author>
      <pages>636-646</pages>
      <abstract>While large language models (LLMs) pre-trained on massive amounts of unpaired language data have reached the state-of-the-art in machine translation (MT) of general domain texts, post-editing (PE) is still required to correct errors and to enhance term translation quality in specialized domains. In this paper we present a pilot study of enhancing translation memories (TM) produced by PE (source segments, machine translations, and reference translations, henceforth called PE-TM) for the needs of correct and consistent term translation in technical domains. We investigate a light-weight two-step scenario where at inference time, a human translator marks errors in the first translation step, and in a second step a few similar examples are extracted from the PE-TM to prompt an LLM. Our experiment shows that the additional effort of augmenting translations with human error markings guides the LLM to focus on a correction of the marked errors, yielding consistent improvements over automatic PE (APE) and MT from scratch.</abstract>
      <url hash="21091f1c">2024.eamt-1.54</url>
      <bibkey>berger-etal-2024-prompting</bibkey>
    </paper>
    <paper id="55">
      <title><fixed-case>E</fixed-case>stonian-Centric Machine Translation: Data, Models, and Challenges</title>
      <author><first>Elizaveta</first><last>Korotkova</last><affiliation>University of Tartu</affiliation></author>
      <author><first>Mark</first><last>Fishel</last><affiliation>University of Tartu</affiliation></author>
      <pages>647-660</pages>
      <abstract>Machine translation (MT) research is most typically English-centric. In recent years, massively multilingual translation systems have also been increasingly popular. However, efforts purposefully focused on less-resourced languages are less widespread. In this paper, we focus on MT from and into the Estonian language. First, emphasizing the importance of data availability, we generate and publicly release a back-translation corpus of over 2 billion sentence pairs. Second, using these novel data, we create MT models covering 18 translation directions, all either from or into Estonian. We re-use the encoder of the NLLB multilingual model and train modular decoders separately for each language, surpassing the original NLLB quality. Our resulting MT models largely outperform other open-source MT systems, including previous Estonian-focused efforts, and are released as part of this submission.</abstract>
      <url hash="f255f90a">2024.eamt-1.55</url>
      <bibkey>korotkova-fishel-2024-estonian</bibkey>
    </paper>
  </volume>
  <volume id="2" ingest-date="2024-09-22" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 25th Annual Conference of the European Association for Machine Translation (Volume 2)</booktitle>
      <editor><first>Carolina</first><last>Scarton</last></editor>
      <editor><first>Charlotte</first><last>Prescott</last></editor>
      <editor><first>Chris</first><last>Bayliss</last></editor>
      <editor><first>Chris</first><last>Oakley</last></editor>
      <editor><first>Joanna</first><last>Wright</last></editor>
      <editor><first>Stuart</first><last>Wrigley</last></editor>
      <editor><first>Xingyi</first><last>Song</last></editor>
      <editor><first>Edward</first><last>Gow-Smith</last></editor>
      <editor><first>Mikel</first><last>Forcada</last></editor>
      <editor><first>Helena</first><last>Moniz</last></editor>
      <publisher>European Association for Machine Translation (EAMT)</publisher>
      <address>Sheffield, UK</address>
      <month>June</month>
      <year>2024</year>
      <url hash="3a3aae04">2024.eamt-2</url>
      <venue>eamt</venue>
    </meta>
    <frontmatter>
      <url hash="e3cc78e9">2024.eamt-2.0</url>
      <bibkey>eamt-2024-2</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Products &amp; Projects</title>
      <author><first>Page</first><last>Break</last></author>
      <pages>1-1</pages>
      <abstract>Products &amp; Projects</abstract>
      <url hash="f1ac3238">2024.eamt-2.1</url>
      <bibkey>break-2024-products</bibkey>
    </paper>
    <paper id="2">
      <title>Transitude: Machine Translation on Social Media: <fixed-case>MT</fixed-case> as a potential tool for opinion (mis)formation</title>
      <author><first>Khetam</first><last>Sharou</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Joss</first><last>Moorkens</last></author>
      <pages>2-3</pages>
      <abstract>Misinformation on social media is a concern for content creators, consumers and regulators alike. Transitude looks at misinformation generated by machine translation (MT) through distortion of the intention and sentiment of text. It is the first study of MT’s impact on the formation of users’ views of society through refugees in Ireland. It extends current MT evaluation methods with a new quality evaluation framework, producing the first dataset annotated for information distortion. It provides insights into the risks of relying on MT, with recommendations for users, developers, and policymakers.</abstract>
      <url hash="7c0f6ea1">2024.eamt-2.2</url>
      <bibkey>sharou-moorkens-2024-transitude</bibkey>
    </paper>
    <paper id="3">
      <title>Lightweight neural translation technologies for low-resource languages</title>
      <author><first>Felipe</first><last>Sánchez-Martínez</last><affiliation>University of Alicante</affiliation></author>
      <author><first>Juan Antonio</first><last>Pérez-Ortiz</last><affiliation>Universidad de Alicante</affiliation></author>
      <author><first>Víctor</first><last>Sánchez-Cartagena</last><affiliation>Universidad de Alicante</affiliation></author>
      <author><first>Andrés</first><last>Lou</last><affiliation>Universidad de Alicante</affiliation></author>
      <author><first>Cristian</first><last>García-Romero</last><affiliation>Universidad de Alicante</affiliation></author>
      <author><first>Aarón</first><last>Galiano-Jiménez</last><affiliation>Universidad de Alicante</affiliation></author>
      <author><first>Miquel</first><last>Esplà-Gomis</last><affiliation>Universidad de Alicante</affiliation></author>
      <pages>4-5</pages>
      <abstract>The LiLowLa (“Lightweight neural translation technologies for low-resource languages”) project aims to enhance machine translation (MT) and translation memory (TM) technologies, particularly for low-resource language pairs, where adequate linguistic resources are scarce. The project started in September 2022 and will run till August 2025.</abstract>
      <url hash="9d2f482b">2024.eamt-2.3</url>
      <bibkey>sanchez-martinez-etal-2024-lightweight</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>M</fixed-case>a<fixed-case>TIAS</fixed-case>: Machine Translation to Inform Asylum Seekers</title>
      <author><first>Lieve</first><last>Macken</last><affiliation>Universiteit Gent</affiliation></author>
      <author><first>Ella</first><last>Hest</last><affiliation>Universiteit Gent</affiliation></author>
      <author><first>Arda</first><last>Tezcan</last><affiliation>Universiteit Gent</affiliation></author>
      <author><first>Michaël</first><last>Lumingu</last><affiliation>NA</affiliation></author>
      <author><first>Katrijn</first><last>Maryns</last><affiliation>NA</affiliation></author>
      <author><first>July</first><last>Wilde</last><affiliation>NA</affiliation></author>
      <pages>6-7</pages>
      <abstract>This project aims to develop a multilingual notification system for asylum reception centres in Belgium using machine translation. The system will allow staff to communicate practical messages to residents in their own language. Ethnographically inspired fieldwork is being conducted in reception centres to understand current communication practices and ensure that the technology meets user needs. The quality and suitability of machine translation will be evaluated for three MT systems supporting all target languages. Automatic and manual evaluation methods will be used to assess translation quality, and terms of use, privacy and data protection conditions will be analysed.</abstract>
      <url hash="944af94d">2024.eamt-2.4</url>
      <bibkey>macken-etal-2024-matias</bibkey>
    </paper>
    <paper id="5">
      <title><fixed-case>S</fixed-case>mart<fixed-case>B</fixed-case>i<fixed-case>C</fixed-case>: Smart Harvesting of Bilingual Corpora from the <fixed-case>I</fixed-case>nternet</title>
      <author><first>Gema</first><last>Ramírez-Sánchez</last></author>
      <author><first>Sergio</first><last>Ortiz Rojas</last><affiliation>Prompsit Language Engineering SL</affiliation></author>
      <author><first>Alicia</first><last>Núñez Alcover</last><affiliation>NA</affiliation></author>
      <author><first>Tudor</first><last>Mateiu</last><affiliation>NA</affiliation></author>
      <author><first>Mikel</first><last>Forcada</last></author>
      <author><first>Pedro</first><last>Orzas</last><affiliation>Universidad Complutense de Madrid</affiliation></author>
      <author><first>Almudena</first><last>Carrillo</last><affiliation>NA</affiliation></author>
      <author><first>Giuseppe</first><last>Nolasco</last><affiliation>NA</affiliation></author>
      <author><first>Noelia</first><last>Listón</last><affiliation>NA</affiliation></author>
      <pages>8-9</pages>
      <abstract>SmartBiC, an 18-month innovation project funded by the Spanish Government, aims at improving the full process of collecting, filtering and selecting in-domain parallel content to be used for machine translation and language model tuning purposes in industrial settings. Based on state-of-the-art technology in the free/open-source parallel web corpora harvester Bitextor, SmartBic develops a web-based application around it including novel components such as a language- and domain-focused crawler and a domain-specific corpora selector. SmartBic also addresses specific industrial use cases for individual components of the Bitextor pipeline, such as parallel data cleaning. Relevant improvements to the current Bitextor pipeline will be publicly released.</abstract>
      <url hash="713e81c0">2024.eamt-2.5</url>
      <bibkey>ramirez-sanchez-etal-2024-smartbic</bibkey>
    </paper>
    <paper id="6">
      <title>An Eye-Tracking Study on the Use of Machine Translation Post-Editing and Automatic Speech Recognition in Translations for the Medical Domain</title>
      <author><first>Raluca</first><last>Chereji</last></author>
      <pages>10-11</pages>
      <abstract>This EAMT-funded eye-tracking study investigates the impact of Machine Translation Post-Editing and Automatic Speech Recognition on English-Romanian translations of patient-facing medical texts. This paper provides an overview of the study objectives, setup and preliminary results.</abstract>
      <url hash="4e69ac7d">2024.eamt-2.6</url>
      <bibkey>chereji-2024-eye</bibkey>
    </paper>
    <paper id="7">
      <title>The <fixed-case>MAKE</fixed-case>-<fixed-case>NMTV</fixed-case>iz Project: Meaningful, Accurate and Knowledge-limited Explanations of <fixed-case>NMT</fixed-case> Systems for Translators</title>
      <author><first>Gabriela</first><last>Gonzalez-Saez</last></author>
      <author><first>Fabien</first><last>Lopez</last><affiliation>Université Grenoble Alpes</affiliation></author>
      <author><first>Mariam</first><last>Nakhle</last></author>
      <author><first>James</first><last>Turner</last><affiliation>Swansea University</affiliation></author>
      <author><first>Nicolas</first><last>Ballier</last></author>
      <author><first>Marco</first><last>Dinarelli</last><affiliation>CNRS</affiliation></author>
      <author><first>Emmanuelle</first><last>Esperança-Rodier</last><affiliation>University of Grenoble-Alpes</affiliation></author>
      <author><first>Sui</first><last>He</last><affiliation>Swansea University</affiliation></author>
      <author><first>Caroline</first><last>Rossi</last><affiliation>Université Grenoble Alpes</affiliation></author>
      <author><first>Didier</first><last>Schwab</last><affiliation>Université Grenoble Alpes</affiliation></author>
      <author><first>Jun</first><last>Yang</last><affiliation>Swansea University</affiliation></author>
      <pages>12-13</pages>
      <abstract>This paper describes MAKE-NMTViz, a project designed to help translators visualize neural machine translation outputs using explainable artificial intelligence visualization tools initially developed for computer vision.</abstract>
      <url hash="ebc61048">2024.eamt-2.7</url>
      <bibkey>gonzalez-saez-etal-2024-make</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>MULTILINGTOOL</fixed-case>, Development of an Automatic Multilingual Subtitling and Dubbing System</title>
      <author><first>Xabier</first><last>Saralegi</last></author>
      <author><first>Ander</first><last>Corral</last><affiliation>Orai NLP Technologies</affiliation></author>
      <author><first>Igor</first><last>Leturia</last><affiliation>NA</affiliation></author>
      <author><first>Xabier</first><last>Sarasola</last></author>
      <author><first>Josu</first><last>Murua</last><affiliation>NA</affiliation></author>
      <author><first>Iker</first><last>Manterola</last><affiliation>NA</affiliation></author>
      <author><first>Itziar</first><last>Cortes</last><affiliation>NA</affiliation></author>
      <pages>14-15</pages>
      <abstract>In this paper, we present the MULTILINGTOOL project, led by the Elhuyar Foundation and funded by the European Commission under the CREA-MEDIA2022-INNOVBUSMOD call. The aim of the project is to develop an advanced platform for automatic multilingual subtitling and dubbing. It will provide support for Spanish, English, and French, as well as the co-official languages of Spain, namely Basque, Catalan, and Galician.</abstract>
      <url hash="17e34d84">2024.eamt-2.8</url>
      <bibkey>saralegi-etal-2024-multilingtool</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>ERC</fixed-case> Advanced Grant Project <fixed-case>CALCULUS</fixed-case>: Extending the Boundary of Machine Translation</title>
      <author><first>Jingyuan</first><last>Sun</last></author>
      <author><first>Mingxiao</first><last>Li</last></author>
      <author><first>Ruben</first><last>Cartuyvels</last></author>
      <author><first>Marie-Francine</first><last>Moens</last><affiliation>KU Leuven, KU Leuven</affiliation></author>
      <pages>16-17</pages>
      <abstract>The CALCULUS project, drawing on human capabilities of imagination and commonsense for natural language understanding (NLU), aims to advance machine-based NLU by integrating traditional AI concepts with contemporary machine learning techniques. It focuses on developing anticipatory event representations from both textual and visual data, connecting language structure to visual spatial organization and incorporating broad knowledge domains. Through testing these models in NLU tasks and evaluating their ability to predict untrained spatial and temporal details using real-world metrics, CALCULUS employs machine learning methods, including Bayesian techniques and neural networks, especially in data-sparse scenarios. The project’s culmination involves creating demonstrators that transform written stories into dynamic videos, showcasing the interdisciplinary expertise of the project leader in natural language processing, language and visual data analysis, information retrieval, and machine learning, all vital for the project’s achievements. In the CALCULUS project, our exploration of machine translation extends beyond the conventional text-to-text framework. We are broadening the horizons of machine translation by delving into the essence of transforming the formats of data distribution while keeping the meaning. This innovative approach involves converting information from one modality into another, transcending traditional linguistic boundaries. Our project includes novel work on translating text into images and videos, brain signals into images and videos.</abstract>
      <url hash="400120d6">2024.eamt-2.9</url>
      <bibkey>sun-etal-2024-erc</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>GAMETRAPP</fixed-case> project in progress: Designing a gamified environment for post-editing research abstracts</title>
      <author><first>Laura</first><last>Noriega-Santiáñez</last></author>
      <author><first>Cristina</first><last>Toledo-Báez</last><affiliation>NA</affiliation></author>
      <pages>18-20</pages>
      <abstract>The «App for post-editing neural machine translation using gamification» (GAMETRAPP) project (TED2021-129789B-I00), funded by the Spanish Ministry of Science and Innovation (2022–2024), has been in progress for a year. Thus, this paper presents its main goals and the analysis of neural machine translation and post-editing errors of research abstracts carried out. This leads to the designing of the gamified environment, which is currently under construction.</abstract>
      <url hash="e8160ebe">2024.eamt-2.10</url>
      <bibkey>noriega-santianez-toledo-baez-2024-gametrapp</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>RC</fixed-case>num: A Semantic and Multilingual Online Edition of the Geneva Council Registers from 1545 to 1550</title>
      <author><first>Pierrette</first><last>Bouillon</last><affiliation>University of Geneva</affiliation></author>
      <author><first>Christophe</first><last>Chazalon</last></author>
      <author><first>Sandra</first><last>Coram-Mekkey</last></author>
      <author><first>Gilles</first><last>Falquet</last><affiliation>University of Geneva, Switzerland</affiliation></author>
      <author><first>Johanna</first><last>Gerlach</last><affiliation>University of Geneva</affiliation></author>
      <author><first>Stephane</first><last>Marchand-Maillet</last><affiliation>University of Geneva, Switzerland</affiliation></author>
      <author><first>Laurent</first><last>Moccozet</last><affiliation>University of Genoa</affiliation></author>
      <author><first>Jonathan</first><last>Mutal</last></author>
      <author><first>Raphael</first><last>Rubino</last><affiliation>University of Geneva</affiliation></author>
      <author><first>Marco</first><last>Sorbi</last></author>
      <pages>21-22</pages>
      <abstract>The RCnum project is funded by the Swiss National Science Foundation and aims at producing a multilingual and semantically rich online edition of the Registers of Geneva Council from 1545 to 1550. Combining multilingual NLP, history and paleography, this collaborative project will clear hurdles inherent to texts manually written in 16th century Middle French while allowing for easy access and interactive consultation of these archives.</abstract>
      <url hash="52b3f7fd">2024.eamt-2.11</url>
      <bibkey>bouillon-etal-2024-rcnum</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>MTPE</fixed-case> quality evaluation in translator education: the postedit.me app</title>
      <author><first>Marie-Aude</first><last>Lefer</last><affiliation>UCLouvain</affiliation></author>
      <author><first>Romane</first><last>Bodart</last></author>
      <author><first>Justine</first><last>Piette</last><affiliation>NA</affiliation></author>
      <author><first>Adam</first><last>Obrusník</last><affiliation>NA</affiliation></author>
      <pages>23-24</pages>
      <abstract>This article presents the main functionality of the postedit.me app. Postedit.me is a software program that supports machine translation post-editing training in translator education, with special emphasis on standardized quality evaluation of post-edited texts produced by students. The app is made freely available to universities for teaching and research purposes.</abstract>
      <url hash="7b6386af">2024.eamt-2.12</url>
      <bibkey>lefer-etal-2024-mtpe</bibkey>
    </paper>
    <paper id="13">
      <title>Boosting Machine Translation with <fixed-case>AI</fixed-case>-powered terminology features</title>
      <author><first>Marek</first><last>Sabo</last><affiliation>NA</affiliation></author>
      <author><first>Judith</first><last>Klein</last><affiliation>STAR Group</affiliation></author>
      <author><first>Giorgio</first><last>Bernardinello</last></author>
      <pages>25-26</pages>
      <abstract>Artificial intelligence (AI) is quickly becoming an exciting new technology for the translation industry in form of large language models (LLMs). AI-based functionality could be used to improve the output of neural machine translation (NMT). One main issue that impacts MT quality and reliability is incorrect terminology. This is why STAR is making AI-powered terminology control a priority for its translation products because of the significant gains to be made - greatly improving the quality of MT output, reducing post editing (PE) costs and efforts, and thereby boosting overall translation productivity.</abstract>
      <url hash="2e7f747b">2024.eamt-2.13</url>
      <bibkey>sabo-etal-2024-boosting</bibkey>
    </paper>
    <paper id="14">
      <title>Automatic detection of (potential) factors in the source text leading to gender bias in machine translation</title>
      <author><first>Janiça</first><last>Hackenbuchner</last></author>
      <author><first>Arda</first><last>Tezcan</last></author>
      <author><first>Joke</first><last>Daems</last></author>
      <pages>27-28</pages>
      <abstract>This research project aims to develop a comprehensive methodology to help make machine translation (MT) systems more gender-inclusive for society. The goal is the creation of a detection system, a machine learning (ML) model trained on manual annotations, that can automatically analyse source data and detect and highlight words and phrases that influence the gender bias inflection in target translations.The main research outputs will be (1) a manually annotated dataset, (2) a taxonomy, and (3) a fine-tuned model.</abstract>
      <url hash="0c33721d">2024.eamt-2.14</url>
      <bibkey>hackenbuchner-etal-2024-automatic</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>INCREC</fixed-case>: Uncovering the creative process of translated content using machine translation</title>
      <author><first>Ana</first><last>Guerberof-Arenas</last><affiliation>University of Groningen</affiliation></author>
      <pages>29-30</pages>
      <abstract>The INCREC project aims to uncover professional translators’ creative stages to understand how technology can be best applied to the translation of literary and audio-visual texts, and to analyse the impact of these processes on readers and viewers. To better understand this process, INCREC triangulates data from eye-tracking, retrospective think-aloud inter-views, translated material, and questionnaires from professional translators and users.</abstract>
      <url hash="64f471ee">2024.eamt-2.15</url>
      <bibkey>guerberof-arenas-2024-increc</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>SMUGRI</fixed-case>-<fixed-case>MT</fixed-case> - Machine Translation System for Low-Resource <fixed-case>F</fixed-case>inno-<fixed-case>U</fixed-case>gric Languages</title>
      <author><first>Taido</first><last>Purason</last></author>
      <author><first>Aleksei</first><last>Ivanov</last><affiliation>NA</affiliation></author>
      <author><first>Lisa</first><last>Yankovskaya</last></author>
      <author><first>Mark</first><last>Fishel</last><affiliation>University of Tartu</affiliation></author>
      <pages>31-32</pages>
      <abstract>We introduce SMUGRI-MT, an online neural machine translation system that covers 20 low-resource Finno-Ugric languages, along with seven high-resource languages.</abstract>
      <url hash="34d06132">2024.eamt-2.16</url>
      <bibkey>purason-etal-2024-smugri</bibkey>
    </paper>
    <paper id="17">
      <title>plain <fixed-case>X</fixed-case>: 4-in-1 multilingual adaptation platform</title>
      <author><first>Peggy</first><last>Kreeft</last><affiliation>Deutsche Welle Innovation</affiliation></author>
      <author><first>Mirko</first><last>Lorenz</last><affiliation>Deutsche Welle</affiliation></author>
      <author><first>Carlos</first><last>Amaral</last><affiliation>NA</affiliation></author>
      <pages>33-34</pages>
      <abstract>plain X is a 4-in-1 solution for language adaptation. The software is an outcome of European HLT research and is by now in use as the major artificial-intelligence-powered human language pro-cessing platform at Deutsche Welle. plain X is a one-stop-shop for automated transcription, translation, subtitling and voice-over, with human correction options at all stages. We demonstrate how the platform works and show new features and developments of the platform in the framework of the SELMA project.</abstract>
      <url hash="b67194dd">2024.eamt-2.17</url>
      <bibkey>kreeft-etal-2024-plain</bibkey>
    </paper>
    <paper id="18">
      <title>The <fixed-case>B</fixed-case>ridge<fixed-case>AI</fixed-case> Project</title>
      <author><first>Helena</first><last>Moniz</last><affiliation>Universidade de Lisboa</affiliation></author>
      <author><first>Joana</first><last>Lamego</last></author>
      <author><first>Nuno</first><last>André</last><affiliation>NA</affiliation></author>
      <author><first>António</first><last>Novais</last><affiliation>Nova School of Business and Economics</affiliation></author>
      <author><first>Bruno</first><last>Silva</last><affiliation>NA</affiliation></author>
      <author><first>Maria</first><last>Henriques</last><affiliation>NA</affiliation></author>
      <author><first>Mariana</first><last>Dalblon</last><affiliation>NA</affiliation></author>
      <author><first>Paulo</first><last>Dimas</last><affiliation>NA</affiliation></author>
      <author><first>Pedro</first><last>Gonçalves</last><affiliation>NA</affiliation></author>
      <pages>35-36</pages>
      <abstract>This paper describes the project “BridgeAI: Boosting Regulatory Implementation with Data-driven insights, Global expertise, and Ethics for AI”, a one-year science-for-policy research project funded by the Portuguese Foundation for Science and Technology (FCT). The project aims to provide decision-makers in Portugal with the best context to implement the EU Artificial Intelligence (AI) Act and bridge the gap between AI research and policy. Although not exclusively on machine translation, the project pertains to natural language processing in general and ultimately to each of us as citizens.</abstract>
      <url hash="d7e72467">2024.eamt-2.18</url>
      <bibkey>moniz-etal-2024-bridgeai</bibkey>
    </paper>
    <paper id="19">
      <title><fixed-case>G</fixed-case>e<fixed-case>FMT</fixed-case>: Gender-Fair Language in <fixed-case>G</fixed-case>erman Machine Translation</title>
      <author><first>Manuel</first><last>Lardelli</last></author>
      <author><first>Anne</first><last>Lauscher</last><affiliation>Universität Hamburg</affiliation></author>
      <author><first>Giuseppe</first><last>Attanasio</last><affiliation>Instituto de Telecomunicações</affiliation></author>
      <pages>37-38</pages>
      <abstract>Research on gender bias in Machine Translation (MT) predominantly focuses on binary gender or few languages. In this project, we investigate the ability of commercial MT systems and neural models to translate using gender-fair language (GFL) from English into German. We enrich a community-created GFL dictionary, and sample multi-sentence test instances from encyclopedic text and parliamentary speeches. We translate our resources with different MT systems and open-weights models. We also plan to post-edit biased outputs with professionals and share them publicly. The outcome will constitute a new resource for automatic evaluation and modeling gender-fair EN-DE MT.</abstract>
      <url hash="87f27d94">2024.eamt-2.19</url>
      <bibkey>lardelli-etal-2024-gefmt</bibkey>
    </paper>
    <paper id="20">
      <title><fixed-case>E</fixed-case>x<fixed-case>U</fixed-case>: <fixed-case>AI</fixed-case> Models for Examining Multilingual Disinformation Narratives and Understanding their Spread</title>
      <author><first>Jake</first><last>Vasilakes</last><affiliation>University of Manchester</affiliation></author>
      <author><first>Zhixue</first><last>Zhao</last><affiliation>University of Sheffield, University of Sheffield</affiliation></author>
      <author><first>Michal</first><last>Gregor</last><affiliation>Kempelen Institute of Intelligent Technologies and University of Zilina</affiliation></author>
      <author><first>Ivan</first><last>Vykopal</last><affiliation>Kempelen Institute of Intelligent Technologies and Brno University of Technology</affiliation></author>
      <author><first>Martin</first><last>Hyben</last><affiliation>Kempelen Institute of Intelligent Technologies</affiliation></author>
      <author><first>Carolina</first><last>Scarton</last><affiliation>University of Sheffield</affiliation></author>
      <pages>39-40</pages>
      <abstract>Addressing online disinformation requires analysing narratives across languages to help fact-checkers and journalists sift through large amounts of data. The ExU project focuses on developing AI-based models for multilingual disinformation analysis, addressing the tasks of rumour stance classification and claim retrieval. We describe the ExU project proposal and summarise the results of a user requirements survey regarding the design of tools to support fact-checking.</abstract>
      <url hash="fba3b4e9">2024.eamt-2.20</url>
      <bibkey>vasilakes-etal-2024-exu</bibkey>
    </paper>
    <paper id="21">
      <title>Multilinguality in the <fixed-case>VIGILANT</fixed-case> project</title>
      <author><first>Brendan</first><last>Spillane</last><affiliation>University College Dublin</affiliation></author>
      <author><first>Carolina</first><last>Scarton</last><affiliation>University of Sheffield</affiliation></author>
      <author><first>Robert</first><last>Moro</last><affiliation>Kempelen Institute of Intelligent Technologies</affiliation></author>
      <author><first>Petar</first><last>Ivanov</last><affiliation>NA</affiliation></author>
      <author><first>Andrey</first><last>Tagarev</last><affiliation>NA</affiliation></author>
      <author><first>Jakub</first><last>Simko</last><affiliation>Kempelen Institute of Intelligent Technologies</affiliation></author>
      <author><first>Ibrahim</first><last>Abu Farha</last><affiliation>University of Sheffield</affiliation></author>
      <author><first>Gary</first><last>Munnelly</last></author>
      <author><first>Filip</first><last>Uhlárik</last><affiliation>NA</affiliation></author>
      <author><first>Freddy</first><last>Heppell</last></author>
      <pages>41-42</pages>
      <abstract>VIGILANT (Vital IntelliGence to Investigate ILlegAl DisiNformaTion) is a three-year Horizon Europe project that will equip European Law Enforcement Agencies (LEAs) with advanced disinformation detection and analysis tools to investigate and prevent criminal activities linked to disinformation. These include disinformation instigating violence towards minorities, promoting false medical cures, and increasing tensions between groups causing civil unrest and violent acts. VIGILANT’s four LEAs require support for English, Spanish, Catalan, Greek, Estonian, Romanian and Russian. Therefore, multilinguality is a major challenge and we present the current status of our tools and our plans to improve their performance.</abstract>
      <url hash="b6598f04">2024.eamt-2.21</url>
      <bibkey>spillane-etal-2024-multilinguality</bibkey>
    </paper>
    <paper id="22">
      <title>Evaluating Machine Translation for Emotion-loaded User Generated Content (<fixed-case>T</fixed-case>rans<fixed-case>E</fixed-case>val4<fixed-case>E</fixed-case>mo-<fixed-case>UGC</fixed-case>)</title>
      <author><first>Shenbin</first><last>Qian</last></author>
      <author><first>Constantin</first><last>Orasan</last><affiliation>University of Surrey</affiliation></author>
      <author><first>Félix</first><last>Do Carmo</last><affiliation>University of Surrey</affiliation></author>
      <author><first>Diptesh</first><last>Kanojia</last><affiliation>University of Surrey</affiliation></author>
      <pages>43-44</pages>
      <abstract>This paper presents a dataset for evaluating the machine translation of emotion-loaded user generated content. It contains human-annotated quality evaluation data and post-edited reference translations. The dataset is available at our GitHub repository.</abstract>
      <url hash="befc43f2">2024.eamt-2.22</url>
      <bibkey>qian-etal-2024-evaluating</bibkey>
    </paper>
    <paper id="23">
      <title>Community-driven machine translation for the <fixed-case>C</fixed-case>atalan language at Softcatalà</title>
      <author><first>Xavi</first><last>Ivars-Ribes</last><affiliation>NA</affiliation></author>
      <author><first>Jordi</first><last>Mas</last><affiliation>NA</affiliation></author>
      <author><first>Marc</first><last>Riera</last><affiliation>NA</affiliation></author>
      <author><first>Jaume</first><last>Ortolà</last><affiliation>NA</affiliation></author>
      <author><first>Mikel</first><last>Forcada</last></author>
      <author><first>David</first><last>Cànovas</last><affiliation>NA</affiliation></author>
      <pages>45-46</pages>
      <abstract>Among the services provided by Softcatalà, a non-profit 25-year-old grassroots organization that localizes software into Catalan and develops software to ease the generation of Catalan content, one of the most used is its machine translation (MT) service, which provides both rule-based MT and neural MT between Catalan and twelve other languages. Development occurs in a community-supported, transparent way by using free/open-source software and open language resources. This paper briefly describes the MT services at Softcatalà: the offered functionalities, the data, and the software used to provide them.</abstract>
      <url hash="53c9ce74">2024.eamt-2.23</url>
      <bibkey>ivars-ribes-etal-2024-community</bibkey>
    </paper>
    <paper id="24">
      <title>The <fixed-case>MT</fixed-case>x<fixed-case>G</fixed-case>ames Project: Creative Video Games and Machine Translation – Different Post-Editing Methods in the Translation Process</title>
      <author><first>Judith</first><last>Brenner</last><affiliation>University of Eastern Finland and Technische Hochschule Köln</affiliation></author>
      <pages>47-48</pages>
      <abstract>MTxGames is a doctoral research project examining three different machine translation (MT) post-editing (PE) methods in the context of translating creative texts from video games, focusing on translation speed, cognitive effort, quality, and translators’ preferences. This is a mixed-methods study, eliciting quantitative data through keylogging, eye-tracking, and error evaluation as well as qualitative data through interviews. To create realistic experimental conditions, data elicitation takes place at the workplaces of freelancing professional game translators.</abstract>
      <url hash="f649383b">2024.eamt-2.24</url>
      <bibkey>brenner-2024-mtxgames</bibkey>
    </paper>
    <paper id="25">
      <title><fixed-case>S</fixed-case>ign<fixed-case>ON</fixed-case> – a Co-creative Machine Translation for Sign and Spoken Languages (end-of-project results, contributions and lessons learned)</title>
      <author><first>Dimitar</first><last>Shterionov</last><affiliation>Tilburg University</affiliation></author>
      <author><first>Vincent</first><last>Vandeghinste</last><affiliation>Instituut voor de Nederlandse Taal, KU Leuven and KU Leuven</affiliation></author>
      <author><first>Mirella</first><last>Sisto</last><affiliation>Tilburg University</affiliation></author>
      <author><first>Aoife</first><last>Brady</last><affiliation>NA</affiliation></author>
      <author><first>Mathieu</first><last>De Coster</last><affiliation>Universiteit Gent</affiliation></author>
      <author><first>Lorraine</first><last>Leeson</last><affiliation>NA</affiliation></author>
      <author><first>Andy</first><last>Way</last><affiliation>NA</affiliation></author>
      <author><first>Josep</first><last>Blat</last><affiliation>Universitat Pompeu Fabra</affiliation></author>
      <author><first>Frankie</first><last>Picron</last><affiliation>NA</affiliation></author>
      <author><first>Davy</first><last>Landuyt</last><affiliation>NA</affiliation></author>
      <author><first>Marcello</first><last>Scipioni</last><affiliation>NA</affiliation></author>
      <author><first>Aditya</first><last>Parikh</last><affiliation>NA</affiliation></author>
      <author><first>Louis</first><last>Bosch</last><affiliation>NA</affiliation></author>
      <author><first>John</first><last>O’Flaherty</last><affiliation>NA</affiliation></author>
      <author><first>Joni</first><last>Dambre</last><affiliation>Universiteit Gent</affiliation></author>
      <author><first>Caro</first><last>Brosens</last><affiliation>NA</affiliation></author>
      <author><first>Jorn</first><last>Rijckaert</last><affiliation>NA</affiliation></author>
      <author><first>Víctor</first><last>Ubieto</last></author>
      <author><first>Bram</first><last>Vanroy</last><affiliation>Instituut voor de Nederlandse Taal and KU Leuven</affiliation></author>
      <author><first>Santiago</first><last>Gomez</last><affiliation>NA</affiliation></author>
      <author><first>Ineke</first><last>Schuurman</last></author>
      <author><first>Gorka</first><last>Labaka</last><affiliation>Universidad del País Vasco</affiliation></author>
      <author><first>Adrián</first><last>Núñez-Marcos</last><affiliation>NA</affiliation></author>
      <author><first>Irene</first><last>Murtagh</last></author>
      <author><first>Euan</first><last>McGill</last><affiliation>Universitat Pompeu Fabra</affiliation></author>
      <author><first>Horacio</first><last>Saggion</last><affiliation>Universitat Pompeu Fabra and Universitat Pompeu Fabra</affiliation></author>
      <pages>49-50</pages>
      <abstract>SignON, a 3-year Horizon 20202 project addressing the lack of technology and services for MT between sign languages (SLs) and spoken languages (SpLs) ended in December 2023. SignON was unprecedented. Not only it addressed the wider complexity of the aforementioned problem – from research and development of recognition, translation and synthesis, through development of easy-to-use mobile applications and a cloud-based framework to do the “heavy lifting” as well as to establishing ethical, privacy and inclusivenesspolicies and operation guidelines – but also engaged with the deaf and hard of hearing communities in an effective co-creation approach where these main stakeholders drove the development in the right direction and had the final say.Currently we are witnessing advances in natural language processing for SLs, including MT. SignON was one of the largest projects that contributed to this surge with 17 partners and more than 60 consortium members, working in parallel with other international and European initiatives, such as project EASIER and others.</abstract>
      <url hash="94160a11">2024.eamt-2.25</url>
      <bibkey>shterionov-etal-2024-signon</bibkey>
    </paper>
    <paper id="26">
      <title>The Use of <fixed-case>MT</fixed-case> by humanitarian <fixed-case>NGO</fixed-case>s in <fixed-case>H</fixed-case>ong <fixed-case>K</fixed-case>ong</title>
      <author><first>Marija</first><last>Todorova</last><affiliation>Hong Kong Baptist University</affiliation></author>
      <author><first>Rachel Hang Yi</first><last>Liu</last><affiliation>Hong Kong Baptist University</affiliation></author>
      <pages>51-52</pages>
      <abstract>In the relief operations of international humanitarian organisations, non-governmental organisations (NGOs) often encounter language needs when delivering services (Tesseur 2022). This project examines the language needs of humanitarian NGOs working from Hong Kong and the solutions they adopted to overcome the language barriers when delivering international humanitarian relief to other countries.</abstract>
      <url hash="672daad0">2024.eamt-2.26</url>
      <bibkey>todorova-liu-2024-use</bibkey>
    </paper>
    <paper id="27">
      <title><fixed-case>HPLT</fixed-case>’s First Release of Data and Models</title>
      <author><first>Nikolay</first><last>Arefyev</last><affiliation>University of Oslo</affiliation></author>
      <author><first>Mikko</first><last>Aulamo</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Pinzhen</first><last>Chen</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Ona</first><last>De Gibert Bonet</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Barry</first><last>Haddow</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Jindřich</first><last>Helcl</last><affiliation>Edinburgh University, University of Edinburgh</affiliation></author>
      <author><first>Bhavitvya</first><last>Malik</last><affiliation>Edinburgh University, University of Edinburgh</affiliation></author>
      <author><first>Gema</first><last>Ramírez-Sánchez</last></author>
      <author><first>Pavel</first><last>Stepachev</last><affiliation>University of Edinburgh, University of Edinburgh</affiliation></author>
      <author><first>Jörg</first><last>Tiedemann</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Dušan</first><last>Variš</last><affiliation>Charles University Prague</affiliation></author>
      <author><first>Jaume</first><last>Zaragoza-Bernabeu</last><affiliation>Prompsit Language Engineering</affiliation></author>
      <pages>53-54</pages>
      <abstract>The High Performance Language Technologies (HPLT) project is a 3-year EU-funded project that started in September 2022. It aims to deliver free, sustainable, and reusable datasets, models, and workflows at scale using high-performance computing. We describe the first results of the project. The data release includes monolingual data in 75 languages at 5.6T tokens and parallel data in 18 language pairs at 96M pairs, derived from 1.8 petabytes of web crawls. Building upon automated and transparent pipelines, the first machine translation (MT) models as well as large language models (LLMs) have been trained and released. Multiple data processing tools and pipelines have also been made public.</abstract>
      <url hash="1ca75153">2024.eamt-2.27</url>
      <bibkey>arefyev-etal-2024-hplts</bibkey>
    </paper>
    <paper id="28">
      <title>Literacy in Digital Environments and Resources (<fixed-case>LT</fixed-case>-<fixed-case>L</fixed-case>i<fixed-case>DER</fixed-case>)</title>
      <author><first>Joss</first><last>Moorkens</last></author>
      <author><first>Pilar</first><last>Sánchez-Gijón</last><affiliation>Universitat Autònoma de Barcelona</affiliation></author>
      <author><first>Esther</first><last>Simon</last><affiliation>Universitat Autònoma de Barcelona</affiliation></author>
      <author><first>Mireia</first><last>Urpí</last><affiliation>NA</affiliation></author>
      <author><first>Nora</first><last>Aranberri</last><affiliation>Universidad del País Vasco</affiliation></author>
      <author><first>Dragoș</first><last>Ciobanu</last><affiliation>Universität Vienna</affiliation></author>
      <author><first>Ana</first><last>Guerberof-Arenas</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Janiça</first><last>Hackenbuchner</last></author>
      <author><first>Dorothy</first><last>Kenny</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Ralph</first><last>Krüger</last><affiliation>Fachhochschule Köln</affiliation></author>
      <author><first>Miguel</first><last>Rios</last><affiliation>Universität Vienna</affiliation></author>
      <author><first>Isabel</first><last>Ginel</last><affiliation>Dublin City University</affiliation></author>
      <author><first>Caroline</first><last>Rossi</last><affiliation>Université Grenoble Alpes</affiliation></author>
      <author><first>Alina</first><last>Secară</last><affiliation>Universität Vienna</affiliation></author>
      <author><first>Antonio</first><last>Toral</last><affiliation>University of Groningen</affiliation></author>
      <pages>55-56</pages>
      <abstract>LT-LiDER is an Erasmus+ cooperation project with two main aims. The first is to map the landscape of technological capabilities required to work as a language and/or translation expert in the digitalised and datafied language industry. The second is to generate training outputs that will help language and translation trainers improve their skills and adopt appropriate pedagogical approaches and strategies for integrating data-driven technology into their language or translation classrooms, with a focus on digital and AI literacy.</abstract>
      <url hash="f51b685a">2024.eamt-2.28</url>
      <bibkey>moorkens-etal-2024-literacy</bibkey>
    </paper>
    <paper id="29">
      <title>Cultural Transcreation with <fixed-case>LLM</fixed-case>s as a new product</title>
      <author><first>Beatriz</first><last>Silva</last><affiliation>Unbabel</affiliation></author>
      <author><first>Helena</first><last>Wu</last><affiliation>Faculty of Arts of the University of Lisbon</affiliation></author>
      <author><first>Yan</first><last>Jingxuan</last><affiliation>NA</affiliation></author>
      <author><first>Vera</first><last>Cabarrão</last><affiliation>Unbabel</affiliation></author>
      <author><first>Helena</first><last>Moniz</last><affiliation>Universidade de Lisboa</affiliation></author>
      <author><first>Sara</first><last>Guerreiro de Sousa</last><affiliation>NA</affiliation></author>
      <author><first>João</first><last>Almeida</last><affiliation>NA</affiliation></author>
      <author><first>Malene</first><last>Sjørslev Søholm</last><affiliation>NA</affiliation></author>
      <author><first>Ana</first><last>Farinha</last></author>
      <author><first>Paulo</first><last>Dimas</last><affiliation>NA</affiliation></author>
      <pages>57-58</pages>
      <abstract>We present how at Unbabel we have been using Large Language Models to apply a Cultural Transcreation (CT) product on customer support (CS) emails and how we have been testing the quality and potential of this product. We discuss our preliminary evaluation of the performance of different MT models in the task of translating rephrased content and the quality of the translation outputs. Furthermore, we introduce the live pilot programme and the corresponding relevant findings, showing that transcreated content is not only culturally adequate but it is also of high rephrasing and translation quality.</abstract>
      <url hash="138ccab1">2024.eamt-2.29</url>
      <bibkey>silva-etal-2024-cultural</bibkey>
    </paper>
    <paper id="30">
      <title><fixed-case>AI</fixed-case>4<fixed-case>C</fixed-case>ulture: Towards Multilingual Access for Cultural Heritage Data</title>
      <author><first>Tom</first><last>Vanallemeersch</last><affiliation>CrossLang</affiliation></author>
      <author><first>Sara</first><last>Szoc</last><affiliation>CrossLang</affiliation></author>
      <author><first>Laurens</first><last>Meeus</last></author>
      <pages>59-60</pages>
      <abstract>The AI4Culture project (2023-2025), funded by the European Commission, and involving a 12-partner consortium led by the National Technical University of Athens, develops a platform serving as an online capacity building hub for AI technologies in the cultural heritage (CH) sector, enabling multilingual access to CH data. It offers access to AI-related resources, including openly labelled datasets for model training and testing, deployable and reusable tools, and capacity building materials. The tools are aimed at optical character recognition (OCR) for printed and handwritten documents, subtitle generation and validation, machine translation (MT), and metadata enrichment via image information extraction and semantic linking. The project also customises these tools to enhance interface and component usability. We illustrate this with technology that corrects OCR output using language models and adapts it for MT.</abstract>
      <url hash="7a2eb4bc">2024.eamt-2.30</url>
      <bibkey>vanallemeersch-etal-2024-ai4culture</bibkey>
    </paper>
    <paper id="31">
      <title>The Center for Responsible <fixed-case>AI</fixed-case> Project</title>
      <author><first>Maria</first><last>Ana Henriques</last><affiliation>NA</affiliation></author>
      <author><first>Ana</first><last>Farinha</last></author>
      <author><first>Nuno</first><last>André</last><affiliation>NA</affiliation></author>
      <author><first>António</first><last>Novais</last><affiliation>Nova School of Business and Economics</affiliation></author>
      <author><first>Sara</first><last>Guerreiro de Sousa</last><affiliation>NA</affiliation></author>
      <author><first>Bruno</first><last>Prezado Silva</last><affiliation>NA</affiliation></author>
      <author><first>Ana</first><last>Oliveira</last><affiliation>NA</affiliation></author>
      <author><first>Helena</first><last>Moniz</last><affiliation>NA</affiliation></author>
      <author><first>Andre</first><last>Martins</last><affiliation>Instituto Superior Técnico and Unbabel</affiliation></author>
      <author><first>Paulo</first><last>Dimas</last><affiliation>NA</affiliation></author>
      <pages>61-62</pages>
      <abstract>This paper describes the project “NextGenAI: Center for Responsible AI”, a 39-month Mobilizing and Green Agenda for Business Innovation funded by the Portuguese Recovery and Resilience Plan, under the Recovery and Resilience Facility (RRF). The project aims to create a new Center for Responsible AI in Portugal, capable of delivering more than 20 AI products in crucial areas like “Life Sciences”, many of which use generative AI, particularly NLP models such as those for Machine Translation, contributing to translating into legislation the European Law included in the EU AI Act, and creating a critical mass in the development of responsible AI technologies. To accomplish this mission, the Center for Responsible AI is formed by an ecosystem of startups and research institutions driving research in a virtuous way by addressing real market needs and opportunities in Responsible AI.</abstract>
      <url hash="6604de75">2024.eamt-2.31</url>
      <bibkey>ana-henriques-etal-2024-center</bibkey>
    </paper>
  </volume>
  <event id="eamt-2024">
    <colocated>
      <volume-id>2024.kemt-1</volume-id>
      <volume-id>2024.gitt-1</volume-id>
      <volume-id>2024.ctt-1</volume-id>
    </colocated>
  </event>
</collection>
