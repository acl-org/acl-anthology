<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.nlp4ecology">
  <volume id="1" ingest-date="2025-03-25" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on Ecology, Environment, and Natural Language Processing (NLP4Ecology2025)</booktitle>
      <editor><first>Valerio</first><last>Basile</last></editor>
      <editor><first>Cristina</first><last>Bosco</last></editor>
      <editor><first>Francesca</first><last>Grasso</last></editor>
      <editor><first>Muhammad Okky</first><last>Ibrohim</last></editor>
      <editor><first>Maria</first><last>Skeppstedt</last></editor>
      <editor><first>Manfred</first><last>Stede</last></editor>
      <publisher>University of Tartu Library</publisher>
      <address>Tallinn, Estonia</address>
      <month>march</month>
      <year>2025</year>
      <url hash="0a79528f">2025.nlp4ecology-1</url>
      <venue>nlp4ecology</venue>
      <venue>ws</venue>
      <isbn>978-9908-53-114-4</isbn>
    </meta>
    <frontmatter>
      <url hash="eb1be866">2025.nlp4ecology-1.0</url>
      <bibkey>nlp4ecology-2025-1</bibkey>
    </frontmatter>
    <paper id="2">
      <title>From Data to Grassroots Initiatives: <fixed-case>Leveraging</fixed-case> Transformer-Based Models for Detecting Green Practices in Social Media</title>
      <author><first>Anna</first><last>Glazkova</last></author>
      <author><first>Olga</first><last>Zakharova</last></author>
      <pages>1–9</pages>
      <abstract>Green practices are everyday activities that support a sustainable relationship between people and the environment. Detecting these practices in social media helps track their prevalence and develop recommendations to promote eco-friendly actions. This study compares machine learning methods for identifying mentions of green waste practices as a multi-label text classification task. We focus on transformer-based models, which currently achieve state-of-the-art performance across various text classification tasks. Along with encoder-only models, we evaluate encoder-decoder and decoder-only architectures, including instruction-based large language models. Experiments on the GreenRu dataset, which consists of Russian social media texts, show the prevalence of the mBART encoder-decoder model. The findings of this study contribute to the advancement of natural language processing tools for ecological and environmental research, as well as the broader development of multi-label text classification methods in other domains.</abstract>
      <url hash="e51c1922">2025.nlp4ecology-1.2</url>
      <bibkey>glazkova-zakharova-2025-data</bibkey>
    </paper>
    <paper id="5">
      <title>Perspectives on Forests and Forestry in <fixed-case>Finnish</fixed-case> Online Discussions - A Topic Modeling Approach to Suomi24</title>
      <author><first>Telma</first><last>Peura</last></author>
      <author><first>Attila</first><last>Krizsán</last></author>
      <author><first>Salla-Riikka</first><last>Kuusalu</last></author>
      <author><first>Veronika</first><last>Laippala</last></author>
      <pages>10–15</pages>
      <abstract>This paper explores how forests and forest industry are perceived on the largest online discussion forum in Finland, Suomi24 (‘Finland24’). Using 30,636 posts published in 2014–2020, we investigate what kind of topics and perspectives towards forest management can be found. We use BERTopic as our topic modeling approach and evaluate the results of its different modular combinations. As the dataset is not labeled, we demonstrate the validity of our best model through illustrating some of the topics about forest use. The results show that a combination of UMAP and K-means leads to the best topic quality. Our exploratory qualitative analysis indicates that the posts reflect polarized discourses between the forest industry and forest conservation adherents.</abstract>
      <url hash="9db990b6">2025.nlp4ecology-1.5</url>
      <bibkey>peura-etal-2025-perspectives</bibkey>
    </paper>
    <paper id="6">
      <title>Mining for Species, Locations, Habitats, and Ecosystems from Scientific Papers in Invasion Biology: <fixed-case>A</fixed-case> Large-Scale Exploratory Study with Large Language Models</title>
      <author><first>Jennifer</first><last>D’Souza</last></author>
      <author><first>Zachary</first><last>Laubach</last></author>
      <author><first>Tarek Al</first><last>Mustafa</last></author>
      <author><first>Sina</first><last>Zarrieß</last></author>
      <author><first>Robert</first><last>Frühstückl</last></author>
      <author><first>Phyllis</first><last>Illari</last></author>
      <pages>16–23</pages>
      <abstract>This study explores the use of large language models (LLMs), specifically GPT-4o, to extract key ecological entities—species, locations, habitats, and ecosystems—from invasion biology literature. This information is critical for understanding species spread, predicting future invasions, and informing conservation efforts. Without domain-specific fine-tuning, we assess the potential and limitations of GPT-4o, out-of-the-box, for this task, highlighting the role of LLMs in advancing automated knowledge extraction for ecological research and management.</abstract>
      <url hash="b89d64fa">2025.nlp4ecology-1.6</url>
      <bibkey>dsouza-etal-2025-mining</bibkey>
    </paper>
    <paper id="7">
      <title>Large Language Models as Annotators of Named Entities in Climate Change and Biodiversity: <fixed-case>A</fixed-case> Preliminary Study</title>
      <author><first>Elena</first><last>Volkanovska</last></author>
      <pages>24–33</pages>
      <abstract>This paper examines whether few-shot techniques for Named Entity Recognition (NER) utilising existing large language models (LLMs) as their backbone can be used to reliably annotate named entities (NEs) in scientific texts on climate change and biodiversity. A series of experiments aim to assess whether LLMs can be integrated into an end-to-end pipeline that could generate token- or sentence-level NE annotations; the former being an ideal-case scenario that allows for seamless integration of existing with new token-level features in a single annotation pipeline. Experiments are run on four LLMs, two NER datasets, two input and output data formats, and ten and nine prompt versions per dataset. The results show that few-shot methods are far from being a silver bullet for NER in highly specialised domains, although improvement in LLM performance is observed for some prompt designs and some NE classes. Few-shot methods would find better use in a human-in-the-loop scenario, where an LLM’s output is verified by a domain expert.</abstract>
      <url hash="5c85136e">2025.nlp4ecology-1.7</url>
      <bibkey>volkanovska-2025-large</bibkey>
    </paper>
    <paper id="9">
      <title>Communicating urgency to prevent environmental damage: insights from a linguistic analysis of the <fixed-case>WWF24</fixed-case> multilingual corpus</title>
      <author><first>Cristina</first><last>Bosco</last></author>
      <author><first>Adriana Silvina</first><last>Pagano</last></author>
      <author><first>Elisa</first><last>Chierchiello</last></author>
      <pages>34–43</pages>
      <abstract>Contemporary environmental discourse focuses on effectively communicating ecological vulnerability to raise public awareness and encourage positive actions. Hence there is a need for studies to support accurate and adequate discourse production, both by humans and computers. Two main challenges need to be tackled. On the one hand, the language used to communicate about environment issues can be very complex for human and automatic analysis, there being few resources to train and test NLP tools. On the other hand, in the current international scenario, most texts are written in multiple languages or translated from a major to minor language, resulting in different meanings in different languages and cultural contexts. This paper presents a novel parallel corpus comprising the text of World Wide Fund (WWF) 2024 Annual Report in English and its translations into Italian and Brazilian Portuguese, and analyses their linguistic features.</abstract>
      <url hash="fc31cba4">2025.nlp4ecology-1.9</url>
      <bibkey>bosco-etal-2025-communicating</bibkey>
    </paper>
    <paper id="11">
      <title>Thematic Categorization on Pineapple Production in <fixed-case>C</fixed-case>osta <fixed-case>R</fixed-case>ica: <fixed-case>An</fixed-case> Exploratory Analysis through Topic Modeling</title>
      <author><first>Valentina Tretti</first><last>Beckles</last></author>
      <author><first>Adrian Vergara</first><last>Heidke</last></author>
      <pages>44–55</pages>
      <abstract>Costa Rica is one of the largest producers and exporters of pineapple in the world. This status has encouraged multinational companies to use plantations in this Central American country for experimentation and the cultivation of new varieties, such as the Pinkglow pineapple. However, pineapple monoculture has significant socio-environmental impacts on the regions where it is cultivated.In this exploratory study, we aimed to analyze how pineapple production is portrayed on the Internet. To achieve this, we collected a corpus of texts in Spanish and English from online sources in two phases: using the BootCat tool and manual search on newspaper websites. The Hierarchical Dirichlet Process (HDP) topic model was then applied to identify dominant topics within the corpus. These topics were subsequently classified into thematic categories, and the texts were categorized accordingly. The findings indicate that environmental issues related to pineapple cultivation are underrepresented on the Internet, particularly in comparison to the extensive focus on topics related to pineapple production and marketing.</abstract>
      <url hash="dc3828ec">2025.nlp4ecology-1.11</url>
      <bibkey>beckles-heidke-2025-thematic</bibkey>
    </paper>
    <paper id="12">
      <title>Entity Linking using <fixed-case>LLM</fixed-case>s for Automated Product Carbon Footprint Estimation</title>
      <author><first>Steffen</first><last>Castle</last></author>
      <author><first>Julian</first><last>Moreno Schneider</last></author>
      <pages>56–60</pages>
      <abstract>Growing concerns about climate change and sustainability are driving manufacturers to take significant steps toward reducing their carbon footprints. For these manufacturers, a first step towards this goal is to identify the environmental impact of the individual components of their products. We propose a system leveraging large language models (LLMs) to automatically map components from manufacturer Bills of Materials (BOMs) to Life Cycle Assessment (LCA) database entries by using LLMs to expand on available component information. Our approach reduces the need for manual data processing, paving the way for more accessible sustainability practices.</abstract>
      <url hash="2d8c424d">2025.nlp4ecology-1.12</url>
      <bibkey>castle-moreno-schneider-2025-entity</bibkey>
    </paper>
    <paper id="13">
      <title>Quantification of Biodiversity from Historical Survey Text with <fixed-case>LLM</fixed-case>-based Best-Worst-Scaling</title>
      <author><first>Thomas</first><last>Haider</last></author>
      <author><first>Tobias</first><last>Perschl</last></author>
      <author><first>Malte</first><last>Rehbein</last></author>
      <pages>61–67</pages>
      <abstract>In this study, we evaluate methods to determine the frequency of species via quantity estimation from historical survey text. To that end, we formulate classification tasks and finally show that this problem can be adequately framed as a regression task using Best-Worst Scaling (BWS) with Large Language Models (LLMs). We test Ministral-8B, DeepSeek-V3, and GPT-4, finding that the latter two have reasonable agreement with humans and each other. We conclude that this approach is more cost-effective and similarly robust compared to a fine-grained multi-class approach, allowing automated quantity estimation across species.</abstract>
      <url hash="b8d1597b">2025.nlp4ecology-1.13</url>
      <bibkey>haider-etal-2025-quantification</bibkey>
    </paper>
    <paper id="15">
      <title>Analyzing the Online Communication of Environmental Movement Organizations: <fixed-case>NLP</fixed-case> Approaches to Topics, Sentiment, and Emotions</title>
      <author><first>Christina</first><last>Barz</last></author>
      <author><first>Melanie</first><last>Siegel</last></author>
      <author><first>Daniel</first><last>Hanss</last></author>
      <pages>68–76</pages>
      <abstract>This project employs state-of-the-art Natural Language Processing (NLP) techniques to analyze the online communication of international Environmental Movement Organizations (EMOs). First, we introduce our overall EMO dataset and describe it through topic modeling. Second, we evaluate current sentiment and emotion classification models for our specific dataset. Third, as we are currently in our annotation process, we evaluate our current progress and issues to determine the most effective approach for creating a high-quality annotated dataset that captures the nuances of EMO communication. Finally, we emphasize the need for domain-specific datasets and tailored NLP tools and suggest refinements for our annotation process moving forward.</abstract>
      <url hash="4851286f">2025.nlp4ecology-1.15</url>
      <bibkey>barz-etal-2025-analyzing</bibkey>
    </paper>
    <paper id="17">
      <title>No <fixed-case>AI</fixed-case> on a Dead Planet: <fixed-case>Sentiment</fixed-case> and Emotion Analysis Across <fixed-case>R</fixed-case>eddit Communities on <fixed-case>AI</fixed-case> and the Environment</title>
      <author><first>Arianna</first><last>Longo</last></author>
      <author><first>Alessandro Y.</first><last>Longo</last></author>
      <pages>77–83</pages>
      <abstract>This paper investigates how different online communities perceive and discuss the environmental impact of AI through sentiment analysis and emotion detection. We analyze Reddit discussion from r/artificial and r/climatechange, using pre-trained models fine-tuned on social media data. Our analysis reveals distinct patterns in how these communities engage with AI’s environmental implications: the AI community demonstrates a shift from predominantly neutral and positive sentiment in posts to more balanced perspectives in comments, while the climate community maintains a more critical stance throughout discussions. The findings contribute to our understanding of how different communities conceptualize and respond to the environmental challenges of AI development.</abstract>
      <url hash="e575a913">2025.nlp4ecology-1.17</url>
      <bibkey>longo-longo-2025-ai</bibkey>
    </paper>
    <paper id="18">
      <title>Towards Addressing Anthropocentric Bias in Large Language Models</title>
      <author><first>Francesca</first><last>Grasso</last></author>
      <author><first>Stefano</first><last>Locci</last></author>
      <author><first>Luigi</first><last>Di Caro</last></author>
      <pages>84–93</pages>
      <abstract>The widespread use of Large Language Models (LLMs), particularly among non-expert users, has raised ethical concerns about the propagation of harmful biases. While much research has addressed social biases, few works, if any, have examined anthropocentric bias in Natural Language Processing (NLP) technology. Anthropocentric language prioritizes human value, framing non-human animals, living entities, and natural elements solely by their utility to humans; a perspective that contributes to the ecological crisis. In this paper, we evaluate anthropocentric bias in OpenAI’s GPT-4o across various target entities, including sentient beings, non-sentient entities, and natural elements. Using prompts eliciting neutral, anthropocentric, and ecocentric perspectives, we analyze the model’s outputs and introduce a manually curated glossary of 424 anthropocentric terms as a resource for future ecocritical research. Our findings reveal a strong anthropocentric bias in the model’s responses, underscoring the need to address human-centered language use in AI-generated text to promote ecological well-being.</abstract>
      <url hash="1bc92c8f">2025.nlp4ecology-1.18</url>
      <bibkey>grasso-etal-2025-towards</bibkey>
    </paper>
    <paper id="20">
      <title>Efficient Scientific Full Text Classification: <fixed-case>The</fixed-case> Case of <fixed-case>EICAT</fixed-case> Impact Assessments</title>
      <author><first>Marc Felix</first><last>Brinner</last></author>
      <author><first>Sina</first><last>Zarrieß</last></author>
      <pages>94–103</pages>
      <abstract>This study explores strategies for efficiently classifying scientific full texts using both small, BERT-based models and local large language models like Llama-3.1 8B. We focus on developing methods for selecting subsets of input sentences to reduce input size while simultaneously enhancing classification performance. To this end, we compile a novel dataset consisting of full-text scientific papers from the field of invasion biology, specifically addressing the impacts of invasive species. These papers are aligned with publicly available impact assessments created by researchers for the International Union for Conservation of Nature (IUCN). Through extensive experimentation, we demonstrate that various sources like human evidence annotations, LLM-generated annotations or explainability scores can be used to train sentence selection models that improve the performance of both encoder- and decoder-based language models while optimizing efficiency through the reduction in input length, leading to improved results even if compared to models like ModernBERT that are able to handle the complete text as input. Additionally, we find that repeated sampling of shorter inputs proves to be a very effective strategy that, at a slightly increased cost, can further improve classification performance.</abstract>
      <url hash="165cbb25">2025.nlp4ecology-1.20</url>
      <bibkey>brinner-zarriess-2025-efficient</bibkey>
    </paper>
    <paper id="21">
      <title>The Accuracy, Robustness, and Readability of <fixed-case>LLM</fixed-case>-Generated Sustainability-Related Word Definitions</title>
      <author><first>Alice</first><last>Heiman</last></author>
      <pages>104–109</pages>
      <abstract>A common language with shared standard definitions is essential for effective climate conversations. However, there is concern that LLMs may misrepresent and/or diversify climate-related terms. We compare 305 official IPCC glossary definitions with those generated by OpenAI’s GPT-4o-mini and investigate their adherence, robustness, and readability using a combination of SBERT sentence embeddings and statistical measures. The LLM definitions received average adherence and robustness scores of <tex-math>0.58 \pm 0.15</tex-math> and <tex-math>0.96 \pm 0.02</tex-math>, respectively. Both sustainability-related terminologies remain challenging to read, with model-generated definitions varying mainly among words with multiple or ambiguous definitions. Thus, the results highlight the potential of LLMs to support environmental discourse while emphasizing the need to align model outputs with established terminology for clarity and consistency.</abstract>
      <url hash="845504a4">2025.nlp4ecology-1.21</url>
      <bibkey>heiman-2025-accuracy</bibkey>
    </paper>
  </volume>
</collection>
