<?xml version='1.0' encoding='UTF-8'?>
<collection id="2022.case">
  <volume id="1" ingest-date="2022-12-07">
    <meta>
      <booktitle>Proceedings of the 5th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE)</booktitle>
      <editor><first>Ali</first><last>Hürriyetoğlu</last></editor>
      <editor><first>Hristo</first><last>Tanev</last></editor>
      <editor><first>Vanni</first><last>Zavarella</last></editor>
      <editor><first>Erdem</first><last>Yörük</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Abu Dhabi, United Arab Emirates (Hybrid)</address>
      <month>December</month>
      <year>2022</year>
      <url hash="76792564">2022.case-1</url>
      <venue>case</venue>
    </meta>
    <frontmatter>
      <url hash="66763527">2022.case-1.0</url>
      <bibkey>case-2022-challenges</bibkey>
    </frontmatter>
    <paper id="1">
      <title>A Multi-Modal Dataset for Hate Speech Detection on Social Media: Case-study of Russia-<fixed-case>U</fixed-case>kraine Conflict</title>
      <author><first>Surendrabikram</first><last>Thapa</last></author>
      <author><first>Aditya</first><last>Shah</last></author>
      <author><first>Farhan</first><last>Jafri</last></author>
      <author><first>Usman</first><last>Naseem</last></author>
      <author><first>Imran</first><last>Razzak</last></author>
      <pages>1-6</pages>
      <abstract>This paper presents a new multi-modal dataset for identifying hateful content on social media, consisting of 5,680 text-image pairs collected from Twitter, labeled across two labels. Experimental analysis of the presented dataset has shown that understanding both modalities is essential for detecting these techniques. It is confirmed in our experiments with several state-of-the-art multi-modal models. In future work, we plan to extend the dataset in size. We further plan to develop new multi-modal models tailored explicitly to hate-speech detection, aiming for a deeper understanding of the text and image relation. It would also be interesting to perform experiments in a direction that explores what social entities the given hate speech tweet targets.</abstract>
      <url hash="fc5cf4a5">2022.case-1.1</url>
      <bibkey>thapa-etal-2022-multi</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>E</fixed-case>vent<fixed-case>G</fixed-case>raph: Event Extraction as Semantic Graph Parsing</title>
      <author><first>Huiling</first><last>You</last></author>
      <author><first>David</first><last>Samuel</last></author>
      <author><first>Samia</first><last>Touileb</last></author>
      <author><first>Lilja</first><last>Øvrelid</last></author>
      <pages>7-15</pages>
      <abstract>Event extraction involves the detection and extraction of both the event triggers and the corresponding arguments. Existing systems often decompose event extraction into multiple subtasks, without considering their possible interactions. In this paper, we propose EventGraph, a joint framework for event extraction, which encodes events as graphs. We represent event triggers and arguments as nodes in a semantic graph. Event extraction therefore becomes a graph parsing problem, which provides the following advantages: 1) performing event detection and argument extraction jointly; 2) detecting and extracting multiple events from a piece of text; 3) capturing the complicated interaction between event arguments and triggers. Experimental results on ACE2005 show that our model is competitive to state-of-the-art systems and has substantially improved the results on argument extraction. Additionally, we create two new datasets from ACE2005 where we keep the entire text spans for event arguments, instead of just the head word(s). Our code and models will be released as open-source.</abstract>
      <url hash="520bef61">2022.case-1.2</url>
      <bibkey>you-etal-2022-eventgraph</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>NLP</fixed-case>4<fixed-case>ITF</fixed-case> @ Causal News Corpus 2022: Leveraging Linguistic Information for Event Causality Classification</title>
      <author><first>Theresa</first><last>Krumbiegel</last></author>
      <author><first>Sophie</first><last>Decher</last></author>
      <pages>16-20</pages>
      <abstract>We present our submission to Subtask 1 of theCASE-2022 Shared Task 3: Event CausalityIdentification with Causal News Corpus as partof the 5th Workshop on Challenges and Applicationsof Automated Extraction of SociopoliticalEvents from Text (CASE 2022) (Tanet al., 2022a). The task focuses on causal eventclassification on the sentence level and involvesdifferentiating between sentences that include acause-effect relation and sentences that do not.We approached this as a binary text classificationtask and experimented with multiple trainingsets augmented with additional linguisticinformation. Our best model was generated bytraining roberta-base on a combination ofdata from both Subtasks 1 and 2 with the additionof named entity annotations. During thedevelopment phase we achieved a macro F1 of0.8641 with this model on the development setprovided by the task organizers. When testingthe model on the final test data, we achieved amacro F1 of 0.8516.</abstract>
      <url hash="65d88a28">2022.case-1.3</url>
      <bibkey>krumbiegel-decher-2022-nlp4itf</bibkey>
    </paper>
    <paper id="4">
      <title>A Hybrid Knowledge and Transformer-Based Model for Event Detection with Automatic Self-Attention Threshold, Layer and Head Selection</title>
      <author><first>Thierry</first><last>Desot</last></author>
      <author><first>Orphee</first><last>De Clercq</last></author>
      <author><first>Veronique</first><last>Hoste</last></author>
      <pages>21-31</pages>
      <abstract>Event and argument role detection are frequently conceived as separate tasks. In this work we conceive both processes as one taskin a hybrid event detection approach. Its main component is based on automatic keyword extraction (AKE) using the self-attention mechanism of a BERT transformer model. As a bottleneck for AKE is defining the threshold of the attention values, we propose a novel method for automatic self-attention thresholdselection. It is fueled by core event information, or simply the verb and its arguments as the backbone of an event. These are outputted by a knowledge-based syntactic parser. In a secondstep the event core is enriched with other semantically salient words provided by the transformer model. Furthermore, we propose an automatic self-attention layer and head selectionmechanism, by analyzing which self-attention cells in the BERT transformer contribute most to the hybrid event detection and which linguistic tasks they represent. This approach was integrated in a pipeline event extraction approachand outperforms three state of the art multi-task event extraction methods.</abstract>
      <url hash="4224d53d">2022.case-1.4</url>
      <bibkey>desot-etal-2022-hybrid</bibkey>
    </paper>
    <paper id="5">
      <title>Improving Zero-Shot Event Extraction via Sentence Simplification</title>
      <author><first>Sneha</first><last>Mehta</last></author>
      <author><first>Huzefa</first><last>Rangwala</last></author>
      <author><first>Naren</first><last>Ramakrishnan</last></author>
      <pages>32-43</pages>
      <abstract>The success of sites such as ACLED and Our World in Data have demonstrated the massive utility of extracting events in structured formats from large volumes of textual data in the formof news, social media, blogs and discussion forums.Event extraction can provide a window into ongoing geopolitical crises and yield actionable intelligence. In this work, we cast socio-political event extraction as a machine reading comprehension (MRC) task. % With the proliferation of large pretrained language models Machine Reading Comprehension (MRC) has emerged as a new paradigm for event extraction in recent times. In this approach, extraction of social-political actors and targets from a sentence is framed as an extractive question-answering problem conditioned on an event type. There are several advantages of using MRC for this task including the ability to leverage large pretrained multilingual language models and their ability to perform zero-shot extraction. Moreover, we find that the problem of long-range dependencies, i.e., large lexical distance between trigger and argument words and the difficulty of processing syntactically complex sentences plague MRC-based approaches.To address this, we present a general approach to improve the performance of MRC-based event extraction by performing unsupervised sentence simplification guided by the MRC model itself. We evaluate our approach on the ICEWS geopolitical event extraction dataset, with specific attention to ‘Actor’ and ‘Target’ argument roles. We show how such context simplification can improve the performance of MRC-based event extraction by more than 5{% for actor extraction and more than 10{% for target extraction.</abstract>
      <url hash="6ddc9765">2022.case-1.5</url>
      <bibkey>mehta-etal-2022-improving-zero</bibkey>
    </paper>
    <paper id="6">
      <title><fixed-case>SNU</fixed-case>-Causality Lab @ Causal News Corpus 2022: Detecting Causality by Data Augmentation via Part-of-Speech tagging</title>
      <author><first>Juhyeon</first><last>Kim</last></author>
      <author><first>Yesong</first><last>Choe</last></author>
      <author><first>Sanghack</first><last>Lee</last></author>
      <pages>44-49</pages>
      <abstract>Finding causal relations in texts has been a challenge since it requires methods ranging from defining event ontologies to developing proper algorithmic approaches. In this paper, we developed a framework which classifies whether a given sentence contains a causal event.As our approach, we exploited an external corpus that has causal labels to overcome the small size of the original corpus (Causal News Corpus) provided by task organizers.Further, we employed a data augmentation technique utilizing Part-Of-Speech (POS) based on our observation that some parts of speech are more (or less) relevant to causality. Our approach especially improved the recall of detecting causal events in sentences.</abstract>
      <url hash="73569815">2022.case-1.6</url>
      <bibkey>kim-etal-2022-snu</bibkey>
    </paper>
    <paper id="7">
      <title><fixed-case>LTRC</fixed-case> @ Causal News Corpus 2022: Extracting and Identifying Causal Elements using Adapters</title>
      <author><first>Hiranmai</first><last>Sri Adibhatla</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <pages>50-55</pages>
      <abstract>Causality detection and identification is centered on identifying semantic and cognitive connections in a sentence. In this paper, we describe the effort of team LTRC for Causal News Corpus - Event Causality Shared Task 2022 at the 5th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2022). The shared task consisted of two subtasks: 1) identifying if a sentence contains a causality relation, and 2) identifying spans of text that correspond to cause, effect and signals. We fine-tuned transformer-based models with adapters for both subtasks. Our best-performing models obtained a binary F1 score of 0.853 on held-out data for subtask 1 and a macro F1 score of 0.032 on held-out data for subtask 2. Our approach is ranked third in subtask 1 and fourth in subtask 2. The paper describes our experiments, solutions, and analysis in detail.</abstract>
      <url hash="9fec7e31">2022.case-1.7</url>
      <bibkey>sri-adibhatla-shrivastava-2022-ltrc</bibkey>
    </paper>
    <paper id="8">
      <title>Cross-modal Transfer Between Vision and Language for Protest Detection</title>
      <author><first>Ria</first><last>Raj</last></author>
      <author><first>Kajsa</first><last>Andreasson</last></author>
      <author><first>Tobias</first><last>Norlund</last></author>
      <author><first>Richard</first><last>Johansson</last></author>
      <author><first>Aron</first><last>Lagerberg</last></author>
      <pages>56-60</pages>
      <abstract>Most of today’s systems for socio-political event detection are text-based, while an increasing amount of information published on the web is multi-modal. We seek to bridge this gap by proposing a method that utilizes existing annotated unimodal data to perform event detection in another data modality, zero-shot. Specifically, we focus on protest detection in text and images, and show that a pretrained vision-and-language alignment model (CLIP) can be leveraged towards this end. In particular, our results suggest that annotated protest text data can act supplementarily for detecting protests in images, but significant transfer is demonstrated in the opposite direction as well.</abstract>
      <url hash="d035cdba">2022.case-1.8</url>
      <bibkey>raj-etal-2022-cross</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>IDIAP</fixed-case>ers @ Causal News Corpus 2022: Efficient Causal Relation Identification Through a Prompt-based Few-shot Approach</title>
      <author><first>Sergio</first><last>Burdisso</last></author>
      <author><first>Juan Pablo</first><last>Zuluaga-gomez</last></author>
      <author><first>Esau</first><last>Villatoro-tello</last></author>
      <author><first>Martin</first><last>Fajcik</last></author>
      <author><first>Muskaan</first><last>Singh</last></author>
      <author><first>Pavel</first><last>Smrz</last></author>
      <author><first>Petr</first><last>Motlicek</last></author>
      <pages>61-69</pages>
      <abstract>In this paper, we describe our participation in the subtask 1 of CASE-2022, Event Causality Identification with Casual News Corpus. We address the Causal Relation Identification (CRI) task by exploiting a set of simple yet complementary techniques for fine-tuning language models (LMs) on a few annotated examples (i.e., a few-shot configuration).We follow a prompt-based prediction approach for fine-tuning LMs in which the CRI task is treated as a masked language modeling problem (MLM). This approach allows LMs natively pre-trained on MLM tasks to directly generate textual responses to CRI-specific prompts.We compare the performance of this method against ensemble techniques trained on the entire dataset.Our best-performing submission was fine-tuned with only 256 instances per class, 15.7% of the all available data, and yet obtained the second-best precision (0.82), third-best accuracy (0.82), and an F1-score (0.85) very close to what was reported by the winner team (0.86).</abstract>
      <url hash="e5c30ec6">2022.case-1.9</url>
      <bibkey>burdisso-etal-2022-idiapers</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>IDIAP</fixed-case>ers @ Causal News Corpus 2022: Extracting Cause-Effect-Signal Triplets via Pre-trained Autoregressive Language Model</title>
      <author><first>Martin</first><last>Fajcik</last></author>
      <author><first>Muskaan</first><last>Singh</last></author>
      <author><first>Juan Pablo</first><last>Zuluaga-gomez</last></author>
      <author><first>Esau</first><last>Villatoro-tello</last></author>
      <author><first>Sergio</first><last>Burdisso</last></author>
      <author><first>Petr</first><last>Motlicek</last></author>
      <author><first>Pavel</first><last>Smrz</last></author>
      <pages>70-78</pages>
      <abstract>In this paper, we describe our shared task submissions for Subtask 2 in CASE-2022, Event Causality Identification with Casual News Corpus. The challenge focused on the automatic detection of all cause-effect-signal spans present in the sentence from news-media. We detect cause-effect-signal spans in a sentence using T5 — a pre-trained autoregressive language model. We iteratively identify all cause-effect-signal span triplets, always conditioning the prediction of the next triplet on the previously predicted ones. To predict the triplet itself, we consider different causal relationships such as cause→effect→signal. Each triplet component is generated via a language model conditioned on the sentence, the previous parts of the current triplet, and previously predicted triplets. Despite training on an extremely small dataset of 160 samples, our approach achieved competitive performance, being placed second in the competition. Furthermore, we show that assuming either cause→effect or effect→cause order achieves similar results.</abstract>
      <url hash="d87d57ac">2022.case-1.10</url>
      <bibkey>fajcik-etal-2022-idiapers</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>N</fixed-case>oisy<fixed-case>A</fixed-case>nnot@ Causal News Corpus 2022: Causality Detection using Multiple Annotation Decisions</title>
      <author><first>Quynh Anh</first><last>Nguyen</last></author>
      <author><first>Arka</first><last>Mitra</last></author>
      <pages>79-84</pages>
      <abstract>The paper describes the work that has been submitted to the 5th workshop on Challenges and Applications of Automated Extraction of socio-political events from text (CASE 2022). The work is associated with Subtask 1 of Shared Task 3 that aims to detect causality in protest news corpus. The authors used different large language models with customized cross-entropy loss functions that exploit annotation information. The experiments showed that bert-based-uncased with refined cross-entropy outperformed the others, achieving a F1 score of 0.8501 on the Causal News Corpus dataset.</abstract>
      <url hash="44d7b763">2022.case-1.11</url>
      <bibkey>nguyen-mitra-2022-noisyannot</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>GGNN</fixed-case>@Causal News Corpus 2022:Gated Graph Neural Networks for Causal Event Classification from Social-Political News Articles</title>
      <author><first>Paul</first><last>Trust</last></author>
      <author><first>Rosane</first><last>Minghim</last></author>
      <author><first>Evangelos</first><last>Milos</last></author>
      <author><first>Kadusabe</first><last>Provia</last></author>
      <pages>85-90</pages>
      <abstract>The discovery of causality mentions from text is a core cognitive concept and appears in many natural language processing (NLP) applications. In this paper, we study the task of Event Causality Identification (ECI) from social-political news. The aim of the task is to detect causal relationships between event mention pairs in text.Although deep learning models have recently achieved a state-of-the-art performance on many tasks and applications in NLP, most of them still fail to capture rich semantic and syntactic structures within sentences which is key for causality classification. We present a solution for causal event detection from social-political news that captures semantic and syntactic information based on gated graph neural networks (GGNN) and contextualized language embeddings. Experimental results show that our proposed method outperforms the baseline model (BERT (Bidirectional Embeddings from Transformers) in terms of f1-score and accuracy.</abstract>
      <url hash="1b25c251">2022.case-1.12</url>
      <bibkey>trust-etal-2022-ggnn</bibkey>
    </paper>
    <paper id="13">
      <title>1<fixed-case>C</fixed-case>ademy @ Causal News Corpus 2022: Leveraging Self-Training in Causality Classification of Socio-Political Event Data</title>
      <author><first>Adam</first><last>Nik</last></author>
      <author><first>Ge</first><last>Zhang</last></author>
      <author><first>Xingran</first><last>Chen</last></author>
      <author><first>Mingyu</first><last>Li</last></author>
      <author><first>Jie</first><last>Fu</last></author>
      <pages>91-99</pages>
      <abstract>This paper details our participation in the Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE) workshop @ EMNLP 2022, where we take part in Subtask 1 of Shared Task 3 {citep{tan-etal-2022-event}. We approach the given task of event causality detection by proposing a self-training pipeline that follows a teacher-student classifier method. More specifically, we initially train a teacher model on the true, original task data, and use that teacher model to self-label data to be used in the training of a separate student model for the final task prediction. We test how restricting the number of positive or negative self-labeled examples in the self-training process affects classification performance. Our final results show that using self-training produces a comprehensive performance improvement across all models and self-labeled training sets tested within the task of event causality sequence classification. On top of that, we find that self-training performance did not diminish even when restricting either positive/negative examples used in training.Our code is be publicly available at {hyperlink{https://github.com/Gzhang-umich/1CademyTeamOfCASE}{https://github.com/Gzhang-umich/1CademyTeamOfCASE}.</abstract>
      <url hash="0cdc2f27">2022.case-1.13</url>
      <bibkey>nik-etal-2022-1cademy</bibkey>
    </paper>
    <paper id="14">
      <title>1<fixed-case>C</fixed-case>ademy @ Causal News Corpus 2022: Enhance Causal Span Detection via Beam-Search-based Position Selector</title>
      <author><first>Xingran</first><last>Chen</last></author>
      <author><first>Ge</first><last>Zhang</last></author>
      <author><first>Adam</first><last>Nik</last></author>
      <author><first>Mingyu</first><last>Li</last></author>
      <author><first>Jie</first><last>Fu</last></author>
      <pages>100-105</pages>
      <abstract>In this paper, we present our approach and empirical observations for Cause-Effect Signal Span Detection—Subtask 2 of Shared task 3 at CASE 2022. The shared task aims to extract the cause, effect, and signal spans from a given causal sentence.We model the task as a reading comprehension (RC) problem and apply a token-level RC-based span prediction paradigm to the task as the baseline.We explore different training objectives to fine-tune the model, as well as data augmentation (DA) tricks based on the language model (LM) for performance improvement.Additionally, we propose an efficient beam-search post-processing strategy to due with the drawbacks of span detection to obtain a further performance gain.Our approach achieves an average $F_1$ score of 54.15 and ranks {textbf{$1ˆ{st}$} in the CASE competition. Our code is available at {url{https://github.com/Gzhang-umich/1CademyTeamOfCASE}.</abstract>
      <url hash="88ec10fd">2022.case-1.14</url>
      <bibkey>chen-etal-2022-1cademy</bibkey>
    </paper>
    <paper id="15">
      <title>Hybrid Knowledge Engineering Leveraging a Robust <fixed-case>ML</fixed-case> Framework to Produce an Assassination Dataset</title>
      <author><first>Abigail</first><last>Sticha</last></author>
      <author><first>Paul</first><last>Brenner</last></author>
      <pages>106-116</pages>
      <abstract>Social and political researchers require robust event datasets to conduct data-driven analysis, an example being the need for trigger event datasets to analyze under what conditions and in what patterns certain trigger-type events increase the probability of mass killings. Fortunately, NLP and ML can be leveraged to create these robust datasets. In this paper we (i) outline a robust ML framework that prioritizes understandability through visualizations and generalizability through the ability to implement different ML algorithms, (ii) perform a comparative analysis of these ML tools within the framework for the coup trigger, (iii) leverage our ML framework along with a unique combination of NLP tools, such as NER and knowledge graphs, to produce a dataset for the the assassination trigger, and (iv) make this comprehensive, consolidated, and cohesive assassination dataset publicly available to provide temporal data for understanding political violence as well as training data for further socio-political research.</abstract>
      <url hash="391666c1">2022.case-1.15</url>
      <bibkey>sticha-brenner-2022-hybrid</bibkey>
    </paper>
    <paper id="16">
      <title>Political Event Coding as Text-to-Text Sequence Generation</title>
      <author><first>Yaoyao</first><last>Dai</last></author>
      <author><first>Benjamin</first><last>Radford</last></author>
      <author><first>Andrew</first><last>Halterman</last></author>
      <pages>117-123</pages>
      <abstract>We report on the current status of an effort to produce political event data from unstructured text via a Transformer language model. Compelled by the current lack of publicly available and up-to-date event coding software, we seek to train a model that can produce structured political event records at the sentence level. Our approach differs from previous efforts in that we conceptualize this task as one of text-to-text sequence generation. We motivate this choice by outlining desirable properties of text generation models for the needs of event coding. To overcome the lack of sufficient training data, we also describe a method for generating synthetic text and event record pairs that we use to fit our model.</abstract>
      <url hash="0da6376a">2022.case-1.16</url>
      <bibkey>dai-etal-2022-political</bibkey>
    </paper>
    <paper id="17">
      <title>Zero-Shot Ranking Socio-Political Texts with Transformer Language Models to Reduce Close Reading Time</title>
      <author><first>Kiymet</first><last>Akdemir</last></author>
      <author><first>Ali</first><last>Hürriyetoğlu</last></author>
      <pages>124-132</pages>
      <abstract>We approach the classification problem as an entailment problem and apply zero-shot ranking to socio-political texts. Documents that are ranked at the top can be considered positively classified documents and this reduces the close reading time for the information extraction process. We use Transformer Language Models to get the entailment probabilities and investigate different types of queries. We find that DeBERTa achieves higher mean average precision scores than RoBERTa and when declarative form of the class label is used as a query, it outperforms dictionary definition of the class label. We show that one can reduce the close reading time by taking some percentage of the ranked documents that the percentage depends on how much recall they want to achieve. However, our findings also show that percentage of the documents that should be read increases as the topic gets broader.</abstract>
      <url hash="61b2ad34">2022.case-1.17</url>
      <bibkey>akdemir-hurriyetoglu-2022-zero</bibkey>
    </paper>
    <paper id="18">
      <title><fixed-case>SPOCK</fixed-case> @ Causal News Corpus 2022: Cause-Effect-Signal Span Detection Using Span-Based and Sequence Tagging Models</title>
      <author><first>Anik</first><last>Saha</last></author>
      <author><first>Alex</first><last>Gittens</last></author>
      <author><first>Jian</first><last>Ni</last></author>
      <author><first>Oktie</first><last>Hassanzadeh</last></author>
      <author><first>Bulent</first><last>Yener</last></author>
      <author><first>Kavitha</first><last>Srinivas</last></author>
      <pages>133-137</pages>
      <abstract>Understanding causal relationship is an importance part of natural language processing. We address the causal information extraction problem with different neural models built on top of pre-trained transformer-based language models for identifying Cause, Effect and Signal spans, from news data sets. We use the Causal News Corpus subtask 2 training data set to train span-based and sequence tagging models. Our span-based model based on pre-trained BERT base weights achieves an F1 score of 47.48 on the test set with an accuracy score of 36.87 and obtained 3rd place in the Causal News Corpus 2022 shared task.</abstract>
      <url hash="2faf4b32">2022.case-1.18</url>
      <bibkey>saha-etal-2022-spock-causal</bibkey>
    </paper>
    <paper id="19">
      <title><fixed-case>CSECU</fixed-case>-<fixed-case>DSG</fixed-case> @ Causal News Corpus 2022: Fusion of <fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a Transformers Variants for Causal Event Classification</title>
      <author><first>Abdul</first><last>Aziz</last></author>
      <author><first>Md. Akram</first><last>Hossain</last></author>
      <author><first>Abu Nowshed</first><last>Chy</last></author>
      <pages>138-142</pages>
      <abstract>Identifying cause-effect relationships in sentences is one of the formidable tasks to tackle the challenges of inference and understanding of natural language. However, the diversity of word semantics and sentence structure makes it challenging to determine the causal relationship effectively. To address these challenges, CASE-2022 shared task 3 introduced a task focusing on event causality identification with causal news corpus. This paper presents our participation in this task, especially in subtask 1 which is the causal event classification task. To tackle the task challenge, we propose a unified neural model through exploiting two fine-tuned transformer models including RoBERTa and Twitter-RoBERTa. For the score fusion, we combine the prediction scores of each component model using weighted arithmetic mean to generate the probability score for class label identification. The experimental results showed that our proposed method achieved the top performance (ranked 1st) among the participants.</abstract>
      <url hash="92d80a1d">2022.case-1.19</url>
      <bibkey>aziz-etal-2022-csecu-dsg-causal</bibkey>
    </paper>
    <paper id="20">
      <title><fixed-case>ARGUABLY</fixed-case> @ Causal News Corpus 2022: Contextually Augmented Language Models for Event Causality Identification</title>
      <author><first>Guneet</first><last>Kohli</last></author>
      <author><first>Prabsimran</first><last>Kaur</last></author>
      <author><first>Jatin</first><last>Bedi</last></author>
      <pages>143-148</pages>
      <abstract>Causal (a cause-effect relationship between two arguments) has become integral to various NLP domains such as question answering, summarization, and event prediction. To understand causality in detail, Event Causality Identification with Causal News Corpus (CASE-2022) has organized shared tasks. This paper defines our participation in Subtask 1, which focuses on classifying event causality. We used sentence-level augmentation based on contextualized word embeddings of distillBERT to construct new data. This data was then trained using two approaches. The first technique used the DeBERTa language model, and the second used the RoBERTa language model in combination with cross-attention. We obtained the second-best F1 score (0.8610) in the competition with the Contextually Augmented DeBERTa model.</abstract>
      <url hash="76476957">2022.case-1.20</url>
      <bibkey>kohli-etal-2022-arguably</bibkey>
    </paper>
    <paper id="21">
      <title><fixed-case>C</fixed-case>lass<fixed-case>B</fixed-case>ases at the <fixed-case>CASE</fixed-case>-2022 Multilingual Protest Event Detection Task: Multilingual Protest News Detection and Automatically Replicating Manually Created Event Datasets</title>
      <author><first>Peratham</first><last>Wiriyathammabhum</last></author>
      <pages>149-154</pages>
      <abstract>In this report, we describe our ClassBases submissions to a shared task on multilingual protest event detection. For the multilingual protest news detection, we participated in subtask-1, subtask-2 and subtask-4 which are document classification, sentence classification and token classification. In subtask-1, we compare XLM-RoBERTa-base, mLUKE-base and XLM-RoBERTa-large on finetuning in a sequential classification setting. We always use a combination of the training data from every language provided to train our multilingual models. We found that larger models seem to work better and entity knowledge helps but at a non-negligible cost. For subtask-2, we only submitted an mLUKE-base system for sentence classification. For subtask-4, we only submitted an XLM-RoBERTa-base for token classification system for sequence labeling. For automatically replicating manually created event datasets, we participated in COVID-related protest events from the New York Times news corpus. We created a system to process the crawled data into a dataset of protest events.</abstract>
      <url hash="7cced9c1">2022.case-1.21</url>
      <bibkey>wiriyathammabhum-2022-classbases</bibkey>
    </paper>
    <paper id="22">
      <title><fixed-case>E</fixed-case>vent<fixed-case>G</fixed-case>raph at <fixed-case>CASE</fixed-case> 2021 Task 1: A General Graph-based Approach to Protest Event Extraction</title>
      <author><first>Huiling</first><last>You</last></author>
      <author><first>David</first><last>Samuel</last></author>
      <author><first>Samia</first><last>Touileb</last></author>
      <author><first>Lilja</first><last>Øvrelid</last></author>
      <pages>155-160</pages>
      <abstract>This paper presents our submission to the 2022 edition of the CASE 2021 shared task 1, subtask 4. The EventGraph system adapts an end-to-end, graph-based semantic parser to the task of Protest Event Extraction and more specifically subtask 4 on event trigger and argument extraction. We experiment with various graphs, encoding the events as either “labeled-edge” or “node-centric” graphs. We show that the “node-centric” approach yields best results overall, performing well across the three languages of the task, namely English, Spanish, and Portuguese. EventGraph is ranked 3rd for English and Portuguese, and 4th for Spanish.</abstract>
      <url hash="96e63159">2022.case-1.22</url>
      <bibkey>you-etal-2022-eventgraph-case</bibkey>
    </paper>
    <paper id="23">
      <title><fixed-case>NSUT</fixed-case>-<fixed-case>NLP</fixed-case> at <fixed-case>CASE</fixed-case> 2022 Task 1: Multilingual Protest Event Detection using Transformer-based Models</title>
      <author><first>Manan</first><last>Suri</last></author>
      <author><first>Krish</first><last>Chopra</last></author>
      <author><first>Adwita</first><last>Arora</last></author>
      <pages>161-168</pages>
      <abstract>Event detection, specifically in the socio-political domain, has posed a long-standing challenge to researchers in the NLP domain. Therefore, the creation of automated techniques that perform classification of the large amounts of accessible data on the Internet becomes imperative. This paper is a summary of the efforts we made in participating in Task 1 of CASE 2022. We use state-of-art multilingual BERT (mBERT) with further fine-tuning to perform document classification in English, Portuguese, Spanish, Urdu, Hindi, Turkish and Mandarin. In the document classification subtask, we were able to achieve F1 scores of 0.8062, 0.6445, 0.7302, 0.5671, 0.6555, 0.7545 and 0.6702 in English, Spanish, Portuguese, Hindi, Urdu, Mandarin and Turkish respectively achieving a rank of 5 in English and 7 on the remaining language tasks.</abstract>
      <url hash="ec927769">2022.case-1.23</url>
      <bibkey>suri-etal-2022-nsut</bibkey>
    </paper>
    <paper id="24">
      <title><fixed-case>C</fixed-case>am<fixed-case>P</fixed-case>ros at <fixed-case>CASE</fixed-case> 2022 Task 1: Transformer-based Multilingual Protest News Detection</title>
      <author><first>Neha</first><last>Kumari</last></author>
      <author><first>Mrinal</first><last>Anand</last></author>
      <author><first>Tushar</first><last>Mohan</last></author>
      <author><first>Ponnurangam</first><last>Kumaraguru</last></author>
      <author><first>Arun Balaji</first><last>Buduru</last></author>
      <pages>169-174</pages>
      <abstract>Socio-political protests often lead to grave consequences when they occur. The early detection of such protests is very important for taking early precautionary measures. However, the main shortcoming of protest event detection is the scarcity of sufficient training data for specific language categories, which makes it difficult to train data-hungry deep learning models effectively. Therefore, cross-lingual and zero-shot learning models are needed to detect events in various low-resource languages. This paper proposes a multi-lingual cross-document level event detection approach using pre-trained transformer models developed for Shared Task 1 at CASE 2022. The shared task constituted four subtasks for event detection at different granularity levels, i.e., document level to token level, spread over multiple languages (English, Spanish, Portuguese, Turkish, Urdu, and Mandarin). Our system achieves an average F1 score of 0.73 for document-level event detection tasks. Our approach secured 2nd position for the Hindi language in subtask 1 with an F1 score of 0.80. While for Spanish, we secure 4th position with an F1 score of 0.69. Our code is available at https://github.com/nehapspathak/campros/.</abstract>
      <url hash="d7b9423f">2022.case-1.24</url>
      <bibkey>kumari-etal-2022-campros</bibkey>
    </paper>
    <paper id="25">
      <title><fixed-case>ARC</fixed-case>-<fixed-case>NLP</fixed-case> at <fixed-case>CASE</fixed-case> 2022 Task 1: Ensemble Learning for Multilingual Protest Event Detection</title>
      <author><first>Umitcan</first><last>Sahin</last></author>
      <author><first>Oguzhan</first><last>Ozcelik</last></author>
      <author><first>Izzet Emre</first><last>Kucukkaya</last></author>
      <author><first>Cagri</first><last>Toraman</last></author>
      <pages>175-183</pages>
      <abstract>Automated socio-political protest event detection is a challenging task when multiple languages are considered. In CASE 2022 Task 1, we propose ensemble learning methods for multilingual protest event detection in four subtasks with different granularity levels from document-level to entity-level. We develop an ensemble of fine-tuned Transformer-based language models, along with a post-processing step to regularize the predictions of our ensembles. Our approach places the first place in 6 out of 16 leaderboards organized in seven languages including English, Mandarin, and Turkish.</abstract>
      <url hash="c886ad0e">2022.case-1.25</url>
      <bibkey>sahin-etal-2022-arc</bibkey>
    </paper>
    <paper id="26">
      <title><fixed-case>CEIA</fixed-case>-<fixed-case>NLP</fixed-case> at <fixed-case>CASE</fixed-case> 2022 Task 1: Protest News Detection for <fixed-case>P</fixed-case>ortuguese</title>
      <author><first>Diogo</first><last>Fernandes</last></author>
      <author><first>Adalberto</first><last>Junior</last></author>
      <author><first>Gabriel</first><last>Marques</last></author>
      <author><first>Anderson</first><last>Soares</last></author>
      <author><first>Arlindo</first><last>Galvao Filho</last></author>
      <pages>184-188</pages>
      <abstract>This paper summarizes our work on the document classification subtask of Multilingual protest news detection of the CASE @ ACL-IJCNLP 2022 workshok. In this context, we investigate the performance of monolingual and multilingual transformer-based models in low data resources, taking Portuguese as an example and evaluating language models on document classification. Our approach became the winning solution in Portuguese document classification achieving 0.8007 F1 Score on Test set. The experimental results demonstrate that multilingual models achieve best results in scenarios with few dataset samples of specific language, because we can train models using datasets from other languages of the same task and domain.</abstract>
      <url hash="9417df75">2022.case-1.26</url>
      <bibkey>fernandes-etal-2022-ceia</bibkey>
    </paper>
    <paper id="27">
      <title><fixed-case>SPARTA</fixed-case> at <fixed-case>CASE</fixed-case> 2021 Task 1: Evaluating Different Techniques to Improve Event Extraction</title>
      <author><first>Arthur</first><last>Müller</last></author>
      <author><first>Andreas</first><last>Dafnos</last></author>
      <pages>189-194</pages>
      <abstract>We participated in the Shared Task 1 at CASE 2021, Subtask 4 on protest event extraction from news articles and examined different techniques aimed at improving the performance of the winning system from the last competition round. We evaluated in-domain pre-training, task-specific pre-fine-tuning, alternative loss function, translation of the English training dataset into other target languages (i.e., Portuguese, Spanish, and Hindi) for the token classification task, and a simple data augmentation technique by random sentence reordering. This paper summarizes the results, showing that random sentence reordering leads to a consistent improvement of the model performance.</abstract>
      <url hash="15e2873e">2022.case-1.27</url>
      <bibkey>muller-dafnos-2022-sparta</bibkey>
    </paper>
    <paper id="28">
      <title>Event Causality Identification with Causal News Corpus - Shared Task 3, <fixed-case>CASE</fixed-case> 2022</title>
      <author><first>Fiona Anting</first><last>Tan</last></author>
      <author><first>Hansi</first><last>Hettiarachchi</last></author>
      <author><first>Ali</first><last>Hürriyetoğlu</last></author>
      <author><first>Tommaso</first><last>Caselli</last></author>
      <author><first>Onur</first><last>Uca</last></author>
      <author><first>Farhana Ferdousi</first><last>Liza</last></author>
      <author><first>Nelleke</first><last>Oostdijk</last></author>
      <pages>195-208</pages>
      <abstract>The Event Causality Identification Shared Task of CASE 2022 involved two subtasks working on the Causal News Corpus. Subtask 1 required participants to predict if a sentence contains a causal relation or not. This is a supervised binary classification task. Subtask 2 required participants to identify the Cause, Effect and Signal spans per causal sentence. This could be seen as a supervised sequence labeling task. For both subtasks, participants uploaded their predictions for a held-out test set, and ranking was done based on binary F1 and macro F1 scores for Subtask 1 and 2, respectively. This paper summarizes the work of the 17 teams that submitted their results to our competition and 12 system description papers that were received. The best F1 scores achieved for Subtask 1 and 2 were 86.19% and 54.15%, respectively. All the top-performing approaches involved pre-trained language models fine-tuned to the targeted task. We further discuss these approaches and analyze errors across participants’ systems in this paper.</abstract>
      <url hash="2eecb5f1">2022.case-1.28</url>
      <bibkey>tan-etal-2022-event</bibkey>
    </paper>
    <paper id="29">
      <title>Tracking <fixed-case>COVID</fixed-case>-19 protest events in the <fixed-case>U</fixed-case>nited <fixed-case>S</fixed-case>tates. Shared Task 2: Event Database Replication, <fixed-case>CASE</fixed-case> 2022</title>
      <author><first>Vanni</first><last>Zavarella</last></author>
      <author><first>Hristo</first><last>Tanev</last></author>
      <author><first>Ali</first><last>Hürriyetoğlu</last></author>
      <author><first>Peratham</first><last>Wiriyathammabhum</last></author>
      <author><first>Bertrand</first><last>De Longueville</last></author>
      <pages>209-216</pages>
      <abstract>The goal of Shared Task 2 is evaluating state-of-the-art event detection systems by comparing the spatio-temporal distribution of the events they detect with existing event databases.The task focuses on some usability requirements of event detection systems in real worldscenarios. Namely, it aims to measure the ability of such a system to: (i) detect socio-political event mentions in news and social media, (ii) properly find their geographical locations, (iii) de-duplicate reports extracted from multiple sources referring to the same actual event. Building an annotated corpus for training and evaluating jointly these sub-tasks is highly time consuming. One possible way to indirectly evaluate a system’s output without an annotated corpus available is to measure its correlation with human-curated event data sets.In the last three years, the COVID-19 pandemic became motivation for restrictions and anti-pandemic measures on a world scale. This has triggered a wave of reactions and citizen actions in many countries. Shared Task 2 challenges participants to identify COVID-19 related protest actions from large unstructureddata sources both from mainstream and social media. We assess each system’s ability to model the evolution of protest events both temporally and spatially by using a number of correlation metrics with respect to a comprehensive and validated data set of COVID-related protest events (Raleigh et al., 2010).</abstract>
      <url hash="cc195090">2022.case-1.29</url>
      <bibkey>zavarella-etal-2022-tracking</bibkey>
    </paper>
    <paper id="30">
      <title>Challenges and Applications of Automated Extraction of Socio-political Events from Text (<fixed-case>CASE</fixed-case> 2022): Workshop and Shared Task Report</title>
      <author><first>Ali</first><last>Hürriyetoğlu</last></author>
      <author><first>Hristo</first><last>Tanev</last></author>
      <author><first>Vanni</first><last>Zavarella</last></author>
      <author><first>Reyyan</first><last>Yeniterzi</last></author>
      <author><first>Osman</first><last>Mutlu</last></author>
      <author><first>Erdem</first><last>Yörük</last></author>
      <pages>217-222</pages>
      <abstract>We provide a summary of the fifth edition of the CASE workshop that is held in the scope of EMNLP 2022. The workshop consists of regular papers, two keynotes, working papers of shared task participants, and task overview papers. This workshop has been bringing together all aspects of event information collection across technical and social science fields. In addition to the progress in depth, the submission and acceptance of multimodal approaches show the widening of this interdisciplinary research topic.</abstract>
      <url hash="a08d1b6c">2022.case-1.30</url>
      <bibkey>hurriyetoglu-etal-2022-challenges</bibkey>
    </paper>
    <paper id="31">
      <title>Extended Multilingual Protest News Detection - Shared Task 1, <fixed-case>CASE</fixed-case> 2021 and 2022</title>
      <author><first>Ali</first><last>Hürriyetoğlu</last></author>
      <author><first>Osman</first><last>Mutlu</last></author>
      <author><first>Fırat</first><last>Duruşan</last></author>
      <author><first>Onur</first><last>Uca</last></author>
      <author><first>Alaeddin</first><last>Gürel</last></author>
      <author><first>Benjamin J.</first><last>Radford</last></author>
      <author><first>Yaoyao</first><last>Dai</last></author>
      <author><first>Hansi</first><last>Hettiarachchi</last></author>
      <author><first>Niklas</first><last>Stoehr</last></author>
      <author><first>Tadashi</first><last>Nomoto</last></author>
      <author><first>Milena</first><last>Slavcheva</last></author>
      <author><first>Francielle</first><last>Vargas</last></author>
      <author><first>Aaqib</first><last>Javid</last></author>
      <author><first>Fatih</first><last>Beyhan</last></author>
      <author><first>Erdem</first><last>Yörük</last></author>
      <pages>223-228</pages>
      <abstract>We report results of the CASE 2022 Shared Task 1 on Multilingual Protest Event Detection. This task is a continuation of CASE 2021 that consists of four subtasks that are i) document classification, ii) sentence classification, iii) event sentence coreference identification, and iv) event extraction. The CASE 2022 extension consists of expanding the test data with more data in previously available languages, namely, English, Hindi, Portuguese, and Spanish, and adding new test data in Mandarin, Turkish, and Urdu for Sub-task 1, document classification. The training data from CASE 2021 in English, Portuguese and Spanish were utilized. Therefore, predicting document labels in Hindi, Mandarin, Turkish, and Urdu occurs in a zero-shot setting. The CASE 2022 workshop accepts reports on systems developed for predicting test data of CASE 2021 as well. We observe that the best systems submitted by CASE 2022 participants achieve between 79.71 and 84.06 F1-macro for new languages in a zero-shot setting. The winning approaches are mainly ensembling models and merging data in multiple languages. The best two submissions on CASE 2021 data outperform submissions from last year for Subtask 1 and Subtask 2 in all languages. Only the following scenarios were not outperformed by new submissions on CASE 2021: Subtask 3 Portuguese {&amp; Subtask 4 English.</abstract>
      <url hash="7f21ae1b">2022.case-1.31</url>
      <bibkey>hurriyetoglu-etal-2022-extended</bibkey>
      <revision id="1" href="2022.case-1.31v1" hash="25ca7c24"/>
      <revision id="2" href="2022.case-1.31v2" hash="7f21ae1b" date="2023-03-20">Corrected author info.</revision>
    </paper>
  </volume>
</collection>
