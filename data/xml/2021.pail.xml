<?xml version='1.0' encoding='UTF-8'?>
<collection id="2021.pail">
  <volume id="1" ingest-date="2022-10-03">
    <meta>
      <booktitle>Proceedings of the First Workshop on Parsing and its Applications for Indian Languages</booktitle>
      <editor><first>Kengatharaiyer</first><last>Sarveswaran</last></editor>
      <editor><first>Parameswari</first><last>Krishnamurthy</last></editor>
      <editor><first>Pruthwik</first><last>Mishra</last></editor>
      <publisher>NLP Association of India (NLPAI)</publisher>
      <address>NIT Silchar, India</address>
      <month>December</month>
      <year>2021</year>
      <url hash="584a6075">2021.pail-1</url>
      <venue>pail</venue>
    </meta>
    <frontmatter>
      <url hash="a8d61c69">2021.pail-1.0</url>
      <bibkey>pail-2021-parsing</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Developing <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies Treebanks for <fixed-case>M</fixed-case>agahi and <fixed-case>B</fixed-case>raj</title>
      <author><first>Mohit</first><last>Raj</last></author>
      <author><first>Shyam</first><last>Ratan</last></author>
      <author><first>Deepak</first><last>Alok</last></author>
      <author><first>Ritesh</first><last>Kumar</last></author>
      <author><first>Atul Kr.</first><last>Ojha</last></author>
      <pages>1–11</pages>
      <abstract>In this paper, we discuss the development of treebanks for two low-resourced Indian languages - Magahi and Braj - based on the Universal Dependencies framework. The Magahi treebank contains 945 sentences and Braj treebank around 500 sentences marked with their lemmas, part-of-speech, morphological features and universal dependencies. This paper gives a description of the different dependency relationship found in the two languages and give some statistics of the two treebanks. The dataset will be made publicly available on Universal Dependency (UD) repository in the next (v2.10) release.</abstract>
      <url hash="f0f8d2c8">2021.pail-1.1</url>
      <bibkey>raj-etal-2021-developing-universal</bibkey>
    </paper>
    <paper id="2">
      <title>Parsing Subordinate Clauses in <fixed-case>T</fixed-case>elugu using Rule-based Dependency Parser</title>
      <author><first>P</first><last>Sangeetha</last></author>
      <author><first>Parameswari</first><last>Krishnamurthy</last></author>
      <author><first>Amba</first><last>Kulkarni</last></author>
      <pages>12–19</pages>
      <abstract>Parsing has been gaining popularity in recent years and attracted the interest of NLP researchers around the world. It is challenging when the language under study is a free-word order language that allows ellipsis like Telugu. In this paper, an attempt is made to parse subordinate clauses especially, non-finite verb clauses and relative clauses in Telugu which are highly productive and constitute a large chunk in parsing tasks. This study adopts a knowledge-driven approach to parse subordinate structures using linguistic cues as rules. Challenges faced in parsing ambiguous structures are elaborated alongside providing enhanced tags to handle them. Results are encouraging and this parser proves to be efficient for Telugu.</abstract>
      <url hash="fdc932a8">2021.pail-1.2</url>
      <bibkey>sangeetha-etal-2021-parsing-subordinate</bibkey>
    </paper>
    <paper id="3">
      <title>Dependency Parsing in a Morphological rich language, <fixed-case>T</fixed-case>amil</title>
      <author><first>Vijay</first><last>Sundar Ram</last></author>
      <author><first>Sobha</first><last>Lalitha Devi</last></author>
      <pages>20–26</pages>
      <abstract>Dependency parsing is the process of analysing the grammatical structure of a sentence based on the dependencies between the words in a sentence. The annotation of dependency parsing is done using different formalisms at word-level namely Universal Dependencies and chunk-level namely AnnaCorra. Though dependency parsing is deeply dealt in languages such as English, Czech etc the same cannot be adopted for the morphologically rich and agglutinative languages. In this paper, we discuss the development of a dependency parser for Tamil, a South Dravidian language. The different characteristics of the language make this task a challenging task. Tamil, a morphologically rich and agglutinative language, has copula drop, accusative and genitive case drop and pro-drop. Coordinative constructions are introduced by affixation of morpheme ‘um’. Embedded clausal structures are common in relative participle and complementizer clauses. In this paper, we have discussed our approach to handle some of these challenges. We have used Malt parser, a supervised learning- approach based implementation. We have obtained an accuracy of 79.27% for Unlabelled Attachment Score, 73.64% for Labelled Attachment Score and 68.82% for Labelled Accuracy.</abstract>
      <url hash="b86079b8">2021.pail-1.3</url>
      <bibkey>sundar-ram-lalitha-devi-2021-dependency-parsing</bibkey>
    </paper>
    <paper id="4">
      <title>Neural-based <fixed-case>T</fixed-case>amil Grammar Error Detection</title>
      <author><first>Dineskumar</first><last>Murugesapillai</last></author>
      <author><first>Anankan</first><last>Ravinthirarasa</last></author>
      <author><first>Gihan</first><last>Dias</last></author>
      <author><first>Kengatharaiyer</first><last>Sarveswaran</last></author>
      <pages>27–32</pages>
      <abstract>This paper describes an ongoing development of a grammar error checker for the Tamil language using a state-of-the-art deep neural-based approach. This proposed checker capture a vital type of grammar error called subject-predicate agreement errors. In this case, we specifically target the agreement error that occurs between nominal subject and verbal predicates. We also created the first-ever grammar error annotated corpus for Tamil. In addition, we experimented with different multi-lingual pre-trained language models to capture syntactic information and found that IndicBERT gives better performance for our tasks. We implemented this grammar checker as a multi-class classification on top of the IndicBERT pre-trained model, which we fine-tuned using our annotated data. This baseline model gives an F1 Score of 73.4. We are now in the process of improving this proposed system with the use of a dependency parser.</abstract>
      <url hash="1c319c0c">2021.pail-1.4</url>
      <bibkey>murugesapillai-etal-2021-neural-based</bibkey>
    </paper>
  </volume>
</collection>
