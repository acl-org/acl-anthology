<?xml version='1.0' encoding='UTF-8'?>
<collection id="2022.naacl">
  <volume id="tutorials" ingest-date="2022-06-28">
    <meta>
      <booktitle>Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Tutorial Abstracts</booktitle>
      <editor><first>Miguel</first><last>Ballesteros</last></editor>
      <editor><first>Yulia</first><last>Tsvetkov</last></editor>
      <editor><first>Cecilia O.</first><last>Alm</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Seattle, United States</address>
      <month>July</month>
      <year>2022</year>
      <url hash="b80dea0e">2022.naacl-tutorials</url>
    </meta>
    <frontmatter>
      <url hash="b80dea0e">2022.naacl-tutorials.0</url>
      <bibkey>naacl-2022-2022</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Text Generation with Text-Editing Models</title>
      <author><first>Eric</first><last>Malmi</last></author>
      <author><first>Yue</first><last>Dong</last></author>
      <author><first>Jonathan</first><last>Mallinson</last></author>
      <author><first>Aleksandr</first><last>Chuklin</last></author>
      <author><first>Jakub</first><last>Adamek</last></author>
      <author><first>Daniil</first><last>Mirylenka</last></author>
      <author><first>Felix</first><last>Stahlberg</last></author>
      <author><first>Sebastian</first><last>Krause</last></author>
      <author><first>Shankar</first><last>Kumar</last></author>
      <author><first>Aliaksei</first><last>Severyn</last></author>
      <pages>1-7</pages>
      <abstract>Text-editing models have recently become a prominent alternative to seq2seq models for monolingual text-generation tasks such as grammatical error correction, text simplification, and style transfer. These tasks share a common trait – they exhibit a large amount of textual overlap between the source and target texts. Text-editing models take advantage of this observation and learn to generate the output by predicting edit operations applied to the source sequence. In contrast, seq2seq models generate outputs word-by-word from scratch thus making them slow at inference time. Text-editing models provide several benefits over seq2seq models including faster inference speed, higher sample efficiency, and better control and interpretability of the outputs. This tutorial provides a comprehensive overview of the text-edit based models and current state-of-the-art approaches analyzing their pros and cons. We discuss challenges related to deployment and how these models help to mitigate hallucination and bias, both pressing challenges in the field of text generation.</abstract>
      <url hash="4d9cc505">2022.naacl-tutorials.1</url>
      <bibkey>malmi-etal-2022-text</bibkey>
    </paper>
    <paper id="2">
      <title>Self-supervised Representation Learning for Speech Processing</title>
      <author><first>Hung-yi</first><last>Lee</last></author>
      <author><first>Abdelrahman</first><last>Mohamed</last></author>
      <author><first>Shinji</first><last>Watanabe</last></author>
      <author><first>Tara</first><last>Sainath</last></author>
      <author><first>Karen</first><last>Livescu</last></author>
      <author><first>Shang-Wen</first><last>Li</last></author>
      <author><first>Shu-wen</first><last>Yang</last></author>
      <author><first>Katrin</first><last>Kirchhoff</last></author>
      <pages>8-13</pages>
      <abstract>There is a trend in the machine learning community to adopt self-supervised approaches to pre-train deep networks. Self-supervised representation learning (SSL) utilizes proxy supervised learning tasks, for example, distinguishing parts of the input signal from distractors, or generating masked input segments conditioned on the unmasked ones, to obtain training data from unlabeled corpora. BERT and GPT in NLP and SimCLR and BYOL in CV are famous examples in this direction. These approaches make it possible to use a tremendous amount of unlabeled data available on the web to train large networks and solve complicated tasks. Thus, SSL has the potential to scale up current machine learning technologies, especially for low-resourced, under-represented use cases, and democratize the technologies. Recently self-supervised approaches for speech processing are also gaining popularity. There are several workshops in relevant topics hosted at ICML 2020 (https://icml-sas.gitlab.io/), NeurIPS 2020 (https://neurips-sas-2020.github.io/), and AAAI 2022 (https://aaai-sas-2022.github.io/). However, there is no previous tutorial about a similar topic based on the authors’ best knowledge. Due to the growing popularity of SSL, and the shared mission of the areas in bringing speech and language technologies to more use cases with better quality and scaling the technologies for under-represented languages, we propose this tutorial to systematically survey the latest SSL techniques, tools, datasets, and performance achievement in speech processing. The proposed tutorial is highly relevant to the special theme of ACL about language diversity. One of the main focuses of the tutorial is leveraging SSL to reduce the dependence of speech technologies on labeled data, and to scale up the technologies especially for under-represented languages and use cases.</abstract>
      <url hash="06a41104">2022.naacl-tutorials.2</url>
      <bibkey>lee-etal-2022-self</bibkey>
    </paper>
    <paper id="3">
      <title>New Frontiers of Information Extraction</title>
      <author><first>Muhao</first><last>Chen</last></author>
      <author><first>Lifu</first><last>Huang</last></author>
      <author><first>Manling</first><last>Li</last></author>
      <author><first>Ben</first><last>Zhou</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>14-25</pages>
      <abstract>This tutorial targets researchers and practitioners who are interested in AI and ML technologies for structural information extraction (IE) from unstructured textual sources. Particularly, this tutorial will provide audience with a systematic introduction to recent advances of IE, by answering several important research questions. These questions include (i) how to develop an robust IE system from noisy, insufficient training data, while ensuring the reliability of its prediction? (ii) how to foster the generalizability of IE through enhancing the system’s cross-lingual, cross-domain, cross-task and cross-modal transferability? (iii) how to precisely support extracting structural information with extremely fine-grained, diverse and boundless labels? (iv) how to further improve IE by leveraging indirect supervision from other NLP tasks, such as NLI, QA or summarization, and pre-trained language models? (v) how to acquire knowledge to guide the inference of IE systems? We will discuss several lines of frontier research that tackle those challenges, and will conclude the tutorial by outlining directions for further investigation.</abstract>
      <url hash="7b5b3e2d">2022.naacl-tutorials.3</url>
      <bibkey>chen-etal-2022-new</bibkey>
    </paper>
    <paper id="4">
      <title>Human-Centered Evaluation of Explanations</title>
      <author><first>Jordan</first><last>Boyd-Graber</last></author>
      <author><first>Samuel</first><last>Carton</last></author>
      <author><first>Shi</first><last>Feng</last></author>
      <author><first>Q. Vera</first><last>Liao</last></author>
      <author><first>Tania</first><last>Lombrozo</last></author>
      <author><first>Alison</first><last>Smith-Renner</last></author>
      <author><first>Chenhao</first><last>Tan</last></author>
      <pages>26-32</pages>
      <abstract>The NLP community are increasingly interested in providing explanations for NLP models to help people make sense of model behavior and potentially improve human interaction with models. In addition to computational challenges in generating these explanations, evaluations of the generated explanations require human-centered perspectives and approaches. This tutorial will provide an overview of human-centered evaluations of explanations. First, we will give a brief introduction to the psychological foundation of explanations as well as types of NLP model explanations and their corresponding presentation, to provide the necessary background. We will then present a taxonomy of human-centered evaluation of explanations and dive into depth in the two categories: 1) evaluation based on human-annotated explanations; 2) evaluation with human-subjects studies. We will conclude by discussing future directions. We will also adopt a flipped format to maximize the in- teractive components for the live audience.</abstract>
      <url hash="65505c52">2022.naacl-tutorials.4</url>
      <bibkey>boyd-graber-etal-2022-human</bibkey>
    </paper>
    <paper id="5">
      <title>Tutorial on Multimodal Machine Learning</title>
      <author><first>Louis-Philippe</first><last>Morency</last></author>
      <author><first>Paul Pu</first><last>Liang</last></author>
      <author><first>Amir</first><last>Zadeh</last></author>
      <pages>33-38</pages>
      <abstract>Multimodal machine learning involves integrating and modeling information from multiple heterogeneous sources of data. It is a challenging yet crucial area with numerous real-world applications in multimedia, affective computing, robotics, finance, HCI, and healthcare. This tutorial, building upon a new edition of a survey paper on multimodal ML as well as previously-given tutorials and academic courses, will describe an updated taxonomy on multimodal machine learning synthesizing its core technical challenges and major directions for future research.</abstract>
      <url hash="6052e7c9">2022.naacl-tutorials.5</url>
      <bibkey>morency-etal-2022-tutorial</bibkey>
    </paper>
    <paper id="6">
      <title>Contrastive Data and Learning for Natural Language Processing</title>
      <author><first>Rui</first><last>Zhang</last></author>
      <author><first>Yangfeng</first><last>Ji</last></author>
      <author><first>Yue</first><last>Zhang</last></author>
      <author><first>Rebecca J.</first><last>Passonneau</last></author>
      <pages>39-47</pages>
      <abstract>Current NLP models heavily rely on effective representation learning algorithms. Contrastive learning is one such technique to learn an embedding space such that similar data sample pairs have close representations while dissimilar samples stay far apart from each other. It can be used in supervised or unsupervised settings using different loss functions to produce task-specific or general-purpose representations. While it has originally enabled the success for vision tasks, recent years have seen a growing number of publications in contrastive NLP. This first line of works not only delivers promising performance improvements in various NLP tasks, but also provides desired characteristics such as task-agnostic sentence representation, faithful text generation, data-efficient learning in zero-shot and few-shot settings, interpretability and explainability. In this tutorial, we aim to provide a gentle introduction to the fundamentals of contrastive learning approaches and the theory behind them. We then survey the benefits and the best practices of contrastive learning for various downstream NLP applications including Text Classification, Question Answering, Summarization, Text Generation, Interpretability and Explainability, Commonsense Knowledge and Reasoning, Vision-and-Language.This tutorial intends to help researchers in the NLP and computational linguistics community to understand this emerging topic and promote future research directions of using contrastive learning for NLP applications.</abstract>
      <url hash="46b089ea">2022.naacl-tutorials.6</url>
      <bibkey>zhang-etal-2022-contrastive-data</bibkey>
    </paper>
  </volume>
  <volume id="srw" ingest-date="2022-06-28">
    <meta>
      <booktitle>Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: \\ Human Language Technologies: Student Research Workshop</booktitle>
      <editor><first>Daphne</first><last>Ippolito</last></editor>
      <editor><first>Liunian Harold</first><last>Li</last></editor>
      <editor><first>Maria Leonor</first><last>Pacheco</last></editor>
      <editor><first>Danqi</first><last>Chen</last></editor>
      <editor><first>Nianwen</first><last>Xue</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Hybrid: Seattle, Washington + Online</address>
      <month>July</month>
      <year>2022</year>
      <url hash="a57edf60">2022.naacl-srw</url>
    </meta>
    <frontmatter>
      <url hash="a57edf60">2022.naacl-srw.0</url>
      <bibkey>naacl-2022-2022-north</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Systematicity Emerges in Transformers when Abstract Grammatical Roles Guide Attention</title>
      <author><first>Ayush K</first><last>Chakravarthy</last></author>
      <author><first>Jacob Labe</first><last>Russin</last></author>
      <author><first>Randall</first><last>O’Reilly</last></author>
      <pages>1-8</pages>
      <abstract>Systematicity is thought to be a key inductive bias possessed by humans that is lacking in standard natural language processing systems such as those utilizing transformers. In this work, we investigate the extent to which the failure of transformers on systematic generalization tests can be attributed to a lack of linguistic abstraction in its attention mechanism. We develop a novel modification to the transformer by implementing two separate input streams: a role stream controls the attention distributions (i.e., queries and keys) at each layer, and a filler stream determines the values. Our results show that when abstract role labels are assigned to input sequences and provided to the role stream, systematic generalization is improved.</abstract>
      <url hash="78d83891">2022.naacl-srw.1</url>
      <bibkey>chakravarthy-etal-2022-systematicity</bibkey>
    </paper>
    <paper id="2">
      <title>Grounding in social media: An approach to building a chit-chat dialogue model</title>
      <author><first>Ritvik</first><last>Choudhary</last></author>
      <author><first>Daisuke</first><last>Kawahara</last></author>
      <pages>9-15</pages>
      <abstract>Building open-domain dialogue systems capable of rich human-like conversational ability is one of the fundamental challenges in language generation. However, even with recent advancements in the field, existing open-domain generative models fail to capture and utilize external knowledge, leading to repetitive or generic responses to unseen utterances. Current work on knowledge-grounded dialogue generation primarily focuses on persona incorporation or searching a fact-based structured knowledge source such as Wikipedia. Our method takes a broader and simpler approach, which aims to improve the raw conversation ability of the system by mimicking the human response behavior through casual interactions found on social media. Utilizing a joint retriever-generator setup, the model queries a large set of filtered comment data from Reddit to act as additional context for the seq2seq generator. Automatic and human evaluations on open-domain dialogue datasets demonstrate the effectiveness of our approach.</abstract>
      <url hash="2bc40cf5">2022.naacl-srw.2</url>
      <bibkey>choudhary-kawahara-2022-grounding</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>E</fixed-case>xtra<fixed-case>P</fixed-case>hrase: Efficient Data Augmentation for Abstractive Summarization</title>
      <author><first>Mengsay</first><last>Loem</last></author>
      <author><first>Sho</first><last>Takase</last></author>
      <author><first>Masahiro</first><last>Kaneko</last></author>
      <author><first>Naoaki</first><last>Okazaki</last></author>
      <pages>16-24</pages>
      <abstract>Neural models trained with large amount of parallel data have achieved impressive performance in abstractive summarization tasks. However, large-scale parallel corpora are expensive and challenging to construct. In this work, we introduce a low-cost and effective strategy, ExtraPhrase, to augment training data for abstractive summarization tasks. ExtraPhrase constructs pseudo training data in two steps: extractive summarization and paraphrasing. We extract major parts of an input text in the extractive summarization step and obtain its diverse expressions with the paraphrasing step. Through experiments, we show that ExtraPhrase improves the performance of abstractive summarization tasks by more than 0.50 points in ROUGE scores compared to the setting without data augmentation. ExtraPhrase also outperforms existing methods such as back-translation and self-training. We also show that ExtraPhrase is significantly effective when the amount of genuine training data is remarkably small, i.e., a low-resource setting. Moreover, ExtraPhrase is more cost-efficient than the existing approaches</abstract>
      <url hash="2b495afb">2022.naacl-srw.3</url>
      <bibkey>loem-etal-2022-extraphrase</bibkey>
    </paper>
    <paper id="4">
      <title>Regularized Training of Nearest Neighbor Language Models</title>
      <author><first>Jean-Francois</first><last>Ton</last></author>
      <author><first>Walter</first><last>Talbott</last></author>
      <author><first>Shuangfei</first><last>Zhai</last></author>
      <author><first>Joshua M.</first><last>Susskind</last></author>
      <pages>25-30</pages>
      <abstract>Including memory banks in a natural language processing architecture increases model capacity by equipping it with additional data at inference time. In this paper, we build upon <tex-math>k</tex-math>NN-LM (CITATION), which uses a pre-trained language model together with an exhaustive <tex-math>k</tex-math>NN search through the training data (memory bank) to achieve state-of-the-art results. We investigate whether we can improve the <tex-math>k</tex-math>NN-LM performance by instead training a LM with the knowledge that we will be using a <tex-math>k</tex-math>NN post-hoc. We achieved significant improvement using our method on language modeling tasks on WIKI-2 and WIKI-103. The main phenomenon that we encounter is that adding a simple L2 regularization on the activations (not weights) of the model, a transformer, improves the post-hoc <tex-math>k</tex-math>NN classification performance. We explore some possible reasons for this improvement. In particular, we find that the added L2 regularization seems to improve the performance for high-frequency words without deteriorating the performance for low frequency ones.</abstract>
      <url hash="95d9852b">2022.naacl-srw.4</url>
      <bibkey>ton-etal-2022-regularized</bibkey>
    </paper>
    <paper id="5">
      <title>“Again, Dozens of Refugees Drowned”: A Computational Study of Political Framing Evoked by Presuppositions</title>
      <author><first>Qi</first><last>Yu</last></author>
      <pages>31-43</pages>
      <abstract>Earlier NLP studies on framing in political discourse have focused heavily on shallow classification of issue framing, while framing effect arising from pragmatic cues remains neglected. We put forward this latter type of framing as “pragmatic framing”. To bridge this gap, we take presupposition-triggering adverbs such as ‘again’ as a study case, and quantitatively investigate how different German newspapers use them to covertly evoke different attitudinal subtexts in their report on the event “European Refugee Crisis” (2014-2018). Our study demonstrates the crucial role of presuppositions in framing, and emphasizes the necessity of more attention on pragmatic framing in the research of automated framing detection.</abstract>
      <url hash="df0caf23">2022.naacl-srw.5</url>
      <bibkey>yu-2022-dozens</bibkey>
    </paper>
    <paper id="6">
      <title>Methods for Estimating and Improving Robustness of Language Models</title>
      <author><first>Michal</first><last>Stefanik</last></author>
      <pages>44-51</pages>
      <abstract>Despite their outstanding performance, large language models (LLMs) suffer notorious flaws related to their preference for shallow textual relations over full semantic complexity of the problem. This proposal investigates a common denominator of this problem in their weak ability to generalise outside of the training domain. We survey diverse research directions providing estimations of model generalisation ability and find that incorporating some of these measures in the training objectives leads to enhanced distributional robustness of neural models. Based on these findings, we present future research directions enhancing the robustness of LLMs.</abstract>
      <url hash="90567f54">2022.naacl-srw.6</url>
      <bibkey>stefanik-2022-methods</bibkey>
    </paper>
    <paper id="7">
      <title>Retrieval-augmented Generation across Heterogeneous Knowledge</title>
      <author><first>Wenhao</first><last>Yu</last></author>
      <pages>52-58</pages>
      <abstract>Retrieval-augmented generation (RAG) methods have been receiving increasing attention from the NLP community and achieved state-of-the-art performance on many NLP downstream tasks. Compared with conventional pre-trained generation models, RAG methods have remarkable advantages such as easy knowledge acquisition, strong scalability, and low training cost. Although existing RAG models have been applied to various knowledge-intensive NLP tasks, such as open-domain QA and dialogue systems, most of the work has focused on retrieving unstructured text documents from Wikipedia. In this paper, I first elaborate on the current obstacles to retrieving knowledge from a single-source homogeneous corpus. Then, I demonstrate evidence from both existing literature and my experiments, and provide multiple solutions on retrieval-augmented generation methods across heterogeneous knowledge.</abstract>
      <url hash="2b8ed428">2022.naacl-srw.7</url>
      <bibkey>yu-2022-retrieval</bibkey>
    </paper>
    <paper id="8">
      <title>Neural Retriever and Go Beyond: A Thesis Proposal</title>
      <author><first>Man</first><last>Luo</last></author>
      <pages>59-67</pages>
      <abstract>Information Retriever (IR) aims to find the relevant documents (e.g. snippets, passages, and articles) to a given query at large scale. IR plays an important role in many tasks such as open domain question answering and dialogue systems, where external knowledge is needed. In the past, searching algorithms based on term matching have been widely used. Recently, neural-based algorithms (termed as neural retrievers) have gained more attention which can mitigate the limitations of traditional methods. Regardless of the success achieved by neural retrievers, they still face many challenges, e.g. suffering from a small amount of training data and failing to answer simple entity-centric questions. Furthermore, most of the existing neural retrievers are developed for pure-text query. This prevents them from handling multi-modality queries (i.e. the query is composed of textual description and images). This proposal has two goals. First, we introduce methods to address the abovementioned issues of neural retrievers from three angles, new model architectures, IR-oriented pretraining tasks, and generating large scale training data. Second, we identify the future research direction and propose potential corresponding solution.</abstract>
      <url hash="3e721e03">2022.naacl-srw.8</url>
      <bibkey>luo-2022-neural</bibkey>
    </paper>
    <paper id="9">
      <title>Improving Classification of Infrequent Cognitive Distortions: Domain-Specific Model vs. Data Augmentation</title>
      <author><first>Xiruo</first><last>Ding</last></author>
      <author><first>Kevin</first><last>Lybarger</last></author>
      <author><first>Justin</first><last>Tauscher</last></author>
      <author><first>Trevor</first><last>Cohen</last></author>
      <pages>68-75</pages>
      <abstract>Cognitive distortions are counterproductive patterns of thinking that are one of the targets of cognitive behavioral therapy (CBT). These can be challenging for clinicians to detect, especially those without extensive CBT training or supervision. Text classification methods can approximate expert clinician judgment in the detection of frequently occurring cognitive distortions in text-based therapy messages. However, performance with infrequent distortions is relatively poor. In this study, we address this sparsity problem with two approaches: Data Augmentation and Domain-Specific Model. The first approach includes Easy Data Augmentation, back translation, and mixup techniques. The second approach utilizes a domain-specific pretrained language model, MentalBERT. To examine the viability of different data augmentation methods, we utilized a real-world dataset of texts between therapists and clients diagnosed with serious mental illness that was annotated for distorted thinking. We found that with optimized parameter settings, mixup was helpful for rare classes. Performance improvements with an augmented model, MentalBERT, exceed those obtained with data augmentation.</abstract>
      <url hash="0b5fac5c">2022.naacl-srw.9</url>
      <bibkey>ding-etal-2022-improving</bibkey>
    </paper>
    <paper id="10">
      <title>Generate, Evaluate, and Select: A Dialogue System with a Response Evaluator for Diversity-Aware Response Generation</title>
      <author><first>Ryoma</first><last>Sakaeda</last></author>
      <author><first>Daisuke</first><last>Kawahara</last></author>
      <pages>76-82</pages>
      <abstract>We aim to overcome the lack of diversity in responses of current dialogue systems and to develop a dialogue system that is engaging as a conversational partner. We propose a generator-evaluator model that evaluates multiple responses generated by a response generator and selects the best response by an evaluator. By generating multiple responses, we obtain diverse responses. We conduct human evaluations to compare the output of the proposed system with that of a baseline system. The results of the human evaluations showed that the proposed system’s responses were often judged to be better than the baseline system’s, and indicated the effectiveness of the proposed method.</abstract>
      <url hash="652d78e4">2022.naacl-srw.10</url>
      <bibkey>sakaeda-kawahara-2022-generate</bibkey>
    </paper>
    <paper id="11">
      <title>Impact of Training Instance Selection on Domain-Specific Entity Extraction using <fixed-case>BERT</fixed-case></title>
      <author><first>Eileen</first><last>Salhofer</last></author>
      <author><first>Xing Lan</first><last>Liu</last></author>
      <author><first>Roman</first><last>Kern</last></author>
      <pages>83-88</pages>
      <abstract>State of the art performances for entity extraction tasks are achieved by supervised learning, specifically, by fine-tuning pretrained language models such as BERT. As a result, annotating application specific data is the first step in many use cases. However, no practical guidelines are available for annotation requirements. This work supports practitioners by empirically answering the frequently asked questions (1) how many training samples to annotate? (2) which examples to annotate? We found that BERT achieves up to 80% F1 when fine-tuned on only 70 training examples, especially on biomedical domain. The key features for guiding the selection of high performing training instances are identified to be pseudo-perplexity and sentence-length. The best training dataset constructed using our proposed selection strategy shows F1 score that is equivalent to a random selection with twice the sample size. The requirement of only a small number of training data implies cheaper implementations and opens door to wider range of applications.</abstract>
      <url hash="82d160d5">2022.naacl-srw.11</url>
      <bibkey>salhofer-etal-2022-impact</bibkey>
    </paper>
    <paper id="12">
      <title>Analysing the Correlation between Lexical Ambiguity and Translation Quality in a Multimodal Setting using <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et</title>
      <author><first>Ali</first><last>Hatami</last></author>
      <author><first>Paul</first><last>Buitelaar</last></author>
      <author><first>Mihael</first><last>Arcan</last></author>
      <pages>89-95</pages>
      <abstract>Multimodal Neural Machine Translation is focusing on using visual information to translate sentences in the source language into the target language. The main idea is to utilise information from visual modalities to promote the output quality of the text-based translation model. Although the recent multimodal strategies extract the most relevant visual information in images, the effectiveness of using visual information on translation quality changes based on the text dataset. Due to this, this work studies the impact of leveraging visual information in multimodal translation models of ambiguous sentences. Our experiments analyse the Multi30k evaluation dataset and calculate ambiguity scores of sentences based on the WordNet hierarchical structure. To calculate the ambiguity of a sentence, we extract the ambiguity scores for all nouns based on the number of senses in WordNet. The main goal is to find in which sentences, visual content can improve the text-based translation model. We report the correlation between the ambiguity scores and translation quality extracted for all sentences in the English-German dataset.</abstract>
      <url hash="af9ad37b">2022.naacl-srw.12</url>
      <bibkey>hatami-etal-2022-analysing</bibkey>
    </paper>
    <paper id="13">
      <title>Building a Personalized Dialogue System with Prompt-Tuning</title>
      <author><first>Tomohito</first><last>Kasahara</last></author>
      <author><first>Daisuke</first><last>Kawahara</last></author>
      <author><first>Nguyen</first><last>Tung</last></author>
      <author><first>Shengzhe</first><last>Li</last></author>
      <author><first>Kenta</first><last>Shinzato</last></author>
      <author><first>Toshinori</first><last>Sato</last></author>
      <pages>96-105</pages>
      <abstract>Dialogue systems without consistent responses are not attractive. In this study, we build a dialogue system that can respond based on a given character setting (persona) to bring consistency. Considering the trend of the rapidly increasing scale of language models, we propose an approach that uses prompt-tuning, which has low learning costs, on pre-trained large-scale language models. The results of the automatic and manual evaluations in English and Japanese show that it is possible to build a dialogue system with more natural and personalized responses with less computational resources than fine-tuning.</abstract>
      <url hash="19f01cfb">2022.naacl-srw.13</url>
      <bibkey>kasahara-etal-2022-building</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>MM</fixed-case>-<fixed-case>GATBT</fixed-case>: Enriching Multimodal Representation Using Graph Attention Network</title>
      <author><first>Seung Byum</first><last>Seo</last></author>
      <author><first>Hyoungwook</first><last>Nam</last></author>
      <author><first>Payam</first><last>Delgosha</last></author>
      <pages>106-112</pages>
      <abstract>While there have been advances in Natural Language Processing (NLP), their success is mainly gained by applying a self-attention mechanism into single or multi-modalities. While this approach has brought significant improvements in multiple downstream tasks, it fails to capture the interaction between different entities. Therefore, we propose MM-GATBT, a multimodal graph representation learning model that captures not only the relational semantics within one modality but also the interactions between different modalities. Specifically, the proposed method constructs image-based node embedding which contains relational semantics of entities. Our empirical results show that MM-GATBT achieves state-of-the-art results among all published papers on the MM-IMDb dataset.</abstract>
      <url hash="84191ea8">2022.naacl-srw.14</url>
      <bibkey>seo-etal-2022-mm</bibkey>
    </paper>
    <paper id="15">
      <title>Simulating Feature Structures with Simple Types</title>
      <author><first>Valentin D.</first><last>Richard</last></author>
      <pages>113-122</pages>
      <abstract>Feature structures have been several times considered to enrich categorial grammars in order to build fine-grained grammars. Most attempts to unify both frameworks either model categorial types as feature structures or add feature structures on top of categorial types. We pursue a different approach: using feature structure as categorial atomic types. In this article, we present a procedure to create, from a simplified HPSG grammar, an equivalent abstract categorial grammar (ACG). We represent a feature structure by the enumeration of its totally well-typed upper bounds, so that unification can be simulated as intersection. We implement this idea as a meta-ACG preprocessor.</abstract>
      <url hash="59c29c02">2022.naacl-srw.15</url>
      <bibkey>richard-2022-simulating</bibkey>
    </paper>
    <paper id="16">
      <title>Dr. Livingstone, <fixed-case>I</fixed-case> presume? Polishing of foreign character identification in literary texts</title>
      <author><first>Aleksandra</first><last>Konovalova</last></author>
      <author><first>Antonio</first><last>Toral</last></author>
      <author><first>Kristiina</first><last>Taivalkoski-Shilov</last></author>
      <pages>123-128</pages>
      <abstract>Character identification is a key element for many narrative-related tasks. To implement it, the baseform of the name of the character (or lemma) needs to be identified, so different appearances of the same character in the narrative could be aligned. In this paper we tackle this problem in translated texts (English–Finnish translation direction), where the challenge regarding lemmatizing foreign names in an agglutinative language appears. To solve this problem, we present and compare several methods. The results show that the method based on a search for the shortest version of the name proves to be the easiest, best performing (83.4% F1), and most resource-independent.</abstract>
      <url hash="1f44c27e">2022.naacl-srw.16</url>
      <bibkey>konovalova-etal-2022-dr</bibkey>
    </paper>
    <paper id="17">
      <title>Zuo Zhuan <fixed-case>A</fixed-case>ncient <fixed-case>C</fixed-case>hinese Dataset for Word Sense Disambiguation</title>
      <author><first>Xiaomeng</first><last>Pan</last></author>
      <author><first>Hongfei</first><last>Wang</last></author>
      <author><first>Teruaki</first><last>Oka</last></author>
      <author><first>Mamoru</first><last>Komachi</last></author>
      <pages>129-135</pages>
      <abstract>Word Sense Disambiguation (WSD) is a core task in Natural Language Processing (NLP). Ancient Chinese has rarely been used in WSD tasks, however, as no public dataset for ancient Chinese WSD tasks exists. Creation of an ancient Chinese dataset is considered a significant challenge because determining the most appropriate sense in a context is difficult and time-consuming owing to the different usages in ancient and modern Chinese. Actually, no public dataset for ancient Chinese WSD tasks exists. To solve the problem of ancient Chinese WSD, we annotate part of Pre-Qin (221 BC) text <i>Zuo Zhuan</i> using a copyright-free dictionary to create a public sense-tagged dataset. Then, we apply a simple Nearest Neighbors (k-NN) method using a pre-trained language model to the dataset. Our code and dataset will be available on GitHub.</abstract>
      <url hash="b4c635d0">2022.naacl-srw.17</url>
      <bibkey>pan-etal-2022-zuo</bibkey>
    </paper>
    <paper id="18">
      <title><fixed-case>V</fixed-case>i<fixed-case>T</fixed-case>5: Pretrained Text-to-Text Transformer for <fixed-case>V</fixed-case>ietnamese Language Generation</title>
      <author><first>Long</first><last>Phan</last></author>
      <author><first>Hieu</first><last>Tran</last></author>
      <author><first>Hieu</first><last>Nguyen</last></author>
      <author><first>Trieu H.</first><last>Trinh</last></author>
      <pages>136-142</pages>
      <abstract>We present ViT5, a pretrained Transformer-based encoder-decoder model for the Vietnamese language. With T5-style self-supervised pretraining, ViT5 is trained on a large corpus of high-quality and diverse Vietnamese texts. We benchmark ViT5 on two downstream text generation tasks, Abstractive Text Summarization and Named Entity Recognition. Although Abstractive Text Summarization has been widely studied for the English language thanks to its rich and large source of data, there has been minimal research into the same task in Vietnamese, a much lower resource language. In this work, we perform exhaustive experiments on both Vietnamese Abstractive Summarization and Named Entity Recognition, validating the performance of ViT5 against many other pretrained Transformer-based encoder-decoder models. Our experiments show that ViT5 significantly outperforms existing models and achieves state-of-the-art results on Vietnamese Text Summarization. On the task of Named Entity Recognition, ViT5 is competitive against previous best results from pretrained encoder-based Transformer models. Further analysis shows the importance of context length during the self-supervised pretraining on downstream performance across different settings.</abstract>
      <url hash="ee2cd4a9">2022.naacl-srw.18</url>
      <bibkey>phan-etal-2022-vit5</bibkey>
    </paper>
    <paper id="19">
      <title>Compositional Generalization in Grounded Language Learning via Induced Model Sparsity</title>
      <author><first>Sam</first><last>Spilsbury</last></author>
      <author><first>Alexander</first><last>Ilin</last></author>
      <pages>143-155</pages>
      <abstract>We provide a study of how induced model sparsity can help achieve compositional generalization and better sample efficiency in grounded language learning problems. We consider simple language-conditioned navigation problems in a grid world environment with disentangled observations. We show that standard neural architectures do not always yield compositional generalization. To address this, we design an agent that contains a goal identification module that encourages sparse correlations between words in the instruction and attributes of objects, composing them together to find the goal. The output of the goal identification module is the input to a value iteration network planner. Our agent maintains a high level of performance on goals containing novel combinations of properties even when learning from a handful of demonstrations. We examine the internal representations of our agent and find the correct correspondences between words in its dictionary and attributes in the environment.</abstract>
      <url hash="b31f5351">2022.naacl-srw.19</url>
      <bibkey>spilsbury-ilin-2022-compositional</bibkey>
    </paper>
    <paper id="20">
      <title>How do people talk about images? A study on open-domain conversations with images.</title>
      <author><first>Yi-Pei</first><last>Chen</last></author>
      <author><first>Nobuyuki</first><last>Shimizu</last></author>
      <author><first>Takashi</first><last>Miyazaki</last></author>
      <author><first>Hideki</first><last>Nakayama</last></author>
      <pages>156-162</pages>
      <abstract>This paper explores how humans conduct conversations with images by investigating an open-domain image conversation dataset, ImageChat. We examined the conversations with images from the perspectives of <tex-math>\textit{image relevancy}</tex-math> and <tex-math>\textit{image information}</tex-math>. We found that utterances/conversations are not always related to the given image, and conversation topics diverge within three turns about half of the time. Besides image objects, more comprehensive non-object image information is also indispensable. After inspecting the causes, we suggested that understanding the overall scenario of image and connecting objects based on their high-level attributes might be very helpful to generate more engaging open-domain conversations when an image is presented. We proposed enriching the image information with image caption and object tags based on our analysis. With our proposed <tex-math>\textit{image}^{+}</tex-math> features, we improved automatic metrics including BLEU and Bert Score, and increased the diversity and image-relevancy of generated responses to the strong baseline. The result verifies that our analysis provides valuable insights and could facilitate future research on open-domain conversations with images.</abstract>
      <url hash="2e0bb714">2022.naacl-srw.20</url>
      <bibkey>chen-etal-2022-people</bibkey>
    </paper>
    <paper id="21">
      <title>Text Style Transfer for Bias Mitigation using Masked Language Modeling</title>
      <author><first>Ewoenam Kwaku</first><last>Tokpo</last></author>
      <author><first>Toon</first><last>Calders</last></author>
      <pages>163-171</pages>
      <abstract>It is well known that textual data on the internet and other digital platforms contain significant levels of bias and stereotypes. Various research findings have concluded that biased texts have significant effects on target demographic groups. For instance, masculine-worded job advertisements tend to be less appealing to female applicants. In this paper, we present a text-style transfer model that can be trained on non-parallel data and be used to automatically mitigate bias in textual data. Our style transfer model improves on the limitations of many existing text style transfer techniques such as the loss of content information. Our model solves such issues by combining latent content encoding with explicit keyword replacement. We will show that this technique produces better content preservation whilst maintaining good style transfer accuracy.</abstract>
      <url hash="125037de">2022.naacl-srw.21</url>
      <bibkey>tokpo-calders-2022-text</bibkey>
    </paper>
    <paper id="22">
      <title>Differentially Private Instance Encoding against Privacy Attacks</title>
      <author><first>Shangyu</first><last>Xie</last></author>
      <author><first>Yuan</first><last>Hong</last></author>
      <pages>172-180</pages>
      <abstract>TextHide was recently proposed to protect the training data via instance encoding in natural language domain. Due to the lack of theoretic privacy guarantee, such instance encoding scheme has been shown to be vulnerable against privacy attacks, e.g., reconstruction attack. To address such limitation, we revise the instance encoding scheme with differential privacy and thus provide a provable guarantee against privacy attacks. The experimental results also show that the proposed scheme can defend against privacy attacks while ensuring learning utility (as a trade-off).</abstract>
      <url hash="d78e031c">2022.naacl-srw.22</url>
      <bibkey>xie-hong-2022-differentially</bibkey>
    </paper>
    <paper id="23">
      <title>A Simple Approach to Jointly Rank Passages and Select Relevant Sentences in the <fixed-case>OBQA</fixed-case> Context</title>
      <author><first>Man</first><last>Luo</last></author>
      <author><first>Shuguang</first><last>Chen</last></author>
      <author><first>Chitta</first><last>Baral</last></author>
      <pages>181-187</pages>
      <abstract>In the open book question answering (OBQA) task, selecting the relevant passages and sentences from distracting information is crucial to reason the answer to a question. HotpotQA dataset is designed to teach and evaluate systems to do both passage ranking and sentence selection. Many existing frameworks use separate models to select relevant passages and sentences respectively. Such systems not only have high complexity in terms of the parameters of models but also fail to take the advantage of training these two tasks together since one task can be beneficial for the other one. In this work, we present a simple yet effective framework to address these limitations by jointly ranking passages and selecting sentences. Furthermore, we propose consistency and similarity constraints to promote the correlation and interaction between passage ranking and sentence selection.The experiments demonstrate that our framework can achieve competitive results with previous systems and outperform the baseline by 28% in terms of exact matching of relevant sentences on the HotpotQA dataset.</abstract>
      <url hash="8d0a2897">2022.naacl-srw.23</url>
      <bibkey>luo-etal-2022-simple</bibkey>
    </paper>
    <paper id="24">
      <title>Multimodal Modeling of Task-Mediated Confusion</title>
      <author><first>Camille</first><last>Mince</last></author>
      <author><first>Skye</first><last>Rhomberg</last></author>
      <author><first>Cecilia</first><last>Alm</last></author>
      <author><first>Reynold</first><last>Bailey</last></author>
      <author><first>Alex</first><last>Ororbia</last></author>
      <pages>188-194</pages>
      <abstract>In order to build more human-like cognitive agents, systems capable of detecting various human emotions must be designed to respond appropriately. Confusion, the combination of an emotional and cognitive state, is under-explored. In this paper, we build upon prior work to develop models that detect confusion from three modalities: video (facial features), audio (prosodic features), and text (transcribed speech features). Our research improves the data collection process by allowing for continuous (as opposed to discrete) annotation of confusion levels. We also craft models based on recurrent neural networks (RNNs) given their ability to predict sequential data. In our experiments, we find that text and video modalities are the most important in predicting confusion while the explored audio features are relatively unimportant predictors of confusion in our data.</abstract>
      <url hash="0e23f0f0">2022.naacl-srw.24</url>
      <bibkey>mince-etal-2022-multimodal</bibkey>
    </paper>
    <paper id="25">
      <title>Probe-Less Probing of <fixed-case>BERT</fixed-case>’s Layer-Wise Linguistic Knowledge with Masked Word Prediction</title>
      <author><first>Tatsuya</first><last>Aoyama</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>195-201</pages>
      <abstract>The current study quantitatively (and qualitatively for an illustrative purpose) analyzes BERT’s layer-wise masked word prediction on an English corpus, and finds that (1) the layerwise localization of linguistic knowledge primarily shown in probing studies is replicated in a behavior-based design and (2) that syntactic and semantic information is encoded at different layers for words of different syntactic categories. Hypothesizing that the above results are correlated with the number of likely potential candidates of the masked word prediction, we also investigate how the results differ for tokens within multiword expressions.</abstract>
      <url hash="c5ffc658">2022.naacl-srw.25</url>
      <bibkey>aoyama-schneider-2022-probe</bibkey>
    </paper>
    <paper id="26">
      <title>Multimodal large language models for inclusive collaboration learning tasks</title>
      <author><first>Armanda</first><last>Lewis</last></author>
      <pages>202-210</pages>
      <abstract>This PhD project leverages advancements in multimodal large language models to build an inclusive collaboration feedback loop, in order to facilitate the automated detection, modeling, and feedback for participants developing general collaboration skills. This topic is important given the role of collaboration as an essential 21st century skill, the potential to ground large language models within learning theory and real-world practice, and the expressive potential of transformer models to support equity and inclusion. We address some concerns of integrating advances in natural language processing into downstream tasks such as the learning analytics feedback loop.</abstract>
      <url hash="be160a18">2022.naacl-srw.26</url>
      <bibkey>lewis-2022-multimodal</bibkey>
    </paper>
    <paper id="27">
      <title>Neural Networks in a Product of Hyperbolic Spaces</title>
      <author><first>Jun</first><last>Takeuchi</last></author>
      <author><first>Noriki</first><last>Nishida</last></author>
      <author><first>Hideki</first><last>Nakayama</last></author>
      <pages>211-221</pages>
      <abstract>Machine learning in hyperbolic spaces has attracted much attention in natural language processing and many other fields. In particular, Hyperbolic Neural Networks (HNNs) have improved a wide variety of tasks, from machine translation to knowledge graph embedding. Although some studies have reported the effectiveness of embedding into the product of multiple hyperbolic spaces, HNNs have mainly been constructed in a single hyperbolic space, and their extension to product spaces has not been sufficiently studied. Therefore, we propose a novel method to extend a given HNN in a single space to a product of hyperbolic spaces. We apply our method to Hyperbolic Graph Convolutional Networks (HGCNs), extending several HNNs. Our model improved the graph node classification accuracy especially on datasets with tree-like structures. The results suggest that neural networks in a product of hyperbolic spaces can be more effective than in a single space in representing structural data.</abstract>
      <url hash="b9553eb8">2022.naacl-srw.27</url>
      <bibkey>takeuchi-etal-2022-neural</bibkey>
    </paper>
    <paper id="28">
      <title>Explicit Use of Topicality in Dialogue Response Generation</title>
      <author><first>Takumi</first><last>Yoshikoshi</last></author>
      <author><first>Hayato</first><last>Atarashi</last></author>
      <author><first>Takashi</first><last>Kodama</last></author>
      <author><first>Sadao</first><last>Kurohashi</last></author>
      <pages>222-228</pages>
      <abstract>The current chat dialogue systems implicitly consider the topic given the context, but not explicitly. As a result, these systems often generate inconsistent responses with the topic of the moment. In this study, we propose a dialogue system that responds appropriately following the topic by selecting the entity with the highest “topicality.” In topicality estimation, the model is trained through self-supervised learning that regards entities that appear in both context and response as the topic entities. In response generation, the model is trained to generate topic-relevant responses based on the estimated topicality. Experimental results show that our proposed system can follow the topic more than the existing dialogue system that considers only the context.</abstract>
      <url hash="779bb697">2022.naacl-srw.28</url>
      <bibkey>yoshikoshi-etal-2022-explicit</bibkey>
    </paper>
    <paper id="29">
      <title>Automating Human Evaluation of Dialogue Systems</title>
      <author><first>Sujan Reddy</first><last>A</last></author>
      <pages>229-234</pages>
      <abstract>Automated metrics to evaluate dialogue systems like BLEU, METEOR, etc., weakly correlate with human judgments. Thus, human evaluation is often used to supplement these metrics for system evaluation. However, human evaluation is time-consuming as well as expensive. This paper provides an alternative approach to human evaluation with respect to three aspects: naturalness, informativeness, and quality in dialogue systems. I propose an approach based on fine-tuning the BERT model with three prediction heads, to predict whether the system-generated output is natural, fluent, and informative. I observe that the proposed model achieves an average accuracy of around 77% over these 3 labels. I also design a baseline approach that uses three different BERT models to make the predictions. Based on experimental analysis, I find that using a shared model to compute the three labels performs better than three separate models.</abstract>
      <url hash="203aea07">2022.naacl-srw.29</url>
      <bibkey>a-2022-automating</bibkey>
    </paper>
    <paper id="30">
      <title>Strong Heuristics for Named Entity Linking</title>
      <author><first>Marko</first><last>Čuljak</last></author>
      <author><first>Andreas</first><last>Spitz</last></author>
      <author><first>Robert</first><last>West</last></author>
      <author><first>Akhil</first><last>Arora</last></author>
      <pages>235-246</pages>
      <abstract>Named entity linking (NEL) in news is a challenging endeavour due to the frequency of unseen and emerging entities, which necessitates the use of unsupervised or zero-shot methods. However, such methods tend to come with caveats, such as no integration of suitable knowledge bases (like Wikidata) for emerging entities, a lack of scalability, and poor interpretability. Here, we consider person disambiguation in Quotebank, a massive corpus of speaker-attributed quotations from the news, and investigate the suitability of intuitive, lightweight, and scalable heuristics for NEL in web-scale corpora. Our best performing heuristic disambiguates 94% and 63% of the mentions on Quotebank and the AIDA-CoNLL benchmark, respectively. Additionally, the proposed heuristics compare favourably to the state-of-the-art unsupervised and zero-shot methods, Eigenthemes and mGENRE, respectively, thereby serving as strong baselines for unsupervised and zero-shot entity linking.</abstract>
      <url hash="745ae789">2022.naacl-srw.30</url>
      <bibkey>culjak-etal-2022-strong</bibkey>
    </paper>
    <paper id="31">
      <title>Static and Dynamic Speaker Modeling based on Graph Neural Network for Emotion Recognition in Conversation</title>
      <author><first>Prakhar</first><last>Saxena</last></author>
      <author><first>Yin Jou</first><last>Huang</last></author>
      <author><first>Sadao</first><last>Kurohashi</last></author>
      <pages>247-253</pages>
      <abstract>Each person has a unique personality which affects how they feel and convey emotions. Hence, speaker modeling is important for the task of emotion recognition in conversation (ERC). In this paper, we propose a novel graph-based ERC model which considers both conversational context and speaker personality. We model the internal state of the speaker (personality) as Static and Dynamic speaker state, where the Dynamic speaker state is modeled with a graph neural network based encoder. Experiments on benchmark dataset shows the effectiveness of our model. Our model outperforms baseline and other graph-based methods. Analysis of results also show the importance of explicit speaker modeling.</abstract>
      <url hash="14d255a7">2022.naacl-srw.31</url>
      <bibkey>saxena-etal-2022-static</bibkey>
    </paper>
    <paper id="32">
      <title>Few-shot fine-tuning <fixed-case>SOTA</fixed-case> summarization models for medical dialogues</title>
      <author><first>David Fraile</first><last>Navarro</last></author>
      <author><first>Mark</first><last>Dras</last></author>
      <author><first>Shlomo</first><last>Berkovsky</last></author>
      <pages>254-266</pages>
      <abstract>Abstractive summarization of medical dialogues presents a challenge for standard training approaches, given the paucity of suitable datasets. We explore the performance of state-of-the-art models with zero-shot and few-shot learning strategies and measure the impact of pretraining with general domain and dialogue-specific text on the summarization performance.</abstract>
      <url hash="b58218c5">2022.naacl-srw.32</url>
      <bibkey>navarro-etal-2022-shot</bibkey>
    </paper>
    <paper id="33">
      <title>Unifying Parsing and Tree-Structured Models for Generating Sentence Semantic Representations</title>
      <author><first>Antoine</first><last>Simoulin</last></author>
      <author><first>Benoit</first><last>Crabbé</last></author>
      <pages>267-276</pages>
      <abstract>We introduce a novel tree-based model that learns its composition function together with its structure. The architecture produces sentence embeddings by composing words according to an induced syntactic tree. The parsing and the composition functions are explicitly connected and, therefore, learned jointly. As a result, the sentence embedding is computed according to an interpretable linguistic pattern and may be used on any downstream task. We evaluate our encoder on downstream tasks, and we observe that it outperforms tree-based models relying on external parsers. In some configurations, it is even competitive with Bert base model. Our model is capable of supporting multiple parser architectures. We exploit this property to conduct an ablation study by comparing different parser initializations. We explore to which extent the trees produced by our model compare with linguistic structures and how this initialization impacts downstream performances. We empirically observe that downstream supervision troubles producing stable parses and preserving linguistically relevant structures.</abstract>
      <url hash="14a0d134">2022.naacl-srw.33</url>
      <bibkey>simoulin-crabbe-2022-unifying</bibkey>
    </paper>
    <paper id="34">
      <title>Multiformer: A Head-Configurable Transformer-Based Model for Direct Speech Translation</title>
      <author><first>Gerard</first><last>Sant</last></author>
      <author><first>Gerard I.</first><last>Gállego</last></author>
      <author><first>Belen</first><last>Alastruey</last></author>
      <author><first>Marta Ruiz</first><last>Costa-jussà</last></author>
      <pages>277-284</pages>
      <abstract>Transformer-based models have been achieving state-of-the-art results in several fields of Natural Language Processing. However, its direct application to speech tasks is not trivial. The nature of this sequences carries problems such as long sequence lengths and redundancy between adjacent tokens. Therefore, we believe that regular self-attention mechanism might not be well suited for it. Different approaches have been proposed to overcome these problems, such as the use of efficient attention mechanisms. However, the use of these methods usually comes with a cost, which is a performance reduction caused by information loss. In this study, we present the Multiformer, a Transformer-based model which allows the use of different attention mechanisms on each head. By doing this, the model is able to bias the self-attention towards the extraction of more diverse token interactions, and the information loss is reduced. Finally, we perform an analysis of the head contributions, and we observe that those architectures where all heads relevance is uniformly distributed obtain better results. Our results show that mixing attention patterns along the different heads and layers outperforms our baseline by up to 0.7 BLEU.</abstract>
      <url hash="094b9633">2022.naacl-srw.34</url>
      <bibkey>sant-etal-2022-multiformer</bibkey>
    </paper>
    <paper id="35">
      <title>Defending Compositionality in Emergent Languages</title>
      <author><first>Michal</first><last>Auersperger</last></author>
      <author><first>Pavel</first><last>Pecina</last></author>
      <pages>285-291</pages>
      <abstract>Compositionality has traditionally been understood as a major factor in productivity of language and, more broadly, human cognition. Yet, recently some research started to question its status showing that artificial neural networks are good at generalization even without noticeable compositional behavior. We argue some of these conclusions are too strong and/or incomplete. In the context of a two-agent communication game, we show that compositionality indeed seems essential for successful generalization when the evaluation is done on a suitable dataset.</abstract>
      <url hash="bc9777b5">2022.naacl-srw.35</url>
      <bibkey>auersperger-pecina-2022-defending</bibkey>
    </paper>
    <paper id="36">
      <title>Exploring the Effect of Dialect Mismatched Language Models in <fixed-case>T</fixed-case>elugu Automatic Speech Recognition</title>
      <author><first>Aditya</first><last>Yadavalli</last></author>
      <author><first>Ganesh Sai</first><last>Mirishkar</last></author>
      <author><first>Anil</first><last>Vuppala</last></author>
      <pages>292-301</pages>
      <abstract>Previous research has found that Acoustic Models (AM) of an Automatic Speech Recognition (ASR) system are susceptible to dialect variations within a language, thereby adversely affecting the ASR. To counter this, researchers have proposed to build a dialect-specific AM while keeping the Language Model (LM) constant for all the dialects. This study explores the effect of dialect mismatched LM by considering three different Telugu regional dialects: Telangana, Coastal Andhra, and Rayalaseema. We show that dialect variations that surface in the form of a different lexicon, grammar, and occasionally semantics can significantly degrade the performance of the LM under mismatched conditions. Therefore, this degradation has an adverse effect on the ASR even when dialect-specific AM is used. We show a degradation of up to 13.13 perplexity points when LM is used under mismatched conditions. Furthermore, we show a degradation of over 9% and over 15% in Character Error Rate (CER) and Word Error Rate (WER), respectively, in the ASR systems when using mismatched LMs over matched LMs.</abstract>
      <url hash="12d93502">2022.naacl-srw.36</url>
      <bibkey>yadavalli-etal-2022-exploring</bibkey>
    </paper>
  </volume>
  <volume id="industry" ingest-date="2022-06-28">
    <meta>
      <booktitle>Proceedings of NAACL-HLT 2022: Industry Track Papers</booktitle>
      <editor><first>Anastassia</first><last>Loukina</last></editor>
      <editor><first>Rashmi</first><last>Gangadharaiah</last></editor>
      <editor><first>Bonan</first><last>Min</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Hybrid: Seattle, Washington + Online</address>
      <month>July</month>
      <year>2022</year>
      <url hash="b5f7d586">2022.naacl-industry</url>
    </meta>
    <frontmatter>
      <url hash="b5f7d586">2022.naacl-industry.0</url>
      <bibkey>naacl-2022-naacl</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Scalable and Robust Self-Learning for Skill Routing in Large-Scale Conversational <fixed-case>AI</fixed-case> Systems</title>
      <author><first>Mohammad</first><last>Kachuee</last></author>
      <author><first>Jinseok</first><last>Nam</last></author>
      <author><first>Sarthak</first><last>Ahuja</last></author>
      <author><first>Jin-Myung</first><last>Won</last></author>
      <author><first>Sungjin</first><last>Lee</last></author>
      <pages>1-8</pages>
      <abstract>Skill routing is an important component in large-scale conversational systems. In contrast to traditional rule-based skill routing, state-of-the-art systems use a model-based approach to enable natural conversations. To provide supervision signal required to train such models, ideas such as human annotation, replication of a rule-based system, relabeling based on user paraphrases, and bandit-based learning were suggested. However, these approaches: (a) do not scale in terms of the number of skills and skill on-boarding, (b) require a very costly expert annotation/rule-design, (c) introduce risks in the user experience with each model update. In this paper, we present a scalable self-learning approach to explore routing alternatives without causing abrupt policy changes that break the user experience, learn from the user interaction, and incrementally improve the routing via frequent model refreshes. To enable such robust frequent model updates, we suggest a simple and effective approach that ensures controlled policy updates for individual domains, followed by an off-policy evaluation for making deployment decisions without any need for lengthy A/B experimentation. We conduct various offline and online A/B experiments on a commercial large-scale conversational system to demonstrate the effectiveness of the proposed method in real-world production settings.</abstract>
      <url hash="98471458">2022.naacl-industry.1</url>
      <bibkey>kachuee-etal-2022-scalable</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>CREATER</fixed-case>: <fixed-case>CTR</fixed-case>-driven Advertising Text Generation with Controlled Pre-Training and Contrastive Fine-Tuning</title>
      <author><first>Penghui</first><last>Wei</last></author>
      <author><first>Xuanhua</first><last>Yang</last></author>
      <author><first>ShaoGuo</first><last>Liu</last></author>
      <author><first>Liang</first><last>Wang</last></author>
      <author><first>Bo</first><last>Zheng</last></author>
      <pages>9-17</pages>
      <abstract>This paper focuses on automatically generating the text of an ad, and the goal is that the generated text can capture user interest for achieving higher click-through rate (CTR). We propose CREATER, a CTR-driven advertising text generation approach, to generate ad texts based on high-quality user reviews. To incorporate CTR objective, our model learns from online A/B test data with contrastive learning, which encourages the model to generate ad texts that obtain higher CTR. To make use of large-scale unpaired reviews, we design a customized self-supervised objective reducing the gap between pre-training and fine-tuning. Experiments on industrial datasets show that CREATER significantly outperforms current approaches. It has been deployed online in a leading advertising platform and brings uplift on core online metrics.</abstract>
      <url hash="eea50163">2022.naacl-industry.2</url>
      <bibkey>wei-etal-2022-creater</bibkey>
    </paper>
    <paper id="3">
      <title>Augmenting Poetry Composition with <fixed-case>V</fixed-case>erse by <fixed-case>V</fixed-case>erse</title>
      <author><first>David</first><last>Uthus</last></author>
      <author><first>Maria</first><last>Voitovich</last></author>
      <author><first>R.j.</first><last>Mical</last></author>
      <pages>18-26</pages>
      <abstract>We describe Verse by Verse, our experiment in augmenting the creative process of writing poetry with an AI. We have created a group of AI poets, styled after various American classic poets, that are able to offer as suggestions generated lines of verse while a user is composing a poem. In this paper, we describe the underlying system to offer these suggestions. This includes a generative model, which is tasked with generating a large corpus of lines of verse offline and which are then stored in an index, and a dual-encoder model that is tasked with recommending the next possible set of verses from our index given the previous line of verse.</abstract>
      <url hash="2235db9a">2022.naacl-industry.3</url>
      <bibkey>uthus-etal-2022-augmenting</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>AB</fixed-case>/<fixed-case>BA</fixed-case> analysis: A framework for estimating keyword spotting recall improvement while maintaining audio privacy</title>
      <author><first>Raphael</first><last>Petegrosso</last></author>
      <author><first>VasistaKrishna</first><last>Baderdinnni</last></author>
      <author><first>Thibaud</first><last>Senechal</last></author>
      <author><first>Benjamin</first><last>Bullough</last></author>
      <pages>27-36</pages>
      <abstract>Evaluation of keyword spotting (KWS) systems that detect keywords in speech is a challenging task under realistic privacy constraints. The KWS is designed to only collect data when the keyword is present, limiting the availability of hard samples that may contain false negatives, and preventing direct estimation of model recall from production data. Alternatively, complementary data collected from other sources may not be fully representative of the real application. In this work, we propose an evaluation technique which we call AB/BA analysis. Our framework evaluates a candidate KWS model B against a baseline model A, using cross-dataset offline decoding for relative recall estimation, without requiring negative examples. Moreover, we propose a formulation with assumptions that allow estimation of relative false positive rate between models with low variance even when the number of false positives is small. Finally, we propose to leverage machine-generated soft labels, in a technique we call Semi-Supervised AB/BA analysis, that improves the analysis time, privacy, and cost. Experiments with both simulation and real data show that AB/BA analysis is successful at measuring recall improvement in conjunction with the trade-off in relative false positive rate.</abstract>
      <url hash="bdc84369">2022.naacl-industry.4</url>
      <bibkey>petegrosso-etal-2022-ab</bibkey>
    </paper>
    <paper id="5">
      <title>Temporal Generalization for Spoken Language Understanding</title>
      <author><first>Judith</first><last>Gaspers</last></author>
      <author><first>Anoop</first><last>Kumar</last></author>
      <author><first>Greg</first><last>Ver Steeg</last></author>
      <author><first>Aram</first><last>Galstyan</last></author>
      <pages>37-44</pages>
      <abstract>Spoken Language Understanding (SLU) models in industry applications are usually trained offline on historic data, but have to perform well on incoming user requests after deployment. Since the application data is not available at training time, this is formally similar to the domain generalization problem, where domains correspond to different temporal segments of the data, and the goal is to build a model that performs well on unseen domains, e.g., upcoming data. In this paper, we explore different strategies for achieving good temporal generalization, including instance weighting, temporal fine-tuning, learning temporal features and building a temporally-invariant model. Our results on data of large-scale SLU systems show that temporal information can be leveraged to improve temporal generalization for SLU models.</abstract>
      <url hash="c34842ac">2022.naacl-industry.5</url>
      <bibkey>gaspers-etal-2022-temporal</bibkey>
    </paper>
    <paper id="6">
      <title>An End-to-End Dialogue Summarization System for Sales Calls</title>
      <author><first>Abedelkadir</first><last>Asi</last></author>
      <author><first>Song</first><last>Wang</last></author>
      <author><first>Roy</first><last>Eisenstadt</last></author>
      <author><first>Dean</first><last>Geckt</last></author>
      <author><first>Yarin</first><last>Kuper</last></author>
      <author><first>Yi</first><last>Mao</last></author>
      <author><first>Royi</first><last>Ronen</last></author>
      <pages>45-53</pages>
      <abstract>Summarizing sales calls is a routine task performed manually by salespeople. We present a production system which combines generative models fine-tuned for customer-agent setting, with a human-in-the-loop user experience for an interactive summary curation process. We address challenging aspects of dialogue summarization task in a real-world setting including long input dialogues, content validation, lack of labeled data and quality evaluation. We show how GPT-3 can be leveraged as an offline data labeler to handle training data scarcity and accommodate privacy constraints in an industrial setting. Experiments show significant improvements by our models in tackling the summarization and content validation tasks on public datasets.</abstract>
      <url hash="00306085">2022.naacl-industry.6</url>
      <bibkey>asi-etal-2022-end</bibkey>
    </paper>
    <paper id="7">
      <title>Controlled Data Generation via Insertion Operations for <fixed-case>NLU</fixed-case></title>
      <author><first>Manoj</first><last>Kumar</last></author>
      <author><first>Yuval</first><last>Merhav</last></author>
      <author><first>Haidar</first><last>Khan</last></author>
      <author><first>Rahul</first><last>Gupta</last></author>
      <author><first>Anna</first><last>Rumshisky</last></author>
      <author><first>Wael</first><last>Hamza</last></author>
      <pages>54-61</pages>
      <abstract>Use of synthetic data is rapidly emerging as a realistic alternative to manually annotating live traffic for industry-scale model building. Manual data annotation is slow, expensive and not preferred for meeting customer privacy expectations. Further, commercial natural language applications are required to support continuously evolving features as well as newly added experiences. To address these requirements, we propose a targeted synthetic data generation technique by inserting tokens into a given semantic signature. The generated data are used as additional training samples in the tasks of intent classification and named entity recognition. We evaluate on a real-world voice assistant dataset, and using only 33% of the available training set, we achieve the same accuracy as training with all available data. Further, we analyze the effects of data generation across varied real-world applications and propose heuristics that improve the task performance further.</abstract>
      <url hash="5a1d7102">2022.naacl-industry.7</url>
      <bibkey>kumar-etal-2022-controlled</bibkey>
    </paper>
    <paper id="8">
      <title>Easy and Efficient Transformer: Scalable Inference Solution For Large <fixed-case>NLP</fixed-case> Model</title>
      <author><first>Gongzheng</first><last>Li</last></author>
      <author><first>Yadong</first><last>Xi</last></author>
      <author><first>Jingzhen</first><last>Ding</last></author>
      <author><first>Duan</first><last>Wang</last></author>
      <author><first>Ziyang</first><last>Luo</last></author>
      <author><first>Rongsheng</first><last>Zhang</last></author>
      <author><first>Bai</first><last>Liu</last></author>
      <author><first>Changjie</first><last>Fan</last></author>
      <author><first>Xiaoxi</first><last>Mao</last></author>
      <author><first>Zeng</first><last>Zhao</last></author>
      <pages>62-68</pages>
      <abstract>Recently, large-scale transformer-based models have been proven to be effective over various tasks across many domains. Nevertheless, applying them in industrial production requires tedious and heavy works to reduce inference costs. To fill such a gap, we introduce a scalable inference solution: <b>Easy and Efficient Transformer (EET)</b>, including a series of transformer inference optimization at the algorithm and implementation levels. First, we design highly optimized kernels for long inputs and large hidden sizes. Second, we propose a flexible CUDA memory manager to reduce the memory footprint when deploying a large model. Compared with the state-of-the-art transformer inference library (Faster Transformer v4.0), EET can achieve an average of 1.40-4.20x speedup on the transformer decoder layer with an A100 GPU.</abstract>
      <url hash="7d9a8de2">2022.naacl-industry.8</url>
      <bibkey>li-etal-2022-easy</bibkey>
    </paper>
    <paper id="9">
      <title>Aspect-based Analysis of Advertising Appeals for Search Engine Advertising</title>
      <author><first>Soichiro</first><last>Murakami</last></author>
      <author><first>Peinan</first><last>Zhang</last></author>
      <author><first>Sho</first><last>Hoshino</last></author>
      <author><first>Hidetaka</first><last>Kamigaito</last></author>
      <author><first>Hiroya</first><last>Takamura</last></author>
      <author><first>Manabu</first><last>Okumura</last></author>
      <pages>69-78</pages>
      <abstract>Writing an ad text that attracts people and persuades them to click or act is essential for the success of search engine advertising. Therefore, ad creators must consider various aspects of advertising appeals (A<tex-math>^3</tex-math>) such as the price, product features, and quality. However, products and services exhibit unique effective A<tex-math>^3</tex-math> for different industries. In this work, we focus on exploring the effective A<tex-math>^3</tex-math> for different industries with the aim of assisting the ad creation process. To this end, we created a dataset of advertising appeals and used an existing model that detects various aspects for ad texts. Our experiments demonstrated %through correlation analysis that different industries have their own effective A<tex-math>^3</tex-math> and that the identification of the A<tex-math>^3</tex-math> contributes to the estimation of advertising performance. </abstract>
      <url hash="a2ec38f9">2022.naacl-industry.9</url>
      <bibkey>murakami-etal-2022-aspect</bibkey>
    </paper>
    <paper id="10">
      <title>Self-supervised Product Title Rewrite for Product Listing Ads</title>
      <author><first>Xue</first><last>Zhao</last></author>
      <author><first>Dayiheng</first><last>Liu</last></author>
      <author><first>Junwei</first><last>Ding</last></author>
      <author><first>Liang</first><last>Yao</last></author>
      <author><first>Mahone</first><last>Yan</last></author>
      <author><first>Huibo</first><last>Wang</last></author>
      <author><first>Wenqing</first><last>Yao</last></author>
      <pages>79-85</pages>
      <abstract>Product Listing Ads (PLAs) are primary online advertisements merchants pay to attract more customers. However, merchants prefer to stack various attributes to the title and neglect the fluency and information priority. These seller-created titles are not suitable for PLAs as they fail to highlight the core information in the visible part in PLAs titles. In this work, we present a title rewrite solution. Specifically, we train a self-supervised language model to generate high-quality titles in terms of fluency and information priority. Extensive offline test and real-world online test have demonstrated that our solution is effective in reducing the cost and gaining more profit as it lowers our CPC, CPB while improving CTR in the online test by a large amount.</abstract>
      <url hash="25eaf32a">2022.naacl-industry.10</url>
      <bibkey>zhao-etal-2022-self</bibkey>
    </paper>
    <paper id="11">
      <title>Efficient Semi-supervised Consistency Training for Natural Language Understanding</title>
      <author><first>George</first><last>Leung</last></author>
      <author><first>Joshua</first><last>Tan</last></author>
      <pages>86-93</pages>
      <abstract>Manually labeled training data is expensive, noisy, and often scarce, such as when developing new features or localizing existing features for a new region. In cases where labeled data is limited but unlabeled data is abundant, semi-supervised learning methods such as consistency training can be used to improve model performance, by training models to output consistent predictions between original and augmented versions of unlabeled data.In this work, we explore different data augmentation methods for consistency training (CT) on Natural Language Understanding (NLU) domain classification (DC) in the limited labeled data regime. We explore three types of augmentation techniques (human paraphrasing, back-translation, and dropout) for unlabeled data and train DC models to jointly minimize both the supervised loss and the consistency loss on unlabeled data. Our results demonstrate that DC models trained with CT methods and dropout based augmentation on only 0.1% (2,998 instances) of labeled data with the remainder as unlabeled can achieve a top-1 relative accuracy reduction of 12.25% compared to fully supervised model trained with 100% of labeled data, outperforming fully supervised models trained on 10x that amount of labeled data. The dropout-based augmentation achieves similar performance compare to back-translation based augmentation with much less computational resources. This paves the way for applications of using large scale unlabeled data for semi-supervised learning in production NLU systems.</abstract>
      <url hash="fac24315">2022.naacl-industry.11</url>
      <bibkey>leung-tan-2022-efficient</bibkey>
    </paper>
    <paper id="12">
      <title>Distantly Supervised Aspect Clustering And Naming For <fixed-case>E</fixed-case>-Commerce Reviews</title>
      <author><first>Prateek</first><last>Sircar</last></author>
      <author><first>Aniket</first><last>Chakrabarti</last></author>
      <author><first>Deepak</first><last>Gupta</last></author>
      <author><first>Anirban</first><last>Majumdar</last></author>
      <pages>94-102</pages>
      <abstract>Product aspect extraction from reviews is a critical task for e-commerce services to understand customer preferences and pain points. While aspect phrases extraction and sentiment analysis have received a lot of attention, clustering of aspect phrases and assigning human readable names to clusters in e-commerce reviews is an extremely important and challenging problem due to the scale of the reviews that makes human review infeasible. In this paper, we propose fully automated methods for clustering aspect words and generating human readable names for the clusters without any manually labeled data. We train transformer based sentence embeddings that are aware of unique e-commerce language characteristics (eg. incomplete sentences, spelling and grammar errors, vernacular etc.). We also train transformer based sequence to sequence models to generate human readable aspect names from clusters. Both the models are trained using heuristic based distant supervision. Additionally, the models are used to improve each other. Extensive empirical testing showed that the clustering model improves the Silhouette Score by 64% when compared to the state-of-the-art baseline and the aspect naming model achieves a high ROUGE-L score of 0.79.</abstract>
      <url hash="a2eeb8cc">2022.naacl-industry.12</url>
      <bibkey>sircar-etal-2022-distantly</bibkey>
    </paper>
    <paper id="13">
      <title>Local-to-global learning for iterative training of production <fixed-case>SLU</fixed-case> models on new features</title>
      <author><first>Yulia</first><last>Grishina</last></author>
      <author><first>Daniil</first><last>Sorokin</last></author>
      <pages>103-111</pages>
      <abstract>In production SLU systems, new training data becomes available with time so that ML models need to be updated on a regular basis. Specifically, releasing new features adds new classes of data while the old data remains constant. However, retraining the full model each time from scratch is computationally expensive. To address this problem, we propose to consider production releases from the curriculum learning perspective and to adapt the local-to-global learning (LGL) schedule (Cheng et. al, 2019) for a statistical model that starts with fewer output classes and adds more classes with each iteration. We report experiments for the tasks of intent classification and slot filling in the context of a production voice-assistant. First, we apply the original LGL schedule on our data and then adapt LGL to the production setting where the full data is not available at initial training iterations. We demonstrate that our method improves model error rates by 7.3% and saves up to 25% training time for individual iterations.</abstract>
      <url hash="bce801a1">2022.naacl-industry.13</url>
      <bibkey>grishina-sorokin-2022-local</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>CULG</fixed-case>: Commercial Universal Language Generation</title>
      <author><first>Haonan</first><last>Li</last></author>
      <author><first>Yameng</first><last>Huang</last></author>
      <author><first>Yeyun</first><last>Gong</last></author>
      <author><first>Jian</first><last>Jiao</last></author>
      <author><first>Ruofei</first><last>Zhang</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Nan</first><last>Duan</last></author>
      <pages>112-120</pages>
      <abstract>Pre-trained language models (PLMs) have dramatically improved performance for many natural language processing (NLP) tasks in domains such as finance and healthcare. However, the application of PLMs in the domain of commerce, especially marketing and advertising, remains less studied. In this work, we adapt pre-training methods to the domain of commerce, by proposing CULG, a large-scale commercial universal language generation model which is pre-trained on a corpus drawn from 10 markets across 7 languages. We propose 4 commercial generation tasks and a two-stage training strategy for pre-training, and demonstrate that the proposed strategy yields performance improvements on three generation tasks as compared to single-stage pre-training. Extensive experiments show that our model outperforms other models by a large margin on commercial generation tasks, and we conclude with a discussion on additional applications over other markets, languages, and tasks.</abstract>
      <url hash="f76f0776">2022.naacl-industry.14</url>
      <bibkey>li-etal-2022-culg</bibkey>
    </paper>
    <paper id="15">
      <title>Constraining word alignments with posterior regularization for label transfer</title>
      <author><first>Thomas</first><last>Gueudre</last></author>
      <author><first>Kevin</first><last>Jose</last></author>
      <pages>121-129</pages>
      <abstract>Unsupervised word alignments offer a lightweight and interpretable method to transfer labels from high- to low-resource languages, as long as semantically related words have the same label across languages. But such an assumption is often not true in industrial NLP pipelines, where multilingual annotation guidelines are complex and deviate from semantic consistency due to various factors (such as annotation difficulty, conflicting ontology, upcoming feature launches etc.);We address this difficulty by constraining the alignments models to remain consistent with both source and target annotation guidelines , leveraging posterior regularization and labeled examples. We illustrate the overall approach using IBM 2 (fast_align) as a base model, and report results on both internal and external annotated datasets. We measure consistent accuracy improvements on the MultiATIS++ dataset over AWESoME, a popular transformer-based alignment model, in the label projection task (<tex-math>+2.7\%</tex-math> at word-level and <tex-math>+15\%</tex-math> at sentence-level), and show how even a small amount of target language annotations help substantially.</abstract>
      <url hash="b9b4a34d">2022.naacl-industry.15</url>
      <bibkey>gueudre-jose-2022-constraining</bibkey>
    </paper>
    <paper id="16">
      <title>Explaining the Effectiveness of Multi-Task Learning for Efficient Knowledge Extraction from Spine <fixed-case>MRI</fixed-case> Reports</title>
      <author><first>Arijit</first><last>Sehanobish</last></author>
      <author><first>McCullen</first><last>Sandora</last></author>
      <author><first>Nabila</first><last>Abraham</last></author>
      <author><first>Jayashri</first><last>Pawar</last></author>
      <author><first>Danielle</first><last>Torres</last></author>
      <author><first>Anasuya</first><last>Das</last></author>
      <author><first>Murray</first><last>Becker</last></author>
      <author><first>Richard</first><last>Herzog</last></author>
      <author><first>Benjamin</first><last>Odry</last></author>
      <author><first>Ron</first><last>Vianu</last></author>
      <pages>130-140</pages>
      <abstract>Pretrained Transformer based models finetuned on domain specific corpora have changed the landscape of NLP. However, training or fine-tuning these models for individual tasks can be time consuming and resource intensive. Thus, a lot of current research is focused on using transformers for multi-task learning (Raffel et al., 2020) and how to group the tasks to help a multi-task model to learn effective representations that can be shared across tasks (Standley et al., 2020; Fifty et al., 2021) . In this work, we show that a single multi-tasking model can match the performance of task specific model when the task specific models show similar representations across all of their hidden layers and their gradients are aligned, i.e. their gradients follow the same direction. We hypothesize that the above observations explain the effectiveness of multi-task learning. We validate our observations on our internal radiologist-annotated datasets on the cervical and lumbar spine. Our method is simple and intuitive, and can be used in a wide range of NLP problems.</abstract>
      <url hash="d2eea078">2022.naacl-industry.16</url>
      <bibkey>sehanobish-etal-2022-explaining</bibkey>
    </paper>
    <paper id="17">
      <title><fixed-case>FPI</fixed-case>: Failure Point Isolation in Large-scale Conversational Assistants</title>
      <author><first>Rinat</first><last>Khaziev</last></author>
      <author><first>Usman</first><last>Shahid</last></author>
      <author><first>Tobias</first><last>Röding</last></author>
      <author><first>Rakesh</first><last>Chada</last></author>
      <author><first>Emir</first><last>Kapanci</last></author>
      <author><first>Pradeep</first><last>Natarajan</last></author>
      <pages>141-148</pages>
      <abstract>Large-scale conversational assistants such as Cortana, Alexa, Google Assistant and Siri process requests through a series of modules for wake word detection, speech recognition, language understanding and response generation. An error in one of these modules can cascade through the system. Given the large traffic volumes in these assistants, it is infeasible to manually analyze the data, identify requests with processing errors and isolate the source of error. We present a machine learning system to address this challenge. First, we embed the incoming request and context, such as system response and subsequent turns, using pre-trained transformer models. Then, we combine these embeddings with encodings of additional metadata features (such as confidence scores from different modules in the online system) using a “mixing-encoder” to output the failure point predictions. Our system obtains 92.2% of human performance on this task while scaling to analyze the entire traffic in 8 different languages of a large-scale conversational assistant. We present detailed ablation studies analyzing the impact of different modeling choices.</abstract>
      <url hash="7fee073e">2022.naacl-industry.17</url>
      <bibkey>khaziev-etal-2022-fpi</bibkey>
    </paper>
    <paper id="18">
      <title>Asynchronous Convergence in Multi-Task Learning via Knowledge Distillation from Converged Tasks</title>
      <author><first>Weiyi</first><last>Lu</last></author>
      <author><first>Sunny</first><last>Rajagopalan</last></author>
      <author><first>Priyanka</first><last>Nigam</last></author>
      <author><first>Jaspreet</first><last>Singh</last></author>
      <author><first>Xiaodi</first><last>Sun</last></author>
      <author><first>Yi</first><last>Xu</last></author>
      <author><first>Belinda</first><last>Zeng</last></author>
      <author><first>Trishul</first><last>Chilimbi</last></author>
      <pages>149-159</pages>
      <abstract>Multi-task learning (MTL) aims to solve multiple tasks jointly by sharing a base representation among them. This can lead to more efficient learning and better generalization, as compared to learning each task individually. However, one issue that often arises in MTL is the convergence speed between tasks varies due to differences in task difficulty, so it can be a challenge to simultaneously achieve the best performance on all tasks with a single model checkpoint. Various techniques have been proposed to address discrepancies in task convergence rate, including weighting the per-task losses and modifying task gradients. In this work, we propose a novel approach that avoids the problem of requiring all tasks to converge at the same rate, but rather allows for “asynchronous” convergence among the tasks where each task can converge on its own schedule. As our main contribution, we monitor per-task validation metrics and switch to a knowledge distillation loss once a task has converged instead of continuing to train on the true labels. This prevents the model from overfitting on converged tasks while it learns the remaining tasks. We evaluate the proposed method in two 5-task MTL setups consisting of internal e-commerce datasets. The results show that our method consistently outperforms existing loss weighting and gradient balancing approaches, achieving average improvements of 0.9% and 1.5% over the best performing baseline model in the two setups, respectively.</abstract>
      <url hash="047bf17c">2022.naacl-industry.18</url>
      <bibkey>lu-etal-2022-asynchronous</bibkey>
    </paper>
    <paper id="19">
      <title>Augmenting Training Data for Massive Semantic Matching Models in Low-Traffic <fixed-case>E</fixed-case>-commerce Stores</title>
      <author><first>Ashutosh</first><last>Joshi</last></author>
      <author><first>Shankar</first><last>Vishwanath</last></author>
      <author><first>Choon</first><last>Teo</last></author>
      <author><first>Vaclav</first><last>Petricek</last></author>
      <author><first>Vishy</first><last>Vishwanathan</last></author>
      <author><first>Rahul</first><last>Bhagat</last></author>
      <author><first>Jonathan</first><last>May</last></author>
      <pages>160-167</pages>
      <abstract>Extreme multi-label classification (XMC) systems have been successfully applied in e-commerce (Shen et al., 2020; Dahiya et al., 2021) for retrieving products based on customer behavior. Such systems require large amounts of customer behavior data (e.g. queries, clicks, purchases) for training. However, behavioral data is limited in low-traffic e-commerce stores, impacting performance of these systems. In this paper, we present a technique that augments behavioral training data via query reformulation. We use the Aggregated Label eXtreme Multi-label Classification (AL-XMC) system (Shen et al., 2020) as an example semantic matching model and show via crowd-sourced human judgments that, when the training data is augmented through query reformulations, the quality of AL-XMC improves over a baseline that does not use query reformulation. We also show in online A/B tests that our method significantly improves business metrics for the AL-XMC model.</abstract>
      <url hash="bf36d620">2022.naacl-industry.19</url>
      <bibkey>joshi-etal-2022-augmenting</bibkey>
    </paper>
    <paper id="20">
      <title>Retrieval Based Response Letter Generation For a Customer Care Setting</title>
      <author><first>Biplob</first><last>Biswas</last></author>
      <author><first>Renhao</first><last>Cui</last></author>
      <author><first>Rajiv</first><last>Ramnath</last></author>
      <pages>168-175</pages>
      <abstract>Letter-like communications (such as email) are a major means of customer relationship management within customer-facing organizations. These communications are initiated on a channel by requests from customers and then responded to by the organization on the same channel. For decades, the job has almost entirely been conducted by human agents who attempt to provide the most appropriate reaction to the request. Rules have been made to standardize the overall customer service process and make sure the customers receive professional responses. Recent progress in natural language processing has made it possible to automate response generation. However, the diversity and open nature of customer queries and the lack of structured knowledge bases make this task even more challenging than typical task-oriented language generation tasks. Keeping those obstacles in mind, we propose a deep-learning based response letter generation framework that attempts to retrieve knowledge from historical responses and utilize it to generate an appropriate reply. Our model uses data augmentation to address the insufficiency of query-response pairs and employs a ranking mechanism to choose the best response from multiple potential options. We show that our technique outperforms the baselines by significant margins while producing consistent and informative responses.</abstract>
      <url hash="85819e7d">2022.naacl-industry.20</url>
      <bibkey>biswas-etal-2022-retrieval</bibkey>
    </paper>
    <paper id="21">
      <title><fixed-case>M</fixed-case>edical Coding with Biomedical Transformer Ensembles and Zero/Few-shot Learning</title>
      <author><first>Angelo</first><last>Ziletti</last></author>
      <author><first>Alan</first><last>Akbik</last></author>
      <author><first>Christoph</first><last>Berns</last></author>
      <author><first>Thomas</first><last>Herold</last></author>
      <author><first>Marion</first><last>Legler</last></author>
      <author><first>Martina</first><last>Viell</last></author>
      <pages>176-187</pages>
      <abstract>Medical coding (MC) is an essential pre-requisite for reliable data retrieval and reporting. Given a free-text <i>reported term</i> (RT) such as “pain of right thigh to the knee”, the task is to identify the matching <i>lowest-level term</i> (LLT) –in this case “unilateral leg pain”– from a very large and continuously growing repository of standardized medical terms. However, automating this task is challenging due to a large number of LLT codes (as of writing over <tex-math>80\,000</tex-math>), limited availability of training data for long tail/emerging classes, and the general high accuracy demands of the medical domain.With this paper, we introduce the MC task, discuss its challenges, and present a novel approach called xTARS that combines traditional BERT-based classification with a recent zero/few-shot learning approach (TARS). We present extensive experiments that show that our combined approach outperforms strong baselines, especially in the few-shot regime. The approach is developed and deployed at Bayer, live since November 2021. As we believe our approach potentially promising beyond MC, and to ensure reproducibility, we release the code to the research community. </abstract>
      <url hash="2396e79a">2022.naacl-industry.21</url>
      <bibkey>ziletti-etal-2022-medical</bibkey>
    </paper>
    <paper id="22">
      <title>Knowledge extraction from aeronautical messages (<fixed-case>NOTAM</fixed-case>s) with self-supervised language models for aircraft pilots</title>
      <author><first>Alexandre</first><last>Arnold</last></author>
      <author><first>Fares</first><last>Ernez</last></author>
      <author><first>Catherine</first><last>Kobus</last></author>
      <author><first>Marion-Cécile</first><last>Martin</last></author>
      <pages>188-196</pages>
      <abstract>During their pre-flight briefings, aircraft pilots must analyse a long list of NoTAMs (NOtice To AirMen) indicating potential hazards along the flight route, sometimes up to pages for long-haul flights. NOTAM free-text fields typically have a very special phrasing, with lots of acronyms and domain-specific vocabulary, which makes it differ significantly from standard English. In this paper, we pretrain language models derived from BERT on circa 1 million unlabeled NOTAMs and reuse the learnt representations on three downstream tasks valuable for pilots: criticality prediction, named entity recognition and translation into a structured language called Airlang. This self-supervised approach, where smaller amounts of labeled data are enough for task-specific fine-tuning, is well suited in the aeronautical context since expert annotations are expensive and time-consuming. We present evaluation scores across the tasks showing a high potential for an operational usability of such models (by pilots, airlines or service providers), which is a first to the best of our knowledge.</abstract>
      <url hash="7367e44f">2022.naacl-industry.22</url>
      <bibkey>arnold-etal-2022-knowledge</bibkey>
    </paper>
    <paper id="23">
      <title>Intent Discovery for Enterprise Virtual Assistants: Applications of Utterance Embedding and Clustering to Intent Mining</title>
      <author><first>Minhua</first><last>Chen</last></author>
      <author><first>Badrinath</first><last>Jayakumar</last></author>
      <author><first>Michael</first><last>Johnston</last></author>
      <author><first>S. Eman</first><last>Mahmoodi</last></author>
      <author><first>Daniel</first><last>Pressel</last></author>
      <pages>197-208</pages>
      <abstract>A key challenge in the creation and refinement of virtual assistants is the ability to mine unlabeled utterance data to discover common intents. We develop an approach to this problem that combines large-scale pre-training and multi-task learning to derive a semantic embedding that can be leveraged to identify clusters of utterances that correspond to unhandled intents. An utterance encoder is first trained with a language modeling objective and subsequently adapted to predict intent labels from a large collection of cross-domain enterprise virtual assistant data using a multi-task cosine softmax loss. Experimental evaluation shows significant advantages for this multi-step pre-training approach, with large gains in downstream clustering accuracy on new applications compared to standard sentence embedding approaches. The approach has been incorporated into an interactive discovery tool that enables visualization and exploration of intents by system analysts and builders.</abstract>
      <url hash="eb8cf882">2022.naacl-industry.23</url>
      <bibkey>chen-etal-2022-intent</bibkey>
    </paper>
    <paper id="24">
      <title><fixed-case>R</fixed-case>e<fixed-case>F</fixed-case>in<fixed-case>ED</fixed-case>: An Efficient Zero-shot-capable Approach to End-to-End Entity Linking</title>
      <author><first>Tom</first><last>Ayoola</last></author>
      <author><first>Shubhi</first><last>Tyagi</last></author>
      <author><first>Joseph</first><last>Fisher</last></author>
      <author><first>Christos</first><last>Christodoulopoulos</last></author>
      <author><first>Andrea</first><last>Pierleoni</last></author>
      <pages>209-220</pages>
      <abstract>We introduce ReFinED, an efficient end-to-end entity linking model which uses fine-grained entity types and entity descriptions to perform linking. The model performs mention detection, fine-grained entity typing, and entity disambiguation for all mentions within a document in a single forward pass, making it more than 60 times faster than competitive existing approaches. ReFinED also surpasses state-of-the-art performance on standard entity linking datasets by an average of 3.7 F1. The model is capable of generalising to large-scale knowledge bases such as Wikidata (which has 15 times more entities than Wikipedia) and of zero-shot entity linking. The combination of speed, accuracy and scale makes ReFinED an effective and cost-efficient system for extracting entities from web-scale datasets, for which the model has been successfully deployed.</abstract>
      <url hash="e74f6131">2022.naacl-industry.24</url>
      <bibkey>ayoola-etal-2022-refined</bibkey>
    </paper>
    <paper id="25">
      <title>Lightweight Transformers for Conversational <fixed-case>AI</fixed-case></title>
      <author><first>Daniel</first><last>Pressel</last></author>
      <author><first>Wenshuo</first><last>Liu</last></author>
      <author><first>Michael</first><last>Johnston</last></author>
      <author><first>Minhua</first><last>Chen</last></author>
      <pages>221-229</pages>
      <abstract>To understand how training on conversational language impacts performance of pre-trained models on downstream dialogue tasks, we build compact Transformer-based Language Models from scratch on several large corpora of conversational data. We compare the performance and characteristics of these models against BERT and other strong baselines on dialogue probing tasks. Commercial dialogue systems typically require a small footprint and fast execution time, but recent trends are in the other direction, with an ever-increasing number of parameters, resulting in difficulties in model deployment. We focus instead on training fast, lightweight models that excel at natural language understanding (NLU) and can replace existing lower-capacity conversational AI models with similar size and speed. In the process, we develop a simple but unique curriculum-based approach that moves from general-purpose to dialogue-targeted both in terms of data and objective. Our resultant models have around 1/3 the number of parameters of BERT-base and produce better representations for a wide array of intent detection datasets using linear and Mutual-Information probing techniques. Additionally, the models can be easily fine-tuned on a single consumer GPU card and deployed in near real-time production environments.</abstract>
      <url hash="003de177">2022.naacl-industry.25</url>
      <bibkey>pressel-etal-2022-lightweight</bibkey>
    </paper>
    <paper id="26">
      <title><fixed-case>NER-MQMRC</fixed-case>: <fixed-case>F</fixed-case>ormulating Named Entity Recognition as Multi Question Machine Reading Comprehension</title>
      <author><first>Anubhav</first><last>Shrimal</last></author>
      <author><first>Avi</first><last>Jain</last></author>
      <author><first>Kartik</first><last>Mehta</last></author>
      <author><first>Promod</first><last>Yenigalla</last></author>
      <pages>230-238</pages>
      <abstract>NER has been traditionally formulated as a sequence labeling task. However, there has been recent trend in posing NER as a machine reading comprehension task (Wang et al., 2020; Mengge et al., 2020), where entity name (or other information) is considered as a question, text as the context and entity value in text as answer snippet. These works consider MRC based on a single question (entity) at a time. We propose posing NER as a multi-question MRC task, where multiple questions (one question per entity) are considered at the same time for a single text. We propose a novel BERT-based multi-question MRC (NER-MQMRC) architecture for this formulation. NER-MQMRC architecture considers all entities as input to BERT for learning token embeddings with self-attention and leverages BERT-based entity representation for further improving these token embeddings for NER task. Evaluation on three NER datasets show that our proposed architecture leads to average 2.5 times faster training and 2.3 times faster inference as compared to NER-SQMRC framework based models by considering all entities together in a single pass. Further, we show that our model performance does not degrade compared to single-question based MRC (NER-SQMRC) (Devlin et al., 2019) leading to F1 gain of +0.41%, +0.32% and +0.27% for AE-Pub, Ecommerce5PT and Twitter datasets respectively. We propose this architecture primarily to solve large scale e-commerce attribute (or entity) extraction from unstructured text of a magnitude of 50k+ attributes to be extracted on a scalable production environment with high performance and optimised training and inference runtimes.</abstract>
      <url hash="dcd352b4">2022.naacl-industry.26</url>
      <bibkey>shrimal-etal-2022-ner</bibkey>
    </paper>
    <paper id="27">
      <title>What Do Users Care About? Detecting Actionable Insights from User Feedback</title>
      <author><first>Kasturi</first><last>Bhattacharjee</last></author>
      <author><first>Rashmi</first><last>Gangadharaiah</last></author>
      <author><first>Kathleen</first><last>McKeown</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>239-246</pages>
      <abstract>Users often leave feedback on a myriad of aspects of a product which, if leveraged successfully, can help yield useful insights that can lead to further improvements down the line. Detecting actionable insights can be challenging owing to large amounts of data as well as the absence of labels in real-world scenarios. In this work, we present an aggregation and graph-based ranking strategy for unsupervised detection of these insights from real-world, noisy, user-generated feedback. Our proposed approach significantly outperforms strong baselines on two real-world user feedback datasets and one academic dataset.</abstract>
      <url hash="4b9fadb9">2022.naacl-industry.27</url>
      <bibkey>bhattacharjee-etal-2022-users</bibkey>
    </paper>
    <paper id="28">
      <title><fixed-case>CTM</fixed-case> - A Model for Large-Scale Multi-View Tweet Topic Classification</title>
      <author><first>Vivek</first><last>Kulkarni</last></author>
      <author><first>Kenny</first><last>Leung</last></author>
      <author><first>Aria</first><last>Haghighi</last></author>
      <pages>247-258</pages>
      <abstract>Automatically associating social media posts with topics is an important prerequisite for effective search and recommendation on many social media platforms. However, topic classification of such posts is quite challenging because of (a) a large topic space (b) short text with weak topical cues, and (c) multiple topic associations per post. In contrast to most prior work which only focuses on post-classification into a small number of topics (<tex-math>10-20</tex-math>), we consider the task of large-scale topic classification in the context of Twitter where the topic space is 10 times larger with potentially multiple topic associations per Tweet. We address the challenges above and propose a novel neural model,  that (a) supports a large topic space of 300 topics (b) takes a holistic approach to tweet content modeling – leveraging multi-modal content, author context, and deeper semantic cues in the Tweet. Our method offers an effective way to classify Tweets into topics at scale by yielding superior performance to other approaches (a relative lift of <tex-math>\mathbf{20}\%</tex-math> in median average precision score) and has been successfully deployed in production at Twitter.</abstract>
      <url hash="70a239fb">2022.naacl-industry.28</url>
      <bibkey>kulkarni-etal-2022-ctm</bibkey>
    </paper>
    <paper id="29">
      <title>Developing a Production System for <fixed-case>P</fixed-case>urpose of <fixed-case>C</fixed-case>all Detection in Business Phone Conversations</title>
      <author><first>Elena</first><last>Khasanova</last></author>
      <author><first>Pooja</first><last>Hiranandani</last></author>
      <author><first>Shayna</first><last>Gardiner</last></author>
      <author><first>Cheng</first><last>Chen</last></author>
      <author><first>Simon</first><last>Corston-Oliver</last></author>
      <author><first>Xue-Yong</first><last>Fu</last></author>
      <pages>259-267</pages>
      <abstract>For agents at a contact centre receiving calls, the most important piece of information is the reason for a given call. An agent cannot provide support on a call if they do not know why a customer is calling. In this paper we describe our implementation of a commercial system to detect Purpose of Call statements in English business call transcripts in real time. We present a detailed analysis of types of Purpose of Call statements and language patterns related to them, discuss an approach to collect rich training data by bootstrapping from a set of rules to a neural model, and describe a hybrid model which consists of a transformer-based classifier and a set of rules by leveraging insights from the analysis of call transcripts. The model achieved 88.6 F1 on average in various types of business calls when tested on real life data and has low inference time. We reflect on the challenges and design decisions when developing and deploying the system.</abstract>
      <url hash="1ce59f05">2022.naacl-industry.29</url>
      <bibkey>khasanova-etal-2022-developing</bibkey>
    </paper>
    <paper id="30">
      <title>Adversarial Text Normalization</title>
      <author><first>Joanna</first><last>Bitton</last></author>
      <author><first>Maya</first><last>Pavlova</last></author>
      <author><first>Ivan</first><last>Evtimov</last></author>
      <pages>268-279</pages>
      <abstract>Text-based adversarial attacks are becoming more commonplace and accessible to general internet users. As these attacks proliferate, the need to address the gap in model robustness becomes imminent. While retraining on adversarial data may increase performance, there remains an additional class of character-level attacks on which these models falter. Additionally, the process to retrain a model is time and resource intensive, creating a need for a lightweight, reusable defense. In this work, we propose the Adversarial Text Normalizer, a novel method that restores baseline performance on attacked content with low computational overhead. We evaluate the efficacy of the normalizer on two problem areas prone to adversarial attacks, i.e. Hate Speech and Natural Language Inference. We find that text normalization provides a task-agnostic defense against character-level attacks that can be implemented supplementary to adversarial retraining solutions, which are more suited for semantic alterations.</abstract>
      <url hash="13d19c54">2022.naacl-industry.30</url>
      <bibkey>bitton-etal-2022-adversarial</bibkey>
    </paper>
    <paper id="31">
      <title>Constraint-based Multi-hop Question Answering with Knowledge Graph</title>
      <author><first>Sayantan</first><last>Mitra</last></author>
      <author><first>Roshni</first><last>Ramnani</last></author>
      <author><first>Shubhashis</first><last>Sengupta</last></author>
      <pages>280-288</pages>
      <abstract>The objective of a Question-Answering system over Knowledge Graph (KGQA) is to respond to natural language queries presented over the KG. A complex question answering system typically addresses one of the two categories of complexity: questions with constraints and questions involving multiple hops of relations. Most of the previous works have addressed these complexities separately. Multi-hop KGQA necessitates reasoning across numerous edges of the KG in order to arrive at the correct answer. Because KGs are frequently sparse, multi-hop KGQA presents extra complications. Recent works have developed KG embedding approaches to reduce KG sparsity by performing missing link prediction. In this paper, we tried to address multi-hop constrained-based queries using KG embeddings to generate more flexible query graphs. Empirical results indicate that the proposed methodology produces state-of-the-art outcomes on three KGQA datasets.</abstract>
      <url hash="2b7ea111">2022.naacl-industry.31</url>
      <bibkey>mitra-etal-2022-constraint</bibkey>
    </paper>
    <paper id="32">
      <title>Fast Bilingual Grapheme-To-Phoneme Conversion</title>
      <author><first>Hwa-Yeon</first><last>Kim</last></author>
      <author><first>Jong-Hwan</first><last>Kim</last></author>
      <author><first>Jae-Min</first><last>Kim</last></author>
      <pages>289-296</pages>
      <abstract>Autoregressive transformer (ART)-based grapheme-to-phoneme (G2P) models have been proposed for bi/multilingual text-to-speech systems. Although they have achieved great success, they suffer from high inference latency in real-time industrial applications, especially processing long sentence. In this paper, we propose a fast and high-performance bilingual G2P model. For fast and exact decoding, we used a non-autoregressive structured transformer-based architecture and data augmentation for predicting output length. Our model achieved better performance than that of the previous autoregressive model and about 2700% faster inference speed.</abstract>
      <url hash="c9277315">2022.naacl-industry.32</url>
      <bibkey>kim-etal-2022-fast</bibkey>
    </paper>
    <paper id="33">
      <title>Knowledge Extraction From Texts Based on <fixed-case>W</fixed-case>ikidata</title>
      <author><first>Anastasia</first><last>Shimorina</last></author>
      <author><first>Johannes</first><last>Heinecke</last></author>
      <author><first>Frédéric</first><last>Herledan</last></author>
      <pages>297-304</pages>
      <abstract>This paper presents an effort within our company of developing knowledge extraction pipeline for English, which can be further used for constructing an entreprise-specific knowledge base. We present a system consisting of entity detection and linking, coreference resolution, and relation extraction based on the Wikidata schema. We highlight existing challenges of knowledge extraction by evaluating the deployed pipeline on real-world data. We also make available a database, which can serve as a new resource for sentential relation extraction, and we underline the importance of having balanced data for training classification models.</abstract>
      <url hash="a0b7870e">2022.naacl-industry.33</url>
      <bibkey>shimorina-etal-2022-knowledge</bibkey>
    </paper>
    <paper id="34">
      <title><fixed-case>AIT-QA</fixed-case>: <fixed-case>Q</fixed-case>uestion Answering Dataset over Complex Tables in the Airline Industry</title>
      <author><first>Yannis</first><last>Katsis</last></author>
      <author><first>Saneem</first><last>Chemmengath</last></author>
      <author><first>Vishwajeet</first><last>Kumar</last></author>
      <author><first>Samarth</first><last>Bharadwaj</last></author>
      <author><first>Mustafa</first><last>Canim</last></author>
      <author><first>Michael</first><last>Glass</last></author>
      <author><first>Alfio</first><last>Gliozzo</last></author>
      <author><first>Feifei</first><last>Pan</last></author>
      <author><first>Jaydeep</first><last>Sen</last></author>
      <author><first>Karthik</first><last>Sankaranarayanan</last></author>
      <author><first>Soumen</first><last>Chakrabarti</last></author>
      <pages>305-314</pages>
      <abstract>Table Question Answering (Table QA) systems have been shown to be highly accurate when trained and tested on open-domain datasets built on top of Wikipedia tables. However, it is not clear whether their performance remains the same when applied to domain-specific scientific and business documents, encountered in industrial settings, which exhibit some unique characteristics: (a) they contain tables with a much more complex layout than Wikipedia tables (including hierarchical row and column headers), (b) they contain domain-specific terms, and (c) they are typically not accompanied by domain-specific labeled data that can be used to train Table QA models.To understand the performance of Table QA approaches in this setting, we introduce AIT-QA; a domain-specific Table QA test dataset. While focusing on the airline industry, AIT-QA reflects the challenges that domain-specific documents pose to Table QA, outlined above. In this work, we describe the creation of the dataset and report zero-shot experimental results of three SOTA Table QA methods. The results clearly expose the limitations of current methods with a best accuracy of just 51.8%. We also present pragmatic table pre-processing steps to pivot and project complex tables into a layout suitable for the SOTA Table QA models. Finally, we provide data-driven insights on how different aspects of this setting (including hierarchical headers, domain-specific terminology, and paraphrasing) affect Table QA methods, in order to help the community develop improved methods for domain-specific Table QA.</abstract>
      <url hash="b6d5b85b">2022.naacl-industry.34</url>
      <bibkey>katsis-etal-2022-ait</bibkey>
    </paper>
    <paper id="35">
      <title>Parameter-efficient Continual Learning Framework in Industrial Real-time Text Classification System</title>
      <author><first>Tao</first><last>Zhu</last></author>
      <author><first>Zhe</first><last>Zhao</last></author>
      <author><first>Weijie</first><last>Liu</last></author>
      <author><first>Jiachi</first><last>Liu</last></author>
      <author><first>Yiren</first><last>Chen</last></author>
      <author><first>Weiquan</first><last>Mao</last></author>
      <author><first>Haoyan</first><last>Liu</last></author>
      <author><first>Kunbo</first><last>Ding</last></author>
      <author><first>Yudong</first><last>Li</last></author>
      <author><first>Xuefeng</first><last>Yang</last></author>
      <pages>315-323</pages>
      <abstract>Catastrophic forgetting is a challenge for model deployment in industrial real-time systems, which requires the model to quickly master a new task without forgetting the old one. Continual learning aims to solve this problem; however, it usually updates all the model parameters, resulting in extensive training times and the inability to deploy quickly. To address this challenge, we propose a parameter-efficient continual learning framework, in which efficient parameters are selected through an offline parameter selection strategy and then trained using an online regularization method. In our framework, only a few parameters need to be updated, which not only alleviates catastrophic forgetting, but also allows the model to be saved with the changed parameters instead of all parameters. Extensive experiments are conducted to examine the effectiveness of our proposal. We believe this paper will provide useful insights and experiences on developing deep learning-based online real-time systems.</abstract>
      <url hash="53bc3d4b">2022.naacl-industry.35</url>
      <bibkey>zhu-etal-2022-parameter</bibkey>
    </paper>
    <paper id="36">
      <title>Self-Aware Feedback-Based Self-Learning in Large-Scale Conversational <fixed-case>AI</fixed-case></title>
      <author><first>Pragaash</first><last>Ponnusamy</last></author>
      <author><first>Clint Solomon</first><last>Mathialagan</last></author>
      <author><first>Gustavo</first><last>Aguilar</last></author>
      <author><first>Chengyuan</first><last>Ma</last></author>
      <author><first>Chenlei</first><last>Guo</last></author>
      <pages>324-333</pages>
      <abstract>Self-learning paradigms in large-scale conversational AI agents tend to leverage user feedback in bridging between what they say and what they mean. However, such learning, particularly in Markov-based query rewriting systems have far from addressed the impact of these models on future training where successive feedback is inevitably contingent on the rewrite itself, especially in a continually updating environment. In this paper, we explore the consequences of this inherent lack of self-awareness towards impairing the model performance, ultimately resulting in both Type I and II errors over time. To that end, we propose augmenting the Markov Graph construction with a superposition-based adjacency matrix. Here, our method leverages an induced stochasticity to reactively learn a locally-adaptive decision boundary based on the performance of the individual rewrites in a bi-variate beta setting. We also surface a data augmentation strategy that leverages template-based generation in abridging complex conversation hierarchies of dialogs so as to simplify the learning process. All in all, we demonstrate that our self-aware model improves the overall PR-AUC by 27.45%, achieves a relative defect reduction of up to 31.22%, and is able to adapt quicker to changes in global preferences across a large number of customers.</abstract>
      <url hash="617ae801">2022.naacl-industry.36</url>
      <bibkey>ponnusamy-etal-2022-self</bibkey>
    </paper>
    <paper id="37">
      <title>Fast and Light-Weight Answer Text Retrieval in Dialogue Systems</title>
      <author><first>Hui</first><last>Wan</last></author>
      <author><first>Siva Sankalp</first><last>Patel</last></author>
      <author><first>J William</first><last>Murdock</last></author>
      <author><first>Saloni</first><last>Potdar</last></author>
      <author><first>Sachindra</first><last>Joshi</last></author>
      <pages>334-343</pages>
      <abstract>Dialogue systems can benefit from being able to search through a corpus of text to find information relevant to user requests, especially when encountering a request for which no manually curated response is available. The state-of-the-art technology for neural dense retrieval or re-ranking involves deep learning models with hundreds of millions of parameters. However, it is difficult and expensive to get such models to operate at an industrial scale, especially for cloud services that often need to support a big number of individually customized dialogue systems, each with its own text corpus. We report our work on enabling advanced neural dense retrieval systems to operate effectively at scale on relatively inexpensive hardware. We compare with leading alternative industrial solutions and show that we can provide a solution that is effective, fast, and cost-efficient.</abstract>
      <url hash="e150f233">2022.naacl-industry.37</url>
      <bibkey>wan-etal-2022-fast</bibkey>
    </paper>
    <paper id="38">
      <title><fixed-case>BLINK</fixed-case> with <fixed-case>E</fixed-case>lasticsearch for Efficient Entity Linking in Business Conversations</title>
      <author><first>Md Tahmid Rahman</first><last>Laskar</last></author>
      <author><first>Cheng</first><last>Chen</last></author>
      <author><first>Aliaksandr</first><last>Martsinovich</last></author>
      <author><first>Jonathan</first><last>Johnston</last></author>
      <author><first>Xue-Yong</first><last>Fu</last></author>
      <author><first>Shashi Bhushan</first><last>Tn</last></author>
      <author><first>Simon</first><last>Corston-Oliver</last></author>
      <pages>344-352</pages>
      <abstract>An Entity Linking system aligns the textual mentions of entities in a text to their corresponding entries in a knowledge base. However, deploying a neural entity linking system for efficient real-time inference in production environments is a challenging task. In this work, we present a neural entity linking system that connects the product and organization type entities in business conversations to their corresponding Wikipedia and Wikidata entries. The proposed system leverages Elasticsearch to ensure inference efficiency when deployed in a resource limited cloud machine, and obtains significant improvements in terms of inference speed and memory consumption while retaining high accuracy.</abstract>
      <url hash="90745fc9">2022.naacl-industry.38</url>
      <bibkey>laskar-etal-2022-blink</bibkey>
    </paper>
    <paper id="39">
      <title><fixed-case>Q</fixed-case>2<fixed-case>R</fixed-case>: A Query-to-Resolution System for Natural-Language Queries</title>
      <author><first>Shiau Hong</first><last>Lim</last></author>
      <author><first>Laura</first><last>Wynter</last></author>
      <pages>353-361</pages>
      <abstract>We present a system for document retrieval that combines direct classification with standard content-based retrieval approaches to significantly improve the relevance of the retrieved documents. Our system exploits the availability of an imperfect but sizable amount of labeled data from past queries. For domains such as technical support, the proposed approach enhances the system’s ability to retrieve documents that are otherwise ranked very low based on content alone. The system is easy to implement and can make use of existing text ranking methods, augmenting them through the novel Q2R orchestration framework. Q2R has been extensively tested and is in use at IBM.</abstract>
      <url hash="d6b75b37">2022.naacl-industry.39</url>
      <bibkey>lim-wynter-2022-q2r</bibkey>
    </paper>
    <paper id="40">
      <title><fixed-case>I</fixed-case>dentifying <fixed-case>C</fixed-case>orporate <fixed-case>C</fixed-case>redit <fixed-case>R</fixed-case>isk <fixed-case>S</fixed-case>entiments from <fixed-case>F</fixed-case>inancial <fixed-case>N</fixed-case>ews</title>
      <author><first>Noujoud</first><last>Ahbali</last></author>
      <author><first>Xinyuan</first><last>Liu</last></author>
      <author><first>Albert</first><last>Nanda</last></author>
      <author><first>Jamie</first><last>Stark</last></author>
      <author><first>Ashit</first><last>Talukder</last></author>
      <author><first>Rupinder Paul</first><last>Khandpur</last></author>
      <pages>362-370</pages>
      <abstract>Credit risk management is one central practice for financial institutions, and such practice helps them measure and understand the inherent risk within their portfolios. Historically, firms relied on the assessment of default probabilities and used the press as one tool to gather insights on the latest credit event developments of an entity. However, due to the deluge of the current news coverage for companies, analyzing news manually by financial experts is considered a highly laborious task. To this end, we propose a novel deep learning-powered approach to automate news analysis and credit adverse events detection to score the credit sentiment associated with a company. This paper showcases a complete system that leverages news extraction and data enrichment with targeted sentiment entity recognition to detect companies and text classification to identify credit events. We developed a custom scoring mechanism to provide the company’s credit sentiment score (<tex-math>CSS^{TM}</tex-math>) based on these detected events. Additionally, using case studies, we illustrate how this score helps understand the company’s credit profile and discriminates between defaulters and non-defaulters.</abstract>
      <url hash="89ad57e3">2022.naacl-industry.40</url>
      <bibkey>ahbali-etal-2022-identifying</bibkey>
    </paper>
  </volume>
  <volume id="demo" ingest-date="2022-06-30">
    <meta>
      <booktitle>Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: \\ Human Language Technologies: System Demonstrations</booktitle>
      <editor><first>Hannaneh</first><last>Hajishirzi</last></editor>
      <editor><first>Qiang</first><last>Ning</last></editor>
      <editor><first>Avi</first><last>Sil</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Hybrid: Seattle, Washington + Online</address>
      <month>July</month>
      <year>2022</year>
      <url hash="99758d0d">2022.naacl-demo</url>
    </meta>
    <frontmatter>
      <url hash="99758d0d">2022.naacl-demo.0</url>
      <bibkey>naacl-2022-2022-north-american</bibkey>
    </frontmatter>
    <paper id="1">
      <title>textless-lib: a Library for Textless Spoken Language Processing</title>
      <author><first>Eugene</first><last>Kharitonov</last></author>
      <author><first>Jade</first><last>Copet</last></author>
      <author><first>Kushal</first><last>Lakhotia</last></author>
      <author><first>Tu Anh</first><last>Nguyen</last></author>
      <author><first>Paden</first><last>Tomasello</last></author>
      <author><first>Ann</first><last>Lee</last></author>
      <author><first>Ali</first><last>Elkahky</last></author>
      <author><first>Wei-Ning</first><last>Hsu</last></author>
      <author><first>Abdelrahman</first><last>Mohamed</last></author>
      <author><first>Emmanuel</first><last>Dupoux</last></author>
      <author><first>Yossi</first><last>Adi</last></author>
      <pages>1-9</pages>
      <abstract>Textless spoken language processing is an exciting area of research that promises to extend applicability of the standard NLP toolset onto spoken language and languages with few or no textual resources.Here, we introduce textless-lib, a PyTorch-based library aimed to facilitate research in the area. We describe the building blocks that the library provides and demonstrate its usability by discuss three different use-case examples: (i) speaker probing, (ii) speech resynthesis and compression, and (iii) speech continuation. We believe that textless-lib substantially simplifies research the textless setting and will be handful not only for speech researchers but also for the NLP community at large.</abstract>
      <url hash="d8bd5057">2022.naacl-demo.1</url>
      <bibkey>kharitonov-etal-2022-textless</bibkey>
    </paper>
    <paper id="2">
      <title>Web-based Annotation Interface for Derivational Morphology</title>
      <author><first>Lukáš</first><last>Kyjánek</last></author>
      <pages>10-16</pages>
      <abstract>The paper presents a visual interface for manual annotation of language resources for derivational morphology. The interface is web-based and created using relatively simple programming techniques, and yet it rapidly facilitates and speeds up the annotation process, especially in languages with rich derivational morphology. As such, it can reduce the cost of the process. After introducing manual annotation tasks in derivational morphology, the paper describes the new visual interface and a case study that compares the current annotation method to the annotation using the interface. In addition, it also demonstrates the opportunity to use the interface for manual annotation of syntactic trees. The source codes are freely available under the MIT License on GitHub.</abstract>
      <url hash="ee4421b1">2022.naacl-demo.2</url>
      <bibkey>kyjanek-2022-web</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>T</fixed-case>urkish<fixed-case>D</fixed-case>elight<fixed-case>NLP</fixed-case>: A Neural <fixed-case>T</fixed-case>urkish <fixed-case>NLP</fixed-case> Toolkit</title>
      <author><first>Huseyin</first><last>Alecakir</last></author>
      <author><first>Necva</first><last>Bölücü</last></author>
      <author><first>Burcu</first><last>Can</last></author>
      <pages>17-26</pages>
      <abstract>We introduce a neural Turkish NLP toolkit called TurkishDelightNLP that performs computational linguistic analyses from morphological level to semantic level that involves tasks such as stemming, morphological segmentation, morphological tagging, part-of-speech tagging, dependency parsing, and semantic parsing, as well as high-level NLP tasks such as named entity recognition. We publicly share the open-source Turkish NLP toolkit through a web interface that allows an input text to be analysed in real-time, as well as the open source implementation of the components provided in the toolkit, an API, and several annotated datasets such as word similarity test set to evaluate word embeddings and UCCA-based semantic annotation in Turkish. This will be the first open-source Turkish NLP toolkit that involves a range of NLP tasks in all levels. We believe that it will be useful for other researchers in Turkish NLP and will be also beneficial for other high-level NLP tasks in Turkish.</abstract>
      <url hash="a06ba4f1">2022.naacl-demo.3</url>
      <bibkey>alecakir-etal-2022-turkishdelightnlp</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>ZS</fixed-case>4<fixed-case>IE</fixed-case>: A toolkit for Zero-Shot Information Extraction with simple Verbalizations</title>
      <author><first>Oscar</first><last>Sainz</last></author>
      <author><first>Haoling</first><last>Qiu</last></author>
      <author><first>Oier</first><last>Lacalle</last></author>
      <author><first>Eneko</first><last>Agirre</last></author>
      <author><first>Bonan</first><last>Min</last></author>
      <pages>27-38</pages>
      <abstract>The current workflow for Information Extraction (IE) analysts involves the definition of the entities/relations of interest and a training corpus with annotated examples. In this demonstration we introduce a new workflow where the analyst directly verbalizes the entities/relations, which are then used by a Textual Entailment model to perform zero-shot IE. We present the design and implementation of a toolkit with a user interface, as well as experiments on four IE tasks that show that the system achieves very good performance at zero-shot learning using only 5–15 minutes per type of a user’s effort. Our demonstration system is open-sourced at https://github.com/BBN-E/ZS4IE. A demonstration video is available at https://vimeo.com/676138340.</abstract>
      <url hash="5e063d12">2022.naacl-demo.4</url>
      <bibkey>sainz-etal-2022-zs4ie</bibkey>
    </paper>
    <paper id="5">
      <title>Flowstorm: Open-Source Platform with Hybrid Dialogue Architecture</title>
      <author><first>Jan</first><last>Pichl</last></author>
      <author><first>Petr</first><last>Marek</last></author>
      <author><first>Jakub</first><last>Konrád</last></author>
      <author><first>Petr</first><last>Lorenc</last></author>
      <author><first>Ondrej</first><last>Kobza</last></author>
      <author><first>Tomáš</first><last>Zajíček</last></author>
      <author><first>Jan</first><last>Šedivý</last></author>
      <pages>39-45</pages>
      <abstract>This paper presents a conversational AI platform called Flowstorm. Flowstorm is an open-source SaaS project suitable for creating, running, and analyzing conversational applications. Thanks to the fast and fully automated build process, the dialogues created within the platform can be executed in seconds. Furthermore, we propose a novel dialogue architecture that uses a combination of tree structures with generative models. The tree structures are also used for training NLU models suitable for specific dialogue scenarios. However, the generative models are globally used across applications and extend the functionality of the dialogue trees. Moreover, the platform functionality benefits from out-of-the-box components, such as the one responsible for extracting data from utterances or working with crawled data. Additionally, it can be extended using a custom code directly in the platform. One of the essential features of the platform is the possibility to reuse the created assets across applications. There is a library of prepared assets where each developer can contribute. All of the features are available through a user-friendly visual editor.</abstract>
      <url hash="1f51ce04">2022.naacl-demo.5</url>
      <bibkey>pichl-etal-2022-flowstorm</bibkey>
    </paper>
    <paper id="6">
      <title>Contrastive Explanations of Text Classifiers as a Service</title>
      <author><first>Lorenzo</first><last>Malandri</last></author>
      <author><first>Fabio</first><last>Mercorio</last></author>
      <author><first>Mario</first><last>Mezzanzanica</last></author>
      <author><first>Navid</first><last>Nobani</last></author>
      <author><first>Andrea</first><last>Seveso</last></author>
      <pages>46-53</pages>
      <abstract>The recent growth of black-box machine-learning methods in data analysis has increased the demand for explanation methods and tools to understand their behaviour and assist human-ML model cooperation. In this paper, we demonstrate ContrXT, a novel approach that uses natural language explanations to help users to comprehend how a back-box model works. ContrXT provides time contrastive (t-contrast) explanations by computing the differences in the classification logic of two different trained models and then reasoning on their symbolic representations through Binary Decision Diagrams. ContrXT is publicly available at ContrXT.ai as a python pip package.</abstract>
      <url hash="0d8a19ab">2022.naacl-demo.6</url>
      <bibkey>malandri-etal-2022-contrastive</bibkey>
    </paper>
    <paper id="7">
      <title><fixed-case>RESIN</fixed-case>-11: Schema-guided Event Prediction for 11 Newsworthy Scenarios</title>
      <author><first>Xinya</first><last>Du</last></author>
      <author><first>Zixuan</first><last>Zhang</last></author>
      <author><first>Sha</first><last>Li</last></author>
      <author><first>Pengfei</first><last>Yu</last></author>
      <author><first>Hongwei</first><last>Wang</last></author>
      <author><first>Tuan</first><last>Lai</last></author>
      <author><first>Xudong</first><last>Lin</last></author>
      <author><first>Ziqi</first><last>Wang</last></author>
      <author><first>Iris</first><last>Liu</last></author>
      <author><first>Ben</first><last>Zhou</last></author>
      <author><first>Haoyang</first><last>Wen</last></author>
      <author><first>Manling</first><last>Li</last></author>
      <author><first>Darryl</first><last>Hannan</last></author>
      <author><first>Jie</first><last>Lei</last></author>
      <author><first>Hyounghun</first><last>Kim</last></author>
      <author><first>Rotem</first><last>Dror</last></author>
      <author><first>Haoyu</first><last>Wang</last></author>
      <author><first>Michael</first><last>Regan</last></author>
      <author><first>Qi</first><last>Zeng</last></author>
      <author><first>Qing</first><last>Lyu</last></author>
      <author><first>Charles</first><last>Yu</last></author>
      <author><first>Carl</first><last>Edwards</last></author>
      <author><first>Xiaomeng</first><last>Jin</last></author>
      <author><first>Yizhu</first><last>Jiao</last></author>
      <author><first>Ghazaleh</first><last>Kazeminejad</last></author>
      <author><first>Zhenhailong</first><last>Wang</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <author><first>Carl</first><last>Vondrick</last></author>
      <author><first>Jiawei</first><last>Han</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <author><first>Shih-Fu</first><last>Chang</last></author>
      <author><first>Martha</first><last>Palmer</last></author>
      <author><first>Heng</first><last>Ji</last></author>
      <pages>54-63</pages>
      <abstract>We introduce RESIN-11, a new schema-guided event extraction&amp;prediction framework that can be applied to a large variety of newsworthy scenarios. The framework consists of two parts: (1) an open-domain end-to-end multimedia multilingual information extraction system with weak-supervision and zero-shot learningbased techniques. (2) schema matching and schema-guided event prediction based on our curated schema library. We build a demo website based on our dockerized system and schema library publicly available for installation (https://github.com/RESIN-KAIROS/RESIN-11). We also include a video demonstrating the system.</abstract>
      <url hash="abe4dd6a">2022.naacl-demo.7</url>
      <bibkey>du-etal-2022-resin</bibkey>
    </paper>
    <paper id="8">
      <title>A Human-machine Interface for Few-shot Rule Synthesis for Information Extraction</title>
      <author><first>Robert</first><last>Vacareanu</last></author>
      <author><first>George C.G.</first><last>Barbosa</last></author>
      <author><first>Enrique</first><last>Noriega-Atala</last></author>
      <author><first>Gus</first><last>Hahn-Powell</last></author>
      <author><first>Rebecca</first><last>Sharp</last></author>
      <author><first>Marco A.</first><last>Valenzuela-Escárcega</last></author>
      <author><first>Mihai</first><last>Surdeanu</last></author>
      <pages>64-70</pages>
      <abstract>We propose a system that assists a user in constructing transparent information extraction models, consisting of patterns (or rules) written in a declarative language, through program synthesis.Users of our system can specify their requirements through the use of examples,which are collected with a search interface.The rule-synthesis system proposes rule candidates and the results of applying them on a textual corpus; the user has the option to accept the candidate, request another option, or adjust the examples provided to the system.Through an interactive evaluation, we show that our approach generates high-precision rules even in a 1-shot setting. On a second evaluation on a widely-used relation extraction dataset (TACRED), our method generates rules that outperform considerably manually written patterns.Our code, demo, and documentation is available at https://clulab.github.io/odinsynth.</abstract>
      <url hash="bd46514c">2022.naacl-demo.8</url>
      <bibkey>vacareanu-etal-2022-human</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>SETS</fixed-case>um: Summarization and Visualization of Student Evaluations of Teaching</title>
      <author><first>Yinuo</first><last>Hu</last></author>
      <author><first>Shiyue</first><last>Zhang</last></author>
      <author><first>Viji</first><last>Sathy</last></author>
      <author><first>Abigail</first><last>Panter</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>71-89</pages>
      <abstract>Student Evaluations of Teaching (SETs) are widely used in colleges and universities. Typically SET results are summarized for instructors in a static PDF report. The report often includes summary statistics for quantitative ratings and an unsorted list of open-ended student comments. The lack of organization and summarization of the raw comments hinders those interpreting the reports from fully utilizing informative feedback, making accurate inferences, and designing appropriate instructional improvements. In this work, we introduce a novel system, SETSUM, that leverages sentiment analysis, aspect extraction, summarization, and visualization techniques to provide organized illustrations of SET findings to instructors and other reviewers. Ten university professors from diverse departments serve as evaluators of the system and all agree that SETSUM help them interpret SET results more efficiently; and 6 out of 10 instructors prefer our system over the standard static PDF report (while the remaining 4 would like to have both). This demonstrates that our work holds the potential of reforming the SET reporting conventions in the future.</abstract>
      <url hash="d7bc554b">2022.naacl-demo.9</url>
      <bibkey>hu-etal-2022-setsum</bibkey>
    </paper>
    <paper id="10">
      <title>Towards Open-Domain Topic Classification</title>
      <author><first>Hantian</first><last>Ding</last></author>
      <author><first>Jinrui</first><last>Yang</last></author>
      <author><first>Yuqian</first><last>Deng</last></author>
      <author><first>Hongming</first><last>Zhang</last></author>
      <author><first>Dan</first><last>Roth</last></author>
      <pages>90-98</pages>
      <abstract>We introduce an open-domain topic classification system that accepts user-defined taxonomy in real time. Users will be able to classify a text snippet with respect to any candidate labels they want, and get instant response from our web interface. To obtain such flexibility, we build the backend model in a zero-shot way. By training on a new dataset constructed from Wikipedia, our label-aware text classifier can effectively utilize implicit knowledge in the pretrained language model to handle labels it has never seen before. We evaluate our model across four datasets from various domains with different label sets. Experiments show that the model significantly improves over existing zero-shot baselines in open-domain scenarios, and performs competitively with weakly-supervised models trained on in-domain data.</abstract>
      <url hash="34b0a0a6">2022.naacl-demo.10</url>
      <bibkey>ding-etal-2022-towards-open</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>S</fixed-case>ent<fixed-case>S</fixed-case>pace: Large-Scale Benchmarking and Evaluation of Text using Cognitively Motivated Lexical, Syntactic, and Semantic Features</title>
      <author><first>Greta</first><last>Tuckute</last></author>
      <author><first>Aalok</first><last>Sathe</last></author>
      <author><first>Mingye</first><last>Wang</last></author>
      <author><first>Harley</first><last>Yoder</last></author>
      <author><first>Cory</first><last>Shain</last></author>
      <author><first>Evelina</first><last>Fedorenko</last></author>
      <pages>99-113</pages>
      <abstract>SentSpace is a modular framework for streamlined evaluation of text. SentSpacecharacterizes textual input using diverse lexical, syntactic, and semantic features derivedfrom corpora and psycholinguistic experiments. Core sentence features fall into three primaryfeature spaces: 1) Lexical, 2) Contextual, and 3) Embeddings. To aid in the analysis of computed features, SentSpace provides a web interface for interactive visualization and comparison with text from large corpora. The modular design of SentSpace allows researchersto easily integrate their own feature computation into the pipeline while benefiting from acommon framework for evaluation and visualization. In this manuscript we will describe thedesign of SentSpace, its core feature spaces, and demonstrate an example use case by comparing human-written and machine-generated (GPT2-XL) sentences to each other. We findthat while GPT2-XL-generated text appears fluent at the surface level, psycholinguistic normsand measures of syntactic processing reveal key differences between text produced by humansand machines. Thus, SentSpace provides a broad set of cognitively motivated linguisticfeatures for evaluation of text within natural language processing, cognitive science, as wellas the social sciences.</abstract>
      <url hash="6f9f5c4d">2022.naacl-demo.11</url>
      <bibkey>tuckute-etal-2022-sentspace</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>P</fixed-case>addle<fixed-case>S</fixed-case>peech: An Easy-to-Use All-in-One Speech Toolkit</title>
      <author><first>Hui</first><last>Zhang</last></author>
      <author><first>Tian</first><last>Yuan</last></author>
      <author><first>Junkun</first><last>Chen</last></author>
      <author><first>Xintong</first><last>Li</last></author>
      <author><first>Renjie</first><last>Zheng</last></author>
      <author><first>Yuxin</first><last>Huang</last></author>
      <author><first>Xiaojie</first><last>Chen</last></author>
      <author><first>Enlei</first><last>Gong</last></author>
      <author><first>Zeyu</first><last>Chen</last></author>
      <author><first>Xiaoguang</first><last>Hu</last></author>
      <author><first>Dianhai</first><last>Yu</last></author>
      <author><first>Yanjun</first><last>Ma</last></author>
      <author><first>Liang</first><last>Huang</last></author>
      <pages>114-123</pages>
      <abstract>PaddleSpeech is an open-source all-in-one speech toolkit. It aims at facilitating the development and research of speech processing technologies by providing an easy-to-use command-line interface and a simple code structure. This paper describes the design philosophy and core architecture of PaddleSpeech to support several essential speech-to-text and text-to-speech tasks. PaddleSpeech achieves competitive or state-of-the-art performance on various speech datasets and implements the most popular methods. It also provides recipes and pretrained models to quickly reproduce the experimental results in this paper. PaddleSpeech is publicly avaiable at https://github.com/PaddlePaddle/PaddleSpeech.</abstract>
      <url hash="434ed40b">2022.naacl-demo.12</url>
      <bibkey>zhang-etal-2022-paddlespeech</bibkey>
    </paper>
    <paper id="13">
      <title><fixed-case>D</fixed-case>adma<fixed-case>T</fixed-case>ools: Natural Language Processing Toolkit for <fixed-case>P</fixed-case>ersian Language</title>
      <author><first>Romina</first><last>Etezadi</last></author>
      <author><first>Mohammad</first><last>Karrabi</last></author>
      <author><first>Najmeh</first><last>Zare</last></author>
      <author><first>Mohamad Bagher</first><last>Sajadi</last></author>
      <author><first>Mohammad Taher</first><last>Pilehvar</last></author>
      <pages>124-130</pages>
      <abstract>We introduce DadmaTools, an open-source Python Natural Language Processing toolkit for the Persian language. The toolkit is a neural pipeline based on spaCy for several text processing tasks, including normalization, tokenization, lemmatization, part-of-speech, dependency parsing, constituency parsing, chunking, and ezafe detecting. DadmaTools relies on fine-tuning of ParsBERT using the PerDT dataset for most of the tasks. Dataset module and embedding module are included in DadmaTools that support different Persian datasets, embeddings, and commonly used functions for them. Our evaluations show that DadmaTools can attain state-of-the-art performance on multiple NLP tasks. The source code is freely available at https://github.com/Dadmatech/DadmaTools.</abstract>
      <url hash="6ad8dc62">2022.naacl-demo.13</url>
      <bibkey>etezadi-etal-2022-dadmatools</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>FAMIE</fixed-case>: A Fast Active Learning Framework for Multilingual Information Extraction</title>
      <author><first>Minh Van</first><last>Nguyen</last></author>
      <author><first>Nghia</first><last>Ngo</last></author>
      <author><first>Bonan</first><last>Min</last></author>
      <author><first>Thien</first><last>Nguyen</last></author>
      <pages>131-139</pages>
      <abstract>This paper presents FAMIE, a comprehensive and efficient active learning (AL) toolkit for multilingual information extraction. FAMIE is designed to address a fundamental problem in existing AL frameworks where annotators need to wait for a long time between annotation batches due to the time-consuming nature of model training and data selection at each AL iteration. This hinders the engagement, productivity, and efficiency of annotators. Based on the idea of using a small proxy network for fast data selection, we introduce a novel knowledge distillation mechanism to synchronize the proxy network with the main large model (i.e., BERT-based) to ensure the appropriateness of the selected annotation examples for the main model. Our AL framework can support multiple languages. The experiments demonstrate the advantages of FAMIE in terms of competitive performance and time efficiency for sequence labeling with AL. We publicly release our code (https://github.com/nlp-uoregon/famie) and demo website (http://nlp.uoregon.edu:9000/). A demo video for FAMIE is provided at: https://youtu.be/I2i8n_jAyrY</abstract>
      <url hash="dee3dc0f">2022.naacl-demo.14</url>
      <bibkey>nguyen-etal-2022-famie</bibkey>
    </paper>
  </volume>
</collection>
