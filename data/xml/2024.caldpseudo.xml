<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.caldpseudo">
  <volume id="1" ingest-date="2024-03-04" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Workshop on Computational Approaches to Language Data Pseudonymization (CALD-pseudo 2024)</booktitle>
      <editor><first>Elena</first><last>Volodina</last></editor>
      <editor><first>David</first><last>Alfter</last></editor>
      <editor><first>Simon</first><last>Dobnik</last></editor>
      <editor><first>Therese</first><last>Lindström Tiedemann</last></editor>
      <editor><first>Ricardo</first><last>Muñoz Sánchez</last></editor>
      <editor><first>Maria Irena</first><last>Szawerna</last></editor>
      <editor><first>Xuan-Son</first><last>Vu</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>St. Julian’s, Malta</address>
      <month>March</month>
      <year>2024</year>
      <url hash="e05703fd">2024.caldpseudo-1</url>
      <venue>caldpseudo</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="70ffd509">2024.caldpseudo-1.0</url>
      <bibkey>caldpseudo-2024-approaches</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Handling Name Errors of a <fixed-case>BERT</fixed-case>-Based De-Identification System: Insights from Stratified Sampling and <fixed-case>M</fixed-case>arkov-based Pseudonymization</title>
      <author><first>Dalton</first><last>Simancek</last><affiliation>Department of Learning Health Sciences, University of Michigan</affiliation></author>
      <author><first>VG Vinod</first><last>Vydiswaran</last><affiliation>School of Information, University of Michigan</affiliation></author>
      <pages>1-7</pages>
      <abstract>Missed recognition of named entities while de-identifying clinical narratives poses a critical challenge in protecting patient-sensitive health information. Mitigating name recognition errors is essential to minimize risk of patient re-identification. In this paper, we emphasize the need for stratified sampling and enhanced contextual considerations concerning Name Tokens using a fine-tuned Longformer BERT model for clinical text de-identifcation. We introduce a Hidden in Plain Sight (HIPS) Markov-based replacement technique for names to mask name recognition misses, revealing a significant reduction in name leakage rates. Our experimental results underscore the impact on addressing name recognition challenges in BERT-based de-identification systems for heightened privacy protection in electronic health records.</abstract>
      <url hash="ed1cd679">2024.caldpseudo-1.1</url>
      <bibkey>simancek-vydiswaran-2024-handling</bibkey>
    </paper>
    <paper id="2">
      <title>Assessing Authenticity and Anonymity of Synthetic User-generated Content in the Medical Domain</title>
      <author><first>Tomohiro</first><last>Nishiyama</last><affiliation>Nara Institue of Science and Technology</affiliation></author>
      <author><first>Lisa</first><last>Raithel</last><affiliation>TU Berlin, BIFOLD / Université Paris-Saclay, CNRS, LISN</affiliation></author>
      <author><first>Roland</first><last>Roller</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Pierre</first><last>Zweigenbaum</last><affiliation>Université Paris-Saclay, CNRS, LISN</affiliation></author>
      <author><first>Eiji</first><last>Aramaki</last><affiliation>Nara Institue of Science and Technology</affiliation></author>
      <pages>8-17</pages>
      <abstract>Since medical text cannot be shared easily due to privacy concerns, synthetic data bears much potential for natural language processing applications. In the context of social media and user-generated messages about drug intake and adverse drug effects, this work presents different methods to examine the authenticity of synthetic text. We conclude that the generated tweets are untraceable and show enough authenticity from the medical point of view to be used as a replacement for a real Twitter corpus. However, original data might still be the preferred choice as they contain much more diversity.</abstract>
      <url hash="7c673002">2024.caldpseudo-1.2</url>
      <bibkey>nishiyama-etal-2024-assessing</bibkey>
    </paper>
    <paper id="3">
      <title>Automatic Detection and Labelling of Personal Data in Case Reports from the <fixed-case>ECHR</fixed-case> in <fixed-case>S</fixed-case>panish: Evaluation of Two Different Annotation Approaches</title>
      <author><first>Maria</first><last>Sierro</last><affiliation>LASLAB, University of the Basque Country (UPV/EHU)</affiliation></author>
      <author><first>Begoña</first><last>Altuna</last><affiliation>HiTZ Center - Ixa. University of the Basque Country (UPV/EHU)</affiliation></author>
      <author><first>Itziar</first><last>Gonzalez-Dios</last><affiliation>HiTZ Center - Ixa, University of the Basque Country (UPV/EHU)</affiliation></author>
      <pages>18-24</pages>
      <abstract>In this paper we evaluate two annotation approaches for automatic detection and labelling of personal information in legal texts in relation to the ambiguity of the labels and the homogeneity of the annotations. For this purpose, we built a corpus of 44 case reports from the European Court of Human Rights in Spanish language and we annotated it following two different annotation approaches: automatic projection of the annotations of an existing English corpus, and manual annotation with our reinterpretation of their guidelines. Moreover, we employ Flair on a Named Entity Recognition task to compare its performance in the two annotation schemes.</abstract>
      <url hash="55b703c1">2024.caldpseudo-1.3</url>
      <bibkey>sierro-etal-2024-automatic</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>PSILENCE</fixed-case>: A Pseudonymization Tool for International Law</title>
      <author><first>Luis Adrián</first><last>Cabrera-Diego</last><affiliation>Jus Mundi, France</affiliation></author>
      <author><first>Akshita</first><last>Gheewala</last><affiliation>Jus Mundi, France</affiliation></author>
      <pages>25-36</pages>
      <abstract>Since the announcement of the GDPR, the pseudonymization of legal documents has become a high-priority task in many legal organizations. This means that for making public a document, it is necessary to redact the identity of certain entities, such as witnesses. In this work, we present the first results obtained by PSILENCE, a pseudonymization tool created for redacting semi-automatically international arbitration documents in English. PSILENCE has been built using a Named Entity Recognition (NER) system, along with a Coreference Resolution system. These systems allow us to find the people that we need to redact in a clustered way, but also to propose the same pseudonym throughout one document. This last aspect makes it easier to read and comprehend a redacted legal document. Different experiments were done on four different datasets, one of which was legal, and the results are promising, reaching a Macro F-score of up to 0.72 on the legal dataset.</abstract>
      <url hash="ed380132">2024.caldpseudo-1.4</url>
      <bibkey>cabrera-diego-gheewala-2024-psilence</bibkey>
    </paper>
    <paper id="5">
      <title>Deidentifying a <fixed-case>N</fixed-case>orwegian Clinical Corpus - an Effort to Create a Privacy-preserving <fixed-case>N</fixed-case>orwegian Large Clinical Language Model</title>
      <author><first>Phuong</first><last>Ngo</last><affiliation>Norwegian Centre for E-health Research, Tromsø, Norway / Department of Physics and Technology, UiT The Arctic University of Norway</affiliation></author>
      <author><first>Miguel</first><last>Tejedor</last><affiliation>Norwegian Centre for E-health Research, Tromsø, Norway / Department of Mathematics and Statistics, UiT The Arctic University of Norway</affiliation></author>
      <author><first>Therese</first><last>Olsen Svenning</last><affiliation>Norwegian Centre for E-health Research, Tromsø, Norway</affiliation></author>
      <author><first>Taridzo</first><last>Chomutare</last><affiliation>Norwegian Centre for E-health Research, Tromsø, Norway / Department of Computer Sciences, UiT The Arctic University of Norway</affiliation></author>
      <author><first>Andrius</first><last>Budrionis</last><affiliation>Norwegian Centre for E-health Research, Tromsø, Norway / Department of Physics and Technology, UiT The Arctic University of Norway</affiliation></author>
      <author><first>Hercules</first><last>Dalianis</last><affiliation>Norwegian Centre for E-health Research, Tromsø, Norway / Department of Computer and Systems Science, Stockholm University, Sweden</affiliation></author>
      <pages>37-43</pages>
      <abstract>The study discusses the methods and challenges of deidentifying and pseudonymizing Norwegian clinical text for research purposes. The results of the NorDeid tool for deidentification and pseudonymization on different types of protected health information were evaluated and discussed, as well as the extension of its functionality with regular expressions to identify specific types of sensitive information. The research used a clinical corpus of adult patients treated in a gastro-surgical department in Norway, which contains approximately nine million clinical notes. The study also highlights the challenges posed by the unique language and clinical terminology of Norway and emphasizes the importance of protecting privacy and the need for customized approaches to meet legal and research requirements.</abstract>
      <url hash="45b1afe2">2024.caldpseudo-1.5</url>
      <bibkey>ngo-etal-2024-deidentifying</bibkey>
    </paper>
    <paper id="6">
      <title>Extending Off-the-shelf <fixed-case>NER</fixed-case> Systems to Personal Information Detection in Dialogues with a Virtual Agent: Findings from a Real-Life Use Case</title>
      <author><first>Mario</first><last>Mina</last><affiliation>Barcelona Supercomputing Center</affiliation></author>
      <author><first>Carlos</first><last>Rodríguez</last><affiliation>Barcelona Supercomputing Center</affiliation></author>
      <author><first>Aitor</first><last>Gonzalez-Agirre</last><affiliation>Barcelona Supercomputing Center</affiliation></author>
      <author><first>Marta</first><last>Villegas</last><affiliation>Barcelona Supercomputing Center</affiliation></author>
      <pages>44-53</pages>
      <abstract>We present the findings and results of our pseudonymisation system, which has been developed for a real-life use-case involving users and an informative chatbot in the context of the COVID-19 pandemic. Message exchanges between the two involve the former group providing information about themselves and their residential area, which could easily allow for their re-identification. We create a modular pipeline to detect PIIs and perform basic deidentification such that the data can be stored while mitigating any privacy concerns. The use-case presents several challenging aspects, the most difficult of which is the logistic challenge of not being able to directly view or access the data due to the very privacy issues we aim to resolve. Nevertheless, our system achieves a high recall of 0.99, correctly identifying almost all instances of personal data. However, this comes at the expense of precision, which only reaches 0.64. We describe the sensitive information identification in detail, explaining the design principles behind our decisions. We additionally highlight the particular challenges we’ve encountered.</abstract>
      <url hash="c1558c1b">2024.caldpseudo-1.6</url>
      <bibkey>mina-etal-2024-extending</bibkey>
    </paper>
    <paper id="7">
      <title>Detecting Personal Identifiable Information in <fixed-case>S</fixed-case>wedish Learner Essays</title>
      <author><first>Maria Irena</first><last>Szawerna</last><affiliation>Språkbanken Text, SFS, University of Gothenburg, Sweden</affiliation></author>
      <author><first>Simon</first><last>Dobnik</last><affiliation>CLASP, FLoV, University of Gothenburg, Sweden</affiliation></author>
      <author><first>Ricardo</first><last>Muñoz Sánchez</last><affiliation>Språkbanken Text, SFS, University of Gothenburg, Sweden</affiliation></author>
      <author><first>Therese</first><last>Lindström Tiedemann</last><affiliation>Department of Finnish, Finnougrian and Scandinavian Studies, University of Helsinki, Finland</affiliation></author>
      <author><first>Elena</first><last>Volodina</last><affiliation>Språkbanken Text, SFS, University of Gothenburg, Sweden</affiliation></author>
      <pages>54-63</pages>
      <abstract>Linguistic data can — and often does — contain PII (Personal Identifiable Information). Both from a legal and ethical standpoint, the sharing of such data is not permissible. According to the GDPR, pseudonymization, i.e. the replacement of sensitive information with surrogates, is an acceptable strategy for privacy preservation. While research has been conducted on the detection and replacement of sensitive data in Swedish medical data using Large Language Models (LLMs), it is unclear whether these models handle PII in less structured and more thematically varied texts equally well. In this paper, we present and discuss the performance of an LLM-based PII-detection system for Swedish learner essays.</abstract>
      <url hash="1c27bab1">2024.caldpseudo-1.7</url>
      <bibkey>szawerna-etal-2024-detecting</bibkey>
    </paper>
    <paper id="8">
      <title>Data Anonymization for Privacy-Preserving Large Language Model Fine-Tuning on Call Transcripts</title>
      <author><first>Shayna</first><last>Gardiner</last><affiliation>Dialpad Canada Inc.</affiliation></author>
      <author><first>Tania</first><last>Habib</last><affiliation>Dialpad Canada Inc.</affiliation></author>
      <author><first>Kevin</first><last>Humphreys</last><affiliation>Dialpad Canada Inc.</affiliation></author>
      <author><first>Masha</first><last>Azizi</last><affiliation>Dialpad Canada Inc.</affiliation></author>
      <author><first>Frederic</first><last>Mailhot</last><affiliation>Dialpad Canada Inc. / Dialpad Inc.</affiliation></author>
      <author><first>Anne</first><last>Paling</last><affiliation>Dialpad Canada Inc.</affiliation></author>
      <author><first>Preston</first><last>Thomas</last><affiliation>Dialpad Canada Inc. / Dialpad Inc.</affiliation></author>
      <author><first>Nathan</first><last>Zhang</last><affiliation>Dialpad Canada Inc.</affiliation></author>
      <pages>64-75</pages>
      <abstract>Large language models in public-facing industrial applications must accurately process data for the domain in which they are deployed, but they must not leak sensitive or confidential information when used. We present a process for anonymizing training data, a framework for quantitatively and qualitatively assessing the effectiveness of this process, and an assessment of the effectiveness of models fine-tuned on anonymized data in comparison with commercially available LLM APIs.</abstract>
      <url hash="bfd35b4f">2024.caldpseudo-1.8</url>
      <bibkey>gardiner-etal-2024-data</bibkey>
    </paper>
    <paper id="9">
      <title>When Is a Name Sensitive? Eponyms in Clinical Text and Implications for De-Identification</title>
      <author><first>Thomas</first><last>Vakili</last><affiliation>Department of Computer and Systems Sciences, Stockholm University, Kista, Sweden</affiliation></author>
      <author><first>Tyr</first><last>Hullmann</last><affiliation>Department of Computer and Systems Sciences, Stockholm University, Kista, Sweden</affiliation></author>
      <author><first>Aron</first><last>Henriksson</last><affiliation>Department of Computer and Systems Sciences, Stockholm University, Kista, Sweden</affiliation></author>
      <author><first>Hercules</first><last>Dalianis</last><affiliation>Department of Computer and Systems Sciences, Stockholm University, Kista, Sweden</affiliation></author>
      <pages>76-80</pages>
      <abstract>Clinical data, in the form of electronic health records, are rich resources that can be tapped using natural language processing. At the same time, they contain very sensitive information that must be protected. One strategy is to remove or obscure data using automatic de-identification. However, the detection of sensitive data can yield false positives. This is especially true for tokens that are similar in form to sensitive entities, such as eponyms. These names tend to refer to medical procedures or diagnoses rather than specific persons. Previous research has shown that automatic de-identification systems often misclassify eponyms as names, leading to a loss of valuable medical information. In this study, we estimate the prevalence of eponyms in a real Swedish clinical corpus. Furthermore, we demonstrate that modern transformer-based de-identification systems are more accurate in distinguishing between names and eponyms than previous approaches.</abstract>
      <url hash="cea56147">2024.caldpseudo-1.9</url>
      <bibkey>vakili-etal-2024-name</bibkey>
    </paper>
    <paper id="10">
      <title>Did the Names <fixed-case>I</fixed-case> Used within My Essay Affect My Score? Diagnosing Name Biases in Automated Essay Scoring</title>
      <author><first>Ricardo</first><last>Muñoz Sánchez</last><affiliation>Språkbanken Text, SFS, University of Gothenburg, Sweden</affiliation></author>
      <author><first>Simon</first><last>Dobnik</last><affiliation>CLASP, FLoV, University of Gothenburg, Sweden</affiliation></author>
      <author><first>Maria Irena</first><last>Szawerna</last><affiliation>Språkbanken Text, SFS, University of Gothenburg, Sweden</affiliation></author>
      <author><first>Therese</first><last>Lindström Tiedemann</last><affiliation>Department of Finnish, Finnougrian and Scandinavian Studies, University of Helsinki, Finland</affiliation></author>
      <author><first>Elena</first><last>Volodina</last><affiliation>Språkbanken Text, SFS, University of Gothenburg, Sweden</affiliation></author>
      <pages>81-91</pages>
      <abstract>Automated essay scoring (AES) of second-language learner essays is a high-stakes task as it can affect the job and educational opportunities a student may have access to. Thus, it becomes imperative to make sure that the essays are graded based on the students’ language proficiency as opposed to other reasons, such as personal names used in the text of the essay. Moreover, most of the research data for AES tends to contain personal identifiable information. Because of that, pseudonymization becomes an important tool to make sure that this data can be freely shared. Thus, our systems should not grade students based on which given names were used in the text of the essay, both for fairness and for privacy reasons. In this paper we explore how given names affect the CEFR level classification of essays of second language learners of Swedish. We use essays containing just one personal name and substitute it for names from lists of given names from four different ethnic origins, namely Swedish, Finnish, Anglo-American, and Arabic. We find that changing the names within the essays has no apparent effect on the classification task, regardless of whether a feature-based or a transformer-based model is used.</abstract>
      <url hash="807e7591">2024.caldpseudo-1.10</url>
      <bibkey>munoz-sanchez-etal-2024-names</bibkey>
    </paper>
  </volume>
</collection>
