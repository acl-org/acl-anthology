<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.ltedi">
  <volume id="1" ingest-date="2025-09-27" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 5th Conference on Language, Data and Knowledge: Fifth Workshop on Language Technology for Equality, Diversity, Inclusion</booktitle>
      <editor><first>Katerina</first><last>Gkirtzou</last><affiliation>ILSP ``Athena'' Research Center, Greece</affiliation></editor>
      <editor><first>Slavko</first><last>Žitnik</last><affiliation>University of Ljubljana, Slovenia</affiliation></editor>
      <editor><first>Jorge</first><last>Gracia</last><affiliation>University of Zaragoza, Spain</affiliation></editor>
      <editor><first>Dagmar</first><last>Gromann</last><affiliation>University of Vienna, Austria</affiliation></editor>
      <editor><first>Maria Pia</first><last>di Buono</last><affiliation>University of Naples “L’Orientale”, Italy</affiliation></editor>
      <editor><first>Johanna</first><last>Monti</last><affiliation>University of Naples “L’Orientale”, Italy</affiliation></editor>
      <editor><first>Maxim</first><last>Ionov</last><affiliation>University of Zaragoza, Spain</affiliation></editor>
      <publisher>Unior Press</publisher>
      <address>Naples, Italy</address>
      <month>September</month>
      <year>2025</year>
      <url hash="6e324962">2025.ltedi-1</url>
      <venue>ltedi</venue>
      <venue>ws</venue>
      <isbn>978-88-6719-334-9</isbn>
    </meta>
    <frontmatter>
      <url hash="23a3639a">2025.ltedi-1.0</url>
      <bibkey>ltedi-ws-2025-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>SSNCSE</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025:Detecting Misogyny Memes using Pretrained Deep Learning models</title>
      <author><first>Sreeja</first><last>K</last><affiliation>Sri Sivasubramaniya Nadar College of Engineering</affiliation></author>
      <author orcid="0000-0001-7279-5357"><first>Bharathi</first><last>B</last></author>
      <pages>1-5</pages>
      <abstract>Misogyny meme detection is identifying memes that are harmful or offensive to women. These memes can hide hate behind jokes or images, making them difficult to identify. It’s important to detect them for a safer and respectful internet for everyone. Our model proposed a multimodal method for misogyny meme detection in Chinese social media by combining both textual and visual aspects of memes. The training and evaluation data were part of a shared task on detecting misogynistic content. We used a pretrained ResNet-50 architecture to extract visual representations of the memes and processed the meme transcriptions with BERT. The model fused modality-specific representations with a feed-forward neural net for classification. The selected pretrained models were frozen to avoid overfitting and to enhance generalization across all classes, and only the final classifier was fine-tuned on labelled meme recollection. The model was trained and evaluated using test data to achieve a macro F1-score of 0.70345. As a result, we have validated lightweight combining approaches for multimodal fusion techniques on noisy social media and how they can be validated in the context of hostile meme detection tasks.</abstract>
      <url hash="5e7620d7">2025.ltedi-1.1</url>
      <bibkey>k-b-2025-ssncse-lt</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>SSNCSE</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025:Speech Recognition for Vulnerable Individuals in <fixed-case>T</fixed-case>amil</title>
      <author><first>Sreeja</first><last>K</last><affiliation>Sri Sivasubramaniya Nadar College of Engineering</affiliation></author>
      <author orcid="0000-0001-7279-5357"><first>Bharathi</first><last>B</last></author>
      <pages>6-10</pages>
      <abstract>Speech recognition is a helpful tool for accessing technology and allowing people to interact with technology naturally. This is especially true for people who want to access technology but may encounter challenges interacting with technology in traditional formats. Some examples of these people include the elderly or people from the transgender community. This research presents an Automatic Speech Recognition (ASR) system developed for Tamil-speaking elderly and transgender people who are generally underrepresented in mainstream ASR training datasets. The proposed work used the speech data shared by the task organisers of LT-EDI2025. In the proposed work used the fine-tuned model of OpenAI’s Whisper model with Parameter-Efficient Fine-Tuning (P-EFT) with Low-Rank Adaptation (LoRA) along with SpecAugment, and used the AdamW optimization method. The model’s work led to an overall Word Error Rate (WER) of 42.3% on the untranscribed test data. A key feature of our work is that it demonstrates potential equitable and accessible ASR systems addressing the linguistic and acoustic features of vulnerable groups.</abstract>
      <url hash="438b84b7">2025.ltedi-1.2</url>
      <bibkey>k-b-2025-ssncse-lt-edi</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>C</fixed-case>rew<fixed-case>X</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025: Transformer-Based <fixed-case>T</fixed-case>amil <fixed-case>ASR</fixed-case> Fine-Tuning with <fixed-case>AVMD</fixed-case> Denoising and <fixed-case>GRU</fixed-case>-<fixed-case>VAD</fixed-case> for Enhanced Transcription Accuracy</title>
      <author><first>Ganesh Sundhar</first><last>S</last></author>
      <author><first>Hari Krishnan</first><last>N</last></author>
      <author><first>Arun Prasad T</first><last>D</last></author>
      <author><first>Shruthikaa</first><last>V</last></author>
      <author><first>Jyothish Lal</first><last>G</last><affiliation>Amrita Vishwa Vidyapeetham (Deemed University)</affiliation></author>
      <pages>11-16</pages>
      <abstract>This research presents an improved Tamil Automatic Speech Recognition (ASR) system designed to enhance accessibility for elderly and transgender populations by addressing unique language challenges. We address the challenges of Tamil ASR—including limited high-quality curated datasets, unique phonetic characteristics, and word-merging tendencies—through a comprehensive pipeline. Our methodology integrates Adaptive Variational Mode Decomposition (AVMD) for selective noise reduction based on signal characteristics, Silero Voice Activity Detection (VAD) with GRU architecture to eliminate non-speech segments, and fine-tuning of OpenAI’s Whisper model optimized for Tamil transcription. The system employs beam search decoding during inference to further improve accuracy. Our approach achieved state-of-the-art performance with a Word Error Rate (WER) of 31.9,winning first place in the LT-EDI 2025 shared task.</abstract>
      <url hash="5d5088d5">2025.ltedi-1.3</url>
      <bibkey>s-etal-2025-crewx</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>JUNLP</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025: Efficient Low-Rank Adaptation of Whisper for Inclusive <fixed-case>T</fixed-case>amil Speech Recognition Targeting Vulnerable Populations</title>
      <author><first>Priyobroto</first><last>Acharya</last></author>
      <author orcid="0009-0004-4306-4167"><first>Soham</first><last>Chaudhuri</last></author>
      <author><first>Sayan</first><last>Das</last></author>
      <author><first>Dipanjan</first><last>Saha</last></author>
      <author orcid="0000-0002-8110-9344"><first>Dipankar</first><last>Das</last><affiliation>Jadavpur University</affiliation></author>
      <pages>17-25</pages>
      <abstract>Speech recognition has received extensive research attention in recent years. It becomes much more challenging when the speaker’s age, gender and other factors introduce variations in the speech. In this work, we propose a fine-tuned automatic speech recognition model derived from OpenAI’s whisperlarge-v2. Though we experimented with both Whisper-large and Wav2vec2-XLSR-large, the reduced WER of whisper-large proved to be a superior model. We secured 4th rank in the LT-EDI-2025 shared task. Our implementation details and code are available at our GitHub repository1.</abstract>
      <url hash="9d30058a">2025.ltedi-1.4</url>
      <bibkey>acharya-etal-2025-junlp</bibkey>
    </paper>
    <paper id="5">
      <title><fixed-case>SKV</fixed-case>trio@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025: Hybrid <fixed-case>TF</fixed-case>-<fixed-case>IDF</fixed-case> and <fixed-case>BERT</fixed-case> Embeddings for Multilingual Homophobia and Transphobia Detection in Social Media Comments</title>
      <author><first>Konkimalla Laxmi</first><last>Vignesh</last></author>
      <author><first>Mahankali Sri Ram</first><last>Krishna</last></author>
      <author><first>Dondluru</first><last>Keerthana</last></author>
      <author orcid="0000-0003-1188-1838"><first>Premjith</first><last>B</last><affiliation>Amrita Vishwa Vidyapeetham (Deemed University)</affiliation></author>
      <pages>26-30</pages>
      <abstract>This paper presents a description of the paper submitted to the Shared Task on Homophobia and Transphobia Detection in Social Media Comments, LT-EDI at LDK 2025. We propose a hybrid approach to detect homophobic and transphobic content in low-resource languages using Term Frequency-Inverse Document Frequency (TF-IDF) and Bidirectional Encoder Representations from Transformers (BERT) for contextual embeddings. The TF-IDF helps capture the token’s importance, whereas BERT generates contextualized embeddings. This hybridization subsequently generates an embedding that contains statistical surface-level patterns and deep semantic understanding. The system uses principal component analysis (PCA) and a random forest classifier. The application of PCA converts a sparse, very high-dimensional embedding into a dense representation by keeping only the most relevant features. The model achieved robust performance across eight Indian languages, with the highest accuracy in Hindi. However, lower performance in Marathi highlights challenges in low-resource settings. Combining TF-IDF and BERT embeddings leads to better classification results, showing the benefits of integrating simple and complex language models. Limitations include potential feature redundancy and poor performance in languages with complex word forms, indicating a need for future adjustments to support multiple languages and address imbalances.</abstract>
      <url hash="52ce0633">2025.ltedi-1.5</url>
      <bibkey>vignesh-etal-2025-skvtrio</bibkey>
    </paper>
    <paper id="6">
      <title><fixed-case>D</fixed-case>ll5143<fixed-case>A</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case> 2025: Bias-Aware Detection of Racial Hoaxes in Code-Mixed Social Media Data (<fixed-case>B</fixed-case>a<fixed-case>C</fixed-case>o<fixed-case>H</fixed-case>oax)</title>
      <author><first>Ashok</first><last>Yadav</last></author>
      <author orcid="0000-0002-8818-5673"><first>Vrijendra</first><last>Singh</last></author>
      <pages>31-38</pages>
      <abstract>The proliferation of racial hoaxes that associate individuals or groups with fabricated crimes or incidents presents unique challenges in multilingual social media contexts. This paper introduces BaCoHoax, a novel framework for detecting race-based misinformation in code-mixed content. We address this problem by participating in the “Shared Task Detecting Racial Hoaxes in Code-Mixed Hindi-English Social Media Data: LT-EDI@LDK 2025.” BaCoHoax is a bias-aware detection system built on a DeBERTa-based architecture, enhanced with disentangled attention mechanisms, a dynamic bias discovery module that adapts to emerging narrative patterns, and an adaptive contrastive learning objective. We evaluated BaCoHoax on the HoaxMixPlus corpus, a collection of 5,105 YouTube comments annotated for racial hoaxes, achieved a competitive macro F1 score of 0.67 and securing 7th place among participating teams in the shared task.Our findings contribute to the growing field of multilingual misinformation detection and highlight the importance of culturally informed approaches to identifying harmful content in linguistically diverse online spaces.</abstract>
      <url hash="636d4398">2025.ltedi-1.6</url>
      <bibkey>yadav-singh-2025-dll5143a-lt</bibkey>
    </paper>
    <paper id="7">
      <title>Hope_for_best@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case> 2025: Detecting Racial Hoaxes in Code-Mixed <fixed-case>H</fixed-case>indi-<fixed-case>E</fixed-case>nglish Social Media Data using a multi-phase fine-tuning strategy</title>
      <author><first>Abhishek Singh</first><last>Yadav</last></author>
      <author><first>Deepawali</first><last>Sharma</last></author>
      <author><first>Aakash</first><last>Singh</last></author>
      <author><first>Vivek Kumar</first><last>Singh</last></author>
      <pages>39-46</pages>
      <abstract>In the age of digital communication, social media platforms have become a medium for the spread of misinformation, with racial hoaxes posing a particularly insidious threat. These hoaxes falsely associate individuals or communities with crimes or misconduct, perpetuating harmful stereotypes and inflaming societal tensions. This paper describes the team “Hope_for_best” submission that addresses the challenge of detecting racial hoaxes in codemixed Hindi-English (Hinglish) social media content and secured the 2nd rank in the shared task (Chakravarthi et al., 2025). To address this challenge, the study employs the HoaxMix Plus dataset, developed by LT-EDI 2025, and adopts a multi-phase fine-tuning strategy. Initially, models are sensitized using the THAR dataset—targeted hate speech against religion (Sharma et al., 2024) —to adjust weights toward contextually relevant biases. Further fine-tuning was performed on the HoaxMix Plus dataset. This work employed data balancing sampling strategies to mitigate class imbalance. Among the evaluated models, Hing BERT achieved the highest macro F1-score of 73% demonstrating promising capabilities in detecting racially charged misinformation in code-mixed Hindi-English texts.</abstract>
      <url hash="c760e46e">2025.ltedi-1.7</url>
      <bibkey>yadav-etal-2025-hope</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>CVF</fixed-case>-<fixed-case>NITT</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025:<fixed-case>M</fixed-case>isogyny<fixed-case>D</fixed-case>etection</title>
      <author orcid="0009-0001-1287-0236"><first>Radhika K</first><last>T</last><affiliation>National Institute of Technology Trichy and Institute of Printing Technology and Government Polytechnic College</affiliation></author>
      <author orcid="0000-0001-8242-8593"><first>Sitara</first><last>K</last><affiliation>National Institute of Technology Tiruchirappalli</affiliation></author>
      <pages>47-53</pages>
      <abstract>Online platforms have enabled users to create and share multimodal content, fostering new forms of personal expression and cultural interaction. Among these, memes—combinations of images and text—have become a prevalent mode of digital communication, often used for humor, satire, or social commentary. However, memes can also serve as vehicles for spreading misogynistic messages, reinforcing harmful gender stereotypes, and targeting individuals based on gender. In this work, we investigate the effectiveness of various multimodal models for detecting misogynistic content in memes. We propose a BERT+CLIP+LR model that integrates BERT’s deep contextual language understanding with CLIP’s powerful visual encoder, followed by Logistic Regression for classification. This approach leverages complementary strengths of vision-language models for robust cross-modal representation. We compare our proposed model with several baselines, including the original CLIP+LR, and traditional early fusion methods such as BERT + ResNet50 and CNN + InceptionV3. Our focus is on accurately identifying misogynistic content in Chinese memes, with careful attention to the interplay between visual elements and textual cues. Experimental results show that the BERT+CLIP+LR model achieves a macro F1 score of 0.87, highlighting the effectiveness of vision-language models in addressing harmful content on social media platforms.</abstract>
      <url hash="d13a3566">2025.ltedi-1.8</url>
      <bibkey>t-k-2025-cvf</bibkey>
    </paper>
    <paper id="9">
      <title>Wise@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025: Combining Classical and Neural Representations with Multi-scale Ensemble Learning for Code-mixed Hate Speech Detection</title>
      <author><first>Ganesh Sundhar</first><last>S</last></author>
      <author><first>Durai Singh</first><last>K</last></author>
      <author><first>Gnanasabesan</first><last>G</last></author>
      <author><first>Hari Krishnan</first><last>N</last></author>
      <author><first>Mc</first><last>Dhanush</last></author>
      <pages>54-62</pages>
      <abstract>Detecting hate speech targeting caste and migration communities in code-mixed Tamil-English social media content is challenging due to limited resources and socio-cultural complexities. This paper proposes a multi-scale hybrid architecture combining classical and neural representations with hierarchical ensemble learning. We employ advanced preprocessing including transliteration and character repetition removal, then extract features using classical TF-IDF vectors at multiple scales (512, 1024, 2048) processed through linear layers, alongside contextual embeddings from five transformer models-Google BERT, XLM-RoBERTa (Base and Large), SeanBenhur BERT, and IndicBERT. These concatenated representations encode both statistical and contextual information, which are input to multiple ML classification heads (Random Forest, SVM, etc). A three-level hierarchical ensemble strategy combines predictions across classifiers, transformer-TF-IDF combinations, and dimensional scales for enhanced robustness. Our method scored an F1-score of 0.818, ranking 3rd in the LT-EDI-2025 shared task, showing the efficacy of blending classical and neural methods with multi-level ensemble learning for hate speech detection in low-resource languages.</abstract>
      <url hash="35ff679f">2025.ltedi-1.9</url>
      <bibkey>s-etal-2025-wise</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>CUET</fixed-case>’s_<fixed-case>W</fixed-case>hite_<fixed-case>W</fixed-case>alkers@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case> 2025: Racial Hoax Detection in Code-Mixed on Social Media Data</title>
      <author><first>Md. Mizanur</first><last>Rahman</last></author>
      <author><first>Jidan Al</first><last>Abrar</last></author>
      <author><first>Md. Siddikul Imam</first><last>Kawser</last></author>
      <author><first>Ariful</first><last>Islam</last></author>
      <author><first>Md. Mubasshir</first><last>Naib</last></author>
      <author><first>Hasan</first><last>Murad</last><affiliation>Chittagong University of Engineering and Technology</affiliation></author>
      <pages>63-67</pages>
      <abstract>False narratives that manipulate racial tensions are increasingly prevalent on social media, often blending languages and cultural references to enhance reach and believability. Among them, racial hoaxes produce unique harm by fabricating events targeting specific communities, social division and fueling misinformation. This paper presents a novel approach to detecting racial hoaxes in code-mixed Hindi-English social media data. Using a carefully constructed training pipeline, we have fine-tuned the XLM-RoBERTa-base multilingual transformer for training the shared task data. Our approach has incorporated task-specific preprocessing, clear methodology, and extensive hyperparameter tuning. After developing our model, we tested and evaluated it on the LT-EDI@LDK 2025 shared task dataset. Our system achieved the highest performance among all the international participants with an F1-score of 0.75, ranking 1st on the official leaderboard.</abstract>
      <url hash="22aa1778">2025.ltedi-1.10</url>
      <bibkey>rahman-etal-2025-cuets</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>CUET</fixed-case>’s_<fixed-case>W</fixed-case>hite_<fixed-case>W</fixed-case>alkers@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025: A Multimodal Framework for the Detection of Misogynistic Memes in <fixed-case>C</fixed-case>hinese Online Content</title>
      <author><first>Md. Mubasshir</first><last>Naib</last></author>
      <author><first>Md. Mizanur</first><last>Rahman</last></author>
      <author><first>Jidan Al</first><last>Abrar</last></author>
      <author><first>Md. Mehedi</first><last>Hasan</last></author>
      <author><first>Md. Siddikul Imam</first><last>Kawser</last></author>
      <author><first>Mohammad Shamsul</first><last>Arefin</last></author>
      <pages>68-74</pages>
      <abstract>Memes, combining visual and textual elements, have emerged as a prominent medium for both expression and the spread of harmful ideologies, including misogyny. To address this issue in Chinese online content, we present a multimodal framework for misogyny meme detection as part of the LT-EDI@LDK 2025 Shared Task. Our study investigates a range of machine learning (ML) methods such as Logistic Regression, Support Vector Machines, and Random Forests, as well as deep learning (DL) architectures including CNNs and hybrid models like BiLSTM-CNN and CNN-GRU for extracting textual features. On the transformer side, we explored multiple pretrained models including mBERT, MuRIL, and BERT- base-chinese to capture nuanced language representations. These textual models were fused with visual features extracted from pretrained ResNet50 and DenseNet121 architectures using both early and decision-level fusion strategies. Among all evaluated configurations, the BERT-base-chinese + ResNet50 early fusion model achieved the best overall performance, with a macro F1-score of 0.8541, ranking 4th in the shared task. These findings underscore the effectiveness of combining pretrained vision and language models for tackling multimodal hate speech detection.</abstract>
      <url hash="6425109b">2025.ltedi-1.11</url>
      <bibkey>naib-etal-2025-cuets</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>CUET</fixed-case>’s_<fixed-case>W</fixed-case>hite_<fixed-case>W</fixed-case>alkers@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case> 2025: Transformer-Based Model for the Detection of Caste and Migration Hate Speech</title>
      <author><first>Jidan Al</first><last>Abrar</last></author>
      <author><first>Md. Mizanur</first><last>Rahman</last></author>
      <author><first>Ariful</first><last>Islam</last></author>
      <author><first>Md. Mehedi</first><last>Hasan</last></author>
      <author><first>Md. Mubasshir</first><last>Naib</last></author>
      <author><first>Mohammad Shamsul</first><last>Arefin</last></author>
      <pages>75-79</pages>
      <abstract>Hate speech on social media is an evolving problem, particularly in low-resource languages like Tamil, where traditional hate speech detection approaches remain under developed. In this work, we provide a focused solution for cast and migration-based hate speech detection using Tamil-BERT, a Tamil-specialized pre-trained transformer model. One of the key challenges in hate speech detection is the severe class imbalance in the dataset, with hate speech being the minority class. We solve this using focal loss, a loss function that gives more importance to harder-to-classify examples, improving the performance of the model in detecting minority classes. We train our model on a publicly available labeled dataset of Tamil text as hate and non-hate speech. Under strict evaluation, our approach achieves impressive results, outperforming baseline models by a considerable margin. The model achieves an F1 score of 0.8634 and good precision, recall, and accuracy, making it a robust solution for hate speech detection in Tamil. The results show that fine-tuning transformer-based models like Tamil-BERT, coupled with techniques like focal loss, can substantially improve performance in hate speech detection for low-resource languages. This work is a contribution to this growing amount of research and provides insights on how to tackle class imbalance for NLP tasks.</abstract>
      <url hash="a3c0f019">2025.ltedi-1.12</url>
      <bibkey>abrar-etal-2025-cuets</bibkey>
    </paper>
    <paper id="13">
      <title><fixed-case>NS</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025 <fixed-case>C</fixed-case>aste<fixed-case>M</fixed-case>igration based hate speech Detection</title>
      <author><first>Nishanth</first><last>S</last></author>
      <author><first>Shruthi</first><last>Rengarajan</last></author>
      <author><first>Sachin Kumar</first><last>S</last><affiliation>Amrita Vishwa Vidyapeetham (Deemed University)</affiliation></author>
      <pages>80-83</pages>
      <abstract>Hate speech directed at caste and migrant communities is a widespread problem on social media, frequently taking the form of insults specific to a given region, coded language, and disparaging slurs. This type of abuse seriously jeopardizes both individual well-being and social harmony in addition to perpetuating discrimination. In order to promote safer and more inclusive digital environments, it is imperative that this challenge be addressed. However, linguistic subtleties, code-mixing, and the lack of extensive annotated datasets make it difficult to detect such hate speech in Indian languages like Tamil. We suggest a supervised machine learning system that uses FastText embeddings specifically designed for Tamil-language content and Whisper-based speech recognition to address these issues. This strategy aims to precisely identify hate speech connected to caste and migration, supporting the larger endeavor to reduce online abuse in low resource languages like Tamil.</abstract>
      <url hash="24a9f13c">2025.ltedi-1.13</url>
      <bibkey>s-etal-2025-ns</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>SSN</fixed-case>_<fixed-case>IT</fixed-case>_<fixed-case>HATE</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025: Caste and Migration Hate Speech Detection</title>
      <author><first>Maria Nancy</first><last>C</last><affiliation>Sri Sivasubramaniya Nadar Institutions</affiliation></author>
      <author><first>Radha</first><last>N</last></author>
      <author><first>Swathika</first><last>R</last></author>
      <pages>84-89</pages>
      <abstract>This paper proposes a transformer-based methodology for detecting hate speech in Tamil, developed as part of the shared task on Caste and Migration Hate Speech Detection. Leveraging the multilingual BERT (mBERT) model, we fine-tune it to classify Tamil social media content into caste/migration-related hate speech and non hate speech categories. Our approach achieves a macro F1-score of 0.72462 in the development dataset, demonstrating the effectiveness of multilingual pretrained models in low-resource language settings. The code for this work is available on github Hate-Speech Deduction.</abstract>
      <url hash="393812c2">2025.ltedi-1.14</url>
      <bibkey>c-etal-2025-ssn-hate</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>I</fixed-case>ts<fixed-case>A</fixed-case>ll<fixed-case>G</fixed-case>ood<fixed-case>M</fixed-case>an@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025: Fusing <fixed-case>TF</fixed-case>-<fixed-case>IDF</fixed-case> and <fixed-case>M</fixed-case>u<fixed-case>RIL</fixed-case> Embeddings for Detecting Caste and Migration Hate Speech</title>
      <author><first>Amritha Nandini K</first><last>L</last></author>
      <author><first>Vishal</first><last>S</last></author>
      <author><first>Giri Prasath</first><last>R</last></author>
      <author><first>Anerud</first><last>Thiyagarajan</last></author>
      <author><first>Sachin Kumar</first><last>S</last><affiliation>Amrita Vishwa Vidyapeetham (Deemed University)</affiliation></author>
      <pages>90-94</pages>
      <abstract>Caste and migration hate speech detection is a critical task in the context of increasingly multilingual and diverse online discourse. In this work, we address the problem of identifying hate speech targeting caste and migrant communities across a multilingual social media dataset containing Tamil, Tamil written in English script, and English. We explore and compare different feature representations, including TF-IDF vectors and embeddings from pretrained transformer-based models, to train various machine learning classifiers. Our experiments show that a Soft Voting Classifier that make use of both TF-IDF vectors and MuRIL embeddings performs best, achieving a macro F1 score of 0.802 on the test set. This approach was evaluated as part of the Shared Task on Caste and Migration Hate Speech Detection at LT-EDI@LDK 2025, where it ranked 6th overall.</abstract>
      <url hash="f6ff1714">2025.ltedi-1.15</url>
      <bibkey>l-etal-2025-itsallgoodman</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>NSR</fixed-case>_<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025 Automatic speech recognition in <fixed-case>T</fixed-case>amil</title>
      <author><first>Nishanth</first><last>S</last></author>
      <author><first>Shruthi</first><last>Rengarajan</last></author>
      <author><first>Burugu</first><last>Rahul</last></author>
      <author><first>Jyothish Lal</first><last>G</last><affiliation>Amrita Vishwa Vidyapeetham (Deemed University)</affiliation></author>
      <pages>95-99</pages>
      <abstract>Automatic Speech Recognition (ASR) technology can potentially make marginalized communities more accessible. However, older adultsand transgender speakers are usually highly disadvantaged in accessing valuable services due to low digital literacy and social biases. In Tamil-speaking regions, these are further compounded by the inability of ASR models to address their unique speech types, accents, and spontaneous speaking styles. To bridge this gap, the LT-EDI-2025 shared task is designed to develop robust ASR systems for Tamil speech from vulnerable populations. Using whisper based models, this task is designed to improve recognition rates in speech data collected from older adults and transgender speakers in naturalistic settings such as banks, hospitals and public offices. By bridging the linguistic heterogeneity and acoustic variability among this underrepresented population, the shared task is designed to develop inclusive AI solutions that break communication barriers and empower vulnerable populations in Tamil Nadu.</abstract>
      <url hash="14ce0c1a">2025.ltedi-1.16</url>
      <bibkey>s-etal-2025-nsr</bibkey>
    </paper>
    <paper id="17">
      <title>Solvers@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025: Caste and Migration Hate Speech Detection in <fixed-case>T</fixed-case>amil-<fixed-case>E</fixed-case>nglish Code-Mixed Text</title>
      <author><first>Ananthakumar</first><last>S</last></author>
      <author><first>Bharath</first><last>P</last></author>
      <author><first>Devasri</first><last>A</last></author>
      <author><first>Anirudh Sriram K</first><last>S</last></author>
      <author><first>Mohanapriya K</first><last>T</last><affiliation>Kongu Engineering College</affiliation></author>
      <pages>100-104</pages>
      <abstract>Hate speech detection in low-resource languages such as Tamil presents significant challenges due to linguistic complexity, limited annotated data, and the sociocultural sensitivity of the subject matter. This study focuses on identifying caste- and migration-related hate speech in Tamil social media texts, as part of the LT-EDI@LDK 2025 Shared Task. The dataset used consists of 5,512 training instances and 787 development instances, annotated for binary classification into caste/migration-related and non-caste/migration-related hate speech. We employ a range of models, including Support Vector Machines (SVM), Convolutional Neural Networks (CNN), and transformer-based architectures such as BERT and multilingual BERT (mBERT). A central focus of this work is evaluating model performance using macro F1-score, which provides a balanced assessment across this imbalanced dataset. Experimental results demonstrate that transformer-based models, particularly mBERT, significantly outperform traditional approaches by effectively capturing the contextual and implicit nature of hate speech. This research underscores the importance of culturally informed NLP solutions for fostering safer online environments in underrepresented linguistic communities such as Tamil.</abstract>
      <url hash="20dcbd9f">2025.ltedi-1.17</url>
      <bibkey>s-etal-2025-solvers</bibkey>
    </paper>
    <paper id="18">
      <title><fixed-case>CUET</fixed-case>_<fixed-case>N</fixed-case>317@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>2025: Detecting Hate Speech Related to Caste and Migration with Transformer Models</title>
      <author><first>Md. Nur Siddik</first><last>Ruman</last><affiliation>Chittagong University of Engineering and Technology</affiliation></author>
      <author><first>Md. Tahfim Juwel</first><last>Chowdhury</last></author>
      <author><first>Hasan</first><last>Murad</last><affiliation>Chittagong University of Engineering and Technology</affiliation></author>
      <pages>105-110</pages>
      <abstract>Language that criticizes threatens, or discriminates against people or groups because of their caste, social rank, or status is known as caste and migration hate speech and it has grown in credibly common on social media. Such speech not only contributes to social disruption and in equity, but it also puts at risk the safety and mental health of the targeted groups. Due to the absence of labeled data, the subtlety of culturally unique insults, and the lack of strong linguistic resources for deep text recognition, it is especially difficult to detect caste and migration hate speech in low-resource Dravidian languages like Tamil. In this work, we address the Caste and Migration Hate Speech Detection task, aiming to automatically classify user-generated content as either hateful or non-hateful. We evaluate a range of approaches, including a traditional TF-IDF-based machine learning pipeline using SVM and Logistic Regression, alongside five transformer-based models: mBERT, XLM-R, MuRIL, Tamil BERT, and Tamilhate-BERT.Among these, the domain-adapted Tamilhate BERT achieved the highest macro-F1 score of 0.88 on the test data, securing 1st place in the Shared Task on Caste and Migration Hate Speech Detection at DravidianLangTech@LT-EDI 2025. Our findings highlight the strong performance of transformer models, particularly those fine-tuned on domain-specific data, in detecting nuanced hate speech in low-resource, code-mixed languages like Tamil.</abstract>
      <url hash="49d67450">2025.ltedi-1.18</url>
      <bibkey>ruman-etal-2025-cuet</bibkey>
    </paper>
    <paper id="19">
      <title><fixed-case>KEC</fixed-case>-Elite-Analysts@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case> 2025: Leveraging Deep Learning for Racial Hoax Detection in Code-Mixed <fixed-case>H</fixed-case>indi-<fixed-case>E</fixed-case>nglish Tweets</title>
      <author orcid="0000-0003-3263-0376"><first>Malliga</first><last>Subramanian</last></author>
      <author><first>Aruna</first><last>A</last></author>
      <author><first>Amudhavan</first><last>M</last></author>
      <author><first>Jahaganapathi</first><last>S</last></author>
      <author orcid="0000-0002-0715-143X"><first>Kogilavani</first><last>Shanmugavadivel</last></author>
      <pages>111-115</pages>
      <abstract>Detecting misinformation in code-mixed languages, particularly Hindi-English, poses significant challenges in natural language processing due to the linguistic diversity found on social media. This paper focuses on racial hoax detection—false narratives that target specific communities—within Hindi-English YouTube comments. We evaluate the effectiveness of several machine learning models, including Logistic Regression, Random Forest, Support Vector Machine, Naive Bayes, and Multi-Layer Perceptron, using a dataset of 5,105 annotated comments. Model performance is assessed using accuracy, precision, recall, and F1-score. Experimental results indicate that neural and ensemble models consistently outperform traditional classifiers. Future work will explore the use of transformer-based architectures and data augmentation techniques to enhance detection in low-resource, code-mixed scenarios.</abstract>
      <url hash="3374669a">2025.ltedi-1.19</url>
      <bibkey>subramanian-etal-2025-kec-elite-analysts</bibkey>
    </paper>
    <paper id="20">
      <title><fixed-case>T</fixed-case>eam_<fixed-case>L</fixed-case>uminaries_0227@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025: A Transformer-Based Fusion Approach to Misogyny Detection in <fixed-case>C</fixed-case>hinese Memes</title>
      <author><first>Adnan</first><last>Faisal</last></author>
      <author><first>Shiti</first><last>Chowdhury</last></author>
      <author><first>Momtazul Arefin</first><last>Labib</last><affiliation>Chittagong University of Engineering and Technology</affiliation></author>
      <author><first>Hasan</first><last>Murad</last><affiliation>Chittagong University of Engineering and Technology</affiliation></author>
      <pages>116-120</pages>
      <abstract>Memes, originally crafted for humor or cultural commentary, have evolved into powerful tools for spreading harmful content, particularly misogynistic ideologies. These memes sustain damaging gender stereotypes, further entrenching social inequality and encouraging toxic behavior across online platforms. While progress has been made in detecting harmful memes in English, identifying misogynistic content in Chinese remains challenging due to the language’s complexities and cultural subtleties. The multimodal nature of memes, combining text and images, adds to the detection difficulty. In the LT-EDI@LDK 2025 Shared Task on Misogyny Meme Detection, we have focused on analyzing both text and image elements to identify misogynistic content in Chinese memes. For text-based models, we have experimented with Chinese BERT, XLM-RoBERTa and DistilBERT, with Chinese BERT yielding the highest performance, achieving an F1 score of 0.86. In terms of image models, VGG16 outperformed ResNet and ViT, also achieving an F1 score of 0.85. Among all model combinations, the integration of Chinese BERT with VGG16 emerged as the most impactful, delivering superior performance, highlighting the benefit of a multimodal approach. By exploiting these two modalities, our model has effectively captured the subtle details present in memes, improving its ability to accurately detect misogynistic content. This approach has resulted in a macro F1 score of 0.90355, securing 3rd rank in the task.</abstract>
      <url hash="b95bd57f">2025.ltedi-1.20</url>
      <bibkey>faisal-etal-2025-team-luminaries</bibkey>
    </paper>
    <paper id="21">
      <title>Hinterwelt@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case> 2025: A Transformer-Based Approach for Identifying Racial Hoaxes in Code-Mixed <fixed-case>H</fixed-case>indi-<fixed-case>E</fixed-case>nglish Social Media Narratives</title>
      <author orcid="0009-0002-8595-5772"><first>Md. Abdur</first><last>Rahman</last></author>
      <author orcid="0009-0008-8981-9667"><first>Md. Al</first><last>Amin</last></author>
      <author orcid="0009-0002-9249-4548"><first>Sabik</first><last>Aftahee</last></author>
      <author><first>Md. Ashiqur</first><last>Rahman</last><affiliation>Southeast University</affiliation></author>
      <pages>121-126</pages>
      <abstract>This paper presents our system for the detection of racial hoaxes in code-mixed Hindi-English social media narratives, which is in reality a form of debunking of online disinformation claiming fake incidents against a racial group. We experiment with different modeling techniques on HoaxMixPlus dataset of 5,102 annotated YouTube comments. In our approach, we utilize traditional machine learning classifiers (SVM, LR, RF), deep learning models (CNN, CNN-LSTM, CNN-BiLSTM), and transformer-based architectures (MuRIL, XLM-RoBERTa, HingRoBERTa-mixed). Experiments show that transformer-based methods substantially outperform traditional approaches, and the HingRoBERTa-mixed model is the best one with an F1 score of 0.7505. An error analysis identifies the difficulty of recognizing implicit bias and nuanced contexts in complex hoaxes. Our team was 5th place in the challenge with an F1 score of 0.69. This work contributes to combating online misinformation in low-resource linguistic environments and highlights the effectiveness of specialized language models for code-mixed content.</abstract>
      <url hash="dcfa8b18">2025.ltedi-1.21</url>
      <bibkey>rahman-etal-2025-hinterwelt</bibkey>
    </paper>
    <paper id="22">
      <title><fixed-case>CUET</fixed-case>_12033@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025: Misogyny Detection</title>
      <author><first>Mehreen</first><last>Rahman</last><affiliation>Chittagong University of Engineering and Technology</affiliation></author>
      <author><first>Faozia</first><last>Fariha</last></author>
      <author><first>Nabilah</first><last>Tabassum</last><affiliation>Chittagong University of Engineering and Technology</affiliation></author>
      <author><first>Samia</first><last>Rahman</last></author>
      <author><first>Hasan</first><last>Murad</last><affiliation>Chittagong University of Engineering and Technology</affiliation></author>
      <pages>127-132</pages>
      <abstract>Misogynistic memes spread harmful stereotypes and toxic content across social media platforms, often combining sarcastic text and offensive visuals that make them difficult to detect using traditional methods. Our research has been part of the the Shared Task on Misogyny Meme Detection - LT- EDI@LDK 2025, identifying misogynistic memes using deep learning-based multimodal approach that leverages both textual and visual information for accurate classification of such memes. We experiment with various models including CharBERT, BiLSTM, and CLIP for text and image encoding, and explore fusion strategies like early and gated fusion. Our best performing model, CharBERT + BiLSTM + CLIP with gated fusion, achieves strong results, showing the effectiveness of combining features from both modalities. To address challenges like language mixing and class imbalance, we apply preprocessing techniques (e.g., Romanizing Chinese text) and data augmentation (e.g., image transformations, text back-translation). The results demonstrate significant improvements over unimodal baselines, highlighting the value of multimodal learning in detecting subtle and harmful content online.</abstract>
      <url hash="692f0a8f">2025.ltedi-1.22</url>
      <bibkey>rahman-etal-2025-cuet-12033</bibkey>
    </paper>
    <paper id="23">
      <title><fixed-case>CUET</fixed-case>_<fixed-case>B</fixed-case>litz_<fixed-case>A</fixed-case>ces@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025: Leveraging Transformer Ensembles and Majority Voting for Hate Speech Detection</title>
      <author><first>Shahriar Farhan</first><last>Karim</last></author>
      <author><first>Anower Sha Shajalal</first><last>Kashmary</last></author>
      <author><first>Hasan</first><last>Murad</last><affiliation>Chittagong University of Engineering and Technology</affiliation></author>
      <pages>133-139</pages>
      <abstract>The rapid growth of the internet and social media has given people an open space to share their opinions, but it has also led to a rise in hate speech targeting different social, cultural, and political groups. While much of the research on hate speech detection has focused on widely spoken languages, languages like Tamil, which are less commonly studied, still face significant gaps in this area. To tackle this, the Shared Task on Caste and Migration Hate Speech Detection was organized at the Fifth Workshop on Language Technology for Equality, Diversity, and Inclusion (LT-EDI-2025). This paper aims to create an automatic system that can detect caste and migration-related hate speech in Tamil-language social media content. We broke down our approach into two phases: in the first phase, we tested seven machine learning models and five transformer-based models. In the second phase, we combined the predictions from the fine-tuned transformers using a majority voting technique. This ensemble approach outperformed all other models, achieving the highest macro F1 score of 0.81682, which earned us 4th place in the competition.</abstract>
      <url hash="08754f55">2025.ltedi-1.23</url>
      <bibkey>karim-etal-2025-cuet</bibkey>
    </paper>
    <paper id="24">
      <title>Hinterwelt@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case> 2025: A Transformer-Based Detection of Caste and Migration Hate Speech in <fixed-case>T</fixed-case>amil Social Media</title>
      <author orcid="0009-0008-8981-9667"><first>Md. Al</first><last>Amin</last></author>
      <author orcid="0009-0002-9249-4548"><first>Sabik</first><last>Aftahee</last></author>
      <author orcid="0009-0002-8595-5772"><first>Md. Abdur</first><last>Rahman</last></author>
      <author><first>Md. Sajid Hossain</first><last>Khan</last><affiliation>Chittagong University of Engineering and Technology</affiliation></author>
      <author><first>Md. Ashiqur</first><last>Rahman</last><affiliation>Southeast University</affiliation></author>
      <pages>140-145</pages>
      <abstract>This paper presents our system for detecting caste and migration-related hate speech in Tamil social media comments, addressing the challenges in this low-resource language setting. We experimented with multiple approaches on a dataset of 7,875 annotated comments. Our methodology encompasses traditional machine learning classifiers (SVM, Random Forest, KNN), deep learning models (CNN, CNN-BiLSTM), and transformer-based architectures (MuRIL, IndicBERT, XLM-RoBERTa). Comprehensive evaluations demonstrate that transformer-based models substantially outperform traditional approaches, with MuRIL-large achieving the highest performance with a macro F1 score of 0.8092. Error analysis reveals challenges in detecting implicit and culturally-specific hate speech expressions requiring deeper socio-cultural context. Our team ranked 5th in the LT-EDI@LDK 2025 shared task with an F1 score of 0.80916. This work contributes to combating harmful online content in low-resource languages and highlights the effectiveness of large pre-trained multilingual models for nuanced text classification tasks.</abstract>
      <url hash="af73832b">2025.ltedi-1.24</url>
      <bibkey>amin-etal-2025-hinterwelt</bibkey>
    </paper>
    <paper id="25">
      <title><fixed-case>EM</fixed-case>-26@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case> 2025: Detecting Racial Hoaxes in Code-Mixed Social Media Data</title>
      <author orcid="0009-0002-9511-0263"><first>Tewodros</first><last>Achamaleh</last></author>
      <author><first>Fatima</first><last>Uroosa</last></author>
      <author orcid="0009-0008-5490-102X"><first>Nida</first><last>Hafeez</last></author>
      <author><first>Tolulope Olalekan</first><last>Abiola</last></author>
      <author><first>Mikiyas</first><last>Mebraihtu</last></author>
      <author><first>Sara</first><last>Getachew</last></author>
      <author orcid="0000-0003-3901-3522"><first>Grigori</first><last>Sidorov</last><affiliation>Instituto Politécnico Nacional</affiliation></author>
      <author orcid="0000-0003-4454-8791"><first>Rolando</first><last>Quintero</last><affiliation>Instituto Politécnico Nacional</affiliation></author>
      <pages>146-152</pages>
      <abstract>Social media platforms and user-generated content, such as tweets, comments, and blog posts often contain offensive language, including racial hate speech, personal attacks, and sexual harassment. Detecting such inappropriate language is essential to ensure user safety and to prevent the spread of hateful behavior and online aggression. Approaches base on conventional machine learning and deep learning have shown robust results for high-resource languages like English and find it hard to deal with code-mixed text, which is common in bilingual communication. We participated in the shared task “LT-EDI@LDK 2025” organized by DravidianLangTech, applying the BERT-base multilingual cased model and achieving an F1 score of 0.63. These results demonstrate how our model effectively processes and interprets the unique linguistic features of code-mixed content. The source code is available on GitHub.1</abstract>
      <url hash="fb4f8277">2025.ltedi-1.25</url>
      <bibkey>achamaleh-etal-2025-em</bibkey>
    </paper>
    <paper id="26">
      <title><fixed-case>EM</fixed-case>-26@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case> 2025: Caste and Migration Hate Speech Detection in <fixed-case>T</fixed-case>amil-<fixed-case>E</fixed-case>nglish Code-Mixed Social Media Texts</title>
      <author orcid="0009-0002-9511-0263"><first>Tewodros</first><last>Achamaleh</last></author>
      <author><first>Tolulope Olalekan</first><last>Abiola</last></author>
      <author><first>Mikiyas</first><last>Mebraihtu</last></author>
      <author><first>Sara</first><last>Getachew</last></author>
      <author orcid="0000-0003-3901-3522"><first>Grigori</first><last>Sidorov</last><affiliation>Instituto Politécnico Nacional</affiliation></author>
      <pages>153-159</pages>
      <abstract>In this paper, we describe the system developed by Team EM-26 for the Shared Task on Caste and Migration Hate Speech Detection at LTEDI@LDK 2025. The task addresses the challenge of recognizing caste-based and migration related hate speech in Tamil social media text, a language that is both nuanced and under resourced for machine learning. To tackle this, we fine-tuned the multilingual transformer XLM-RoBERTa-Large on the provided training data, leveraging its cross-lingual strengths to detect both explicit and implicit hate speech. To improve performance, we applied social media focused preprocessing techniques, including Tamil text normalization and noise removal. Our model achieved a macro F1-score of 0.6567 on the test set, highlighting the effectiveness of multilingual transformers for low resource hate speech detection. Additionally, we discuss key challenges and errors in Tamil hate speech classification, which may guide future work toward building more ethical and inclusive AI systems. The source code is available on GitHub.1</abstract>
      <url hash="0fe8d8b7">2025.ltedi-1.26</url>
      <bibkey>achamaleh-etal-2025-em-26</bibkey>
    </paper>
    <paper id="27">
      <title>Hoax Terminators@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case> 2025: <fixed-case>C</fixed-case>har<fixed-case>BERT</fixed-case>’s dominance over <fixed-case>LLM</fixed-case> Models in the Detection of Racial Hoaxes in Code-Mixed <fixed-case>H</fixed-case>indi-<fixed-case>E</fixed-case>nglish Social Media Data</title>
      <author><first>Abrar Hafiz</first><last>Rabbani</last></author>
      <author><first>Diganta Das</first><last>Droba</last><affiliation>Chittagong University of Engineering and Technology</affiliation></author>
      <author><first>Momtazul Arefin</first><last>Labib</last><affiliation>Chittagong University of Engineering and Technology</affiliation></author>
      <author><first>Samia</first><last>Rahman</last></author>
      <author><first>Hasan</first><last>Murad</last><affiliation>Chittagong University of Engineering and Technology</affiliation></author>
      <pages>160-171</pages>
      <abstract>This paper presents our system for the LT-EDI 2025 Shared Task on Racial Hoax Detection, addressing the critical challenge of identifying racially charged misinformation in code-mixed Hindi-English (Hinglish) social media—a low-resource, linguistically complex domain with real-world impact. We adopt a two-pronged strategy, independently fine-tuning a transformer-based model and a large language model. CharBERT was optimized using Optuna, while XLM-RoBERTa and DistilBERT were fine-tuned for the classification task. FLAN-T5-base was fine-tuned with SMOTE-based oversampling, semantic-preserving back translation, and prompt engineering, whereas LLaMA was used solely for inference. Our preprocessing included Hinglish-specific normalization, noise reduction, sentiment-aware corrections and a custom weighted loss to emphasize the minority Hoax class. Despite using FLAN-T5-base due to resource limits, our models performed well. CharBERT achieved a macro F1 of 0.70 and FLAN-T5 followed at 0.69, both outperforming baselines like DistilBERT and LLaMA-3.2-1B. Our submission ranked 4th of 11 teams, underscoring the promise of our approach for scalable misinformation detection in code-switched contexts. Future work will explore larger LLMs, adversarial training and context-aware decoding.</abstract>
      <url hash="7526adee">2025.ltedi-1.27</url>
      <bibkey>rabbani-etal-2025-hoax</bibkey>
    </paper>
    <paper id="28">
      <title><fixed-case>CUET</fixed-case>_<fixed-case>I</fixed-case>gnite@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025: A Multimodal Transformer-Based Approach for Detecting Misogynistic Memes in <fixed-case>C</fixed-case>hinese Social Media</title>
      <author><first>MD. Mahadi</first><last>Rahman</last></author>
      <author><first>Mohammad Minhaj</first><last>Uddin</last></author>
      <author><first>Mohammad</first><last>Oman</last></author>
      <author><first>Mohammad Shamsul</first><last>Arefin</last></author>
      <pages>172-177</pages>
      <abstract>Misogynistic content in memes on social me dia platforms poses a significant challenge for content moderation, particularly in languages like Chinese, where cultural nuances and multi modal elements complicate detection. Address ing this issue is critical for creating safer online environments, A shared task on multimodal misogyny identification in Chinese memes, or ganized by LT-EDI@LDK 2025, provided a curated dataset for this purpose. Since memes mix pictures and words, we used two smart tools: ResNet-50 to understand the images and Chinese RoBERTa to make sense of the text. The data set consisted of Chinese social media memes annotated with binary labels (Misogynistic and Non-Misogynistic), capturing explicit misogyny, implicit biases, and stereo types. Our experiments demonstrated that ResNet-50 combined with Chinese RoBERTa achieved a macro F1 score of 0.91, placing second in the competition and underscoring its effectiveness in handling the complex interplay of text and visuals in Chinese memes. This research advances multimodal misogyny detection and contributes to natural language and vision processing for low-resource languages, particularly in combating gender-based abuse online.</abstract>
      <url hash="5890d711">2025.ltedi-1.28</url>
      <bibkey>rahman-etal-2025-cuet-ignite</bibkey>
    </paper>
    <paper id="29">
      <title>girlsteam@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025: Caste/Migration based hate speech Detection</title>
      <author><first>Towshin Hossain</first><last>Tushi</last></author>
      <author><first>Walisa</first><last>Alam</last></author>
      <author><first>Rehenuma</first><last>Ilman</last></author>
      <author><first>Samia</first><last>Rahman</last></author>
      <pages>178-183</pages>
      <abstract>The proliferation of caste- and migration-based hate speech on social media poses a significant challenge, particularly in low-resource languages like Tamil. This paper presents our approach to the LT-EDI@ACL 2025 shared task, addressing this issue through a hybrid transformer-based framework. We explore a range of Machine Learning (ML), Deep Learning (DL), and multilingual transformer models, culminating in a novel m-BERT+BiLSTM hybrid architecture. This model integrates contextual embeddings from m-BERT with lexical features from TF-IDF and FastText, feeding the enriched representations into a BiLSTM to capture bidirectional semantic dependencies. Empirical results demonstrate the superiority of this hybrid architecture, achieving a macro-F1 score of 0.76 on the test set and surpassing the performance of standalone models such as MuRIL and IndicBERT. These results affirm the effectiveness of hybrid multilingual models for hate speech detection in low-resource and culturally complex linguistic settings.</abstract>
      <url hash="9c8ad132">2025.ltedi-1.29</url>
      <bibkey>tushi-etal-2025-girlsteam</bibkey>
    </paper>
    <paper id="30">
      <title><fixed-case>CUET</fixed-case>_320@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-2025: A Multimodal Approach for Misogyny Meme Detection in <fixed-case>C</fixed-case>hinese Social Media</title>
      <author><first>Madiha Ahmed</first><last>Chowdhury</last></author>
      <author><first>Lamia Tasnim</first><last>Khan</last></author>
      <author><first>Md. Shafiqul</first><last>Hasan</last></author>
      <author><first>Ashim</first><last>Dey</last><affiliation>Chittagong University of Engineering and Technology</affiliation></author>
      <pages>184-189</pages>
      <abstract>Detecting misogyny in memes is challenging due to their complex interplay of images and text that often disguise offensive content. Current AI models struggle with these cross-modal relationships and contain inherent biases. We tested multiple approaches for the Misogyny Meme Detection task at LT-EDI@LDK 2025: ChineseBERT, mBERT, and XLM-R for text; DenseNet, ResNet, and InceptionV3 for images. Our best-performing system fused fine-tuned ChineseBERT and DenseNet features, concatenating them before final classification through a fully connected network. This multimodal approach achieved a 0.93035 macro F1-score, winning 1st place in the competition and demonstrating the effectiveness of our strategy for analyzing the subtle ways misogyny manifests in visual-textual content.</abstract>
      <url hash="29d20a5e">2025.ltedi-1.30</url>
      <bibkey>chowdhury-etal-2025-cuet</bibkey>
    </paper>
    <paper id="31">
      <title>Speech Personalization using Parameter Efficient Fine-Tuning for <fixed-case>N</fixed-case>epali Speakers</title>
      <author orcid="0009-0002-7955-9765"><first>Kiran</first><last>Pantha</last><affiliation>Kathmandu University</affiliation></author>
      <author><first>Rupak Raj</first><last>Ghimire</last></author>
      <author><first>Bal Krishna</first><last>Bal</last><affiliation>Kathmandu University</affiliation></author>
      <pages>190-199</pages>
      <abstract>The performance of Automatic Speech Recognition (ASR) systems has improved significantly, driven by advancements in large-scale pre-trained models. However, adapting such models to low-resource languages such as Nepali is challenging due to the lack of labeled data and computational resources. Additionally, adapting the unique speech parameters of the speaker to a model is also a challenging task. Personalization helps to target the model to fit the particular speaker. This work investigates parameter-efficient fine-tuning (PEFT) methods like Low-Rank Adaptation (LoRA) and Decomposed Weight Low-Rank Adaptation (DoRA) to improve the performance of fine-tuned Whisper ASR models for Nepali ASR tasks by Personalization. These experiments demonstrate that the PEFT methods obtain competitive results while significantly reducing the number of trainable parameters compared to full fine-tuning. LoRA and DoRA show a relative WER to <tex-math>FT_{Base}</tex-math> increment of 34.93% and 36.79%, respectively, and a relative CER to <tex-math>FT_{Base}</tex-math> increment of 49.50% and 50.03%, respectively. Furthermore, the results highlight a 99.74% reduction in total training parameters.</abstract>
      <url hash="e92bd691">2025.ltedi-1.31</url>
      <bibkey>pantha-etal-2025-speech</bibkey>
    </paper>
    <paper id="32">
      <title>An Overview of the Misogyny Meme Detection Shared Task for <fixed-case>C</fixed-case>hinese Social Media</title>
      <author orcid="0000-0002-4575-7934"><first>Bharathi Raja</first><last>Chakravarthi</last><affiliation>University of Galway</affiliation></author>
      <author orcid="0000-0001-8023-7742"><first>Rahul</first><last>Ponnusamy</last></author>
      <author><first>Ping</first><last>Du</last></author>
      <author><first>Xiaojian</first><last>Zhuang</last></author>
      <author><first>Saranya</first><last>Rajiakodi</last><affiliation>Central University of Tamil Nadu</affiliation></author>
      <author orcid="0000-0001-7238-9842"><first>Paul</first><last>Buitelaar</last><affiliation>University of Galway</affiliation></author>
      <author orcid="0000-0003-1188-1838"><first>Premjith</first><last>B</last><affiliation>Amrita Vishwa Vidyapeetham (Deemed University)</affiliation></author>
      <author><first>Bhuvaneswari</first><last>Sivagnanam</last><affiliation>Central University of Tamil Nadu</affiliation></author>
      <author orcid="0009-0003-4824-5250"><first>Anshid</first><last>Kizhakkeparambil</last></author>
      <author><first>Lavanya</first><last>S.K.</last><affiliation>Anna University</affiliation></author>
      <pages>200-208</pages>
      <abstract>The increasing prevalence of misogynistic content in online memes has raised concerns about their impact on digital discourse. The culture specific images and informal usage of text in the memes present considerable challenges for the automatic detection systems, especially in low-resource languages. While previous shared tasks have addressed misogyny detection in English and several European languages, misogynistic meme detection in the Chinese has remained largely unexplored. To address this gap, we introduced a shared task focused on binary classification of Chinese language memes as misogynistic or non-misogynistic. The task featured memes collected from the Chinese social media and annotated by native speakers. A total of 45 teams registered, with 8 teams submitting predictions from their multimodal models integrating textual and visual features through diverse fusion strategies. The best-performing system achieved a macro F1-score of 0.93035, highlighting the effectiveness of lightweight pretrained encoder fusion. This system used the Chinese BERT and DenseNet-121 for text and image feature extraction, respectively. A feedforward network was trained as a classifier using the features obtained by concatenating text and image features.</abstract>
      <url hash="86074f7c">2025.ltedi-1.32</url>
      <bibkey>chakravarthi-etal-2025-overview-misogyny</bibkey>
    </paper>
    <paper id="33">
      <title>Findings of the Shared Task Multilingual Bias and Propaganda Annotation in Political Discourse</title>
      <author orcid="0000-0001-5341-7684"><first>Shunmuga Priya Muthusamy</first><last>Chinnan</last></author>
      <author orcid="0000-0002-4575-7934"><first>Bharathi Raja</first><last>Chakravarthi</last><affiliation>University of Galway</affiliation></author>
      <author><first>Meghann</first><last>Drury-Grogan</last><affiliation>Atlantic Technological University, Ireland</affiliation></author>
      <author orcid="0000-0003-0835-5271"><first>Senthil Kumar</first><last>B</last><affiliation>Velammal Institute of Technology</affiliation></author>
      <author><first>Saranya</first><last>Rajiakodi</last><affiliation>Central University of Tamil Nadu</affiliation></author>
      <author><first>Angel Deborah</first><last>S</last></author>
      <pages>209-214</pages>
      <abstract>The Multilingual Bias and Propaganda Annotation task focuses on annotating biased and propagandist content in political discourse across English and Tamil. This paper presents the findings of the shared task on bias and propaganda annotation task. This task involves two sub tasks, one in English and another in Tamil, both of which are annotation task where a text comment is to be labeled. With a particular emphasis on polarizing policy debates such as the US Gender Policy and India’s Three Language Policy, this shared task invites participants to build annotation systems capable of labeling textual bias and propaganda. The dataset was curated by collecting comments from YouTube videos. Our curated dataset consists of 13,010 English sentences on US Gender Policy, Russia-Ukraine War and 5,880 Tamil sentences on Three Language Policy. Participants were instructed to annotate following the guidelines at sentence level with the bias labels that are fine-grained, domain specific and 4 propaganda labels. Participants were encouraged to leverage existing tools or develop novel approaches to perform fine-grained annotations that capture the complex socio-political nuances present in the data.</abstract>
      <url hash="1eff9394">2025.ltedi-1.33</url>
      <bibkey>chinnan-etal-2025-findings</bibkey>
    </paper>
    <paper id="34">
      <title>Findings of the Shared Task Caste and Migration Hate Speech Detection</title>
      <author><first>Saranya</first><last>Rajiakodi</last><affiliation>Central University of Tamil Nadu</affiliation></author>
      <author orcid="0000-0002-4575-7934"><first>Bharathi Raja</first><last>Chakravarthi</last><affiliation>University of Galway</affiliation></author>
      <author orcid="0000-0001-8023-7742"><first>Rahul</first><last>Ponnusamy</last></author>
      <author orcid="0000-0001-5341-7684"><first>Shunmuga Priya Muthusamy</first><last>Chinnan</last></author>
      <author orcid="0000-0003-2244-246X"><first>Prasanna Kumar</first><last>Kumaresan</last><affiliation>Data Science Institution, University of Galway, Ireland</affiliation></author>
      <author orcid="0000-0002-2272-3117"><first>Sathiyaraj</first><last>Thangasamy</last></author>
      <author><first>Bhuvaneswari</first><last>Sivagnanam</last><affiliation>Central University of Tamil Nadu</affiliation></author>
      <author><first>Balasubramanian</first><last>Palani</last><affiliation>IIIT Kottayam</affiliation></author>
      <author orcid="0000-0002-0715-143X"><first>Kogilavani</first><last>Shanmugavadivel</last></author>
      <author><first>Abirami</first><last>Murugappan</last><affiliation>Anna University</affiliation></author>
      <author><first>Charmathi</first><last>Rajkumar</last></author>
      <pages>215-221</pages>
      <abstract>Hate speech targeting caste and migration communities is a growing concern in online platforms, particularly in linguistically diverse regions. By focusing on Tamil language text content, this task provides a unique opportunity to tackle caste or migration related hate speech detection in a low resource language Tamil, contributing to a safer digital space. We present the results and main findings of the shared task caste and migration hate speech detection. The task is a binary classification determining whether a text is caste/migration related hate speech or not. The task attracted 17 participating teams, experimenting with a wide range of methodologies from traditional machine learning to advanced multilingual transformers. The top performing system achieved a macro F1-score of 0.88105, enhancing an ensemble of fine-tuned transformer models including XLM-R and MuRIL. Our analysis highlights the effectiveness of multilingual transformers in low resource, ensemble learning, and culturally informed socio political context based techniques.</abstract>
      <url hash="28207656">2025.ltedi-1.34</url>
      <bibkey>rajiakodi-etal-2025-findings-shared</bibkey>
    </paper>
    <paper id="35">
      <title>Overview of the Shared Task on Detecting Racial Hoaxes in Code-Mixed <fixed-case>H</fixed-case>indi-<fixed-case>E</fixed-case>nglish Social Media Data</title>
      <author orcid="0000-0002-4575-7934"><first>Bharathi Raja</first><last>Chakravarthi</last><affiliation>University of Galway</affiliation></author>
      <author orcid="0000-0003-2244-246X"><first>Prasanna Kumar</first><last>Kumaresan</last><affiliation>Data Science Institution, University of Galway, Ireland</affiliation></author>
      <author><first>Shanu</first><last>Dhawale</last></author>
      <author><first>Saranya</first><last>Rajiakodi</last><affiliation>Central University of Tamil Nadu</affiliation></author>
      <author><first>Sajeetha</first><last>Thavareesan</last></author>
      <author><first>Subalalitha Chinnaudayar</first><last>Navaneethakrishnan</last></author>
      <author orcid="0000-0003-0681-6628"><first>Thenmozhi</first><last>Durairaj</last></author>
      <pages>222-228</pages>
      <abstract>The widespread use of social media has made it easier for false information to proliferate, particularly racially motivated hoaxes that can encourage violence and hatred. Such content is frequently shared in code-mixed languages in multilingual nations like India, which presents special difficulties for automated detection systems because of the casual language, erratic grammar, and rich cultural background. The shared task on detecting racial hoaxes in code mixed social media data aims to identify the racial hoaxes in Hindi-English data. It is a binary classification task with more than 5,000 labeled instances. A total of 11 teams participated in the task, and the results are evaluated using the macro-F1 score. The team that employed XLM-RoBERTa secured the first position in the task.</abstract>
      <url hash="7ca499f3">2025.ltedi-1.35</url>
      <bibkey>chakravarthi-etal-2025-overview-shared</bibkey>
    </paper>
    <paper id="36">
      <title>Overview of Homophobia and Transphobia Span Detection in Social Media Comments</title>
      <author orcid="0000-0003-2244-246X"><first>Prasanna Kumar</first><last>Kumaresan</last><affiliation>Data Science Institution, University of Galway, Ireland</affiliation></author>
      <author orcid="0000-0002-4575-7934"><first>Bharathi Raja</first><last>Chakravarthi</last><affiliation>University of Galway</affiliation></author>
      <author><first>Ruba</first><last>Priyadharshini</last><affiliation>The Gandhigram Rural Institute - Deemed University</affiliation></author>
      <author orcid="0000-0001-7238-9842"><first>Paul</first><last>Buitelaar</last><affiliation>University of Galway</affiliation></author>
      <author orcid="0000-0003-3263-0376"><first>Malliga</first><last>Subramanian</last></author>
      <author orcid="0000-0001-9621-668X"><first>Kishore Kumar</first><last>Ponnusamy</last></author>
      <pages>229-234</pages>
      <abstract>The rise and the intensity of harassment and hate speech in social media platforms against LGBTQ+ communities is a growing concern. This work is an initiative to address this problem by conducting a shared task focused on the detection of homophobic and transphobic content in multilingual settings. The task comprises two subtasks: (1) multi-class classification of content into Homophobia, Transphobia, or Non-anti-LGBT+ categories across eight languages and (2) span-level detection to identify specific toxic segments within comments in English, Tamil, and Marathi. This initiative helps the development of explainable and socially re- sponsible AI tools for combating identity-based harm in digital spaces. Multiple teams registered for the task, however only two teams submitted their results, and the results were evaluated using the macro F1 score.</abstract>
      <url hash="a09cc4ce">2025.ltedi-1.36</url>
      <bibkey>kumaresan-etal-2025-overview</bibkey>
    </paper>
    <paper id="37">
      <title>Overview of the Fifth Shared Task on Speech Recognition for Vulnerable Individuals in <fixed-case>T</fixed-case>amil</title>
      <author orcid="0000-0001-7279-5357"><first>Bharathi</first><last>B</last></author>
      <author orcid="0000-0002-4575-7934"><first>Bharathi Raja</first><last>Chakravarthi</last><affiliation>University of Galway</affiliation></author>
      <author orcid="0000-0003-2070-418X"><first>Sripriya</first><last>N</last></author>
      <author><first>Rajeswari</first><last>Natarajan</last></author>
      <author orcid="0000-0002-6570-483X"><first>Ratnavel</first><last>Rajalakshmi</last><affiliation>Vellore Institute of Technology</affiliation></author>
      <author><first>Suhasini</first><last>S</last></author>
      <pages>235-241</pages>
      <abstract>In this paper, an overview of the shared task on speech recognition for vulnerable individuals in Tamil (LT-EDI@LDK2025) is described. The work comes with a Tamil dataset that was collected from elderly individuals who identify as male, female, or transgender. The audio samples were taken in public places such as markets, vegetable shops, hospitals, etc. The training phase and the testing phase are when the dataset is made available. The task required of the participants was to handle audio signals using various models and techniques and then turn in their results as transcriptions of the provided test samples. The participant’s results were assessed using WER (Word Error Rate). The transformer-based approach was used by participants to achieve automatic voice recognition. This overview paper discusses the findings and various pre-trained transformer-based models that the participants employed.</abstract>
      <url hash="e4f57710">2025.ltedi-1.37</url>
      <bibkey>b-etal-2025-overview-fifth</bibkey>
    </paper>
  </volume>
</collection>
