<?xml version='1.0' encoding='UTF-8'?>
<collection id="2016.jeptalnrecital">
  <volume id="jep" ingest-date="2020-07-08">
    <meta>
      <booktitle>Actes de la conférence conjointe JEP-TALN-RECITAL 2016. volume 1 : JEP</booktitle>
      <editor><first>Laurence</first><last>Danlos</last></editor>
      <editor><first>Thierry</first><last>Hamon</last></editor>
      <publisher>AFCP - ATALA</publisher>
      <address>Paris, France</address>
      <month>7</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="c9c77997">2016.jeptalnrecital-jep.0</url>
    </frontmatter>
    <paper id="1">
      <title>Le <fixed-case>VOT</fixed-case> des éjectives : le cas du maya yucatèque (The <fixed-case>VOT</fixed-case> of ejective stops in Maya Yucatec)</title>
      <language>fra</language>
      <author><first>Emre</first><last>Bayraktar</last></author>
      <author><first>Rachid</first><last>Ridouane</last></author>
      <pages>1–9</pages>
      <abstract>Cet article présente une étude acoustique des occlusives éjectives du maya yucatèque. S’intéressant spécifiquement au voice onset time (VOT), l’étude examine d’une part si le VOT est un corrélat acoustique fiable de l’éjectivité dans cette langue et d’autre part si le VOT varie selon le lieu d’articulation et la hauteur vocalique. Les résultats, obtenus à partir des productions de deux locuteurs natifs, montrent que les éjectives ont un VOT plus long comparées à leurs contreparties pulmonaires. Parmi les éjectives, le VOT varie en fonction du lieu d’articulation, les vélaires présentant le VOT le plus long. De même une tendance pour un VOT plus court devant les voyelles hautes a été observée. Ces résultats soulèvent un ensemble de questions concernant les mécanismes qui sous-tendent les variations du VOT, notamment en lien avec les contraintes aérodynamiques en jeu lors de la production des occlusives éjectives.</abstract>
      <url hash="5093c2bd">2016.jeptalnrecital-jep.1</url>
    </paper>
    <paper id="2">
      <title>Accommodation temporelle chez l’enfant dans une tâche de parole alternée (Children’s temporal accommodation in an alternated naming task)</title>
      <language>fra</language>
      <author><first>Céline</first><last>Hidalgo</last></author>
      <author><first>Simone</first><last>Falk</last></author>
      <author><first>Daniele</first><last>Schön</last></author>
      <pages>10–18</pages>
      <abstract>L’accommodation temporelle entre deux interlocuteurs est un phénomène qui émerge lors d’une interaction et qui jouerait un rôle important dans la fluidité des échanges. Cette étude examine cette capacité temporelle chez l’enfant âgé de 5 à 6 ans grâce au développement d’une nouvelle tâche de dénomination en alternance avec un partenaire virtuel. Les variables temporelles analysées sont le tempo de l’alternance (lent versus rapide) et la rythmicité des mots échangés (constante versus aléatoire). Les enfants sont plus précis dans la condition de tempo rapide et plus réguliers lorsque la rythmicité des listes de mots est maintenue constante. Ces résultats montrent 1) que la dénomination en alternance est un paradigme permettant de mesurer les capacités d’accommodation temporelle des enfants et que 2) dès 5 ans, les enfants peuvent ajuster leur parole à celle d’un agent. Ces données constituent une base pour mesurer les capacités linguistiques d’accommodation temporelle chez des populations cliniques.</abstract>
      <url hash="c33d35bf">2016.jeptalnrecital-jep.2</url>
    </paper>
    <paper id="3">
      <title>Accès lexical et reconnaissance du voisement en voix chuchotée (Lexical acces and recognition of voicing in whisper)</title>
      <language>fra</language>
      <author><first>Yohann</first><last>Meynadier</last></author>
      <author><first>Sophie</first><last>Dufour</last></author>
      <pages>19–27</pages>
      <abstract>La reconnaissance du trait de voisement de consonnes obstruantes chuchotées en français a été examinée via un paradigme d’amorçage sémantique auditif-visuel. Un effet d’amorçage d’amplitude similaire à celui mesuré en voix modale a été observé uniquement lorsque l’obstruante du mot amorce chuchoté est sourde (dessert-CHOCOLAT). Aucun effet d’amorçage n’a été noté quand l’obstruante du mot amorce est voisée (désert) que ce soit sur le mot cible SABLE associé sémantique de désert ou sur le mot cible CHOCOLAT associé sémantique de dessert. Ainsi, même si certaines travaux ont mis en évidence qu’en voix chuchotée les consonnes obstruantes voisées maintiennent des traces phonétiques de leur identité sous-jacente, notre étude montre que ces consonnes sont ambigües pour l’auditeur et que leur reconnaissance n’est pas immédiate.</abstract>
      <url hash="181b6a4c">2016.jeptalnrecital-jep.3</url>
    </paper>
    <paper id="4">
      <title>Acquisition et reconnaissance automatique d’expressions et d’appels vocaux dans un habitat. (Acquisition and recognition of expressions and vocal calls in a smart home)</title>
      <language>fra</language>
      <author><first>Michel</first><last>Vacher</last></author>
      <author><first>Benjamin</first><last>Lecouteux</last></author>
      <author><first>Frédéric</first><last>Aman</last></author>
      <author><first>François</first><last>Portet</last></author>
      <author><first>Solange</first><last>Rossato</last></author>
      <pages>28–36</pages>
      <abstract>Cet article présente un système capable de reconnaître les appels à l’aide de personnes âgées vivant à domicile afin de leur fournir une assistance. Le système utilise une technologie de Reconnaissance Automatique de la Parole (RAP) qui doit fonctionner en conditions de parole distante et avec de la parole expressive. Pour garantir l’intimité, le système s’exécute localement et ne reconnaît que des phrases prédéfinies. Le système a été évalué par 17 participants jouant des scénarios incluant des chutes dans un Living lab reproduisant un salon. Le taux d’erreur de détection obtenu, 29%, est encourageant et souligne les défis à surmonter pour cette tâche.</abstract>
      <url hash="61484a33">2016.jeptalnrecital-jep.4</url>
    </paper>
    <paper id="5">
      <title>Adaptation de la prononciation pour la synthèse de la parole spontanée en utilisant des informations linguistiques (Pronunciation adaptation for spontaneous speech synthesis using linguistic information)</title>
      <language>fra</language>
      <author><first>Raheel</first><last>Qader</last></author>
      <author><first>Gwénolé</first><last>Lecorvé</last></author>
      <author><first>Damien</first><last>Lolive</last></author>
      <author><first>Pascale</first><last>Sébillot</last></author>
      <pages>37–45</pages>
      <abstract>Cet article présente une nouvelle méthode d’adaptation de la prononciation dont le but est de reproduire le style spontané. Il s’agit d’une tâche-clé en synthèse de la parole car elle permet d’apporter de l’expressivité aux signaux produits, ouvrant ainsi la voie à de nouvelles applications. La force de la méthode proposée est de ne s’appuyer que sur des informations linguistiques et de considérer un cadre probabiliste pour ce faire, précisément les champs aléatoires conditionnels. Dans cet article, nous étudions tout d’abord la pertinence d’un ensemble d’informations pour l’adaptation, puis nous combinons les informations les plus pertinentes lors d’expériences finales. Les évaluations de la méthode sur un corpus de parole conversationnelle en anglais montrent que les prononciations adaptées reflètent significativement mieux un style spontané que les prononciations canoniques.</abstract>
      <url hash="d7518eef">2016.jeptalnrecital-jep.5</url>
    </paper>
    <paper id="6">
      <title>Alignement de séquences phonétiques pour une analyse phonologique des erreurs de transcription automatique (Phonetic sequences alignment for a phonemic analysis of automatic speech transcription errors )</title>
      <language>fra</language>
      <author><first>Camille</first><last>Dutrey</last></author>
      <author><first>Martine</first><last>Adda-Decker</last></author>
      <author><first>Naomi</first><last>Yamaguchi</last></author>
      <pages>46–54</pages>
      <abstract>La transcription automatique de la parole obtient aujourd’hui des performances élevées avec des taux d’erreur qui tombent facilement en dessous de 10% pour une parole journalistique. Cependant, pour des conversations plus libres, ils stagnent souvent autour de 20–30%. En français, une grande partie des erreurs sont dues à des confusions entre homophones n’impliquant pas les niveaux acousticophonétique et phonologique. Cependant, de nombreuses erreurs peuvent s’expliquer par des variantes de productions non prévues par le système. Afin de mieux comprendre quels processus phonologiques pourraient expliquer ces variantes spécifiques de la parole spontanée, nous proposons une analyse des erreurs en comparant prononciations attendue (référence) et reconnue (hypothèse) via un alignement phonétique par programmation dynamique. Les distances locales entre paires de phonèmes appariés correspondent au nombre de traits phonétiques disjoints. Nos analyses permettent d’identifier les traits phonétiques les plus fréquemment impliqués dans les erreurs et donnent des pistes pour des interprétations phonologiques.</abstract>
      <url hash="312b25f0">2016.jeptalnrecital-jep.6</url>
    </paper>
    <paper id="7">
      <title>Allophonie et position dans la syllabe: Indices acoustiques pour les consonnes laterales (Acoustics of syllable position allophony: The case of lateral consonants)</title>
      <language>fra</language>
      <author><first>Anisia</first><last>Popescu</last></author>
      <author><first>Ioana</first><last>Chitoran</last></author>
      <pages>55–63</pages>
      <abstract>L‟article traite de la manifestation acoustique des consonnes latérales en anglais américain et en roumain en fonction de la position syllabique et de la complexité phonotactique. Nous avons considéré quatre types de mesures: valeurs formantiques, équations locus, ratio d‟intensité et présence/absence de relâchements. Notre but est, d‟une part, de classifier les allophones des deux langues considérées et d‟autre part de déterminer les indices acoustiques des gestes articulatoires des consonnes latérales. Les résultats indiquent des différences importantes entre les deux langues. On montre que la distribution des allophones n‟est pas binaire, mais graduée et que le statut du geste dorsal peut être considéré comme un marqueur de « degré de clarté ». On montre aussi que l‟allophonie dépend de la position syllabique mais pas forcément de la complexité syllabique.</abstract>
      <url hash="86e40916">2016.jeptalnrecital-jep.7</url>
    </paper>
    <paper id="8">
      <title>Analyses acoustiques des monophtongues du luxembourgeois produites dans la parole lue (Acoustic analyses of <fixed-case>L</fixed-case>uxembourgish monophthongs produced in reading speech)</title>
      <language>fra</language>
      <author><first>Tina</first><last>Thill</last></author>
      <pages>64–72</pages>
      <abstract>Cet article présente une analyse acoustique de 12 monophtongues du luxembourgeois produites par des locuteurs de la région centrale du Grand-Duché de Luxembourg. Cette analyse fait partie du travail empirique de notre thèse de doctorat sur les productions natives et non natives des voyelles du luxembourgeois. A partir des données de 10 locuteurs natifs, nous analysons les valeurs de la durée et des trois premiers formants des paires de voyelles longues et brèves opposées [iː]-[i], [eː][e], [aː]-[ɑ], [oː]-[ɔ], [uː]-[u] et de l’allophone [ɛː] réalisée lorsqu’elle est suivie d’un /r/. Les analyses montrent que (i) les voyelles longues et brèves se distinguent tant par la durée acoustique que par le timbre, (ii) la voyelle semi-ouverte [ɛː] suivie d’un /r/ vocalisé tend à se diphtonguer.</abstract>
      <url hash="25146588">2016.jeptalnrecital-jep.8</url>
    </paper>
    <paper id="9">
      <title>Auto-encodeurs pour la compréhension de documents parlés (Auto-encoders for Spoken Document Understanding)</title>
      <language>fra</language>
      <author><first>Killian</first><last>Janod</last></author>
      <author><first>Mohamed</first><last>Morchid</last></author>
      <author><first>Richard</first><last>Dufour</last></author>
      <author><first>Georges</first><last>Linarès</last></author>
      <author><first>Renato</first><last>De Mori</last></author>
      <pages>73–81</pages>
      <abstract>Les représentations de documents au moyen d’approches à base de réseaux de neurones ont montré des améliorations significatives dans de nombreuses tâches du traitement du langage naturel. Dans le cadre d’applications réelles, où des conditions d’enregistrement difficiles peuvent être rencontrées, la transcription automatique de documents parlés peut générer un nombre de mots mal transcrits important. Cet article propose une représentation des documents parlés très bruités utilisant des caractéristiques apprises par un auto-encodeur profond supervisé. La méthode proposée s’appuie à la fois sur les documents bruités et leur équivalent propre annoté manuellement pour estimer une représentation plus robuste des documents bruités. Cette représentation est évaluée sur le corpus DECODA sur une tâche de classification thématique de conversations téléphoniques atteignant une précision de 83% avec un gain d’environ 6%.</abstract>
      <url hash="8d2dde63">2016.jeptalnrecital-jep.9</url>
    </paper>
    <paper id="10">
      <title>Autoapprentissage pour le regroupement en locuteurs : premières investigations (First investigations on self trained speaker diarization )</title>
      <language>fra</language>
      <author><first>Gaël</first><last>Le Lan</last></author>
      <author><first>Sylvain</first><last>Meignier</last></author>
      <author><first>Delphine</first><last>Charlet</last></author>
      <author><first>Anthony</first><last>Larcher</last></author>
      <pages>82–90</pages>
      <abstract>This paper investigates self trained cross-show speaker diarization applied to collections of French TV archives, based on an <i>i-vector/PLDA</i> framework. The parameters used for i-vectors extraction and PLDA scoring are trained in a unsupervised way, using the data of the collection itself. Performances are compared, using combinations of target data and external data for training. The experimental results on two distinct target corpora show that using data from the corpora themselves to perform unsupervised iterative training and domain adaptation of PLDA parameters can improve an existing system, trained on external annotated data. Such results indicate that performing speaker indexation on small collections of unlabeled audio archives should only rely on the availability of a sufficient external corpus, which can be specifically adapted to every target collection. We show that a minimum collection size is required to exclude the use of such an external bootstrap.</abstract>
      <url hash="897f6a0e">2016.jeptalnrecital-jep.10</url>
    </paper>
    <paper id="11">
      <title>Bilinguismes et compliance phonique (<fixed-case>BILINGUALISMS</fixed-case> <fixed-case>AND</fixed-case> <fixed-case>PHONETIC</fixed-case> <fixed-case>COMPLIANCE</fixed-case>)</title>
      <language>fra</language>
      <author><first>Marie</first><last>Philippart de Foy</last></author>
      <author><first>Véronique</first><last>Delvaux</last></author>
      <author><first>Kathy</first><last>Huet</last></author>
      <author><first>Myriam</first><last>Piccaluga</last></author>
      <author><first>Rima</first><last>Rabeh</last></author>
      <author><first>Bernard</first><last>Harmegnies</last></author>
      <pages>91–100</pages>
      <abstract>BILINGUISMES ET COMPLIANCE PHONIQUE Certains types de bilinguisme pourraient avoir un impact positif sur l’apprentissage phonique et faciliter l’acquisition d’une L3. Certains bilingues pourraient donc présenter une meilleure compliance phonique (aptitude à produire des sons de parole non familiers) que les monolingues. Les données de quatre sujets bilingues ont été recueillies lors d’une tâche de reproduction de voyelles synthétiques précédée d’une phase de production de voyelles en langue maternelle (paradigme développé par Huet et al., 2012). Trois indices ont été calculés et comparés à ceux obtenus par des monolingues francophones lors d’une étude précédente (Delvaux et al., 2014). Les résultats n’ont pas révélé de différence significative entre monolingues et bilingues. Toutefois, le classement des bilingues variait d’un indice à l’autre, suggérant des profils plus diversifiés que chez les monolingues. En conclusion, ces résultats confirment la complexité de la compliance phonique, en particulier chez des locuteurs bilingues, et soulignent l’intérêt d’une approche multi-componentielle ainsi que le besoin d’ajustements ultérieurs de la réflexion théorique sous-jacente.</abstract>
      <url hash="9cd9fa7d">2016.jeptalnrecital-jep.11</url>
    </paper>
    <paper id="12">
      <title>De bé à bébé : le transfert d’apprentissage auditori-moteur pour interroger l’unité de production de la parole (From sensorimotor experience to speech unit)</title>
      <language>fra</language>
      <author><first>Tiphaine</first><last>Caudrelier</last></author>
      <author><first>Pascal</first><last>Perrier</last></author>
      <author><first>Jean-Luc</first><last>Schwartz</last></author>
      <author><first>Christophe</first><last>Savariaux</last></author>
      <author><first>Amélie</first><last>Rochet-Capellan</last></author>
      <pages>101–109</pages>
      <abstract>La parole est souvent décrite comme une mise en séquence d’unités associant des représentations linguistiques, sensorielles et motrices. Le lien entre ces représentations se fait-il de manière privilégiée sur une unité spécifique ? Par exemple, est-ce la syllabe ou le mot ? Dans cette étude, nous voulons contraster ces deux hypothèses. Pour cela, nous avons modifié chez des locuteurs du français la production de la syllabe « bé », selon un paradigme d’adaptation auditori-motrice, consistant à perturber le retour auditif. Nous avons étudié comment cette modification se transfère ensuite à la production du mot « bébé ». Les résultats suggèrent un lien entre représentations linguistiques et motrices à plusieurs niveaux, à la fois celui du mot et de la syllabe. Ils montrent également une influence de la position de la syllabe dans le mot sur le transfert, qui soulève de nouvelles questions sur le contrôle sériel de la parole.</abstract>
      <url hash="ecd93419">2016.jeptalnrecital-jep.12</url>
    </paper>
    <paper id="13">
      <title>Caractérisation statique et dynamique des voyelles dans des transitions <fixed-case>VV</fixed-case> (Static and dynamic characterization of vowels in <fixed-case>VV</fixed-case> sequences)</title>
      <language>fra</language>
      <author><first>Julien</first><last>Millasseau</last></author>
      <author><first>Olivier</first><last>Crouzet</last></author>
      <pages>110–118</pages>
      <abstract>Nous étudions les indices acoustiques liés à la caractérisation statique et / ou dynamique des voyelles du français. Nous avons analysé les caractéristiques formantiques de six réalisations vocaliques ainsi que les transitions formantiques de seize combinaisons V1 V2 impliquant ces 6 voyelles afin d’évaluer les contributions des indices dynamiques liés aux transitions entre voyelles et des indices statiques de fréquence. Les mesures correspondantes sont issues d’un protocole dans lequel le débit de parole était influencé expérimentalement afin de provoquer d’éventuelles variations de vitesse de transition. Les résultats ne permettent pas de départager ces deux hypothèses mais montrent que les indices dynamiques pourraient être aussi fiables que les mesures statiques. Des pistes d’extension de ce travail sont proposées qui pourraient contribuer de manière plus informative à cette problématique.</abstract>
      <url hash="257b7519">2016.jeptalnrecital-jep.13</url>
    </paper>
    <paper id="14">
      <title>Cartopho : un site web de cartographie de variantes de prononciation en français (Cartopho: a website for mapping pronunciation variants in <fixed-case>F</fixed-case>rench)</title>
      <language>fra</language>
      <author><first>Philippe</first><last>Boula de Mareüil</last></author>
      <author><first>Jean-Philippe</first><last>Goldman</last></author>
      <author><first>Albert</first><last>Rilliard</last></author>
      <author><first>Yves</first><last>Scherrer</last></author>
      <author><first>Frédéric</first><last>Vernier</last></author>
      <pages>119–127</pages>
      <abstract>Le présent travail se propose de renouveler les traditionnels atlas dialectologiques pour cartographier les variantes de prononciation en français, à travers un site internet. La toile est utilisée non seulement pour collecter des données, mais encore pour disséminer les résultats auprès des chercheurs et du grand public. La méthodologie utilisée, à base de crowdsourcing (ou « production participative »), nous a permis de recueillir des informations auprès de 2500 francophones d’Europe (France, Belgique, Suisse). Une plateforme dynamique à l’interface conviviale a ensuite été développée pour cartographier la prononciation de 70 mots dans les différentes régions des pays concernés (des mots notamment à voyelle moyenne ou dont la consonne finale peut être prononcée ou non). Les options de visualisation par département/canton/province ou par région, combinant plusieurs traits de prononciation et ensembles de mots, sous forme de pastilles colorées, de hachures, etc. sont présentées dans cet article. On peut ainsi observer immédiatement un /E/ plus fermé (ainsi qu’un /O/ plus ouvert) dans le Nord-Pas-de-Calais et le sud de la France, pour des mots comme parfait ou rose, un /Œ/ plus fermé en Suisse pour un mot comme gueule, par exemple.</abstract>
      <url hash="a1af24d9">2016.jeptalnrecital-jep.14</url>
    </paper>
    <paper id="15">
      <title>Comparaison de listes d’erreurs de transcription automatique de la parole : quelle complémentarité entre les différentes métriques ? (Comparing error lists for <fixed-case>ASR</fixed-case> systems : contribution of different metrics)</title>
      <language>fra</language>
      <author><first>Olivier</first><last>Galibert</last></author>
      <author><first>Juliette</first><last>Kahn</last></author>
      <author><first>Sophie</first><last>Rosset</last></author>
      <pages>128–136</pages>
      <abstract>Le travail que nous présentons ici s’inscrit dans le domaine de l’évaluation des systèmes de reconnaissance automatique de la parole en vue de leur utilisation dans une tâche aval, ici la reconnaissance des entités nommées. Plus largement, la question que nous nous posons est “que peut apporter une métrique d’évaluation en dehors d’un score ?". Nous nous intéressons particulièrement aux erreurs des systèmes et à leur analyse et éventuellement à l’utilisation de ce que nous connaissons de ces erreurs. Nous étudions dans ce travail les listes ordonnées d’erreurs générées à partir de différentes métriques et analysons ce qui en ressort. Nous avons appliqué la même méthode sur les sorties de différents systèmes de reconnaissance de la parole. Nos expériences mettent en évidence que certaines métriques apportent une information plus pertinente étant donné une tâche et transverse à différents systèmes.</abstract>
      <url hash="8c9ced7b">2016.jeptalnrecital-jep.15</url>
    </paper>
    <paper id="16">
      <title>Se concentrer sur les différences : une méthode d’évaluation subjective efficace pour la comparaison de systèmes de synthèse (Focus on differences : a subjective evaluation method to efficiently compare <fixed-case>TTS</fixed-case> systems * )</title>
      <language>fra</language>
      <author><first>Jonathan</first><last>Chevelu</last></author>
      <author><first>Damien</first><last>Lolive</last></author>
      <author><first>Sébastien Le</first><last>Maguer</last></author>
      <author><first>David</first><last>Guennec</last></author>
      <pages>137–145</pages>
      <abstract>En proposant une nouvelle approche de synthèse de la parole, les études comportent généralement une évaluation subjective d’échantillons acoustiques produits par un système de référence et un nouveau système. Ces échantillons sont produits à partir d’un petit ensemble de phrases choisies aléatoirement dans un unique domaine. Ainsi, statistiquement, des échantillons pratiquement identiques sont présentés et réduisent les écarts de mesure entre les systèmes, au risque de les considérer comme non significatifs. Pour éviter cette problématique méthodologique, nous comparons deux systèmes sur des milliers d’échantillons de différents domaines. L’évaluation est réalisée uniquement sur les paires d’échantillons les plus pertinentes, c’est-à-dire les plus différentes acoustiquement. Cette méthode est appliquée sur un système de synthèse de type HTS et un second par sélection d’unités. La comparaison avec l’approche classique montre que cette méthode révèle des écarts qui jusqu’alors n’étaient pas significatifs.</abstract>
      <url hash="aab85e08">2016.jeptalnrecital-jep.16</url>
    </paper>
    <paper id="17">
      <title>Constituance et phrasé prosodique en français : une étude perceptive. (Prosodic constituency and phrasing in <fixed-case>F</fixed-case>rench: a perception study)</title>
      <language>fra</language>
      <author><first>Laury</first><last>Garnier</last></author>
      <author><first>Corine</first><last>Astésano</last></author>
      <author><first>Lorraine</first><last>Baqué</last></author>
      <author><first>Anne</first><last>Dagnac</last></author>
      <pages>146–154</pages>
      <abstract>L’objectif de cette étude est d’explorer l’organisation du phrasé prosodique en français. Il n’existe pas de consensus clair sur le nombre de niveaux nécessaires pour refléter la hiérarchie prosodique de la langue. Dans ce cadre, nous proposons une étude perceptive, via un corpus de parole contrôlée manipulant des structures syntaxiques ambiguës, où 27 participants ont effectué 3 tâches de perception : proéminence, frontière et groupement. Nos résultats montrent une utilisation privilégiée des indices de frontières dans le marquage des groupes prosodiques. Plus précisément, on observe que les auditeurs sont capables de percevoir des niveaux de granularité de frontières plus fins que ce que les descriptions traditionnelles du français prédisent. Par ailleurs, les résultats de la tâche de proéminence montrent que l’accent initial est toujours perçu plus fort que l’accent final, et ce dès les niveaux les plus bas de la hiérarchie.</abstract>
      <url hash="9af5b8c3">2016.jeptalnrecital-jep.17</url>
    </paper>
    <paper id="18">
      <title>Contribuer au progrès solidaire des recherches et de la documentation : la Collection Pangloss et la Collection <fixed-case>A</fixed-case>u<fixed-case>C</fixed-case>o (Contributing to joint progress in documentation and research: some achievements and future perspectives of the Pangloss Collection and the <fixed-case>A</fixed-case>u<fixed-case>C</fixed-case>o Collection)</title>
      <language>fra</language>
      <author><first>Alexis</first><last>Michaud</last></author>
      <author><first>Séverine</first><last>Guillaume</last></author>
      <author><first>Guillaume</first><last>Jacques</last></author>
      <author><first>Đăng-Khoa</first><last>Mạc</last></author>
      <author><first>Michel</first><last>Jacobson</last></author>
      <author><first>Thu-Hà</first><last>Phạm</last></author>
      <author><first>Matthew</first><last>Deo</last></author>
      <pages>155–163</pages>
      <abstract>La présente communication présente les projets scientifiques et les réalisations de deux collections hébergées par la plateforme de ressources orales Cocoon : la Collection Pangloss, qui concerne principalement des langues de tradition orale (sans écriture), du monde entier ; et la Collection AuCo, dédiée aux langues du Vietnam et de pays voisins. L’objectif est un progrès solidaire des recherches et de la documentation linguistique. L’accent est mis sur les perspectives ouvertes pour la recherche en phonétique/phonologie par certaines réalisations récentes dans le cadre de ces deux Collections.</abstract>
      <url hash="d747c6d7">2016.jeptalnrecital-jep.18</url>
    </paper>
    <paper id="19">
      <title>Contribution à l’étude de la focalisation prosodique en français (Contribution to the study of prosodic highlighting in <fixed-case>F</fixed-case>rench)</title>
      <language>fra</language>
      <author><first>Rémi</first><last>Godement-Berline</last></author>
      <pages>164–172</pages>
      <abstract>Cette étude porte sur la focalisation prosodique en français dans plusieurs styles de parole (parole spontanée et lecture ou interprétation par des acteurs). Nous attribuons à la focalisation des fonctions sémantico-pragmatiques ou emphatiques. Un groupe de dix experts en prosodie a relevé les occurrences de focalisation dans le corpus d’étude. Les résultats confirment que la focalisation est réalisée par une augmentation de hauteur et de durée. Ils diffèrent de la littérature précédente du point de vue du type de contour prosodique employé sur les occurrences de focalisation et de la présence d’accent initial. Des problèmes méthodologiques sont soulevés concernant l’analyse des contours terminaux et de la désaccentuation.</abstract>
      <url hash="c32ea835">2016.jeptalnrecital-jep.19</url>
    </paper>
    <paper id="20">
      <title>Un Corpus de Flux <fixed-case>TV</fixed-case> Annotés pour la Prédiction de Genres (A Genre Annotated Corpus of <fixed-case>F</fixed-case>rench Multi-channel <fixed-case>TV</fixed-case> Streams for Genre Prediction)</title>
      <language>fra</language>
      <author><first>Mohamed</first><last>Bouaziz</last></author>
      <author><first>Mohamed</first><last>Morchid</last></author>
      <author><first>Richard</first><last>Dufour</last></author>
      <author><first>Georges</first><last>Linarès</last></author>
      <author><first>Prosper</first><last>Correa</last></author>
      <pages>173–181</pages>
      <abstract>Cet article présente une méthode de prédiction de genres d’émissions télévisées couvrant 2 jours de diffusion de 4 chaînes TV françaises structurés en émissions annotées en genres. Ce travail traite des médias de masse de flux de chaînes télévisées et rejoint l’effort global d’extraction de connaissance à partir de cette grande quantité de données produites continuellement. Le corpus employé est fourni par l’entreprise EDD, anciennement appelée “L’Européenne de Données”, une entreprise spécialisée dans la gestion des flux multimédias. Les expériences détaillées dans cet article montrent qu’une approche simple fondée sur un modèle de n-grammes permet de prédire le genre d’une émission selon un historique avec une précision avoisinant les 50 %.</abstract>
      <url hash="35832aff">2016.jeptalnrecital-jep.20</url>
    </paper>
    <paper id="21">
      <title>Disfluences dans le vieillissement « normal » et la maladie d’<fixed-case>A</fixed-case>lzheimer : indices segmentaux, suprasegmentaux et gestuels (Disfluencies in “normal” aging and <fixed-case>A</fixed-case>lzheimer’s disease: segmental, suprasegmental and gestural markers)</title>
      <language>fra</language>
      <author><first>Diane</first><last>Caussade</last></author>
      <author><first>Nathalie</first><last>Vallée</last></author>
      <author><first>Nathalie</first><last>Henrich Bernardoni</last></author>
      <author><first>Jean-Marc</first><last>Colletta</last></author>
      <author><first>Silvain</first><last>Gerber</last></author>
      <author><first>Frédérique</first><last>Letué</last></author>
      <author><first>Marie-José</first><last>Martinez</last></author>
      <pages>182–190</pages>
      <abstract>L’objectif de cette étude est d’analyser et comparer les productions langagières dans leur multimodalité de 10 personnes atteintes de la maladie d’Alzheimer (MA) appariées à 10 contrôles. Différentes mesures aux niveaux segmental et suprasegmental – erreurs, pauses et allongements vocaliques – ont été réalisées dans une tâche de répétition avec ou sans gestes imposés pour caractériser une disfluence, typique de la MA, puis observées en lien avec les gestes manuels produits. Les résultats montrent la diminution significative de la fluence chez les personnes atteintes de la MA, avec davantage d’erreurs produites au niveau lexical par le groupe Patient et au niveau phonétique par les patients au stade modéré de la maladie, ainsi que de nombreuses pauses silencieuses précédant ou suivant souvent les erreurs produites au niveau segmental. De plus, dans la tâche avec gestes imposés, la répétition de ceux-ci a impacté la fluence des groupes Contrôle et Patient avec une augmentation significative des disfluences au niveau suprasegmental et des erreurs phonétiques au niveau segmental.</abstract>
      <url hash="8e91df5f">2016.jeptalnrecital-jep.21</url>
    </paper>
    <paper id="22">
      <title>Disfluences normales vs. Disfluences sévères : une étude acoustique (Normal disfluences vs)</title>
      <language>fra</language>
      <author><first>Ivana</first><last>Didirkova</last></author>
      <author><first>Camille</first><last>Fauth</last></author>
      <author><first>Fabrice</first><last>Hirsch</last></author>
      <author><first>Giancarlo</first><last>Luxardo</last></author>
      <author><first>Sascha</first><last>Diwersy</last></author>
      <pages>191–199</pages>
      <abstract>L’objectif de cette recherche est d’étudier les caractéristiques acoustiques et perceptives des disfluences normales et sévères. Pour ce faire, un jury d’auditeurs experts a relevé les disfluences sévères et normales de 4 locuteurs qui bégaient ainsi que les accidents de parole de 4 sujets normofluents. Une analyse acoustique portant sur des paramètres tels que la durée de la disfluence, le nombre de disfluences ou encore sur la présence d’éléments prosodiques particuliers a été menée sur les seules disfluences ayant été relevés par l’ensemble du jury. Nos résultats montrent que si les prolongations et les répétitions sont bien évidemment catégorisées comme sévères respectivement en fonction de leur durée et du nombre d’éléments réitérés, d’autres paramètres sont également significatifs, tels que la présence ou non d’une tension audible, le type d’éléments répétés ou encore le fait que la syllabe soit ou non clivée.</abstract>
      <url hash="84d56d70">2016.jeptalnrecital-jep.22</url>
    </paper>
    <paper id="23">
      <title>La distinction entre les paraphasies phonétiques et phonologiques dans l’aphasie : Etude de cas de deux patients aphasiques (The distinction between phonetic and phonological paraphasias in aphasia: A multiple casestudy of aphasic patients)</title>
      <language>fra</language>
      <author><first>Clémence</first><last>Verhaegen</last></author>
      <author><first>Véronique</first><last>Delvaux</last></author>
      <author><first>Kathy</first><last>Huet</last></author>
      <author><first>Fagniart</first><last>Sophie</last></author>
      <author><first>Myriam</first><last>Piccaluga</last></author>
      <author><first>Bernard</first><last>Harmegnies</last></author>
      <pages>200–210</pages>
      <abstract>La spécificité phonologique ou phonétique des erreurs de production orale observées chez les patients aphasiques reste débattue. Cependant, la distinction entre ces deux types d’erreurs est fréquemment basée sur des analyses perceptives qui peuvent être influencées par le système perceptif de l’expérimentateur. Afin de pallier ce biais, nous avons réalisé des analyses acoustiques des productions de deux patients aphasiques, dans une tâche de répétition de non-mots. Nous nous sommes centrés sur l’analyse de consonnes occlusives. Les résultats ont montré la présence de difficultés de gestion du voisement chez les deux patients, indiquant la présence de troubles phonétiques. En outre, les résultats montrent une grande diversité des manifestations des troubles langagiers des patients ainsi que l’intervention potentielle de stratégies de compensation de leurs difficultés. L’intérêt de procéder à des analyses acoustiques précises utilisant des indices multiples est discuté.</abstract>
      <url hash="d6d71199">2016.jeptalnrecital-jep.23</url>
    </paper>
    <paper id="24">
      <title>Dynamique phonétique et contrôle moteur dans la maladie de <fixed-case>P</fixed-case>arkinson: analyse du contrôle de la production des glides (Speech dynamics and motion control in people with <fixed-case>P</fixed-case>arkinson’s disease: analysis of glides’ production)</title>
      <language>fra</language>
      <author><first>Virginie</first><last>Roland</last></author>
      <author><first>Véronique</first><last>Delvaux</last></author>
      <author><first>Kathy</first><last>Huet</last></author>
      <author><first>Myriam</first><last>Piccaluga</last></author>
      <author><first>Marie-Claire</first><last>Haelewyck</last></author>
      <author><first>Bernard</first><last>Harmegnies</last></author>
      <pages>211–219</pages>
      <abstract>Nous nous interrogeons quant à la possibilité d’identifier les difficultés de contrôle du mouvement chez les personnes atteintes de la maladie de Parkinson (MP) à partir de l’étude de leurs comportements dans la production de sons de parole nécessitant des mouvements continus des articulateurs supralaryngés (logatomes VCV, où C est un glide). Notre hypothèse est que les parkinsoniens présentent des modifications dans leur dynamique de mouvement par rapport à des personnes sans pathologie lors de la production. A cette fin, sont étudiés des sons de parole recueillis hors contexte communicationnel auprès de neuf personnes porteuses de la MP et de dix sujets sains. Les analyses révèlent des différences entre les deux groupes, notamment en ce qui concerne l’espace articulatoire, l’amplitude des mouvements et leur localisation dans le plan F 1-F2. On note par ailleurs qu’un point-cible est préservé lors de l’émission de logatomes : le centre du glide.</abstract>
      <url hash="c8aaa297">2016.jeptalnrecital-jep.24</url>
    </paper>
    <paper id="25">
      <title>Dénomination d’image versus détection interne de phonème : deux méthodes pour étudier la planification de la production de parole (Picture naming versus internal phoneme monitoring: two methods for exploring speech production planning)</title>
      <language>fra</language>
      <author><first>Pierre</first><last>Hallé</last></author>
      <author><first>Laura</first><last>Manoiloff</last></author>
      <author><first>Juan</first><last>Segui</last></author>
      <pages>220–228</pages>
      <abstract>Cette étude est motivée initialement par une question méthodologique : la validité des mesures de temps de dénomination d’image, très utilisés pour explorer les processus de planification de production de parole. Le temps de dénomination est le temps écoulé entre affichage de l’image et début acoustique de la réponse verbale. Dans cet article, nous résumons la littérature sur les inconvénients de cette mesure. Nous présentons ensuite notre étude, qui compare directement temps de dénomination d’image et temps de détection interne de phonème initial. Les participants sont hispanophones. Les noms d’image sont contrastés en fréquence lexicale et phonème initial. Les temps de réponse pour les deux mesures sont assez proches. Cependant, ceux de détection de phonème sont relativement insensibles au type de phonème initial, contrairement aux temps de dénomination. Au delà de l’avantage méthodologique de la détection interne de phonème, nos données suggèrent que celle-ci opère sur des représentations relativement abstraites.</abstract>
      <url hash="9f9214fe">2016.jeptalnrecital-jep.25</url>
    </paper>
    <paper id="26">
      <title>Détection automatique d’anomalies sur deux styles de parole dysarthrique: parole lue vs spontanée (Automatic anomaly detection for dysarthria across two speech styles : read vs spontaneous speech)</title>
      <language>fra</language>
      <author><first>Imed</first><last>Laaridh</last></author>
      <author><first>Corinne</first><last>Fredouille</last></author>
      <author><first>Meunier</first><last>Christine</last></author>
      <pages>229–237</pages>
      <abstract>L’évaluation perceptive de la parole pathologique reste le standard dans la pratique clinique pour le diagnostic et le suivi des patients. De telles méthodes incluent plusieurs tâches telles que la lecture, la parole spontanée, le chant, les mots isolés, la voyelle tenue, etc. Dans ce contexte, les outils de traitement automatique de la parole ont montré leur pertinence dans l’évaluation de la qualité de parole ainsi que dans le cadre de la communication améliorée et alternative (CAA) pour les patients atteints de troubles de parole. Cependant, peu de travaux ont étudié l’utilisation de ces outils sur la parole spontanée. Ce papier examine le comportement d’un système de détection automatique d’anomalies au niveau phonème face à la parole dysarthrique lue et spontanée. Le comportement du système révèle une variabilité inter-pathologique à travers les styles de parole.</abstract>
      <url hash="13de1368">2016.jeptalnrecital-jep.26</url>
    </paper>
    <paper id="27">
      <title>Effet de l’input auditif sur la production de voyelles orales : étude acoustique chez des enfants normo-entendants et des enfants porteurs d’implants cochléaires âgés de 5 à 11 ans (Effect of audio input on vowel production: an acoustic study in 5- to 11-year old normalhearing and cochlear implanted children)</title>
      <language>fra</language>
      <author><first>Benedicte</first><last>Grandon</last></author>
      <author><first>Anne</first><last>Vilain</last></author>
      <pages>238–246</pages>
      <abstract>Treize enfants porteurs d’implants cochléaires (CI) et vingt enfants normo-entendants (NH) ont été enregistrés dans deux conditions : répétition de mots avec un modèle audio et production des mêmes mots sans modèle audio. Notre but était d’étudier l’effet de l’input audio sur la hauteur, l’antériorité et la dispersion des dix voyelles orales du français chez ces deux populations d’enfants. Les résultats de notre étude acoustique indiquent que : (1) l’input immédiat n’influence que la hauteur du /a/ chez les enfants NH, (2) les enfants CI produisent des voyelles /y/, /ø/, /œ/ plus postérieures que les enfants NH mais que cette différence diminue à mesure que la durée d’utilisation de l’implant augmente, et (3) la dispersion de /y/, /ø/, /œ/ est plus grande chez les enfants CI que chez les enfants NH.</abstract>
      <url hash="233d8ce6">2016.jeptalnrecital-jep.27</url>
    </paper>
    <paper id="28">
      <title>Effet de la fréquence d’usage sur l’élision du schwa des clitiques : étude d’un corpus d’interactions naturelles (Frequency effect on schwa elision in clitics: a corpus based study)</title>
      <language>fra</language>
      <author><first>Loïc</first><last>Liégeois</last></author>
      <pages>247–255</pages>
      <abstract>Cette étude s’intéresse à l’influence d’un facteur d’usage, à savoir la fréquence des formes, sur la (non) production des schwas des clitiques. Dans cet objectif, nous nous appuyons sur un corpus d’interactions entre adultes recueillies en situation naturelle : les enregistrements, réalisés au domicile de nos six sujets, ont été récoltés au cours de scènes de vie quotidienne. Les données présentées au cours de nos analyses corroborent les résultats exposés dans de précédents travaux au sujet des schwas initiaux de polysyllabes. En effet, il s’avère que la fréquence d’emploi des collocations “Clitique + X” a un effet significatif sur les taux d’élision relevés dans les productions de nos sujets.</abstract>
      <url hash="b8734283">2016.jeptalnrecital-jep.28</url>
    </paper>
    <paper id="29">
      <title>Effort produit et ressenti selon le voisement en français (Produced and perceived effort according to the voicing in <fixed-case>F</fixed-case>rench)</title>
      <language>fra</language>
      <author><first>Camille</first><last>Robieux</last></author>
      <author><first>Thierry</first><last>Legou</last></author>
      <author><first>Yohann</first><last>Meynadier</last></author>
      <author><first>Meunier</first><last>Christine</last></author>
      <pages>256–264</pages>
      <abstract>Les muscles laryngés et articulatoires sont impliqués dans la réalisation des traits qui distinguent les phonèmes. Cette étude porte sur l’auto-perception par les locuteurs et la répartition de l’effort vocal et articulatoire en fonction du trait de voisement en parole modale comparée à la parole chuchotée en français. Pour les 12 obstruantes du français, l’effort est ressenti plus important pour les voisées que les non voisées correspondantes, excepté dans le cas des fricatives labiodentales. Les analyses de la production des occlusives bilabiales montrent que l’effort laryngé est supérieur pour les consonnes voisées et l’effort articulatoire supérieur pour les non voisées, mais l’inverse pour les fricatives. Ces résultats indiquent que l’effort ressenti lors de sa propre production repose sur une perception prédominante de l’effort laryngé sur l’effort articulatoire en voix modale comme en voix chuchotée ; mais qu’il est cependant modulé selon le lieu et le mode d’articulation des consonnes.</abstract>
      <url hash="42b0cfc5">2016.jeptalnrecital-jep.29</url>
    </paper>
    <paper id="30">
      <title>Entraînements à la prosodie des questions ouvertes et fermées de l’anglais chez des apprenants francophones (Prosodic training for <fixed-case>F</fixed-case>rench students of <fixed-case>E</fixed-case>nglish on Wh- and yes-no questions)</title>
      <language>fra</language>
      <author><first>Anne</first><last>Guyot-Talbot</last></author>
      <author><first>Karin</first><last>Heidlmayr</last></author>
      <author><first>Emmanuel</first><last>Ferragne</last></author>
      <pages>265–273</pages>
      <abstract>Des étudiants en anglais étaient invités à lire trois types de phrases : assertions, questions fermées et ouvertes. Ils étaient ensuite soumis à 3 sessions d’entraînements où ils devaient répéter des phrases interrogatives prononcées par une anglophone. Après chaque phrase, leur contour de F0 sur la syllabe portant le noyau intonatif ainsi que celui de la locutrice anglaise étaient affichés à l’écran. Ces sessions devaient leur permettre d’inférer une règle du système intonatif de l’anglais qui induit, par défaut, un contour montant pour les questions fermées et un contour descendant pour les questions ouvertes. Puis, une nouvelle séance d’enregistrements permettait de collecter des phrases à comparer au pré-test pour juger l’efficacité de l’entraînement. Les résultats montrent une réduction significative de la distance entre les contours mélodiques des apprenants du groupe test et ceux de la locutrice modèle entre pré-test et post-test, ce qui suggère un effet bénéfique de nos entraînements.</abstract>
      <url hash="e788eeb2">2016.jeptalnrecital-jep.30</url>
    </paper>
    <paper id="31">
      <title>Estimation de la qualité d’un système de reconnaissance de la parole pour une tâche de compréhension (Quality estimation of a Speech Recognition System for a Spoken Language Understanding task)</title>
      <language>fra</language>
      <author><first>Olivier</first><last>Galibert</last></author>
      <author><first>Nathalie</first><last>Camelin</last></author>
      <author><first>Paul</first><last>Deléglise</last></author>
      <author><first>Sophie</first><last>Rosset</last></author>
      <pages>274–282</pages>
      <abstract>Nous nous intéressons à l’évaluation de la qualité des systèmes de reconnaissance de la parole étant donné une tâche de compréhension. L’objectif de ce travail est de fournir un outil permettant la sélection d’un système de reconnaissance automatique de la parole le plus adapté pour un système de dialogue donné. Nous comparons ici différentes métriques, notamment le WER, NE-WER et ATENE métrique proposée récemment pour l’évaluation des systèmes de reconnaissance de la parole étant donné une tâche de reconnaissance d’entités nommées. Cette dernière métrique montrait une meilleure corrélation avec les résultats de la tâche globale que toutes les autres métriques testées. Nos mesures indiquent une très forte corrélation avec la mesure ATENE et une moins forte avec le WER.</abstract>
      <url hash="a8d1c498">2016.jeptalnrecital-jep.31</url>
    </paper>
    <paper id="32">
      <title>Etude acoustique du discours politique d’hispanophones : le cas de Hugo Chávez et de José Zapatero (Politicians’ speech styles can be distinguished thanks to their prosodic realizations)</title>
      <language>fra</language>
      <author><first>Carmen Patricia</first><last>Pérez</last></author>
      <pages>283–291</pages>
      <abstract>Les styles de discours des hommes politiques peuvent être identifiés grâce à leurs réalisations prosodiques. On peut reconnaître un homme politique ‘révolutionnaire’ ou ‘traditionnel’ en écoutant quelques minutes de discours. Je me propose de montrer quels sont les paramètres prosodiques pertinents dans cette distinction en comparant les phonostyles de Hugo Chávez et José Zapatero. Je présente également le changement de phonostyle de Chávez dans deux situations différentes (c.-àd. deux phono-genres), en interview et en public. Le modèle de Ph. Martin Contraste de Pente Mélodique est utilisé pour décrire la structure prosodique. Les analyses acoustiques montrent que les phonostyles de ces personnalités se différencient, dans le même phono-genre, dans la réalisation des contours de continuation, l’étendue du registre et le débit, alors que la construction des groupes intonatifs est semblable. Une brève étude sur les imitateurs de Chávez et de Zapatero est rajoutée pour montrer qu’ils reproduisent avec efficacité les paramètres acoustiques pertinents de ces leaders.</abstract>
      <url hash="54daa1fc">2016.jeptalnrecital-jep.32</url>
    </paper>
    <paper id="33">
      <title>Etude acoustique et représentation phonologique sur /ə˞/ suffixe rhotique en mandarin (Acoustic study and phonological representation of the rhotic suffix /ə˞/ in mandarin)</title>
      <language>fra</language>
      <author><first>Anqi</first><last>Liu</last></author>
      <pages>292–300</pages>
      <abstract>Historiquement, le suffixe /ə˞/ est un suffixe diminutif correspondant au mot 儿 (&lt;er&gt; en pinyin) qui signifie ”petitesse”. Il relève d’une particularité du style plutôt que de la grammaire. Il apparait souvent dans la parole des locuteurs du nord de la Chine. Pour mieux comprendre le phénomène et son comportement phonologique, on présente les résultats d’une étude acoustique qui vérifie les effets de la rhoticité sur les voyelles adjacentes. Sur la base de ces résultats, on propose une représentation gestuelle du suffixe et des processus qui l’impliquent dans le cadre de la phonologie articulatoire (Browman &amp; Goldstein1992).</abstract>
      <url hash="0fa59740">2016.jeptalnrecital-jep.33</url>
    </paper>
    <paper id="34">
      <title>Étude de la contribution acoustique de la structure formantique à la perception du ton chuchoté (A study of the acoustic contri bution of formant structure to tone i dentificati on in whis pered speech)</title>
      <language>fra</language>
      <author><first>Zhang</first><last>Xuelu</last></author>
      <author><first>Rudolph</first><last>Sock</last></author>
      <pages>301–309</pages>
      <abstract>Cette étude examine la contribution de la structure formantique du segment vocalique à l’identification du ton que ce segment porte, et cela en voix chuchotée. Le mandarin a été choisi en tant que langue cible parce que les traits tonals (tone features) en mandarin s’appuient acoustiquement sur deux dimensions : le registre et le contour. Nous supposons qu’en l’absence d e F0, la structure formantique subirait néanmo ins une modification, en fonction du ton et fournirait des indices acoustiques des traits tonals à l’auditeur. Nous nous intéressons aux rapports entre les deux dimensions de traits tonals et à la modification de la structure formantique. À travers l’analyse des données acoustiques issues de 13 sujets locutrices, nous avons observé une divergence d’importance dans les intervalles F2-F3 et F3-F4, en fonction du ton. Cette divergence semble liée aux contrastes tonals en registre et non au x contours mélodiques. Cette d istinction semble dépendre d’ailleurs de la nature de voyelle.</abstract>
      <url hash="aed95a0a">2016.jeptalnrecital-jep.34</url>
    </paper>
    <paper id="35">
      <title>Étude de la qualité vocale post-thyroïdectomie chez des patients souffrants ou non de paralysie récurrentielle (A post-thyroidectomy voice quality study in patients suffering or not from laryngeal paralysis)</title>
      <language>fra</language>
      <author><first>Ming</first><last>Xiu</last></author>
      <author><first>Camille</first><last>Fauth</last></author>
      <author><first>Béatrice</first><last>Vaxelaire</last></author>
      <author><first>Jean-François</first><last>Rodier</last></author>
      <author><first>Pierre-Philippe</first><last>Volkmar</last></author>
      <author><first>Rudolph</first><last>Sock</last></author>
      <pages>310–318</pages>
      <abstract>L’objet principal de cette étude est la qualité vocale après une thyroïdectomie. Cette opération provoque souvent une dégradation de la qualité vocale de façon permanente ou temporaire. La qualité vocale sera étudiée à l’aide d’indices aérodynamiques et acoustiques. Deux groupes de patients sont suivis et étudiés : un premier groupe de patients pour lesquels l’examen post-opératoire a révélé un défaut de mobilité de l’un des plis vocaux ; Un second groupe de patients pour lesquels l’examen post-opératoire n’a pas révélé de perturbation de la mobilité laryngée. Il s’agit d’une étude longitudinale dans laquelle la référence est constituée par la voix du locuteur en préopératoire. Les résultats préliminaires indiquent que l’ablation de la glande thyroïde modifie la voix des patients alors même que la mobilité laryngée est préservée. Tous les paramètres étudiés ont été modifiés. Le temps a toutefois un effet positif pour tous les locuteurs suivis, puisque leurs productions s’approchent, un mois après l’opération, des valeurs mesurées en préopératoire.</abstract>
      <url hash="14d672ef">2016.jeptalnrecital-jep.35</url>
    </paper>
    <paper id="36">
      <title>Etude par <fixed-case>EMA</fixed-case> des mouvements de la mâchoire inférieure durant les consonnes de l’arabe marocain (<fixed-case>EMA</fixed-case> study of jaw movements during <fixed-case>M</fixed-case>oroccan <fixed-case>A</fixed-case>rabic consonants)</title>
      <language>fra</language>
      <author><first>Chakir</first><last>Zeroual</last></author>
      <author><first>Philip</first><last>Hoole</last></author>
      <author><first>Adamantios</first><last>Gafos</last></author>
      <pages>319–327</pages>
      <abstract>Cette étude est basée sur des données obtenues à l’aide d’EMA (AG500) enregistrant les mouvements de la mâchoire inférieure (Minf) durant les consonnes labiales, coronales, vélaires, uvulaires, pharyngales et laryngales de l’arabe marocain dans les contextes aCa et iCi. Nous avons montré que l’implication de la Minf est cruciale durant /s S t T/ (S T : consonnes emphatiques). Le recul de la racine de la langue n’est pas nécessairement corrélé à la baisse de la Minf. Les consonnes apicales ne sont pas toujours associées à l’abaissement de la Minf. La Minf ne semble pas impliquée durant les laryngales et les pharyngales, ce qui est en accord avec les déductions de Goldstein (1995). Les mouvements verticaux et horizontaux de la Minf sont relativement indépendants.</abstract>
      <url hash="9b10791f">2016.jeptalnrecital-jep.36</url>
    </paper>
    <paper id="37">
      <title>Étude transversale du rythme de l’anglais chez des apprenants francophones (A cross-sectional study of rhythm in <fixed-case>F</fixed-case>rench students of <fixed-case>E</fixed-case>nglish)</title>
      <language>fra</language>
      <author><first>Quentin</first><last>Michardière</last></author>
      <author><first>Anne</first><last>Guyot-Talbot</last></author>
      <author><first>Emmanuel</first><last>Ferragne</last></author>
      <author><first>François</first><last>Pellegrino</last></author>
      <pages>328–336</pages>
      <abstract>Dans cette étude, nous avons demandé à 3 groupes d’étudiants en anglais (niveaux L1, L2 et L3) de lire un dialogue en anglais afin d’évaluer la possibilité d’une amélioration de leur production sur le plan du rythme en fonction de leur niveau universitaire. Le dialogue a également été lu par des anglophones, et une traduction du dialogue en français a été enregistrée par des francophones dans le but d’établir un espace de référence pour l’anglais L1 et le français L1. Nous avons employé des mesures classiques du rythme s’appuyant sur la durée, et avons également exploré la pertinence de mesures basées sur l’enveloppe d’amplitude et le spectre de cette enveloppe. Nous constatons un manque de fiabilité des mesures classiques du rythme, et proposons quelques pistes.</abstract>
      <url hash="2d625bf0">2016.jeptalnrecital-jep.37</url>
    </paper>
    <paper id="38">
      <title>Exploration de paramètres acoustiques dérivés de <fixed-case>GMM</fixed-case> pour l’adaptation non supervisée de modèles acoustiques à base de réseaux de neurones profonds (Exploring <fixed-case>GMM</fixed-case>-derived features for unsupervised adaptation of deep neural network acoustic models)</title>
      <language>fra</language>
      <author><first>Natalia</first><last>Tomashenko</last></author>
      <author><first>Yuri</first><last>Khokhlov</last></author>
      <author><first>Anthony</first><last>Larcher</last></author>
      <author><first>Yannick</first><last>Estève</last></author>
      <pages>337–345</pages>
      <abstract>L’étude présentée dans cet article améliore une méthode récemment proposée pour l’adaptation de modèles acoustiques markoviens couplés à un réseau de neurones profond (DNN-HMM). Cette méthode d’adaptation utilise des paramètres acoustiques dérivés de mixtures de modèles Gaussiens (GMM-derived features, GMMD ). L’amélioration provient de l’emploi de scores et de mesures de confiance calculés à partir de graphes construits dans le cadre d’un algorithme d’adaptation conventionnel dit de maximum a posteriori (MAP). Une version modifiée de l’adaptation MAP est appliquée sur le modèle GMM auxiliaire utilisé dans une procédure d’apprentissage adaptatif au locuteur (speaker adaptative training, SAT) lors de l’apprentissage du DNN. Des expériences menées sur le corpus Wall Street Journal (WSJ0) montrent que la technique d’adaptation non supervisée proposée dans cet article permet une réduction relative de 8, 4% du taux d’erreurs sur les mots (WER), par rapport aux résultats obtenus avec des modèles DNN-HMM indépendants du locuteur utilisant des paramètres acoustiques plus conventionnels.</abstract>
      <url hash="c2559ea9">2016.jeptalnrecital-jep.38</url>
    </paper>
    <paper id="39">
      <title>Extraction automatique de contour de lèvre à partir du modèle <fixed-case>CLNF</fixed-case> (Automatic lip contour extraction using <fixed-case>CLNF</fixed-case> model)</title>
      <language>fra</language>
      <author><first>Li</first><last>Liu</last></author>
      <author><first>Gang</first><last>Feng</last></author>
      <author><first>Denis</first><last>Beautemps</last></author>
      <pages>346–354</pages>
      <abstract>Dans cet article nous proposons une nouvelle solution pour extraire le contour interne des lèvres d’un locuteur sans utiliser d’artifices. La méthode s’appuie sur un algorithme récent d’extraction du contour de visage développé en vision par ordinateur, CLNF pour Constrained Local Neural Field. Cet algorithme fournit en particulier 8 points caractéristiques délimitant le contour interne des lèvres. Appliqué directement à nos données audio-visuelles du locuteur, le CLNF donne de très bons résultats dans environ 70% des cas. Des erreurs subsistent cependant pour le reste des cas. Nous proposons des solutions pour estimer un contour raisonnable des lèvres à partir des points fournis par CLNF utilisant l’interpolation par spline permettant de corriger ses erreurs et d’extraire correctement les paramètres labiaux classiques. Les évaluations sur une base de données de 179 images confirment les performances de notre algorithme.</abstract>
      <url hash="fa79e50c">2016.jeptalnrecital-jep.39</url>
    </paper>
    <paper id="40">
      <title><fixed-case>FN</fixed-case>5, un modèle psycholinguistique informatique de la reconnaissance des mots parlés chez l’auditeur français, mis à la disposition des chercheurs et enseignants (<fixed-case>FN</fixed-case>5, a computational psycholinguistic model of spoken word recognition in <fixed-case>F</fixed-case>rench, made available to researchers and teachers)</title>
      <language>fra</language>
      <author><first>Nicolas</first><last>Léwy</last></author>
      <pages>355–363</pages>
      <abstract>Voici un modèle psycholinguistique informatique pour le français. Il s’appelle FN5 et simule la reconnaissance humaine de mots parlés, présentés seuls (déterminant, adjectif antéposé, substantif) ou en suites de deux mots (déterminant et substantif, adjectif antéposé et substantif). Le modèle contient un lexique de 17 668 mots et cela dans deux versions, française et Suisse romande. Grâce à une architecture connexionniste localiste à trois niveaux (traits distinctifs, phonèmes, mots) qui est enrichie de plusieurs innovations clés (processeur de position, groupements de connexions, et point d’isolation), le modèle peut reconnaître la plupart des mots et des suites qu’on lui présente (taux de succès entre 83.6% et 99.7%), et en plus, il est capable de reproduire un grand nombre d’effets trouvés lors d’études expérimentales (ex. fréquence, longueur, effacement du schwa, liaison, etc.). Le modèle, qui possède une interface graphique, est téléchargeable, et utilisable à la fois pour la recherche et pour l’enseignement.</abstract>
      <url hash="b92f7e45">2016.jeptalnrecital-jep.40</url>
    </paper>
    <paper id="41">
      <title>Fusion d’espaces de représentations multimodaux pour la reconnaissance du rôle du locuteur dans des documents télévisuels (Multimodal embedding fusion for robust speaker role recognition in video broadcast )</title>
      <language>fra</language>
      <author><first>Sebastien</first><last>Delecraz</last></author>
      <author><first>Frederic</first><last>Bechet</last></author>
      <author><first>Benoit</first><last>Favre</last></author>
      <author><first>Mickael</first><last>Rouvier</last></author>
      <pages>364–372</pages>
      <abstract>L’identification du rôle d’un locuteur dans des émissions de télévision est un problème de classification de personne selon une liste de rôles comme présentateur, journaliste, invité, etc. À cause de la nonsynchronie entre les modalités, ainsi que par le manque de corpus de vidéos annotées dans toutes les modalités, seulement une des modalités est souvent utilisée. Nous présentons dans cet article une fusion multimodale des espaces de représentations de l’audio, du texte et de l’image pour la reconnaissance du rôle du locuteur pour des données asynchrones. Les espaces de représentations monomodaux sont entraînés sur des corpus de données exogènes puis ajustés en utilisant des réseaux de neurones profonds sur un corpus d’émissions françaises pour notre tâche de classification. Les expériences réalisées sur le corpus de données REPERE ont mis en évidence les gains d’une fusion au niveau des espaces de représentations par rapport aux méthodes de fusion tardive standard.</abstract>
      <url hash="94c65595">2016.jeptalnrecital-jep.41</url>
    </paper>
    <paper id="42">
      <title>L’impact des variations temporelles intrinsèques et extrinsèques de la voyelle sur la relation consonne-voyelle : Étude translinguistique sur l’arabe jordanien et le français (The impact of extrinsic and intrisic vowel temporal variations on the consonant-vowel relationship : A trans-linguistic investigation on Jordanian arabic and <fixed-case>F</fixed-case>rench)</title>
      <language>fra</language>
      <author><first>Mohammad</first><last>Abuoudeh</last></author>
      <author><first>Olivier</first><last>Crouzet</last></author>
      <pages>373–381</pages>
      <abstract>Cette étude permet d’explorer les variations spectrales engendrées par deux types de variations temporelles qui résultent respectivement de l’opposition de longueur vocalique et des variations de débit de parole. Deux protocoles expérimentaux ont été conçus, l’un en arabe jordanien et l’autre en français, pour examiner ce phénomène. Un intérêt particulier a été porté aux occlusives produites dans des séquences CVC dans le but d’étudier la consonne en position initiale et la coarticulation anticipatoire. La durée des voyelles et la fréquence des trois premiers formants au début et au milieu de chaque séquence ont été mesurées dans chaque condition de longueur / débit. Les équations de locus ont été utilisées afin de décrire la relation CV quand elle subit ces deux types de variations. Selon les résultats, la qualité de la voyelle et de la consonne est influencée dans l’opposition de durée et dans le débit de parole. Ce changement généré par les variations temporelles est détecté à l’aide des équations de locus. Ces dernières révèlent qu’il existe un chevauchement coarticulatoire plus important quand la durée de la voyelle décroît.</abstract>
      <url hash="5a9787e5">2016.jeptalnrecital-jep.42</url>
    </paper>
    <paper id="43">
      <title>Incidence de la chirurgie naso-sinusienne sur la qualité vocale : étude d’un cas clinique (Impact of Sinus Surgery on Voice Quality: Case Study)</title>
      <language>fra</language>
      <author><first>Lise Crevier</first><last>Buchman</last></author>
      <author><first>Angelique</first><last>Amelot</last></author>
      <author><first>Benedicte</first><last>Mas</last></author>
      <author><first>Mathilde</first><last>Giron</last></author>
      <author><first>Pierre</first><last>Bonfils</last></author>
      <pages>382–391</pages>
      <abstract>Les fosses nasales participent à la résonance vocale et toute modification de ces structures peut altérer la qualité vocale. Le rôle des sinus comme résonateurs dans la production vocale reste plus controversé. Le but de notre étude prospective était d’explorer d’éventuelles modifications acoustiques chez un chanteur professionnel en pré et post-opératoire après chirurgie naso-sinusienne unilatérale. A partir de la lecture d’un texte, nous avons extrait les voyelles /a,i,u/ pour mesurer les paramètres acoustiques de fréquence (F0), des formants F1 et F2, de leur largeur de bande, et de qualité vocale (LTAS et H1*-H2*). L’étude a été complétée par une auto-évaluation de la qualité de voix. Nos résultats n’ont pas permis de mettre en évidence de différence statistiquement significative des paramètres acoustiques bien que le patient ait signalé une impression d’amélioration vocale chantée. Ces résultats pour le français confirment ceux de la littérature et peuvent servir à informer les patients.</abstract>
      <url hash="9f2876b4">2016.jeptalnrecital-jep.43</url>
    </paper>
    <paper id="44">
      <title>Influence de la quantité de données sur une tâche de segmentation de phones fondée sur les réseaux de neurones (Phone-level speech segmentation with neural networks : influence of the amount of data )</title>
      <language>fra</language>
      <author><first>Céline</first><last>Manenti</last></author>
      <author><first>Thomas</first><last>Pellegrini</last></author>
      <author><first>Julien</first><last>Pinquier</last></author>
      <pages>392–400</pages>
      <abstract>Dans cet article, nous décrivons une étude expérimentale de segmentation de parole en unités acoustiques sous-lexicales (phones) à l’aide de réseaux de neurones. Sur le corpus de parole spontanée d’anglais américain BUCKEYE, une F-mesure de 68% a été obtenue à l’aide d’un réseau convolutif, en considérant une marge d’erreur de 10 ms. Cette performance est supérieure à celle d’un annotateur manuel, l’accord inter-annotateurs étant de 62%. Restreindre les données d’apprentissage à celles d’un unique locuteur, 30 minutes environ, a eu pour conséquence moins de 10% de perte et utiliser celles de 5 locuteurs a permis d’atteindre des résultats similaires à utiliser plus de données. Utiliser le modèle entraîné avec le corpus anglais sur un petit corpus d’une langue peu dotée a donné des résultats comparables à estimer un modèle avec des données de cette langue.</abstract>
      <url hash="a7b30229">2016.jeptalnrecital-jep.44</url>
    </paper>
    <paper id="45">
      <title>L’invasivité phonologique dans le traitement des anglicismes : une étude quantitative de trois langues (Phonological invasiveness in the treatment of loanwords)</title>
      <language>fra</language>
      <author><first>Tomáš</first><last>Duběda</last></author>
      <pages>401–409</pages>
      <abstract>Dans la présente étude, nous analysons, dans une perspective typologique, l’adaptation phonologique des anglicismes dans trois langues (français, allemand et tchèque). La classification des formes phonologiques, qui s’appuie sur un système de huit principes d’adaptation, a pour but d’établir le degré d’« invasivité phonologique » propre à chaque langue. L’approximation phonologique (substitution de phonèmes natifs aux phonèmes étrangers) semble être le principe fondamental dans les trois langues analysées, alors que la prononciation orthographique (phonétisation des graphèmes) intervient avant tout en français. La prononciation authentique (imitation phonologique de la langue source) n’est active qu’en allemand. Les mécanismes d’approximation phonologique sont plus invasifs en français que dans les deux autres langues, et ce notamment en ce qui concerne le système vocalique. Globalement, l’invasivité phonologique semble augmenter dans l’ordre allemand – tchèque – français.</abstract>
      <url hash="f4b9f773">2016.jeptalnrecital-jep.45</url>
    </paper>
    <paper id="46">
      <title>Investigation glottographique et laryngoscopique de la transition entre les deux principaux mécanismes laryngés (Glottographic and laryngoscopic investigation of the transition between the two main laryngeal mechanisms)</title>
      <language>fra</language>
      <author><first>Arthur</first><last>Givois</last></author>
      <author><first>Didier</first><last>Demolin</last></author>
      <author><first>Lise</first><last>Crevier-Buchman</last></author>
      <author><first>Angélique</first><last>Amelot</last></author>
      <pages>410–418</pages>
      <abstract>Cet article étudie par une approche descriptive la transition entre le premier et le second mécanisme laryngé. Des mesures électroglottographiques ont été réalisées simultanément à des captures d’images par laryngoscopie sur deux sujets : une femme et un homme. Des différences de comportement entre les deux sujets ont été observées. Un mouvement vertical de grande amplitude du larynx est systématiquement observé au moment de la transition chez le sujet masculin, tandis que des modifications de petite amplitude de la distance entre paroi pharyngale et épiglotte, ou de la compression des plis aryépiglottiques sont remarquées chez le sujet féminin. Ces changements de configurations s’effectuent de façon continue chez cette dernière alors qu’un changement soudain de l’activité des plis vocaux a lieu à un instant précisément localisé pour les productions des deux sujets. Ces différences d’ajustements laryngés sont liées à des modifications des paramètres mécaniques dont dépendent la fréquence fondamentale et qui restent à estimer.</abstract>
      <url hash="58b0aff8">2016.jeptalnrecital-jep.46</url>
    </paper>
    <paper id="47">
      <title>Modélisation bayésienne de la planification motrice des gestes de parole: Évaluation du rôle des différentes modalités sensorielles (<fixed-case>B</fixed-case>ayesian modeling of speech gesture motor planning: Evaluating the role of different sensory modalities )</title>
      <language>fra</language>
      <author><first>Jean-François</first><last>Patri</last></author>
      <author><first>Julien</first><last>Diard</last></author>
      <author><first>Pascal</first><last>Perrier</last></author>
      <pages>419–427</pages>
      <abstract>La prise en compte des informations auditives et proprioceptives dans le contrôle de la parole est mise en évidence par un nombre croissant de résultats expérimentaux. Cependant, les modèles de production imposent le plus souvent l’une ou l’autre des modalités, ou n’offrent pas de cadre formel pour évaluer leurs contributions respectives. Nous proposons d’explorer le rôle de ces modalités sensorielles dans la planification des gestes de parole à partir d’un modèle bayésien représentant la structure des connaissances mises en jeu dans cette tâche. Le modèle permet d’envisager trois mécanismes de planification, reposant sur la modalité auditive, proprioceptive ou sur les deux conjointement. Nous comparons des simulations obtenues par les deux premiers mécanismes de planification. Les résultats indiquent des réalisations articulatoires différentes mais donnant néanmoins des réalisations auditives qualitativement similaires dans leur variabilité.</abstract>
      <url hash="3eb33b86">2016.jeptalnrecital-jep.47</url>
    </paper>
    <paper id="48">
      <title>Une méthode d’évaluation de la compréhension orale par choix d’image : application à de la parole dégradée par simulation de la presbyacousie (A method for assessing listening comprehension using image selection : application to speech degraded by presbycusis simulation)</title>
      <language>fra</language>
      <author><first>Cynthia</first><last>Magnen</last></author>
      <author><first>Julien</first><last>Tardieu</last></author>
      <author><first>Lionel</first><last>Fontan</last></author>
      <author><first>Pascal</first><last>Gaillard</last></author>
      <author><first>Nathalie</first><last>Spanghero-Gaillard</last></author>
      <pages>428–436</pages>
      <abstract>Nous présentons une méthode permettant d’évaluer la compréhension de la parole dégradée par simulation des effets de la presbyacousie, dans le calme et dans le bruit. Cette méthode intègre des phrases signifiantes et implique pour l’auditeur de sélectionner, parmi un ensemble de quatre images, celle qui correspond à l’énoncé qu’il entend. Le test présente de nombreux avantages méthodologiques comme l’immédiateté du score et le fait qu’il ne nécessite pas de faire répéter la phrase entendue. Les résultats obtenus montrent un effet significatif de la dégradation et du bruit du fond. La cohérence de ces effets avec les études précédentes sur la presbyacousie permet de valider cette méthode. Par ailleurs, la nature exacte du score mesuré dans ce test est discutée en le comparant avec le score d’intelligibilité obtenu par répétition d’items dans une précédente étude.</abstract>
      <url hash="8d604c21">2016.jeptalnrecital-jep.48</url>
    </paper>
    <paper id="49">
      <title>Optimiser l’adaptation en ligne d’un module de compréhension de la parole avec un algorithme de bandit contre un adversaire (Adversarial bandit for optimising online active learning of spoken language understanding)</title>
      <language>fra</language>
      <author><first>Emmanuel</first><last>Ferreira</last></author>
      <author><first>Alexandre</first><last>Reiffers-Masson</last></author>
      <author><first>Bassam</first><last>Jabaian</last></author>
      <author><first>Fabrice</first><last>Lefèvre</last></author>
      <pages>437–445</pages>
      <abstract>De nombreux modules de compréhension de la parole ont en commun d’être probabilistes et basés sur des algorithmes d’apprentissage automatique. Deux difficultés majeures, rencontrées par toutes les méthodes existantes sont : le coût de la collecte des données et l’adaptation d’un module existant à un nouveau domaine. Dans cet article, nous proposons un processus d’adaptation en ligne avec une politique apprise en utilisant un algorithme de type bandit contre un adversaire. Nous montrons que cette proposition peut permettre d’optimiser un équilibre entre le coût de la collecte des retours demandés aux utilisateurs et la performance globale de la compréhension du langage parlé après sa mise à jour.</abstract>
      <url hash="a808f821">2016.jeptalnrecital-jep.49</url>
    </paper>
    <paper id="50">
      <title>Patrons Rythmiques et Genres Littéraires en Synthèse de la Parole (How to improve rhythmic patterns according to literary genre in synthesized speech ⇤ )</title>
      <language>fra</language>
      <author><first>Elisabeth</first><last>Delais-Roussarie</last></author>
      <author><first>Damien</first><last>Lolive</last></author>
      <author><first>Hiyon</first><last>Yoo</last></author>
      <author><first>David</first><last>Guennec</last></author>
      <pages>446–454</pages>
      <abstract>Ces vingt dernières années, la qualité de la parole synthétique s’est améliorée grâce notamment à l’émergence de nouvelles techniques comme la synthèse par corpus. Mais les patrons rythmiques obtenus ne sont pas toujours perçus comme très naturels. Dans ce papier, nous comparons les patrons rythmiques observés en parole naturelle et synthétique pour trois genres littéraires. Le but de ce travail est d’étudier comment le rythme pourrait être amélioré en synthèse de parole. La comparaison des patrons rythmiques est réalisée grâce à une analyse de la durée relativement à la structure prosodique, les données audio provenant de six comptines, quatre poèmes et deux extraits de conte. Les résultats obtenus laissent penser que les différences rythmiques entre parole naturelle et synthétique sont principalement dues au marquage de la structure prosodique, particulièrement au niveau des groupes intonatifs. De fait, le taux d’allongement des syllabes accentuées en fin de groupes intonatifs est beaucoup plus important en synthèse que dans la parole naturelle.</abstract>
      <url hash="34e5e351">2016.jeptalnrecital-jep.50</url>
    </paper>
    <paper id="51">
      <title>Une pénalité floue fondée phonologiquement pour améliorer la Sélection d’Unité (A Phonologically Motivated Penalty To Improve Unit Selection)</title>
      <language>fra</language>
      <author><first>David</first><last>Guennec</last></author>
      <author><first>Damien</first><last>Lolive</last></author>
      <pages>455–463</pages>
      <abstract>Les systèmes de synthèse par corpus reposent, sauf de rares exceptions, sur des coûts cibles et des coûts de concaténation pour sélectionner la meilleure séquence d’unités. Le rôle du coût de concaténation est de s’assurer que l’assemblage de deux segments de parole ne causera l’apparition d’aucun artefact acoustique. Pour cette tâche, des distances acoustiques (MFCC, F0) sont généralement utilisées, mais dans de nombreux cas cela ne suffit pas. Dans cet article, nous introduisons une pénalité héritée du domaine de la couverture de corpus dans le coût de concaténation afin de bloquer certaines concaténations en fonction de la classe phonologique des diphones à concaténer. En outre, une seconde version faisant appel à une fonction floue est proposée pour relâcher la pénalité en fonction du positionnement du coût de concaténation par rapport à sa distribution. Une évaluation objective montre que la pénalité est efficace et amène à un meilleur classement des séquences d’unités candidates au cours de la sélection. Une évaluation subjective révèle une performance supérieure de l’approche floue.</abstract>
      <url hash="26a923cb">2016.jeptalnrecital-jep.51</url>
    </paper>
    <paper id="52">
      <title>Perception audio-visuelle de séquences <fixed-case>VCV</fixed-case> produites par des personnes porteuses de Trisomie 21 : une étude préliminaire (Auditory-visual Perception of <fixed-case>VCV</fixed-case>s Produced by People with Down Syndrome: a Preliminary Study)</title>
      <language>fra</language>
      <author><first>Alexandre</first><last>Hennequin</last></author>
      <author><first>Amélie</first><last>Rochet-Capellan</last></author>
      <author><first>Marion</first><last>Dohen</last></author>
      <pages>464–472</pages>
      <abstract>La parole des personnes avec trisomie 21 (T21) présente une altération systématique de l’intelligibilité qui n’a été quantifiée qu’auditivement. Or la modalité visuelle pourrait améliorer l’intelligibilité comme c’est le cas pour les personnes « ordinaires ». Cette étude compare la manière dont 24 participants ordinaires perçoivent des séquences VCV voyelle-consonne-voyelle) produites par quatre adultes (2 avec T21 et 2 ordinaires) et présentées dans le bruit en modalités auditive, visuelle et audiovisuelle. Les résultats confirment la perte d’intelligibilité en modalité auditive dans le cas de locuteurs porteurs de T21. Pour les deux locuteurs impliqués, l’intelligibilité visuelle est néanmoins équivalente à celle des deux locuteurs ordinaires et compensent le déficit d’intelligibilité auditive. Ces résultats suggèrent l’apport de la modalité visuelle vers une meilleure intelligibilité des personnes porteuses de T21.</abstract>
      <url hash="3c6a37e3">2016.jeptalnrecital-jep.52</url>
    </paper>
    <paper id="53">
      <title>Perception des consonnes géminées en japonais langue étrangère par des apprenants francophones (Perception of geminate consonants in <fixed-case>J</fixed-case>apanese as a foreign language by <fixed-case>F</fixed-case>rench-speaking learners)</title>
      <language>fra</language>
      <author><first>Akiko</first><last>Takemura</last></author>
      <author><first>Takeki</first><last>Kamiyama</last></author>
      <pages>473–481</pages>
      <abstract>Le japonais présente une opposition phonémique entre les obstruantes simples et géminées, qui pose des difficultés aux apprenants non-natifs tant au niveau de la perception que de la production, notamment quand une opposition similaire est absente dans la langue des apprenants. La discrimination perceptive de cette opposition a été étudiée chez 19 apprenants francophones de deux niveaux différents de compétence et chez 6 auditeurs natifs à l’aide d’une expérience AXB avec des non-mots dysyllabiques prononcés par 2 locuteurs natifs du japonais de Tokyo. Les résultats montrent une différence significative entre les apprenants (10,91% d’erreurs en moyenne) et les natifs (3,86% en moyenne). Le taux d’erreurs était plus élevé quand l’accent lexical du mot testé était du type HB (haut-bas) que BH. Les auditeurs natifs ont également montré un taux d’erreur plus élevé pour la fricative /s/, et aussi quand la consonne est entourée des voyelles fermées /i/ et /u/.</abstract>
      <url hash="f9353c59">2016.jeptalnrecital-jep.53</url>
    </paper>
    <paper id="54">
      <title>La perception des séquences consonantiques non-natives par les locuteurs monolingues de mandarin (Perception of non-native consonant sequences by <fixed-case>M</fixed-case>andarin monolingual speakers)</title>
      <language>fra</language>
      <author><first>Qianwen</first><last>Guan</last></author>
      <author><first>Harim</first><last>Kwon</last></author>
      <pages>482–490</pages>
      <abstract>Cette étude examine le rôle de la structure phonotactique native et des facteurs phonétiques dans la perception des séquences consonantiques non-natives. Des locuteurs monolingues de mandarin ont été testés dans les deux expériences suivantes: dans la première expérience, les locuteurs ont du décider s’ils entendaient une voyelle entre deux consonnes en écoutant des séquences intervocaliques-CC (akta) et leurs contrôles CVC (akata). Les participants mandarins monolingues ont tendance à percevoir une voyelle entre deux consonnes dans les deux séquences CC et CVC. Mais le pourcentage de la voyelle perçue varie selon les différentes séquences. Dans la deuxième expérience, les mêmes participants ont écouté des séquences CC initiales et intervocaliques (ktapa, akta) ainsi que CVC (katapa, akata) et les ont transcrites en Pinyin. Les stratégies observées dans la transcription: l’épenthèse, la métathèse, l’omission de C1 et celle de C2, montrent que les participants sont sensibles aux facteurs phonétiques. Les résultats des deux expériences suggèrent que la phonotactique native ainsi que des facteurs phonétiques affectent la perception des séquences non-natives.</abstract>
      <url hash="1cd15215">2016.jeptalnrecital-jep.54</url>
    </paper>
    <paper id="55">
      <title>Perception et production de voyelles de l’anglais par des apprenants francophones : effet d’entraînements en perception et en production (Perception and production of <fixed-case>E</fixed-case>nglish vowels by <fixed-case>F</fixed-case>rench learners: effect of perception and production trainings)</title>
      <language>fra</language>
      <author><first>Jennifer</first><last>Krzonowski</last></author>
      <author><first>Emmanuel</first><last>Ferragne</last></author>
      <author><first>François</first><last>Pellegrino</last></author>
      <pages>491–499</pages>
      <abstract>Cette étude propose de tester l’effet de deux entraînements, en perception et en production, sur l’acquisition de voyelles de l’anglais britannique par des francophones. L’étude se focalise sur deux régions de l’espace acoustique pour lesquelles plusieurs catégories phonologiques existent en anglais alors qu’une seule existe en français. Trois groupes ont été constitués : l’un recevant un entraînement de type High Variability Perceptual Training, un second recevant un entraînement en production et le troisième constituait un groupe contrôle ne recevant pas d’entraînement. Les performances des participants ont été évaluées avant et après entraînement en perception et en production. Les résultats semblent montrer un effet de l’entraînement en perception sur les performances en perception et en production et un effet plus restreint de l’entraînement en production. Mais leur interprétation reste difficile du fait d’un effet test/re-test observé sur le groupe contrôle.</abstract>
      <url hash="5842d004">2016.jeptalnrecital-jep.55</url>
    </paper>
    <paper id="56">
      <title>Perception native des voyelles catalanes produites par des locutrices multilingues (Native perception of <fixed-case>C</fixed-case>atalan vowels uttered by female multilingual speakers)</title>
      <language>fra</language>
      <author><first>Cynthia</first><last>Magnen</last></author>
      <author><first>Josefina</first><last>Carrera-Sabaté</last></author>
      <author><first>Pascal</first><last>Gaillard</last></author>
      <pages>500–508</pages>
      <abstract>Cette étude porte sur les voyelles catalanes produites par des adolescentes multilingues en CatalanCastillan ayant pour langue maternelle soit le Catalan, soit le Roumain, soit l’Arabe du Maghreb. Nous proposons à vingt-et-un auditeurs catalanophones natifs un Test de Catégorisation Libre des voyelles produites dans ce contexte multilingue. Ce faisant, nous testons le modèle Automatic Selective Perception (ASP - Strange, 2011) qui stipule qu’en fonction de la variabilité des stimuli et de la tâche proposée, les auditeurs réalisent un traitement des stimuli selon un mode phonétique ou phonologique. Les résultats indiquent que le traitement des stimuli est double : les voyelles moyennes sont traitées selon un mode phonétique, tandis que les voyelles extrêmes sont traitées selon un mode phonologique. L’assimilation de voyelles d’une catégorie vocalique à une autre informe sur la qualité des réalisations non natives et témoigne de l’influence de la L1.</abstract>
      <url hash="858ef14f">2016.jeptalnrecital-jep.56</url>
    </paper>
    <paper id="57">
      <title>Peut-on caractériser globalement une « qualité d’acte expressif » : de « breathy voice » à « breathy turn taking » dans la glu socio-affective de l’interaction humain-robot ? (Multidimensional prosodic style, as characteristics of the “gluing” relation process: extension of “breathiness” from voice quality to “turn talk quality”)</title>
      <language>fra</language>
      <author><first>Liliya</first><last>Tsvetanova</last></author>
      <author><first>Véronique</first><last>Aubergé</last></author>
      <author><first>Yuko</first><last>Sasa</last></author>
      <pages>509–517</pages>
      <abstract>L’interaction face-à-face est considérée ici comme un système émergeant, englobant les soussystèmes en synchronie des interactants inscrits, à travers leur personnalité, dans leur rôle social, leurs motivations, leurs intentions, leurs états socio-affectifs. L’interaction est instanciée par une « glu » socio-affective pour laquelle nous testons une dimension altruiste, orthogonale à la dimension de dominance, expérimentée dans le scénario écologique Emoz (Sasa et Aubergé, 2014) pour des personnes âgées donnant des commandes domotiques de forme imposée à un robot. Le dialogue est conduit par des feedbacks socio-affectifs primitifs du robot supposés « gluer » progressivement. Nous montrons que la variation faite par les sujets autour des commandes référentes, non seulement suit un décours dynamique de « glu » progressive, mais que le comportement communicatif des sujets est globalement inscrit dans des caractéristiques d’« intimité-care» d’une production breathy de toutes les modalités (voix, prosodie, paraphrasage lexico-morpho-syntaxique, timing, posture, direction du regard, proxémie, déplacement).</abstract>
      <url hash="b36adca3">2016.jeptalnrecital-jep.57</url>
    </paper>
    <paper id="58">
      <title>Phonétisation statistique adaptable d’énoncés pour le français (Adaptive statistical utterance phonetization for <fixed-case>F</fixed-case>rench ⇤ )</title>
      <language>fra</language>
      <author><first>Gwénolé</first><last>Lecorvé</last></author>
      <author><first>Damien</first><last>Lolive</last></author>
      <pages>518–526</pages>
      <abstract>Les méthodes classiques de phonétisation d’énoncés concatènent les prononciations hors-contexte des mots. Ce type d’approches est trop faible pour certaines langues, comme le français, où les transitions entre les mots impliquent des modifications de prononciation. De plus, cela rend difficile la modélisation de stratégies de prononciation globales, par exemple pour modéliser un locuteur ou un accent particulier. Pour palier ces problèmes, ce papier présente une approche originale pour la phonétisation du français afin de générer des variantes de prononciation dans le cas d’énoncés. Par l’emploi de champs aléatoires conditionnels et de transducteurs finis pondérés, cette approche propose un cadre statistique particulièrement souple et adaptable. Cette approche est évaluée sur un corpus de mots isolés et sur un corpus d’énoncés prononcés.</abstract>
      <url hash="0134621f">2016.jeptalnrecital-jep.58</url>
    </paper>
    <paper id="59">
      <title>Pics mélodiques prétoniques en portugais brésilien : une étude quantitative (Pre-stress pitch peaks in <fixed-case>B</fixed-case>razilian <fixed-case>P</fixed-case>ortuguese: a quantitative study)</title>
      <language>fra</language>
      <author><first>Plínio</first><last>Barbosa</last></author>
      <author><first>Philippe Boula</first><last>de Mareüil</last></author>
      <pages>527–535</pages>
      <abstract>Le présent travail porte sur un trait prosodique assez typique du portugais brésilien : un pic mélodique en position prétonique en fin d’énoncé déclaratif. Il vise à quantifier le phénomène, à partir d’enregistrements de cinq hommes et cinq femmes de l’état de São Paulo, en lecture et en narration. Il en résulte que des montées sur les prétoniques de 4 demi-tons suivies de descentes de 8 demi-tons, en moyenne, s’observent dans les deux styles de parole, chez les femmes. Chez les hommes, ces valeurs sont respectivement de 3 et 7 demi-tons. Ces montées-descentes d’une tierce et d’une quinte, respectivement, peuvent donner au portugais brésilien cette musicalité particulière et, puisque les descentes sont plus rapides chez les femmes, elles ouvrent des perspectives sociolinguistiques intéressantes.</abstract>
      <url hash="9467eace">2016.jeptalnrecital-jep.59</url>
    </paper>
    <paper id="60">
      <title>Préservation du pattern syllabique iambique dans la production des locuteurs dysarthriques (The preservation of iambic syllabic pattern in the production of dysarthric speakers)</title>
      <language>fra</language>
      <author><first>Laurianne</first><last>Georgeton</last></author>
      <author><first>Meunier</first><last>Christine</last></author>
      <pages>536–544</pages>
      <abstract>Ce travail vise à évaluer une éventuelle dégradation du pattern rythmique iambique dans la production de locuteurs atteints de différents types de dysarthrie. Ce pattern se traduit par une structure court-long dans les mots dissyllabiques. Cette structure est très robuste en français aussi bien en production qu¶en perception. Par ailleurs, chez des locuteurs dysarthriques, des perturbations prosodiques et donc rythmiques sont souvent observées. Ainsi, ces patients peuventils maintenir ce pattern iambique dans leurs productions? Les résultats montrent que le pattern rythmique iambique est bien conservé chez toutes les populations dysarthriques aussi bien en lecture qu¶en parole spontanée. Ce pattern est en général plus marqué en spontané qu¶en lecture et la population contrôle se démarque des populations dysarthriques par un pattern plus marqué en lecture, mais plus encore en spontané. Ce pattern rythmique semble donc robuste même s¶il semble être affecté quand la sévérité de la maladie augmente.</abstract>
      <url hash="2c0f8fe8">2016.jeptalnrecital-jep.60</url>
    </paper>
    <paper id="61">
      <title>Production des voyelles parlées et chantées dans le Cantu in Paghjella (Production of spoken and sung vowels in Cantu in Paghjella)</title>
      <language>fra</language>
      <author><first>Claire</first><last>Pillot-Loiseau</last></author>
      <author><first>Patrick</first><last>Chawah</last></author>
      <author><first>Angélique</first><last>Amelot</last></author>
      <author><first>Grégoire</first><last>Bachman</last></author>
      <author><first>Catherine</first><last>Herrgott</last></author>
      <author><first>Martine</first><last>Adda-Decker</last></author>
      <author><first>Lise</first><last>Crevier-Buchman</last></author>
      <pages>545–553</pages>
      <abstract>Quelles sont les caractéristiques acoustiques et articulatoires des voyelles parlées et chantées du Cantu in Paghjella (polyphonie corse à trois voix), en fonction du chanteur, de la voyelle et de la fréquence fondamentale ? L’analyse acoustique des quatre premiers formants de la parole au chant et celle des mouvements articulatoires lingual et labial, montrent généralement (i) une significative augmentation de F1 avec abaissement lingual mais fermeture labiale, en lien avec une corrélation entre F0 et F1 ; (ii) une baisse de F2 pour les voyelles antérieures, une postériorisation linguale et un recul de l’ombre hyoïdienne uniquement pour le bassu ; (iii) une nette augmentation de F3 et F4 surtout chez le bassu ; (iv) une augmentation du Singing Power Ratio surtout chez les bassu et secunda. Ses valeurs sont toutefois inférieures à celles de chanteurs lyriques, et ne correspondant pas comme ces derniers à un rapprochement de F3 et F4.</abstract>
      <url hash="63d15327">2016.jeptalnrecital-jep.61</url>
    </paper>
    <paper id="62">
      <title>La prosodie du focus dans les parlers algérois et oranais (The prosody of focus in <fixed-case>A</fixed-case>lgiers and <fixed-case>O</fixed-case>ran dialects)</title>
      <language>fra</language>
      <author><first>Ismaël</first><last>Benali</last></author>
      <pages>554–562</pages>
      <abstract>Le but de cette étude est d’étudier les caractéristiques prosodiques de différents types de focus dans les parlers algérois et oranais. Il ressort de l’analyse acoustique des productions des locuteurs que les récurrences des schèmes prosodiques qui distinguent les deux parlers sont observées dans deux types de focus : le focus étroit d’insistance quand il est placé à la frontière d’un groupe intonatif et le focus interrogatif. Le premier est réalisé dans le parler algérois par un contour montant descendant. Dans le parler oranais, il est produit par un contour plat ou légèrement montant ou descendant. On retrouve, dans le focus interrogatif, le mêmes contour intonatif plus amplifié du focus d’insistance chez les Algérois alors que chez les Oranais la dernière syllabe est toujours montante précédée d’une descente. Le focus de contraste est produit différemment dans le même dialecte avec plus d’allongement en oranais. La réalisation du focus large n’est pas distinctive.</abstract>
      <url hash="d1c2e971">2016.jeptalnrecital-jep.62</url>
    </paper>
    <paper id="63">
      <title>Que disents nos silences? Apport des données acoustiques, articulatoires et physiologiques pour l’étude des pauses silencieuses (What do our silences say? Contribution of acoustic, articulatory and physiological data to the study on silent pauses)</title>
      <language>fra</language>
      <author><first>Lalain</first><last>Muriel</last></author>
      <author><first>Legou</first><last>Thierry</last></author>
      <author><first>Fauth</first><last>Camille</last></author>
      <author><first>Hirsch</first><last>Fabrice</last></author>
      <author><first>Didirkova</first><last>Ivana</last></author>
      <pages>563–570</pages>
      <abstract>Si la rhétorique s’est intéressée très tôt à la pause, il a fallu attendre le XXème siècle pour que d’autres disciplines – la psycholinguistique, le traitement automatique des langues, la phonétique – accordent à ces moments de silence l’intérêt qu’ils méritent. Il a ainsi été montré que ces ruptures dans le signal acoustique, loin de signer une absence d’activité, constituaient en réalité le lieu d’une activité physiologique (la respiration) et/ou cognitive (planification du discours) qui participent tout autant au message que la parole elle-même. Dans cette étude pilote, nous proposons des observations et des pistes de réflexions à partir de l’analyse des pauses silencieuses dans un corpus de parole lue et semi dirigée. Nous mettons notamment en évidence l’apport de l’analyse conjointe de données acoustiques, articulatoires (EMA) et physiologiques (respiratoires) pour l’identification, parmi les pauses silencieuses, des pauses respiratoires, syntaxiques et d’hésitation.</abstract>
      <url hash="8baa6e4f">2016.jeptalnrecital-jep.63</url>
    </paper>
    <paper id="64">
      <title>Que nous apprennent les gros corpus sur l’harmonie vocalique en français ? (What can we learn from big speech corpora about <fixed-case>F</fixed-case>rench vowel harmony?)</title>
      <language>fra</language>
      <author><first>Giuseppina</first><last>Turco</last></author>
      <author><first>Cécile</first><last>Fougeron</last></author>
      <author><first>Nicolas</first><last>Audibert</last></author>
      <pages>571–579</pages>
      <abstract>Afin de mieux identifier le poids relatif des différents facteurs décrits dans la littérature comme influençant le phénomène d’harmonie vocalique (HV) en français, 33k mots extraits de deux corpus de parole continue et présentant un contexte d’HV possible V1C(C)V2 (V1∈e,ɛ,o,ɔ) sont analysés. Le degré d’HV est mesuré en termes d’abaissement du F1 de V1 induit par la présence d’une V2 /+haut/ (fermée ou mi-fermée) par rapport à une V2 /-haut/ (ouverte ou mi-ouverte). Les résultats montrent une HV plus importante pour les voyelles moyennes postérieures que pour les antérieures, et plus faible lorsque l’orthographe favorise une prononciation mi-fermée de V1. Comme attendu, l’HV est plus forte quand V1 est séparé de V2 par une consonne labiale vs. linguale ou par un cluster consonantique sous-jacent vs. un cluster résultant de la chute d’un schwa. En revanche, le style de parole (conversationnelle vs. journalistique) a un effet plus nuancé que celui attendu.</abstract>
      <url hash="30ffb819">2016.jeptalnrecital-jep.64</url>
    </paper>
    <paper id="65">
      <title>Quelle(s) mesure(s) de similarité prosodique comme évaluation de l’imitation ? (Which measure(s) of prosodic similarity as an evaluation of imitation?)</title>
      <language>fra</language>
      <author><first>Olivier</first><last>Nocaudie</last></author>
      <author><first>Corine</first><last>Astésano</last></author>
      <pages>580–588</pages>
      <abstract>La performance imitative des locuteurs varie de celle du professionnel, expert, à celle du naïf, plus ou moins talentueux. L’étude de l’imitation souligne la difficulté pour trouver des indices mesurables de la réussite d’une imitation. Dans cette étude exploratoire, des contours de f0 recueillis au fil de tâches d’imitation sont testés au moyen d’une double approche : mesure objective par le biais de deux mesures de la similarité prosodique reportées dans la littérature et évaluation perceptive par un panel de 15 auditeurs naïfs. Nos premiers résultats indiquent une bonne corrélation entre les deux approches et soulèvent la question du choix de l’indice mesurable qui rendrait le mieux compte d’une imitation au niveau tonal. Ils soulignent également la variabilité interindividuelle des comportements imitatifs en parole tout en ouvrant des perspectives intéressantes dans le domaine de la formation à la phonétique corrective par la Méthode Verbotonale.</abstract>
      <url hash="04cfac2d">2016.jeptalnrecital-jep.65</url>
    </paper>
    <paper id="66">
      <title>Quels tests d’intelligibilité pour évaluer les troubles de production de la parole ? (What kind of intelligibility test to assess speech production disorders?)</title>
      <language>fra</language>
      <author><first>Alain</first><last>Ghio</last></author>
      <author><first>Laurence</first><last>Giusti</last></author>
      <author><first>Emilie</first><last>Blanc</last></author>
      <author><first>Serge</first><last>Pinto</last></author>
      <author><first>Lalain</first><last>Muriel</last></author>
      <author><first>Danièle</first><last>Robert</last></author>
      <author><first>Corine</first><last>Fredouille</last></author>
      <author><first>Virginie</first><last>Woisard</last></author>
      <pages>589–596</pages>
      <abstract>L’intelligibilité de la parole se définit comme le degré de précision avec lequel un message est compris par un auditeur. A ce titre, la perte d’intelligibilité représente souvent une plainte importante pour les patients atteints de troubles de production de la parole, puisqu’elle participe à la diminution de la qualité de vie au niveau communicationnel. Plusieurs outils existent actuellement pour évaluer l’intelligibilité mais aucun ne satisfait pleinement les contraintes cliniques. Dans une première étude, nous avons adapté au français la version 2 du Frenchay Dysarthria Assessment, un test reconnu dans le milieu anglo-saxon pour l’évaluation de locuteurs dysarthriques. Nous avons créé le corpus de mots français en nous appuyant sur les critères définis dans le FDA-2 puis nous avons testé le protocole sur une cinquantaine de locuteurs. Les résultats sont satisfaisants mais divers biais méthodologiques nous ont conduits à poursuivre notre démarche en proposant des listes de pseudo-mots apparentant le test à du décodage acoustico-phonétique.</abstract>
      <url hash="20146cec">2016.jeptalnrecital-jep.66</url>
    </paper>
    <paper id="67">
      <title>Réalisation phonétique et contraste phonologique marginal : une étude automatique des voyelles du roumain (Phonetic realization and marginal phonemic contrast : an automatic study of the <fixed-case>R</fixed-case>omanian vowels)</title>
      <language>fra</language>
      <author><first>Ioana</first><last>Vasilescu</last></author>
      <author><first>Margaret</first><last>Renwick</last></author>
      <author><first>Camille</first><last>Dutrey</last></author>
      <author><first>Lori</first><last>Lamel</last></author>
      <author><first>Biana</first><last>Vieru</last></author>
      <pages>597–606</pages>
      <abstract>Cet article est dédié à l’analyse acoustique des voyelles du roumain : des productions en parole continue sont comparées à des prononciations “de laboratoire”. Les objectifs sont : (1) décrire les traits acoustiques des voyelles en fonction du style de parole ; (2) estimer la relation entre traits acoustiques et contrastes phonémiques de la langue ; (3) estimer dans quelle mesure l’étude de l’oral apporte des éclairages au sujet des attributs phonémiques des voyelles centrales [2] et [1], dont le statut (phonèmes vs allophones) est controversé. Nous montrons que les traits acoustiques sont comparables pour la parole journalistique vs contrôlée pour l’ensemble de l’inventaire sauf [2] et [1]. Dans la parole contrôlée [2] et [1] sont distinctes, mais confondues en faveur du timbre [2] à l’oral. La confusion de timbres n’est pas source d’inintelligibilité car [2] et [1] sont en distribution quasicomplémentaire. Ce résultat apporte des éclairages sur la question du contraste phonémique graduel et marginal (Goldsmith, 1995; Scobbie &amp; Stuart-Smith, 2008; Hall, 2013).</abstract>
      <url hash="75e5f935">2016.jeptalnrecital-jep.67</url>
    </paper>
    <paper id="68">
      <title>La reconnaissance des mots dans la parole accentuée : Une étude en laboratoire et à l’extérieur. (Mispronunciations slow down word recognition: A study using touchscreens in the lab and the real world)</title>
      <language>fra</language>
      <author><first>Delphine</first><last>Deï</last></author>
      <author><first>Page</first><last>Piccinini</last></author>
      <author><first>Isabelle</first><last>Dautriche</last></author>
      <author><first>Marieke Van</first><last>Heugten</last></author>
      <author><first>Alejandrina</first><last>Cristia</last></author>
      <pages>607–614</pages>
      <abstract>Des travaux récents suggèrent que les enfants et les adultes sont initialement ralentis dans leur compréhension des mots qui n’ont pas été prononcés de façon standard. Néanmoins, quand ils font face à un interlocuteur qui à un discours accentué, ils développent rapidement des stratégies spécifiques qui leur permettent de comprendre même des prononciations atypiques. Cependant, ces résultats sont typiquement issus de recherches en laboratoire, où l’attention des participants se concentre sur une tâche unique qui leur demande peu de ressources. Afin de dépasser ces limitations, nous avons mené une expérience de reconnaissance de mots sur tablette tactile, en évaluant des enfants et des adultes, en laboratoire et dans l’environnement naturel de chaque groupe. Nous avons constaté que des déviations de prononciation dans la parole accentuée ralentissent la reconnaissance des mots, chez des enfants et adultes, tant dans le laboratoire que dans des environnements naturels.</abstract>
      <url hash="57a13d52">2016.jeptalnrecital-jep.68</url>
    </paper>
    <paper id="69">
      <title>Répartition des phonèmes réduits en parole conversationnelle. Approche quantitative par extraction automatique (The distribution of reduced phoneme in conversational speech)</title>
      <language>fra</language>
      <author><first>Meunier</first><last>Christine</last></author>
      <author><first>Brigitte</first><last>Bigi</last></author>
      <pages>615–623</pages>
      <abstract>Cette étude vise à mieux comprendre la répartition des réductions phonétiques présentes dans la production de parole. Nous avons sélectionné l! ensemble des phonèmes les plus courts (30ms) à partir de l! alignement d! un corpus de parole conversationnelle. Cette version contenant uniquement les phonèmes courts (V1) est comparée à la version contenant l! alignement de tous les phonèmes du corpus (V0). Les deux versions sont mises en relation avec l! annotation des mots et de leur catégorie syntaxique. Les résultats montrent que les liquides, les glissantes et les voyelles fermées sont plus représentées dans V1 que dans V0. Par ailleurs, la nature et la catégorie syntaxique des mots modulent la distribution des phonèmes en V1. Ainsi, la nature instable du /l/, ainsi que sa présence dans de très nombreux pronoms et déterminants, en fait le phonème le plus marqué par la réduction. Enfin, la fréquence des mots semble montrer des effets contradictoires.</abstract>
      <url hash="4c6ebe4c">2016.jeptalnrecital-jep.69</url>
    </paper>
    <paper id="70">
      <title>Réseau de neurones convolutif pour l’évaluation automatique de la prononciation (<fixed-case>CNN</fixed-case>-based automatic pronunciation assessment of <fixed-case>J</fixed-case>apanese speakers learning <fixed-case>F</fixed-case>rench )</title>
      <language>fra</language>
      <author><first>Thomas</first><last>Pellegrini</last></author>
      <author><first>Lionel</first><last>Fontan</last></author>
      <author><first>Halima</first><last>Sahraoui</last></author>
      <pages>624–632</pages>
      <abstract>Dans cet article, nous comparons deux approches d’évaluation automatique de la prononciation de locuteurs japonophones apprenant le français. La première, l’algorithme standard appelé Goodness Of Pronunciation (GOP), compare les vraisemblances obtenues lors d’un alignement forcé et lors d’une reconnaissance de phones sans contrainte. La deuxième, nécessitant également un alignement préalable, fait appel à un réseau de neurones convolutif (CNN) comme classifieur binaire, avec comme entrée des trames de coefficients spectraux. Les deux approches sont évaluées sur deux phonèmes cibles /R/ et /v/ du français, particulièrement difficiles à prononcer pour des Japonophones. Les paramètres du GOP (seuils) et du CNN sont estimés sur un corpus de parole lue par des locuteurs natifs du français, dans lequel des erreurs de prononciation artificielles sont introduites. Un gain de performance relatif de 13,4% a été obtenu avec le CNN, avec une précision globale de 72,6%, sur un corpus d’évaluation enregistré par 23 locuteurs japonophones.</abstract>
      <url hash="c8d39b7c">2016.jeptalnrecital-jep.70</url>
    </paper>
    <paper id="71">
      <title>Rôle des contextes lexical et post-lexical dans la réalisation du schwa : apports du traitement automatique de grands corpus (Role of lexical and post-lexical contexts in <fixed-case>F</fixed-case>rench schwa realisations : benefits of automatic processing of large corpora )</title>
      <language>fra</language>
      <author><first>Yaru</first><last>Wu</last></author>
      <author><first>Martine</first><last>Adda-Decker</last></author>
      <author><first>Cécile</first><last>Fougeron</last></author>
      <pages>633–641</pages>
      <abstract>Le rôle du contexte est connu dans la réalisation ou non du schwa en français. Deux grands corpus oraux de parole journalistique (ETAPE) et de parole familière (NCCFr), dans lesquels la realisation de schwa est déterminée à partir d’un alignement automatique, ont été utilisés pour examiner la contribution du contexte au sein du mot contenant schwa (lexical) vs. au travers de la frontière avec le mot précédent (post-lexical). Nos résultats montrent l’importance du contexte pré-frontière dans l’explication de la chute du schwa dans la première syllabe d’un mot polysyllabique en parole spontanée. Si le mot précédant se termine par une consonne, nous pouvons faire appel à la loi des trois consonnes et au principe de sonorité pour expliquer des différences de comportement en fonction de la nature des consonnes en contact.</abstract>
      <url hash="2f294ad9">2016.jeptalnrecital-jep.71</url>
    </paper>
    <paper id="72">
      <title>Des Réseaux de Neurones avec Mécanisme d’Attention pour la Compréhension de la Parole (Exploring the use of Attention-Based Recurrent Neural Networks For Spoken Language Understanding )</title>
      <language>fra</language>
      <author><first>Edwin</first><last>Simonnet</last></author>
      <author><first>Paul</first><last>Deléglise</last></author>
      <author><first>Nathalie</first><last>Camelin</last></author>
      <author><first>Yannick</first><last>Estève</last></author>
      <pages>642–650</pages>
      <abstract>L’étude porte sur l’apport d’un réseau de neurones récurrent (Recurrent Neural Network RNN) bidirectionnel encodeur/décodeur avec mécanisme d’attention pour une tâche de compréhension de la parole. Les premières expériences faites sur le corpus ATIS confirment la qualité du système RNN état de l’art utilisé pour cet article, en comparant les résultats obtenus à ceux récemment publiés dans la littérature. Des expériences supplémentaires montrent que les RNNs avec mécanisme d’attention obtiennent de meilleures performances que les RNNs récemment proposés pour la tâche d’étiquetage en concepts sémantiques. Sur le corpus MEDIA, un corpus français état de l’art pour la compréhension dédié à la réservation d’hôtel et aux informations touristiques, les expériences montrent qu’un RNN bidirectionnel atteint une f-mesure de 79,51 tandis que le même système intégrant le mécanisme d’attention permet d’atteindre une f-mesure de 80,27.</abstract>
      <url hash="7b905318">2016.jeptalnrecital-jep.72</url>
    </paper>
    <paper id="73">
      <title>Un Sous-espace Thématique Latent pour la Compréhension du Langage Parlé (A Latent Topic-based Subspace for Spoken Language Understanding)</title>
      <language>fra</language>
      <author><first>Mohamed</first><last>Bouaziz</last></author>
      <author><first>Mohamed</first><last>Morchid</last></author>
      <author><first>Pierre-Michel</first><last>Bousquet</last></author>
      <author><first>Richard</first><last>Dufour</last></author>
      <author><first>Killian</first><last>Janod</last></author>
      <author><first>Waad Ben</first><last>Kheder</last></author>
      <author><first>Georges</first><last>Linarès</last></author>
      <pages>651–659</pages>
      <abstract>Les applications de compréhension du langage parlé sont moins performantes si les documents transcrits automatiquement contiennent un taux d’erreur-mot élevé. Des solutions récentes proposent de projeter ces transcriptions dans un espace de thèmes, comme par exemple l’allocation latente de Dirichlet (LDA), la LDA supervisée ainsi que le modèle author-topic (AT). Une représentation compacte originale, appelée c-vector, a été récemment introduite afin de surmonter la difficulté liée au choix de la taille de ces espaces thématiques. Cette représentation améliore la robustesse aux erreurs de transcription, en compactant les différentes représentations LDA d’un document parlé dans un espace réduit. Le défaut majeur de cette méthode est le nombre élevé de sous-tâches nécessaires à la construction de l’espace c-vector. Cet article propose de corriger ce défaut en utilisant un cadre original fondé sur un espace de caractéristiques robustes de faible dimension provenant d’un ensemble de modèles AT considérant à la fois le contenu du dialogue parlé (les mots) et la classe du document. Les expérimentations, conduites sur le corpus DECODA, montrent que la représentation proposée permet un gain de plus de 2.5 points en termes de conversations correctement classifiées.</abstract>
      <url hash="76aae68d">2016.jeptalnrecital-jep.73</url>
    </paper>
    <paper id="74">
      <title>Stratégies d’adaptation de la vitesse d’articulation lors de conversations spontanées entre locuteurs natifs et non-natifs (Adaptation of articulation rate in spontaneous speech between native speakers and <fixed-case>L</fixed-case>2 learners)</title>
      <language>fra</language>
      <author><first>Barbara</first><last>Kühnert</last></author>
      <author><first>Tanja Kocjančič</first><last>Antolík</last></author>
      <pages>660–668</pages>
      <abstract>Cet article examine la vitesse d’articulation dans un corpus de conversations spontanées entre locuteurs natifs et non-natifs. L’objectif est d’étudier (i) dans quelle mesure les locuteurs natifs adaptent dans leur L1 leur vitesse d’articulation aux apprenants L2 et (ii) dans quelle mesure les deux locuteurs en interaction ont tendance à rapprocher ou à dissocier leurs caractéristiques temporelles au cours d’une conversation. Les données proviennent du corpus SITAF d’interactions tandem en anglais-français. A ce jour, 10 sujets ont été analysés, chacun ayant été enregistré dans trois conditions différentes : en utilisant sa L1 avec un autre locuteur natif, en utilisant sa L1 avec un apprenant L2, et en utilisant sa L2 avec un interlocuteur parlant sa propre L1. Les résultats indiquent que les propriétés rythmiques de la L1 ont une nette influence sur les variations de la vitesse d’articulation des locuteurs non seulement lorsqu’ils interagissent dans leur L2 mais également dans leurs stratégies d’adaptation lorsqu’ils interagissent avec des apprenants.</abstract>
      <url hash="3d530e2b">2016.jeptalnrecital-jep.74</url>
    </paper>
    <paper id="75">
      <title>Stress, charge cognitive et signal de parole : étude exploratoire auprès de pilotes de chasse. (Stress, cognitive load and speech signal : an exploratory study among fighter pilots)</title>
      <language>fra</language>
      <author><first>Stavaux</first><last>Luc</last></author>
      <author><first>Margaux</first><last>Albart</last></author>
      <author><first>Véronique</first><last>Delvaux</last></author>
      <author><first>Kathy</first><last>Huet</last></author>
      <author><first>Myriam</first><last>Piccaluga</last></author>
      <author><first>Bernard</first><last>Harmegnies</last></author>
      <pages>669–677</pages>
      <abstract>Cet article traite des effets de la charge cognitive sur la fréquence fondamentale de pilotes de F-16 placés dans un scénario de vol de nuit. La charge cognitive a été estimée à l’aide de paramètres liés à la tâche (hétéro-évaluation), à l’individu (anxiété, auto-évaluation du stress ressenti) et à la situation (simulation contrôlée). Nos résultats montrent que l’écart mélodique est un bon candidat pour évaluer le niveau de la charge cognitive, même si la relation entre eux présente des profils individuels spécifiques. La création d’une typologie des situations de communication, l’adjonction d’autres indices acoustiques et le croisement avec des données physiologiques constituent les perspectives de cette étude.</abstract>
      <url hash="a72a8cb0">2016.jeptalnrecital-jep.75</url>
    </paper>
    <paper id="76">
      <title>Structure prosodique des langues romanes (Prosodic Structures of <fixed-case>R</fixed-case>omance Languages)</title>
      <language>fra</language>
      <author><first>Philippe</first><last>Martin</last></author>
      <pages>678–686</pages>
      <abstract>La description phonologique de la structure prosodique des langues romanes apparait similaire lorsque les interactions entre les accents mélodiques est prise en compte (ce qui n’est pas le cas dans la théorie autosegmentale-métrique). L’analyse acoustique de plus de 2600 énoncés lus et spontanés suggère que la réalisation des accents mélodiques, décrits en termes de contours mélodiques plutôt que de cibles tonales, indiquent avec les contours de frontière, des relations de dépendance « vers la droite » entre groupes accentuels. Ces relations permettent par incrémentation successive dans l’axe du temps la reconstitution par l’auditeur de la structure prosodique voulue par le locuteur. Dans ce cadre théorique, les langues romanes (italien, espagnol, catalan, portugais, roumain) utilisent les mêmes contours phonologiques pour indiquer les relations de dépendance menant au codage de la structure prosodique. Le français, dépourvu d’accent lexical, utilise un système de contours différent.</abstract>
      <url hash="469c378d">2016.jeptalnrecital-jep.76</url>
    </paper>
    <paper id="77">
      <title>Suivi de contours d’articulateurs orofaciaux à partir d’<fixed-case>IRM</fixed-case> dynamique (Orofacial articulators tracking from dynamic <fixed-case>MRI</fixed-case>)</title>
      <language>fra</language>
      <author><first>Mathieu</first><last>Labrunie</last></author>
      <author><first>Pierre</first><last>Badin</last></author>
      <author><first>Laurent</first><last>Lamalle</last></author>
      <author><first>Coriandre</first><last>Vilain</last></author>
      <author><first>Louis-Jean</first><last>Boë</last></author>
      <author><first>Jens</first><last>Frahm</last></author>
      <author><first>Peter</first><last>Birkholz</last></author>
      <pages>687–695</pages>
      <abstract>Nous présentons une méthode de prédiction de contours médiosagittaux des organes orofaciaux de la parole et la déglutition à partir d’images IRM dynamiques. Pour chaque locuteur, un ensemble de 60 images représentatives pour lesquelles les contours ont été tracés manuellement permet d’entraîner des modèles ACP d’images et de contours articulatoires, ainsi qu’un modèle multilinéaire qui prédit les paramètres des contours à partir des paramètres des images. Les contours obtenus sont ensuite corrigés par des modèles de forme actifs (ASM) modifiés utilisant les informations locales de profils d’intensité de pixels le long des normales aux contours. Les performances de cette méthode (erreurs moyennes « points à contour » entre 0,57 et 0,70 mm) sont insensibles au type de séquence IRM (écho de gradient avec échantillonnage synchronisé ou écho de gradient radial hautement sous-échantillonné), sont meilleures que celles de la littérature, et rendent possible le traitement de volumineux corpus d’images IRM dynamiques.</abstract>
      <url hash="c188fbf8">2016.jeptalnrecital-jep.77</url>
    </paper>
    <paper id="78">
      <title>Sur les traces acoustiques de /ʃ/ et /ç/ en allemand <fixed-case>L</fixed-case>2 (Acoustic tracing of /<fixed-case>S</fixed-case>/ and /ç/ in <fixed-case>G</fixed-case>erman <fixed-case>L</fixed-case>2)</title>
      <language>fra</language>
      <author><first>Jane</first><last>Wottawa</last></author>
      <author><first>Martine</first><last>Adda-Decker</last></author>
      <pages>696–704</pages>
      <abstract>Les apprenants français de l’allemand ont des difficultés à produire la fricative palatale sourde allemande /ç/ (Ich-Laut) et ont tendance à la remplacer par la fricative post-alvéolaire /S/. Nous nous demandons si avec des mesures acoustiques ces imprécisions de production peuvent être quantifiées d’une manière plus objective. Deux mesures acoustiques ont été examinées afin de distinguer au mieux /S/ et /ç/ dans un contexte VC en position finale de mot dans des productions de locuteurs germanophones natifs. Elles servent ensuite à quantifier les difficultés de production des apprenants français. 285 tokens de 20 locuteurs natifs et 20 locuteurs L2 ont été analysés. Les mesures appliquées sont le centre de gravité spectral et des rapports d’intensité par bande de fréquence. Sur les productions de locuteurs natifs, les résultats montrent que la mesure la plus fiable pour distinguer acoustiquement /S/ et /ç/ est le ratio d’intensité entre fréquences hautes (4-7 kHz) et basses (1-4 kHz). Les mesures confirment également les difficultés de production des locuteurs natifs français.</abstract>
      <url hash="977a3ba6">2016.jeptalnrecital-jep.78</url>
    </paper>
    <paper id="79">
      <title>Syllabe <fixed-case>CVC</fixed-case> et cycle mandibulaire : une étude articulatoire des asymétries. Le cas du vietnamien (<fixed-case>CVC</fixed-case> syllable and jaw cycle: an articulatory study of asymmetries)</title>
      <language>fra</language>
      <author><first>Thi Thuy Hien</first><last>Tran</last></author>
      <author><first>Nathalie</first><last>Vallée</last></author>
      <author><first>Silvain</first><last>Gerber</last></author>
      <pages>705–713</pages>
      <abstract>Cette étude se situe dans le cadre d’un projet qui tente d’établir le lien entre asymétries phonétique et phonologique de la syllabe, plus spécifiquement le lien entre caractéristiques du geste mandibulaire et MOP, Maximum Onset Principle, principe phonologique empirique qui affecte les segments consonantiques à la position initiale de syllabe plutôt que finale. Plusieurs travaux antérieurs sur l’anglais américain ont montré l’existence d’asymétries au niveau des phases du cycle mandibulaire qui pourraient expliquer certaines tendances des structures syllabiques et notamment la structure canonique CV (plutôt que VC). Dans ce projet, une première étude sur le français a confirmé un patron d’asymétries mais inverse à celui trouvé pour l’anglais. Nous présentons les premiers résultats obtenus pour le vietnamien. Les résultats sont discutés dans deux cadres théoriques, Frame/Content Theory et Articulatory Phonology, le premier attribuant un rôle fondamental au geste mandibulaire dans la phonologie de la syllabe, le second ne lui concédant qu’un rôle secondaire.</abstract>
      <url hash="5db0e689">2016.jeptalnrecital-jep.79</url>
    </paper>
    <paper id="80">
      <title>De l’utilisation de descripteurs issus de la linguistique computationnelle dans le cadre de la synthèse par <fixed-case>HMM</fixed-case> (Toward the use of information density based descriptive features in <fixed-case>HMM</fixed-case> based speech synthesis)</title>
      <language>fra</language>
      <author><first>Sébastien Le</first><last>Maguer</last></author>
      <author><first>Bernd</first><last>Moebius</last></author>
      <author><first>Ingmar</first><last>Steiner</last></author>
      <author><first>Damien</first><last>Lolive</last></author>
      <pages>714–722</pages>
      <abstract>Durant les dernières décennies, la modélisation acoustique effectuée par les systèmes de synthèse de parole paramétrique a fait l’objet d’une attention particulière. Toutefois, dans la plupart des systèmes connus, l’ensemble des descripteurs linguistiques utilisés pour représenter le texte reste identique. Plus specifiquement, la modélisation de la prosodie reste guidée par des descripteurs de bas niveau comme l’information d’accentuation de la syllabe ou bien l’étiquette grammaticale du mot. Dans cet article, nous proposons d’intégrer des informations basées sur la prédictibilité d’un évènement (la syllabe ou le mot). Plusieurs études indiquent une corrélation forte entre cette mesure, fortement présente dans la linguistique computationnelle, et certaines spécificités lors de la production humaine de la parole. Notre hypothèse est donc que l’ajout de ces descripteurs améliore la modélisation de la prosodie. Cet article se focalise sur une analyse objective de l’apport de ces descripteurs sur la synthèse HMM pour la langue anglaise et française.</abstract>
      <url hash="2d33e535">2016.jeptalnrecital-jep.80</url>
    </paper>
    <paper id="81">
      <title>Utilisation des représentations continues des mots et des paramètres prosodiques pour la détection d’erreurs dans les transcriptions automatiques de la parole (Combining continuous word representation and prosodic features for <fixed-case>ASR</fixed-case> error detection)</title>
      <language>fra</language>
      <author><first>Sahar</first><last>Ghannay</last></author>
      <author><first>Yannick</first><last>Estève</last></author>
      <author><first>Nathalie</first><last>Camelin</last></author>
      <author><first>Camille</first><last>Dutrey</last></author>
      <author><first>Fabian</first><last>Santiago</last></author>
      <author><first>Martine</first><last>Adda-Decker</last></author>
      <pages>723–731</pages>
      <abstract>Récemment, l’utilisation des représentations continues de mots a connu beaucoup de succès dans plusieurs tâches de traitement du langage naturel. Dans cet article, nous proposons d’étudier leur utilisation dans une architecture neuronale pour la tâche de détection des erreurs au sein de transcriptions automatiques de la parole. Nous avons également expérimenté et évalué l’utilisation de paramètres prosodiques en suppléments des paramètres classiques (lexicaux, syntaxiques, . . .). La principale contribution de cet article porte sur la combinaison de différentes représentations continues de mots : plusieurs approches de combinaison sont proposées et évaluées afin de tirer profit de leurs complémentarités. Les expériences sont effectuées sur des transcriptions automatiques du corpus ETAPE générées par le système de reconnaissance automatique du LIUM. Les résultats obtenus sont meilleurs que ceux d’un système état de l’art basé sur les champs aléatoires conditionnels. Pour terminer, nous montrons que la mesure de confiance produite est particulièrement bien calibrée selon une évaluation en terme d’Entropie Croisée Normalisée (NCE).</abstract>
      <url hash="95afa30a">2016.jeptalnrecital-jep.81</url>
    </paper>
    <paper id="82">
      <title>Variabilité des syllabes réalisées par des apprenants de l’anglais (Analysing syllable variability in a <fixed-case>F</fixed-case>rench learner corpus of <fixed-case>E</fixed-case>nglish)</title>
      <language>fra</language>
      <author><first>Nicolas</first><last>Ballier</last></author>
      <author><first>Philippe</first><last>Martin</last></author>
      <author><first>Maelle</first><last>Amand</last></author>
      <pages>732–740</pages>
      <abstract>Cette contribution analyse la segmentation syllabique des francophones du corpus d’apprenant d’anglais ANGLISH (Tortel 2009). A partir d’une méthode d’alignement par alignement forcé, on montre la pertinence d’une analyse de l’interlangue fondée sur la comparaison des durées des syllabes. La comparaison des réalisations est ici centrée sur une typologie des syllabes fondée sur des propriétés distributionnelles, accentuelles et où l’interlangue tient sa place (risques d’isosyllabicité les plus manifestes pour les réalisations des francophones). La variabilité des réalisations des syllabes est appréciée en fonction des propriétés positionnelles, accentuelles et structurelles des syllabes. L’étude démontre l’intérêt d’une approche fonctionnelle des syllabes, plus pertinente que les intervalles interconsonantiques et intervocaliques inspirés de Ramus et al. (1999) pour la discrimination du niveau des locuteurs.</abstract>
      <url hash="12edd5f9">2016.jeptalnrecital-jep.82</url>
    </paper>
    <paper id="83">
      <title>Variabilité du geste palatal : effet du locuteur, de la structure syllabique et de l’accent sur différents types de consonnes en russe (Palatal gesture variability: speaker, stress and syllabic structure effects in <fixed-case>R</fixed-case>ussian)</title>
      <language>fra</language>
      <author><first>Ekaterina Biteeva</first><last>Lecocq</last></author>
      <author><first>Nathalie</first><last>Vallée</last></author>
      <author><first>Silvain</first><last>Gerber</last></author>
      <author><first>Christophe</first><last>Savariaux</last></author>
      <pages>741–749</pages>
      <abstract>Les linguistes se sont régulièrement penchés sur la description du trait consonantique [+palatal] ; pourtant, le manque de données expérimentales constitue un obstacle au classement des consonnes concernées. Peu de travaux ont abordé la question du contrôle du geste lingual dans l’articulation palatale. Cependant, ils montrent que celui-ci semble bien plus complexe que dans d’autres consonnes. En russe, la plupart des consonnes possèdent une contrepartie palatalisée ce qui permet d’étudier les différences de réalisation du trait palatal au sein du même système. Nous proposons ici, à partir de données acquises avec un articulographe électromagnétique, de caractériser la variabilité du geste palatal impliqué dans la réalisation de différents types de consonnes palatalisées et prépalatales du russe en fonction des facteurs locuteur, accent et structure syllabique.</abstract>
      <url hash="b919fff8">2016.jeptalnrecital-jep.83</url>
    </paper>
    <paper id="84">
      <title>Variation prosodique et traduction poétique (<fixed-case>LSF</fixed-case>/français) : Que devient la prosodie lorsqu’elle change de canal ? (Prosodic variation and poetic translation (<fixed-case>LSF</fixed-case>/<fixed-case>F</fixed-case>rench): What happens to prosody with a channel change?)</title>
      <language>fra</language>
      <author><first>Fanny</first><last>Catteau</last></author>
      <author><first>Marion</first><last>Blondel</last></author>
      <author><first>Coralie</first><last>Vincent</last></author>
      <author><first>Patrice</first><last>Guyot</last></author>
      <author><first>Dominique</first><last>Boutet</last></author>
      <pages>750–758</pages>
      <abstract>L’étude de la prosodie des langues vocales repose en partie sur la mesure des paramètres de durée, d’intensité et de fréquence sonores. Les langues des signes, quant à elles, empruntent le canal visuogestuel et mobilisent des articulateurs manuels et non manuels (buste, tête, éléments du visage). Notre étude a pour objectif d’établir des outils permettant de comparer, au niveau prosodique, la traduction en français de séquences poétiques et la version originale en langue des signes française (LSF). Nous avons recueilli des données vidéo augmentées de capture de mouvement – qui offrent plusieurs pistes d’exploration des paramètres prosodiques pour la LSF – ainsi que des données audio des traductions en français – qui révèlent les stratégies des interprètes pour interpréter la variation prosodique.</abstract>
      <url hash="94af2cd6">2016.jeptalnrecital-jep.84</url>
    </paper>
    <paper id="85">
      <title>Voix de femmes, voix d’hommes: une étude du voice onset time, de la répartition consonnes/voyelles et du débit de parole chez des locuteurs francophones et anglophones américains (Female and male speech: a study of <fixed-case>VOT</fixed-case>, <fixed-case>C</fixed-case>/<fixed-case>V</fixed-case> temporal distribution and speech rate in Parisian <fixed-case>F</fixed-case>rench and <fixed-case>A</fixed-case>merican <fixed-case>E</fixed-case>nglish speakers)</title>
      <language>fra</language>
      <author><first>Erwan</first><last>Pépiot</last></author>
      <pages>759–767</pages>
      <abstract>________________________________________________ La présente étude est une analyse acoustique de mots et pseudo-mots de type /CVCV/ produits par des locuteurs anglophones du nord-est des États-Unis (5 femmes, 5 hommes) et des francophones parisiens (5 femmes, 5 hommes). Le VOT des consonnes occlusives initiales, la durée des énoncés, ainsi que la répartition temporelle consonnes/voyelles ont été mesurés. Des différences inter-genres significatives ont été observées dans les deux langues sur chacun des paramètres testés : le contraste de VOT entre les occlusives sourdes et voisées s’est révélé plus important chez les locutrices, le débit de parole plus élevé chez les locuteurs masculins, et la proportion occupée par les consonnes plus importantes chez les femmes. Ces résultats suggèrent une tendance à la recherche d’une plus grande intelligibilité chez les locutrices. Les différences acoustiques femmes-hommes seraient donc en partie construites socialement.</abstract>
      <url hash="9a6232e2">2016.jeptalnrecital-jep.85</url>
    </paper>
    <paper id="86">
      <title>Voyelles moyennes en français calédonien : propriétés phonétiques acoustiques (Mid vowels in New Caledonian <fixed-case>F</fixed-case>rench: Acoustic phonetic properties)</title>
      <language>fra</language>
      <author><first>Eleanor</first><last>Lewis</last></author>
      <pages>768–776</pages>
      <abstract>Cette étude examine la réalisation des voyelles moyennes /e, ɛ, ø, œ, o, ɔ/ par dix locuteurs du français calédonien. Les propriétés formantiques de ces voyelles sont analysées en ce qui concerne le genre de syllabe dans lesquelles elles se produisent. La durée des voyelles mi-fermées et miouvertes produites en paires minimales est statistiquement comparée. Les résultats indiquent que les locuteurs de cette variété ont tendance à respecter catégoriquement la loi de position, tel que les variantes mi-fermées se présentent dans les syllabes ouvertes et les variantes mi-ouvertes se présentent dans les syllabes fermées. Il existe pourtant une certaine variation individuelle concernant le niveau de conformité à cette loi. Cette étude met également en avant des indices de l’antériorisation du /ɔ/ (et du /o/ en syllabe fermée), une caractéristique qui a été documentée dans d’autres variétés du français.</abstract>
      <url hash="80071244">2016.jeptalnrecital-jep.86</url>
    </paper>
  </volume>
  <volume id="long" ingest-date="2020-07-08">
    <meta>
      <booktitle>Actes de la conférence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Articles longs)</booktitle>
      <editor><first>Laurence</first><last>Danlos</last></editor>
      <editor><first>Thierry</first><last>Hamon</last></editor>
      <publisher>AFCP - ATALA</publisher>
      <address>Paris, France</address>
      <month>7</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="7260f25d">2016.jeptalnrecital-long.0</url>
    </frontmatter>
    <paper id="1">
      <title>Apprentissage d’analyseur en dépendances cross-lingue par projection partielle de dépendances (Cross-lingual learning of dependency parsers from partially projected dependencies )</title>
      <language>fra</language>
      <author><first>Ophélie</first><last>Lacroix</last></author>
      <author><first>Lauriane</first><last>Aufrant</last></author>
      <author><first>Guillaume</first><last>Wisniewski</last></author>
      <author><first>François</first><last>Yvon</last></author>
      <pages>1–14</pages>
      <abstract>Cet article présente une méthode simple de transfert cross-lingue de dépendances. Nous montrons tout d’abord qu’il est possible d’apprendre un analyseur en dépendances par transition à partir de données partiellement annotées. Nous proposons ensuite de construire de grands ensembles de données partiellement annotés pour plusieurs langues cibles en projetant les dépendances via les liens d’alignement les plus sûrs. En apprenant des analyseurs pour les langues cibles à partir de ces données partielles, nous montrons que cette méthode simple obtient des performances qui rivalisent avec celles de méthodes état-de-l’art récentes, tout en ayant un coût algorithmique moindre.</abstract>
      <url hash="4b088a05">2016.jeptalnrecital-long.1</url>
    </paper>
    <paper id="2">
      <title><fixed-case>B</fixed-case>leu, contusion, ecchymose : tri automatique de synonymes en fonction de leur difficulté de lecture et compréhension (Automatic ranking of synonyms according to their reading and comprehension difficulty)</title>
      <language>fra</language>
      <author><first>Thomas</first><last>Francois</last></author>
      <author><first>Mokhtar B.</first><last>Billami</last></author>
      <author><first>Núria</first><last>Gala</last></author>
      <author><first>Delphine</first><last>Bernhard</last></author>
      <pages>15–28</pages>
      <abstract>La lisibilité d’un texte dépend fortement de la difficulté des unités lexicales qui le composent. La simplification lexicale vise ainsi à remplacer les termes complexes par des équivalents sémantiques plus simples à comprendre : par exemple, BLEU (‘résultat d’un choc’) est plus simple que CONTUSION ou ECCHYMOSE. Il est pour cela nécessaire de disposer de ressources qui listent des synonymes pour des sens donnés et les trient par ordre de difficulté. Cet article décrit une méthode pour constituer une ressource de ce type pour le français. Les listes de synonymes sont extraites de BabelNet et de JeuxDeMots, puis triées grâce à un algorithme statistique d’ordonnancement. Les résultats du tri sont évalués par rapport à 36 listes de synonymes ordonnées manuellement par quarante annotateurs.</abstract>
      <url hash="ca604c40">2016.jeptalnrecital-long.2</url>
    </paper>
    <paper id="3">
      <title>Comparaison d’approches de classification automatique des actes de dialogue dans un corpus de conversations écrites en ligne sur différentes modalités (A comparison of automatic dialog act recognition approaches in a multimodal corpus of online written conversations)</title>
      <language>fra</language>
      <author><first>Soufian</first><last>Salim</last></author>
      <author><first>Nicolas</first><last>Hernandez</last></author>
      <author><first>Emmanuel</first><last>Morin</last></author>
      <pages>29–42</pages>
      <abstract>L’analyse des conversations écrites porteuses de demandes d’assistance est un enjeu important pour le développement de nouvelles technologies liées au support client. Dans cet article, nous nous intéressons à l’analyse d’un même type d’échange sur un canal différent : les conversations se déroulant sur les plate-formes d’entraide entre utilisateurs. Nous comparons des approches de classification supervisées sur trois modalités des CMR 1 différentes à même thématique : des courriels, forums et chats issus de la communauté Ubuntu. Le système emploie une taxonomie fine basée sur le schéma DIT++. D’autres expériences sont détaillées, et nous rapportons les résultats obtenus avec différentes approches et différents traits sur les différentes parties de notre corpus multimodal.</abstract>
      <url hash="a46fa5e2">2016.jeptalnrecital-long.3</url>
    </paper>
    <paper id="4">
      <title>Construire un lexique de sentiments par crowdsourcing et propagation (Building a sentiment lexicon through crowdsourcing and spreading)</title>
      <language>fra</language>
      <author><first>Mathieu</first><last>Lafourcade</last></author>
      <author><first>Nathalie Le</first><last>Brun</last></author>
      <author><first>Alain</first><last>Joubert</last></author>
      <pages>43–56</pages>
      <abstract>Cet article présente une méthode de construction d’une ressource lexicale de sentiments/émotions. Son originalité est d’associer le crowdsourcing via un GWAP (Game With A Purpose) à un algorithme de propagation, les deux ayant pour support et source de données le réseau lexical JeuxDeMots. Nous décrivons le jeu permettant de collecter des informations de sentiments, ainsi que les principes et hypothèses qui sous-tendent le fonctionnement de l’algorithme qui les propage au sein du réseau. Enfin, nous donnons les résultats quantitatifs et expliquons les méthodes d’évaluation qualitative des données obtenues, à la fois par le jeu et par la propagation par l’algorithme. Ces méthodes incluent une comparaison avec Emolex, une autre ressource de sentiments/émotions.</abstract>
      <url hash="36914ea6">2016.jeptalnrecital-long.4</url>
    </paper>
    <paper id="5">
      <title>Détection de concepts pertinents pour le résumé automatique de conversations par recombinaison de patrons (Relevant concepts detection for the automatic summary of conversations using patterns recombination )</title>
      <language>fra</language>
      <author><first>Jérémy</first><last>Trione</last></author>
      <author><first>Benoit</first><last>Favre</last></author>
      <author><first>Frederic</first><last>Bechet</last></author>
      <pages>57–69</pages>
      <abstract>automatique de conversations par recombinaison de patrons Jérémy Trione Benoit Favre Frédéric Béchet Aix-Marseille Université, CNRS, LIF UMR 7279, 13000, Marseille, France prénom.nom@lif.univ-mrs.fr R ÉSUMÉ Ce papier décrit une approche pour créer des résumés de conversations parlées par remplissage de patrons. Les patrons sont générés automatiquement à partir de fragments généralisés depuis un corpus de résumés d’apprentissage. Les informations nécessaires pour remplir les patrons sont détectées dans les transcriptions des conversations et utilisées pour sélectionner les fragments candidats. L’approche obtient un score ROUGE-2 de 0.116 sur le corpus RATP-DECODA. Les résultats obtenus montrent que cette approche abstractive est plus performante que les approches extractives utilisées habituellement dans le domaine du résumé automatique.</abstract>
      <url hash="b2ec870c">2016.jeptalnrecital-long.5</url>
    </paper>
    <paper id="6">
      <title>Détection et classification non supervisées de relations sémantiques dans des articles scientifiques (Unsupervised Classification of Semantic Relations in Scientific Papers)</title>
      <language>fra</language>
      <author><first>Kata</first><last>Gábor</last></author>
      <author><first>Isabelle</first><last>Tellier</last></author>
      <author><first>Thierry</first><last>Charnois</last></author>
      <author><first>Haïfa</first><last>Zargayouna</last></author>
      <author><first>Davide</first><last>Buscaldi</last></author>
      <pages>70–83</pages>
      <abstract>Dans cet article, nous abordons une tâche encore peu explorée, consistant à extraire automatiquement l’état de l’art d’un domaine scientifique à partir de l’analyse d’articles de ce domaine. Nous la ramenons à deux sous-tâches élémentaires : l’identification de concepts et la reconnaissance de relations entre ces concepts. Une extraction terminologique permet d’identifier les concepts candidats, qui sont ensuite alignés à des ressources externes. Dans un deuxième temps, nous cherchons à reconnaître et classifier automatiquement les relations sémantiques entre concepts de manière nonsupervisée, en nous appuyant sur différentes techniques de clustering et de biclustering. Nous mettons en œuvre ces deux étapes dans un corpus extrait de l’archive de l’ACL Anthology. Une analyse manuelle nous a permis de proposer une typologie des relations sémantiques, et de classifier un échantillon d’instances de relations. Les premières évaluations suggèrent l’intérêt du biclustering pour détecter de nouveaux types de relations dans le corpus.</abstract>
      <url hash="b803b9d2">2016.jeptalnrecital-long.6</url>
    </paper>
    <paper id="7">
      <title>Etude de l’impact d’un lexique bilingue spécialisé sur la performance d’un moteur de traduction à base d’exemples (Studying the impact of a specialized bilingual lexicon on the performance of an example-based machine translation engine)</title>
      <language>fra</language>
      <author><first>Nasredine</first><last>Semmar</last></author>
      <author><first>Othman</first><last>Zennaki</last></author>
      <author><first>Meriama</first><last>Laib</last></author>
      <pages>84–97</pages>
      <abstract>La traduction automatique statistique bien que performante est aujourd’hui limitée parce qu’elle nécessite de gros volumes de corpus parallèles qui n’existent pas pour tous les couples de langues et toutes les spécialités et que leur production est lente et coûteuse. Nous présentons, dans cet article, un prototype d’un moteur de traduction à base d’exemples utilisant la recherche d’information interlingue et ne nécessitant qu’un corpus de textes en langue cible. Plus particulièrement, nous proposons d’étudier l’impact d’un lexique bilingue de spécialité sur la performance de ce prototype. Nous évaluons ce prototype de traduction et comparons ses résultats à ceux du système de traduction statistique Moses en utilisant les corpus parallèles anglais-français Europarl (European Parliament Proceedings) et Emea (European Medicines Agency Documents). Les résultats obtenus montrent que le score BLEU du prototype du moteur de traduction à base d’exemples est proche de celui du système Moses sur des documents issus du corpus Europarl et meilleur sur des documents extraits du corpus Emea.</abstract>
      <url hash="4b9a74ba">2016.jeptalnrecital-long.7</url>
    </paper>
    <paper id="8">
      <title>Étude des réseaux de neurones récurrents pour étiquetage de séquences (A study of Recurrent Neural Networks for Sequence Labelling)</title>
      <language>fra</language>
      <author><first>Marco</first><last>Dinarelli</last></author>
      <author><first>Isabelle</first><last>Tellier</last></author>
      <pages>98–111</pages>
      <abstract>Dans cet article nous étudions plusieurs types de réseaux neuronaux récurrents (RNN) pour l’étiquetage de séquences. Nous proposons deux nouvelles variantes de RNN et nous les comparons aux variantes plus classiques de type Jordan et Elman. Nous expliquons en détails quels sont les avantages de nos nouvelles variantes par rapport aux autres RNN. Nous évaluons tous les modèles, les nouvelles variantes ainsi que les RNN existants, sur deux tâches de compréhension de la parole : ATIS et MEDIA. Les résultats montrent que nos nouvelles variantes de RNN sont plus efficaces que les autres.</abstract>
      <url hash="668147cf">2016.jeptalnrecital-long.8</url>
    </paper>
    <paper id="9">
      <title>Évaluation de l’apprentissage incrémental par analogie (Incremental Learning From Scratch Using Analogical Reasoning )</title>
      <language>fra</language>
      <author><first>Vincent</first><last>Letard</last></author>
      <author><first>Gabriel</first><last>Illouz</last></author>
      <author><first>Sophie</first><last>Rosset</last></author>
      <pages>112–124</pages>
      <abstract>Cet article examine l’utilisation du raisonnement analogique dans le contexte de l’apprentissage incrémental. Le problème d’apprentissage sous-jacent développé est le transfert de requêtes formulées en langue naturelle vers des commandes dans un langage de programmation. Nous y explorons deux questions principales : Comment se comporte le raisonnement par analogie dans le contexte de l’apprentissage incrémental ? De quelle manière la séquence d’apprentissage influence-t-elle la performance globale ? Pour y répondre, nous proposons un protocole expérimental simulant deux utilisateurs et différentes séquences d’apprentissage. Nous montrons que l’ordre dans la séquence d’apprentissage incrémental n’a d’influence notable que sous des conditions spécifiques. Nous constatons également la complémentarité de l’apprentissage incrémental avec l’analogie pour un nombre d’exemples d’apprentissage minimal.</abstract>
      <url hash="1bd02ab5">2016.jeptalnrecital-long.9</url>
    </paper>
    <paper id="10">
      <title>Évaluation des modèles sémantiques distributionnels : le cas de la dérivation syntaxique (Evaluation of distributional semantic models : The case of syntactic derivation )</title>
      <language>fra</language>
      <author><first>Gabriel</first><last>Bernier-Colborne</last></author>
      <author><first>Patrick</first><last>Drouin</last></author>
      <pages>125–138</pages>
      <abstract>Nous évaluons deux modèles sémantiques distributionnels au moyen d’un jeu de données représentant quatre types de relations lexicales et analysons l’influence des paramètres des deux modèles. Les résultats indiquent que le modèle qui offre les meilleurs résultats dépend des relations ciblées, et que l’influence des paramètres des deux modèles varie considérablement en fonction de ce facteur. Ils montrent également que ces modèles captent aussi bien la dérivation syntaxique que la synonymie, mais que les configurations qui captent le mieux ces deux types de relations sont très différentes.</abstract>
      <url hash="6e5e212c">2016.jeptalnrecital-long.10</url>
    </paper>
    <paper id="11">
      <title>Évaluation dune nouvelle structuration thématique hiérarchique des textes dans un cadre de résumé automatique et de détection d’ancres au sein de vidéos (Evaluation of a novel hierarchical thematic structuring of texts in the framework of text summarization and anchor detection for video hyperlinking )</title>
      <language>fra</language>
      <author><first>Anca</first><last>Simon</last></author>
      <author><first>Guillaume</first><last>Gravier</last></author>
      <author><first>Pascale</first><last>Sébillot</last></author>
      <pages>139–152</pages>
      <abstract>automatique et de détection d’ancres au sein de vidéos Anca Simon1 Guillaume Gravier2 Pascale Sébillot3 (1) Université de Rennes 1, IRISA &amp; INRIA Rennes, Campus de Beaulieu, 35042 Rennes, France (2) CNRS, IRISA &amp; INRIA Rennes, Campus de Beaulieu, 35042 Rennes, France (3) INSA, IRISA &amp; INRIA Rennes, Campus de Beaulieu, 35042 Rennes, France anca.simon@irisa.fr, guillaume.gravier@irisa.fr, pascale.sebillot@irisa.fr R ÉSUMÉ Dans cet article, nous évaluons, à travers son intérêt pour le résumé automatique et la détection d’ancres dans des vidéos, le potentiel d’une nouvelle structure thématique extraite de données textuelles, composée d’une hiérarchie de fragments thématiquement focalisés. Cette structure est produite par un algorithme exploitant les distributions temporelles d’apparition des mots dans les textes en se fondant sur une analyse de salves lexicales. La hiérarchie obtenue a pour objet de filtrer le contenu non crucial et de ne conserver que l’information saillante des textes, à différents niveaux de détail. Nous montrons qu’elle permet d’améliorer la production de résumés ou au moins de maintenir les résultats de l’état de l’art, tandis que pour la détection d’ancres, elle nous conduit à la meilleure précision dans le contexte de la tâche Search and Anchoring in Video Archives à MediaEval. Les expériences sont réalisées sur du texte écrit et sur un corpus de transcriptions automatiques d’émissions de télévision.</abstract>
      <url hash="6dc196aa">2016.jeptalnrecital-long.11</url>
    </paper>
    <paper id="12">
      <title>Exploitation de reformulations pour l’acquisition d’un vocabulaire expert/non expert (Exploitation of reformulations for the acquisition of expert/non-expert vocabulary)</title>
      <language>fra</language>
      <author><first>Edwige</first><last>Antoine</last></author>
      <author><first>Natalia</first><last>Grabar</last></author>
      <pages>153–166</pages>
      <abstract>Les notions de domaines techniques, comme les notions médicales, présentent souvent des difficultés de compréhension par les non experts. Un vocabulaire qui associe les termes techniques aux expressions grand public peut aider à rendre les textes techniques mieux compréhensibles. L’objectif de notre travail est de construire un tel vocabulaire. Nous proposons d’exploiter la notion de reformulation grâce à trois méthodes : extraction d’abréviations, exploitation de marqueurs de reformulation et de parenthèses. Les segments associés grâce à ces méthodes sont alignés avec les terminologies médicales. Nos résultats permettent de couvrir un grand nombre de termes médicaux et montrent une précision d’extraction entre 0,68 et 0,98. Au total, plusieurs dizaines de milliers de paires sont proposés. Ces résultats sont analysés et comparés avec les travaux existants.</abstract>
      <url hash="24348280">2016.jeptalnrecital-long.12</url>
    </paper>
    <paper id="13">
      <title>Extension lexicale de définitions grâce à des corpus annotés en sens (Lexical Expansion of definitions based on sense-annotated corpus )</title>
      <language>fra</language>
      <author><first>Loïc</first><last>Vial</last></author>
      <author><first>Andon</first><last>Tchechmedjiev</last></author>
      <author><first>Didier</first><last>Schwab</last></author>
      <pages>167–179</pages>
      <abstract>Pour un certain nombre de tâches ou d’applications du TALN, il est nécessaire de déterminer la proximité sémantique entre des sens, des mots ou des segments textuels. Dans cet article, nous nous intéressons à une mesure basée sur des savoirs, la mesure de Lesk. La proximité sémantique de deux définitions est évaluée en comptant le nombre de mots communs dans les définitions correspondantes dans un dictionnaire. Dans cet article, nous étudions plus particulièrement l’extension de définitions grâce à des corpus annotés en sens. Il s’agit de prendre en compte les mots qui sont utilisés dans le voisinage d’un certain sens et d’étendre lexicalement la définition correspondante. Nous montrons une amélioration certaine des performances obtenues en désambiguïsation lexicale qui dépassent l’état de l’art.</abstract>
      <url hash="2928a2ac">2016.jeptalnrecital-long.13</url>
    </paper>
    <paper id="14">
      <title>Extraction de lexiques bilingues à partir de corpus comparables spécialisés à travers une langue pivot (Bilingual lexicon extraction from specialized comparable corpora using a pivot language)</title>
      <language>fra</language>
      <author><first>Alexis</first><last>Linard</last></author>
      <author><first>Emmanuel</first><last>Morin</last></author>
      <author><first>Béatrice</first><last>Daille</last></author>
      <pages>180–193</pages>
      <abstract>L’extraction de lexiques bilingues à partir de corpus comparables se réalise traditionnellement en s’appuyant sur deux langues. Des travaux précédents en extraction de lexiques bilingues à partir de corpus parallèles ont démontré que l’utilisation de plus de deux langues peut être utile pour améliorer la qualité des alignements extraits. Nos travaux montrent qu’il est possible d’utiliser la même stratégie pour des corpus comparables. Nous avons défini deux méthodes originales impliquant des langues pivots et nous les avons évaluées sur quatre langues et deux langues pivots en particulier. Nos expérimentations ont montré que lorsque l’alignement entre la langue source et la langue pivot est de bonne qualité, l’extraction du lexique en langue cible s’en trouve améliorée.</abstract>
      <url hash="514cde1c">2016.jeptalnrecital-long.14</url>
    </paper>
    <paper id="15">
      <title>Fouille de motifs et <fixed-case>CRF</fixed-case> pour la reconnaissance de symptômes dans les textes biomédicaux (Pattern mining and <fixed-case>CRF</fixed-case> for symptoms recognition in biomedical texts)</title>
      <language>fra</language>
      <author><first>Pierre</first><last>Holat</last></author>
      <author><first>Nadi</first><last>Tomeh</last></author>
      <author><first>Thierry</first><last>Charnois</last></author>
      <author><first>Delphine</first><last>Battistelli</last></author>
      <author><first>Marie-Christine</first><last>Jaulent</last></author>
      <author><first>Jean-Philippe</first><last>Métivier</last></author>
      <pages>194–206</pages>
      <abstract>Dans cet article, nous nous intéressons à l’extraction d’entités médicales de type symptôme dans les textes biomédicaux. Cette tâche est peu explorée dans la littérature et il n’existe pas à notre connaissance de corpus annoté pour entraîner un modèle d’apprentissage. Nous proposons deux approches faiblement supervisées pour extraire ces entités. Une première est fondée sur la fouille de motifs et introduit une nouvelle contrainte de similarité sémantique. La seconde formule la tache comme une tache d’étiquetage de séquences en utilisant les CRF (champs conditionnels aléatoires). Nous décrivons les expérimentations menées qui montrent que les deux approches sont complémentaires en termes d’évaluation quantitative (rappel et précision). Nous montrons en outre que leur combinaison améliore sensiblement les résultats.</abstract>
      <url hash="cd76006b">2016.jeptalnrecital-long.15</url>
    </paper>
    <paper id="16">
      <title>Une méthode non-supervisée pour la segmentation morphologique et l’apprentissage de morphotactique à l’aide de processus de <fixed-case>P</fixed-case>itman-<fixed-case>Y</fixed-case>or (An unsupervised method for joint morphological segmentation and morphotactics learning using <fixed-case>P</fixed-case>itman-<fixed-case>Y</fixed-case>or processes)</title>
      <language>fra</language>
      <author><first>Kevin</first><last>Löser</last></author>
      <author><first>Alexandre</first><last>Allauzen</last></author>
      <pages>207–220</pages>
      <abstract>Cet article présente un modèle bayésien non-paramétrique pour la segmentation morphologique non supervisée. Ce modèle semi-markovien s’appuie sur des classes latentes de morphèmes afin de modéliser les caractéristiques morphotactiques du lexique, et son caractère non-paramétrique lui permet de s’adapter aux données sans avoir à spécifier à l’avance l’inventaire des morphèmes ainsi que leurs classes. Un processus de Pitman-Yor est utilisé comme a priori sur les paramètres afin d’éviter une convergence vers des solutions dégénérées et inadaptées au traitemement automatique des langues. Les résultats expérimentaux montrent la pertinence des segmentations obtenues pour le turc et l’anglais. Une étude qualitative montre également que le modèle infère une morphotactique linguistiquement pertinente, sans le recours à des connaissances expertes quant à la structure morphologique des formes de mots.</abstract>
      <url hash="c8cd55ad">2016.jeptalnrecital-long.16</url>
    </paper>
    <paper id="17">
      <title>Modèles adaptatifs pour prédire automatiquement la compétence lexicale d’un apprenant de français langue étrangère (Adaptive models for automatically predicting the lexical competence of <fixed-case>F</fixed-case>rench as a foreign language learners)</title>
      <language>fra</language>
      <author><first>Anaïs</first><last>Tack</last></author>
      <author><first>Thomas</first><last>François</last></author>
      <author><first>Anne-Laure</first><last>Ligozat</last></author>
      <author><first>Cédrick</first><last>Fairon</last></author>
      <pages>221–234</pages>
      <abstract>Cette étude examine l’utilisation de méthodes d’apprentissage incrémental supervisé afin de prédire la compétence lexicale d’apprenants de français langue étrangère (FLE). Les apprenants ciblés sont des néerlandophones ayant un niveau A2/B1 selon le Cadre européen commun de référence pour les langues (CECR). À l’instar des travaux récents portant sur la prédiction de la maîtrise lexicale à l’aide d’indices de complexité, nous élaborons deux types de modèles qui s’adaptent en fonction d’un retour d’expérience, révélant les connaissances de l’apprenant. En particulier, nous définissons (i) un modèle qui prédit la compétence lexicale de tous les apprenants du même niveau de maîtrise et (ii) un modèle qui prédit la compétence lexicale d’un apprenant individuel. Les modèles obtenus sont ensuite évalués par rapport à un modèle de référence déterminant la compétence lexicale à partir d’un lexique spécialisé pour le FLE et s’avèrent gagner significativement en exactitude (9%-17%).</abstract>
      <url hash="6dcf088f">2016.jeptalnrecital-long.17</url>
    </paper>
    <paper id="18">
      <title>Modélisation unifiée du document et de son domaine pour une indexation par termes-clés libre et contrôlée (Unified document and domain-specific model for keyphrase extraction and assignment )</title>
      <language>fra</language>
      <author><first>Adrien</first><last>Bougouin</last></author>
      <author><first>Florian</first><last>Boudin</last></author>
      <author><first>Beatrice</first><last>Daille</last></author>
      <pages>235–247</pages>
      <abstract>Dans cet article, nous nous intéressons à l’indexation de documents de domaines de spécialité par l’intermédiaire de leurs termes-clés. Plus particulièrement, nous nous intéressons à l’indexation telle qu’elle est réalisée par les documentalistes de bibliothèques numériques. Après analyse de la méthodologie de ces indexeurs professionnels, nous proposons une méthode à base de graphe combinant les informations présentes dans le document et la connaissance du domaine pour réaliser une indexation (hybride) libre et contrôlée. Notre méthode permet de proposer des termes-clés ne se trouvant pas nécessairement dans le document. Nos expériences montrent aussi que notre méthode surpasse significativement l’approche à base de graphe état de l’art.</abstract>
      <url hash="a530d2e9">2016.jeptalnrecital-long.18</url>
    </paper>
    <paper id="19">
      <title>Ne nous arrêtons pas en si bon chemin : améliorations de l’apprentissage global d’analyseurs en dépendances par transition (Don’t Stop Me Now ! Improved Update Strategies for Global Training of Transition-Based)</title>
      <language>fra</language>
      <author><first>Lauriane</first><last>Aufrant</last></author>
      <author><first>Guillaume</first><last>Wisniewski</last></author>
      <author><first>François</first><last>Yvon</last></author>
      <pages>248–261</pages>
      <abstract>Dans cet article, nous proposons trois améliorations simples pour l’apprentissage global d’analyseurs en dépendances par transition de type A RC E AGER : un oracle non déterministe, la reprise sur le même exemple après une mise à jour et l’entraînement en configurations sous-optimales. Leur combinaison apporte un gain moyen de 0,2 UAS sur le corpus SPMRL. Nous introduisons également un cadre général permettant la comparaison systématique de ces stratégies et de la plupart des variantes connues. Nous montrons que la littérature n’a étudié que quelques stratégies parmi les nombreuses variations possibles, négligeant ainsi plusieurs pistes d’améliorations potentielles.</abstract>
      <url hash="862dc838">2016.jeptalnrecital-long.19</url>
    </paper>
    <paper id="20">
      <title>Prédiction automatique de fonctions pragmatiques dans les reformulations (Automatic prediction of pragmatic functions in reformulations)</title>
      <language>fra</language>
      <author><first>Natalia</first><last>Grabar</last></author>
      <author><first>Iris</first><last>Eshkol-Taravella</last></author>
      <pages>262–275</pages>
      <abstract>La reformulation participe à la structuration du discours, notamment dans le cas des dialogues, et contribue également à la dynamique du discours. Reformuler est un acte significatif qui poursuit des objectifs précis. L’objectif de notre travail est de prédire automatiquement la raison pour laquelle un locuteur effectue une reformulation. Nous utilisons une classification de onze fonctions pragmatiques inspirées des travaux existants et des données analysées. Les données de référence sont issues d’annotations manuelles et consensuelles des reformulations spontanées formées autour de trois marqueurs (c’est-à-dire, je veux dire, disons). Les données proviennent d’un corpus oral et d’un corpus de discussions sur les forums de santé. Nous exploitons des algorithmes de catégorisation supervisée et un ensemble de plusieurs descripteurs (syntaxiques, formels, sémantiques et discursifs) pour prédire les catégories de reformulation. La distribution des énoncés et phrases selon les catégories n’est pas homogène. Les expériences sont positionnées à deux niveaux : générique et spécifique. Nos résultats indiquent qu’il est plus facile de prédire les types de fonctions au niveau générique (la moyenne des F-mesures est autour de 0,80), qu’au niveau des catégories individuelles (la moyenne des F-mesures est autour de 0,40). L’influence de différents paramètres est étudiée.</abstract>
      <url hash="8d07a065">2016.jeptalnrecital-long.20</url>
    </paper>
    <paper id="21">
      <title>Projection Interlingue d’Étiquettes pour l’Annotation Sémantique Non Supervisée (Cross-lingual Annotation Projection for Unsupervised Semantic Tagging)</title>
      <language>fra</language>
      <author><first>Othman</first><last>Zennaki</last></author>
      <author><first>Nasredine</first><last>Semmar</last></author>
      <author><first>Laurent</first><last>Besacier</last></author>
      <pages>276–289</pages>
      <abstract>Nos travaux portent sur la construction rapide d’outils d’analyse linguistique pour des langues peu dotées en ressources. Dans une précédente contribution, nous avons proposé une méthode pour la construction automatique d’un analyseur morpho-syntaxique via une projection interlingue d’annotations linguistiques à partir de corpus parallèles (méthode fondée sur les réseaux de neurones récurrents). Nous présentons, dans cet article, une amélioration de notre modèle neuronal, avec la prise en compte d’informations linguistiques externes pour un annotateur plus complexe. En particulier, nous proposons d’intégrer des annotations morpho-syntaxiques dans notre architecture neuronale pour l’apprentissage non supervisé d’annotateurs sémantiques multilingues à gros grain (annotation en SuperSenses). Nous montrons la validité de notre méthode et sa généricité sur l’italien et le français et étudions aussi l’impact de la qualité du corpus parallèle sur notre approche (généré par traduction manuelle ou automatique). Nos expériences portent sur la projection d’annotations de l’anglais vers le français et l’italien.</abstract>
      <url hash="5fe2ddac">2016.jeptalnrecital-long.21</url>
    </paper>
    <paper id="22">
      <title>Utilisation des relations d’une base de connaissances pour la désambiguïsation d’entités nommées (Using the Relations of a Knowledge Base to Improve Entity Linking )</title>
      <language>fra</language>
      <author><first>Romaric</first><last>Besançon</last></author>
      <author><first>Hani</first><last>Daher</last></author>
      <author><first>Olivier</first><last>Ferret</last></author>
      <author><first>Hervé</first><last>Le Borgne</last></author>
      <pages>290–303</pages>
      <abstract>L’identification des entités nommées dans un texte est une tâche essentielle des outils d’extraction d’information dans de nombreuses applications. Cette identification passe par la reconnaissance d’une mention d’entité dans le texte, ce qui a été très largement étudié, et par l’association des entités reconnues à des entités connues, présentes dans une base de connaissances. Cette association repose souvent sur une mesure de similarité entre le contexte textuel de la mention de l’entité et un contexte textuel de description des entités de la base de connaissances. Or, ce contexte de description n’est en général pas présent pour toutes les entités. Nous proposons d’exploiter les relations de la base de connaissances pour ajouter un indice de désambiguïsation pour ces entités. Nous évaluons notre travail sur des corpus d’évaluation standards en anglais issus de la tâche de désambiguïsation d’entités de la campagne TAC-KBP.</abstract>
      <url hash="67e4434f">2016.jeptalnrecital-long.22</url>
    </paper>
    <paper id="23">
      <title><fixed-case>W</fixed-case>ord2<fixed-case>V</fixed-case>ec vs <fixed-case>DB</fixed-case>nary ou comment (ré)concilier représentations distribuées et réseaux lexico-sémantiques ? Le cas de l’évaluation en traduction automatique (<fixed-case>W</fixed-case>ord2<fixed-case>V</fixed-case>ec vs <fixed-case>DB</fixed-case>nary or how to bring back together vector representations and lexical resources ? A case study for machine translation evaluation)</title>
      <language>fra</language>
      <author><first>Christophe</first><last>Servan</last></author>
      <author><first>Zied</first><last>Elloumi</last></author>
      <author><first>Hervé</first><last>Blanchon</last></author>
      <author><first>Laurent</first><last>Besacier</last></author>
      <pages>304–317</pages>
      <abstract>Cet article présente une approche associant réseaux lexico-sémantiques et représentations distribuées de mots appliquée à l’évaluation de la traduction automatique. Cette étude est faite à travers l’enrichissement d’une métrique bien connue pour évaluer la traduction automatique (TA) : METEOR. METEOR permet un appariement approché (similarité morphologique ou synonymie) entre une sortie de système automatique et une traduction de référence. Nos expérimentations s’appuient sur la tâche Metrics de la campagne d’évaluation WMT 2014 et montrent que les représentations distribuées restent moins performantes que les ressources lexico-sémantiques pour l’évaluation en TA mais peuvent néammoins apporter un complément d’information intéressant à ces dernières.</abstract>
      <url hash="15d533fc">2016.jeptalnrecital-long.23</url>
    </paper>
  </volume>
  <volume id="poster" ingest-date="2020-07-08">
    <meta>
      <booktitle>Actes de la conférence conjointe JEP-TALN-RECITAL 2016. volume 2 : TALN (Posters)</booktitle>
      <editor><first>Laurence</first><last>Danlos</last></editor>
      <editor><first>Thierry</first><last>Hamon</last></editor>
      <publisher>AFCP - ATALA</publisher>
      <address>Paris, France</address>
      <month>7</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="7260f25d">2016.jeptalnrecital-poster.0</url>
    </frontmatter>
    <paper id="1">
      <title>Amélioration de la traduction automatique d’un corpus annoté (Improvement of the automatic translation of an annotated corpus)</title>
      <language>fra</language>
      <author><first>Marwa Hadj</first><last>Salah</last></author>
      <author><first>Hervé</first><last>Blanchon</last></author>
      <author><first>Mounir</first><last>Zrigui</last></author>
      <author><first>Didier</first><last>Schwab</last></author>
      <pages>318–324</pages>
      <abstract>Dans cet article, nous présentons une méthode pour améliorer la traduction automatique d’un corpus annoté et porter ses annotations de l’anglais vers une langue cible. Il s’agit d’améliorer la méthode de (Nasiruddin et al., 2015) qui donnait de nombreux segments non traduits, des duplications et des désordres. Nous proposons un processus de pré-traitement du SemCor anglais, pour qu’il soit adapté au système de traduction automatique statistique utilisé, ainsi qu’un processus de post-traitement pour la sortie. Nous montrons une augmentation de 2,9 points en terme de score F1 sur une tâche de désambiguïsation lexicale ce qui prouve l’efficacité de notre méthode.</abstract>
      <url hash="0158cdd9">2016.jeptalnrecital-poster.1</url>
    </paper>
    <paper id="2">
      <title>Analyse d’une tâche de substitution lexicale : quelles sont les sources de difficulté ? (Difficulty analysis for a lexical substitution task)</title>
      <language>fra</language>
      <author><first>Ludovic</first><last>Tanguy</last></author>
      <author><first>Cécile</first><last>Fabre</last></author>
      <author><first>Camille</first><last>Mercier</last></author>
      <pages>325–332</pages>
      <abstract>Nous proposons dans cet article une analyse des résultats de la campagne SemDis 2014 qui proposait une tâche de substitution lexicale en français. Pour les 300 phrases du jeu de test, des annotateurs ont proposé des substituts à un mot cible, permettant ainsi d’établir un gold standard sur lequel les systèmes participants ont été évalués. Nous cherchons à identifier les principales caractéristiques des items du jeu de test qui peuvent expliquer les variations de performance pour les humains comme pour les systèmes, en nous basant sur l’accord inter-annotateurs des premiers et les scores de rappel des seconds. Nous montrons que si plusieurs caractéristiques communes sont associées aux deux types de difficulté (rareté du sens dans lequel le mot-cible est employé, fréquence d’emploi du mot-cible), d’autres sont spécifiques aux systèmes (degré de polysémie du mot-cible, complexité syntaxique).</abstract>
      <url hash="08dd84ba">2016.jeptalnrecital-poster.2</url>
    </paper>
    <paper id="3">
      <title>L’anti-correcteur : outil d’évaluation positive de l’orthographe et de la grammaire (The ”anticorrecteur”: a positive evaluation module for spell and grammar checking)</title>
      <language>fra</language>
      <author><first>Lydia-Mai</first><last>Ho-Dac</last></author>
      <author><first>Sophie</first><last>Muller</last></author>
      <author><first>Valentine</first><last>Delbar</last></author>
      <pages>333–341</pages>
      <abstract>L’objectif de cette étude est d’expérimenter l’intégration d’une nouvelle forme d’évaluation dans un correcteur orthographique et grammatical. L’« anticorrecteur » a pour objet de mesurer le taux de réussites orthographiques et grammaticales d’un texte sur certains points jugés difficiles selon la littérature et une observation d’erreurs en corpus. L’évaluation du niveau d’écriture ne se base plus uniquement sur les erreurs commises, mais également sur les réussites réalisées. Une version bêta de ce nouveau mode d’évaluation positive a été intégré dans le correcteur Cordial. Cet article a pour but de discuter de l’intérêt de ce nouveau rapport à l’orthographe et de présenter quelques premiers éléments d’analyse résultant de l’application de l’anticorrecteur sur un corpus de productions variées en matière de niveau d’écriture et genre discursif. Ici, un résumé en français (max. 150 mots). Times, 10pt.</abstract>
      <url hash="7d02cc28">2016.jeptalnrecital-poster.3</url>
    </paper>
    <paper id="4">
      <title>Appariement d’articles en ligne et de vidéos : stratégies de sélection et méthodes d’évaluation (Pairing On-line News Articles to Videos : Selection Strategies and Evaluation Methods)</title>
      <language>fra</language>
      <author><first>Adèle</first><last>Désoyer</last></author>
      <author><first>Delphine</first><last>Battistelli</last></author>
      <author><first>Jean-Luc</first><last>Minel</last></author>
      <pages>342–348</pages>
      <abstract>Dans cet article, nous proposons une méthode d’appariement de contenus d’actualité multimédias, considérant les exigences à la fois sémantiques et temporelles du besoin d’information. La pertinence d’une vidéo pour un article de presse est mesurée par deux indices, l’un saisissant la similarité de leurs contenus, l’autre la cohérence de leurs dates d’édition. Nous présentons également une méthodologie d’évaluation s’affranchissant des standards comparant les résultats du système à des résultats de référence, en soumettant les paires de documents proposées automatiquement à un panel d’utilisateurs chargé de juger de leur pertinence.</abstract>
      <url hash="67ada2e3">2016.jeptalnrecital-poster.4</url>
    </paper>
    <paper id="5">
      <title>Approximate unsupervised summary optimisation for selections of <fixed-case>ROUGE</fixed-case></title>
      <author><first>Natalie</first><last>Schluter</last></author>
      <author><first>Héctor</first><last>Martínez Alonso</last></author>
      <pages>349–354</pages>
      <abstract>Approximate summary optimisation for selections of ROUGE It is standard to measure automatic summariser performance using the ROUGE metric. Unfortunately, ROUGE is not appropriate for unsupervised summarisation approaches. On the other hand, we show that it is possible to optimise approximately for ROUGE-n by using a document-weighted ROUGE objective. Doing so results in state-of-the-art summariser performance for single and multiple document summaries for both English and French. This is despite a non-correlation of the documentweighted ROUGE metric with human judgments, unlike the original ROUGE metric. These findings suggest a theoretical approximation link between the two metrics.</abstract>
      <url hash="21c32400">2016.jeptalnrecital-poster.5</url>
    </paper>
    <paper id="6">
      <title>L’architecture d’un modèle hybride pour la normalisation de <fixed-case>SMS</fixed-case> (A hybrid model architecture for <fixed-case>SMS</fixed-case> normalization)</title>
      <language>fra</language>
      <author><first>Eleni</first><last>Kogkitsidou</last></author>
      <author><first>Georges</first><last>Antoniadis</last></author>
      <pages>355–363</pages>
      <abstract>La communication par SMS (Short Message Service), aussi bien que tout autre type de communication virtuelle sous forme de textes courts (mails, microblogs, tweets, etc.), présente certaines particularités spécifiques (syntaxe irrégulière, fusionnement et phonétisation de mots, formes abrégées, etc.). A cause de ces caractéristiques, l’application d’outils en Traitement Automatique du Langage (TAL) rend difficile l’exploitation d’informations utiles contenues dans des messages bruités. Nous proposons un modèle de normalisation en deux étapes fondé sur une approche symbolique et statistique. La première partie vise à produire une représentation intermédiaire du message SMS par l’application des grammaires locales, tandis que la deuxième utilise un système de traduction automatique à base de règles pour convertir la représentation intermédiaire vers une forme standard.</abstract>
      <url hash="8b533f14">2016.jeptalnrecital-poster.6</url>
    </paper>
    <paper id="7">
      <title>Une catégorisation de fins de lignes non-supervisée (End-of-line classification with no supervision)</title>
      <language>fra</language>
      <author><first>Pierre</first><last>Zweigenbaum</last></author>
      <author><first>Cyril</first><last>Grouin</last></author>
      <author><first>Thomas</first><last>Lavergne</last></author>
      <pages>364–371</pages>
      <abstract>Dans certains textes bruts, les marques de fin de ligne peuvent marquer ou pas la frontière d’une unité textuelle (typiquement un paragraphe). Ce problème risque d’influencer les traitements subséquents, mais est rarement traité dans la littérature. Nous proposons une méthode entièrement non-supervisée pour déterminer si une fin de ligne doit être vue comme un simple espace ou comme une véritable frontière d’unité textuelle, et la testons sur un corpus de comptes rendus médicaux. Cette méthode obtient une F-mesure de 0,926 sur un échantillon de 24 textes contenant des lignes repliées. Appliquée sur un échantillon plus grand de textes contenant ou pas des lignes repliées, notre méthode la plus prudente obtient une F-mesure de 0,898, valeur élevée pour une méthode entièrement non-supervisée.</abstract>
      <url hash="f3a8d207">2016.jeptalnrecital-poster.7</url>
    </paper>
    <paper id="8">
      <title>Classification automatique de dictées selon leur niveau de difficulté de compréhension et orthographique (Automatic classification of dictations according to their complexity for comprehension and writing production)</title>
      <language>fra</language>
      <author><first>Adeline</first><last>Müller</last></author>
      <author><first>Thomas</first><last>Francois</last></author>
      <author><first>Sophie</first><last>Roekhaut</last></author>
      <author><first>Cedrick</first><last>Fairon</last></author>
      <pages>372–380</pages>
      <abstract>Cet article présente une approche visant à évaluer automatiquement la difficulté de dictées en vue de les intégrer dans une plateforme d’apprentissage de l’orthographe. La particularité de l’exercice de la dictée est de devoir percevoir du code oral et de le retranscrire via le code écrit. Nous envisageons ce double niveau de difficulté à l’aide de 375 variables mesurant la difficulté de compréhension d’un texte ainsi que les phénomènes orthographiques et grammaticaux complexes qu’il contient. Un sous-ensemble optimal de ces variables est combiné à l’aide d’un modèle par machines à vecteurs de support (SVM) qui classe correctement 56% des textes. Les variables lexicales basées sur la liste orthographique de Catach (1984) se révèlent les plus informatives pour le modèle.</abstract>
      <url hash="1065e5ce">2016.jeptalnrecital-poster.8</url>
    </paper>
    <paper id="9">
      <title>Combiner des modèles sémantiques distributionnels pour mieux détecter les termes évoquant le même cadre sémantique (Combining distributional semantic models to improve the identification of terms that evoke the same semantic frame)</title>
      <language>fra</language>
      <author><first>Gabriel</first><last>Bernier-Colborne</last></author>
      <author><first>Patrick</first><last>Drouin</last></author>
      <pages>381–388</pages>
      <abstract>Nous utilisons des modèles sémantiques distributionnels pour détecter des termes qui évoquent le même cadre sémantique. Dans cet article, nous vérifions si une combinaison de différents modèles permet d’obtenir une précision plus élevée qu’un modèle unique. Nous mettons à l’épreuve plusieurs méthodes simples pour combiner les mesures de similarité calculées à partir de chaque modèle. Les résultats indiquent qu’on obtient systématiquement une augmentation de la précision par rapport au meilleur modèle unique en combinant des modèles différents.</abstract>
      <url hash="b2999a9a">2016.jeptalnrecital-poster.9</url>
    </paper>
    <paper id="10">
      <title>Comparing Named-Entity Recognizers in a Targeted Domain: Handcrafted Rules vs Machine Learning</title>
      <author><first>Ioannis</first><last>Partalas</last></author>
      <author><first>Cédric</first><last>Lopez</last></author>
      <author><first>Frédérique</first><last>Segond</last></author>
      <pages>389–395</pages>
      <abstract>Comparing Named-Entity Recognizers in a Targeted Domain : Handcrafted Rules vs. Machine Learning Named-Entity Recognition concerns the classification of textual objects in a predefined set of categories such as persons, organizations, and localizations. While Named-Entity Recognition is well studied since 20 years, the application to specialized domains still poses challenges for current systems. We developed a rule-based system and two machine learning approaches to tackle the same task : recognition of product names, brand names, etc., in the domain of Cosmetics, for French. Our systems can thus be compared under ideal conditions. In this paper, we introduce both systems and we compare them.</abstract>
      <url hash="a5c636c2">2016.jeptalnrecital-poster.10</url>
    </paper>
    <paper id="11">
      <title>Compilation de grammaire de propriétés pour l’analyse syntaxique par optimisation de contraintes (Compilation of a Property Grammar for Syntactic Parsing through Constraint Optimisation)</title>
      <language>fra</language>
      <author><first>Jean-Philippe</first><last>Prost</last></author>
      <author><first>Rémi</first><last>Coletta</last></author>
      <author><first>Christophe</first><last>Lecoutre</last></author>
      <pages>396–402</pages>
      <abstract>Cet article présente un processus de compilation d’une grammaire de propriétés en une contrainte en extension. Le processus s’insère dans le cadre d’un analyseur syntaxique robuste par résolution d’un problème d’optimisation de contraintes. La grammaire compilée est une énumération de tous les constituants immédiats uniques de l’espace de recherche. L’intérêt de ce travail encore préliminaire tient principalement dans l’exploration d’une modélisation computationnelle de la langue à base de Syntaxe par Modèles (MTS, Model-Theoretic Syntax), qui intègre la représentation indifférenciée des énoncés canoniques et non-canoniques. L’objectif plus particulier du travail présenté ici est d’explorer la possibilité de construire l’ensemble des structures candidat-modèles à partir de l’ensemble des structures syntagmatiques observées sur corpus. Cet article discute notamment le potentiel en matière d’intégration de prédictions probabilistes dans un raisonnement exact pour contribuer à la discrimination entre analyses grammaticales et agrammaticales.</abstract>
      <url hash="af99afc0">2016.jeptalnrecital-poster.11</url>
    </paper>
    <paper id="12">
      <title>Découverte de nouvelles entités et relations spatiales à partir d’un corpus de <fixed-case>SMS</fixed-case> (Discovering of new Spatial Entities and Relations from <fixed-case>SMS</fixed-case> Within the context of the currently available data masses, many works related to the analysis of spatial information are based on the exploitation of textual data)</title>
      <language>fra</language>
      <author><first>Sarah</first><last>Zenasni</last></author>
      <author><first>Maguelonne</first><last>Teisseire</last></author>
      <author><first>Mathieu</first><last>Roche</last></author>
      <author><first>Eric</first><last>Kergosien</last></author>
      <pages>403–410</pages>
      <abstract>Dans le contexte des masses de données aujourd’hui disponibles, de nombreux travaux liés à l’analyse de l’information spatiale s’appuient sur l’exploitation des données textuelles. La communication médiée (SMS, tweets, etc.) véhiculant des informations spatiales prend une place prépondérante. L’objectif du travail présenté dans cet article consiste à extraire ces informations spatiales à partir d’un corpus authentique de SMS en français. Nous proposons un processus dans lequel, dans un premier temps, nous extrayons de nouvelles entités spatiales (par exemple, motpellier, montpeul à associer au toponyme Montpellier). Dans un second temps, nous identifions de nouvelles relations spatiales qui précèdent les entités spatiales (par exemple, sur, par, pres, etc.). La tâche est difficile et complexe en raison de la spécificité du langage SMS qui repose sur une écriture peu standardisée (apparition de nombreux lexiques, utilisation massive d’abréviations, variation par rapport à l’écrit classique, etc.). Les expérimentations qui ont été réalisées à partir du corpus 88milSMS mettent en relief la robustesse de notre système pour identifier de nouvelles entités et relations spatiales.</abstract>
      <url hash="bbcefeb6">2016.jeptalnrecital-poster.12</url>
    </paper>
    <paper id="13">
      <title>Description de la juxtaposition en Langue des Signes Française à partir d’une grammaire récursive (The present communication tackles formal grammar developpement of <fixed-case>F</fixed-case>rench <fixed-case>S</fixed-case>ign <fixed-case>L</fixed-case>anguage (<fixed-case>LSF</fixed-case>))</title>
      <language>fra</language>
      <author><first>Mohamed Nassime</first><last>Hadjadj</last></author>
      <author><first>Michael</first><last>Filhol</last></author>
      <pages>411–418</pages>
      <abstract>La présente communication s’inscrit dans le cadre du développement d’une grammaire formelle pour la langue des signes française (LSF). Générer automatiquement des énoncés en LSF implique la définition de certaines règles de production pour synchroniser les différents articulateurs du corps, signes, mouvements, etc. Cet article présente dans sa première partie notre méthodologie pour définir des règles de production à partir d’une étude de corpus. Dans la deuxième partie nous présenterons notre étude qui portera sur deux règles de production pour juxtaposer quelques types de structures en LSF. Nous finissons par une discussion sur la nature et l’apport de notre démarche par rapport aux approches existantes.</abstract>
      <url hash="c0340cca">2016.jeptalnrecital-poster.13</url>
    </paper>
    <paper id="14">
      <title>Détecter le besoin d’information dans des requêtes d’usagers d’agents virtuels : sélection de données pertinentes (Selecting relevant data for information need detection in virtual agent user queries)</title>
      <language>fra</language>
      <author><first>Octavia</first><last>Efraim</last></author>
      <author><first>Fabienne</first><last>Moreau</last></author>
      <pages>419–427</pages>
      <abstract>Pour orienter efficacement les messages reçus par différents canaux de communication, dont l’agent virtuel (AV), un système de gestion de la relation client doit prendre en compte le besoin d’information de l’usager. En vue d’une tâche de classification par type de besoin d’information, il est utile de pouvoir en amont sélectionner dans les messages des utilisateurs, souvent de mauvaise qualité, les unités textuelles qui seront pertinentes pour représenter ce besoin d’information. Après avoir décrit les spécificités d’un corpus de requêtes d’AV nous expérimentons deux méthodes de sélection de segments informatifs : par extraction et par filtrage. Les résultats sont encourageants, mais des améliorations et une évaluation extrinsèque restent à faire.</abstract>
      <url hash="f1249ad2">2016.jeptalnrecital-poster.14</url>
    </paper>
    <paper id="15">
      <title>Estimer la notoriété d’un nom propre via <fixed-case>W</fixed-case>ikipedia (Estimate the notoriety of a Proper name using <fixed-case>W</fixed-case>ikipedia)</title>
      <language>fra</language>
      <author><first>Mouna</first><last>Elashter</last></author>
      <author><first>Denis</first><last>Maurel</last></author>
      <pages>428–434</pages>
      <abstract>Cet article propose de calculer, via Wikipedia, un indice de notoriété pour les entrées du dictionnaire relationnel multilingue de noms propres Prolexbase. Cet indice de notoriété dépend de la langue et participera, d’une part, à la construction d’un module de Prolexbase pour la langue arabe et, d’autre part, à la révision de la notoriété actuellement présente pour les autres langues de la base. Pour calculer la notoriété, nous utilisons la méthode SAW (précédée du calcul de l’entropie de Shannon) à partir de cinq valeurs numériques déduites de Wikipedia.</abstract>
      <url hash="ac2de503">2016.jeptalnrecital-poster.15</url>
    </paper>
    <paper id="16">
      <title>Étiquetage multilingue en parties du discours avec <fixed-case>ME</fixed-case>lt (Multilingual part-of-speech tagging with <fixed-case>ME</fixed-case>lt)</title>
      <language>fra</language>
      <author><first>Benoît</first><last>Sagot</last></author>
      <pages>435–442</pages>
      <abstract>Nous présentons des travaux récents réalisés autour de MElt, système discriminant d’étiquetage en parties du discours. MElt met l’accent sur l’exploitation optimale d’informations lexicales externes pour améliorer les performances des étiqueteurs par rapport aux modèles entraînés seulement sur des corpus annotés. Nous avons entraîné MElt sur plus d’une quarantaine de jeux de données couvrant plus d’une trentaine de langues. Comparé au système état-de-l’art MarMoT, MElt obtient en moyenne des résultats légèrement moins bons en l’absence de lexique externe, mais meilleurs lorsque de telles ressources sont disponibles, produisant ainsi des étiqueteurs état-de-l’art pour plusieurs langues.</abstract>
      <url hash="3fa1b564">2016.jeptalnrecital-poster.16</url>
    </paper>
    <paper id="17">
      <title>Extraction d’expressions-cibles de l’opinion : de l’anglais au français (Opinion Target Expression extraction : from <fixed-case>E</fixed-case>nglish to <fixed-case>F</fixed-case>rench)</title>
      <language>fra</language>
      <author><first>Grégoire</first><last>Jadi</last></author>
      <author><first>Laura</first><last>Monceaux</last></author>
      <author><first>Vincent</first><last>Claveau</last></author>
      <author><first>Béatrice</first><last>Daille</last></author>
      <pages>443–450</pages>
      <abstract>Dans cet article, nous présentons le développement d’un système d’extraction d’expressions-cibles pour l’anglais et sa transposition au français. En complément, nous avons réalisé une étude de l’efficacité des traits en anglais et en français qui tend à montrer qu’il est possible de réaliser un système d’extraction d’expressions-cibles indépendant du domaine. Pour finir, nous proposons une analyse comparative des erreurs commises par nos systèmes en anglais et français et envisageons différentes solutions à ces problèmes.</abstract>
      <url hash="fdda5422">2016.jeptalnrecital-poster.17</url>
    </paper>
    <paper id="18">
      <title>Extraction d’opinions ambigües dans des corpus d’avis clients (Ambiguous opinion extraction in user feedbacks)</title>
      <language>fra</language>
      <author><first>Joseph</first><last>Lark</last></author>
      <author><first>Emmanuel</first><last>Morin</last></author>
      <author><first>Sebastián Peña</first><last>Saldarriaga</last></author>
      <pages>451–458</pages>
      <abstract>Nous détectons dans des corpus d’avis clients en français des expressions d’opinion ne contenant pas de marqueur d’opinion explicitement positif ou négatif. Nous procédons pour cela en deux étapes en nous appuyant sur des méthodes existantes : nous identifions ces expressions à l’aide de fenêtres de mots puis nous les classifions en polarité. Le processus global présente des résultats satisfaisants pour notre cadre applicatif demandant une haute précision.</abstract>
      <url hash="92a30731">2016.jeptalnrecital-poster.18</url>
    </paper>
    <paper id="19">
      <title>Extraction de relations temporelles dans des dossiers électroniques patient (Extracting Temporal Relations from Electronic Health Records)</title>
      <language>fra</language>
      <author><first>Julien</first><last>Tourille</last></author>
      <author><first>Olivier</first><last>Ferret</last></author>
      <author><first>Aurélie</first><last>Névéol</last></author>
      <author><first>Xavier</first><last>Tannier</last></author>
      <pages>459–466</pages>
      <abstract>L’analyse temporelle des documents cliniques permet d’obtenir des représentations riches des informations contenues dans les dossiers électroniques patient. Cette analyse repose sur l’extraction d’événements, d’expressions temporelles et des relations entre eux. Dans ce travail, nous considérons que nous disposons des événements et des expressions temporelles pertinents et nous nous intéressons aux relations temporelles entre deux événements ou entre un événement et une expression temporelle. Nous présentons des modèles de classification supervisée pour l’extraction de des relations en français et en anglais. Les performances obtenues sont comparables dans les deux langues, suggérant ainsi que différents domaines cliniques et différentes langues pourraient être abordés de manière similaire.</abstract>
      <url hash="e0c963f1">2016.jeptalnrecital-poster.19</url>
    </paper>
    <paper id="20">
      <title>Impact de l’agglutination dans l’extraction de termes en arabe standard moderne (Adaptation of a term extractor to the <fixed-case>M</fixed-case>odern <fixed-case>S</fixed-case>tandard <fixed-case>A</fixed-case>rabic language)</title>
      <language>fra</language>
      <author><first>Wafa</first><last>Neifar</last></author>
      <author><first>Thierry</first><last>Hamon</last></author>
      <author><first>Pierre</first><last>Zweigenbaum</last></author>
      <author><first>Mariem</first><last>Ellouze</last></author>
      <author><first>Lamia Hadrich</first><last>Belguith</last></author>
      <pages>467–474</pages>
      <abstract>Nous présentons, dans cet article, une adaptation à l’arabe standard moderne d’un extracteur de termes pour le français et l’anglais. L’adaptation a d’abord consisté à décrire le processus d’extraction des termes de manière similaire à celui défini pour l’anglais et le français en prenant en compte certains particularités morpho-syntaxiques de la langue arabe. Puis, nous avons considéré le phénomène de l’agglutination de la langue arabe. L’évaluation a été réalisée sur un corpus de textes médicaux. Les résultats montrent que parmi 400 termes candidats maximaux analysés, 288 sont jugés corrects par rapport au domaine (72,1%). Les erreurs d’extraction sont dues à l’étiquetage morpho-syntaxique et à la non-voyellation des textes mais aussi à des phénomènes d’agglutination.</abstract>
      <url hash="7b1db6e5">2016.jeptalnrecital-poster.20</url>
    </paper>
    <paper id="21">
      <title>Inbenta Semantic Clustering : un outil de classification non-supervisée hybride (Inbenta Semantic Clustering : a hybrid unsupervised classification tool)</title>
      <language>fra</language>
      <author><first>Manon</first><last>Quintana</last></author>
      <author><first>Laurie</first><last>Planes</last></author>
      <pages>475–481</pages>
      <abstract>Inbenta développe un outil de classification non-supervisée hybride qui allie à la fois les statistiques et la puissance de notre lexique inspiré de la Théorie Sens-Texte. Nous présenterons ici le contexte qui a amené à la nécessité de développer un tel outil. Après un rapide état de l’art sur la classification non-supervisée en TAL, nous décrirons le fonctionnement de notre clustering sémantique.</abstract>
      <url hash="5de5a54f">2016.jeptalnrecital-poster.21</url>
    </paper>
    <paper id="22">
      <title>Intégration de la similarité entre phrases comme critère pour le résumé multi-document (Integrating sentence similarity as a constraint for multi-document summarization)</title>
      <language>fra</language>
      <author><first>Maâli</first><last>Mnasri</last></author>
      <author><first>Gaël</first><last>de Chalendar</last></author>
      <author><first>Olivier</first><last>Ferret</last></author>
      <pages>482–489</pages>
      <abstract>multi-document Maâli Mnasri1, 2 Gaël de Chalendar1 Olivier Ferret1 (1) CEA, LIST, Laboratoire Vision et Ingénierie des Contenus, Gif-sur-Yvette, F-91191, France. (2) Université Paris-Sud, Université Paris-Saclay, F-91405 Orsay, France. maali.mnasri@cea.fr, gael.de-chalendar@cea.fr, olivier.ferret@cea.fr R ÉSUMÉ À la suite des travaux de Gillick &amp; Favre (2009), beaucoup de travaux portant sur le résumé par extraction se sont appuyés sur une modélisation de cette tâche sous la forme de deux contraintes antagonistes : l’une vise à maximiser la couverture du résumé produit par rapport au contenu des textes d’origine tandis que l’autre représente la limite du résumé en termes de taille. Dans cette approche, la notion de redondance n’est prise en compte que de façon implicite. Dans cet article, nous reprenons le cadre défini par Gillick &amp; Favre (2009) mais nous examinons comment et dans quelle mesure la prise en compte explicite de la similarité sémantique des phrases peut améliorer les performances d’un système de résumé multi-document. Nous vérifions cet impact par des évaluations menées sur les corpus DUC 2003 et 2004.</abstract>
      <url hash="5452f033">2016.jeptalnrecital-poster.22</url>
    </paper>
    <paper id="23">
      <title>Investigating gender adaptation for speech translation</title>
      <author><first>Rachel</first><last>Bawden</last></author>
      <author><first>Guillaume</first><last>Wisniewski</last></author>
      <author><first>Hélène</first><last>Maynard</last></author>
      <pages>490–497</pages>
      <abstract>In this paper we investigate the impact of the integration of context into dialogue translation. We present a new contextual parallel corpus of television subtitles and show how taking into account speaker gender can significantly improve machine translation quality in terms of B LEU and M ETEOR scores. We perform a manual analysis, which suggests that these improvements are not necessary related to the morphological consequences of speaker gender, but to more general linguistic divergences.</abstract>
      <url hash="a524792e">2016.jeptalnrecital-poster.23</url>
    </paper>
    <paper id="24">
      <title>Médias traditionnels, médias sociaux : caractériser la réinformation (Traditional medias, social medias : characterizing reinformation)</title>
      <language>fra</language>
      <author><first>Cédric</first><last>Maigrot</last></author>
      <author><first>Ewa</first><last>Kijak</last></author>
      <author><first>Vincent</first><last>Claveau</last></author>
      <pages>498–505</pages>
      <abstract>Les médias traditionnels sont de plus en plus présents sur les réseaux sociaux, mais ces sources d’informations sont confrontées à d’autres sources dites de réinformation. Ces dernières ont parfois tendance à déformer les informations relayées pour correspondre aux idéologies qu’elles souhaitent défendre, les rendant partiellement ou totalement fausses. Le but de cet article est, d’une part, de présenter un corpus que nous avons constitué à partir de groupes Facebook de ces deux types de médias. Nous présentons d’autre part quelques expériences de détection automatique des messages issus des médias de réinformation, en étudiant notamment l’influence d’attributs de surface et d’attributs portant plus spécifiquement sur le contenu de ces messages.</abstract>
      <url hash="0c615565">2016.jeptalnrecital-poster.24</url>
    </paper>
    <paper id="25">
      <title>Mise au point d’une méthode d’annotation morphosyntaxique fine du serbe (Developping a method for detailed morphosyntactic tagging of <fixed-case>S</fixed-case>erbian)</title>
      <language>fra</language>
      <author><first>Aleksandra</first><last>Miletic</last></author>
      <author><first>Cécile</first><last>Fabre</last></author>
      <author><first>Dejan</first><last>Stosic</last></author>
      <pages>506–513</pages>
      <abstract>Cet article présente une expérience d’annotation morphosyntaxique fine du volet serbe du corpus parallèle ParCoLab (corpus serbe-français-anglais). Elle a consisté à enrichir une annotation existante en parties du discours avec des traits morphosyntaxiques fins, afin de préparer une étape ultérieure de parsing. Nous avons comparé trois approches : 1) annotation manuelle ; 2) préannotation avec un étiqueteur entraîné sur le croate suivie d’une correction manuelle ; 3) réentraînement de l’outil sur un petit échantillon validé du corpus, suivi de l’annotation automatique et de la correction manuelle. Le modèle croate maintient une stabilité globale en passant au serbe, mais les différences entre les deux jeux d’étiquettes exigent des interventions manuelles importantes. Le modèle ré-entraîné sur un échantillon de taille limité (20K tokens) atteint la même exactitude que le modèle existant et le gain de temps observé montre que cette méthode optimise la phase de correction.</abstract>
      <url hash="f608a63d">2016.jeptalnrecital-poster.25</url>
    </paper>
    <paper id="26">
      <title>Patrons sémantiques pour l’extraction de relations entre termes - Application aux comptes rendus radiologiques (Here the title in <fixed-case>E</fixed-case>nglish)</title>
      <language>fra</language>
      <author><first>Lionel</first><last>Ramadier</last></author>
      <author><first>Mathieu</first><last>Lafourcade</last></author>
      <pages>514–521</pages>
      <abstract>Dans cet article nous nous intéressons à la tâche d’extraction de relations sémantiques dans les textes médicaux et plus particulièrement dans les comptes rendus radiologiques. L’identification de relations sémantiques est une tâche importante pour plusieurs applications (recherche d’information, génération de résumé, etc). Nous proposons une approche fondée sur l’utilisation de patrons sémantiques vérifiant des contraintes dans une base de connaissances.</abstract>
      <url hash="ac6f5097">2016.jeptalnrecital-poster.26</url>
    </paper>
    <paper id="27">
      <title>Recherche de « périsegments » dans un contexte d’analyse conceptuelle assistée par ordinateur : le concept d’« esprit » chez Peirce (Search of “perisegments” in computer-assisted conceptual analysis : the concept of “mind” in Peirce)</title>
      <language>fra</language>
      <author><first>Davide</first><last>Pulizzotto</last></author>
      <author><first>José Alejandro</first><last>Lopez Gonzalez</last></author>
      <author><first>Jean-François</first><last>Chartier</last></author>
      <author><first>Jean-Guy</first><last>Meunier</last></author>
      <author><first>Louis</first><last>Chartrand</last></author>
      <author><first>Francis</first><last>Lareau</last></author>
      <author><first>Tan Le</first><last>Ngoc</last></author>
      <pages>522–530</pages>
      <abstract>En sciences humaines et plus particulièrement en philosophie, l’analyse conceptuelle (AC) est une pratique fondamentale qui permet de décortiquer les propriétés d’un concept. Lors de l’analyse d’un un corpus textuel, le principal défi est l’identification des segments de texte qui expriment le concept. Parfois, ces segments sont facilement reconnaissables grâce à une unité lexicale attendue, appelée forme canonique. Toutefois, ce n’est pas toujours le cas. Cet article propose une chaîne de traitement pour la découverte d’un certain nombre de segments périphériques, dits périsegments. Pour illustrer le processus, nous réalisons des expérimentations sur le concept d’« esprit » dans les Collected Papers de Ch. S. Peirce, en obtenant une précision moyenne supérieure à 83%.</abstract>
      <url hash="caf50517">2016.jeptalnrecital-poster.27</url>
    </paper>
    <paper id="28">
      <title>Segmentation automatique d’un texte en rhèses (Automatic segmentation of a text into rhesis)</title>
      <language>fra</language>
      <author><first>Victor</first><last>Pineau</last></author>
      <author><first>Constance</first><last>Nin</last></author>
      <author><first>Solen</first><last>Quiniou</last></author>
      <author><first>Béatrice</first><last>Daille</last></author>
      <pages>531–538</pages>
      <abstract>La segmentation d’un texte en rhèses, unités-membres signifiantes de la phrase, permet de fournir des adaptations de celui-ci pour faciliter la lecture aux personnes dyslexiques. Dans cet article, nous proposons une méthode d’identification automatique des rhèses basée sur un apprentissage supervisé à partir d’un corpus que nous avons annoté. Nous comparons celle-ci à l’identification manuelle ainsi qu’à l’utilisation d’outils et de concepts proches, tels que la segmentation d’un texte en chunks.</abstract>
      <url hash="6bf345ba">2016.jeptalnrecital-poster.28</url>
    </paper>
    <paper id="29">
      <title>Système hybride pour la reconnaissance des entités nommées arabes à base des <fixed-case>CRF</fixed-case> (Hybrid arabic <fixed-case>NER</fixed-case> system using <fixed-case>CRF</fixed-case> Model)</title>
      <language>fra</language>
      <author><first>Emna</first><last>Hkiri</last></author>
      <author><first>Souheyl</first><last>Mallat</last></author>
      <author><first>Mounir</first><last>Zrigui</last></author>
      <pages>539–546</pages>
      <abstract>La reconnaissance d’entités nommées (REN) pour les langues naturelles telles que l’arabe est une tâche essentielle et difficile. Dans cet article, nous décrivons notre système hybride afin d’améliorer la performance du système de REN et de combler le manque de ressources pour le TAL arabe. Notre système applique un modèle CRF, un lexique bilingue d’ENs et des règles linguistiques spécifiques à la tâche de reconnaissance d’entités nommées dans les textes arabes. Les résultats empiriques indiquent que notre système surpasse l’état-de l’art de la REN arabe lorsqu’il est appliqué au corpus d’évaluation standard ANERcorp.</abstract>
      <url hash="797d087f">2016.jeptalnrecital-poster.29</url>
    </paper>
    <paper id="30">
      <title>Vers un lexique ouvert des formes fléchies de l’alsacien : génération de flexions pour les verbes (Towards an Open Lexicon of Inflected Word Forms for <fixed-case>A</fixed-case>lsatian: Generation of Verbal Inflection)</title>
      <language>fra</language>
      <author><first>Lucie</first><last>Steiblé</last></author>
      <author><first>Delphine</first><last>Bernhard</last></author>
      <pages>547–554</pages>
      <abstract>Cet article présente les méthodes mises en œuvre et les résultats obtenus pour la création d’un lexique de formes fléchies de l’alsacien. Les dialectes d’Alsace font partie des langues peu dotées : rares sont les outils et ressources informatisées les concernant. Plusieurs difficultés doivent être prises en compte afin de générer des ressources pour ces langues, généralement liées à la variabilité en l’absence de norme graphique, et au manque de formes fléchies dans les quelques ressources existantes. Nous avons pour ce faire utilisé plusieurs outils permettant la génération automatique de variantes graphiques et la création de formes fléchies (graphes morphologiques et de flexion d’Unitex). Les résultats en termes de couverture des formes rencontrées dans des textes ont permis l’évaluation de la méthode.</abstract>
      <url hash="1221f26e">2016.jeptalnrecital-poster.30</url>
    </paper>
    <paper id="31">
      <title>Vers une analyse des différences interlinguistiques entre les genres textuels : étude de cas basée sur les n-grammes et l’analyse factorielle des correspondances (Towards a cross-linguistic analysis of genres: A case study based on n-grams and Correspondence Analysis)</title>
      <language>fra</language>
      <author><first>Marie-Aude</first><last>Lefer</last></author>
      <author><first>Yves</first><last>Bestgen</last></author>
      <author><first>Natalia</first><last>Grabar</last></author>
      <pages>555–563</pages>
      <abstract>L’objectif de notre travail est d’évaluer l’intérêt d’employer les n-grammes et l’analyse factorielle des correspondances (AFC) pour comparer les genres textuels dans les études contrastives interlinguistiques. Nous exploitons un corpus bilingue anglais-français constitué de textes originaux comparables. Le corpus réunit trois genres : les débats parlementaires européens, les éditoriaux de presse et les articles scientifiques. Dans un premier temps, les n-grammes d’une longueur de 2 à 4 mots sont extraits dans chaque langue. Ensuite, pour chaque longueur, les 1 000 n-grammes les plus fréquents dans chaque langue sont traités par l’AFC pour déterminer quels n-grammes sont particulièrement saillants dans les genres étudiés. Enfin, les n-grammes sont catégorisés manuellement en distinguant les expressions d’opinion et de certitude, les marqueurs discursifs et les expressions référentielles. Les résultats montrent que les n-grammes permettent de mettre au jour des caractéristiques typiques des genres étudiés, de même que des contrastes interlangues intéressants.</abstract>
      <url hash="009db251">2016.jeptalnrecital-poster.31</url>
    </paper>
  </volume>
  <volume id="recital" ingest-date="2020-07-08">
    <meta>
      <booktitle>Actes de la conférence conjointe JEP-TALN-RECITAL 2016. volume 3 : RECITAL</booktitle>
      <editor><first>Laurence</first><last>Danlos</last></editor>
      <editor><first>Thierry</first><last>Hamon</last></editor>
      <publisher>AFCP - ATALA</publisher>
      <address>Paris, France</address>
      <month>7</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="165c2807">2016.jeptalnrecital-recital.0</url>
    </frontmatter>
    <paper id="1">
      <title>Acquisition terminologique en arabe: État de l’art (Terminological acquisition on <fixed-case>MSA</fixed-case> : State of the art)</title>
      <language>fra</language>
      <author><first>Wafa</first><last>Neifar</last></author>
      <author><first>Ahmed Ben</first><last>Ltaief</last></author>
      <pages>1–12</pages>
      <abstract>L’acquisition terminologique est une tâche indispensable pour l’accès aux informations présentes dans les corpus de spécialité. Il s’agit d’une part, d’identifier et d’extraire des termes, et d’autre part, de structurer ces termes à l’aide de méthodes d’acquisition de relations sémantiques. Dans cet article, nous nous intéressons l’acquisition terminologique sur des textes arabe standard moderne (MSA). Nous réalisons tout d’abord, un état de l’art décrivant les méthodes d’extraction de termes sur cette langue ainsi que les approches proposées pour la reconnaissance de relations sémantiques entre termes issus. Après avoir présenter quelques corpus de spécialité et ressources terminologiques disponibles en MSA que nous avons identifiés, nous décrivons nos premières pistes de travail.</abstract>
      <url hash="84f411a1">2016.jeptalnrecital-recital.1</url>
    </paper>
    <paper id="2">
      <title>Apprentissage bayésien incrémental pour la détermination de l’âge et du genre d’utilisateurs de plateformes du web social (<fixed-case>UGC</fixed-case> text-based age &amp; gender author profiling through incrementally semi-supervised bayesian learning)</title>
      <language>fra</language>
      <author><first>Jugurtha Aït</first><last>Hamlat</last></author>
      <pages>13–26</pages>
      <abstract>Les méthodes de classification textuelles basées sur l’apprentissage automatique ont l’avantage, en plus d’être robustes, de fournir des résultats satisfaisants, sous réserve de disposer d’une base d’entraînement de qualité et en quantité suffisante. Les corpus d’apprentissage étant coûteux à construire, leur carence à grande échelle se révèle être l’une des principales causes d’erreurs. Dans un contexte industriel à forte volumétrie de données, nous présentons une approche de prédiction des deux plus importants indicateurs socio-démographiques « âge » et « genre » appliquée à des utilisateurs de forums, blogs et réseaux sociaux et ce, à partir de leurs seules productions textuelles. Le modèle bayésien multinomial est construit à partir d’un processus d’apprentissage incrémental et itératif sur une vaste base d’entraînement semi-supervisée. Le caractère incrémental permet de s’affranchir des contraintes de volumétrie. L’aspect itératif a pour objectif d’affiner le modèle et d’augmenter ainsi les niveaux de rappel &amp; précision.</abstract>
      <url hash="19ce7904">2016.jeptalnrecital-recital.2</url>
    </paper>
    <paper id="3">
      <title>Conjonctions de subordination, verbes de dire et d’attitude propositionnelle : une modélisation <fixed-case>STAG</fixed-case> pour le discours (Modelling Subordinate Conjunctions, Attitude Verbs and Reporting Verbs in <fixed-case>STAG</fixed-case>: a Discourse Perspective)</title>
      <language>fra</language>
      <author><first>Timothée</first><last>Bernard</last></author>
      <pages>27–39</pages>
      <abstract>Nous proposons une nouvelle modélisation en grammaire d’arbres adjoints synchrone (STAG) syntaxe/sémantique pour les conjonctions de subordination (ConjSub) et les verbes de dire et d’attitude propositionnelle (VAP ; dire, penser, croire, etc.). Cette modélisation, plus riche que les modélisations traditionnelles, est conçue pour l’analyse du discours et fondée sur l’observation que ces deux catégories sont loin d’être homogènes. En effet, des travaux antérieurs ont montré d’une part que les occurrences de ConjSub pouvaient être divisées en deux classes aux propriétés syntaxiques et sémantiques différentes, d’autre part que les VAP présentaient en discours deux usages distincts : évidentiel et intentionnel. Notre proposition vise donc à rendre compte précisément de ces différences tout en modélisant les interactions entre VAP et ConjSub.</abstract>
      <url hash="e1e237ed">2016.jeptalnrecital-recital.3</url>
    </paper>
    <paper id="4">
      <title>Hypernym extraction from <fixed-case>W</fixed-case>ikipedia</title>
      <author><first>Adel</first><last>Ghamnia</last></author>
      <pages>40–51</pages>
      <abstract>Hypernym extraction from Wikipédia The volume of available documents on the Web continues to increase, the texts contained in these documents are rich information describing concepts and relationships between concepts specific to a particular field. In this paper, we propose and exploit an hypernymy extractor based on lexico-syntactic patterns designed for Wikipedia semi-structured pages, especially the disambiguation pages, to enrich a knowledge base as BabelNet and DBPedia. The results show a precision of 0.68 and a recall of 0.75 for the patterns that we have defined, and an enrichment rate up to 33% for both BabelNet and DBPédia semantic resources.</abstract>
      <url hash="1ffccd24">2016.jeptalnrecital-recital.4</url>
    </paper>
    <paper id="5">
      <title>Identifier et catégoriser l’ambiguïté dans les spécifications techniques de conceptions de systèmes (Identifying and classifying ambiguity in requirements)</title>
      <language>fra</language>
      <author><first>Émilie</first><last>Merdy</last></author>
      <pages>52–65</pages>
      <abstract>Cette étude s’inscrit dans le cadre d’une thèse Cifre avec Prometil 1 , une société qui commercialise un outil de détection automatique des erreurs dans les exigences, i.e. le contenu textuel des spécifications techniques. Il s’agit d’un travail de recherche dans la lignée des travaux en analyse de corpus menés par le laboratoire CLLE-ERSS qui s’intéresse aux corpus spécialisés. Dans le cadre de l’adaptation automatique des analyses sémantiques à de nouveaux domaines, nous étudions la détection automatique de l’ambiguïté - qu’elle soit syntaxique, sémantique ou lexicale - dans les exigences à partir de ressources lexicales spécifiques mais incomplètes. En parallèle, l’exploration des exigences, qui sont des données non-massives et porteuses de peu de variétés lexicale et syntaxique, doit permettre de mieux appréhender la spécificité linguistique de corpus techniques spécialisés pour enrichir semi-automatiquement des ressources lexicales adaptées.</abstract>
      <url hash="3ff25b2c">2016.jeptalnrecital-recital.5</url>
    </paper>
    <paper id="6">
      <title>Un modèle simple de coût cognitif de la résolution d’anaphores (A Simple Model of Cognitive Cost of Anaphora Resolution)</title>
      <language>fra</language>
      <author><first>Olga</first><last>Seminck</last></author>
      <pages>66–79</pages>
      <abstract>Nous présentons un travail en cours sur un projet de recherche en TAL et en psycholinguistique. Le but de notre projet est de modéliser le coût cognitif que représente la résolution d’anaphores. Nous voulons obtenir une mesure du coût cognitif continue et incrémentale qui peut, à un stade de recherche plus avancé, être corrélée avec des mesures d’occulométrie sur corpus. Pour cela, nous proposons une modélisation inspirée par des techniques venues du TAL. Nous utilisons un solveur d’anaphores probabiliste basé sur l’algorithme couples de mentions et la notion d’entropie pour établir une mesure du coût cognitif des anaphores. Ensuite, nous montrons par des visualisations quelles sont les prédictions de cette première modélisation pour les pronoms personnels de troisième personne dans le corpus ANCOR Centre.</abstract>
      <url hash="4a2bd08d">2016.jeptalnrecital-recital.6</url>
    </paper>
    <paper id="7">
      <title>La polysémie lexicale et syntaxique de l’alternance modale indicatif/subjonctif – perspectives <fixed-case>TAL</fixed-case> (Lexical and syntactic polysemy of the modal alternation indicative/subjunctive – <fixed-case>NLP</fixed-case> perspectives)</title>
      <language>fra</language>
      <author><first>Divna</first><last>Petkovic</last></author>
      <author><first>Victor</first><last>Rabiet</last></author>
      <pages>80–93</pages>
      <abstract>Certains verbes ont une double commande modale : ils admettent une construction permettant l’usage du subjonctif et de l’indicatif dans la complétive qui leur est adjointe. Ainsi, ces verbes se trouvent dans des contextes polysémiques à tous les niveaux d’analyse (lexicale, syntaxique, grammaticale et pragmatique). Dans un tel cas, le mode peut représenter une marque formelle désambiguïsante. Plus précisément, parfois le verbe régissant (dans la principale) est polysémique en lui-même, et selon son sens il commande soit l’indicatif, soit le subjonctif dans la subordonnée complétive : il s’agit de la polysémie lexicale, qui peut être forte ou faible. D’un autre point de vue, certains verbes à l’indicatif/subjonctif dans la subordonnée modifient plus ou moins légèrement le sens de la phrase entière : on considère ici cela comme un cas de polysémie syntaxique, étant donné que ces verbes apparaissent dans diverses structures et modalités.</abstract>
      <url hash="4ce1fd17">2016.jeptalnrecital-recital.7</url>
    </paper>
    <paper id="8">
      <title>Quelles sont les caractéristiques des interactions problématiques entre des utilisateurs et un conseiller virtuel ? (How to characterize problematic interactions between users and a web virtual advisor?)</title>
      <language>fra</language>
      <author><first>Irina</first><last>Maslowski</last></author>
      <pages>94–107</pages>
      <abstract>L’utilisation d’un conseiller virtuel pour la gestion de la relation client sur les sites des entreprises est une solution numérique de plus en plus adoptée. Le défi pour les entreprises est de mieux répondre aux attentes des clients en leur fournissant des interactions fluides entre le client et l’agent. Pour faire face à ce problème, cet article met l’accent sur la détection des problèmes d’interactions dans un corpus de tchat écrit entre un conseiller virtuel et ses utilisateurs. Il fournit une analyse de corpus en décrivant non seulement les spécificités linguistiques et les marqueurs d’opinion contenus dans le corpus du tchat humain-agent, mais aussi les indices linguistiques et dialogiques qui peuvent être pertinents pour caractériser une interaction problématique. Le modèle de règles proposé, utilisant les indices trouvés, est appliqué à un corpus avec des retours client négatifs et positifs pour révéler les tendances.</abstract>
      <url hash="77a863cd">2016.jeptalnrecital-recital.8</url>
    </paper>
  </volume>
  <volume id="invite" ingest-date="2020-07-08">
    <meta>
      <booktitle>Actes de la conférence conjointe JEP-TALN-RECITAL 2016. Volume 4 : Conférences invitées</booktitle>
      <editor><first>Laurence</first><last>Danlos</last></editor>
      <editor><first>Thierry</first><last>Hamon</last></editor>
      <publisher>AFCP - ATALA</publisher>
      <address>Paris, France</address>
      <month>7</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="1ad21474">2016.jeptalnrecital-invite.0</url>
    </frontmatter>
    <paper id="1">
      <title>Corpora and Linguistic Linked Open Data: Motivations, Applications, Limitations</title>
      <author><first>Christian</first><last>Chiarcos</last></author>
      <pages>1–2</pages>
      <abstract>Linguistic Linked Open Data (LLOD) is a technology and a movement in several disciplines working with language resources, including Natural Language Processing, general linguistics, computational lexicography and the localization industry. This talk describes basic principles of Linguistic Linked Open Data and their application to linguistically annotated corpora, it summarizes the current status of the Linguistic Linked Open Data cloud and gives an overview over selected LLOD vocabularies and their uses.</abstract>
      <url hash="0c07d1e6">2016.jeptalnrecital-invite.1</url>
    </paper>
    <paper id="2">
      <title>From Human Language Technology to Human Language Science</title>
      <author><first>Mark</first><last>Liberman</last></author>
      <pages>3–3</pages>
      <abstract>Thirty years ago, in order to get past roadblocks in Machine Translation and Automatic Speech Recognition, DARPA invented a new way to organize and manage technological R&amp;D : a “common task” is defined by a formal quantitative evaluation metric and a body of shared training data, and researchers join an open competition to compare approaches. Over the past three decades, this method has produced steadily improving technologies, with many practical applications now possible. And Moore’s law has created a sort of digital shadow universe, which increasingly mirrors the real world in flows and stores of bits, while the same improvements in digital hardware and software make it increasingly easy to pull content out of the these rivers and oceans of information. It’s natural to be excited about these technologies, where we can see an open road to rapid improvements beyond the current state of the art, and an explosion of near-term commercial applications. But there are some important opportunities in a less obvious direction. Several areas of scientific and humanistic research are being revolutionized by the application of Human Language Technology. At a minimum, orders of magnitude more data can be addressed with orders of magnitude less effort - but this change also transforms old theoretical questions, and poses new ones. And eventually, new modes of research organization and funding are likely to emerge..</abstract>
      <url hash="aa6cc87f">2016.jeptalnrecital-invite.2</url>
    </paper>
  </volume>
  <volume id="demo" ingest-date="2020-07-08">
    <meta>
      <booktitle>Actes de la conférence conjointe JEP-TALN-RECITAL 2016. volume 5 : Démonstrations</booktitle>
      <editor><first>Laurence</first><last>Danlos</last></editor>
      <editor><first>Thierry</first><last>Hamon</last></editor>
      <publisher>AFCP - ATALA</publisher>
      <address>Paris, France</address>
      <month>7</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="0353b47c">2016.jeptalnrecital-demo.0</url>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>ACG</fixed-case>tk : un outil de développement et de test pour les grammaires catégorielles abstraites (<fixed-case>ACG</fixed-case> <fixed-case>TK</fixed-case> : a Toolkit to Develop and Test Abstract Categorial Grammars )</title>
      <language>fra</language>
      <author><first>Sylvain</first><last>Pogodalla</last></author>
      <pages>1–2</pages>
      <abstract>Nous présentons un outil, ACG TK, offrant un environnement de développement et d’utilisation des grammaires catégorielles abstraites pour l’analyse et la génération.</abstract>
      <url hash="62721ee2">2016.jeptalnrecital-demo.1</url>
    </paper>
    <paper id="2">
      <title>Un analyseur de conversations pour la relation client (Parsing email and chat conversations for customer support softwares)</title>
      <language>fra</language>
      <author><first>Hugues</first><last>de Mazancourt</last></author>
      <author><first>Gaëlle</first><last>Recourcé</last></author>
      <author><first>Soufian</first><last>Salim</last></author>
      <pages>3–5</pages>
      <abstract>Cette démonstration a pour objet de présenter l’utilisation d’un analyseur de conversations par email ou chat dans le cadre d’une application de support client : mise en valeur des demandes d’action, repérage des thèmes dangereux, tableau de bord pour le superviseur, alertes pour l’agent ...</abstract>
      <url hash="2fedb9ae">2016.jeptalnrecital-demo.2</url>
    </paper>
    <paper id="3">
      <title><fixed-case>A</fixed-case>pp<fixed-case>FM</fixed-case>, une plate-forme de gestion de modules de <fixed-case>TAL</fixed-case> (<fixed-case>A</fixed-case>pp<fixed-case>FM</fixed-case>, a tool for managing <fixed-case>NLP</fixed-case> modules)</title>
      <language>fra</language>
      <author><first>Paul</first><last>Bui-Quang</last></author>
      <author><first>Brigitte</first><last>Grau</last></author>
      <author><first>Patrick</first><last>Paroubek</last></author>
      <pages>6–8</pages>
      <abstract>AppFM 1 est un outil à mi-chemin entre un environnement de création de chaînes modulaires de TAL et un gestionnaire de services systèmes. Il permet l’intégration d’applications ayant des dépendances complexes en des chaînes de traitements réutilisables facilement par le biais de multiples interfaces.</abstract>
      <url hash="cd675178">2016.jeptalnrecital-demo.3</url>
    </paper>
    <paper id="4">
      <title><fixed-case>C</fixed-case>ommunico<fixed-case>T</fixed-case>ool Advance, un prototype d’application d’aide à la communication (<fixed-case>C</fixed-case>ommunico<fixed-case>T</fixed-case>ool Advance: an assistive communication app prototype)</title>
      <language>fra</language>
      <author><first>Charlotte</first><last>Roze</last></author>
      <pages>9–11</pages>
      <abstract>CommunicoTool Advance est un prototype d’application mobile d’aide à la communication destinée à des personnes qui présentent des troubles moteurs et des troubles de la parole.</abstract>
      <url hash="14ca2a9c">2016.jeptalnrecital-demo.4</url>
    </paper>
    <paper id="5">
      <title>Construction automatisée d’une base de connaissances (Automated Building a Knowledge Base)</title>
      <language>fra</language>
      <author><first>Olivier</first><last>Mesnard</last></author>
      <author><first>Yoann</first><last>Dupont</last></author>
      <author><first>Jérémy</first><last>Guillemot</last></author>
      <author><first>Rashedur</first><last>Rahman</last></author>
      <pages>12–14</pages>
      <abstract>Le système présenté permet la construction automatisée d’une base de connaissances sur des personnes et des organisations à partir d’une collection de documents. Il s’appuie sur de l’apprentissage distant pour l’extraction d’hypothèses de relations entre mentions d’entités qu’il consolide avec des informations orientées graphe.</abstract>
      <url hash="44dd8b3c">2016.jeptalnrecital-demo.5</url>
    </paper>
    <paper id="6">
      <title><fixed-case>E</fixed-case>-Quotes : un outil de navigation textuelle guidée par les annotations sémantiques (<fixed-case>E</fixed-case>-Quotes : A semantic annotations-driven tool for textual navigation)</title>
      <language>fra</language>
      <author><first>Motasem</first><last>Alrahabi</last></author>
      <pages>15–17</pages>
      <abstract>Nous présentons E-Quotes, un outil de navigation textuelle guidée par les annotations sémantiques. Le système permet de localiser les mots clés et leurs variantes dans les citations sémantiquement catégorisés dans corpus annoté, et de naviguer entre ces citations. Nous avons expérimenté ce système sur un corpus de littérature française automatiquement annoté selon des catégories sémantiques présentes dans le contexte des citations, comme par exemple la définition, l’argumentation, l’opinion, l’ironie ou la rumeur rapportées.</abstract>
      <url hash="07ebc41d">2016.jeptalnrecital-demo.6</url>
    </paper>
    <paper id="7">
      <title>Exploration de collections d’archives multimédia dans le contexte des Humanités Numériques : revisiter <fixed-case>TALN</fixed-case>’2015 ? (Exploring multimedia archives in the context of Digital Humanities: browsing <fixed-case>TALN</fixed-case>’2015?)</title>
      <language>fra</language>
      <author><first>Géraldine</first><last>Damnati</last></author>
      <author><first>Marc</first><last>Denjean</last></author>
      <author><first>Delphine</first><last>Charlet</last></author>
      <pages>18–20</pages>
      <abstract>Cette démonstration présente un prototype d’exploration de contenus multimédias développé dans le but de faciliter l’accès aux contenus de la Connaissance. Après une extraction automatique de métadonnées, les contenus sont indexés et accessibles via un moteur de recherche spécifique. Des fonctionnalités innovantes de navigation à l’intérieur des contenus sont également présentées. La collection des enregistrements vidéo de TALN’2015 sert de support privilégié à cette démonstration.</abstract>
      <url hash="cddcd15e">2016.jeptalnrecital-demo.7</url>
    </paper>
    <paper id="8">
      <title><fixed-case>F</fixed-case>lexi<fixed-case>M</fixed-case>ac 1.1. – Conjugueur automatique des verbes macédoniens (<fixed-case>F</fixed-case>lexi<fixed-case>M</fixed-case>ac 1)</title>
      <language>fra</language>
      <author><first>Jovan</first><last>Kostov</last></author>
      <pages>21–23</pages>
      <abstract>Cette démonstration présente la plateforme FlexiMac 1.1., générateur automatique des verbes macédoniens qui permet de conjuguer un verbe dans la plupart des modes et des temps, sans faire appel à une base de données. Après un bref exposé du fonctionnement de la plateforme, nous allons également évoquer les travaux actuels qui en ont découlé, et ceux qui sont en train d’émerger dans une perspective de traitement automatique du macédonien en tant que langue européenne peu-dotée.</abstract>
      <url hash="c2706b84">2016.jeptalnrecital-demo.8</url>
    </paper>
    <paper id="9">
      <title>Héloïse, une plate-forme pour développer des systèmes de <fixed-case>TA</fixed-case> compatibles Ariane en réseau (Heloise, a platform for collaborative development of Ariane-compatible <fixed-case>MT</fixed-case> systems)</title>
      <language>fra</language>
      <author><first>Vincent</first><last>Berment</last></author>
      <author><first>Christian</first><last>Boitet</last></author>
      <author><first>Guillaume</first><last>de Malézieux</last></author>
      <pages>24–26</pages>
      <abstract>Dans cette démo, nous montrons comment utiliser Héloïse pour développer des systèmes de TA.</abstract>
      <url hash="48297fcd">2016.jeptalnrecital-demo.9</url>
    </paper>
    <paper id="10">
      <title>Identification de lieux dans les messageries mobiles (Place extraction from smartphone messaging applications)</title>
      <language>fra</language>
      <author><first>Clément</first><last>Doumouro</last></author>
      <author><first>Adrien</first><last>Ball</last></author>
      <author><first>Joseph</first><last>Dureau</last></author>
      <author><first>Sylvain</first><last>Raybaud</last></author>
      <author><first>Ramzi Ben</first><last>Yahya</last></author>
      <pages>27–28</pages>
      <abstract>Nous présentons un système d’identification de lieux dans les messageries typiquement utilisées sur smartphone. L’implémentation sur mobile et son cortège de contraintes, ainsi que la faible quantité de ressources disponibles pour le type de langage utilisé rendent la tâche particulièrement délicate. Ce système, implémenté sur Android, atteint une précision de 30% et un rappel de 72%.</abstract>
      <url hash="710ec1c9">2016.jeptalnrecital-demo.10</url>
    </paper>
    <paper id="11">
      <title>Interface Web pour l’annotation morpho-syntaxique de textes (Web interface for the morpho-syntactic annotation of texts)</title>
      <language>fra</language>
      <author><first>Thierry</first><last>Hamon</last></author>
      <pages>29–31</pages>
      <abstract>Nous présentons une interface Web pour la visualisation etl’annotation de textes avec des étiquettes morphosyntaxiques etdes lemmes. Celle-ci est actuellement utilisée pour annoter destextes ukrainiens avec le jeu d’étiquettes Multext-East.Les utilisateurs peuvent rapidement visualiser les annotationsassociées aux mots d’un texte, modifier les annotationsexistantes ou en ajouter de nouvelles. Les annotations peuvent chargéeset exportées en XML au format TEI, mais aussi sous forme tabulée.Des scripts de conversion de format et de chargement dans une basede données sont également mis à disposition.</abstract>
      <url hash="ed8cc3fc">2016.jeptalnrecital-demo.11</url>
    </paper>
    <paper id="12">
      <title>Lecture bilingue augmentée par des alignements multi-niveaux (Augmenting bilingual reading with alignment information)</title>
      <language>fra</language>
      <author><first>François</first><last>Yvon</last></author>
      <author><first>Yong</first><last>Xu</last></author>
      <author><first>Marianna</first><last>Apidianaki</last></author>
      <author><first>Clément</first><last>Pillias</last></author>
      <author><first>Cubaud</first><last>Pierre</last></author>
      <pages>32–33</pages>
      <abstract>Le travail qui a conduit à cette démonstration combine des outils de traitement des langues multilingues, en particulier l’alignement automatique, avec des techniques de visualisation et d’interaction. Il vise à proposer des pistes pour le développement d’outils permettant de lire simultanément les différentes versions d’un texte disponible en plusieurs langues, avec des applications en lecture de loisir ou en lecture professionnelle.</abstract>
      <url hash="62b7ad41">2016.jeptalnrecital-demo.12</url>
    </paper>
    <paper id="13">
      <title><fixed-case>LNE</fixed-case>-Visu : a tool to explore and visualize multimedia data</title>
      <author><first>Guillaume</first><last>Bernard</last></author>
      <author><first>Juliette</first><last>Kahn</last></author>
      <author><first>Olivier</first><last>Galibert</last></author>
      <author><first>Rémi</first><last>Regnier</last></author>
      <author><first>Séverine</first><last>Demeyer</last></author>
      <pages>34–36</pages>
      <abstract>LNE-Visu : a tool to explore and visualize multimedia data LNE-Visu is a tool to explore and visualize multimedia data created for the LNE evaluation campaigns. 3 functionalities are available: explore and select data, visualize and listen data, apply significance tests</abstract>
      <url hash="36098568">2016.jeptalnrecital-demo.13</url>
    </paper>
    <paper id="14">
      <title>Un outil multilingue d’extraction de collocations en ligne (This demo shows the web version of a multilingual collocation extraction tool)</title>
      <language>fra</language>
      <author><first>Luka</first><last>Nerima</last></author>
      <author><first>Violeta</first><last>Seretan</last></author>
      <author><first>Eric</first><last>Wehrli</last></author>
      <pages>37–39</pages>
      <abstract>Cette démonstration présente la version web d’un outil multilingue d’extraction de collocations. Elle est destinée aux lexicographes, aux traducteurs, aux enseignants et apprenants L2 et, plus généralement, aux linguistes désireux d’analyser et d’exploiter leurs propres corpus.</abstract>
      <url hash="a0fcfcab">2016.jeptalnrecital-demo.14</url>
    </paper>
    <paper id="15">
      <title>Radarly : écouter et analyser le web conversationnel en temps réel (Real time listening and analysis of the social web using Radarly)</title>
      <language>fra</language>
      <author><first>Jade</first><last>Copet</last></author>
      <author><first>Christine</first><last>de Carvalho</last></author>
      <author><first>Virginie</first><last>Mouilleron</last></author>
      <author><first>Benoit</first><last>Tabutiaux</last></author>
      <author><first>Hugo</first><last>Zanghi</last></author>
      <pages>40–42</pages>
      <abstract>De par le contexte conversationnel digital, l’outil Radarly a été conçu pour permettre de traiter de grands volumes de données hétérogènes en temps réel, de générer de nouveaux indicateurs et de les visualiser sur une interface cohérente et confortable afin d’en tirer des analyses et études pertinentes. Ce document expose les techniques et processus utilisés pour extraire et traiter toutes ces données.</abstract>
      <url hash="57b801e6">2016.jeptalnrecital-demo.15</url>
    </paper>
    <paper id="16">
      <title><fixed-case>SOFA</fixed-case> : Une plateforme d’analyse syntaxique en ligne pour l’ancien français (<fixed-case>SOFA</fixed-case> : An online Syntactic <fixed-case>O</fixed-case>ld <fixed-case>F</fixed-case>rench Annotator)</title>
      <language>fra</language>
      <author><first>Gaël</first><last>Guibon</last></author>
      <pages>43–45</pages>
      <abstract>SOFA une application web dédiée à l’étiquetage syntaxique de l’ancien français. Cette plateforme est une démonstration permettant d’appliquer sur n’importe quel texte, ou sur un des textes d’ancien français, des modèles de lemmatisation, d’annotation morpho-syntaxique, et d’analyse syntaxique, en plus d’en visualiser les performances.</abstract>
      <url hash="f0cd5886">2016.jeptalnrecital-demo.16</url>
    </paper>
    <paper id="17">
      <title><fixed-case>STAM</fixed-case> : traduction des textes non structurés (dialectes du Maghreb) (<fixed-case>STAM</fixed-case>: Translation of unstructured text (Maghreb dialects) The use of communication platforms (social networks, discussion forums)</title>
      <language>fra</language>
      <author><first>Mehdi</first><last>Embarek</last></author>
      <author><first>Soumya</first><last>Embarek</last></author>
      <pages>46–48</pages>
      <abstract>L’utilisation des plateformes de communication (réseaux sociaux, forums de discussions, ...) a pris une ampleur considérable. Ces plateformes permettent aux internautes d’exprimer leur avis concernant un sujet, demander ou échanger des informations, commenter un événement, etc. Ainsi, nous retrouvons dans ces différentes sources d’informations une quantité importante de textes rédigés dans des dialectes locaux dont sont originaires les rédacteurs. Cependant, ces textes non structurés rendent l’exploitation des outils de traitement automatique des langues très difficile. Le système STAM aborde cette problématique en proposant un système capable de transcrire automatiquement des textes écrits dans un dialecte parlé dans les pays du Maghreb en un texte facilement interprétable et compréhensible (français ou anglais).</abstract>
      <url hash="feeb4b18">2016.jeptalnrecital-demo.17</url>
    </paper>
    <paper id="18">
      <title>Un système automatique de sélection de réponse en domaine ouvert intégrable à un système de dialogue social (An automatic open-domain response selection system integrable to a social dialogue system)</title>
      <language>fra</language>
      <author><first>Franck</first><last>Charras</last></author>
      <author><first>Guillaume</first><last>Dubuisson Duplessis</last></author>
      <author><first>Vincent</first><last>Letard</last></author>
      <author><first>Anne-Laure</first><last>Ligozat</last></author>
      <author><first>Sophie</first><last>Rosset</last></author>
      <pages>49–51</pages>
      <abstract>Cette démonstration présente un système de dialogue en domaine ouvert qui utilise une base d’exemples de dialogue automatiquement constituée depuis un corpus de sous-titres afin de gérer un dialogue social de type « chatbot ».</abstract>
      <url hash="ba6d43c9">2016.jeptalnrecital-demo.18</url>
    </paper>
    <paper id="19">
      <title>Tag Thunder : plateforme de démonstration et d’expérimentation (Tag Thunder : demonstration and experimentation platform)</title>
      <language>fra</language>
      <author><first>Jean-Marc</first><last>Lecarpentier</last></author>
      <author><first>Elena</first><last>Manishina</last></author>
      <author><first>Maxence</first><last>Busson</last></author>
      <author><first>Fabrice</first><last>Maurel</last></author>
      <author><first>Stephane</first><last>Ferrari</last></author>
      <pages>52–54</pages>
      <abstract>Dans cette démonstration, nous proposons un système qui permettrait aux utilisateurs non-voyants d’obtenir le first glance d’une page web. L’objectif est de réduire le temps d’accès à la structure logico-thématique de la page et de favoriser le développement de stratégies de lecture de haut niveau. Notre concept, appelé Tag Thunder, s’appuie sur une phase de segmentation de la page en zones, suivie d’une étape de représentation des zones par un mot ou groupe de mots, puis une vocalisation simultanée de ces représentants.</abstract>
      <url hash="9110f9bf">2016.jeptalnrecital-demo.19</url>
    </paper>
  </volume>
</collection>
