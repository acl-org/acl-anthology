<?xml version='1.0' encoding='UTF-8'?>
<collection id="2022.restup">
  <volume id="1" ingest-date="2022-09-28" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Second International Workshop on Resources and Techniques for User Information in Abusive Language Analysis</booktitle>
      <editor><first>Johanna</first><last>Monti</last></editor>
      <editor><first>Valerio</first><last>Basile</last></editor>
      <editor><first>Maria Pia Di</first><last>Buono</last></editor>
      <editor><first>Raffaele</first><last>Manna</last></editor>
      <editor><first>Antonio</first><last>Pascucci</last></editor>
      <editor><first>Sara</first><last>Tonelli</last></editor>
      <publisher>European Language Resources Association</publisher>
      <address>Marseille, France</address>
      <month>June</month>
      <year>2022</year>
      <url hash="9a9b290a">2022.restup-1</url>
      <venue>restup</venue>
    </meta>
    <frontmatter>
      <url hash="6ce40c22">2022.restup-1.0</url>
      <bibkey>restup-2022-international</bibkey>
    </frontmatter>
    <paper id="1">
      <title>A First Attempt at Unreliable News Detection in <fixed-case>S</fixed-case>wedish</title>
      <author><first>Ricardo</first><last>Muñoz Sánchez</last></author>
      <author><first>Eric</first><last>Johansson</last></author>
      <author><first>Shakila</first><last>Tayefeh</last></author>
      <author><first>Shreyash</first><last>Kad</last></author>
      <pages>1–7</pages>
      <abstract>Throughout the COVID-19 pandemic, a parallel infodemic has also been going on such that the information has been spreading faster than the virus itself. During this time, every individual needs to access accurate news in order to take corresponding protective measures, regardless of their country of origin or the language they speak, as misinformation can cause significant loss to not only individuals but also society. In this paper we train several machine learning models (ranging from traditional machine learning to deep learning) to try to determine whether news articles come from either a reliable or an unreliable source, using just the body of the article. Moreover, we use a previously introduced corpus of news in Swedish related to the COVID-19 pandemic for the classification task. Given that our dataset is both unbalanced and small, we use subsampling and easy data augmentation (EDA) to try to solve these issues. In the end, we realize that, due to the small size of our dataset, using traditional machine learning along with data augmentation yields results that rival those of transformer models such as BERT.</abstract>
      <url hash="74eb1a17">2022.restup-1.1</url>
      <bibkey>munoz-sanchez-etal-2022-first</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>B</fixed-case>angla<fixed-case>H</fixed-case>ate<fixed-case>BERT</fixed-case>: <fixed-case>BERT</fixed-case> for Abusive Language Detection in <fixed-case>B</fixed-case>engali</title>
      <author><first>Md Saroar</first><last>Jahan</last></author>
      <author><first>Mainul</first><last>Haque</last></author>
      <author><first>Nabil</first><last>Arhab</last></author>
      <author><first>Mourad</first><last>Oussalah</last></author>
      <pages>8–15</pages>
      <abstract>This paper introduces BanglaHateBERT, a retrained BERT model for abusive language detection in Bengali. The model was trained with a large-scale Bengali offensive, abusive, and hateful corpus that we have collected from different sources and made available to the public. Furthermore, we have collected and manually annotated 15K Bengali hate speech balanced dataset and made it publicly available for the research community. We used existing pre-trained BanglaBERT model and retrained it with 1.5 million offensive posts. We presented the results of a detailed comparison between generic pre-trained language model and retrained with the abuse-inclined version. In all datasets, BanglaHateBERT outperformed the corresponding available BERT model.</abstract>
      <url hash="0c104474">2022.restup-1.2</url>
      <bibkey>jahan-etal-2022-banglahatebert</bibkey>
    </paper>
    <paper id="3">
      <title>A Comparison of Machine Learning Techniques for <fixed-case>T</fixed-case>urkish Profanity Detection</title>
      <author><first>Levent</first><last>Soykan</last></author>
      <author><first>Cihan</first><last>Karsak</last></author>
      <author><first>Ilknur</first><last>Durgar Elkahlout</last></author>
      <author><first>Burak</first><last>Aytan</last></author>
      <pages>16–24</pages>
      <abstract>Profanity detection became an important task with the increase of social media usage. Most of the users prefer a clean and profanity free environment to communicate with others. In order to provide a such environment for the users, service providers are using various profanity detection tools. In this paper, we researched on Turkish profanity detection in our search engine. We collected and labeled a dataset from search engine queries as one of the two classes: profane and not-profane. We experimented with several classical machine learning and deep learning methods and compared methods in means of speed and accuracy. We performed our best scores with transformer based Electra model with 0.93 F1 Score. We also compared our models with the state-of-the-art Turkish profanity detection tool and observed that we outperform it from all aspects.</abstract>
      <url hash="b6898a99">2022.restup-1.3</url>
      <bibkey>soykan-etal-2022-comparison</bibkey>
    </paper>
    <paper id="4">
      <title>Features and Categories of Hyperbole in Cyberbullying Discourse on Social Media</title>
      <author><first>Simona</first><last>Ignat</last></author>
      <author><first>Carl</first><last>Vogel</last></author>
      <pages>25–31</pages>
      <abstract>Cyberbullying discourse is achieved with multiple linguistic conveyances. Hyperboles witnessed in a corpus of cyberbullying utterances are studied. Linguistic features of hyperbole using the traditional grammatical indications of exaggerations are analyzed. The method relies on data selected from a larger corpus of utterances identified and labelled as “bullying”, from Twitter, from October 2020 to March 2022. An outcome is a lexicon of 250 entries. A small number of lexical level features have been isolated, and chi-squared contingency tests applied to evaluating their information value in identifying hyperbole. Words or affixes indicating superlatives or extremes of scales, with positive but not negative valency items, interact with hyperbole classification in this data set. All utterances extracted has been considered exaggerations and the stylistic status of “hyperbole” has been commented within the frame of new meanings in the context of social media.</abstract>
      <url hash="beaa1169">2022.restup-1.4</url>
      <bibkey>ignat-vogel-2022-features</bibkey>
    </paper>
  </volume>
</collection>
