<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.cl4health">
  <volume id="1" ingest-date="2024-05-18" type="proceedings">
    <meta>
      <booktitle>Proceedings of the First Workshop on Patient-Oriented Language Processing (CL4Health) @ LREC-COLING 2024</booktitle>
      <editor><first>Dina</first><last>Demner-Fushman</last></editor>
      <editor><first>Sophia</first><last>Ananiadou</last></editor>
      <editor><first>Paul</first><last>Thompson</last></editor>
      <editor><first>Brian</first><last>Ondov</last></editor>
      <publisher>ELRA and ICCL</publisher>
      <address>Torino, Italia</address>
      <month>May</month>
      <year>2024</year>
      <url hash="0a35c181">2024.cl4health-1</url>
      <venue>cl4health</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="f1014464">2024.cl4health-1.0</url>
      <bibkey>cl4health-2024-patient</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Improving Sign Language Production in the Healthcare Domain Using <fixed-case>UMLS</fixed-case> and Multi-task Learning</title>
      <author><first>Jonathan</first><last>Mutal</last></author>
      <author id="raphael-rubino"><first>Raphael</first><last>Rubino</last></author>
      <author id="pierrette-bouillon"><first>Pierrette</first><last>Bouillon</last></author>
      <author><first>Bastien</first><last>David</last></author>
      <author><first>Johanna</first><last>Gerlach</last></author>
      <author><first>Irene</first><last>Strasly</last></author>
      <pages>1–7</pages>
      <abstract>This paper presents a study on Swiss-French sign language production in the medical domain. In emergency care settings, a lack of clear communication can interfere with accurate delivery of health related services. For patients communicating with sign language, equal access to healthcare remains an issue. While previous work has explored producing sign language gloss from a source text, we propose to extend this approach to produce a multichannel sign language output given a written French input. Furthermore, we extend our approach with a multi-task framework allowing us to include the Unified Medical Language System (UMLS) in our model. Results show that the introduction of UMLS in the training data improves model accuracy by 13.64 points.</abstract>
      <url hash="be588d51">2024.cl4health-1.1</url>
      <bibkey>mutal-etal-2024-improving</bibkey>
    </paper>
    <paper id="2">
      <title>It’s Difficult to Be Neutral – Human and <fixed-case>LLM</fixed-case>-based Sentiment Annotation of Patient Comments</title>
      <author><first>Petter</first><last>Mæhlum</last></author>
      <author><first>David</first><last>Samuel</last></author>
      <author><first>Rebecka Maria</first><last>Norman</last></author>
      <author><first>Elma</first><last>Jelin</last></author>
      <author><first>Øyvind Andresen</first><last>Bjertnæs</last></author>
      <author id="lilja-ovrelid"><first>Lilja</first><last>Øvrelid</last></author>
      <author><first>Erik</first><last>Velldal</last></author>
      <pages>8–19</pages>
      <abstract>Sentiment analysis is an important tool for aggregating patient voices, in order to provide targeted improvements in healthcare services. A prerequisite for this is the availability of in-domain data annotated for sentiment. This article documents an effort to add sentiment annotations to free-text comments in patient surveys collected by the Norwegian Institute of Public Health (NIPH). However, annotation can be a time-consuming and resource-intensive process, particularly when it requires domain expertise. We therefore also evaluate a possible alternative to human annotation, using large language models (LLMs) as annotators. We perform an extensive evaluation of the approach for two openly available pretrained LLMs for Norwegian, experimenting with different configurations of prompts and in-context learning, comparing their performance to human annotators. We find that even for zero-shot runs, models perform well above the baseline for binary sentiment, but still cannot compete with human annotators on the full dataset.</abstract>
      <url hash="f95fcf7e">2024.cl4health-1.2</url>
      <bibkey>maehlum-etal-2024-difficult</bibkey>
    </paper>
    <paper id="3">
      <title>Simulating Diverse Patient Populations Using Patient Vignettes and Large Language Models</title>
      <author><first>Daniel</first><last>Reichenpfader</last></author>
      <author><first>Kerstin</first><last>Denecke</last></author>
      <pages>20–25</pages>
      <abstract>Ensuring equitable access to digital therapeutics (DTx) is essential to avoid healthcare inequalities in an era of increasing digitization. This requires DTx to be tested with users from diverse populations, which is often not realistic due to time and resource constraints. In this paper, we propose the use of large language models (LLMs) to simulate diverse patients. Specifically, we manually create a patient vignette that characterizes a specific population group. Variations of this vignette are used for role-prompting a commercial LLM, GPT-4, instructing the LLM to take on the role described in the patient vignette and act accordingly. We investigate if the LLM stays in its given role. To do this, we simulate a medical anamnesis interview with the role-prompted LLM and analyze its responses for compliance, coherence, correctness, containment, and clarification. Our results show that GPT-4 generates compliant, coherent and clinically valid responses, including information that is not explicitly stated in the provided patient vignette.</abstract>
      <url hash="859c86e8">2024.cl4health-1.3</url>
      <bibkey>reichenpfader-denecke-2024-simulating</bibkey>
    </paper>
    <paper id="4">
      <title>Annotating Emotions in Acquired Brain Injury Patients’ Narratives</title>
      <author><first>Salomé</first><last>Klein</last></author>
      <author id="amalia-todirascu"><first>Amalia</first><last>Todirascu</last></author>
      <author><first>Hélène</first><last>Vassiliadou</last></author>
      <author><first>Marie</first><last>Kuppelin</last></author>
      <author><first>Joffrey</first><last>Becart</last></author>
      <author><first>Thalassio</first><last>Briand</last></author>
      <author><first>Clara</first><last>Coridon</last></author>
      <author><first>Francine</first><last>Gerhard-Krait</last></author>
      <author><first>Joé</first><last>Laroche</last></author>
      <author><first>Jean</first><last>Ulrich</last></author>
      <author><first>Agata</first><last>Krasny-Pacini</last></author>
      <pages>26–36</pages>
      <abstract>In this article, we aim to measure the patients’ progress in recognizing and naming emotions by capturing a variety of phenomena that express emotion in discourse. To do so, we introduce an emotion annotation scheme adapted for Acquired Brain Injury (ABI) patients’ narratives. We draw on recent research outcomes in line with linguistic and psychological theories of emotion in the development of French resources for Natural Language Processing (NLP). From this perspective and following Battistelli et al. (2022) guidelines, our protocol considers several means of expressing emotions, including prototypical expressions as well as implicit means. Its originality lies on the methodology adopted for its creation, as we combined, adapted, and tested several previous annotation schemes to create a tool tailored to our spoken clinical French corpus and its unique characteristics and challenges.</abstract>
      <url hash="61c13946">2024.cl4health-1.4</url>
      <bibkey>klein-etal-2024-annotating</bibkey>
    </paper>
    <paper id="5">
      <title>Structuring Clinical Notes of <fixed-case>I</fixed-case>talian <fixed-case>ST</fixed-case>-elevation Myocardial Infarction Patients</title>
      <author><first>Vittorio</first><last>Torri</last></author>
      <author><first>Sara</first><last>Mazzucato</last></author>
      <author><first>Stefano</first><last>Dalmiani</last></author>
      <author><first>Umberto</first><last>Paradossi</last></author>
      <author><first>Claudio</first><last>Passino</last></author>
      <author><first>Sara</first><last>Moccia</last></author>
      <author><first>Silvestro</first><last>Micera</last></author>
      <author><first>Francesca</first><last>Ieva</last></author>
      <pages>37–43</pages>
      <abstract>In recent years, it has become common for patients to get full access to their Electronic Health Records (EHRs), thanks to the advancements in the EHRs systems of many healthcare providers. While this access empowers patients and doctors with comprehensive and real-time health information, it also introduces new challenges, in particular due to the unstructured nature of much of the information within EHRs. To address this, we propose a pipeline to structure clinical notes, providing them with a clear and concise overview of their health data and its longitudinal evolution, also allowing clinicians to focus more on patient care during consultations. In this paper, we present preliminary results on extracting structured information from anamneses of patients diagnosed with ST-Elevation Myocardial Infarction from an Italian hospital. Our pipeline exploits text classification models to extract relevant clinical variables, comparing rule-based, recurrent neural network and BERT-based models. While various approaches utilized ontologies or knowledge graphs for Italian data, our work represents the first attempt to develop this type of pipeline. The results for the extraction of most variables are satisfactory (f1-score &gt; 0.80), with the exception of the most rare values of certain variables, for which we propose future research directions to investigate.</abstract>
      <url hash="28aeb989">2024.cl4health-1.5</url>
      <bibkey>torri-etal-2024-structuring</bibkey>
    </paper>
    <paper id="6">
      <title>Towards <fixed-case>AI</fixed-case>-supported Health Communication in Plain Language: Evaluating Intralingual Machine Translation of Medical Texts</title>
      <author><first>Silvana</first><last>Deilen</last></author>
      <author><first>Ekaterina</first><last>Lapshinova-Koltunski</last></author>
      <author><first>Sergio</first><last>Hernández Garrido</last></author>
      <author><first>Christiane</first><last>Maaß</last></author>
      <author><first>Julian</first><last>Hörner</last></author>
      <author><first>Vanessa</first><last>Theel</last></author>
      <author><first>Sophie</first><last>Ziemer</last></author>
      <pages>44–53</pages>
      <abstract>In this paper, we describe results of a study on evaluation of intralingual machine translation. The study focuses on machine translations of medical texts into Plain German. The automatically simplified texts were compared with manually simplified texts (i.e., simplified by human experts) as well as with the underlying, unsimplified source texts. We analyse the quality of the translations based on different criteria, such as correctness, readability, and syntactic complexity. The study revealed that the machine translations were easier to read than the source texts, but contained a higher number of complex syntactic relations than the human translations. Furthermore, we identified various types of mistakes. These included not only grammatical mistakes but also content-related mistakes that resulted, for example, from mistranslations of grammatical structures, ambiguous words or numbers, omissions of relevant prefixes or negation, and incorrect explanations of technical terms.</abstract>
      <url hash="d234a90e">2024.cl4health-1.6</url>
      <bibkey>deilen-etal-2024-towards</bibkey>
    </paper>
    <paper id="7">
      <title>Large Language Models as Drug Information Providers for Patients</title>
      <author><first>Luca</first><last>Giordano</last></author>
      <author><first>Maria Pia</first><last>di Buono</last></author>
      <pages>54–63</pages>
      <abstract>Recently, a significant interest has arisen about the application of Large Language Models (LLMs) in medical settings to enhance various aspects of healthcare. Particularly, the application of such models to improve knowledge access for both clinicians and patients seems very promising but still far from perfect. In this paper, we present a preliminary evaluation of LLMs as drug information providers to support patients in drug administration. We focus on posology, namely dosage quantity and prescription, contraindications and adverse drug reactions and run an experiment on the Italian language to assess both the trustworthiness of the outputs and their readability. The results show that different types of errors affect the LLM answers. In some cases, the model does not recognize the drug name, due to the presence of synonymous words, or it provides untrustworthy information, caused by intrinsic hallucinations. Overall, the complexity of the language is lower and this could contribute to make medical information more accessible to lay people.</abstract>
      <url hash="629c0bf2">2024.cl4health-1.7</url>
      <bibkey>giordano-di-buono-2024-large</bibkey>
    </paper>
    <paper id="8">
      <title>Towards Generation of Personalised Health Intervention Messages</title>
      <author><first>Clara</first><last>Wan Ching Ho</last></author>
      <author><first>Volha</first><last>Petukhova</last></author>
      <pages>64–72</pages>
      <abstract>Self-care is essential in managing chronic diseases when patients could not always be monitored by medical staff. It therefore fills in the gap to provide patients with advice in improving their conditions in day-to-day practices. However, effectiveness of self-interventions in encouraging healthy behaviour is limited, as they are often delivered in the same manner for patients regardless of their demographics, personality and individual preferences. In this paper, we propose strategies to generate personalized health intervention messages departing from assumptions made by theories of social cognition and learning, planned behaviour and information processing. The main task is then defined personalised argument generation task. Specifically, an existing well-performing Natural Language Generation (NLG) pipeline model is extended to modulate linguistic features by ranking texts generated based on individuals’ predicted preferences for persuasive messages. Results show that the model is capable of generating diverse intervention messages while preserving the original intended meaning. The modulated interventions were approved by human evaluators as being more understandable and maintaining the same level of convincingness as human-written texts. However, the generated personalised interventions did not show significant improvements in the power to change health-related attitudes and/or behaviour compared to their non-personalised counterparts. This is attributed to the fact that human data collected for the model’s training was rather limited in size and variation.</abstract>
      <url hash="72ec668a">2024.cl4health-1.8</url>
      <bibkey>wan-ching-ho-petukhova-2024-towards</bibkey>
    </paper>
    <paper id="9">
      <title>Analysing Emotions in Cancer Narratives: A Corpus-Driven Approach</title>
      <author><first>Daisy Monika</first><last>Lal</last></author>
      <author><first>Paul</first><last>Rayson</last></author>
      <author><first>Sheila A.</first><last>Payne</last></author>
      <author><first>Yufeng</first><last>Liu</last></author>
      <pages>73–83</pages>
      <abstract>Cancer not only affects a patient’s physical health, but it can also elicit a wide spectrum of intense emotions in patients, friends, and family members. People with cancer and their carers (family member, partner, or friend) are increasingly turning to the web for information and support. Despite the expansion of sentiment analysis in the context of social media and healthcare, there is relatively less research on patient narratives, which are longer, more complex texts, and difficult to assess. In this exploratory work, we examine how patients and carers express their feelings about various aspects of cancer (treatments and stages). The objective of this paper is to illustrate with examples the nature of language in the clinical domain, as well as the complexities of language when performing automatic sentiment and emotion analysis. We perform a linguistic analysis of a corpus of cancer narratives collected from Reddit. We examine the performance of five state-of-the-art models (T5, DistilBERT, Roberta, RobertaGo, and NRCLex) to see how well they match with human comparisons separated by linguistic and medical background. The corpus yielded several surprising results that could be useful to sentiment analysis NLP experts. The linguistic issues encountered were classified into four categories: statements expressing a variety of emotions, ambiguous or conflicting statements with contradictory emotions, statements requiring additional context, and statements in which sentiment and emotions can be inferred but are not explicitly mentioned.</abstract>
      <url hash="cf9a5f08">2024.cl4health-1.9</url>
      <bibkey>lal-etal-2024-analysing</bibkey>
    </paper>
    <paper id="10">
      <title>Study of Medical Text Reading and Comprehension through Eye-Tracking Fixations</title>
      <author><first>Oksana</first><last>Ivchenko</last></author>
      <author><first>Natalia</first><last>Grabar</last></author>
      <pages>84–92</pages>
      <abstract>Reading plays a crucial role in cognitive processes, acting as the primary way in which people access and assimilate information. However, the ability to effectively comprehend and understand text is significantly influenced by various factors related to people and text types. We propose to study the reading easiness and comprehension of texts through the eye-tracking technology, which tracks gaze and records eye movement during reading. We concentrate on the study of eye-tracking measures related to fixations (average duration of fixations and number of fixations). The experiments are performed on several types of texts (clinical cases, encyclopedia articles related to the medical area, general-language texts, and simplified clinical cases). Eye-tracking measures are analysed quantitatively and qualitatively to draw the reading patterns and analyse how the reading differs across the text types.</abstract>
      <url hash="41a21f48">2024.cl4health-1.10</url>
      <bibkey>ivchenko-grabar-2024-study</bibkey>
    </paper>
    <paper id="11">
      <title>A Neuro-Symbolic Approach to Monitoring Salt Content in Food</title>
      <author><first>Anuja</first><last>Tayal</last></author>
      <author><first>Barbara</first><last>Di Eugenio</last></author>
      <author><first>Devika</first><last>Salunke</last></author>
      <author id="andrew-boyd"><first>Andrew D.</first><last>Boyd</last></author>
      <author><first>Carolyn A.</first><last>Dickens</last></author>
      <author><first>Eulalia P.</first><last>Abril</last></author>
      <author><first>Olga</first><last>Garcia-Bedoya</last></author>
      <author><first>Paula G.</first><last>Allen-Meares</last></author>
      <pages>93–103</pages>
      <abstract>We propose a dialogue system that enables heart failure patients to inquire about salt content in foods and help them monitor and reduce salt intake. Addressing the lack of specific datasets for food-based salt content inquiries, we develop a template-based conversational dataset. The dataset is structured to ask clarification questions to identify food items and their salt content. Our findings indicate that while fine-tuning transformer-based models on the dataset yields limited performance, the integration of Neuro-Symbolic Rules significantly enhances the system’s performance. Our experiments show that by integrating neuro-symbolic rules, our system achieves an improvement in joint goal accuracy of over 20% across different data sizes compared to naively fine-tuning transformer-based models.</abstract>
      <url hash="1d6acdda">2024.cl4health-1.11</url>
      <bibkey>tayal-etal-2024-neuro</bibkey>
    </paper>
    <paper id="12">
      <title>On Simplification of Discharge Summaries in <fixed-case>S</fixed-case>erbian: Facing the Challenges</title>
      <author><first>Anđelka</first><last>Zečević</last></author>
      <author><first>Milica</first><last>Ćulafić</last></author>
      <author><first>Stefan</first><last>Stojković</last></author>
      <pages>104–108</pages>
      <abstract>The simplified information page (SIP) is a simplified discharge summary created to mitigate health risks caused by low medical comprehension. One of the most critical aspects of medical comprehension concerns interpreting medication instructions such as proper dosing, frequency, and duration. In our work, we examine the capacities of mainstream Large Language Models (LLMs) such as ChatGPT and Gemini to generate SIP-like medication-oriented pages based on the provided discharge summaries. We are sharing the initial qualitative assessments of our study based on a small collection of discharge summaries in Serbian, pointing to noticed inaccuracies, unfaithful content, and language quality. Hopefully, these findings might be helpful in addressing the multilingual perspective of patient-oriented language.</abstract>
      <url hash="bb0afcc5">2024.cl4health-1.12</url>
      <bibkey>zecevic-etal-2024-simplification</bibkey>
    </paper>
    <paper id="13">
      <title>Medical-<fixed-case>FLAVORS</fixed-case>: A Figurative Language and Vocabulary Open Repository for <fixed-case>S</fixed-case>panish in the Medical Domain</title>
      <author><first>Lucia</first><last>Pitarch</last></author>
      <author><first>Emma</first><last>Angles-Herrero</last></author>
      <author><first>Yufeng</first><last>Liu</last></author>
      <author><first>Daisy Monika</first><last>Lal</last></author>
      <author><first>Jorge</first><last>Gracia</last></author>
      <author><first>Paul</first><last>Rayson</last></author>
      <author><first>Judith</first><last>Rietjens</last></author>
      <pages>109–114</pages>
      <abstract>Metaphors shape the way we think by enabling the expression of one concept in terms of another one. For instance, cancer can be understood as a place from which one can go in and out, as a journey that one can traverse, or as a battle. Giving patients awareness of the way they refer to cancer and different narratives in which they can reframe it has been proven to be a key aspect when experiencing the disease. In this work, we propose a preliminary identification and representation of Spanish cancer metaphors using MIP (Metaphor Identification Procedure) and MetaNet. The created resource is the first openly available dataset for medical metaphors in Spanish. Thus, in the future, we expect to use it as the gold standard in automatic metaphor processing tasks, which will also serve to further populate the resource and understand how cancer is experienced and narrated.</abstract>
      <url hash="d0fa344b">2024.cl4health-1.13</url>
      <bibkey>pitarch-etal-2024-medical</bibkey>
    </paper>
    <paper id="14">
      <title>Generating Synthetic Documents with Clinical Keywords: A Privacy-Sensitive Methodology</title>
      <author><first>Simon</first><last>Meoni</last></author>
      <author><first>Éric</first><last>De la Clergerie</last></author>
      <author><first>Théo</first><last>Ryffel</last></author>
      <pages>115–123</pages>
      <abstract>Electronic Health Records store valuable patient-staff interaction data. These notes, often unstructured to save healthcare personnel time, can be challenging to analyze manually. Proprietary online Large Language Models have demonstrated impressive results in analyzing EHR notes. However, Clinical NLP faces unique challenges due to the sensitive and specialized nature of the data. Sending patient information via external APIs poses privacy risks, and hospitals require customized NLP systems to align with their unique practices. To address these challenges, developing customized LLMs using specific training datasets is crucial. To address this, we propose generating synthetic training data using keywords extracted without confidential information. Furthermore, we introduce a reward mechanism that iteratively refines the quality of synthetic documents. This involves scoring synthetic candidates against real clinical reports using a semantic textual similarity score and performing an aligment step to align the model with its best-scored utterances.</abstract>
      <url hash="cbcb465d">2024.cl4health-1.14</url>
      <bibkey>meoni-etal-2024-generating</bibkey>
    </paper>
    <paper id="15">
      <title>Building Certified Medical Chatbots: Overcoming Unstructured Data Limitations with Modular <fixed-case>RAG</fixed-case></title>
      <author><first>Leonardo</first><last>Sanna</last></author>
      <author><first>Patrizio</first><last>Bellan</last></author>
      <author><first>Simone</first><last>Magnolini</last></author>
      <author><first>Marina</first><last>Segala</last></author>
      <author><first>Saba</first><last>Ghanbari Haez</last></author>
      <author><first>Monica</first><last>Consolandi</last></author>
      <author><first>Mauro</first><last>Dragoni</last></author>
      <pages>124–130</pages>
      <abstract>Creating a certified conversational agent poses several issues. The need to manage fine-grained information delivery and the necessity to provide reliable medical information requires a notable effort, especially in dataset preparation. In this paper, we investigate the challenges of building a certified medical chatbot in Italian that provides information about pregnancy and early childhood. We show some negative initial results regarding the possibility of creating a certified conversational agent within the RASA framework starting from unstructured data. Finally, we propose a modular RAG model to implement a Large Language Model in a certified context, overcoming data limitations and enabling data collection on actual conversations.</abstract>
      <url hash="5cc8f95b">2024.cl4health-1.15</url>
      <bibkey>sanna-etal-2024-building</bibkey>
    </paper>
    <paper id="16">
      <title>Towards Using Automatically Enhanced Knowledge Graphs to Aid Temporal Relation Extraction</title>
      <author><first>Timotej</first><last>Knez</last></author>
      <author><first>Slavko</first><last>Žitnik</last></author>
      <pages>131–136</pages>
      <abstract>Temporal relation extraction in medical document analysis is crucial for understanding patient histories and treatment outcomes. This paper introduces a novel approach leveraging a bimodal model integrating textual content and a knowledge graph, to enhance temporal relation extraction. The paper presents ongoing research in constructing an optimal knowledge graph by augmenting PrimeKG with dynamically expanded information using a language model-generated knowledge graph, and further personalize the information with patient-specific graphs tailored for relation prediction. The pipeline for constructing this enriched knowledge graph is detailed, aiming to improve the capabilities of temporal relation extraction models. The preliminary results show that adding a simple knowledge graph to the temporal relation extraction model can significantly increase the performance, achieving new state-of-the-art results. While the research in using enhanced knowledge graphs is still ongoing, this paper lays the groundwork for leveraging common knowledge to advance temporal relation extraction in medical contexts. This approach holds promise for enhancing the understanding of patient histories and treatment outcomes, potentially leading to improved healthcare decision-making and patient care.</abstract>
      <url hash="31575496">2024.cl4health-1.16</url>
      <bibkey>knez-zitnik-2024-towards</bibkey>
    </paper>
    <paper id="17">
      <title>Experiments in Automated Generation of Discharge Summaries in <fixed-case>I</fixed-case>talian</title>
      <author><first>Lorenzo</first><last>Ruinelli</last></author>
      <author><first>Amos</first><last>Colombo</last></author>
      <author><first>Mathilde</first><last>Rochat</last></author>
      <author><first>Sotirios Georgios</first><last>Popeskou</last></author>
      <author><first>Andrea</first><last>Franchini</last></author>
      <author><first>Sandra</first><last>Mitrović</last></author>
      <author><first>Oscar William</first><last>Lithgow</last></author>
      <author><first>Joseph</first><last>Cornelius</last></author>
      <author><first>Fabio</first><last>Rinaldi</last></author>
      <pages>137–144</pages>
      <abstract>Hospital discharge letters are a fundamental component of patient management, as they provide the crucial information needed for patient post-hospital care. However their creation is very demanding and resource intensive, as it requires consultation of several reports documenting the patient’s journey throughout their hospital stay. Given the increasing pressures on doctor’s time, tools that can draft a reasonable discharge summary, to be then reviewed and finalized by the experts, would be welcome. In this paper we present a comparative study exploring the possibility of automatic generation of discharge summaries within the context of an hospital in an Italian-speaking region and discuss quantitative and qualitative results. Despite some shortcomings, the obtained results show that a generic generative system such as ChatGPT is capable of producing discharge summaries which are relatively close to the human generated ones, even in Italian.</abstract>
      <url hash="cfa8d560">2024.cl4health-1.17</url>
      <bibkey>ruinelli-etal-2024-experiments</bibkey>
    </paper>
    <paper id="18">
      <title>Evaluating <fixed-case>LLM</fixed-case>s for Temporal Entity Extraction from Pediatric Clinical Text in Rare Diseases Context</title>
      <author><first>Judith Jeyafreeda</first><last>Andrew</last></author>
      <author><first>Marc</first><last>Vincent</last></author>
      <author><first>Anita</first><last>Burgun</last></author>
      <author><first>Nicolas</first><last>Garcelon</last></author>
      <pages>145–152</pages>
      <abstract>The aim of this work is to extract Temporal Entities from patients’ EHR from pediatric hospital specialising in Rare Diseases, thus allowing to create a patient timeline relative to diagnosis . We aim to perform an evaluation of NLP tools and Large Language Models (LLM) to test their application in the field of clinical study where data is limited and sensitive. We present a short annotation guideline for temporal entity identification. We then use the tool EDS-NLP, the Language Model CamemBERT-with-Dates and the LLM Vicuna to extract temporal entities. We perform experiments using three different prompting techniques on the LLM Vicuna to evaluate the model thoroughly. We use a small dataset of 50 EHR describing the evolution of rare diseases in patients to perform our experiments. We show that among the different methods to prompt a LLM, using a decomposed structure of prompting method on the LLM vicuna produces the best results for temporal entity recognition. The LLM learns from examples in the prompt and decomposing one prompt to several prompts allows the model to avoid confusions between the different entity types. Identifying the temporal entities in EHRs helps to build the timeline of a patient and to learn the evolution of a diseases. This is specifically important in the case of rare diseases due to the availability of limited examples. In this paper, we show that this can be made possible with the use of Language Models and LLM in a secure environment, thus preserving the privacy of the patient</abstract>
      <url hash="d5209fef">2024.cl4health-1.18</url>
      <bibkey>andrew-etal-2024-evaluating</bibkey>
    </paper>
    <paper id="19">
      <title>Generating Distributable Surrogate Corpus for Medical Multi-label Classification</title>
      <author><first>Seiji</first><last>Shimizu</last></author>
      <author><first>Shuntaro</first><last>Yada</last></author>
      <author><first>Shoko</first><last>Wakamiya</last></author>
      <author><first>Eiji</first><last>Aramaki</last></author>
      <pages>153–162</pages>
      <abstract>In medical and social media domains, annotated corpora are often hard to distribute due to copyrights and privacy issues. To overcome this situation, we propose a new method to generate a surrogate corpus for a downstream task by using a text generation model. We chose a medical multi-label classification task, MedWeb, in which patient-generated short messages express multiple symptoms. We first fine-tuned text generation models with different prompting designs on the original corpus to obtain synthetic versions of that corpus. To assess the viability of the generated corpora for the downstream task, we compared the performance of multi-label classification models trained either on the original or the surrogate corpora. The results and the error analysis showed the difficulty of generating surrogate corpus in multi-label settings, suggesting text generation under complex conditions is not trivial. On the other hand, our experiment demonstrates that the generated corpus with a sentinel-based prompting is comparatively viable in a single-label (multiclass) classification setting.</abstract>
      <url hash="090fe2ae">2024.cl4health-1.19</url>
      <bibkey>shimizu-etal-2024-generating</bibkey>
    </paper>
    <paper id="20">
      <title><fixed-case>C</fixed-case>lini<fixed-case>R</fixed-case>es: Publicly Available Mapping of Clinical Lexical Resources</title>
      <author><first>Elena</first><last>Zotova</last></author>
      <author><first>Montse</first><last>Cuadros</last></author>
      <author id="german-rigau"><first>German</first><last>Rigau</last></author>
      <pages>163–172</pages>
      <abstract>This paper presents a human-readable resource for mapping identifiers from various clinical knowledge bases. This resource is a version of UMLS Metathesaurus enriched with WordNet 3.0 and 3.1 synsets, Wikidata items with their clinical identifiers, SNOMED CT to ICD-10 mapping and Spanish ICD-10 codes description. The main goal of the presented resource is to provide semantic interoperability across the clinical concepts from various knowledge bases and facilitate its integration into mapping tools. As a side effect, the mapping enriches already annotated medical corpora for entity recognition or entity linking tasks with new labels. We experiment with entity linking task, using a corpus annotated both manually and with the mapping method and demonstrate that a semi-automatic way of annotation may be used to create new labels. The resource is available in English and Spanish, although all languages of UMLS may be extracted. The new lexical resource is publicly available.</abstract>
      <url hash="4adca1af">2024.cl4health-1.20</url>
      <bibkey>zotova-etal-2024-clinires</bibkey>
    </paper>
    <paper id="21">
      <title><fixed-case>M</fixed-case>ed<fixed-case>D</fixed-case>ialog-<fixed-case>FR</fixed-case>: A <fixed-case>F</fixed-case>rench Version of the <fixed-case>M</fixed-case>ed<fixed-case>D</fixed-case>ialog Corpus for Multi-label Classification and Response Generation Related to Women’s Intimate Health</title>
      <author><first>Xingyu</first><last>Liu</last></author>
      <author><first>Vincent</first><last>Segonne</last></author>
      <author><first>Aidan</first><last>Mannion</last></author>
      <author><first>Didier</first><last>Schwab</last></author>
      <author><first>Lorraine</first><last>Goeuriot</last></author>
      <author><first>François</first><last>Portet</last></author>
      <pages>173–183</pages>
      <abstract>This article presents MedDialog-FR, a large publicly available corpus of French medical conversations for the medical domain. Motivated by the lack of French dialogue corpora for data-driven dialogue systems and the paucity of available information related to women’s intimate health, we introduce an annotated corpus of question-and-answer dialogues between a real patient and a real doctor concerning women’s intimate health. The corpus is composed of about 20,000 dialogues automatically translated from the English version of MedDialog-EN. The corpus test set is composed of 1,400 dialogues that have been manually post-edited and annotated with 22 categories from the UMLS ontology. We also fine-tuned state-of-the-art reference models to automatically perform multi-label classification and response generation to give an initial performance benchmark and highlight the difficulty of the tasks.</abstract>
      <url hash="f320b71f">2024.cl4health-1.21</url>
      <bibkey>liu-etal-2024-meddialog</bibkey>
    </paper>
    <paper id="22">
      <title>Exploring the Suitability of Transformer Models to Analyse Mental Health Peer Support Forum Data for a Realist Evaluation</title>
      <author><first>Matthew</first><last>Coole</last></author>
      <author><first>Paul</first><last>Rayson</last></author>
      <author><first>Zoe</first><last>Glossop</last></author>
      <author><first>Fiona</first><last>Lobban</last></author>
      <author><first>Paul</first><last>Marshall</last></author>
      <author><first>John</first><last>Vidler</last></author>
      <pages>184–188</pages>
      <abstract>Mental health peer support forums have become widely used in recent years. The emerging mental health crisis and the COVID-19 pandemic have meant that finding a place online for support and advice when dealing with mental health issues is more critical than ever. The need to examine, understand and find ways to improve the support provided by mental health forums is vital in the current climate. As part of this, we present our initial explorations in using modern transformer models to detect four key concepts (connectedness, lived experience, empathy and gratitude), which we believe are essential to understanding how people use mental health forums and will serve as a basis for testing more expansive realise theories about mental health forums in the future. As part of this work, we also replicate previously published results on empathy utilising an existing annotated dataset and test the other concepts on our manually annotated mental health forum posts dataset. These results serve as a basis for future research examining peer support forums.</abstract>
      <url hash="17d321d7">2024.cl4health-1.22</url>
      <bibkey>coole-etal-2024-exploring</bibkey>
    </paper>
    <paper id="23">
      <title>Revisiting the <fixed-case>MIMIC</fixed-case>-<fixed-case>IV</fixed-case> Benchmark: Experiments Using Language Models for Electronic Health Records</title>
      <author><first>Jesus</first><last>Lovon-Melgarejo</last></author>
      <author><first>Thouria</first><last>Ben-Haddi</last></author>
      <author><first>Jules</first><last>Di Scala</last></author>
      <author id="jose-g-moreno"><first>Jose G.</first><last>Moreno</last></author>
      <author><first>Lynda</first><last>Tamine</last></author>
      <pages>189–196</pages>
      <abstract>The lack of standardized evaluation benchmarks in the medical domain for text inputs can be a barrier to widely adopting and leveraging the potential of natural language models for health-related downstream tasks. This paper revisited an openly available MIMIC-IV benchmark for electronic health records (EHRs) to address this issue. First, we integrate the MIMIC-IV data within the Hugging Face datasets library to allow an easy share and use of this collection. Second, we investigate the application of templates to convert EHR tabular data to text. Experiments using fine-tuned and zero-shot LLMs on the mortality of patients task show that fine-tuned text-based models are competitive against robust tabular classifiers. In contrast, zero-shot LLMs struggle to leverage EHR representations. This study underlines the potential of text-based approaches in the medical field and highlights areas for further improvement.</abstract>
      <url hash="d477f4ab">2024.cl4health-1.23</url>
      <bibkey>lovon-melgarejo-etal-2024-revisiting</bibkey>
    </paper>
    <paper id="24">
      <title>Unraveling Clinical Insights: A Lightweight and Interpretable Approach for Multimodal and Multilingual Knowledge Integration</title>
      <author><first>Kanimozhi</first><last>Uma</last></author>
      <author id="marie-francine-moens"><first>Marie-Francine</first><last>Moens</last></author>
      <pages>197–203</pages>
      <abstract>In recent years, the analysis of clinical texts has evolved significantly, driven by the emergence of language models like BERT such as PubMedBERT, and ClinicalBERT, which have been tailored for the (bio)medical domain that rely on extensive archives of medical documents. While they boast high accuracy, their lack of interpretability and language transfer limitations restrict their clinical utility. To address this, we propose a new, lightweight graph-based embedding method designed specifically for radiology reports. This approach considers the report’s structure and content, connecting medical terms through the multilingual SNOMED Clinical Terms knowledge base. The resulting graph embedding reveals intricate relationships among clinical terms, enhancing both clinician comprehension and clinical accuracy without the need for large pre-training datasets. Demonstrating the versatility of our method, we apply this embedding to two tasks: disease and image classification in X-ray reports. In disease classification, our model competes effectively with BERT-based approaches, yet it is significantly smaller and requires less training data. Additionally, in image classification, we illustrate the efficacy of the graph embedding by leveraging cross-modal knowledge transfer, highlighting its applicability across diverse languages.</abstract>
      <url hash="708a9e53">2024.cl4health-1.24</url>
      <bibkey>uma-moens-2024-unraveling</bibkey>
    </paper>
    <paper id="25">
      <title>Automated Question-Answer Generation for Evaluating <fixed-case>RAG</fixed-case>-based Chatbots</title>
      <author><first>Juan José</first><last>González Torres</last></author>
      <author><first>Mihai Bogdan</first><last>Bîndilă</last></author>
      <author><first>Sebastiaan</first><last>Hofstee</last></author>
      <author><first>Daniel</first><last>Szondy</last></author>
      <author><first>Quang-Hung</first><last>Nguyen</last></author>
      <author><first>Shenghui</first><last>Wang</last></author>
      <author><first>Gwenn</first><last>Englebienne</last></author>
      <pages>204–214</pages>
      <abstract>In this research, we propose a framework to generate human-like question-answer pairs with long or factoid answers automatically and, based on them, automatically evaluate the quality of Retrieval-Augmented Generation (RAG). Our framework can also create datasets that assess hallucination levels of Large Language Models (LLMs) by simulating unanswerable questions. We then apply the framework to create a dataset of question-answer (QA) pairs based on more than 1,000 leaflets about the medical and administrative procedures of a hospital. The dataset was evaluated by hospital specialists, who confirmed that more than 50% of the QA pairs are applicable. Finally, we show that our framework can be used to evaluate LLM performance by using Llama-2-13B fine-tuned in Dutch (Vanroy, 2023) with the generated dataset, and show the method’s use in testing models with regard to answering unanswerable and factoid questions appears promising.</abstract>
      <url hash="4b9b7408">2024.cl4health-1.25</url>
      <bibkey>gonzalez-torres-etal-2024-automated</bibkey>
    </paper>
    <paper id="26">
      <title>Speech Accommodation in Health-Care Interactions: Evidence Using a Mixed-Reality Platform</title>
      <author><first>Rose</first><last>Baker</last></author>
      <author><first>Susan C.</first><last>Bobb</last></author>
      <author><first>Dai’Sha</first><last>Dowson</last></author>
      <author><first>Elisha</first><last>Eanes</last></author>
      <author><first>Makyah</first><last>McNeill</last></author>
      <author><first>Hannah</first><last>Ragsdale</last></author>
      <author><first>Audrey</first><last>Eaves</last></author>
      <author><first>Joseph G.</first><last>Lee</last></author>
      <author><first>Kathrin</first><last>Rothermich</last></author>
      <pages>215–219</pages>
      <abstract>Many people in the US use more than one language at home, yet English remains the dominant (L1) language in US society, which can complicate medical encounters. In this study we ask in what ways effective communication can be ensured in health care settings when speakers differ in language proficiency. One strategy people use is second language (L2) speech accommodation, which is characterized by slowed speech, less complex words, and clearer enunciation. We employ a mixed-reality platform called MURSION to document how a group of Physician Assistant students use speech accommodation during a healthcare encounter. MURSION is a computer-based virtual environment where participants interact with an Avatar controlled by a human interactor in a standardized environment. We record 5-minute interactions between the student and a high or low English proficiency Avatar. Our analyses evaluate lexical choices in L1-L2 interactions with SCOPE (South Carolina Psycholinguistic Metabase) and acoustic properties with PRAAT. Results show that clinical students use slower speech and high frequency words when speaking to a low proficiency virtual patient, indicating a sensitivity for the communicative needs of L2 English users. Speech accommodation results will contribute to communication training modules for clinicians to interact efficiently with linguistically diverse populations.</abstract>
      <url hash="67c65b6d">2024.cl4health-1.26</url>
      <bibkey>baker-etal-2024-speech</bibkey>
    </paper>
    <paper id="27">
      <title>Enhancing Consumer Health Question Reformulation: Chain-of-Thought Prompting Integrating Focus, Type, and User Knowledge Level</title>
      <author><first>Jooyeon</first><last>Lee</last></author>
      <author><first>Luan Huy</first><last>Pham</last></author>
      <author id="ozlem-uzuner"><first>Özlem</first><last>Uzuner</last></author>
      <pages>220–228</pages>
      <abstract>In this paper, we explore consumer health question (CHQ) reformulation, focusing on enhancing the quality of reformation of questions without considering interest shifts. Our study introduces the use of the NIH GARD website as a gold standard dataset for this specific task, emphasizing its relevance and applicability. Additionally, we developed other datasets consisting of related questions scraped from Google, Bing, and Yahoo. We augmented, evaluated and analyzed the various datasets, demonstrating that the reformulation task closely resembles the question entailment generation task. Our approach, which integrates the Focus and Type of consumer inquiries, represents a significant advancement in the field of question reformulation. We provide a comprehensive analysis of different methodologies, offering insights into the development of more effective and user-centric AI systems for consumer health support.</abstract>
      <url hash="6c73da3b">2024.cl4health-1.27</url>
      <bibkey>lee-etal-2024-enhancing</bibkey>
    </paper>
    <paper id="28">
      <title>Exploring the Challenges of Behaviour Change Language Classification: A Study on Semi-Supervised Learning and the Impact of Pseudo-Labelled Data</title>
      <author><first>Selina</first><last>Meyer</last></author>
      <author><first>Marcos</first><last>Fernandez-Pichel</last></author>
      <author><first>David</first><last>Elsweiler</last></author>
      <author><first>David E.</first><last>Losada</last></author>
      <pages>229–239</pages>
      <abstract>Automatic classification of behaviour change language can enhance conversational agents’ capabilities to adjust their behaviour based on users’ current situations and to encourage individuals to make positive changes. However, the lack of annotated language data of change-seekers hampers the performance of existing classifiers. In this study, we investigate the use of semi-supervised learning (SSL) to classify highly imbalanced texts around behaviour change. We assess the impact of including pseudo-labelled data from various sources and examine the balance between the amount of added pseudo-labelled data and the strictness of the inclusion criteria. Our findings indicate that while adding pseudo-labelled samples to the training data has limited classification impact, it does not significantly reduce performance regardless of the source of these new samples. This reinforces previous findings on the feasibility of applying classifiers trained on behaviour change language to diverse contexts.</abstract>
      <url hash="02ea42f9">2024.cl4health-1.28</url>
      <bibkey>meyer-etal-2024-exploring</bibkey>
    </paper>
    <paper id="29">
      <title>Development of a Benchmark Corpus for Medical Device Adverse Event Detection</title>
      <author><first>Susmitha</first><last>Wunnava</last></author>
      <author><first>David</first><last>Harris</last></author>
      <author><first>Florence T.</first><last>Bourgeois</last></author>
      <author><first>Timothy A.</first><last>Miller</last></author>
      <pages>240–245</pages>
      <abstract>The U.S. Food and Drug Administration (FDA) collects real-world adverse events, including device-associated deaths, injuries, and malfunctions, through passive reporting to the agency’s Manufacturer and User Facility Device Experience (MAUDE) database. However, this system’s full potential remains untapped given the extensive use of unstructured text in medical device adverse event reports and lack of FDA resources and expertise to properly analyze all available data. In this work, we focus on addressing this limitation through the development of an annotated benchmark corpus to support the design and development of state-of-the-art NLP approaches towards automatic extraction of device-related adverse event information from FDA Medical Device Adverse Event Reports. We develop a dataset of labeled medical device reports from a diverse set of high-risk device types, that can be used for supervised machine learning. We develop annotation guidelines and manually annotate for nine entity types. The resulting dataset contains 935 annotated adverse event reports, containing 12252 annotated spans across the nine entity types. The dataset developed in this work will be made publicly available upon publication.</abstract>
      <url hash="6da4d2aa">2024.cl4health-1.29</url>
      <bibkey>wunnava-etal-2024-development</bibkey>
    </paper>
    <paper id="30">
      <title>Using <fixed-case>BART</fixed-case> to Automatically Generate Discharge Summaries from <fixed-case>S</fixed-case>wedish Clinical Text</title>
      <author><first>Nils</first><last>Berg</last></author>
      <author><first>Hercules</first><last>Dalianis</last></author>
      <pages>246–252</pages>
      <abstract>Documentation is a regular part of contemporary healthcare practices and one such documentation task is the creation of a discharge summary, which summarizes a care episode. However, to manually write discharge summaries is a time-consuming task, and research has shown that discharge summaries are often lacking quality in various respects. To alleviate this problem, text summarization methods could be applied on text from electronic health records, such as patient notes, to automatically create a discharge summary. Previous research has been conducted on this topic on text in various languages and with various methods, but no such research has been conducted on Swedish text. In this paper, four datasets extracted from a Swedish clinical corpora were used to fine-tune four BART language models to perform the task of summarizing Swedish patient notes into a discharge summary. Out of these models, the best performing model was manually evaluated by a senior, now retired, nurse and clinical coder. The evaluation results show that the best performing model produces discharge summaries of overall low quality. This is possibly due to issues in the data extracted from the Health Bank research infrastructure, which warrants further work on this topic.</abstract>
      <url hash="88d6d056">2024.cl4health-1.30</url>
      <bibkey>berg-dalianis-2024-using</bibkey>
    </paper>
    <paper id="31">
      <title>Biomedical Entity Linking for <fixed-case>D</fixed-case>utch: Fine-tuning a Self-alignment <fixed-case>BERT</fixed-case> Model on an Automatically Generated <fixed-case>W</fixed-case>ikipedia Corpus</title>
      <author><first>Fons</first><last>Hartendorp</last></author>
      <author><first>Tom</first><last>Seinen</last></author>
      <author id="erik-van-mulligen"><first>Erik</first><last>van Mulligen</last></author>
      <author><first>Suzan</first><last>Verberne</last></author>
      <pages>253–263</pages>
      <abstract>Biomedical entity linking, a main component in automatic information extraction from health-related texts, plays a pivotal role in connecting textual entities (such as diseases, drugs and body parts mentioned by patients) to their corresponding concepts in a structured biomedical knowledge base. The task remains challenging despite recent developments in natural language processing. This report presents the first evaluated biomedical entity linking model for the Dutch language. We use MedRoBERTa.nl as basemodel and perform second-phase pretraining through self-alignment on a Dutch biomedical ontology extracted from the UMLS and Dutch SNOMED. We derive a corpus from Wikipedia of ontology-linked Dutch biomedical entities in context and fine-tune our model on this dataset. We evaluate our model on the Dutch portion of the Mantra GSC-corpus and achieve 54.7% classification accuracy and 69.8% 1-distance accuracy. We then perform a case study on a collection of unlabeled, patient-support forum data and show that our model is hampered by the limited quality of the preceding entity recognition step. Manual evaluation of small sample indicates that of the correctly extracted entities, around 65% is linked to the correct concept in the ontology. Our results indicate that biomedical entity linking in a language other than English remains challenging, but our Dutch model can be used to for high-level analysis of patient-generated text.</abstract>
      <url hash="31c2e447">2024.cl4health-1.31</url>
      <bibkey>hartendorp-etal-2024-biomedical</bibkey>
    </paper>
    <paper id="32">
      <title>Unveiling Voices: Identification of Concerns in a Social Media Breast Cancer Cohort via Natural Language Processing</title>
      <author><first>Swati</first><last>Rajwal</last><affiliation>Dept. of Biomedical Informatics, Emory University</affiliation></author>
      <author><first>Avinash Kumar</first><last>Pandey</last><affiliation>Goizueta Business School, Emory University</affiliation></author>
      <author><first>Zhishuo</first><last>Han</last><affiliation>Goizueta Business School, Emory University</affiliation></author>
      <author><first>Abeed</first><last>Sarker</last><affiliation>Dept. of Biomedical Informatics, Emory University</affiliation></author>
      <pages>264–270</pages>
      <abstract>We leveraged a dataset of ∼1.5 million Twitter (now X) posts to develop a framework for analyzing breast cancer (BC) patients’ concerns and possible reasons for treatment discontinuation. Our primary objectives were threefold: (1) to curate and collect data from a BC cohort; (2) to identify topics related to uncertainty/concerns in BC-related posts; and (3) to conduct a sentiment intensity analysis of posts to identify and analyze negatively polarized posts. RoBERTa outperformed other models with a micro-averaged F1 score of 0.894 and a macro-averaged F1 score of 0.853 for (1). For (2), we used GPT-4 and BERTopic, and qualitatively analyzed posts under relevant topics. For (3), sentiment intensity analysis of posts followed by qualitative analyses shed light on potential reasons behind treatment discontinuation. Our work demonstrates the utility of social media mining to discover BC patient concerns. Information derived from the cohort data may help design strategies in the future for increasing treatment compliance.</abstract>
      <url hash="d166b733">2024.cl4health-1.32</url>
      <bibkey>rajwal-etal-2024-unveiling</bibkey>
    </paper>
    <paper id="33">
      <title>Intent Detection and Entity Extraction from Biomedical Literature</title>
      <author><first>Ankan</first><last>Mullick</last></author>
      <author><first>Mukur</first><last>Gupta</last></author>
      <author><first>Pawan</first><last>Goyal</last></author>
      <pages>271–278</pages>
      <abstract>Biomedical queries have become increasingly prevalent in web searches, reflecting the growing interest in accessing biomedical literature. Despite recent research on large-language models (LLMs) motivated by endeavors to attain generalized intelligence, their efficacy in replacing task and domain-specific natural language understanding approaches remains questionable. In this paper, we address this question by conducting a comprehensive empirical evaluation of intent detection and named entity recognition (NER) tasks from biomedical text. We show that Supervised Fine Tuned approaches are still relevant and more effective than general-purpose LLMs. Biomedical transformer models such as PubMedBERT can surpass ChatGPT on NER task with only 5 supervised examples.</abstract>
      <url hash="c744373f">2024.cl4health-1.33</url>
      <bibkey>mullick-etal-2024-intent</bibkey>
    </paper>
  </volume>
</collection>
