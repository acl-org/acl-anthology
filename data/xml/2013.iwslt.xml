<?xml version='1.0' encoding='UTF-8'?>
<collection id="2013.iwslt">
  <volume id="keynote" ingest-date="2021-08-08" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 10th International Workshop on Spoken Language Translation: Keynote</booktitle>
      <address>Heidelberg, Germany</address>
      <month>December 5-6</month>
      <year>2013</year>
      <editor><first>Joy Ying</first><last>Zhang</last></editor>
      <venue>iwslt</venue>
    </meta>
    <paper id="1">
      <title>The human interpreter in action – multilingualism at the <fixed-case>E</fixed-case>uropean Parliament</title>
      <author><first>Susanne</first><last>Altenberg</last></author>
      <attachment type="presentation" hash="e3b1811f">2013.iwslt-keynote.1.Presentation.pdf</attachment>
      <bibkey>altenberg-2013-human</bibkey>
    </paper>
  </volume>
  <volume id="evaluation" ingest-date="2021-08-08" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 10th International Workshop on Spoken Language Translation: Evaluation Campaign</booktitle>
      <address>Heidelberg, Germany</address>
      <month>December 5-6</month>
      <year>2013</year>
      <editor><first>Joy Ying</first><last>Zhang</last></editor>
      <venue>iwslt</venue>
    </meta>
    <paper id="1">
      <title>Report on the 10th <fixed-case>IWSLT</fixed-case> evaluation campaign</title>
      <author><first>Mauro</first><last>Cettolo</last></author>
      <author><first>Jan</first><last>Niehues</last></author>
      <author><first>Sebastian</first><last>Stüker</last></author>
      <author><first>Luisa</first><last>Bentivogli</last></author>
      <author><first>Marcello</first><last>Federico</last></author>
      <url hash="0253c927">2013.iwslt-evaluation.1</url>
      <abstract>The paper overviews the tenth evaluation campaign organized by the IWSLT workshop. The 2013 evaluation offered multiple tracks on lecture transcription and translation based on the TED Talks corpus. In particular, this year IWSLT included two automatic speech recognition tracks, on English and German, three speech translation tracks, from English to French, English to German, and German to English, and three text translation track, also from English to French, English to German, and German to English. In addition to the official tracks, speech and text translation optional tracks were offered involving 12 other languages: Arabic, Spanish, Portuguese (B), Italian, Chinese, Polish, Persian, Slovenian, Turkish, Dutch, Romanian, Russian. Overall, 18 teams participated in the evaluation for a total of 217 primary runs submitted. All runs were evaluated with objective metrics on a current test set and two progress test sets, in order to compare the progresses against systems of the previous years. In addition, submissions of one of the official machine translation tracks were also evaluated with human post-editing.</abstract>
      <bibkey>cettolo-etal-2013-report</bibkey>
    </paper>
    <paper id="2">
      <title>Human semantic <fixed-case>MT</fixed-case> evaluation with <fixed-case>HMEANT</fixed-case> for <fixed-case>IWSLT</fixed-case> 2013</title>
      <author><first>Chi-kiu</first><last>Lo</last></author>
      <author><first>Dekai</first><last>Wu</last></author>
      <url hash="bd5f946e">2013.iwslt-evaluation.2</url>
      <abstract>We present the results of large-scale human semantic MT evaluation with HMEANT on the IWSLT 2013 German-English MT and SLT tracks and show that HMEANT evaluates the performance of the MT systems differently compared to BLEU and TER. Together with the references, all the translations are annotated by annotators who are native English speakers in both semantic role labeling stage and role filler alignment stage of HMEANT. We obtain high inter-annotator agreement and low annotation time costs which indicate that it is feasible to run a large-scale human semantic MT evaluation campaign using HMEANT. Our results also show that HMEANT is a robust and reliable semantic MT evaluation metric for running large-scale evaluation campaigns as it is inexpensive and simple while maintaining the semantic representational transparency to provide a perspective which is different from BLEU and TER in order to understand the performance of the state-of-the-art MT systems.</abstract>
      <bibkey>lo-wu-2013-human</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>E</fixed-case>nglish <fixed-case>SLT</fixed-case> and <fixed-case>MT</fixed-case> system description for the <fixed-case>IWSLT</fixed-case> 2013 evaluation</title>
      <author><first>Alexandra</first><last>Birch</last></author>
      <author><first>Nadir</first><last>Durrani</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <url hash="3ff16ca1">2013.iwslt-evaluation.3</url>
      <abstract>This paper gives a description of the University of Edinburgh’s (UEDIN) systems for IWSLT 2013. We participated in all the MT tracks and the German-to-English and Englishto-French SLT tracks. Our SLT submissions experimented with including ASR uncertainty into the decoding process via confusion networks, and looked at different ways of punctuating ASR output. Our MT submissions are mainly based on a system used in the recent evaluation campaign at the Workshop on Statistical Machine Translation [1]. We additionally explored the use of generalized representations (Brown clusters, POS and morphological tags) translating out of English into European languages.</abstract>
      <bibkey>birch-etal-2013-english</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>MSR</fixed-case>-<fixed-case>FBK</fixed-case> <fixed-case>IWSLT</fixed-case> 2013 <fixed-case>SLT</fixed-case> system description</title>
      <author><first>Anthony</first><last>Aue</last></author>
      <author><first>Qin</first><last>Gao</last></author>
      <author><first>Hany</first><last>Hassan</last></author>
      <author><first>Xiaodong</first><last>He</last></author>
      <author><first>Gang</first><last>Li</last></author>
      <author><first>Nicholas</first><last>Ruiz</last></author>
      <author><first>Frank</first><last>Seide</last></author>
      <url hash="24e01689">2013.iwslt-evaluation.4</url>
      <abstract>This paper describes the systems used for the MSR+FBK submission for the SLT track of IWSLT 2013. Starting from a baseline system we made a series of iterative and additive improvements, including a novel method for processing bilingual data used to train MT systems for use on ASR output. Our primary submission is a system combination of five individual systems, combining the output of multiple ASR engines with multiple MT techniques. There are two contrastive submissions to help place the combined system in context. We describe the systems used and present results on the test sets.</abstract>
      <bibkey>aue-etal-2013-msr</bibkey>
    </paper>
    <paper id="5">
      <title>Improving machine translation into <fixed-case>C</fixed-case>hinese by tuning against <fixed-case>C</fixed-case>hinese <fixed-case>MEANT</fixed-case></title>
      <author><first>Chi-kiu</first><last>Lo</last></author>
      <author><first>Meriem</first><last>Beloucif</last></author>
      <author><first>Dekai</first><last>Wu</last></author>
      <url hash="71d88ebf">2013.iwslt-evaluation.5</url>
      <abstract>We present the first ever results showing that Chinese MT output is significantly improved by tuning a MT system against a semantic frame based objective function, MEANT, rather than an n-gram based objective function, BLEU, as measured across commonly used metrics and different test sets. Recent work showed that by preserving the meaning of the translations as captured by semantic frames in the training process, MT systems for translating into English on both formal and informal genres are constrained to produce more adequate translations by making more accurate choices on lexical output and reordering rules. In this paper we describe our experiments in IWSLT 2013 TED talk MT tasks on tuning MT systems against MEANT for translating into Chinese and English respectively. We show that the Chinese translation output benefits more from tuning a MT system against MEANT than the English translation output due to the ambiguous nature of word boundaries in Chinese. Our encouraging results show that using MEANT is a promising alternative to BLEU in both evaluating and tuning MT systems to drive the progress of MT research across different languages.</abstract>
      <bibkey>lo-etal-2013-improving-machine</bibkey>
    </paper>
    <paper id="6">
      <title>The <fixed-case>NICT</fixed-case> <fixed-case>ASR</fixed-case> system for <fixed-case>IWSLT</fixed-case> 2013</title>
      <author><first>Chien-Lin</first><last>Huang</last></author>
      <author><first>Paul R.</first><last>Dixon</last></author>
      <author><first>Shigeki</first><last>Matsuda</last></author>
      <author><first>Youzheng</first><last>Wu</last></author>
      <author><first>Xugang</first><last>Lu</last></author>
      <author><first>Masahiro</first><last>Saiko</last></author>
      <author><first>Chiori</first><last>Hori</last></author>
      <url hash="99863774">2013.iwslt-evaluation.6</url>
      <abstract>This study presents the NICT automatic speech recognition (ASR) system submitted for the IWSLT 2013 ASR evaluation. We apply two types of acoustic features and three types of acoustic models to the NICT ASR system. Our system is comprised of six subsystems with different acoustic features and models. This study reports the individual results and fusion of systems and highlights the improvements made by our proposed methods that include the automatic segmentation of audio data, language model adaptation, speaker adaptive training of deep neural network models, and the NICT SprinTra decoder. Our experimental results indicated that our proposed methods offer good performance improvements on lecture speech recognition tasks. Our results denoted a 13.5% word error rate on the IWSLT 2013 ASR English test data set.</abstract>
      <bibkey>huang-etal-2013-nict</bibkey>
    </paper>
    <paper id="7">
      <title><fixed-case>FBK</fixed-case> @ <fixed-case>IWSLT</fixed-case> 2013 – <fixed-case>ASR</fixed-case> tracks</title>
      <author><first>Daniele</first><last>Falavigna</last></author>
      <author><first>Roberto</first><last>Gretter</last></author>
      <author><first>Fabio</first><last>Brugnara</last></author>
      <author><first>Diego</first><last>Giuliani</last></author>
      <url hash="14462b66">2013.iwslt-evaluation.7</url>
      <abstract>This paper reports on the participation of FBK at the IWSLT2013 evaluation campaign on automatic speech recognition (ASR): precisely on both English and German ASR track. Only primary submissions have been sent for evaluation. For English, the ASR system features acoustic models trained on a portion of the TED talk recordings that was automatically selected according to the fidelity of the provided transcriptions. Two decoding steps are performed interleaved by acoustic feature normalization and acoustic model adaptation. A final step combines the outputs obtained after having rescored the word graphs generated in the second decoding step with 4 different language models. The latter are trained on: out-of-domain text data, in-domain data and several sets of automatically selected data. For German, acoustic models have been trained on automatically selected portions of a broadcast news corpus, called ”Euronews”. Differently from English, in this case only two decoding steps are carried out without making use of any rescoring procedure.</abstract>
      <bibkey>falavigna-etal-2013-fbk</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>QCRI</fixed-case> at <fixed-case>IWSLT</fixed-case> 2013: experiments in <fixed-case>A</fixed-case>rabic-<fixed-case>E</fixed-case>nglish and <fixed-case>E</fixed-case>nglish-<fixed-case>A</fixed-case>rabic spoken language translation</title>
      <author><first>Hassan</first><last>Sajjad</last></author>
      <author><first>Francisco</first><last>Guzmán</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <author><first>Ahmed</first><last>Abdelali</last></author>
      <author><first>Kenton</first><last>Murray</last></author>
      <author><first>Fahad</first><last>Al Obaidli</last></author>
      <author><first>Stephan</first><last>Vogel</last></author>
      <url hash="de35bb70">2013.iwslt-evaluation.8</url>
      <abstract>We describe the Arabic-English and English-Arabic statistical machine translation systems developed by the Qatar Computing Research Institute for the IWSLT’2013 evaluation campaign on spoken language translation. We used one phrase-based and two hierarchical decoders, exploring various settings thereof. We further experimented with three domain adaptation methods, and with various Arabic word segmentation schemes. Combining the output of several systems yielded a gain of up to 3.4 BLEU points over the baseline. Here we also describe a specialized normalization scheme for evaluating Arabic output, which was adopted for the IWSLT’2013 evaluation campaign.</abstract>
      <bibkey>sajjad-etal-2013-qcri-iwslt</bibkey>
    </paper>
    <paper id="9">
      <title>A discriminative reordering parser for <fixed-case>IWSLT</fixed-case> 2013</title>
      <author><first>Hwidong</first><last>Na</last></author>
      <author><first>Jong-Hyeok</first><last>Lee</last></author>
      <url hash="45f222ea">2013.iwslt-evaluation.9</url>
      <abstract>We participated in the IWSLT 2013 Evaluation Campaign for the MT track for two official directions: German↔English. Our system consisted of a reordering module and a statistical machine translation (SMT) module under a pre-ordering SMT framework. We trained the reordering module using three scalable methods in order to utilize training instances as many as possible. The translation quality of our primary submissions were comparable to that of a hierarchical phrasebased SMT, which usually requires a longer time to decode.</abstract>
      <bibkey>na-lee-2013-discriminative</bibkey>
    </paper>
    <paper id="10">
      <title>The <fixed-case>RWTH</fixed-case> <fixed-case>A</fixed-case>achen machine translation systems for <fixed-case>IWSLT</fixed-case> 2013</title>
      <author><first>Joern</first><last>Wuebker</last></author>
      <author><first>Stephan</first><last>Peitz</last></author>
      <author><first>Tamer</first><last>Alkhouli</last></author>
      <author><first>Jan-Thorsten</first><last>Peter</last></author>
      <author><first>Minwei</first><last>Feng</last></author>
      <author><first>Markus</first><last>Freitag</last></author>
      <author><first>Hermann</first><last>Ney</last></author>
      <url hash="a15389eb">2013.iwslt-evaluation.10</url>
      <abstract>This work describes the statistical machine translation (SMT) systems of RWTH Aachen University developed for the evaluation campaign International Workshop on Spoken Language Translation (IWSLT) 2013. We participated in the English→French, English↔German, Arabic→English, Chinese→English and Slovenian↔English MT tracks and the English→French and English→German SLT tracks. We apply phrase-based and hierarchical SMT decoders, which are augmented by state-of-the-art extensions. The novel techniques we experimentally evaluate include discriminative phrase training, a continuous space language model, a hierarchical reordering model, a word class language model, domain adaptation via data selection and system combination of standard and reverse order models. By application of these methods we can show considerable improvements over the respective baseline systems.</abstract>
      <bibkey>wuebker-etal-2013-rwth</bibkey>
    </paper>
    <paper id="11">
      <title>Description of the <fixed-case>UEDIN</fixed-case> system for <fixed-case>G</fixed-case>erman <fixed-case>ASR</fixed-case></title>
      <author><first>Joris</first><last>Driesen</last></author>
      <author><first>Peter</first><last>Bell</last></author>
      <author><first>Mark</first><last>Sinclair</last></author>
      <author><first>Steve</first><last>Renals</last></author>
      <url hash="59c71e6c">2013.iwslt-evaluation.11</url>
      <abstract>In this paper we describe the ASR system for German built at the University of Edinburgh (UEDIN) for the 2013 IWSLT evaluation campaign. For ASR, the major challenge to overcome, was to find suitable acoustic training data. Due to the lack of expertly transcribed acoustic speech data for German, acoustic model training had to be performed on publicly available data crawled from the internet. For evaluation, lack of a manual segmentation into utterances was handled in two different ways: by generating an automatic segmentation, and by treating entire input files as a single segment. Demonstrating the latter method is superior in the current task, we obtained a WER of 28.16% on the dev set and 36.21% on the test set.</abstract>
      <bibkey>driesen-etal-2013-description</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>NTT</fixed-case>-<fixed-case>NAIST</fixed-case> <fixed-case>SMT</fixed-case> systems for <fixed-case>IWSLT</fixed-case> 2013</title>
      <author><first>Katsuhito</first><last>Sudoh</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Kevin</first><last>Duh</last></author>
      <author><first>Hajime</first><last>Tsukada</last></author>
      <url hash="5e5c7c93">2013.iwslt-evaluation.12</url>
      <abstract>This paper presents NTT-NAIST SMT systems for English-German and German-English MT tasks of the IWSLT 2013 evaluation campaign. The systems are based on generalized minimum Bayes risk system combination of three SMT systems: forest-to-string, hierarchical phrase-based, phrasebased with pre-ordering. Individual SMT systems include data selection for domain adaptation, rescoring using recurrent neural net language models, interpolated language models, and compound word splitting (only for German-English).</abstract>
      <bibkey>sudoh-etal-2013-ntt</bibkey>
    </paper>
    <paper id="13">
      <title>The 2013 <fixed-case>KIT</fixed-case> <fixed-case>IWSLT</fixed-case> speech-to-text systems for <fixed-case>G</fixed-case>erman and <fixed-case>E</fixed-case>nglish</title>
      <author><first>Kevin</first><last>Kilgour</last></author>
      <author><first>Christian</first><last>Mohr</last></author>
      <author><first>Michael</first><last>Heck</last></author>
      <author><first>Quoc Bao</first><last>Nguyen</last></author>
      <author><first>Van Huy</first><last>Nguyen</last></author>
      <author><first>Evgeniy</first><last>Shin</last></author>
      <author><first>Igor</first><last>Tseyzer</last></author>
      <author><first>Jonas</first><last>Gehring</last></author>
      <author><first>Markus</first><last>Müller</last></author>
      <author><first>Matthias</first><last>Sperber</last></author>
      <author><first>Sebastian</first><last>Stüker</last></author>
      <author><first>Alex</first><last>Waibel</last></author>
      <url hash="e309b235">2013.iwslt-evaluation.13</url>
      <abstract>This paper describes our English Speech-to-Text (STT) systems for the 2013 IWSLT TED ASR track. The systems consist of multiple subsystems that are combinations of different front-ends, e.g. MVDR-MFCC based and lMel based ones, GMM and NN acoustic models and different phone sets. The outputs of the subsystems are combined via confusion network combination. Decoding is done in two stages, where the systems of the second stage are adapted in an unsupervised manner on the combination of the first stage outputs using VTLN, MLLR, and cMLLR.</abstract>
      <bibkey>kilgour-etal-2013-2013</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>P</fixed-case>olish-<fixed-case>E</fixed-case>nglish speech statistical machine translation systems for the <fixed-case>IWSLT</fixed-case> 2013</title>
      <author><first>Krzysztof</first><last>Wolk</last></author>
      <author><first>Krzysztof</first><last>Marasek</last></author>
      <url hash="88bf71ad">2013.iwslt-evaluation.14</url>
      <abstract>This research explores the effects of various training settings from Polish to English Statistical Machine Translation system for spoken language. Various elements of the TED parallel text corpora for the IWSLT 2013 evaluation campaign were used as the basis for training of language models, and for development, tuning and testing of the translation system. The BLEU, NIST, METEOR and TER metrics were used to evaluate the effects of data preparations on translation results. Our experiments included systems, which use stems and morphological information on Polish words. We also conducted a deep analysis of provided Polish data as preparatory work for the automatic data correction and cleaning phase.</abstract>
      <bibkey>wolk-marasek-2013-polish</bibkey>
    </paper>
    <paper id="15">
      <title>The <fixed-case>RWTH</fixed-case> <fixed-case>A</fixed-case>achen <fixed-case>G</fixed-case>erman and <fixed-case>E</fixed-case>nglish <fixed-case>LVCSR</fixed-case> systems for <fixed-case>IWSLT</fixed-case>-2013</title>
      <author><first>M. Ali Basha</first><last>Shaik</last></author>
      <author><first>Zoltan</first><last>Tüske</last></author>
      <author><first>Simon</first><last>Wiesler</last></author>
      <author><first>Markus</first><last>Nußbaum-Thom</last></author>
      <author><first>Stephan</first><last>Peitz</last></author>
      <author><first>Ralf</first><last>Schlüter</last></author>
      <author><first>Hermann</first><last>Ney</last></author>
      <url hash="b8bf8ec9">2013.iwslt-evaluation.15</url>
      <abstract>In this paper, German and English large vocabulary continuous speech recognition (LVCSR) systems developed by the RWTH Aachen University for the IWSLT-2013 evaluation campaign are presented. Good improvements are obtained with state-of-the-art monolingual and multilingual bottleneck features. In addition, an open vocabulary approach using morphemic sub-lexical units is investigated along with the language model adaptation for the German LVCSR. For both the languages, competitive WERs are achieved using system combination.</abstract>
      <bibkey>shaik-etal-2013-rwth</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>EU</fixed-case>-<fixed-case>BRIDGE</fixed-case> <fixed-case>MT</fixed-case>: text translation of talks in the <fixed-case>EU</fixed-case>-<fixed-case>BRIDGE</fixed-case> project</title>
      <author><first>Markus</first><last>Freitag</last></author>
      <author><first>Stephan</first><last>Peitz</last></author>
      <author><first>Joern</first><last>Wuebker</last></author>
      <author><first>Hermann</first><last>Ney</last></author>
      <author><first>Nadir</first><last>Durrani</last></author>
      <author><first>Matthias</first><last>Huck</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <author><first>Thanh-Le</first><last>Ha</last></author>
      <author><first>Jan</first><last>Niehues</last></author>
      <author><first>Mohammed</first><last>Mediani</last></author>
      <author><first>Teresa</first><last>Herrmann</last></author>
      <author><first>Alex</first><last>Waibel</last></author>
      <author><first>Nicola</first><last>Bertoldi</last></author>
      <author><first>Mauro</first><last>Cettolo</last></author>
      <author><first>Marcello</first><last>Federico</last></author>
      <url hash="38b712b2">2013.iwslt-evaluation.16</url>
      <abstract>EU-BRIDGE1 is a European research project which is aimed at developing innovative speech translation technology. This paper describes one of the collaborative efforts within EUBRIDGE to further advance the state of the art in machine translation between two European language pairs, English→French and German→English. Four research institutions involved in the EU-BRIDGE project combined their individual machine translation systems and participated with a joint setup in the machine translation track of the evaluation campaign at the 2013 International Workshop on Spoken Language Translation (IWSLT). We present the methods and techniques to achieve high translation quality for text translation of talks which are applied at RWTH Aachen University, the University of Edinburgh, Karlsruhe Institute of Technology, and Fondazione Bruno Kessler. We then show how we have been able to considerably boost translation performance (as measured in terms of the metrics BLEU and TER) by means of system combination. The joint setups yield empirical gains of up to 1.4 points in BLEU and 2.8 points in TER on the IWSLT test sets compared to the best single systems.</abstract>
      <bibkey>freitag-etal-2013-eu</bibkey>
    </paper>
    <paper id="17">
      <title>The <fixed-case>MIT</fixed-case>-<fixed-case>LL</fixed-case>/<fixed-case>AFRL</fixed-case> <fixed-case>IWSLT</fixed-case>-2013 <fixed-case>MT</fixed-case> system</title>
      <author><first>Michaeel</first><last>Kazi</last></author>
      <author><first>Michael</first><last>Coury</last></author>
      <author><first>Elizabeth</first><last>Salesky</last></author>
      <author><first>Jessica</first><last>Ray</last></author>
      <author><first>Wade</first><last>Shen</last></author>
      <author><first>Terry</first><last>Gleason</last></author>
      <author><first>Tim</first><last>Anderson</last></author>
      <author><first>Grant</first><last>Erdmann</last></author>
      <author><first>Lane</first><last>Schwartz</last></author>
      <author><first>Brian</first><last>Ore</last></author>
      <author><first>Raymond</first><last>Slyh</last></author>
      <author><first>Jeremy</first><last>Gwinnup</last></author>
      <author><first>Katherine</first><last>Young</last></author>
      <author><first>Michael</first><last>Hutt</last></author>
      <url hash="a3735e0a">2013.iwslt-evaluation.17</url>
      <abstract>This paper describes the MIT-LL/AFRL statistical MT system and the improvements that were developed during the IWSLT 2013 evaluation campaign [1]. As part of these efforts, we experimented with a number of extensions to the standard phrase-based model that improve performance on the Russian to English, Chinese to English, Arabic to English, and English to French TED-talk translation task. We also applied our existing ASR system to the TED-talk lecture ASR task. We discuss the architecture of the MIT-LL/AFRL MT system, improvements over our 2012 system, and experiments we ran during the IWSLT-2013 evaluation. Specifically, we focus on 1) cross-entropy filtering of MT training data, and 2) improved optimization techniques, 3) language modeling, and 4) approximation of out-of-vocabulary words.</abstract>
      <bibkey>kazi-etal-2013-mit</bibkey>
    </paper>
    <paper id="18">
      <title>The speech recognition and machine translation system of <fixed-case>IOIT</fixed-case> for <fixed-case>IWSLT</fixed-case> 2013</title>
      <author><first>Ngoc-Quan</first><last>Pham</last></author>
      <author><first>Hai-Son</first><last>Le</last></author>
      <author><first>Tat-Thang</first><last>Vu</last></author>
      <author><first>Chi-Mai</first><last>Luong</last></author>
      <url hash="12a10e68">2013.iwslt-evaluation.18</url>
      <abstract>This paper describes the Automatic Speech Recognition (ASR) and Machine Translation (MT) systems developed by IOIT for the evaluation campaign of IWSLT2013. For the ASR task, using Kaldi toolkit, we developed the system based on weighted finite state transducer. The system is constructed by applying several techniques, notably, subspace Gaussian mixture models, speaker adaptation, discriminative training, system combination and SOUL, a neural network language model. The techniques used for automatic segmentation are also clarified. Besides, we compared different types of SOUL models in order to study the impact of words of previous sentences in predicting words in language modeling. For the MT task, the baseline system was built based on the open source toolkit N-code, then being augmented by using SOUL on top, i.e., in N-best rescoring phase.</abstract>
      <bibkey>pham-etal-2013-speech</bibkey>
    </paper>
    <paper id="19">
      <title><fixed-case>TÜBİTAK</fixed-case> <fixed-case>T</fixed-case>urkish-<fixed-case>E</fixed-case>nglish submissions for <fixed-case>IWSLT</fixed-case> 2013</title>
      <author><first>Ertuğrul</first><last>Yılmaz</last></author>
      <author><first>İlknur Durgar</first><last>El-Kahlout</last></author>
      <author><first>Burak</first><last>Aydın</last></author>
      <author><first>Zişan Sıla</first><last>Özil</last></author>
      <author><first>Coşkun</first><last>Mermer</last></author>
      <url hash="8800e6d4">2013.iwslt-evaluation.19</url>
      <abstract>This paper describes the TU ̈ B ̇ITAK Turkish-English submissions in both directions for the IWSLT’13 Evaluation Campaign TED Machine Translation (MT) track. We develop both phrase-based and hierarchical phrase-based statistical machine translation (SMT) systems based on Turkish wordand morpheme-level representations. We augment training data with content words extracted from itself and experiment with reverse word order for source languages. For the Turkish-to-English direction, we use Gigaword corpus as an additional language model with the training data. For the English-to-Turkish direction, we implemented a wide coverage Turkish word generator to generate words from the stem and morpheme sequences. Finally, we perform system combination of the different systems produced with different word alignments.</abstract>
      <bibkey>yilmaz-etal-2013-tubitak</bibkey>
    </paper>
    <paper id="20">
      <title><fixed-case>FBK</fixed-case>’s machine translation systems for the <fixed-case>IWSLT</fixed-case> 2013 evaluation campaign</title>
      <author><first>Nicola</first><last>Bertoldi</last></author>
      <author><first>M. Amin</first><last>Farajian</last></author>
      <author><first>Prashant</first><last>Mathur</last></author>
      <author><first>Nicholas</first><last>Ruiz</last></author>
      <author><first>Marcello</first><last>Federico</last></author>
      <url hash="d0ab879b">2013.iwslt-evaluation.20</url>
      <abstract>This paper describes the systems submitted by FBK for the MT track of IWSLT 2013. We participated in the English-French as well as the bidirectional Persian-English translation tasks. We report substantial improvements in our English-French systems over last year’s baselines, largely due to improved techniques of combining translation and language models. For our Persian-English and English-Persian systems, we observe substantive improvements over baselines submitted by the workshop organizers, due to enhanced language-specific text normalization and the creation of a large monolingual news corpus in Persian.</abstract>
      <bibkey>bertoldi-etal-2013-fbks</bibkey>
    </paper>
    <paper id="21">
      <title>The Heidelberg University machine translation systems for <fixed-case>IWSLT</fixed-case>2013</title>
      <author><first>Patrick</first><last>Simianer</last></author>
      <author><first>Laura</first><last>Jehl</last></author>
      <author><first>Stefan</first><last>Riezler</last></author>
      <url hash="9a951e8f">2013.iwslt-evaluation.21</url>
      <abstract>We present our systems for the machine translation evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT) 2013. We submitted systems for three language directions: German-to-English, Russian-to-English and English-to-Russian. The focus of our approaches lies on effective usage of the in-domain parallel training data. Therefore, we use the training data to tune parameter weights for millions of sparse lexicalized features using efficient parallelized stochastic learning techniques. For German-to-English we incorporate syntax features. We combine all of our systems with large language models. For the systems involving Russian we also incorporate more data into building of the translation models.</abstract>
      <bibkey>simianer-etal-2013-heidelberg</bibkey>
    </paper>
    <paper id="22">
      <title>The <fixed-case>UEDIN</fixed-case> <fixed-case>E</fixed-case>nglish <fixed-case>ASR</fixed-case> system for the <fixed-case>IWSLT</fixed-case> 2013 evaluation</title>
      <author><first>Peter</first><last>Bell</last></author>
      <author><first>Fergus</first><last>McInnes</last></author>
      <author><first>Siva Reddy</first><last>Gangireddy</last></author>
      <author><first>Mark</first><last>Sinclair</last></author>
      <author><first>Alexandra</first><last>Birch</last></author>
      <author><first>Steve</first><last>Renals</last></author>
      <url hash="3e21d196">2013.iwslt-evaluation.22</url>
      <abstract>This paper describes the University of Edinburgh (UEDIN) English ASR system for the IWSLT 2013 Evaluation. Notable features of the system include deep neural network acoustic models in both tandem and hybrid configuration, cross-domain adaptation with multi-level adaptive networks, and the use of a recurrent neural network language model. Improvements to our system since the 2012 evaluation – which include the use of a significantly improved n-gram language model – result in a 19% relative WER reduction on the tst2012 set.</abstract>
      <bibkey>bell-etal-2013-uedin</bibkey>
    </paper>
    <paper id="23">
      <title>The <fixed-case>NAIST</fixed-case> <fixed-case>E</fixed-case>nglish speech recognition system for <fixed-case>IWSLT</fixed-case> 2013</title>
      <author><first>Sakriani</first><last>Sakti</last></author>
      <author><first>Keigo</first><last>Kubo</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Tomoki</first><last>Toda</last></author>
      <author><first>Satoshi</first><last>Nakamura</last></author>
      <url hash="e15313ed">2013.iwslt-evaluation.23</url>
      <abstract>This paper describes the NAIST English speech recognition system for the IWSLT 2013 Evaluation Campaign. In particular, we participated in the ASR track of the IWSLT TED task. Last year, we participated in collaboration with Karlsruhe Institute of Technology (KIT). This year is our first time to build a full-fledged ASR system for IWSLT solely developed by NAIST. Our final system utilizes weighted finitestate transducers with four-gram language models. The hypothesis selection is based on the principle of system combination. On the IWSLT official test set our system introduced in this work achieves a WER of 9.1% for tst2011, 10.0% for tst2012, and 16.2% for the new tst2013.</abstract>
      <bibkey>sakti-etal-2013-naist</bibkey>
    </paper>
    <paper id="24">
      <title>The <fixed-case>KIT</fixed-case> translation systems for <fixed-case>IWSLT</fixed-case> 2013</title>
      <author><first>Than-Le</first><last>Ha</last></author>
      <author><first>Teresa</first><last>Herrmann</last></author>
      <author><first>Jan</first><last>Niehues</last></author>
      <author><first>Mohammed</first><last>Mediani</last></author>
      <author><first>Eunah</first><last>Cho</last></author>
      <author><first>Yuqi</first><last>Zhang</last></author>
      <author><first>Isabel</first><last>Slawik</last></author>
      <author><first>Alex</first><last>Waibel</last></author>
      <url hash="103642d9">2013.iwslt-evaluation.24</url>
      <abstract>In this paper, we present the KIT systems participating in all three official directions, namely English→German, German→English, and English→French, in translation tasks of the IWSLT 2013 machine translation evaluation. Additionally, we present the results for our submissions to the optional directions English→Chinese and English→Arabic. We used phrase-based translation systems to generate the translations. This year, we focused on adapting the systems towards ASR input. Furthermore, we investigated different reordering models as well as an extended discriminative word lexicon. Finally, we added a data selection approach for domain adaptation.</abstract>
      <bibkey>ha-etal-2013-kit</bibkey>
    </paper>
    <paper id="25">
      <title>The <fixed-case>CASIA</fixed-case> machine translation system for <fixed-case>IWSLT</fixed-case> 2013</title>
      <author><first>Xingyuan</first><last>Peng</last></author>
      <author><first>Xiaoyin</first><last>Fu</last></author>
      <author><first>Wei</first><last>Wei</last></author>
      <author><first>Zhenbiao</first><last>Chen</last></author>
      <author><first>Wei</first><last>Chen</last></author>
      <author><first>Bo</first><last>Xu</last></author>
      <url hash="ca070d34">2013.iwslt-evaluation.25</url>
      <abstract>In this paper, we describe the CASIA statistical machine translation (SMT) system for the IWSLT2013 Evaluation Campaign. We participated in the Chinese-English and English-Chinese translation tasks. For both of these tasks, we used a hierarchical phrase-based (HPB) decoder and made it as our baseline translation system. A number of techniques were proposed to deal with these translation tasks, including parallel sentence extraction, pre-processing, translation model (TM) optimization, language model (LM) interpolation, turning, and post-processing. With these techniques, the translation results were significantly improved compared with that of the baseline system.</abstract>
      <bibkey>peng-etal-2013-casia</bibkey>
    </paper>
  </volume>
  <volume id="papers" ingest-date="2021-08-08" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 10th International Workshop on Spoken Language Translation: Papers</booktitle>
      <address>Heidelberg, Germany</address>
      <month>December 5-6</month>
      <year>2013</year>
      <editor><first>Joy Ying</first><last>Zhang</last></editor>
      <venue>iwslt</venue>
    </meta>
    <paper id="1">
      <title>Using viseme recognition to improve a sign language translation system</title>
      <author><first>Christoph</first><last>Schmidt</last></author>
      <author><first>Oscar</first><last>Koller</last></author>
      <author><first>Hermann</first><last>Ney</last></author>
      <author><first>Thomas</first><last>Hoyoux</last></author>
      <author><first>Justus</first><last>Piater</last></author>
      <url hash="003010b5">2013.iwslt-papers.1</url>
      <abstract>Sign language-to-text translation systems are similar to spoken language translation systems in that they consist of a recognition phase and a translation phase. First, the video of a person signing is transformed into a transcription of the signs, which is then translated into the text of a spoken language. One distinctive feature of sign languages is their multi-modal nature, as they can express meaning simultaneously via hand movements, body posture and facial expressions. In some sign languages, certain signs are accompanied by mouthings, i.e. the person silently pronounces the word while signing. In this work, we closely integrate a recognition and translation framework by adding a viseme recognizer (“lip reading system”) based on an active appearance model and by optimizing the recognition system to improve the translation output. The system outperforms the standard approach of separate recognition and translation.</abstract>
      <bibkey>schmidt-etal-2013-using</bibkey>
    </paper>
    <paper id="2">
      <title>The <fixed-case>AMARA</fixed-case> corpus: building resources for translating the web’s educational content</title>
      <author><first>Francisco</first><last>Guzman</last></author>
      <author><first>Hassan</first><last>Sajjad</last></author>
      <author><first>Stephan</first><last>Vogel</last></author>
      <author><first>Ahmed</first><last>Abdelali</last></author>
      <url hash="6ea1644e">2013.iwslt-papers.2</url>
      <abstract>In this paper, we introduce a new parallel corpus of subtitles of educational videos: the AMARA corpus for online educational content. We crawl a multilingual collection community generated subtitles, and present the results of processing the Arabic–English portion of the data, which yields a parallel corpus of about 2.6M Arabic and 3.9M English words. We explore different approaches to align the segments, and extrinsically evaluate the resulting parallel corpus on the standard TED-talks tst-2010. We observe that the data can be successfully used for this task, and also observe an absolute improvement of 1.6 BLEU when it is used in combination with TED data. Finally, we analyze some of the specific challenges when translating the educational content.</abstract>
      <bibkey>guzman-etal-2013-amara</bibkey>
    </paper>
    <paper id="3">
      <title>Constructing a speech translation system using simultaneous interpretation data</title>
      <author><first>Hiroaki</first><last>Shimizu</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Sakriani</first><last>Sakti</last></author>
      <author><first>Tomoki</first><last>Toda</last></author>
      <author><first>Satoshi</first><last>Nakamura</last></author>
      <url hash="1b85df3a">2013.iwslt-papers.3</url>
      <abstract>There has been a fair amount of work on automatic speech translation systems that translate in real-time, serving as a computerized version of a simultaneous interpreter. It has been noticed in the field of translation studies that simultaneous interpreters perform a number of tricks to make the content easier to understand in real-time, including dividing their translations into small chunks, or summarizing less important content. However, the majority of previous work has not specifically considered this fact, simply using translation data (made by translators) for learning of the machine translation system. In this paper, we examine the possibilities of additionally incorporating simultaneous interpretation data (made by simultaneous interpreters) in the learning process. First we collect simultaneous interpretation data from professional simultaneous interpreters of three levels, and perform an analysis of the data. Next, we incorporate the simultaneous interpretation data in the learning of the machine translation system. As a result, the translation style of the system becomes more similar to that of a highly experienced simultaneous interpreter. We also find that according to automatic evaluation metrics, our system achieves performance similar to that of a simultaneous interpreter that has 1 year of experience.</abstract>
      <bibkey>shimizu-etal-2013-constructing</bibkey>
    </paper>
    <paper id="4">
      <title>Improving the minimum <fixed-case>B</fixed-case>ayes’ risk combination of machine translation systems</title>
      <author><first>Jesús</first><last>González-Rubio</last></author>
      <author><first>Francisco</first><last>Casacuberta</last></author>
      <url hash="e0d3a795">2013.iwslt-papers.4</url>
      <abstract>We investigate the problem of combining the outputs of different translation systems into a minimum Bayes’ risk consensus translation. We explore different risk formulations based on the BLEU score, and provide a dynamic programming decoding algorithm for each of them. In our experiments, these algorithms generated consensus translations with better risk, and more efficiently, than previous proposals.</abstract>
      <bibkey>gonzalez-rubio-casacuberta-2013-improving</bibkey>
    </paper>
    <paper id="5">
      <title>Emprical study of a two-step approach to estimate translation quality</title>
      <author><first>Jesús</first><last>González-Rubio</last></author>
      <author><first>J. Ramón</first><last>Navarro-Cerdán</last></author>
      <author><first>Francisco</first><last>Casacuberta</last></author>
      <url hash="5a8d9848">2013.iwslt-papers.5</url>
      <abstract>We present a method to estimate the quality of automatic translations when reference translations are not available. Quality estimation is addressed as a two-step regression problem where multiple features are combined to predict a quality score. Given a set of features, we aim at automatically extracting the variables that better explain translation quality, and use them to predict the quality score. The soundness of our approach is assessed by the encouraging results obtained in an exhaustive experimentation with several feature sets. Moreover, the studied approach is highly-scalable allowing us to employ hundreds of features to predict translation quality.</abstract>
      <bibkey>gonzalez-rubio-etal-2013-emprical</bibkey>
    </paper>
    <paper id="6">
      <title>The 2013 <fixed-case>KIT</fixed-case> Quaero speech-to-text system for <fixed-case>F</fixed-case>rench</title>
      <author><first>Joshua</first><last>Winebarger</last></author>
      <author><first>Bao</first><last>Nguyen</last></author>
      <author><first>Jonas</first><last>Gehring</last></author>
      <author><first>Sebastian</first><last>Stüker</last></author>
      <author><first>Alex</first><last>Waibel</last></author>
      <url hash="7eda2291">2013.iwslt-papers.6</url>
      <abstract>This paper describes our Speech-to-Text (STT) system for French, which was developed as part of our efforts in the Quaero program for the 2013 evaluation. Our STT system consists of six subsystems which were created by combining multiple complementary sources of pronunciation modeling including graphemes with various feature front-ends based on deep neural networks and tonal features. Both speaker-independent and speaker adaptively trained versions of the systems were built. The resulting systems were then combined via confusion network combination and crossadaptation. Through progressive advances and system combination we reach a word error rate (WER) of 16.5% on the 2012 Quaero evaluation data.</abstract>
      <bibkey>winebarger-etal-2013-2013</bibkey>
    </paper>
    <paper id="7">
      <title>Improving bilingual sub-sentential alignment by sampling-based transpotting</title>
      <author><first>Li</first><last>Gong</last></author>
      <author><first>Aurélien</first><last>Max</last></author>
      <author><first>François</first><last>Yvon</last></author>
      <url hash="bb2573d8">2013.iwslt-papers.7</url>
      <abstract>In this article, we present a sampling-based approach to improve bilingual sub-sentential alignment in parallel corpora. This approach can be used to align parallel sentences on an as needed basis, and is able to accurately align newly available sentences. We evaluate the resulting alignments on several Machine Translation tasks. Results show that for the tasks considered here, our approach performs on par with the state-of-the-art statistical alignment pipeline giza++/Moses, and obtains superior results in a number of configurations, notably when aligning additional parallel sentence pairs carefully selected to match the test input.</abstract>
      <bibkey>gong-etal-2013-improving</bibkey>
    </paper>
    <paper id="8">
      <title>Incremental unsupervised training for university lecture recognition</title>
      <author><first>Michael</first><last>Heck</last></author>
      <author><first>Sebastian</first><last>Stüker</last></author>
      <author><first>Sakriani</first><last>Sakti</last></author>
      <author><first>Alex</first><last>Waibel</last></author>
      <author><first>Satoshi</first><last>Nakamura</last></author>
      <url hash="33eac22c">2013.iwslt-papers.8</url>
      <abstract>In this paper we describe our work on unsupervised adaptation of the acoustic model of our simultaneous lecture translation system. We trained a speaker independent acoustic model, with which we produce automatic transcriptions of new lectures in order to improve the system for a specific lecturer. We compare our results against a model that was trained in a supervised way on an exact manual transcription. We examine four different ways of processing the decoder outputs of the automatic transcription with respect to the treatment of pronunciation variants and noise words. We will show that, instead of fixating the latter informations in the transcriptions, it is of advantage to let the Viterbi algorithm during training decide which pronunciations to use and where to insert which noise words. Further, we utilize word level posterior probabilities obtained during decoding by weighting and thresholding the words of a transcription.</abstract>
      <bibkey>heck-etal-2013-incremental</bibkey>
    </paper>
    <paper id="9">
      <title>Studies on training text selection for conversational <fixed-case>F</fixed-case>innish language modeling</title>
      <author><first>Seppo</first><last>Enarvi</last></author>
      <author><first>Mikko</first><last>Kurimo</last></author>
      <url hash="549d5cd8">2013.iwslt-papers.9</url>
      <abstract>Current ASR and MT systems do not operate on conversational Finnish, because training data for colloquial Finnish has not been available. Although speech recognition performance on literary Finnish is already quite good, those systems have very poor baseline performance in conversational speech. Text data for relevant vocabulary and language models can be collected from the Internet, but web data is very noisy and most of it is not helpful for learning good models. Finnish language is highly agglutinative, and written phonetically. Even phonetic reductions and sandhi are often written down in informal discussions. This increases vocabulary size dramatically and causes word-based selection methods to fail. Our selection method explicitly optimizes the perplexity of a subword language model on the development data, and requires only very limited amount of speech transcripts as development data. The language models have been evaluated for speech recognition using a new data set consisting of generic colloquial Finnish.</abstract>
      <bibkey>enarvi-kurimo-2013-studies</bibkey>
    </paper>
    <paper id="10">
      <title>Assessing quick update methods of statistical translation models</title>
      <author><first>Shachar</first><last>Mirkin</last></author>
      <author><first>Nicola</first><last>Cancedda</last></author>
      <url hash="21a24499">2013.iwslt-papers.10</url>
      <abstract>The ability to quickly incorporate incoming training data into a running translation system is critical in a number of applications. Mechanisms based on incremental model update and the online EM algorithm hold the promise of achieving this objective in a principled way. Still, efficient tools for incremental training are yet to be available. In this paper we experiment with simple alternative solutions for interim model updates, within the popular Moses system. Short of updating the model in real time, such updates can execute in short timeframes even when operating on large models, and achieve a performance level close to, and in some cases exceeding, that of batch retraining.</abstract>
      <bibkey>mirkin-cancedda-2013-assessing</bibkey>
    </paper>
    <paper id="11">
      <title>Analyzing the potential of source sentence reordering in statistical machine translation</title>
      <author><first>Teresa</first><last>Herrmann</last></author>
      <author><first>Jochen</first><last>Weiner</last></author>
      <author><first>Jan</first><last>Niehues</last></author>
      <author><first>Alex</first><last>Waibel</last></author>
      <url hash="b4c15714">2013.iwslt-papers.11</url>
      <abstract>We analyze the performance of source sentence reordering, a common reordering approach, using oracle experiments on German-English and English-German translation. First, we show that the potential of this approach is very promising. Compared to a monotone translation, the optimally reordered source sentence leads to improvements of up to 4.6 and 6.2 BLEU points, depending on the language. Furthermore, we perform a detailed evaluation of the different aspects of the approach. We analyze the impact of the restriction of the search space by reordering lattices and we can show that using more complex rule types for reordering results in better approximation of the optimally reordered source. However, a gap of about 3 to 3.8 BLEU points remains, presenting a promising perspective for research on extending the search space through better reordering rules. When evaluating the ranking of different reordering variants, the results reveal that the search for the best path in the lattice performs very well for German-English translation. For English-German translation there is potential for an improvement of up to 1.4 BLEU points through a better ranking of the different reordering possibilities in the reordering lattice.</abstract>
      <bibkey>herrmann-etal-2013-analyzing</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>CRF</fixed-case>-based disfluency detection using semantic features for <fixed-case>G</fixed-case>erman to <fixed-case>E</fixed-case>nglish spoken language translation</title>
      <author><first>Eunah</first><last>Cho</last></author>
      <author><first>Than-Le</first><last>Ha</last></author>
      <author><first>Alex</first><last>Waibel</last></author>
      <url hash="1225e6da">2013.iwslt-papers.12</url>
      <abstract>Disfluencies in speech pose severe difficulties in machine translation of spontaneous speech. This paper presents our conditional random field (CRF)-based speech disfluency detection system developed on German to improve spoken language translation performance. In order to detect speech disfluencies considering syntactics and semantics of speech utterances, we carried out a CRF-based approach using information learned from the word representation and the phrase table used for machine translation. The word representation is gained using recurrent neural networks and projected words are clustered using the k-means algorithm. Using the output from the model trained with the word representations and phrase table information, we achieve an improvement of 1.96 BLEU points on the lecture test set. By keeping or removing humanannotated disfluencies, we show an upper bound and lower bound of translation quality. In an oracle experiment we gain 3.16 BLEU points of improvement on the lecture test set, compared to the same set with all disfluencies.</abstract>
      <bibkey>cho-etal-2013-crf</bibkey>
    </paper>
    <paper id="13">
      <title>Maximum entropy language modeling for <fixed-case>R</fixed-case>ussian <fixed-case>ASR</fixed-case></title>
      <author><first>Evgeniy</first><last>Shin</last></author>
      <author><first>Sebastian</first><last>Stüker</last></author>
      <author><first>Kevin</first><last>Kilgour</last></author>
      <author><first>Christian</first><last>Fügen</last></author>
      <author><first>Alex</first><last>Waibel</last></author>
      <url hash="256b13b1">2013.iwslt-papers.13</url>
      <abstract>Russian is a challenging language for automatic speech recognition systems due to its rich morphology. This rich morphology stems from Russian’s highly inflectional nature and the frequent use of preand suffixes. Also, Russian has a very free word order, changes in which are used to reflect connotations of the sentences. Dealing with these phenomena is rather difficult for traditional n-gram models. We therefore investigate in this paper the use of a maximum entropy language model for Russian whose features are specifically designed to deal with the inflections in Russian, as well as the loose word order. We combine this with a subword based language model in order to alleviate the problem of large vocabulary sizes necessary for dealing with highly inflecting languages. Applying the maximum entropy language model during re-scoring improves the word error rate of our recognition system by 1.2% absolute, while the use of the sub-word based language model reduces the vocabulary size from 120k to 40k and the OOV rate from 4.8% to 2.1%.</abstract>
      <bibkey>shin-etal-2013-maximum</bibkey>
    </paper>
    <paper id="14">
      <title>Improved speech-to-text translation with the Fisher and Callhome <fixed-case>S</fixed-case>panish-<fixed-case>E</fixed-case>nglish speech translation corpus</title>
      <author><first>Matt</first><last>Post</last></author>
      <author><first>Gaurav</first><last>Kumar</last></author>
      <author><first>Adam</first><last>Lopez</last></author>
      <author><first>Damianos</first><last>Karakos</last></author>
      <author><first>Chris</first><last>Callison-Burch</last></author>
      <author><first>Sanjeev</first><last>Khudanpur</last></author>
      <url hash="431f26fc">2013.iwslt-papers.14</url>
      <abstract>Research into the translation of the output of automatic speech recognition (ASR) systems is hindered by the dearth of datasets developed for that explicit purpose. For SpanishEnglish translation, in particular, most parallel data available exists only in vastly different domains and registers. In order to support research on cross-lingual speech applications, we introduce the Fisher and Callhome Spanish-English Speech Translation Corpus, supplementing existing LDC audio and transcripts with (a) ASR 1-best, lattice, and oracle output produced by the Kaldi recognition system and (b) English translations obtained on Amazon’s Mechanical Turk. The result is a four-way parallel dataset of Spanish audio, transcriptions, ASR lattices, and English translations of approximately 38 hours of speech, with defined training, development, and held-out test sets. We conduct baseline machine translation experiments using models trained on the provided training data, and validate the dataset by corroborating a number of known results in the field, including the utility of in-domain (information, conversational) training data, increased performance translating lattices (instead of recognizer 1-best output), and the relationship between word error rate and BLEU score.</abstract>
      <bibkey>post-etal-2013-improved</bibkey>
    </paper>
    <paper id="15">
      <title>Unsupervised learning of bilingual categories in inversion transduction grammar induction</title>
      <author><first>Markus</first><last>Saers</last></author>
      <author><first>Dekai</first><last>Wu</last></author>
      <url hash="4b70f53b">2013.iwslt-papers.15</url>
      <abstract>We present the first known experiments incorporating unsupervised bilingual nonterminal category learning within end-to-end fully unsupervised transduction grammar induction using matched training and testing models. Despite steady recent progress, such induction experiments until now have not allowed for learning differentiated nonterminal categories. We divide the learning into two stages: (1) a bootstrap stage that generates a large set of categorized short transduction rule hypotheses, and (2) a minimum conditional description length stage that simultaneously prunes away less useful short rule hypotheses, while also iteratively segmenting full sentence pairs into useful longer categorized transduction rules. We show that the second stage works better when the rule hypotheses have categories than when they do not, and that the proposed conditional description length approach combines the rules hypothesized by the two stages better than a mixture model does. We also show that the compact model learned during the second stage can be further improved by combining the result of different iterations in a mixture model. In total, we see a jump in BLEU score, from 17.53 for a standalone minimum description length baseline with no category learning, to 20.93 when incorporating category induction on a Chinese–English translation task.</abstract>
      <bibkey>saers-wu-2013-unsupervised-learning</bibkey>
    </paper>
    <paper id="16">
      <title>A study in greedy oracle improvement of translation hypotheses</title>
      <author><first>Benjamin</first><last>Marie</last></author>
      <author><first>Aurélien</first><last>Max</last></author>
      <url hash="8f1f84cb">2013.iwslt-papers.16</url>
      <abstract>This paper describes a study of translation hypotheses that can be obtained by iterative, greedy oracle improvement from the best hypothesis of a state-of-the-art phrase-based Statistical Machine Translation system. The factors that we consider include the influence of the rewriting operations, target languages, and training data sizes. Analysis of our results provide new insights into some previously unanswered questions, which include the reachability of previously unreachable hypotheses via indirect translation (thanks to the introduction of a rewrite operation on the source text), and the potential translation performance of systems relying on pruned phrase tables.</abstract>
      <bibkey>marie-max-2013-study</bibkey>
    </paper>
    <paper id="17">
      <title>Source aware phrase-based decoding for robust conversational spoken language translation</title>
      <author><first>Sankaranarayanan</first><last>Ananthakrishnan</last></author>
      <author><first>Wei</first><last>Chen</last></author>
      <author><first>Rohit</first><last>Kumar</last></author>
      <author><first>Dennis</first><last>Mehay</last></author>
      <url hash="10700b82">2013.iwslt-papers.17</url>
      <abstract>Spoken language translation (SLT) systems typically follow a pipeline architecture, in which the best automatic speech recognition (ASR) hypothesis of an input utterance is fed into a statistical machine translation (SMT) system. Conversational speech often generates unrecoverable ASR errors owing to its rich vocabulary (e.g. out-of-vocabulary (OOV) named entities). In this paper, we study the possibility of alleviating the impact of unrecoverable ASR errors on translation performance by minimizing the contextual effects of incorrect source words in target hypotheses. Our approach is driven by locally-derived penalties applied to bilingual phrase pairs as well as target language model (LM) likelihoods in the vicinity of source errors. With oracle word error labels on an OOV word-rich English-to-Iraqi Arabic translation task, we show statistically significant relative improvements of 3.2% BLEU and 2.0% METEOR over an error-agnostic baseline SMT system. We then investigate the impact of imperfect source error labels on error-aware translation performance. Simulation experiments reveal that modest translation improvements are to be gained with this approach even when the source error labels are noisy.</abstract>
      <bibkey>ananthakrishnan-etal-2013-source</bibkey>
    </paper>
    <paper id="18">
      <title>Evaluation of a simultaneous interpretation system and analysis of speech log for user experience assessment</title>
      <author><first>Akiko</first><last>Sakamoto</last></author>
      <author><first>Kazuhiko</first><last>Abe</last></author>
      <author><first>Kazuo</first><last>Sumita</last></author>
      <author><first>Satoshi</first><last>Kamatani</last></author>
      <url hash="658ab388">2013.iwslt-papers.18</url>
      <abstract>This paper focuses on the user experience (UX) of a simultaneous interpretation system for face-to-face conversation between two users. To assess the UX of the system, we first made a transcript of the speech of users recorded during a task-based evaluation experiment and then analyzed user speech from the viewpoint of UX. In a task-based evaluation experiment, 44 tasks out of 45 tasks were solved. The solved task ratio was 97.8%. This indicates that the system can effectively provide interpretation to enable users to solve tasks. However, we found that users repeated speech due to errors in automatic speech recognition (ASR) or machine translation (MT). Users repeated clauses 1.8 times on average. Users seemed to repeat themselves until they received a response from their partner users. In addition, we found that after approximately 3.6 repetitions, users would change their words to avoid errors in ASR or MT and to evoke a response from their partner users.</abstract>
      <bibkey>sakamoto-etal-2013-evaluation</bibkey>
    </paper>
    <paper id="19">
      <title>Parameter optimization for iterative confusion network decoding in weather-domain speech recognition</title>
      <author><first>Shahab</first><last>Jalalvand</last></author>
      <author><first>Daniele</first><last>Falavigna</last></author>
      <url hash="ffd5dece">2013.iwslt-papers.19</url>
      <abstract>In this paper, we apply a set of approaches to, efficiently, rescore the output of the automatic speech recognition over weather-domain data. Since the in-domain data is usually insufficient for training an accurate language model (LM) we utilize an automatic selection method to extract domain-related sentences from a general text resource. Then, an N-gram language model is trained on this set. We exploit this LM, along with a pre-trained acoustic model for recognition of the development and test instances. The recognizer generates a confusion network (CN) for each instance. Afterwards, we make use of the recurrent neural network language model (RNNLM), trained on the in-domain data, in order to iteratively rescore the CNs. Rescoring the CNs, in this way, requires estimating the weights of the RNNLM, N-gramLM and acoustic model scores. Weights optimization is the critical part of this work, whereby, we propose using the minimum error rate training (MERT) algorithm along with a novel N-best list extraction method. The experiments are done over weather forecast domain data that has been provided in the framework of EUBRIDGE project.</abstract>
      <bibkey>jalalvand-falavigna-2013-parameter</bibkey>
    </paper>
  </volume>
</collection>
