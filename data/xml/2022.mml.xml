<?xml version='1.0' encoding='UTF-8'?>
<collection id="2022.mml">
  <volume id="1" ingest-date="2022-05-15" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Workshop on Multilingual Multimodal Learning</booktitle>
      <editor><first>Emanuele</first><last>Bugliarello</last></editor>
      <editor><first>Kai-Wei</first><last>Cheng</last></editor>
      <editor><first>Desmond</first><last>Elliott</last></editor>
      <editor><first>Spandana</first><last>Gella</last></editor>
      <editor><first>Aishwarya</first><last>Kamath</last></editor>
      <editor><first>Liunian Harold</first><last>Li</last></editor>
      <editor><first>Fangyu</first><last>Liu</last></editor>
      <editor><first>Jonas</first><last>Pfeiffer</last></editor>
      <editor><first>Edoardo Maria</first><last>Ponti</last></editor>
      <editor><first>Krishna</first><last>Srinivasan</last></editor>
      <editor><first>Ivan</first><last>VuliÄ‡</last></editor>
      <editor><first>Yinfei</first><last>Yang</last></editor>
      <editor><first>Da</first><last>Yin</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Dublin, Ireland and Online</address>
      <month>May</month>
      <year>2022</year>
      <url hash="6398787a">2022.mml-1</url>
      <venue>mml</venue>
    </meta>
    <frontmatter>
      <url hash="e6ad046f">2022.mml-1.0</url>
      <bibkey>mml-2022-multilingual</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Language-agnostic Semantic Consistent Text-to-Image Generation</title>
      <author><first>SeongJun</first><last>Jung</last></author>
      <author><first>Woo Suk</first><last>Choi</last></author>
      <author><first>Seongho</first><last>Choi</last></author>
      <author><first>Byoung-Tak</first><last>Zhang</last></author>
      <pages>1-5</pages>
      <abstract>Recent GAN-based text-to-image generation models have advanced that they can generate photo-realistic images matching semantically with descriptions. However, research on multi-lingual text-to-image generation has not been carried out yet much. There are two problems when constructing a multilingual text-to-image generation model: 1) language imbalance issue in text-to-image paired datasets and 2) generating images that have the same meaning but are semantically inconsistent with each other in texts expressed in different languages. To this end, we propose a Language-agnostic Semantic Consistent Generative Adversarial Network (LaSC-GAN) for text-to-image generation, which can generate semantically consistent images via language-agnostic text encoder and Siamese mechanism. Experiments on relatively low-resource language text-image datasets show that the model has comparable generation quality as images generated by high-resource language text, and generates semantically consistent images for texts with the same meaning even in different languages.</abstract>
      <url hash="69ff7e82">2022.mml-1.1</url>
      <bibkey>jung-etal-2022-language</bibkey>
      <doi>10.18653/v1/2022.mml-1.1</doi>
      <video href="2022.mml-1.1.mp4"/>
      <pwcdataset url="https://paperswithcode.com/dataset/coco-cn">COCO-CN</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/coco">MS COCO</pwcdataset>
    </paper>
  </volume>
</collection>
