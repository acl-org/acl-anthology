<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.umrpw">
  <volume id="1" ingest-date="2025-04-12" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 2024 UMR Parsing Workshop</booktitle>
      <editor><first>Nianwen</first><last>Xue</last></editor>
      <editor><first>James</first><last>Martin</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Boulder, Colorado</address>
      <month>June</month>
      <year>2024</year>
      <venue>umrpw</venue>
      <venue>ws</venue>
    </meta>
    <paper id="1">
      <title>Linearization Order Matters for <fixed-case>AMR</fixed-case>-to-Text Generation Input</title>
      <author><first>Justin</first><last>DeBenedetto</last></author>
      <pages>1–7</pages>
      <abstract>Abstract Meaning Representation (AMR) is a semantic graph formalism designed to capture sentence meaning using a directed graph. Many systems treat AMR-to-text generation as a sequence-to-sequence problem, drawing upon existing models. The largest AMR dataset (AMR 3.0) provides a sequence format which is considered equivalent to the graph format. However, due to the position-sensitive nature of sequence-to-sequence models, graph traversal order affects system performance. In this work we explore the effect that different, valid orderings have on the performance of sequence-to-sequence AMR-to-text systems and find that changing the traversal order can result in a BLEU score drop of up to 17.5 on a state-of-the-art system.</abstract>
      <url hash="6ffdc9f4">2024.umrpw-1.1</url>
      <bibkey>debenedetto-2024-linearization</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>P</fixed-case>ersian <fixed-case>A</fixed-case>bstract <fixed-case>M</fixed-case>eaning <fixed-case>R</fixed-case>epresentation: Annotation Guidelines and Gold Standard Dataset</title>
      <author><first>Reza</first><last>Takhshid</last></author>
      <author><first>Tara</first><last>Azin</last></author>
      <author><first>Razieh</first><last>Shojaei</last></author>
      <author><first>Mohammad</first><last>Bahrani</last></author>
      <pages>8–15</pages>
      <abstract>This paper introduces the Persian Abstract Meaning Representation (AMR) guidelines, a detailed guide for annotating Persian sentences with AMR, focusing on the necessary adaptations to fit Persian’s unique syntactic structures. We discuss the development process of a Persian AMR gold standard dataset consisting of 1562 sentences created following the guidelines. By examining the language specifications and nuances that distinguish AMR annotations of a low-resource language like Persian, we shed light on the challenges and limitations of developing a universal meaning representation framework. The guidelines and the dataset introduced in this study highlight such challenges, aiming to advance the field.</abstract>
      <url hash="2deb22ae">2024.umrpw-1.2</url>
      <bibkey>takhshid-etal-2024-persian</bibkey>
    </paper>
  </volume>
</collection>
