<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.kallm">
  <volume id="1" ingest-date="2024-07-26" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on Knowledge Graphs and Large Language Models (KaLLM 2024)</booktitle>
      <editor><first>Russa</first><last>Biswas</last></editor>
      <editor><first>Lucie-Aimée</first><last>Kaffee</last></editor>
      <editor><first>Oshin</first><last>Agarwal</last></editor>
      <editor><first>Pasquale</first><last>Minervini</last></editor>
      <editor><first>Sameer</first><last>Singh</last></editor>
      <editor><first>Gerard</first><last>de Melo</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Bangkok, Thailand</address>
      <month>August</month>
      <year>2024</year>
      <url hash="9df36e78">2024.kallm-1</url>
      <venue>kallm</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="b3f716d1">2024.kallm-1.0</url>
      <bibkey>kallm-2024-knowledge</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Multi-hop Database Reasoning with Virtual Knowledge Graph</title>
      <author><first>Juhee</first><last>Son</last></author>
      <author><first>Yeon</first><last>Seonwoo</last></author>
      <author><first>Seunghyun</first><last>Yoon</last><affiliation>Adobe Research</affiliation></author>
      <author><first>James</first><last>Thorne</last><affiliation>KAIST</affiliation></author>
      <author><first>Alice</first><last>Oh</last><affiliation>Korea Advanced Institute of Science and Technology</affiliation></author>
      <pages>1-11</pages>
      <abstract>Application of LLM to database queries on natural language sentences has demonstrated impressive results in both single and multi-hop scenarios.In the existing methodologies, the requirement to re-encode query vectors at each stage for processing multi-hop queries presents a significant bottleneck to the inference speed.This paper proposes VKGFR (Virtual Knowledge Graph based Fact Retriever) that leverages large language models to extract representations corresponding to a sentence’s knowledge graph, significantly enhancing inference speed for multi-hop reasoning without performance loss.Given that both the queries and natural language database sentences can be structured as a knowledge graph, we suggest extracting a Virtual Knowledge Graph (VKG) representation from sentences with LLM.Over the pre-constructed VKG, our VKGFR conducts retrieval with a tiny model structure, showing performance improvements with higher computational efficiency. We evaluate VKGFR on the WikiNLDB and MetaQA dataset, designed for multi-hop database reasoning over text. The results indicate 13x faster inference speed on the WikiNLDB dataset without performance loss.</abstract>
      <url hash="d9dd4e2f">2024.kallm-1.1</url>
      <bibkey>son-etal-2024-multi</bibkey>
      <doi>10.18653/v1/2024.kallm-1.1</doi>
    </paper>
    <paper id="2">
      <title>Zero- and Few-Shots Knowledge Graph Triplet Extraction with Large Language Models</title>
      <author><first>Andrea</first><last>Papaluca</last></author>
      <author><first>Daniel</first><last>Krefl</last><affiliation>Ludwig-Maximilians-Universität München</affiliation></author>
      <author><first>Sergio</first><last>Rodríguez Méndez</last><affiliation>Australian National University</affiliation></author>
      <author><first>Artem</first><last>Lensky</last><affiliation>University of New South Wales and University of Sydney, University of Sydney</affiliation></author>
      <author><first>Hanna</first><last>Suominen</last><affiliation>Australian National University</affiliation></author>
      <pages>12-23</pages>
      <abstract>In this work, we tested the Triplet Extraction (TE) capabilities of a variety of Large Language Models (LLMs) of different sizes in the Zero- and Few-Shots settings. In detail, we proposed a pipeline that dynamically gathers contextual information from a Knowledge Base (KB), both in the form of context triplets and of (sentence, triplets) pairs as examples, and provides it to the LLM through a prompt. The additional context allowed the LLMs to be competitive with all the older fully trained baselines based on the Bidirectional Long Short-Term Memory (BiLSTM) Network architecture. We further conducted a detailed analysis of the quality of the gathered KB context, finding it to be strongly correlated with the final TE performance of the model. In contrast, the size of the model appeared to only logarithmically improve the TE capabilities of the LLMs. We release the code on GitHub for reproducibility.</abstract>
      <url hash="5e2a90da">2024.kallm-1.2</url>
      <bibkey>papaluca-etal-2024-zero</bibkey>
      <doi>10.18653/v1/2024.kallm-1.2</doi>
    </paper>
    <paper id="3">
      <title>Analysis of <fixed-case>LLM</fixed-case>’s “Spurious” Correct Answers Using Evidence Information of Multi-hop <fixed-case>QA</fixed-case> Datasets</title>
      <author><first>Ai</first><last>Ishii</last><affiliation>RIKEN and BIPROGY</affiliation></author>
      <author><first>Naoya</first><last>Inoue</last><affiliation>RIKEN and Japan Advanced Institute of Science and Technology</affiliation></author>
      <author><first>Hisami</first><last>Suzuki</last><affiliation>NII, National Institute of Informatics</affiliation></author>
      <author><first>Satoshi</first><last>Sekine</last><affiliation>RIKEN</affiliation></author>
      <pages>24-34</pages>
      <abstract>Recent LLMs show an impressive accuracy on one of the hallmark tasks of language understanding, namely Question Answering (QA). However, it is not clear if the correct answers provided by LLMs are actually grounded on the correct knowledge related to the question. In this paper, we use multi-hop QA datasets to evaluate the accuracy of the knowledge LLMs use to answer questions, and show that as much as 31% of the correct answers by the LLMs are in fact spurious, i.e., the knowledge LLMs used to ground the answer is wrong while the answer is correct. We present an analysis of these spurious correct answers by GPT-4 using three datasets in two languages, while suggesting future pathways to correct the grounding information using existing external knowledge bases.</abstract>
      <url hash="d6d29edf">2024.kallm-1.3</url>
      <bibkey>ishii-etal-2024-analysis</bibkey>
      <doi>10.18653/v1/2024.kallm-1.3</doi>
    </paper>
    <paper id="4">
      <title>Application of Generative <fixed-case>AI</fixed-case> as an Enterprise Wikibase Knowledge Graph <fixed-case>Q</fixed-case>&amp;<fixed-case>A</fixed-case> System</title>
      <author><first>Renê</first><last>Mendes</last><affiliation>Universidade Presbiteriana Mackenzie</affiliation></author>
      <author><first>Dimas</first><last>Oliveira</last></author>
      <author><first>Victor</first><last>Garcia</last></author>
      <pages>35-42</pages>
      <abstract>Generative AI and Large Language Models are increasingly used in business contexts. One application involves natural language conversations contextualized by company data, which can be accomplished by Enterprise Knowledge Graphs, standardized representations of data. This paper outlines an architecture for implementation of an Enterprise Knowledge Graph using open-source Wikibase software. Additionally, it is presented a Knowledge Graph Q&amp;A System powered by Generative AI.</abstract>
      <url hash="00447cdb">2024.kallm-1.4</url>
      <bibkey>mendes-etal-2024-application</bibkey>
      <doi>10.18653/v1/2024.kallm-1.4</doi>
    </paper>
    <paper id="5">
      <title><fixed-case>KGAST</fixed-case>: From Knowledge Graphs to Annotated Synthetic Texts</title>
      <author><first>Nakanyseth</first><last>Vuth</last></author>
      <author><first>Gilles</first><last>Sérasset</last><affiliation>Université Grenoble Alpes</affiliation></author>
      <author><first>Didier</first><last>Schwab</last><affiliation>Université Grenoble Alpes</affiliation></author>
      <pages>43-55</pages>
      <abstract>In recent years, the use of synthetic data, either as a complement or a substitute for original data, has emerged as a solution to challenges such as data scarcity and security risks. This paper is an initial attempt to automatically generate such data for Information Extraction tasks. We accomplished this by developing a novel synthetic data generation framework called KGAST, which leverages Knowledge Graphs and Large Language Models. In our preliminary study, we conducted simple experiments to generate synthetic versions of two datasets—a French security defense dataset and an English general domain dataset, after which we evaluated them both intrinsically and extrinsically. The results indicated that synthetic data can effectively complement original data, improving the performance of models on classes with limited training samples. This highlights KGAST’s potential as a tool for generating synthetic data for Information Extraction tasks.</abstract>
      <url hash="ba2d9b24">2024.kallm-1.5</url>
      <bibkey>vuth-etal-2024-kgast</bibkey>
      <doi>10.18653/v1/2024.kallm-1.5</doi>
    </paper>
    <paper id="6">
      <title><fixed-case>HRG</fixed-case>raph: Leveraging <fixed-case>LLM</fixed-case>s for <fixed-case>HR</fixed-case> Data Knowledge Graphs with Information Propagation-based Job Recommendation</title>
      <author><first>Azmine Toushik</first><last>Wasi</last></author>
      <pages>56-62</pages>
      <abstract>Knowledge Graphs (KGs) serving as semantic networks, prove highly effective in managing complex interconnected data in different domains, by offering a unified, contextualized, and structured representation with flexibility that allows for easy adaptation to evolving knowledge. Processing complex Human Resources (HR) data, KGs can help in different HR functions like recruitment, job matching, identifying learning gaps, and enhancing employee retention. Despite their potential, limited efforts have been made to implement practical HR knowledge graphs. This study addresses this gap by presenting a framework for effectively developing HR knowledge graphs from documents using Large Language Models. The resulting KG can be used for a variety of downstream tasks, including job matching, identifying employee skill gaps, and many more. In this work, we showcase instances where HR KGs prove instrumental in precise job matching, yielding advantages for both employers and employees. Empirical evidence from experiments with information propagation in KGs and Graph Neural Nets, along with case studies underscores the effectiveness of KGs in tasks such as job and employee recommendations and job area classification. Code and data are available at : https://github.com/azminewasi/HRGraph</abstract>
      <url hash="d2b17da6">2024.kallm-1.6</url>
      <bibkey>wasi-2024-hrgraph</bibkey>
      <doi>10.18653/v1/2024.kallm-1.6</doi>
    </paper>
    <paper id="7">
      <title>Adapting Multilingual <fixed-case>LLM</fixed-case>s to Low-Resource Languages with Knowledge Graphs via Adapters</title>
      <author><first>Daniil</first><last>Gurgurov</last></author>
      <author><first>Mareike</first><last>Hartmann</last><affiliation>Universität des Saarlandes</affiliation></author>
      <author><first>Simon</first><last>Ostermann</last><affiliation>German Research Center for AI</affiliation></author>
      <pages>63-74</pages>
      <abstract>This paper explores the integration of graph knowledge from linguistic ontologies into multilingual Large Language Models (LLMs) using adapters to improve performance for low-resource languages (LRLs) in sentiment analysis (SA) and named entity recognition (NER). Building upon successful parameter-efficient fine-tuning techniques, such as K-ADAPTER and MAD-X, we propose a similar approach for incorporating knowledge from multilingual graphs, connecting concepts in various languages with each other through linguistic relationships, into multilingual LLMs for LRLs. Specifically, we focus on eight LRLs — Maltese, Bulgarian, Indonesian, Nepali, Javanese, Uyghur, Tibetan, and Sinhala — and employ language-specific adapters fine-tuned on data extracted from the language-specific section of ConceptNet, aiming to enable knowledge transfer across the languages covered by the knowledge graph. We compare various fine-tuning objectives, including standard Masked Language Modeling (MLM), MLM with full-word masking, and MLM with targeted masking, to analyze their effectiveness in learning and integrating the extracted graph data. Through empirical evaluation on language-specific tasks, we assess how structured graph knowledge affects the performance of multilingual LLMs for LRLs in SA and NER, providing insights into the potential benefits of adapting language models for low-resource scenarios.</abstract>
      <url hash="3e14b935">2024.kallm-1.7</url>
      <bibkey>gurgurov-etal-2024-adapting</bibkey>
      <doi>10.18653/v1/2024.kallm-1.7</doi>
    </paper>
    <paper id="8">
      <title>Ontology-guided Knowledge Graph Construction from Maintenance Short Texts</title>
      <author><first>Zeno</first><last>Cauter</last></author>
      <author><first>Nikolay</first><last>Yakovets</last></author>
      <pages>75-84</pages>
      <abstract>Large-scale knowledge graph construction remains infeasible since it requires significant human-expert involvement. Further complications arise when building graphs from domain-specific data due to their unique vocabularies and associated contexts. In this work, we demonstrate the ability of open-source large language models (LLMs), such as Llama-2 and Llama-3, to extract facts from domain-specific Maintenance Short Texts (MSTs). We employ an approach which combines ontology-guided triplet extraction and in-context learning. By using only 20 semantically similar examples with the Llama-3-70B-Instruct model, we achieve performance comparable to previous methods that relied on fine-tuning techniques like SpERT and REBEL. This indicates that domain-specific fact extraction can be accomplished through inference alone, requiring minimal labeled data. This opens up possibilities for effective and efficient semi-automated knowledge graph construction for domain-specific data.</abstract>
      <url hash="2a7d1afe">2024.kallm-1.8</url>
      <bibkey>cauter-yakovets-2024-ontology</bibkey>
      <doi>10.18653/v1/2024.kallm-1.8</doi>
    </paper>
    <paper id="9">
      <title>Educational Material to Knowledge Graph Conversion: A Methodology to Enhance Digital Education</title>
      <author><first>Miquel</first><last>Canal-Esteve</last><affiliation>Universidad de Alicante</affiliation></author>
      <author><first>Yoan</first><last>Gutierrez</last><affiliation>University of Alicante</affiliation></author>
      <pages>85-91</pages>
      <abstract>This article argues that digital educational content should be structured as knowledge graphs (KGs). Unlike traditional repositories such as Moodle, a KG offers a more flexible representation of the relationships between concepts, facilitating intuitive navigation and discovery of connections. In addition, it integrates effectively with Large Language Models, enhancing personalized explanations, answers, and recommendations. This article studies different proposals based on semantics and knowledge modelling to determine the most appropriate ways to strengthen intelligent educational technologies.</abstract>
      <url hash="10eb2a79">2024.kallm-1.9</url>
      <bibkey>canal-esteve-gutierrez-2024-educational</bibkey>
      <doi>10.18653/v1/2024.kallm-1.9</doi>
    </paper>
    <paper id="10">
      <title><fixed-case>STAGE</fixed-case>: Simplified Text-Attributed Graph Embeddings using Pre-trained <fixed-case>LLM</fixed-case>s</title>
      <author><first>Aaron</first><last>Zolnai-Lucas</last><affiliation>Quantexa Ltd</affiliation></author>
      <author><first>Jack</first><last>Boylan</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Chris</first><last>Hokamp</last><affiliation>Quantexa</affiliation></author>
      <author><first>Parsa</first><last>Ghaffari</last></author>
      <pages>92-104</pages>
      <abstract>We present STAGE, a straightforward yet effective method for enhancing node features in Graph Neural Network (GNN) models that encode Text-Attributed Graphs (TAGs). Our approach leverages Large-Language Models (LLMs) to generate embeddings for textual attributes. STAGE achieves competitive results on various node classification benchmarks while also maintaining a simplicity in implementation relative to current state-of-the-art (SoTA) techniques. We show that utilizing pre-trained LLMs as embedding generators provides robust features for ensemble GNN training, enabling pipelines that are simpler than current SoTA approaches which require multiple expensive training and prompting stages. We also implement diffusion-pattern GNNs in an effort to make this pipeline scalable to graphs beyond academic benchmarks.</abstract>
      <url hash="a70c3207">2024.kallm-1.10</url>
      <bibkey>zolnai-lucas-etal-2024-stage</bibkey>
      <doi>10.18653/v1/2024.kallm-1.10</doi>
    </paper>
    <paper id="11">
      <title>Zero-Shot Fact-Checking with Semantic Triples and Knowledge Graphs</title>
      <author><first>Moy</first><last>Yuan</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Andreas</first><last>Vlachos</last><affiliation>University of Cambridge</affiliation></author>
      <pages>105-115</pages>
      <abstract>Despite progress in automated fact-checking, most systems require a significant amount of labeled training data, which is expensive. In this paper, we propose a novel zero-shot method, which instead of operating directly on the claim and evidence sentences, decomposes them into semantic triples augmented using external knowledge graphs, and uses large language models trained for natural language inference. This allows it to generalize to adversarial datasets and domains that supervised models require specific training data for. Our empirical results show that our approach outperforms previous zero-shot approaches on FEVER, FEVER-Symmetric, FEVER 2.0, and Climate-FEVER, while being comparable or better than supervised models on the adversarial and the out-of-domain datasets.</abstract>
      <url hash="a50c4d63">2024.kallm-1.11</url>
      <bibkey>yuan-vlachos-2024-zero</bibkey>
      <doi>10.18653/v1/2024.kallm-1.11</doi>
    </paper>
    <paper id="12">
      <title>Fine-tuning Language Models for Triple Extraction with Data Augmentation</title>
      <author><first>Yujia</first><last>Zhang</last><affiliation>University of Alberta</affiliation></author>
      <author><first>Tyler</first><last>Sadler</last></author>
      <author><first>Mohammad Reza</first><last>Taesiri</last></author>
      <author><first>Wenjie</first><last>Xu</last></author>
      <author><first>Marek</first><last>Reformat</last></author>
      <pages>116-124</pages>
      <abstract>Advanced language models with impressive capabilities to process textual information can more effectively extract high-quality triples, which are the building blocks of knowledge graphs. Our work examines language models’ abilities to extract entities and the relationships between them. We use a diverse data augmentation process to fine-tune large language models to extract triples from the text. Fine-tuning is performed using a mix of trainers from HuggingFace and five public datasets, such as different variations of the WebNLG, SKE, DocRed, FewRel, and KELM. Evaluation involves comparing model outputs with test-set triples based on several criteria, such as type, partial, exact, and strict accuracy.The obtained results outperform ChatGPT and even match or exceed the performance of GPT-4.</abstract>
      <url hash="d6946aeb">2024.kallm-1.12</url>
      <bibkey>zhang-etal-2024-fine-tuning</bibkey>
      <doi>10.18653/v1/2024.kallm-1.12</doi>
    </paper>
    <paper id="13">
      <title>Improving <fixed-case>LLM</fixed-case>-based <fixed-case>KGQA</fixed-case> for multi-hop Question Answering with implicit reasoning in few-shot examples</title>
      <author><first>Mili</first><last>Shah</last><affiliation>Microsoft</affiliation></author>
      <author><first>Joyce</first><last>Cahoon</last><affiliation>Microsoft</affiliation></author>
      <author><first>Mirco</first><last>Milletari</last><affiliation>Microsoft</affiliation></author>
      <author><first>Jing</first><last>Tian</last><affiliation>Microsoft</affiliation></author>
      <author><first>Fotis</first><last>Psallidas</last><affiliation>Microsoft</affiliation></author>
      <author><first>Andreas</first><last>Mueller</last><affiliation>Microsoft</affiliation></author>
      <author><first>Nick</first><last>Litombe</last><affiliation>Microsoft</affiliation></author>
      <pages>125-135</pages>
      <abstract>Large language models (LLMs) have shown remarkable capabilities in generating natural language texts for various tasks. However, using LLMs for question answering on knowledge graphs still remains a challenge, especially for questions requiring multi-hop reasoning. In this paper, we present a novel planned query guidance approach that improves large language model (LLM) performance in multi-hop question answering on knowledge graphs (KGQA). We do this by designing few-shot examples that implicitly demonstrate a systematic reasoning methodology to answer multi-hop questions. We evaluate our approach for two graph query languages, Cypher and SPARQL, and show that the queries generated using our strategy outperform the queries generated using a baseline LLM and typical few-shot examples by up to 24.66% and 7.7% in execution match accuracy for the MetaQA and the Spider benchmarks respectively. We also conduct an ablation study to analyze the incremental effects of the different techniques of designing few-shot examples. Our results suggest that our approach enables the LLM to effectively leverage the few-shot examples to generate queries for multi-hop KGQA.</abstract>
      <url hash="9e621cf2">2024.kallm-1.13</url>
      <bibkey>shah-etal-2024-improving</bibkey>
      <doi>10.18653/v1/2024.kallm-1.13</doi>
    </paper>
  </volume>
</collection>
