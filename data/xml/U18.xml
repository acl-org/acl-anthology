<?xml version='1.0' encoding='UTF-8'?>
<collection id="U18">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the Australasian Language Technology Association Workshop 2018</booktitle>
      <url hash="d16bf8c3">U18-1</url>
      <editor><first>Sunghwan Mac</first><last>Kim</last></editor>
      <editor><first>Xiuzhen (Jenny)</first><last>Zhang</last></editor>
      <address>Dunedin, New Zealand</address>
      <month>December</month>
      <year>2018</year>
    </meta>
    <frontmatter>
      <url hash="5802d99e">U18-1000</url>
    </frontmatter>
    <paper id="1">
      <title>Improved Neural Machine Translation using Side Information</title>
      <author><first>Cong Duy Vu</first><last>Hoang</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <pages>6–16</pages>
      <url hash="46593160">U18-1001</url>
      <abstract>In this work, we investigate whether side information is helpful in neural machine translation (NMT). We study various kinds of side information, including topical information, personal trait, then propose different ways of incorporating them into the existing NMT models. Our experimental results show the benefits of side information in improving the NMT models.</abstract>
    </paper>
    <paper id="2">
      <title>Text-dependent Forensic Voice Comparison: Likelihood Ratio Estimation with the Hidden <fixed-case>M</fixed-case>arkov Model (<fixed-case>HMM</fixed-case>) and <fixed-case>G</fixed-case>aussian Mixture Model</title>
      <author><first>Satoru</first><last>Tsuge</last></author>
      <author><first>Shunichi</first><last>Ishihara</last></author>
      <pages>17–25</pages>
      <url hash="cfe90e05">U18-1002</url>
      <abstract>Among the more typical forensic voice comparison (FVC) approaches, the acoustic-phonetic statistical approach is suitable for text-dependent FVC, but it does not fully exploit available time-varying information of speech in its modelling. The automatic approach, on the other hand, essentially deals with text-independent cases, which means temporal information is not explicitly incorporated in the modelling. Text-dependent likelihood ratio (LR)-based FVC studies, in particular those that adopt the automatic approach, are few. This preliminary LR-based FVC study compares two statistical models, the Hidden Markov Model (HMM) and the Gaussian Mixture Model (GMM), for the calculation of forensic LRs using the same speech data. FVC experiments were carried out using different lengths of Japanese short words under a forensically realistic, but challenging condition: only two speech tokens for model training and LR estimation. Log-likelihood-ratio cost (Cllr) was used as the assessment metric. The study demonstrates that the HMM system constantly outperforms the GMM system in terms of average Cllr values. However, words longer than three mora are needed if the advantage of the HMM is to become evident. With a seven-mora word, for example, the HMM outperformed the GMM by a Cllr value of 0.073.</abstract>
    </paper>
    <paper id="3">
      <title>Development of Natural Language Processing Tools for <fixed-case>C</fixed-case>ook <fixed-case>I</fixed-case>slands <fixed-case>M</fixed-case>āori</title>
      <author><first>Rolando Coto</first><last>Solano</last></author>
      <author><first>Sally Akevai</first><last>Nicholas</last></author>
      <author><first>Samantha</first><last>Wray</last></author>
      <pages>26–33</pages>
      <url hash="f4845959">U18-1003</url>
      <abstract>This paper presents three ongoing projects for NLP in Cook Islands Maori: Untrained Forced Alignment (approx. 9% error when detecting the center of words), speech-to-text (37% WER in the best trained models) and POS tagging (92% accuracy for the best performing model). Included as part of these projects are new resources filling in a gap in Australasian languages, including gold standard POS-tagged written corpora, transcribed speech corpora, time-aligned corpora down to the level of phonemes. These are part of efforts to accelerate the documentation of Cook Islands Maori and to increase its vitality amongst its users.</abstract>
    </paper>
    <paper id="4">
      <title>Unsupervised Mining of Analogical Frames by Constraint Satisfaction</title>
      <author><first>Lance</first><last>De Vine</last></author>
      <author><first>Shlomo</first><last>Geva</last></author>
      <author><first>Peter</first><last>Bruza</last></author>
      <pages>34–43</pages>
      <url hash="9cc4271d">U18-1004</url>
      <abstract>It has been demonstrated that vector-based representations of words trained on large text corpora encode linguistic regularities that may be exploited via the use of vector space arithmetic. This capability has been extensively explored and is generally measured via tasks which involve the automated completion of linguistic proportional analogies. The question remains, however, as to what extent it is possible to induce relations from word embeddings in a principled and systematic way, without the provision of exemplars or seed terms. In this paper we propose an extensible and efficient framework for inducing relations via the use of constraint satisfaction. The method is efficient, unsupervised and can be customized in various ways. We provide both quantitative and qualitative analysis of the results.</abstract>
    </paper>
    <paper id="5">
      <title>Specifying Conceptual Models Using Restricted Natural Language</title>
      <author><first>Bayzid Ashik</first><last>Hossain</last></author>
      <author><first>Rolf</first><last>Schwitter</last></author>
      <pages>44–52</pages>
      <url hash="5269a4f3">U18-1005</url>
      <abstract>The key activity to design an information system is conceptual modelling which brings out and describes the general knowledge that is required to build a system. In this paper we propose a novel approach to conceptual modelling where the domain experts will be able to specify and construct a model using a restricted form of natural language. A restricted natural language is a subset of a natural language that has well-defined computational properties and therefore can be translated unambiguously into a formal notation. We will argue that a restricted natural language is suitable for writing precise and consistent specifications that lead to executable conceptual models. Using a restricted natural language will allow the domain experts to describe a scenario in the terminology of the application domain without the need to formally encode this scenario. The resulting textual specification can then be automatically translated into the language of the desired conceptual modelling framework.</abstract>
    </paper>
    <paper id="6">
      <title>Extracting structured data from invoices</title>
      <author><first>Xavier</first><last>Holt</last></author>
      <author><first>Andrew</first><last>Chisholm</last></author>
      <pages>53–59</pages>
      <url hash="7220c734">U18-1006</url>
      <abstract>Business documents encode a wealth of information in a format tailored to human consumption – i.e. aesthetically disbursed natural language text, graphics and tables. We address the task of extracting key fields (e.g. the amount due on an invoice) from a wide-variety of potentially unseen document formats. In contrast to traditional template driven extraction systems, we introduce a content-driven machine-learning approach which is both robust to noise and generalises to unseen document formats. In a comparison of our approach with alternative invoice extraction systems, we observe an absolute accuracy gain of 20\% across compared fields, and a 25\%–94\% reduction in extraction latency.</abstract>
    </paper>
    <paper id="7">
      <title>Exploring Textual and Speech information in Dialogue Act Classification with Speaker Domain Adaptation</title>
      <author><first>Xuanli</first><last>He</last></author>
      <author><first>Quan</first><last>Tran</last></author>
      <author><first>William</first><last>Havard</last></author>
      <author><first>Laurent</first><last>Besacier</last></author>
      <author><first>Ingrid</first><last>Zukerman</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>61–65</pages>
      <url hash="ffff6bd6">U18-1007</url>
      <abstract>In spite of the recent success of Dialogue Act (DA) classification, the majority of prior works focus on text-based classification with oracle transcriptions, i.e. human transcriptions, instead of Automatic Speech Recognition (ASR)’s transcriptions. In spoken dialog systems, however, the agent would only have access to noisy ASR transcriptions, which may further suffer performance degradation due to domain shift. In this paper, we explore the effectiveness of using both acoustic and textual signals, either oracle or ASR transcriptions, and investigate speaker domain adaptation for DA classification. Our multimodal model proves to be superior to the unimodal models, particularly when the oracle transcriptions are not available. We also propose an effective method for speaker domain adaptation, which achieves competitive results.</abstract>
    </paper>
    <paper id="8">
      <title>Cluster Labeling by Word Embeddings and <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et's Hypernymy</title>
      <author><first>Hanieh</first><last>Poostchi</last></author>
      <author><first>Massimo</first><last>Piccardi</last></author>
      <pages>66–70</pages>
      <url hash="e98a71c5">U18-1008</url>
      <abstract>Cluster labeling is the assignment of representative labels to clusters obtained from the organization of a document collection. Once assigned, the labels can play an important role in applications such as navigation, search and document classification. However, finding appropriately descriptive labels is still a challenging task. In this paper, we propose various approaches for assigning labels to word clusters by leveraging word embeddings and the synonymity and hypernymy relations in the WordNet lexical ontology. Experiments carried out using the WebAP document dataset have shown that one of the approaches stand out in the comparison and is capable of selecting labels that are reasonably aligned with those chosen by a pool of four human annotators.</abstract>
    </paper>
    <paper id="9">
      <title>A Comparative Study of Embedding Models in Predicting the Compositionality of Multiword Expressions</title>
      <author><first>Navnita</first><last>Nandakumar</last></author>
      <author><first>Bahar</first><last>Salehi</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <pages>71–76</pages>
      <url hash="3d7aad37">U18-1009</url>
      <abstract>In this paper, we perform a comparative evaluation of off-the-shelf embedding models over the task of compositionality prediction of multiword expressions("MWEs"). Our experimental results suggest that character- and document-level models capture knowledge of MWE compositionality and are effective in modelling varying levels of compositionality, with the advantage over word-level models that they do not require token-level identification of MWEs in the training corpus.</abstract>
    </paper>
    <paper id="10">
      <title>Towards Efficient Machine Translation Evaluation by Modelling Annotators</title>
      <author><first>Nitika</first><last>Mathur</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Trevor</first><last>Cohn</last></author>
      <pages>77–82</pages>
      <url hash="618332c5">U18-1010</url>
      <abstract>Accurate evaluation of translation has long been a difficult, yet important problem. Current evaluations use direct assessment (DA), based on crowd sourcing judgements from a large pool of workers, along with quality control checks, and a robust method for combining redundant judgements. In this paper we show that the quality control mechanism is overly conservative, which increases the time and expense of the evaluation. We propose a model that does not rely on a pre-processing step to filter workers and takes into account varying annotator reliabilities. Our model effectively weights each worker's scores based on the inferred precision of the worker, and is much more reliable than the mean of either the raw scores or the standardised scores. We also show that DA does not deliver on the promise of longitudinal evaluation, and propose redesigning the structure of the annotation tasks that can solve this problem.</abstract>
    </paper>
    <paper id="11">
      <title>Overview of the 2018 <fixed-case>ALTA</fixed-case> Shared Task: Classifying Patent Applications</title>
      <author><first>Diego</first><last>Mollá</last></author>
      <author><first>Dilesha</first><last>Seneviratne</last></author>
      <pages>84–88</pages>
      <url hash="b16206b8">U18-1011</url>
      <abstract>We present an overview of the 2018 ALTA shared task. This is the 9th of the series of shared tasks organised by ALTA since 2010. The task was to classify Australian patent classifications following the sections defined by the International Patient Classification (IPC), using data made available by IP Australia. We introduce the task, describe the data and present the results of the participating teams. Some of the participating teams outperformed state of the art.</abstract>
    </paper>
    <paper id="12">
      <title>Classifying Patent Applications with Ensemble Methods</title>
      <author><first>Fernando</first><last>Benites</last></author>
      <author><first>Shervin</first><last>Malmasi</last></author>
      <author><first>Marcos</first><last>Zampieri</last></author>
      <pages>89–92</pages>
      <url hash="fe24ec3a">U18-1012</url>
      <abstract>We present methods for the automatic classification of patent applications using an annotated dataset provided by the organizers of the ALTA 2018 shared task - Classifying Patent Applications. The goal of the task is to use computational methods to categorize patent applications according to a coarse-grained taxonomy of eight classes based on the International Patent Classification (IPC). We tested a variety of approaches for this task and the best results, 0.778 micro-averaged F1-Score, were achieved by SVM ensembles using a combination of words and characters as features. Our team, BMZ, was ranked first among 14 teams in the competition.</abstract>
    </paper>
    <paper id="13">
      <title>Universal Language Model Fine-tuning for Patent Classification</title>
      <author><first>Jason</first><last>Hepburn</last></author>
      <pages>93–96</pages>
      <url hash="5e044eeb">U18-1013</url>
      <abstract>This paper describes the methods used for the 2018 ALTA Shared Task. The task this year was to automatically classify Australian patents into their main International Patent Classification section. Our final submission used a Support Vector Machine (SVM) and Universal Language Model with Fine-tuning (ULMFiT). Our system achieved the best results in the student category.</abstract>
    </paper>
  </volume>
</collection>
