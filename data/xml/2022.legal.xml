<?xml version='1.0' encoding='UTF-8'?>
<collection id="2022.legal">
  <volume id="1" ingest-date="2022-09-23" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Workshop on Ethical and Legal Issues in Human Language Technologies and Multilingual De-Identification of Sensitive Data In Language Resources within the 13th Language Resources and Evaluation Conference</booktitle>
      <editor><first>Ingo</first><last>Siegert</last></editor>
      <editor><first>Mickael</first><last>Rigault</last></editor>
      <editor><first>Victoria</first><last>Arranz</last></editor>
      <publisher>European Language Resources Association</publisher>
      <address>Marseille, France</address>
      <month>June</month>
      <year>2022</year>
      <url hash="dec2ece7">2022.legal-1</url>
      <venue>legal</venue>
    </meta>
    <frontmatter>
      <url hash="26a1c1dc">2022.legal-1.0</url>
      <bibkey>legal-2022-ethical</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Keynote Speech - Major developments in the legal framework concerning language resources</title>
      <author><first>Pawel</first><last>Kamocki</last></author>
      <pages>1</pages>
      <abstract>Introductory Talk for the Workshop on Legal and Ethical Issues in Human Language Technologies, LREC 2022, Marseille, 24 June 2022</abstract>
      <url hash="7d8862a1">2022.legal-1.1</url>
      <bibkey>kamocki-2022-keynote</bibkey>
    </paper>
    <paper id="2">
      <title>Sentiment Analysis and Topic Modeling for Public Perceptions of Air Travel: <fixed-case>COVID</fixed-case> Issues and Policy Amendments</title>
      <author><first>Avery</first><last>Field</last></author>
      <author><first>Aparna</first><last>Varde</last></author>
      <author><first>Pankaj</first><last>Lal</last></author>
      <pages>2–8</pages>
      <abstract>Among many industries, air travel is impacted by the COVID pandemic. Airlines and airports rely on public sector information to enforce guidelines for ensuring health and safety of travelers. Such guidelines can be policy amendments or laws during the pandemic. In response to the inception of COVID preventive policies, travelers have exercised freedom of expression via the avenue of online reviews. This avenue facilitates voicing public concern while anonymizing / concealing user identity as needed. It is important to assess opinions on policy amendments to ensure transparency and openness, while also preserving confidentiality and ethics. Hence, this study leverages data science to analyze, with identity protection, the online reviews of airlines and airports since 2017, considering impacts of COVID issues and relevant policy amendments since 2020. Supervised learning with VADER sentiment analysis is deployed to predict changes in opinion from 2017 to date. Unsupervised learning with LDA topic modeling is employed to discover air travelers’ major areas of concern before and after the pandemic. This study reveals that COVID policies have worsened public perceptions of air travel and aroused notable new concerns, affecting economics, environment and health.</abstract>
      <url hash="66844de4">2022.legal-1.2</url>
      <bibkey>field-etal-2022-sentiment</bibkey>
    </paper>
    <paper id="3">
      <title>Data Protection, Privacy and <fixed-case>US</fixed-case> Regulation</title>
      <author><first>Denise</first><last>DiPersio</last></author>
      <pages>9–16</pages>
      <abstract>This paper examines the state of data protection and privacy in the United States. There is no comprehensive federal data protection or data privacy law despite bipartisan and popular support. There are several data protection bills pending in the 2022 session of the US Congress, five of which are examined in Section 2 below. Although it is not likely that any will be enacted, the growing number reflects the concerns of citizens and lawmakers about the power of big data. Recent actions against data abuses, including data breaches, litigation and settlements, are reviewed in Section 3 of this paper. These reflect the real harm caused when personal data is misused. Section 4 contains a brief US copyright law update on the fair use exemption, highlighting a recent court decision and indications of a re-thinking of the fair use analysis. In Section 5, some observations are made on the role of privacy in data protection regulation. It is argued that privacy should be considered from the start of the data collection and technology development process. Enhanced awareness of ethical issues, including privacy, through university-level data science programs will also lay the groundwork for best practices throughout the data and development cycles.</abstract>
      <url hash="fa7eacb2">2022.legal-1.3</url>
      <bibkey>dipersio-2022-data</bibkey>
    </paper>
    <paper id="4">
      <title>Pseudonymisation of Speech Data as an Alternative Approach to <fixed-case>GDPR</fixed-case> Compliance</title>
      <author><first>Pawel</first><last>Kamocki</last></author>
      <author><first>Ingo</first><last>Siegert</last></author>
      <pages>17–21</pages>
      <abstract>The debate on the use of personal data in language resources usually focuses — and rightfully so — on anonymisation. However, this very same debate usually ends quickly with the conclusion that proper anonymisation would necessarily cause loss of linguistically valuable information. This paper discusses an alternative approach — pseudonymisation. While pseudonymisation does not solve all the problems (inasmuch as pseudonymised data are still to be regarded as personal data and therefore their processing should still comply with the GDPR principles), it does provide a significant relief, especially — but not only — for those who process personal data for research purposes. This paper describes pseudonymisation as a measure to safeguard rights and interests of data subjects under the GDPR (with a special focus on the right to be informed). It also provides a concrete example of pseudonymisation carried out within a research project at the Institute of Information Technology and Communications of the Otto von Guericke University Magdeburg.</abstract>
      <url hash="91ff8e31">2022.legal-1.4</url>
      <bibkey>kamocki-siegert-2022-pseudonymisation</bibkey>
    </paper>
    <paper id="5">
      <title>Categorizing legal features in a metadata-oriented task: defining the conditions of use</title>
      <author><first>Mickaël</first><last>Rigault</last></author>
      <author><first>Victoria</first><last>Arranz</last></author>
      <author><first>Valérie</first><last>Mapelli</last></author>
      <author><first>Penny</first><last>Labropoulou</last></author>
      <author><first>Stelios</first><last>Piperidis</last></author>
      <pages>22–26</pages>
      <abstract>In recent times, more attention has been brought by the Human Language Technology (HLT) community to the legal framework for making available and reusing Language Resources (LR) and tools. Licensing is now an issue that is foreseen in most research projects and that is essential to provide legal certainty for repositories when distributing resources. Some repositories such as Zenodo or Quantum Stat do not offer the possibility to search for resources by licenses which can turn the searching for relevant resources a very complex task. Other repositories such as Hugging Face propose a search feature by license which may make it difficult to figure out what use can be made of such resources. During the European Language Grid (ELG) project, we moved a step forward to link metadata with the terms and conditions of use. In this paper, we document the process we undertook to categorize legal features of licenses listed in the SPDX license list and widely used in the HLT community as well as those licenses used within the ELG platform</abstract>
      <url hash="f19eead8">2022.legal-1.5</url>
      <bibkey>rigault-etal-2022-categorizing</bibkey>
    </paper>
    <paper id="6">
      <title>About Migration Flows and Sentiment Analysis on <fixed-case>T</fixed-case>witter data: Building the Bridge between Technical and Legal Approaches to Data Protection</title>
      <author><first>Thilo</first><last>Gottschalk</last></author>
      <author><first>Francesca</first><last>Pichierri</last></author>
      <pages>27–37</pages>
      <abstract>Sentiment analysis has always been an important driver of political decisions and campaigns across all fields. Novel technologies allow automatizing analysis of sentiments on a big scale and hence provide allegedly more accurate outcomes. With user numbers in the billions and their increasingly important role in societal discussions, social media platforms become a glaring data source for these types of analysis. Due to its public availability, the relative ease of access and the sheer amount of available data, the Twitter API has become a particularly important source to researchers and data analysts alike. Despite the evident value of these data sources, the analysis of such data comes with legal, ethical and societal risks that should be taken into consideration when analysing data from Twitter. This paper describes these risks along the technical processing pipeline and proposes related mitigation measures.</abstract>
      <url hash="99d4e1f0">2022.legal-1.6</url>
      <bibkey>gottschalk-pichierri-2022-migration</bibkey>
    </paper>
    <paper id="7">
      <title>Transparency and Explainability of a Machine Learning Model in the Context of Human Resource Management</title>
      <author><first>Sebastien</first><last>Delecraz</last></author>
      <author><first>Loukman</first><last>Eltarr</last></author>
      <author><first>Olivier</first><last>Oullier</last></author>
      <pages>38–43</pages>
      <abstract>We introduce how the proprietary machine learning algorithms developed by Gojob, an HR Tech company, to match candidates to a job offer are as transparent and explainable as possible to users (i.e., our recruiters) and our clients (e.g. companies looking to fill jobs). We detail how our matching algorithm (which identifies the best candidates for a job offer) controls the fairness of its outcome. We have described the steps we have taken to ensure that the decisions made by our mathematical models not only inform but improve the performance of our recruiters.</abstract>
      <url hash="e5d5a027">2022.legal-1.7</url>
      <bibkey>delecraz-etal-2022-transparency</bibkey>
    </paper>
    <paper id="8">
      <title>Public Interactions with Voice Assistant – Discussion of Different One-Shot Solutions to Preserve Speaker Privacy</title>
      <author><first>Ingo</first><last>Siegert</last></author>
      <author><first>Yamini</first><last>Sinha</last></author>
      <author><first>Gino</first><last>Winkelmann</last></author>
      <author><first>Oliver</first><last>Jokisch</last></author>
      <author><first>Andreas</first><last>Wendemuth</last></author>
      <pages>44–47</pages>
      <abstract>In recent years, the use of voice assistants has rapidly grown. Hereby, above all, the user’s speech data is stored and processed on a cloud platform, being the decisive factor for a good performance in speech processing and understanding. Although usually, they can be found in private households, a lot of business cases are also employed using voice assistants for public places, be it as an information service, a tour guide, or a booking system. As long as the systems are used in private spaces, it could be argued that the usage is voluntary and that the user itself is responsible for what is processed by the voice assistant system. When leaving the private space, the voluntary use is not the case anymore, as users may be made aware that their voice is processed in the cloud and background voices can be unintendedly recorded and processed as well. Thus, the usage of voice assistants in public environments raises a lot of privacy concerns. In this contribution, we discuss possible anonymization solutions to hide the speakers’ identity, thus allowing a safe cloud processing of speech data. Thereby, we promote the public use of voice assistants.</abstract>
      <url hash="4588bb37">2022.legal-1.8</url>
      <bibkey>siegert-etal-2022-public</bibkey>
    </paper>
    <paper id="9">
      <title>Keynote Speech - Voice anonymization and the <fixed-case>GDPR</fixed-case></title>
      <author><first>Brij Mohan Lal</first><last>Srivastava</last></author>
      <pages>48</pages>
      <abstract>Talk for the Workshop on Legal and Ethical Issues in Human Language Technologies, LREC 2022, Marseille, 24 June 2022</abstract>
      <url hash="a66f3ac7">2022.legal-1.9</url>
      <bibkey>srivastava-2022-keynote</bibkey>
    </paper>
    <paper id="10">
      <title>Cross-Clinic De-Identification of <fixed-case>S</fixed-case>wedish Electronic Health Records: Nuances and Caveats</title>
      <author><first>Olle</first><last>Bridal</last></author>
      <author><first>Thomas</first><last>Vakili</last></author>
      <author><first>Marina</first><last>Santini</last></author>
      <pages>49–52</pages>
      <abstract>Privacy preservation of sensitive information is one of the main concerns in clinical text mining. Due to the inherent privacy risks of handling clinical data, the clinical corpora used to create the clinical Named Entity Recognition (NER) models underlying clinical de-identification systems cannot be shared. This situation implies that clinical NER models are trained and tested on data originating from the same institution since it is rarely possible to evaluate them on data belonging to a different organization. These restrictions on sharing make it very difficult to assess whether a clinical NER model has overfitted the data or if it has learned any undetected biases. This paper presents the results of the first-ever cross-institution evaluation of a Swedish de-identification system on Swedish clinical data. Alongside the encouraging results, we discuss differences and similarities across EHR naming conventions and NER tagsets.</abstract>
      <url hash="e2e0c454">2022.legal-1.10</url>
      <bibkey>bridal-etal-2022-cross</bibkey>
    </paper>
    <paper id="11">
      <title>Generating Realistic Synthetic Curricula Vitae for Machine Learning Applications under Differential Privacy</title>
      <author><first>Andrea</first><last>Bruera</last></author>
      <author><first>Francesco</first><last>Alda</last></author>
      <author><first>Francesco</first><last>Di Cerbo</last></author>
      <pages>53–63</pages>
      <abstract>Applications involving machine learning in Human Resources (HR, the management of human talent in order to accomplish organizational goals) must respect the privacy of the individuals whose data is being used. This is a difficult aim, given the extremely personal nature of text data handled by HR departments, such as Curricula Vitae (CVs).</abstract>
      <url hash="258422b1">2022.legal-1.11</url>
      <bibkey>bruera-etal-2022-generating</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>MAPA</fixed-case> Project: Ready-to-Go Open-Source Datasets and Deep Learning Technology to Remove Identifying Information from Text Documents</title>
      <author><first>Victoria</first><last>Arranz</last></author>
      <author><first>Khalid</first><last>Choukri</last></author>
      <author><first>Montse</first><last>Cuadros</last></author>
      <author><first>Aitor</first><last>García Pablos</last></author>
      <author><first>Lucie</first><last>Gianola</last></author>
      <author><first>Cyril</first><last>Grouin</last></author>
      <author><first>Manuel</first><last>Herranz</last></author>
      <author><first>Patrick</first><last>Paroubek</last></author>
      <author><first>Pierre</first><last>Zweigenbaum</last></author>
      <pages>64–72</pages>
      <abstract>This paper presents the outcomes of the MAPA project, a set of annotated corpora for 24 languages of the European Union and an open-source customisable toolkit able to detect and substitute sensitive information in text documents from any domain, using state-of-the art, deep learning-based named entity recognition techniques. In the context of the project, the toolkit has been developed and tested on administrative, legal and medical documents, obtaining state-of-the-art results. As a result of the project, 24 dataset packages have been released and the de-identification toolkit is available as open source.</abstract>
      <url hash="921a51db">2022.legal-1.12</url>
      <bibkey>arranz-etal-2022-mapa</bibkey>
    </paper>
    <paper id="13">
      <title><fixed-case>P</fixed-case>ri<fixed-case>PA</fixed-case>: A Tool for Privacy-Preserving Analytics of Linguistic Data</title>
      <author><first>Jeremie</first><last>Clos</last></author>
      <author><first>Emma</first><last>McClaughlin</last></author>
      <author><first>Pepita</first><last>Barnard</last></author>
      <author><first>Elena</first><last>Nichele</last></author>
      <author><first>Dawn</first><last>Knight</last></author>
      <author><first>Derek</first><last>McAuley</last></author>
      <author><first>Svenja</first><last>Adolphs</last></author>
      <pages>73–78</pages>
      <abstract>The days of large amorphous corpora collected with armies of Web crawlers and stored indefinitely are, or should be, coming to an end. There is a wealth of hidden linguistic information that is increasingly difficult to access, hidden in personal data that would be unethical and technically challenging to collect using traditional methods such as Web crawling and mass surveillance of online discussion spaces. Advances in privacy regulations such as GDPR and changes in the public perception of privacy bring into question the problematic ethical dimension of extracting information from unaware if not unwilling participants. Modern corpora need to adapt, be focused on testing specific hypotheses, and be respectful of the privacy of the people who generated its data. Our work focuses on using a distributed participatory approach and continuous informed consent to solve these issues, by allowing participants to voluntarily contribute their own censored personal data at a granular level. We evaluate our approach in a three-pronged manner, testing the accuracy of measurement of statistical measures of language with respect to standard corpus linguistics tools, evaluating the usability of our application with a participant involvement panel, and using the tool for a case study on health communication.</abstract>
      <url hash="dc88697c">2022.legal-1.13</url>
      <bibkey>clos-etal-2022-pripa</bibkey>
    </paper>
    <paper id="14">
      <title>Legal and Ethical Challenges in Recording Air Traffic Control Speech</title>
      <author><first>Mickaël</first><last>Rigault</last></author>
      <author><first>Claudia</first><last>Cevenini</last></author>
      <author><first>Khalid</first><last>Choukri</last></author>
      <author><first>Martin</first><last>Kocour</last></author>
      <author><first>Karel</first><last>Veselý</last></author>
      <author><first>Igor</first><last>Szoke</last></author>
      <author><first>Petr</first><last>Motlicek</last></author>
      <author><first>Juan Pablo</first><last>Zuluaga-Gomez</last></author>
      <author><first>Alexander</first><last>Blatt</last></author>
      <author><first>Dietrich</first><last>Klakow</last></author>
      <author><first>Allan</first><last>Tart</last></author>
      <author><first>Pavel</first><last>Kolčárek</last></author>
      <author><first>Jan</first><last>Černocký</last></author>
      <pages>79–83</pages>
      <abstract>In this paper the authors detail the various legal and ethical issues faced during the ATCO2 project. This project is aimed at developing tools to automatically collect and transcribe air traffic conversations, especially conversations between pilots and air controls towers. In this paper the authors will develop issues related to intellectual property, public data, privacy, and general ethics issues related to the collection of air-traffic control speech.</abstract>
      <url hash="f8508690">2022.legal-1.14</url>
      <bibkey>rigault-etal-2022-legal</bibkey>
    </paper>
    <paper id="15">
      <title>It is not Dance, is Data: Gearing Ethical Circulation of Intangible Cultural Heritage practices in the Digital Space</title>
      <author><first>Jorge</first><last>Yánez</last></author>
      <author><first>Amel</first><last>Fraisse</last></author>
      <pages>84–91</pages>
      <abstract>The documentation, protection and dissemination of Intangible Cultural Heritage (ICH) in the digital age pose significant theoretical, technological and legal challenges. Through a multidisciplinary lens, this paper presents new approaches for collecting, documenting, encrypting and protecting ICH-related data for more ethical circulation. Human-movement recognition technologies such as motion capture, allows for the recording, extraction and reproduction of human movement with unprecedented precision. The once indistinguishable or hard-to-trace reproduction of dance steps between their creators and unauthorized third parties becomes patent through the transmission of embodied knowledge, but in the form of data. This new battlefield prompted by digital technologies only adds to the disputes within the creative industries, in terms of authorship, ownership and commodification of body language. For the sake of this paper, we are aiming to disentangle the various layers present in the process of digitisation of the dancing body, to identify its by-products as well as the possible arising ownership rights that might entail. ”Who owns what?”, the basic premise of intellectual property law, is transposed, in this case, onto the various types of data generated when intangible cultural heritage, in the form of dance, is digitised through motion capture and encrypted with blockchain technologies.</abstract>
      <url hash="266f5d5c">2022.legal-1.15</url>
      <bibkey>yanez-fraisse-2022-dance</bibkey>
    </paper>
  </volume>
</collection>
