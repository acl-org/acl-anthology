<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.clicit">
  <volume id="1" ingest-date="2025-03-05" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 10th Italian Conference on Computational Linguistics (CLiC-it 2024)</booktitle>
      <editor><first>Felice</first><last>Dell'Orletta</last></editor>
      <editor><first>Alessandro</first><last>Lenci</last></editor>
      <editor><first>Simonetta</first><last>Montemagni</last></editor>
      <editor><first>Rachele</first><last>Sprugnoli</last></editor>
      <publisher>CEUR Workshop Proceedings</publisher>
      <address>Pisa, Italy</address>
      <month>December</month>
      <year>2024</year>
      <url hash="47ae4ad5">2024.clicit-1</url>
      <venue>clicit</venue>
    </meta>
    <frontmatter>
      <url hash="62d50911">2024.clicit-1.0</url>
      <bibkey>clic-it-2024-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Preface to the <fixed-case>CL</fixed-case>i<fixed-case>C</fixed-case>-it 2024 Proceedings</title>
      <author><first>Felice</first><last>Dell’Orletta</last><affiliation>ItaliaNLP Lab @ Institute for Computational Linguistics “Antonio Zampolli”, ILC - CNR</affiliation></author>
      <author><first>Alessandro</first><last>Lenci</last><affiliation>University of Pisa</affiliation></author>
      <author><first>Simonetta</first><last>Montemagni</last><affiliation>Istituto di Linguistica Computazionale “Antonio Zampolli”</affiliation></author>
      <author><first>Rachele</first><last>Sprugnoli</last><affiliation>University of Parma</affiliation></author>
      <pages>1-3</pages>
      <abstract/>
      <url hash="28f3ed61">2024.clicit-1.1</url>
      <bibkey>dellorletta-etal-2024-preface</bibkey>
    </paper>
    <paper id="2">
      <title>Lifeless Winter without Break: Ovid’s Exile Works and the <fixed-case>L</fixed-case>i<fixed-case>L</fixed-case>a Knowledge Base</title>
      <author><first>Aurora</first><last>Alagni</last><affiliation>Università Cattolica del Sacro Cuore</affiliation></author>
      <author><first>Francesco</first><last>Mambrini</last><affiliation>Università Cattolica del Sacro Cuore</affiliation></author>
      <author><first>Marco</first><last>Passarotti</last><affiliation>Università Cattolica del Sacro Cuore</affiliation></author>
      <pages>4-12</pages>
      <abstract>In this paper we describe the process of semi-automatic annotation and linking performed to connect two works by the Latin poet Ovid to the LiLa Knowledge Base of interoperable linguistic resources. Written after Ovid’s exile from Rome, the Tristia and the Epistulae ex Ponto mark the beginning of the “literature of exile”. In spite of their importance, no lemmatized version existed and the two collections were not part of the major annotated corpora linked to LiLa. The paper discusses the workflow used to annotate and publish the works as Linked Open Data connected to the LiLa Knowledge Base. On account of their subject and the emotional tone attached to the theme of exile, the two works are particularly relevant for sentiment analysis. We discuss some results of a lexicon-based analysis that is enabled by the interlinking with LiLa. We use LatinAffectus, a manually-generated polarity lexicon for Latin nouns and adjectives, to perform Sentiment Analysis on the aforementioned works and interpret the (replicable) results by consulting and simultaneously enriching the available literary scholarship with new information.</abstract>
      <url hash="7a76ca4d">2024.clicit-1.2</url>
      <bibkey>alagni-etal-2024-lifeless</bibkey>
    </paper>
    <paper id="3">
      <title>Exploring the Use of Cohesive Devices in Dementia within an Elderly <fixed-case>I</fixed-case>talian Semi-spontaneous Speech Corpus</title>
      <author><first>Giorgia</first><last>Albertin</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Elena</first><last>Martinelli</last><affiliation>University of Bologna</affiliation></author>
      <pages>13-19</pages>
      <abstract>The study of language disruption in dementia aimed at individuating which features correlate with the progression of cognitive impairment is a growing area in computational linguistic research. Still, it needs a further development in analyzing some discourse phenomena that also undergo deterioration, and can help expand our understanding of dementia-related speech and refine automatic tools. This paper explores the discourse property of cohesion by investigating three types of cohesive devices: reference, lexical iteration, and connectives. Ten features related to these categories have been defined and automatically extracted from an Italian corpus of semi-spontaneous speech collected from dementia patients and healthy controls. Some of the designed features have proven significant for the binary classification of the two groups and further quantitative analysis highlight interesting differences in the use of cohesive devices, that seem to be associated with cognitive decline.</abstract>
      <url hash="fc4d917a">2024.clicit-1.3</url>
      <bibkey>albertin-martinelli-2024-exploring</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>S</fixed-case>imil<fixed-case>E</fixed-case>x: The First <fixed-case>I</fixed-case>talian Dataset for Sentence Similarity with Natural Language Explanations</title>
      <author><first>Chiara</first><last>Alzetta</last><affiliation>Institute of Computational Linguistics “Antonio Zampolli”, CNR</affiliation></author>
      <author><first>Felice</first><last>Dell’orletta</last><affiliation>ItaliaNLP Lab @ Institute for Computational Linguistics “Antonio Zampolli”, ILC - CNR</affiliation></author>
      <author><first>Chiara</first><last>Fazzone</last><affiliation>ItaliaNLP Lab @ Institute for Computational Linguistics “Antonio Zampolli”, ILC - CNR</affiliation></author>
      <author><first>Giulia</first><last>Venturi</last><affiliation>Institute of Computational Linguistics “Antonio Zampolli” (ILC-CNR)</affiliation></author>
      <pages>20-28</pages>
      <abstract>Large language models (LLMs) demonstrate great performance in natural language processing and understanding tasks. However, much work remains to enhance their interpretability. Annotated datasets with explanations could be key to addressing this issue, as they enable the development of models that provide human-like explanations for their decisions. In this paper, we introduce the SimilEx dataset, the first Italian dataset reporting human evaluations of similarity between pairs of sentences. For a subset of these pairs, the annotators also provided explanations in natural language for the scores assigned. The SimilEx dataset is valuable for exploring the variability in similarity perception between sentences and for training LLMs to offer human-like explanations for their predictions.</abstract>
      <url hash="6613b4f8">2024.clicit-1.4</url>
      <bibkey>alzetta-etal-2024-similex</bibkey>
    </paper>
    <paper id="5">
      <title>Data Augmentation for Low-Resource <fixed-case>I</fixed-case>talian <fixed-case>NLP</fixed-case>: Enhancing Semantic Processing with <fixed-case>DRS</fixed-case></title>
      <author><first>Muhammad Saad</first><last>Amin</last><affiliation>The University of Turin</affiliation></author>
      <author><first>Luca</first><last>Anselma</last><affiliation>Università degli Studi di Torino</affiliation></author>
      <author><first>Alessandro</first><last>Mazzei</last><affiliation>Università degli Studi di Torino</affiliation></author>
      <pages>29-38</pages>
      <abstract>Discourse Representation Structure (DRS), a formal meaning representation, has shown promising results in semantic parsing and natural language generation tasks for high-resource languages like English. This paper investigates enhancing the application of DRS to low-resource Italian Natural Language Processing (NLP), in both semantic parsing (Text-to-DRS) and natural language generation (DRS-to-Text). To address the scarcity of annotated corpora for Italian DRS, we propose a novel data augmentation technique that involves the use of external linguistic resources including: (i) WordNet for common nouns, adjectives, adverbs, and verbs; (ii) LLM-generated named entities for proper nouns; and (iii) rule-based algorithms fortense augmentation. This approach not only increases the quantity of training data but also introduces linguistic diversity, which is crucial for improving model performance and robustness. Using this augmented dataset, we developed neural semantic parser and generator models that demonstrated enhanced generalization ability compared to models trained on non-augmented data. We evaluated the effect of semantic data augmentation using two state-of-the-art transformer-based neural sequence-to-sequence models, i.e., byT5 and IT5. Our implementation shows promising results for Italian semanticprocessing. Data augmentation significantly increased the performance of semantic parsing from 76.10 to 90.56 (+14.46%) F1-SMATCH score and generation with 37.79 to 57.48 (+19.69%) BLEU, 30.83 to 40.95 (+10.12%) METEOR, 81.66 to 90.97 (+9.31%) COMET, 54.84 to 70.88 (+16.04%) chrF, and 88.86 to 92.97 (+4.11%) BERT scores. These results demonstrate the effectiveness of our novel augmentation approach in enhancing semantic processing capabilities for low-resource languages like Italian.</abstract>
      <url hash="a075e8be">2024.clicit-1.5</url>
      <bibkey>amin-etal-2024-data</bibkey>
    </paper>
    <paper id="6">
      <title><fixed-case>I</fixed-case>ta<fixed-case>E</fixed-case>val and <fixed-case>T</fixed-case>weety<fixed-case>I</fixed-case>ta: A New Extensive Benchmark and Efficiency-First Language Model for <fixed-case>I</fixed-case>talian</title>
      <author><first>Giuseppe</first><last>Attanasio</last><affiliation>Instituto de Telecomunicacoes</affiliation></author>
      <author><first>Pieter</first><last>Delobelle</last><affiliation>KU Leuven, Department of Computer Science</affiliation></author>
      <author><first>Moreno</first><last>La Quatra</last><affiliation>Kore University of Enna</affiliation></author>
      <author><first>Andrea</first><last>Santilli</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Beatrice</first><last>Savoldi</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <pages>39-51</pages>
      <abstract>Current development and benchmarking efforts for modern, large-scale Italian language models (LMs) are scattered.This paper situates such efforts by introducing two new resources: ItaEval, a comprehensive evaluation suite, and TweetyIta, an efficiency-first language model for Italian.Through ItaEval, we standardize evaluation across language understanding, commonsense and factual knowledge, and social bias-related tasks.In our attempt at language modeling, we experiment with efficient, tokenization-based adaption techniques. Our TweetyIta shows encouraging results after training on as little as 5G tokens from natural Italian corpora. We benchmark an extensive list of models against ItaEval and find several interesting insights. Surprisingly, i) models trained predominantly on English data dominate the leaderboard; ii) TweetyIta is competitive against other forms of adaptation or inherently monolingual models;iii) natural language understanding tasks are challenging for current models.We release code and data at https://github.com/RiTA-nlp/ita-eval and host a live leaderboard at https://huggingface.co/spaces/RiTA-nlp/ita-eval.</abstract>
      <url hash="2259ecd0">2024.clicit-1.6</url>
      <bibkey>attanasio-etal-2024-itaeval</bibkey>
    </paper>
    <paper id="7">
      <title><fixed-case>LL</fixed-case>a<fixed-case>MA</fixed-case>ntino against Cyber Intimate Partner Violence</title>
      <author><first>Pierpaolo</first><last>Basile</last><affiliation>Department of Computer Science, University of Bari Aldo Moro</affiliation></author>
      <author><first>Marco</first><last>Degemmis</last><affiliation>University of Bari</affiliation></author>
      <author><first>Marco</first><last>Polignano</last><affiliation>University of Bari</affiliation></author>
      <author><first>Giovanni</first><last>Semeraro</last><affiliation>University of Bari “Aldo Moro”</affiliation></author>
      <author><first>Lucia</first><last>Siciliani</last><affiliation>University of Bari Aldo Moro</affiliation></author>
      <author><first>Vincenzo</first><last>Tamburrano</last><affiliation>University of Bari Aldo Moro</affiliation></author>
      <author><first>Fabiana</first><last>Battista</last><affiliation>University of Bari Aldo Moro</affiliation></author>
      <author><first>Rosa</first><last>Scardigno</last><affiliation>University of Bari Aldo Moro</affiliation></author>
      <pages>52-58</pages>
      <abstract>Intimate Partner Violence refers to the abusive behaviours perpetrated on their own partner. Unfortunately this is a social issue that has witnessed an increase over time, particularly after Covid-19. IPV be circumscribed into two broad categories known as Intimate Partner Violence (IPV) and Cyber Intimate Partner Violence (C-IPV). Social Media and technologies can exacerbate these types of behaviors but some “digital footprints”, such as textual conversations, can be exploited by Artificial Intelligence models to detect and, in turn, prevent them. With this aim in mind, this paper describes a scenario in which the Italian Language Model family LLAmAntino can be exploited to explain the presence of toxicity elements in conversations related to teenage relationships and then educate the interlocutor to recognize these elements in the messages received.</abstract>
      <url hash="686bff7b">2024.clicit-1.7</url>
      <bibkey>basile-etal-2024-llamantino</bibkey>
    </paper>
    <paper id="8">
      <title>Taking Decisions in a Hybrid Conversational <fixed-case>AI</fixed-case> Architecture Using Influence Diagrams</title>
      <author><first>Roberto</first><last>Basile Giannini</last><affiliation>University of Naples Federico II</affiliation></author>
      <author><first>Antonio</first><last>Origlia</last><affiliation>Dept. of Electrical Engineering and Information Technology - University of Naples “Federico II”</affiliation></author>
      <author><first>Maria</first><last>Di Maro</last><affiliation>Università degli Studi di Napoli ‘Federico II’</affiliation></author>
      <pages>59-65</pages>
      <abstract>This paper explores the application of the Influence Diagrams model for decision-making in the context of conversational agents. The system consists of a Conversational Recommender System (CoRS), in which the decision-making module is separate from the language generation module. It provides the capability to evolve a belief based on user responses, which in turn influences the decisions made by the conversational agent. The proposed system is based on a pre-existing CoRS that relies on Bayesian Networks informing a separate decision process. The introduction of Influence Diagrams aims to integrate both Bayesian inference and the dialogue move selection phase into a single model, thereby generalising the decision-making process. To test the effectiveness and plausibility of the dialogues generated by the developed CoRS, a dialogue simulator was created and the simulated interactions were evaluated by a pool of human judges.</abstract>
      <url hash="d708b921">2024.clicit-1.8</url>
      <bibkey>basile-giannini-etal-2024-taking</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>KEVLAR</fixed-case>: The Complete Resource for <fixed-case>E</fixed-case>uro<fixed-case>V</fixed-case>oc Classification of Legal Documents</title>
      <author><first>Lorenzo</first><last>Bocchi</last><affiliation>University of Trento</affiliation></author>
      <author><first>Camilla</first><last>Casula</last><affiliation>University of Trento / Fondazione Bruno Kessler</affiliation></author>
      <author><first>Alessio</first><last>Palmero Aprosio</last><affiliation>University of Trento</affiliation></author>
      <pages>66-73</pages>
      <abstract>The use of Machine Learning and Artificial Intelligence in the Public Administration (PA) has increased in the last years. In particular, recent guidelines proposed by various governments for the classification of documents released by the PA suggest to use the EuroVoc thesaurus. In this paper, we present KEVLAR, an all-in-one solution for performing the above-mentioned task on acts belonging to the Public Administration. First, we create a collection of 8 million documents in 24 languages, tagged with EuroVoc labels, taken from EUR-Lex, the web portal of the European Union legislation. Then, we train different pre-trained BERT-based models, comparing the performance of base models with domain-specific and multilingual ones. We release the corpus, the best-performing models, and a Docker image containing the source code of the trainer, the REST API, and the web interface. This image can be employed out-of-the-box for document classification.</abstract>
      <url hash="24b4f149">2024.clicit-1.9</url>
      <bibkey>bocchi-etal-2024-kevlar</bibkey>
    </paper>
    <paper id="10">
      <title>Title Is (Not) All You Need for <fixed-case>E</fixed-case>uro<fixed-case>V</fixed-case>oc Multi-Label Classification of <fixed-case>E</fixed-case>uropean Laws</title>
      <author><first>Lorenzo</first><last>Bocchi</last><affiliation>University of Trento</affiliation></author>
      <author><first>Alessio</first><last>Palmero Aprosio</last><affiliation>University of Trento</affiliation></author>
      <pages>74-80</pages>
      <abstract>Machine Learning and Artificial Intelligence approaches within Public Administration (PA) have grown significantly in recent years. Specifically, new guidelines from various governments recommend employing the EuroVoc thesaurus for the classification of documents issued by the PA.In this paper, we explore some methods to perform document classification in the legal domain, in order to mitigate the length limitation for input texts in BERT models.We first collect data from the European Union, already tagged with the aforementioned taxonomy.Then we reorder the sentences included in the text, with the aim of bringing the most informative part of the document in the first part of the text.Results show that the title and the context are both important, although the order of the text may not.Finally, we release on GitHub both the dataset and the source code used for the experiments.</abstract>
      <url hash="fd4e7929">2024.clicit-1.10</url>
      <bibkey>bocchi-palmero-aprosio-2024-title</bibkey>
    </paper>
    <paper id="11">
      <title>Exploring the Dissociated Nucleus Phenomenon in Semantic Role Labeling</title>
      <author><first>Tommaso</first><last>Bonomo</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Simone</first><last>Conia</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Roberto</first><last>Navigli</last><affiliation>Sapienza University of Rome</affiliation></author>
      <pages>81-89</pages>
      <abstract>Dependency-based Semantic Role Labeling (SRL) is bound to dependency parsing, as the arguments of a predicate are identified through the token that heads the dependency relation subtree of the argument. However, most dependency-based SRL corpora are susceptible to the dissociated nucleus problem: when a subclause’s semantic and structural cores are two separate words, the dependency tree chooses the structural token as the head of the subtree, coercing the SRL annotation into making the same choice. This leads to undesirable consequences: when directly using the output of a dependency-based SRL method in downstream tasks it is useful to work with the token representing the semantic core of a subclause, not the structural core. In this paper, we carry out a linguistically-driven investigation on the dissociated nucleus problem in dependency-based SRL and propose a novel algorithm that aligns predicate-argument structures to the syntactic structures from Universal Dependencies to select the semantic core of an argument. Our analysis shows that dissociated nuclei appear more often than one could expect, and that our novel algorithm greatly increases the richness of the semantic information in dependency-based SRL. We release the software to reproduce our experiments at http://omitted.link.</abstract>
      <url hash="84ceab34">2024.clicit-1.11</url>
      <bibkey>bonomo-etal-2024-exploring</bibkey>
    </paper>
    <paper id="12">
      <title>Data Augmentation through Back-Translation for Stereotypes and Irony Detection</title>
      <author><first>Tom</first><last>Bourgeade</last><affiliation>LORIA - INRIA, University of Lorraine</affiliation></author>
      <author><first>Silvia</first><last>Casola</last><affiliation>LMU Munich</affiliation></author>
      <author><first>Adel</first><last>Mahmoud Wizan</last><affiliation>Dipartimento di Informatica, Università di Torino, Turin, Italy</affiliation></author>
      <author><first>Cristina</first><last>Bosco</last><affiliation>Dipartimento di Informatica - UniversitÃ di Torino</affiliation></author>
      <pages>90-97</pages>
      <abstract>Complex linguistic phenomena such as stereotypes or irony are still challenging to detect, particularly due to the lower availability of annotated data. In this paper, we explore Back-Translation (BT) as a data augmentation method to enhance such datasets by artificially introducing semantics-preserving variations. We investigate French and Italian as source languages on two multilingual datasets annotated for the presence of stereotypes or irony and evaluate French/Italian, English, andArabic as pivot languages for the BT process. We also investigate cross-translation, i.e., augmenting one language subset of a multilingual dataset with translated instances from the other languages. We conduct an intrinsic evaluation of the quality of back-translated instances, identifying linguistic or translation model-specific errors that may occur with BT. We also perform an extrinsic evaluation of different data augmentation configurations to train a multilingual Transformer-based classifier forstereotype or irony detection on mono-lingual data.</abstract>
      <url hash="23f7c275">2024.clicit-1.12</url>
      <bibkey>bourgeade-etal-2024-data</bibkey>
    </paper>
    <paper id="13">
      <title>Community-based Stance Detection</title>
      <author><first>Emanuele</first><last>Brugnoli</last><affiliation>Sony CSL - Rome</affiliation></author>
      <author><first>Donald Ruggiero</first><last>Lo Sardo</last><affiliation>Sony CSL - Rome</affiliation></author>
      <pages>98-105</pages>
      <abstract>Stance detection is a critical task in understanding the alignment or opposition of statements within social discourse. In this study, we present a novel stance detection model that labels claim-perspective pairs as either aligned or opposed. The primary innovation of our work lies in our training technique, which leverages social network data from X (formerly Twitter). Our dataset comprises tweets from opinion leaders, political entities and news outlets, along with their followers’ interactions through retweets and quotes. By reconstructing politically aligned communities based on retweet interactions, treated as endorsements, we check these communities against common knowledge representations of the political landscape.Our training dataset consists of tweet/quote pairs where the tweet comes from a political entity and the quote either originates from a follower who exclusively retweets that political entity (treated as aligned) or from a user who exclusively retweets a political entity from an opposing ideological community (treated as opposed). This curated subset is used to train an Italian language model based on the RoBERTa architecture, achieving an accuracy of approximately 85%. We then apply our model to label all tweet/quote pairs in the dataset, analyzing its out-of-sample predictions.This work not only demonstrates the efficacy of our stance detection model but also highlights the utility of social network structures in training robust NLP models. Our approach offers a scalable and accurate method for understanding political discourse and the alignment of social media statements.</abstract>
      <url hash="5662d0e7">2024.clicit-1.13</url>
      <bibkey>brugnoli-lo-sardo-2024-community</bibkey>
    </paper>
    <paper id="14">
      <title>Towards a Hate Speech Index with Attention-based <fixed-case>LSTM</fixed-case>s and <fixed-case>XLM</fixed-case>-<fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a</title>
      <author><first>Mauro</first><last>Bruno</last><affiliation>Istat - Italian National Institute of Statistics</affiliation></author>
      <author><first>Elena</first><last>Catanese</last><affiliation>Istat - Italian National Institute of Statistics</affiliation></author>
      <author><first>Francesco</first><last>Ortame</last><affiliation>Istat - Italian National Institute of Statistics</affiliation></author>
      <pages>106-113</pages>
      <abstract>The uncontrolled diffusion of hate speech on social media requires robust detection mechanisms to measure its harmful impact. Analyzing texts from X (formerly Twitter) is challenging due to slang, neologisms, and sarcasm, which require advanced and intelligent detection approaches. While sophisticated models like large language models (LLMs) demonstrate impressive accuracy, their prohibitive inference times make it impractical to process millions of tweets. Therefore, we propose a mixed approach using a bidirectional long short-term memory model with an added attention mechanism (AT-BiLSTM) for improved natural language understanding. We benchmark this model against a standard BiLSTM model and a fine-tuned multilingual robustly optimized BERT (RoBERTa).The task of hate speech detection has been extensively explored in the EVALITA campaigns, which have achieved impressive results. Building on this foundation, we aim to develop a robust classifier to predict the content of approximately 20 million tweets related to immigration. The performance of our models is comparable to the top entries from the EVALITA campaigns, and we show the effects of training different networks on the dynamics of the Hate Speech Index (HSI). We also utilize a custom labeled dataset for benchmarking and training.</abstract>
      <url hash="a1339cf0">2024.clicit-1.14</url>
      <bibkey>bruno-etal-2024-towards</bibkey>
    </paper>
    <paper id="15">
      <title>Written Goodbyes: How Genre and Sociolinguistic Factors Influence the Content and Style of Suicide Notes</title>
      <author><first>Lucia</first><last>Busso</last><affiliation>Aston Institute for Forensic Linguistics, Aston University</affiliation></author>
      <author><first>Claudia Roberta</first><last>Combei</last><affiliation>University of Pavia</affiliation></author>
      <pages>114-121</pages>
      <abstract>The study analyses a novel corpus of 76 freely available English authentic suicide notes (SNs) (letters and social media posts), spanning from 1902 to 2023. By using computational and corpus linguistics, this research aims at decoding patterns of discourse, content, and emotions in SNs. In particular, we explore variation in linguistic features in SNs across sociolinguistic factors (age, gender, addressee, time period) and between genres (letter vs. post). To this end, we use topic models, subjectivity analysis, and sentiment and emotion analysis. Results highlight how both style, content, and emotion expression, show differences depending on genre, gender, age group and time period. We suggest a more nuanced approach to personalized prevention and intervention strategies based on insights from computer-assisted linguistic analysis.</abstract>
      <url hash="550faab6">2024.clicit-1.15</url>
      <bibkey>busso-combei-2024-written</bibkey>
    </paper>
    <paper id="16">
      <title>Argument Mining in <fixed-case>B</fixed-case>io<fixed-case>M</fixed-case>edicine: Zero-Shot, In-Context Learning and Fine-tuning with <fixed-case>LLM</fixed-case>s</title>
      <author><first>Jérémie</first><last>Cabessa</last><affiliation>University of Versailles (UVSQ) - University of Paris-Saclay</affiliation></author>
      <author><first>Hugo</first><last>Hernault</last><affiliation>Playtika Ltd.</affiliation></author>
      <author><first>Umer</first><last>Mushtaq</last><affiliation>La Rochelle Université</affiliation></author>
      <pages>122-131</pages>
      <abstract>Argument Mining (AM) aims to extract the complex argumentative structure of a text and Argument Type Classification (ATC) is an essential sub-task of AM. Large Language Models (LLMs) have shown impressive capabilities in most NLP tasks and beyond. However, fine-tuning LLMs can be challenging. In-Context Learning (ICL) has been suggested as a bridging paradigm between training-free and fine-tuning settings for LLMs. In ICL, an LLM is conditioned to solve tasks using a few solved demonstration examples included in its prompt. We focuse on AM in the biomedical AbstRCT dataset. We address ATC using quantized and unquantized LLaMA-3 models through zero-shot learning, in-context learning, and fine-tuning approaches. We introduce a novel ICL strategy that combines $k$NN-based example selection with majority vote ensembling, along with a well-designed fine-tuning strategy for ATC. In zero-shot setting, we show that LLaMA-3 fails to achieve acceptable classification results, suggesting the need for additional training modalities. However, in our ICL training-free setting, LLaMA-3 can leverage relevant information from only a few demonstration examples to achieve very competitive results. Finally, in our fine-tuning setting, LLaMA-3 achieves state-of-the-art performance on ATC task in AbstRCT dataset.</abstract>
      <url hash="1151b302">2024.clicit-1.16</url>
      <bibkey>cabessa-etal-2024-argument</bibkey>
    </paper>
    <paper id="17">
      <title>Multisource Approaches to <fixed-case>I</fixed-case>talian <fixed-case>S</fixed-case>ign <fixed-case>L</fixed-case>anguage (<fixed-case>LIS</fixed-case>) Recognition: Insights from the <fixed-case>M</fixed-case>ulti<fixed-case>M</fixed-case>eda<fixed-case>LIS</fixed-case> Dataset</title>
      <author><first>Gaia</first><last>Caligiore</last><affiliation>University of Modena Reggio-Emilia</affiliation></author>
      <author><first>Raffaele</first><last>Mineo</last><affiliation>University of Catania</affiliation></author>
      <author><first>Concetto</first><last>Spampinato</last><affiliation>University of Catania</affiliation></author>
      <author><first>Egidio</first><last>Ragonese</last><affiliation>University of Catania</affiliation></author>
      <author><first>Simone</first><last>Palazzo</last><affiliation>University of Catania</affiliation></author>
      <author><first>Sabina</first><last>Fontana</last><affiliation>University of Catania</affiliation></author>
      <pages>132-140</pages>
      <abstract>Given their status as unwritten visual-gestural languages, research on the automatic recognition of sign languages has increasingly implemented multisource capturing tools for data collection and processing. This paper explores advancements in Italian Sign Language (LIS) recognition using a multimodal dataset in the medical domain: the MultiMedaLIS Dataset. We investigate the integration of RGB frames, depth data, optical flow, and skeletal information to develop and evaluate two computational models: Skeleton-Based Graph Convolutional Network (SL-GCN) and Spatiotemporal Separable Convolutional Network (SSTCN). RADAR data was collected but not included in the testing phase. Our experiments validate the effectiveness of these models in enhancing the accuracy and robustness of isolated LIS signs recognition. Our findings highlight the potential of multisource approaches in computational linguistics to improve linguistic accessibility and inclusivity for members of the signing community.</abstract>
      <url hash="1b5a053b">2024.clicit-1.17</url>
      <bibkey>caligiore-etal-2024-multisource</bibkey>
    </paper>
    <paper id="18">
      <title>Combining <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies and <fixed-case>F</fixed-case>rame<fixed-case>N</fixed-case>et to Identify Constructions in a Poetic Corpus: Syntax and Semantics of <fixed-case>L</fixed-case>atin Felix and Infelix in Virgilian Poetics</title>
      <author><first>Giulia</first><last>Calvi</last><affiliation>Università Cattolica del Sacro Cuore</affiliation></author>
      <author><first>Riccardo</first><last>Ginevra</last><affiliation>Università Cattolica del Sacro Cuore</affiliation></author>
      <author><first>Federica</first><last>Iurescia</last><affiliation>Catholic University of the Sacred Hearth</affiliation></author>
      <pages>141-147</pages>
      <abstract>The paper is a pilot study which argues for a constructionist and computer-based approach to the syntactic and semantic analysis of a poetic corpus in Latin. We focus on the terms felix and on its opposite infelix and perform manual annotation of their occurrences in Virgil’s poems using Universal Dependencies for the syntactic analysis and FrameNet for the semantic one. Integrating the approaches of Dependency Syntax and Construction Grammar, we analyze the linguistic contexts in which the two terms occur and identify the different “constructions” (pairings of form and function) that they instantiate. Our methodology is language-independent and has the potential to aid scholars in the comparative analysis of poetic texts, allowing for the detection of hidden parallels in the style and poetics of different texts and authors.</abstract>
      <url hash="c706047c">2024.clicit-1.18</url>
      <bibkey>calvi-etal-2024-combining</bibkey>
    </paper>
    <paper id="19">
      <title>Lost in Disambiguation: How Instruction-Tuned <fixed-case>LLM</fixed-case>s Master Lexical Ambiguity</title>
      <author><first>Luca</first><last>Capone</last><affiliation>CoLing Lab, Dipartimento di Filologia, Letteratura e Linguistica, Università di Pisa, Via Santa Maria, Pisa, 56126, Italy</affiliation></author>
      <author><first>Serena</first><last>Auriemma</last><affiliation>University of Pisa</affiliation></author>
      <author><first>Martina</first><last>Miliani</last><affiliation>University of Pisa</affiliation></author>
      <author><first>Alessandro</first><last>Bondielli</last><affiliation>University of Pisa</affiliation></author>
      <author><first>Alessandro</first><last>Lenci</last><affiliation>University of Pisa</affiliation></author>
      <pages>148-156</pages>
      <abstract>This paper investigates how decoder-only instruction-tuned LLMs handle lexical ambiguity. Two distinct methodologies are employed: Eliciting rating scores from the model via prompting and analysing the cosine similarity between pairs of polysemous words in context. Ratings and embeddings are obtained by providing pairs of sentences from Haber and Poesio (2021) to the model. These ratings and cosine similarity scores are compared with each other and with the human similarity judgments in the dataset.Surprisingly, the model scores show only a moderate correlation with the subjects’ similarity judgments and no correlation with the target word embedding similarities. A vector space anisotropy inspection has also been performed, as a potential source of the experimental results. The analysis reveals that the embedding spaces of two out of the three analyzed models exhibit poor anisotropy, while the third model shows relatively moderate anisotropy compared to previous findings for models with similar architecture (Ethayarajh 2019). These findings offer new insights into the relationship between generation quality and vector representations in decoder-only LLMs.</abstract>
      <url hash="17a2d21e">2024.clicit-1.19</url>
      <bibkey>capone-etal-2024-lost</bibkey>
    </paper>
    <paper id="20">
      <title><fixed-case>B</fixed-case>a<fixed-case>BIE</fixed-case>s: A Benchmark for the Linguistic Evaluation of <fixed-case>I</fixed-case>talian Baby Language Models</title>
      <author><first>Luca</first><last>Capone</last><affiliation>CoLing Lab, Dipartimento di Filologia, Letteratura e Linguistica, Università di Pisa, Via Santa Maria, Pisa, 56126, Italy</affiliation></author>
      <author><first>Alice</first><last>Suozzi</last><affiliation>Ca Foscari University of Venice</affiliation></author>
      <author><first>Gianluca</first><last>Lebani</last><affiliation>Ca’ Foscari University of Venice</affiliation></author>
      <author><first>Alessandro</first><last>Lenci</last><affiliation>University of Pisa</affiliation></author>
      <pages>157-170</pages>
      <abstract>The possibility of comparing the linguistic competence of Language Models (LMs) to that of children has gained growing attention lately, raising the need for effective tools for evaluating both the former and the latter. To this purpose, we developed a resource for the linguistic evaluation of BabyLMs, which are LMs trained on datasets that comparable to the linguistic stimulus received by children. This resource adapts four standardized tests for the evaluation of linguistic skills of Italian-speaking children (BVL, TROG-2, TCGB-2 and Peabody). To verify the effectiveness of our benchmark, we administered it to Minerva, a LLM pretrained from scratch on Italian. Our results indicate that Minerva struggles to master certain linguistic aspects, achieving an age-equivalent score of 4 years, and that the type of task administered affects the model’s performance.</abstract>
      <url hash="27a5c9ab">2024.clicit-1.20</url>
      <bibkey>capone-etal-2024-babies</bibkey>
    </paper>
    <paper id="21">
      <title>Beyond Headlines: A Corpus of Femicides News Coverage in <fixed-case>I</fixed-case>talian Newspapers</title>
      <author><first>Eleonora</first><last>Cappuccio</last><affiliation>University of Pisa</affiliation></author>
      <author><first>Benedetta</first><last>Muscato</last><affiliation>Università di Pisa</affiliation></author>
      <author><first>Laura</first><last>Pollacci</last><affiliation>University of Pisa</affiliation></author>
      <author><first>Marta</first><last>Marchiori Manerba</last><affiliation>Università di Pisa</affiliation></author>
      <author><first>Clara</first><last>Punzi</last><affiliation>University of Pisa</affiliation></author>
      <author><first>Chandana</first><last>Mala</last><affiliation>University of Pisa</affiliation></author>
      <author><first>Margherita</first><last>Lalli</last><affiliation>Scuola Normale Superiore</affiliation></author>
      <author><first>Gizem</first><last>Gezici</last><affiliation>Scuola Normale Superiore</affiliation></author>
      <author><first>Michela</first><last>Natilli</last><affiliation>ISTI-CNR Pisa</affiliation></author>
      <author><first>Fosca</first><last>Giannotti</last><affiliation>Scuola Normale Superiore</affiliation></author>
      <pages>171-181</pages>
      <abstract>How newspapers cover news significantly impacts how facts are understood, perceived, and processed by the public. This is especially crucial when serious crimes are reported, e.g., in the case of femicides, where the description of the perpetrator and the victim builds a strong, often polarized opinion of this severe societal issue. This paper presents FMNews, a new dataset of articles reporting femicides extracted from Italian newspapers. Our core contribution aims to promote the development of a deeper framing and awareness of the phenomenon through an original resource available and accessible to the research community, facilitating further analyses on the topic. The paper also provides a preliminary study of the resulting collection through several example use cases and scenarios.</abstract>
      <url hash="71fef51c">2024.clicit-1.21</url>
      <bibkey>cappuccio-etal-2024-beyond</bibkey>
    </paper>
    <paper id="22">
      <title>Women’s Professions and Targeted Misogyny Online</title>
      <author><first>Alessio</first><last>Cascione</last><affiliation>University of Pisa</affiliation></author>
      <author><first>Aldo</first><last>Cerulli</last><affiliation>University of Pisa</affiliation></author>
      <author><first>Marta</first><last>Marchiori Manerba</last><affiliation>University of Pisa</affiliation></author>
      <author><first>Lucia</first><last>Passaro</last><affiliation>University of Pisa</affiliation></author>
      <pages>182-189</pages>
      <abstract>With the increasing popularity of social media platforms, the dissemination of misogynistic content has become more prevalent and challenging to address. In this paper, we investigate the phenomenon of online misogyny on Twitter through the lens of hurtfulness, qualifying its different manifestation considering the profession of the targets of misogynistic attacks.By leveraging manual annotation and a BERTweet model trained for fine-grained misogyny identification, we find that specific types of misogynistic speech are more intensely directed towards particular professions: derailing discourse predominantly targets authors and cultural figures, while dominance-oriented speech and sexual harassment are mainly directed at politicians and athletes. Additionally, we use the HurtLex lexicon and ItEM to assign hurtfulness scores to tweets based on different hate speech categories. Our analysis reveals that these scores align with the profession-based distribution of misogynistic speech, highlighting the targeted nature of such attacks.</abstract>
      <url hash="ca87d35d">2024.clicit-1.22</url>
      <bibkey>cascione-etal-2024-womens</bibkey>
    </paper>
    <paper id="23">
      <title><fixed-case>DWUG</fixed-case>s-<fixed-case>IT</fixed-case>: Extending and Standardizing Lexical Semantic Change Detection for <fixed-case>I</fixed-case>talian</title>
      <author><first>Pierluigi</first><last>Cassotti</last><affiliation>University of Gothenburg</affiliation></author>
      <author><first>Pierpaolo</first><last>Basile</last><affiliation>Department of Computer Science, University of Bari Aldo Moro</affiliation></author>
      <author><first>Nina</first><last>Tahmasebi</last><affiliation>University of Gothenburg</affiliation></author>
      <pages>190-197</pages>
      <abstract>Lexical Semantic Change Detection (LSCD) is the task of determining whether a word has undergone a change in meaning over time. There has been a marked increase in interest in this task, accompanied by a corresponding growth in the scientific community involved in developing computational approaches to semantic change. In recent years, a number of resources have been made available for the evaluation of LSC models in a number of languages, including English, Swedish, German, Latin, Russian and Chinese. DIACR-ITA is the only existing resource for LSCD in Italian. However, DIACR-ITA has a different format from that used for other languages. In this paper we present DWUGs-IT, which extends the DIACR-ITA dataset with additional target words and usage-sense pair annotations and adapts it to the DURel format, including the first implementation of a LSCD graded task for Italian.</abstract>
      <url hash="d3a9f01b">2024.clicit-1.23</url>
      <bibkey>cassotti-etal-2024-dwugs</bibkey>
    </paper>
    <paper id="24">
      <title>History Repeats: Historical Phase Recognition from Short Texts</title>
      <author><first>Fabio</first><last>Celli</last><affiliation>Maggioli Informatica R&amp;D</affiliation></author>
      <author><first>Valerio</first><last>Basile</last><affiliation>University of Turin</affiliation></author>
      <pages>198-204</pages>
      <abstract>This paper introduces a new multi-class classification task: the prediction of the Structural-Demographic phase of historical cycles - such as growth, impoverishment and crisis - from text describing historical events. To achieve this, we leveraged data from the Seshat project, annotated it following specific guidelines and then evaluated the consistency between three annotators. The classification experiments, with transformers and Large Language Models, show that 2 of 5 phases can be detected with good accuracy. We believe that this task could have a great impact on comparative history and can be helped by event extraction in NLP.</abstract>
      <url hash="b4c1f0df">2024.clicit-1.24</url>
      <bibkey>celli-basile-2024-history</bibkey>
    </paper>
    <paper id="25">
      <title>Emojilingo: Harnessing <fixed-case>AI</fixed-case> to Translate Words into Emojis</title>
      <author><first>Francesca</first><last>Chiusaroli</last><affiliation>University of Macerata</affiliation></author>
      <author><first>Federico</first><last>Sangati</last><affiliation>OIST Graduate University, Japan</affiliation></author>
      <author><first>Johanna</first><last>Monti</last><affiliation>University of Naples L’Orientale</affiliation></author>
      <author><first>Maria Laura</first><last>Pierucci</last><affiliation>University of Macerata</affiliation></author>
      <author><first>Tiberio</first><last>Uricchio</last><affiliation>University of Macerata</affiliation></author>
      <pages>205-213</pages>
      <abstract>This paper presents an AI experiment of translation in emoji conducted on a glossary from Dante Alighieri’s Comedy. The experiment is part of a project aiming to build up an automated emojibased pivot language providing an interlingua as a tool for linguistic simplification, accessibility, and international communication: Emojilingo. The present test involves human (Emojitaliano) and machine (Chat-GPT) translations in a comparative analysis to devise an automated integrated model highlighting emojis’ expressive ability in transferring senses, clarifying semantic obscurities and ambiguities, and simplifying language. A first preliminary evaluation highlights Chat-GPT’s ability to deal with a classic archaic literary vocabulary, also raising issues on managing criteria for better grasping the meanings and forms and about the multicultural extent of content transfer.</abstract>
      <url hash="9eafc31b">2024.clicit-1.25</url>
      <bibkey>chiusaroli-etal-2024-emojilingo</bibkey>
    </paper>
    <paper id="26">
      <title>Towards an <fixed-case>ASR</fixed-case> System for Documenting Endangered Languages: A Preliminary Study on <fixed-case>S</fixed-case>ardinian</title>
      <author><first>Ilaria</first><last>Chizzoni</last><affiliation>Free University of Bozen-Bolzano</affiliation></author>
      <author><first>Alessandro</first><last>Vietti</last><affiliation>Free University of Bozen-Bolzano</affiliation></author>
      <pages>214-220</pages>
      <abstract>Speech recognition systems are still highly dependent on textual orthographic resources, posing a challenge for low-resourcelanguages. Recent research leverages self-supervised learning of unlabeled data or employs multilingual models pre-trainedon high resource languages for fine-tuning on the target low-resource language. These are effective approacheswhen the target language has a shared writing tradition, but when we are confronted with mainly spoken languages, beingthem endangered minority languages, dialects, or regional varieties, other than labeled data, we lack a shared metric toassess speech recognition performance. We first provide a research background on ASR for low-resource languages anddescribe the specific linguistic situation of Campidanese Sardinian, we then evaluate five multilingual ASR models usingtraditional evaluation metrics and an exploratory linguistic analysis. The paper addresses key challenges in developing a toolfor researchers to document and analyze the phonetics and phonology of spoken (endangered) languages.</abstract>
      <url hash="ada72163">2024.clicit-1.26</url>
      <bibkey>chizzoni-vietti-2024-towards</bibkey>
    </paper>
    <paper id="27">
      <title>Controllable Text Generation to Evaluate Linguistic Abilities of <fixed-case>I</fixed-case>talian <fixed-case>LLM</fixed-case>s</title>
      <author><first>Cristiano</first><last>Ciaccio</last><affiliation>Istituto di Linguistica Computazionale “A.Zampolli” (CNR-ILC)</affiliation></author>
      <author><first>Felice</first><last>Dell’orletta</last><affiliation>ItaliaNLP Lab @ Institute for Computational Linguistics “Antonio Zampolli”, ILC - CNR</affiliation></author>
      <author><first>Alessio</first><last>Miaschi</last><affiliation>Institute for Computational Linguistics “A. Zampolli” (CNR-ILC), Pisa</affiliation></author>
      <author><first>Giulia</first><last>Venturi</last><affiliation>Institute of Computational Linguistics “Antonio Zampolli” (ILC-CNR)</affiliation></author>
      <pages>221-232</pages>
      <abstract>State-of-the-art Large Language Models (LLMs) demonstrate exceptional proficiency across diverse tasks, yet systematic evaluations of their linguistic abilities remain limited. This paper addresses this gap by proposing a new evaluation framework leveraging the potentialities of Controllable Text Generation. Our approach evaluates the models’ capacity to generate sentences that adhere to specific linguistic constraints and their ability to recognize the linguistic properties of their own generated sentences, also in terms of consistency with the specified constraints. We tested our approach on six Italian LLMs using various linguistic constraints.</abstract>
      <url hash="cc78904f">2024.clicit-1.27</url>
      <bibkey>ciaccio-etal-2024-controllable</bibkey>
    </paper>
    <paper id="28">
      <title>A Modal Sense Classifier for the <fixed-case>F</fixed-case>rench Modal Verb Pouvoir</title>
      <author><first>Anna</first><last>Colli</last><affiliation>Modyco laboratory, Paris Nanterre University</affiliation></author>
      <author><first>Diego</first><last>Rossini</last><affiliation>Paris Nanterre University</affiliation></author>
      <author><first>Delphine</first><last>Battistelli</last><affiliation>CNRS Paris Nanterre University</affiliation></author>
      <pages>233-243</pages>
      <abstract>In this paper we address the problem of modal sense classification for the French modal verb pouvoir in a transcribed spoken corpus. To the best of our knowledge, no studies have focused on this task in French. We fine-tuned various BERT-based models for French in order to determine which one performed best. It was found that the Flaubert-base-cased model was the most effective (F1-score of 0.94) and that the most frequent categories in our corpus were material possibility and ability, which are both part of the more global alethic category.</abstract>
      <url hash="1d7c5569">2024.clicit-1.28</url>
      <bibkey>colli-etal-2024-modal</bibkey>
    </paper>
    <paper id="29">
      <title>Topic Similarity of Heterogeneous Legal Sources Supporting the Legislative Process</title>
      <author><first>Michele</first><last>Corazza</last><affiliation>Department of Legal Studies - University of Bologna</affiliation></author>
      <author><first>Leonardo</first><last>Zilli</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Monica</first><last>Palmirani</last><affiliation>Department of Legal Studies - University of Bologna</affiliation></author>
      <pages>244-250</pages>
      <abstract>The legislative process starts with a deep analysis of the existing regulations at European and national levels to avoid conflicts and fostering the into force norms. Also the Constitutional Court decisions play a fundamental role in this analysis for checking the compliance with the constitutional framework and for including the inputs coming from this relevant court in the law-making process. Finally, it is also significant to compare the forthcoming proposal with the already presented bills regarding the same topic. This comparison is crucial to avoid overlapping and to coordinate the democratic dialogue with the different parties. In this light, this paper presents an unsupervised approach for calculating similarity between heterogeneous documents annotated in Akoma Ntoso XML, with the aim to support the information retrieval of similar documents using thematic taxonomy used in legal domain. The prototype has been developed for answering to a call for manifestation of interests launched by the Chamber of Deputy of Italy in order to adopt hybrid AI in the legislation process. It uses a completely unsupervised approach based on Sentence Transformers, meaning that neither annotated data or any fine-tuning process is required.</abstract>
      <url hash="ffbd412a">2024.clicit-1.29</url>
      <bibkey>corazza-etal-2024-topic</bibkey>
    </paper>
    <paper id="30">
      <title>Join Together? Combining Data to Parse <fixed-case>I</fixed-case>talian Texts</title>
      <author><first>Claudia</first><last>Corbetta</last><affiliation>University Bergamo/Pavia</affiliation></author>
      <author><first>Giovanni</first><last>Moretti</last><affiliation>Università Cattolica del Sacro Cuore</affiliation></author>
      <author><first>Marco</first><last>Passarotti</last><affiliation>Università Cattolica del Sacro Cuore</affiliation></author>
      <pages>251-257</pages>
      <abstract>In this paper, we create and evaluate non-combined and combined models using Old and Contemporary Italian data to determine whether increasing the size of the training data with a combined model could improve parsing accuracy to facilitate manual annotation. We find that, despite the increased size of the training data, in-domain parsing performs better. Additionally, we discover that models trained on Old Italian data perform better on Contemporary Italian data than the reverse. We attempt to explain this result in terms of syntactic complexity, finding that Old Italian text exhibits higher sentence length and non-projectivity rate.</abstract>
      <url hash="41f89f8a">2024.clicit-1.30</url>
      <bibkey>corbetta-etal-2024-join</bibkey>
    </paper>
    <paper id="31">
      <title>Using Large Speech Models for Feature Extraction in Cross-Lingual Speech Emotion Recognition</title>
      <author><first>Federico</first><last>D’asaro</last><affiliation>Politecnico di Torino</affiliation></author>
      <author><first>Juan José</first><last>Márquez Villacís</last><affiliation>LINKS Foundation</affiliation></author>
      <author><first>Giuseppe</first><last>Rizzo</last><affiliation>LINKS Foundation</affiliation></author>
      <author><first>Andrea</first><last>Bottino</last><affiliation>Politecnico di Torino</affiliation></author>
      <pages>258-265</pages>
      <abstract>Large Speech Models (LSMs), pre-trained on extensive unlabeled data using Self-Supervised Learning (SSL) or WeaklySupervised Learning (WSL), are increasingly employed for tasks like Speech Emotion Recognition (SER). Their capability to extract general-purpose features makes them a strong alternative to low-level descriptors. Most studies focus on English, with limited research on other languages. We evaluate English-Only and Multilingual LSMs from the Wav2Vec 2.0 and Whisper families as feature extractors for SER in eight languages. We have stacked three alternative downstream classifiers of increasing complexity, named Linear, Non-Linear, and Multi-Layer, on top of the LSMs. Results indicate that Whisper models perform best with a simple linear classifier using features from the last transformer layer, while Wav2Vec 2.0 models benefit from features from the middle and early transformer layers. When comparing English-Only and Multilingual LSMs, we find that Whisper models benefit from multilingual pre-training, excelling in Italian, Canadian French, French, Spanish, German and competitively on Greek, Egyptian Arabic, Persian. In contrast, English-Only Wav2Vec 2.0 models outperform their multilingual counterpart, XLS-R, in most languages, achieving the highest performance in Greek, Egyptian Arabic.</abstract>
      <url hash="772a7603">2024.clicit-1.31</url>
      <bibkey>dasaro-etal-2024-using</bibkey>
    </paper>
    <paper id="32">
      <title>Building a Pragmatically Annotated Diachronic Corpus: The <fixed-case>DIADI</fixed-case>ta Project</title>
      <author><first>Irene</first><last>De Felice</last><affiliation>Università del Piemonte Orientale</affiliation></author>
      <author><first>Francesca</first><last>Strik Lievers</last><affiliation>University of Genoa</affiliation></author>
      <pages>266-272</pages>
      <abstract>We present here the initial stages of the construction of the DIADIta corpus, a diachronic corpus of Italian annotated for interactional pragmatic phenomena. First, we describe the annotation scheme, which is structured into four levels: speech acts (e.g., apology; threat), forms (e.g., discourse marker; expressive), pragmatic functions (which are speaker-oriented, e.g., mitigation; turn-taking), and pragmatic aims (which are interlocutor-oriented, e.g., attention-getting; request for agreement). Next, we discuss how the results of a first annotation exercise provide indications for refining the annotation procedure.</abstract>
      <url hash="b3a944ed">2024.clicit-1.32</url>
      <bibkey>de-felice-strik-lievers-2024-building</bibkey>
    </paper>
    <paper id="33">
      <title>Building <fixed-case>C</fixed-case>oref<fixed-case>L</fixed-case>at. a Linguistic Resource for Coreference and Anaphora Resolution in <fixed-case>L</fixed-case>atin</title>
      <author><first>Eleonora</first><last>Delfino</last><affiliation>University of Udine</affiliation></author>
      <author><first>Roberta</first><last>Leotta</last><affiliation>Università Cattolica del Sacro Cuore di Milano</affiliation></author>
      <author><first>Marco</first><last>Passarotti</last><affiliation>Università Cattolica del Sacro Cuore</affiliation></author>
      <author><first>Giovanni</first><last>Moretti</last><affiliation>Università Cattolica del Sacro Cuore di Milano</affiliation></author>
      <pages>273-279</pages>
      <abstract>This paper presents the initial stages of a project focused on coreference and anaphora resolution in Latin texts. By building a corpus enhanced with coreference/anaphora annotation, the project wants to explore empirically a layer of metalinguistic analysis that has not been yet extensively investigated in linguistic resources and natural language processing for Latin. After reviewing the related work, the paper discusses annotation criteria and data analysis, providing examples about a few issues that emerged during the annotation process.</abstract>
      <url hash="f84effd0">2024.clicit-1.33</url>
      <bibkey>delfino-etal-2024-building</bibkey>
    </paper>
    <paper id="34">
      <title>Is Explanation All You Need? An Expert Survey on <fixed-case>LLM</fixed-case>-generated Explanations for Abusive Language Detection</title>
      <author><first>Chiara</first><last>Di Bonaventura</last><affiliation>King’s College London</affiliation></author>
      <author><first>Lucia</first><last>Siciliani</last><affiliation>University of Bari Aldo Moro</affiliation></author>
      <author><first>Pierpaolo</first><last>Basile</last><affiliation>Department of Computer Science, University of Bari Aldo Moro</affiliation></author>
      <author><first>Albert</first><last>Merono Penuela</last><affiliation>King’s College London</affiliation></author>
      <author><first>Barbara</first><last>Mcgillivray</last><affiliation>King’s College London</affiliation></author>
      <pages>280-288</pages>
      <abstract>Explainable abusive language detection has proven to help both users and content moderators, and recent research has focused on prompting LLMs to generate explanations for why a specific text is hateful. Yet, understanding the alignment of these generated explanations with human expectations and judgements is far from being solved. In this paper, we design a before-and-after study recruiting AI experts to evaluate the usefulness and trustworthiness of LLM-generated explanations for abusive language detection tasks, investigating multiple LLMs and learning strategies. Our experiments show that expectations in terms of usefulness and trustworthiness of LLM-generated explanations are not met, as their ratings decrease by 47.78% and 64.32%, respectively, after treatment. Further, our results suggest caution in using LLMs for explanation generation of abusive language detection due to (i) their cultural bias, and (ii) difficulty in reliably evaluating them with empirical metrics. In light of our results, we provide three recommendations to use LLMs responsibly for explainable abusive language detection.</abstract>
      <url hash="9e4020e7">2024.clicit-1.34</url>
      <bibkey>di-bonaventura-etal-2024-explanation</bibkey>
    </paper>
    <paper id="35">
      <title>Scalable Query Understanding for <fixed-case>E</fixed-case>-commerce: An Ensemble Architecture with Graph-based Optimization</title>
      <author><first>Giuseppe</first><last>Di Fabbrizio</last><affiliation>Harvard Business School</affiliation></author>
      <author><first>Evgeny</first><last>Stepanov</last><affiliation>VUI, Inc.</affiliation></author>
      <author><first>Ludovico</first><last>Frizziero</last><affiliation>VUI, Inc.</affiliation></author>
      <author><first>Filippo</first><last>Tessaro</last><affiliation>VUI, Inc.</affiliation></author>
      <pages>289-296</pages>
      <abstract>Query understanding is a critical component of e-commerce platforms, enabling accurate interpretation of users’ intents and efficient retrieval of relevant products. This paper presents a study on scalable query understanding techniques applied to a real use case in the e-commerce grocery domain. We propose a novel architecture that combines deep learning models with traditional ML models to capture query nuances and provide robust performance. Our model ensemble approach aims to capture the nuances of user queries and provide robust performance across various query types and categories. We conduct experiments on real-life datasets and demonstrate the effectiveness of our proposed solution in terms of accuracy and scalability. An optimized graph-based architecture using Ray enables efficient processing of high-volume traffic. The experimental results highlight the benefits of combining diverse models.</abstract>
      <url hash="8170fc11">2024.clicit-1.35</url>
      <bibkey>di-fabbrizio-etal-2024-scalable</bibkey>
    </paper>
    <paper id="36">
      <title><fixed-case>ELI</fixed-case>ta: A New <fixed-case>I</fixed-case>talian Language Resource for Emotion Analysis</title>
      <author><first>Eliana</first><last>Di Palma</last><affiliation>Sapienza- University of Rome - Università degli studi Roma Tre</affiliation></author>
      <pages>297-307</pages>
      <abstract>Emotions and language are strongly associated. In recent years, many resources have been created to investigate this association and automatically detect emotions from texts.Presenting ELIta (Emotion Lexicon for Italian), this study provides a new language resource for the analysis and detection of emotions in Italian texts. It describes the process of lexicon creation, including lexicon selection and annotation methodologies, and compares the collected data with existing resources. By offering a non-aggregated lexicon, ELIta fills a crucial gap and is applicable to various research and practical applications. Furthermore, the work utilises the lexicon by analysing the relationships between emotions and gender.</abstract>
      <url hash="43588589">2024.clicit-1.36</url>
      <bibkey>di-palma-2024-elita</bibkey>
    </paper>
    <paper id="37">
      <title>Comparing Large Language Models Verbal Creativity to Human Verbal Creativity</title>
      <author><first>Anca</first><last>Dinu</last><affiliation>University of Bucharest</affiliation></author>
      <author><first>Andra</first><last>Florescu</last><affiliation>University of Bucharest</affiliation></author>
      <pages>308-315</pages>
      <abstract>This study investigates verbal creativity differences and similarities between Large Language Models and humans, based ontheir answers given to the integrated verbal creativity test in [1 ]. Since this article reported a very small difference of scoresin favour of the machines, the aim of the present work is to thoroughly analyse the data through four methods: scoring theuniqueness of the answers of one human or one machine compared to all the others, semantic similarity clustering, binaryclassification and manual inspection of the data. The results showed that humans and machines are on a par in terms ofuniqueness scores, that humans and machines group in two well defined clusters based on semantics similarities, and that theanswers are not so easy to automatically classify in human answers and LLM answers.</abstract>
      <url hash="37c25149">2024.clicit-1.37</url>
      <bibkey>dinu-florescu-2024-comparing</bibkey>
    </paper>
    <paper id="38">
      <title><fixed-case>I</fixed-case>t<fixed-case>G</fixed-case>ra<fixed-case>S</fixed-case>yll: A Computational Analysis of Graphical Syllabification and Stress Assignment in <fixed-case>I</fixed-case>talian</title>
      <author><first>Liviu</first><last>Dinu</last><affiliation>University of Bucharest</affiliation></author>
      <author><first>Ioan-Bogdan</first><last>Iordache</last><affiliation>University of Bucharest</affiliation></author>
      <author><first>Simona</first><last>Georgescu</last><affiliation>University of Bucharest</affiliation></author>
      <author><first>Alina Maria</first><last>Cristea</last><affiliation>University of Bucharest</affiliation></author>
      <author><first>Bianca</first><last>Guita</last><affiliation>HLT Research Center</affiliation></author>
      <pages>316-324</pages>
      <abstract>In this paper we build a dataset of Italian syllables. We perform quantitative and qualitative analyses on the syllabification and stress assignment in Italian. We propose a machine learning model, based on deep-learning techniques, for automatically inferring syllabification and stress assignment. For stress prediction we report 94.45% word-level accuracy, and for syllabification we report 98.41% word-level accuracy and 99.82% hyphen-level accuracy.</abstract>
      <url hash="3587b498">2024.clicit-1.38</url>
      <bibkey>dinu-etal-2024-itgrasyll</bibkey>
    </paper>
    <paper id="39">
      <title>Generation and Evaluation of <fixed-case>E</fixed-case>nglish Grammar Multiple-Choice Cloze Exercises</title>
      <author><first>Nicolò</first><last>Donati</last><affiliation>University of Bologna at Bologna DISI Department</affiliation></author>
      <author><first>Matteo</first><last>Periani</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Paolo</first><last>Di Natale</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Giuseppe</first><last>Savino</last><affiliation>Zanichelli editore</affiliation></author>
      <author><first>Paolo</first><last>Torroni</last><affiliation>University of Bologna DISI Department</affiliation></author>
      <pages>325-334</pages>
      <abstract>English grammar Multiple-Choice Cloze (MCC) exercises are crucial for improving learners’ grammatical proficiency andcomprehension skills. However, creating these exercises is labour-intensive and requires expert knowledge. Effective MCCexercises must be contextually relevant and engaging, incorporating distractors—plausible but incorrect alternatives—tobalance difficulty and maintain learner motivation. Despite the increasing interest in utilizing large language models (LLMs)in education, their application in generating English grammar MCC exercises is still limited. Previous methods typicallyimpose constraints on LLMs, producing grammatically correct yet uncreative results. This paper explores the potentialof LLMs to independently generate diverse and contextually relevant MCC exercises without predefined limitations. Wehypothesize that LLMs can craft self-contained sentences that foster learner’s communicative competence. Our analysisof existing MCC exercise datasets revealed issues of diversity, completeness, and correctness. Furthermore, we addressthe lack of a standardized automatic metric for evaluating the quality of generated exercises. Our contributions includedeveloping an LLM-based solution for generating MCC exercises, curating a comprehensive dataset spanning 19 grammartopics, and proposing an automatic metric validated against human expert evaluations. This work aims to advance theautomatic generation of English grammar MCC exercises, enhancing both their quality and creativity.</abstract>
      <url hash="ec71b78f">2024.clicit-1.39</url>
      <bibkey>donati-etal-2024-generation</bibkey>
    </paper>
    <paper id="40">
      <title><fixed-case>R</fixed-case>e<fixed-case>CLAIM</fixed-case> Project: Exploring <fixed-case>I</fixed-case>talian Slurs Reappropriation with Large Language Models</title>
      <author><first>Lia</first><last>Draetta</last><affiliation>University of Turin</affiliation></author>
      <author><first>Chiara</first><last>Ferrando</last><affiliation>Università di Torino</affiliation></author>
      <author><first>Marco</first><last>Cuccarini</last><affiliation>Univeristy of Naples Federico II and University of Perugia</affiliation></author>
      <author><first>Liam</first><last>James</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Viviana</first><last>Patti</last><affiliation>University of Turin, Dipartimento di Informatica</affiliation></author>
      <pages>335-342</pages>
      <abstract>Recently, social networks have become the primary means of communication for many people, leading computational linguistics researchers to focus on the language used on these platforms. As online interactions grow, recognizing and preventing offensive messages targeting various groups has become urgent. However, finding a balance between detecting hate speech and preserving free expression while promoting inclusive language is challenging. Previous studies have highlighted the risks of automated analysis misinterpreting context, which can lead to the censorship of marginalized groups. Our study is the first to explore the reappropriative use of slurs in Italian by leveraging Large Language Models (LLMs) witha zero-shot approach. We revised annotations of an existing Italian homotransphobic dataset, developed new guidelines, and designed various prompts to address the LLMs task. Our findings illustrate the difficulty of this challenge and provide preliminary results on using LLMs for such a language specific task.</abstract>
      <url hash="7fe6a65b">2024.clicit-1.40</url>
      <bibkey>draetta-etal-2024-reclaim</bibkey>
    </paper>
    <paper id="41">
      <title>You Write like a <fixed-case>GPT</fixed-case></title>
      <author><first>Andrea</first><last>Esuli</last><affiliation>ISTI-CNR</affiliation></author>
      <author><first>Fabrizio</first><last>Falchi</last><affiliation>ISTI-CNR</affiliation></author>
      <author><first>Marco</first><last>Malvaldi</last><affiliation>Independent Researcher</affiliation></author>
      <author><first>Giovanni</first><last>Puccetti</last><affiliation>information Science and Technologies Institute “A. Faedo”</affiliation></author>
      <pages>343-348</pages>
      <abstract>We investigate how Raymond Queneau’s Exercises in Style are evaluated by automatic methods for detection of artificially-generated text. We work with the Queneau’s original French version, the Italian translation by Umberto Eco andthe English translation by Barbara Wright.We start by comparing how various methods for the detection of automatically generated text, also using different large language models and evaluate the different styles in the opera. We then link this automatic evaluation to distinct characteristic related to content and structure of the various styles.This work is an initial attempt at exploring how methods for detection artificially-generated text can find application as tools to evaluate the qualities and characteristics of human writing, to support better writing in terms of originality, informativeness, clarity.</abstract>
      <url hash="ef5da53a">2024.clicit-1.41</url>
      <bibkey>esuli-etal-2024-write</bibkey>
    </paper>
    <paper id="42">
      <title>Constructing a Multimodal, Multilingual Translation and Interpreting Corpus: A Modular Pipeline and an Evaluation of <fixed-case>ASR</fixed-case> for Verbatim Transcription</title>
      <author><first>Alice</first><last>Fedotova</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Adriano</first><last>Ferraresi</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Maja</first><last>Miličević Petrović</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Alberto</first><last>Barrón-Cedeño</last><affiliation>Università di Bologna</affiliation></author>
      <pages>349-355</pages>
      <abstract>This paper presents a novel pipeline for constructing multimodal and multilingual parallel corpora, with a focus on evaluating state-of-the-art ASR tools for verbatim transcription. Our findings indicate that current technologies can streamline corpus construction, with fine-tuning showing promising results in terms of transcription quality compared to out-of-the-box Whisper models. The lowest overall WER achieved for English was 0.180, using a fine-tuned Whisper-small model. As for Italian, the fine-tuned Whisper-small model obtained a lower WER of 0.201 compared to the baseline Whisper-small’s WER of 0.219. While limitations remain, the updated pipeline is expected to drastically reduce the human efforts involved.</abstract>
      <url hash="cd0e68f2">2024.clicit-1.42</url>
      <bibkey>fedotova-etal-2024-constructing</bibkey>
    </paper>
    <paper id="43">
      <title>Exploring <fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube Comments Reacting to Femicide News in <fixed-case>I</fixed-case>talian</title>
      <author><first>Chiara</first><last>Ferrando</last><affiliation>Università di Torino</affiliation></author>
      <author><first>Marco</first><last>Madeddu</last><affiliation>University of Turin</affiliation></author>
      <author><first>Viviana</first><last>Patti</last><affiliation>University of Turin, Dipartimento di Informatica</affiliation></author>
      <author><first>Mirko</first><last>Lai</last><affiliation>Università degli Studi di Torino</affiliation></author>
      <author><first>Sveva</first><last>Pasini</last><affiliation>Università di Pavia</affiliation></author>
      <author><first>Giulia</first><last>Telari</last><affiliation>University of Pavia</affiliation></author>
      <author><first>Beatrice</first><last>Antola</last><affiliation>University of Padova</affiliation></author>
      <pages>356-365</pages>
      <abstract>In recent years, the Gender Based Violence (GBV) has become an important issue in modern society and a central topic in different research areas due to its alarming spread. Several Natural Language Processing (NLP) studies, concerning Hate Speech directed against women, have focused on slurs or incel communities. The main contribution of our work is the creation of the first dataset on social media comments to GBV, in particular to a femicide event. Our dataset, named GBV-Maltesi, contains 2,934 YouTube comments annotated following a new schema that we developed in order to study GBV and misogyny with an intersectional approach. During the experimental phase, we trained models on different corpora for binary misogyny detection and found that datasets that mostly include explicit expressions of misogyny are an easier challenge, compared to more implicit forms of misogyny contained in GVB-Maltesi.</abstract>
      <url hash="31de38dc">2024.clicit-1.43</url>
      <bibkey>ferrando-etal-2024-exploring</bibkey>
    </paper>
    <paper id="44">
      <title>Automatic Error Detection: Comparing <fixed-case>AI</fixed-case> vs. Human Performance on <fixed-case>L</fixed-case>2 <fixed-case>I</fixed-case>talian Texts</title>
      <author><first>Irene</first><last>Fioravanti</last><affiliation>University for Foreigners of Perugia</affiliation></author>
      <author><first>Luciana</first><last>Forti</last><affiliation>University for Foreigners of Perugia</affiliation></author>
      <author><first>Stefania</first><last>Spina</last><affiliation>University for Foreigners of Perugia</affiliation></author>
      <pages>366-372</pages>
      <abstract>This paper reports on a study aimed at comparing AI vs. human performance in detecting and categorising errors in L2 Italian texts. Four LLMs were considered: ChatGPT, Copilot, Gemini and Llama3. Two groups of human annotators were involved: L1 and L2 speakers of Italian. A gold standard set of annotations was developed. A fine-grained annotation scheme was adopted, to reflect the specific traits of Italian morphosyntax, with related potential learner errors. Overall, we found that human annotation outperforms AI, with some degree of variation with respect tospecific error types. An increased attention to languages other than English in NLP may significantly improve AI performance in this pivotal task for the many domains of language-related disciplines.</abstract>
      <url hash="d9174c99">2024.clicit-1.44</url>
      <bibkey>fioravanti-etal-2024-automatic</bibkey>
    </paper>
    <paper id="45">
      <title>Explainability for Speech Models: On the Challenges of Acoustic Feature Selection</title>
      <author><first>Dennis</first><last>Fucci</last><affiliation>Fondazione Bruno Kessler, University of Trento</affiliation></author>
      <author><first>Beatrice</first><last>Savoldi</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Marco</first><last>Gaido</last><affiliation>Fondazione Bruno Kessler, University of Trento</affiliation></author>
      <author><first>Matteo</first><last>Negri</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Mauro</first><last>Cettolo</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Luisa</first><last>Bentivogli</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <pages>373-381</pages>
      <abstract>Spurred by the demand for transparency and interpretability in Artificial Intelligence (AI), the field of eXplainable AI (XAI) has experienced significant growth, marked by both theoretical reflections and technical advancements. While various XAI techniques, especially feature attribution methods, have been extensively explored across diverse tasks, their adaptation for the speech modality is lagging behind. We argue that a key factor hindering the diffusion of such methods in speech processing research lies in the complexity of defining interpretable acoustic features. In this paper, we discuss the key challenges in selecting the features for speech explanations. Also in light of existing research, we highlight current gaps and propose future avenues to enhance the depth and informativeness of explanations for speech.</abstract>
      <url hash="d772e2c2">2024.clicit-1.45</url>
      <bibkey>fucci-etal-2024-explainability</bibkey>
    </paper>
    <paper id="46">
      <title>Recurrent Networks Are (Linguistically) Better? An (Ongoing) Experiment on Small-<fixed-case>LM</fixed-case> Training on Child-Directed Speech in <fixed-case>I</fixed-case>talian</title>
      <author><first>Achille</first><last>Fusco</last><affiliation>IUSS Pavia</affiliation></author>
      <author><first>Matilde</first><last>Barbini</last><affiliation>IUSS Pavia</affiliation></author>
      <author><first>Maria Letizia</first><last>Piccini Bianchessi</last><affiliation>IUSS Pavia</affiliation></author>
      <author><first>Veronica</first><last>Bressan</last><affiliation>IUSS Pavia</affiliation></author>
      <author><first>Sofia</first><last>Neri</last><affiliation>IUSS Pavia</affiliation></author>
      <author><first>Sarah</first><last>Rossi</last><affiliation>IUSS Pavia</affiliation></author>
      <author><first>Tommaso</first><last>Sgrizzi</last><affiliation>IUSS Pavia</affiliation></author>
      <author><first>Cristiano</first><last>Chesi</last><affiliation>IUSS Pavia</affiliation></author>
      <pages>382-389</pages>
      <abstract>We discuss the strategies and results of a small-sized training program based on Italian child-directed speech (less than 3M tokens) for various network architectures. The rationale behind these experiments [1] lies in the attempt to understand the effect of this naturalistic training diet on different models architecture. Preliminary findings lead us to conclude that (a) different tokenization strategies produce only numerical, but not statistically significant, improvements overall, although segmentation aligns more or less with linguistic intuitions; and (b) modified LSTM networks with a single layer and a structurally more controlled cell state perform worse in training (compared to standard one- and two-layered LSTM models) but better on linguistically critical contrasts. This suggests that standard loss/accuracy metrics in autoregressive training procedures are linguistically irrelevant and, more generally, misleading, since the best-trained models qualify as poorer “linguistic theories” ([2], pace [3]).</abstract>
      <url hash="10b5dcaa">2024.clicit-1.46</url>
      <bibkey>fusco-etal-2024-recurrent</bibkey>
    </paper>
    <paper id="47">
      <title>On Cross-Language Entity Label Projection and Recognition</title>
      <author><first>Paolo</first><last>Gajo</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Alberto</first><last>Barrón-Cedeño</last><affiliation>Università di Bologna</affiliation></author>
      <pages>390-402</pages>
      <abstract>Most work on named entity recognition (NER) focuses solely on English. Through the use of training data augmentation via machine translation (MT), multilingual NER can become a powerful tool for information extraction in multilingual contexts. In this paper, we augment NER data from culinary recipe ingredient lists, by means of MT and word alignment (WA), following two approaches: (i) translating each entity separately, while taking into account the full context of the list and (ii) translating the whole list of ingredients and then aligning entities using three types of WA models: Giza++, Fast Align, and BERT, fine-tuned using a novel entity-shuffling approach. We depart from English data and produce Italian versions via MT, span-annotated with the entities projected from English. Then, we use the data produced by the two approaches to train mono- and multilingual NER BERT models. We test the performance of the WA and NER models on an annotated dataset of ingredient lists, partially out-of-domain compared to the training data. The results show that shuffling entities leads to better BERT aligner models. The higher quality NER data created by these models enables NER models to achieve better results, with multilingual models reaching performances equal to or greater than their monolingual counterparts.</abstract>
      <url hash="28ae7c8c">2024.clicit-1.47</url>
      <bibkey>gajo-barron-cedeno-2024-cross</bibkey>
    </paper>
    <paper id="48">
      <title><fixed-case>NYTAC</fixed-case>-<fixed-case>CC</fixed-case>: A Climate Change Subcorpus of <fixed-case>N</fixed-case>ew <fixed-case>Y</fixed-case>ork <fixed-case>T</fixed-case>imes Articles</title>
      <author><first>Francesca</first><last>Grasso</last><affiliation>University of Turin</affiliation></author>
      <author><first>Ronny</first><last>Patz</last><affiliation>University of Potsdam</affiliation></author>
      <author><first>Manfred</first><last>Stede</last><affiliation>University of Potsdam</affiliation></author>
      <pages>403-409</pages>
      <abstract>Over the past decade, the analysis of discourses on climate change (CC) has gained increased interest within the social sciences and the NLP community. Textual resources are crucial for understanding how narratives about this phenomenon are crafted and delivered. However, there still is a scarcity of datasets that cover CC in news media in a representative way. This paper presents a CC-specific subcorpus extracted from the 1.8 million New York Times Annotated Corpus, marking the first CC analysis on this data. The subcorpus was created by combining different methods for text selection to ensure representativeness and reliability, which is further validated using ClimateBERT. To provide initial insights into the CC subcorpus, we discuss the results of a topic modeling experiment (LDA). These show the diversity of contexts in which CC is discussed in news media over time, which is relevant for various downstream tasks.</abstract>
      <url hash="a5c55c57">2024.clicit-1.48</url>
      <bibkey>grasso-etal-2024-nytac</bibkey>
    </paper>
    <paper id="49">
      <title>Task-Incremental Learning on Long Text Sequences</title>
      <author><first>Natalia</first><last>Graziuso</last><affiliation>University of Siena</affiliation></author>
      <author><first>Andrea</first><last>Zugarini</last><affiliation>Expert.ai</affiliation></author>
      <author><first>Stefano</first><last>Melacci</last><affiliation>University of Siena</affiliation></author>
      <pages>410-416</pages>
      <abstract>The extraordinary results achieved by Large Language Models are paired with issues that are critical in real-world applications. The costs of inference and, in particular, training are extremely large, both in terms of time and computational resources, and they become prohibitive when working in dynamic environments, where data and tasks are progressively provided over time. The model must be able to adapt to new knowledge, new domains, new settings, without forgetting the previously learned skills. Retraining from scratch easily becomes too costly, thus Continual Learning strategies are of crucial importance. This is even more evident when data consist of “long” documents, that require several resources to be processed by modern neural models, leading to very long prompts. This paper investigates LLM-based Task-Incremental Learning in the case of tasks exploiting long sequences of text, as it is typical in summarization, question-answering on long documents, reviewing long contracts, and several others. We show how adapting the model by Task Arithmetic with LoRA, which was proposed for visual data, yields promising results also in the case of such “long” text data. To our best knowledge, this is the first work along this challenging direction. The outcome of the investigation of this paper is generic enough to represent an important starting point for further research in processing linguistic data in every language.</abstract>
      <url hash="91cc2382">2024.clicit-1.49</url>
      <bibkey>graziuso-etal-2024-task</bibkey>
    </paper>
    <paper id="50">
      <title>The Vulnerable Identities Recognition Corpus (<fixed-case>VIRC</fixed-case>) for Hate Speech Analysis</title>
      <author><first>Ibai</first><last>Guillén-Pacho</last><affiliation>Universidad Politécnica de Madrid</affiliation></author>
      <author><first>Arianna</first><last>Longo</last><affiliation>University of Turin, Italy</affiliation></author>
      <author><first>Marco Antonio</first><last>Stranisci</last><affiliation>University of Turin</affiliation></author>
      <author><first>Viviana</first><last>Patti</last><affiliation>University of Turin, Dipartimento di Informatica</affiliation></author>
      <author><first>Carlos</first><last>Badenes-Olmedo</last><affiliation>Universidad Politecnica de Madrid</affiliation></author>
      <pages>417-424</pages>
      <abstract>This paper presents the Vulnerable Identities Recognition Corpus (VIRC), a novel resource designed to enhance hate speech analysis in Italian and Spanish news headlines. VIRC comprises 921 headlines, manually annotated for vulnerable identities, dangerous discourse, derogatory expressions, and entities. Our experiments reveal that large language models (LLMs) struggle significantly with the fine-grained identification of these elements, underscoring the complexity of detecting hate speech. VIRC stands out as the first resource of its kind in these languages, offering a richer annotation schema compared to existing corpora. The insights derived from VIRC can inform the development of sophisticated detection tools and the creation of policies and regulations to combat hate speech on social media, promoting a safer online environment. Future work will focus on expanding the corpus and refining annotation guidelines to further enhance its comprehensiveness and reliability.</abstract>
      <url hash="36787064">2024.clicit-1.50</url>
      <bibkey>guillen-pacho-etal-2024-vulnerable</bibkey>
    </paper>
    <paper id="51">
      <title>The Self-Contained <fixed-case>I</fixed-case>talian Negation Test (<fixed-case>SCIN</fixed-case>)</title>
      <author><first>Viola</first><last>Gullace</last><affiliation>Scuola Normale Superiore, Università di Pisa</affiliation></author>
      <author><first>David</first><last>Kletz</last><affiliation>Sorbonne-Nouvelle, Universite Paris Cite</affiliation></author>
      <author><first>Thierry</first><last>Poibeau</last><affiliation>LATTICE (CNRS &amp; ENS/PSL)</affiliation></author>
      <author><first>Alessandro</first><last>Lenci</last><affiliation>University of Pisa</affiliation></author>
      <author><first>Pascal</first><last>Amsili</last><affiliation>Université Sorbonne Nouvelle - Paris 3</affiliation></author>
      <pages>425-430</pages>
      <abstract>Recent research has focused extensively on state-of-the-art pretrained language models, particularly those based on Transformer architectures, and how well they account for negation and other linguistic phenomena in various tasks. This study aims to evaluate the understanding of negation in Italian bert- and roberta-based models, contrasting the predominant English-focused prior research. We develop the SCIN Set, an Italian dataset designed to model the influence of polarity constraints on models in a masked predictions task. Applying the SCIN Set reveals that these models do not adjust their behaviour based on sentences polarity, even when the resulting sentence is contradictory. We conclude that the tested models lack a clear understanding of how negation alters sentence meaning.</abstract>
      <url hash="b69c38d0">2024.clicit-1.51</url>
      <bibkey>gullace-etal-2024-self</bibkey>
    </paper>
    <paper id="52">
      <title>La Non Canonica L’hai Studiata? Exploring <fixed-case>LLM</fixed-case>s and Sentence Canonicity in <fixed-case>I</fixed-case>talian</title>
      <author><first>Claudiu</first><last>Hromei</last><affiliation>Department of Enterprise Engineering University of Rome, Tor Vergata, Italy</affiliation></author>
      <author><first>Danilo</first><last>Croce</last><affiliation>University of Roma, Tor Vergata</affiliation></author>
      <author><first>Rodolfo</first><last>Delmonte</last><affiliation>Ca’ Foscari University Venice now retired</affiliation></author>
      <author><first>Roberto</first><last>Basili</last><affiliation>University of Roma, Tor Vergata</affiliation></author>
      <pages>431-439</pages>
      <abstract>This paper investigates the ability of Large Language Models (LLMs) to differentiate between canonical and non-canonical sentences in Italian, employing advanced neural architectures like LLaMA and its adaptations. Canonical sentences adhere to the standard Subject-Verb-Object (SVO) structure. We hypothesize that recent generative LLMs are influenced heavily by the English language, where non-canonical structures are very rare. Using the in-context learning technique, we probe these models and further fine-tune them for this specific task. Initial results indicate that these models continue to struggle with this task even after fine-tuning. Additionally, we introduce a new dataset comprising several hundred sentences from the poetry domain, which presents significant challenges for the canonical structure task.</abstract>
      <url hash="90804877">2024.clicit-1.52</url>
      <bibkey>hromei-etal-2024-la</bibkey>
    </paper>
    <paper id="53">
      <title>Enhancing Job Posting Classification with Multilingual Embeddings and Large Language Models</title>
      <author><first>Hamit</first><last>Kavas</last><affiliation>Pompeu Fabra University</affiliation></author>
      <author><first>Marc</first><last>Serra-Vidal</last><affiliation>Adevinta Spain</affiliation></author>
      <author><first>Leo</first><last>Wanner</last><affiliation>ICREA and Pompeu Fabra University</affiliation></author>
      <pages>440-450</pages>
      <abstract>In the modern labour market, taxonomies such the European Skills, Competences, Qualifications and Occupations (ESCO) classification are used as an interlingua to match job postings with job seeker profiles. Both are classified with respect to ESCO occupations, and match if they align with the same occupation and the same skills assigned to the occupation. However, matching models usually struggle with the classification because of overlapping skills and similar definitions of occupations defined in the ESCO taxonomy. This often leads to imprecise classification outcomes. In this paper, we focus on the challenge of the classification of job postings written in Italian or Spanish against ESCO occupations written in English. We experiment with multilingual embeddings, zero-shot classification, and use of a large language model (LLM) and show that the use of an LLM leads to best results.</abstract>
      <url hash="922b3568">2024.clicit-1.53</url>
      <bibkey>kavas-etal-2024-enhancing</bibkey>
    </paper>
    <paper id="54">
      <title>Divergent Discourses: A Comparative Examination of Blackout <fixed-case>T</fixed-case>uesday and #<fixed-case>B</fixed-case>lack<fixed-case>L</fixed-case>ives<fixed-case>M</fixed-case>atter on <fixed-case>I</fixed-case>nstagram</title>
      <author><first>Aenne</first><last>Knierim</last><affiliation>Universität Hildesheim</affiliation></author>
      <author><first>Michael</first><last>Achmann-Denkler</last><affiliation>Universität Regensburg</affiliation></author>
      <author><first>Ulrich</first><last>Heid</last><affiliation>Universität Hildesheim</affiliation></author>
      <author><first>Christian</first><last>Wolff</last><affiliation>Universität Regensburg</affiliation></author>
      <pages>451-458</pages>
      <abstract>On May 25th, 2020, a viral eleven-minute clip showing the murder of George Floyd sparked international outrage and solidarity, leading to the digital memorial event Blackout Tuesday on Instagram. We analyzed posts to compare Blackout Tuesday discourse with #blacklivesmatter movement conversations. Using topic modeling, we identified dominant themes and counter-narratives in Blackout Tuesday and #blacklivesmatter captions. Using hashtag co-occurrence analysis, we investigatehashtag networks to situate the discourses within spheres of Instagram activism. Our findings indicate that both corpora share themes like “calls to action”, but Blackout Tuesday posts are shorter and solidarity-focused, while #blacklivesmatter posts are longer and address white privilege more explicitly. #blacklivesmatter is linked to anti-racist activism hashtags, while Blackout Tuesday connects more with popular culture and #Alllivesmatter. This supports qualitative research on Blackout Tuesday’s performative allyship, adding a quantitative perspective to the field.</abstract>
      <url hash="f274be8a">2024.clicit-1.54</url>
      <bibkey>knierim-etal-2024-divergent</bibkey>
    </paper>
    <paper id="55">
      <title><fixed-case>THAVQA</fixed-case>: A <fixed-case>G</fixed-case>erman Task-oriented <fixed-case>VQA</fixed-case> Dataset Annotated with Human Visual Attention</title>
      <author><first>Moritz</first><last>Kronberger</last><affiliation>Technische Hochschule Augsburg, An der Hochschule 1, 86161 Augsburg, Germany</affiliation></author>
      <author><first>Viviana</first><last>Ventura</last><affiliation>Technische Hochschule Augsburg</affiliation></author>
      <pages>459-469</pages>
      <abstract>Video question answering (VQA) is a challenging task that requires models to generate answers by using both information from text and video. We present Task-oriented Human Attention Video Question Answering (THAVQA), a new VQA dataset consisting of third- and first- person videos of an instructor using a sewing machine. The sewing task is formalized step-by-step in a script: each step consists of a video annotated with German language open-ended question and answer (QA) pairs and with human visual attention. The paper also includes a first assessment of the performance of a pre-trained Multimodal Large Language Model (MLLM) in generating answers to the questions of our dataset across different experimental settings.Results show that our task-oriented dataset is challenging for pre-trained models. Specifically, the model struggles to answer questions requiring technical knowledge or spatio-temporal reasoning.</abstract>
      <url hash="f1d2c195">2024.clicit-1.55</url>
      <bibkey>kronberger-ventura-2024-thavqa</bibkey>
    </paper>
    <paper id="56">
      <title>Are You a Good Assistant? Assessing <fixed-case>LLM</fixed-case> Trustability in Task-oriented Dialogues</title>
      <author><first>Tiziano</first><last>Labruna</last><affiliation>Fondazione Bruno Kessler and Free University of Bozen-Bolzano</affiliation></author>
      <author><first>Sofia</first><last>Brenna</last><affiliation>FBK, Unibz</affiliation></author>
      <author><first>Giovanni</first><last>Bonetta</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Bernardo</first><last>Magnini</last><affiliation>FBK</affiliation></author>
      <pages>470-477</pages>
      <abstract>Despite the impressive capabilities of recent Large Language Models (LLMs) to generate human-like text, their ability to produce contextually appropriate content for specific communicative situations is still a matter of debate. This issue is particularly crucial when LLMs are employed as assistants to help solve tasks or achieve goals within a given conversational domain. In such scenarios, the assistant is expected to access specific knowledge (e.g., a database of restaurants, a calendar of appointments) that is not directly accessible to the user and must be consistently utilised to accomplish the task.In this paper, we conduct experiments to evaluate the trustworthiness of automatic assistants in task-oriented dialogues. Our findings indicate that state-of-the-art open-source LLMs still face significant challenges in maintaining logical consistency with a knowledge base of facts, highlighting the need for further advancements in this area.</abstract>
      <url hash="fe98c358">2024.clicit-1.56</url>
      <bibkey>labruna-etal-2024-good</bibkey>
    </paper>
    <paper id="57">
      <title>Comparative Evaluation of Computational Models Predicting Eye Fixation Patterns During Reading: Insights from Transformers and Simpler Architectures</title>
      <author><first>Alessandro</first><last>Lento</last><affiliation>Università Campus Bio-Medico, Roma, Italy</affiliation></author>
      <author><first>Andrea</first><last>Nadalini</last><affiliation>Consiglio Nazionale delle Ricerche, Istituto di Linguistica Computazionale “A. Zampolli”, Pisa, Italy</affiliation></author>
      <author><first>Nadia</first><last>Khlif</last><affiliation>Consiglio Nazionale delle Ricerche, Istituto di Linguistica Computazionale “A. Zampolli”, Pisa, Italy</affiliation></author>
      <author><first>Vito</first><last>Pirrelli</last><affiliation>ILC - CNR Pisa</affiliation></author>
      <author><first>Claudia</first><last>Marzi</last><affiliation>Institute for Computational Linguistics - CNR</affiliation></author>
      <author><first>Marcello</first><last>Ferro</last><affiliation>Istituto di Linguistica Computazionale (ILC), CNR, Pisa</affiliation></author>
      <pages>478-487</pages>
      <abstract>Eye tracking data during reading provides significant insights into the cognitive processes underlying language comprehension. It allows for the estimation of lexical, contextual, and higher-level structural effects on word identification through metrics such as fixation duration. Despite advancements in psycholinguistic experiments that have elucidated these effects, the extent to which computational models can predict gaze patterns remains unclear. Recent developments in computational modeling, particularly the use of pre-trained transformer language models, have shown promising results in mirroring human reading behaviors. However, previous studies have not adequately compared these models to alternative architectures or considered various input features comprehensively. This paper addresses these gaps by replicating prior findings on English data, critically evaluating performance metrics, and proposing a stricter accuracy measurement method. Furthermore, it compares different computational models, demonstrating that simpler architectures can achieve results comparable to or better than transformers. The study also emphasizes the significance of individual differences in reading behavior, presenting challenges for simulating natural reading tasks.</abstract>
      <url hash="254a5663">2024.clicit-1.57</url>
      <bibkey>lento-etal-2024-comparative</bibkey>
    </paper>
    <paper id="58">
      <title><fixed-case>H</fixed-case>its or Misses? A Linguistically Explainable Formula for Fanfiction Success</title>
      <author><first>Giulio</first><last>Leonardi</last><affiliation>Università di Pisa</affiliation></author>
      <author><first>Dominique</first><last>Brunato</last><affiliation>Institute of Computational Linguistics “A. Zampolli” (ILC-CNR), Pisa</affiliation></author>
      <author><first>Felice</first><last>Dell’orletta</last><affiliation>ItaliaNLP Lab @ Institute for Computational Linguistics “Antonio Zampolli”, ILC - CNR</affiliation></author>
      <pages>488-495</pages>
      <abstract>This study presents a computational analysis of Italian fanfiction, aiming to construct an interpretable model of successful writing within this emerging literary domain. Leveraging explicit features that capture both linguistic style and semantic content, we demonstrate the feasibility of automatically predicting successful writing in fanfiction and we identify a set of robust linguistic predictors that maintain their predictive power across diverse topics and time periods, offering insights into the universal aspects of engaging storytelling. This approach not only enhances our understanding of fanfiction as a genre but also offers potential applications in broader literary analysis and content creation.</abstract>
      <url hash="f8062b58">2024.clicit-1.58</url>
      <bibkey>leonardi-etal-2024-hits</bibkey>
    </paper>
    <paper id="59">
      <title>A Novel Multi-Step Prompt Approach for <fixed-case>LLM</fixed-case>-based <fixed-case>Q</fixed-case>&amp;As on Banking Supervisory Regulation</title>
      <author><first>Daniele</first><last>Licari</last><affiliation>Banca d’Italia</affiliation></author>
      <author><first>Canio</first><last>Benedetto</last><affiliation>Banca d’Italia</affiliation></author>
      <author><first>Praveen</first><last>Bushipaka</last><affiliation>Scuola Superiore Sant’Anna</affiliation></author>
      <author><first>Alessandro</first><last>De Gregorio</last><affiliation>Banca d’Italia</affiliation></author>
      <author><first>Marco</first><last>De Leonardis</last><affiliation>Banca d’Italia</affiliation></author>
      <author><first>Tommaso</first><last>Cucinotta</last><affiliation>Scuola Superiore Sant’Anna</affiliation></author>
      <pages>496-509</pages>
      <abstract>This paper investigates the use of large language models (LLMs) in analyzing and answering questions related to banking supervisory regulation concerning reporting obligations. We introduce a multi-step prompt construction method that enhances the context provided to the LLM, resulting in more precise and informative answers. This multi-step approach is compared with a standard “zero-shot” approach, which lacks context enrichment. To assess the quality of the generated responses, we utilize an LLM Evaluator. Our findings indicate that the multi-step approach significantly outperforms the zero-shot method, producing more comprehensive and accurate responses.</abstract>
      <url hash="2222233d">2024.clicit-1.59</url>
      <bibkey>licari-etal-2024-novel</bibkey>
    </paper>
    <paper id="60">
      <title>Lupus Alberto: A Transformer-Based Approach for <fixed-case>SLE</fixed-case> Information Extraction from <fixed-case>I</fixed-case>talian Clinical Reports</title>
      <author><first>Livia</first><last>Lilli</last><affiliation>Università Cattolica del Sacro Cuore</affiliation></author>
      <author><first>Laura</first><last>Antenucci</last><affiliation>Università Cattolica del Sacro Cuore</affiliation></author>
      <author><first>Augusta</first><last>Ortolan</last><affiliation>Fondazione Policlinico Universitario A Gemelli IRCCS</affiliation></author>
      <author><first>Silvia Laura</first><last>Bosello</last><affiliation>Fondazione Policlinico Universitario A Gemelli IRCCS</affiliation></author>
      <author><first>Maria Antonietta</first><last>D’agostino</last><affiliation>Fondazione Policlinico Universitario A Gemelli IRCCS</affiliation></author>
      <author><first>Stefano</first><last>Patarnello</last><affiliation>Fondazione Policlinico Universitario A Gemelli IRCCS</affiliation></author>
      <author><first>Carlotta</first><last>Masciocchi</last><affiliation>Fondazione Policlinico Universitario A Gemelli IRCCS</affiliation></author>
      <author><first>Jacopo</first><last>Lenkowicz</last><affiliation>Fondazione Policlinico Universitario A Gemelli IRCCS</affiliation></author>
      <pages>510-516</pages>
      <abstract>Natural Language Processing (NLP) is widely used across several fields, particularly in medicine, where information often originates from unstructured data sources. This creates the need for automated systems, in order to classify text and extract information from Electronic Health Records (EHRs). However, a significant challenge lies in the limited availability of pre-trained models for less common languages, such as Italian, and for specific medical domains.Our study aims to develop an NLP approach to extract Systemic Lupus Erythematosus (SLE) information from Italian EHRs at Gemelli Hospital in Rome. We then introduce Lupus Alberto, a fine-tuned version of AlBERTo, trained for classifying categories derived from three distinct domains: Diagnosis, Therapy and Symptom. We evaluated Lupus Alberto’s performance by comparing it with other baseline approaches, selecting from available BERT-based models for the Italian language and fine-tuning them for the same tasks.Evaluation results show that Lupus Alberto achieves overall F-Scores equal to 79%, 87%, and 76% for the Diagnosis, Therapy, and Symptom domains, respectively. Furthermore, our approach outperformed other baseline models in the Diagnosis and Symptom domains, demonstrating superior performance in identifying and categorizing relevant SLE information, thereby improving clinical decision-making and patient management.</abstract>
      <url hash="cf96924e">2024.clicit-1.60</url>
      <bibkey>lilli-etal-2024-lupus</bibkey>
    </paper>
    <paper id="61">
      <title>The Lemma Bank of the <fixed-case>L</fixed-case>i<fixed-case>ITA</fixed-case> Knowledge Base of Interoperable Resources for <fixed-case>I</fixed-case>talian</title>
      <author><first>Eleonora</first><last>Litta</last><affiliation>Università Cattolica del Sacro Cuore, Milano</affiliation></author>
      <author><first>Marco</first><last>Passarotti</last><affiliation>Università Cattolica del Sacro Cuore</affiliation></author>
      <author><first>Paolo</first><last>Brasolin</last><affiliation>Eurac Research</affiliation></author>
      <author><first>Giovanni</first><last>Moretti</last><affiliation>Università Cattolica del Sacro Cuore, Milano</affiliation></author>
      <author><first>Valerio</first><last>Basile</last><affiliation>University of Turin</affiliation></author>
      <author><first>Andrea</first><last>Di Fabio</last><affiliation>Università di Torino</affiliation></author>
      <author><first>Cristina</first><last>Bosco</last><affiliation>Dipartimento di Informatica - UniversitÃ di Torino</affiliation></author>
      <pages>517-522</pages>
      <abstract>The paper introduces the LiIta Knowledge Base of interoperable linguistic resources for Italian. After describing the principles of the Linked Data paradigm, on which LiIta is grounded, the paper presents the lemma-centred architecture of the Knowledge Base and details its core component, consisting of a large collection of Italian lemmas (called the Lemma Bank) used to interlink distributed lexical and textual resources.</abstract>
      <url hash="3e02eb97">2024.clicit-1.61</url>
      <bibkey>litta-etal-2024-lemma</bibkey>
    </paper>
    <paper id="62">
      <title>Multimodal Chain-of-Thought Prompting for Metaphor Generation</title>
      <author><first>Sofia</first><last>Lugli</last><affiliation>University of Trento</affiliation></author>
      <author><first>Carlo</first><last>Strapparava</last><affiliation>FBK-irst</affiliation></author>
      <pages>523-530</pages>
      <abstract>This paper introduces an exploratory approach in the field of metaphorical and visual reasoning by proposing the Multimodal Chain-of-Thought Prompting for Metaphor Generation task aimed to generate metaphorical linguistic expressions from non-metaphorical images by using the multimodal LLaVA 1.5 model and the two-step approach of multimodal chain-of- thought prompting. The generated metaphors were evaluated in two ways: using BERTscore and by five human workers on Amazon Mechanical Turk. Concerning the automatic evaluation, each generated metaphorical expression was paired with a corresponding human metaphorical expressions. The overall BERTscore was the following: precision= 0.41, recall= 0.43, and F1= 0.42, suggesting that generated and human metaphors might not have captured the same semantic meaning. The human evaluation showed the model’s ability to generate metaphorical expressions, as 92% of them were classified as metaphors by the majority of the workers. Additionally, the evaluation revealed interesting patterns in terms of metaphoricity, familiarity and appeal scores across the generated metaphors: as the metaphoricity and appeal scores increased, the familiarity score decreased, suggesting that the model exhibited a certain degree of creativity, as it has also generated novel or unconventional metaphorical expressions. It is important to acknowledge that this work is exploratory in nature and has certain limitations.</abstract>
      <url hash="b13bc0d7">2024.clicit-1.62</url>
      <bibkey>lugli-strapparava-2024-multimodal</bibkey>
    </paper>
    <paper id="63">
      <title>Leveraging Advanced Prompting Strategies in <fixed-case>LL</fixed-case>a<fixed-case>MA</fixed-case>3-8<fixed-case>B</fixed-case> for Enhanced Hyperpartisan News Detection</title>
      <author><first>Michele</first><last>Maggini</last><affiliation>Centro Singular de Investigación en Tecnoloxías Intelixentes da USC</affiliation></author>
      <author><first>Pablo</first><last>Gamallo Otero</last><affiliation>Centro Singular de Investigación en Tecnoloxías Intelixentes da USC</affiliation></author>
      <pages>531-539</pages>
      <abstract>This paper explores advanced prompting strategies for hyperpartisan news detection using the LLaMA3-8b-Instruct model, an open-source LLM developed by Meta AI. We evaluate zero-shot, few-shot, and Chain-of-Thought (CoT) techniques on two datasets: SemEval-2019 Task 4 and a headline-specific corpus. Collaborating with a political science expert, we incorporate domain-specific knowledge and structured reasoning steps into our prompts, particularly for the CoT approach. Our findings reveal that zero-shot prompting, especially with general prompts, consistently outperforms other techniques across both datasets. This unexpected result challenges assumptions about the superiority of few-shot and CoT methods in specialized tasks. We discuss the implications of these findings for ICL in political text analysis and suggest directions for future research in leveraging large language models for nuanced content classification tasks.</abstract>
      <url hash="2aa97239">2024.clicit-1.63</url>
      <bibkey>maggini-gamallo-otero-2024-leveraging</bibkey>
    </paper>
    <paper id="64">
      <title>Understanding High-complexity Technical Documents with State-of-Art Models</title>
      <author><first>Bernardo</first><last>Magnini</last><affiliation>FBK</affiliation></author>
      <author><first>Roberto</first><last>Zanoli</last><affiliation>Fondazione Bruno Kessler -FBK</affiliation></author>
      <pages>540-547</pages>
      <abstract>Technical documents, particularly those in civil engineering, contain crucial information that supports critical decision-making in construction, transportation and infrastructure projects. Large language models (LLMs) offer a promising solution for automating the extraction and comprehension of technical documents, potentially transforming our interaction with technical information. However, LLMs may encounter significant challenges when processing technical documents due to their complex structure, specialized terminology and reliance on graphical and visual elements. Moreover, LLMs are known to sometimes produce unexpected or incorrect analyses, a phenomenon referred to as hallucination.This study explores the potential of state-of-the-art LLMs, specifically GPT-4omni, to automate the comprehension of technical documents. The evaluation was performed on two types of PDF documents. The first type is selectable text PDFs, which are extractable and editable, focusing on civil engineering documents from the Italian state railways. The second type is scanned OCR PDFs, where text is derived from scanning or OCR, specifically focusing on the design of an outdoor swimming pool. These documents include textual and visual elements such as tables, figures and photos. Our findings suggest that GPT-4omni has a high potential for real-world use, although it may still be susceptible to producing misleading information.</abstract>
      <url hash="b49987e8">2024.clicit-1.64</url>
      <bibkey>magnini-zanoli-2024-understanding</bibkey>
    </paper>
    <paper id="65">
      <title>Temporal Word Embeddings in the Study of Metaphor Change over Time and across Genres: A Proof-of-concept Study on <fixed-case>E</fixed-case>nglish</title>
      <author><first>Veronica</first><last>Mangiaterra</last><affiliation>Laboratory of Neurolinguistics and Experimental Pragmatics (NEP), Department of Humanities and Life Sciences, University School for Advanced Studies IUSS, Pavia, Italy</affiliation></author>
      <author><first>Chiara</first><last>Barattieri Di San Pietro</last><affiliation>Laboratory of Neurolinguistics and Experimental Pragmatics (NEP), Department of Humanities and Life Sciences, University School for Advanced Studies IUSS, Pavia, Italy</affiliation></author>
      <author><first>Valentina</first><last>Bambini</last><affiliation>Laboratory of Neurolinguistics and Experimental Pragmatics (NEP), Department of Humanities and Life Sciences, University School for Advanced Studies IUSS, Pavia, Italy</affiliation></author>
      <pages>548-555</pages>
      <abstract>Temporal word embeddings have been successfully employed in semantic change research to identify and trace shifts in the meaning of words. In a previous work, we developed an approach to study the diachrony of complex expressions, namely literary metaphors extracted from Italian literary texts. Capitalizing on the evidence that measures of cosine similarity between the two terms of a metaphor approximate human judgments on the difficulty of the expression, we used time-locked measures of similarity to reconstruct the evolution of processing costs of literary metaphors over the past two centuries. In this work, we present a proof-of-concept study testing the crosslinguistic applicability of this approach on a set of 19th-century English literary metaphors. Our results show that metaphors changed as a function of textual genre but not of epoch: cosine similarity between the two terms of literary metaphors is higher in literary compared to nonliterary texts, and this difference is stable across epochs. We show that the difference between genres is affected by the frequency of the metaphor’s vehicle and the stability of the meaning of both topic and vehicle. Overall, the processing costs of English literary metaphors do not differin different time points, but are influenced by the textual genres of language. In a broader perspective, general considerations can be drawn about the history of literary and nonliterary English language and the semantic change of words</abstract>
      <url hash="166091dc">2024.clicit-1.65</url>
      <bibkey>mangiaterra-etal-2024-temporal</bibkey>
    </paper>
    <paper id="66">
      <title>Fine-grained Sexism Detection in <fixed-case>I</fixed-case>talian Newspapers</title>
      <author><first>Federica</first><last>Manzi</last><affiliation>Ludwig-Maximilians-University Munich (LMU University)</affiliation></author>
      <author><first>Leon</first><last>Weber-Genzel</last><affiliation>Ludwig-Maximilians-University Munich (LMU University)</affiliation></author>
      <author><first>Barbara</first><last>Plank</last><affiliation>Ludwig-Maximilians-University Munich (LMU University)</affiliation></author>
      <pages>556-583</pages>
      <abstract>In recent years, tasks revolving around hate speech detection have experienced a growing interest in the field of Natural Language Processing. Two main trends stand out in the context of sexism recognition: the focus on overt forms of sexism such as misogyny on social media and tackling the problem as a text classification task. The main objective of this work is to introduce a new approach to tackle sexism recognition as a sequence labelling task, operating on the token level rather than the document one. To achieve this goal, we introduce (i) the FGSDI (Fine-Grained Sexism Detection in Italian) corpus, containing Italian newspaper articles annotated with fine-grained linguistic markers of sexism, and (ii) a two-step pipeline that sequentially performs sexism detection on the sentence level and sexism classification on the token one. Our primary findings include that (i) tackling the task of sexism recognition as a sequence labelling task is possible, however, a large amount of labelled data is needed; (ii) leveraging few-shot learning for sexism detection proves to be an effective solution in scenarios where only a limited amount of data are available; (iii) the proposed pipeline approach allows for better results compared to the baseline by doubling the overall precision and achieving a better F1-score.</abstract>
      <url hash="2857038a">2024.clicit-1.66</url>
      <bibkey>manzi-etal-2024-fine</bibkey>
    </paper>
    <paper id="67">
      <title>Towards a More Comprehensive Evaluation for <fixed-case>I</fixed-case>talian <fixed-case>LLM</fixed-case>s</title>
      <author><first>Luca</first><last>Moroni</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Simone</first><last>Conia</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Federico</first><last>Martelli</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Roberto</first><last>Navigli</last><affiliation>Sapienza University of Rome</affiliation></author>
      <pages>584-599</pages>
      <abstract>Recent Large Language Models (LLMs) have shown impressive performance in addressing complex aspects of human language. These models have also demonstrated significant capabilities in processing and generating Italian text, achieving state-of-the-art results on current benchmarks for the Italian language. However, the number of such benchmarks is still insufficient. A case in point is the “Open Ita LLM Leaderboard” which only supports three benchmarks, despite being one of the most popular evaluation suite for the evaluation of Italian-speaking LLMs. In this paper, we analyze the current pitfalls of existing evaluation suites and propose two ways to this gap: i) a new suite of automatically-translated benchmarks, drawn from the most popular English benchmarks; and ii) the adaptation of existing manual dataset so that they can be used to complement the evaluation of Italian LLMs. We discuss the pros and cons of both approaches and release all our data to foster further research on the evaluation of Italian-speaking LLMs.</abstract>
      <url hash="ed909ef9">2024.clicit-1.67</url>
      <bibkey>moroni-etal-2024-towards</bibkey>
    </paper>
    <paper id="68">
      <title>A Study on the Soundness of Closed-ended Evaluation of Large Language Models Adapted to the <fixed-case>I</fixed-case>talian Language</title>
      <author><first>Elio</first><last>Musacchio</last><affiliation>University of Bari / University of Pisa</affiliation></author>
      <author><first>Lucia</first><last>Siciliani</last><affiliation>University of Bari Aldo Moro</affiliation></author>
      <author><first>Pierpaolo</first><last>Basile</last><affiliation>Department of Computer Science, University of Bari Aldo Moro</affiliation></author>
      <author><first>Edoardo</first><last>Michielon</last><affiliation>Fastweb SpA, Milan, Italy</affiliation></author>
      <author><first>Marco</first><last>Pasqualini</last><affiliation>Fastweb SpA, Milan, Italy</affiliation></author>
      <author><first>Asia Beatrice</first><last>Uboldi</last><affiliation>Fastweb SpA, Milan, Italy</affiliation></author>
      <author><first>Giovanni</first><last>Semeraro</last><affiliation>University of Bari “Aldo Moro”</affiliation></author>
      <pages>600-611</pages>
      <abstract>With the rising interest in Large Language Models, deep architectures capable of solving a wide range of Natural LanguageGeneration tasks, an increasing number of open weights architectures have been developed and released online. In contrastwith older architectures, which were aimed at solving specific linguistic assignments, Large Language Models have shownoutstanding capabilities in solving several tasks at once, raising the question of whether they can truly comprehend naturallanguage. Nevertheless, evaluating this kind of capability is far from easy. One of the proposed solutions so far is usingbenchmarks that combine various types of tasks. This approach is based on the premise that achieving good performance ineach of these individual tasks can imply having developed a model capable of understanding language. However, while thisassumption is not incorrect, it is evident that it is not sufficient, and the evaluation of Large Language Models still remains anopen challenge. In this paper, we conduct a study aimed at highlighting the potential and limitations of current datasets andhow a new evaluation setting applied to language-adapted Large Language Models may provide more insight than traditionalapproaches.</abstract>
      <url hash="a6a03f24">2024.clicit-1.68</url>
      <bibkey>musacchio-etal-2024-study</bibkey>
    </paper>
    <paper id="69">
      <title>Understanding the Future Green Workforce through a Corpus of Curricula Vitae from Recent Graduates</title>
      <author><first>Francesca</first><last>Nannetti</last><affiliation>University of Modena and Reggio Emilia</affiliation></author>
      <author><first>Matteo</first><last>Di Cristofaro</last><affiliation>University of Modena and Reggio Emilia</affiliation></author>
      <pages>612-619</pages>
      <abstract>In view of the much-heralded ecological transition, to stay competitive and participate in the collective effort to face global warming and climate change, organisations need to select employees interested in and able to develop environmentally sustainable and innovative ideas. The existing literature however does not present consistent nor concordant results on the effective interest, involvement and expertise of Generation Z members – namely, the newest entrants into the workforce – in green issues. The aim of this study is to explore the profile of the upcoming workforce expected to present itself to companies, and to support them in managing the green transition. With CVs as one of the first interfaces between candidate and company in the recruitment process, this study is based on a purpose-built corpus consisting of 8,096 Curricula Vitae from recent graduates of the University of Modena and Reggio Emilia. Data is investigated through a Corpus-Assisted Discourse Studies (CADS) framework, proposing a novel interaction between structured metadata and textual information. The original contribution of this approach lies in the extraction of information from the narrative structure of CVs which, guiding the evaluation and exploration of metadata, ensures that the knowledge value of the data can be explored in a discursive manner and not reduced to lists of competences and qualifications.</abstract>
      <url hash="71a58403">2024.clicit-1.69</url>
      <bibkey>nannetti-di-cristofaro-2024-understanding</bibkey>
    </paper>
    <paper id="70">
      <title>Exploring <fixed-case>I</fixed-case>talian Sentence Embeddings Properties through Multi-tasking</title>
      <author><first>Vivi</first><last>Nastase</last><affiliation>University of Geneva</affiliation></author>
      <author><first>Giuseppe</first><last>Samo</last><affiliation>University of Geneva</affiliation></author>
      <author><first>Chunyang</first><last>Jiang</last><affiliation>University of Geneva</affiliation></author>
      <author><first>Paola</first><last>Merlo</last><affiliation>University of Geneva</affiliation></author>
      <pages>620-630</pages>
      <abstract>We investigate to what degree existing LLMs encode abstract linguistic information in Italian in a multi-task setting. We exploit curated synthetic data on a large scale – several Blackbird Language Matrices (BLMs) problems in Italian – and use them to study how sentence representations built using pre-trained language models encode specific syntactic and semantic information. We use a two-level architecture to model separately a compression of the sentence embeddings into a representation that contains relevant information for a task, and a BLM task. We then investigate whether we can obtain compressed sentence representations that encode syntactic and semantic information relevant to several BLM tasks. While we expected that the sentence structure – in terms of sequence of phrases/chunks – and chunk properties could be shared across tasks, performance and error analysis show that the clues for the different tasks are encoded in different manners in the sentence embeddings, suggesting that abstract linguistic notions such as constituents or thematic roles does not seem to be present in the pretrained sentence embeddings.</abstract>
      <url hash="47d3d839">2024.clicit-1.70</url>
      <bibkey>nastase-etal-2024-exploring</bibkey>
    </paper>
    <paper id="71">
      <title>Exploring Syntactic Information in Sentence Embeddings through Multilingual Subject-verb Agreement</title>
      <author><first>Vivi</first><last>Nastase</last><affiliation>University of Geneva</affiliation></author>
      <author><first>Giuseppe</first><last>Samo</last><affiliation>University of Geneva</affiliation></author>
      <author><first>Chunyang</first><last>Jiang</last><affiliation>University of Geneva</affiliation></author>
      <author><first>Paola</first><last>Merlo</last><affiliation>University of Geneva</affiliation></author>
      <pages>631-643</pages>
      <abstract>In this paper, our goal is to investigate to what degree multilingual pretrained language models capture cross-linguistically valid abstract linguistic representations. We take the approach of developing curated synthetic data on a large scale, with specific properties, and using them to study sentence representations built using pretrained language models. We use a new multiple-choice task and datasets, Blackbird Language Matrices (BLMs), to focus on a specific grammatical structural phenomenon – subject-verb agreement across a variety of sentence structures – in several languages. Finding a solution to this task requires a system detecting complex linguistic patterns and paradigms in text representations. Using a two-level architecture that solves the problem in two steps – detect syntactic objects and their properties in individual sentences, and find patterns across an input sequence of sentences – we show that despite having been trained on multilingual texts in a consistent manner, multilingual pretrained language models have language-specific differences, and syntactic structure is not shared, even across closely related languages.</abstract>
      <url hash="fc83ae13">2024.clicit-1.71</url>
      <bibkey>nastase-etal-2024-exploring-syntactic</bibkey>
    </paper>
    <paper id="72">
      <title>Dynamic Prompting: Large Language Models for Task Oriented Dialog</title>
      <author><first>Jan</first><last>Nehring</last><affiliation>DFKI</affiliation></author>
      <author><first>Akhil</first><last>Juneja</last><affiliation>DFKI</affiliation></author>
      <author><first>Adnan</first><last>Ahmad</last><affiliation>TU Berlin</affiliation></author>
      <author><first>Roland</first><last>Roller</last><affiliation>DFKI SLT Lab</affiliation></author>
      <author><first>Dietrich</first><last>Klakow</last><affiliation>Saarland University</affiliation></author>
      <pages>644-653</pages>
      <abstract>Large Language Models show impressive results in many different applications, most notably in the context of question-answering and open dialog situations. However, it is still an open question how to use those models for task-oriented dialogs such as booking or customer information systems, and such. In this work, we propose Dynamic Prompting, an architecture for task-oriented dialog, integrating the benefits of Large Language Models and showcasing the approach on the MultiWOZ 2.2 dataset. Our architecture leads to a high task success rate, provides sensible and specific answers, and is resistant to hallucinations. Further, we show that Dynamic Prompting is able to answer questions that were not anticipated by the dialog systems designer and that it can correct several types of errors and other characteristics of the system.</abstract>
      <url hash="43c40282">2024.clicit-1.72</url>
      <bibkey>nehring-etal-2024-dynamic</bibkey>
    </paper>
    <paper id="73">
      <title>Exploring Text-Embedding Retrieval Models for the <fixed-case>I</fixed-case>talian Language</title>
      <author><first>Yuri</first><last>Noviello</last><affiliation>FICLIT - University of Bologna</affiliation></author>
      <author><first>Fabio</first><last>Tamburini</last><affiliation>FICLIT - University of Bologna</affiliation></author>
      <pages>654-661</pages>
      <abstract>Text retrieval systems have become essential in the field of natural language processing (NLP), serving as the backbone for applications such as search engines, document indexing, and information retrieval. With the rise of generative AI, particularly Retrieval-Augmented Generation (RAG) systems, the demand for robust text retrieval models has increased. However, existing large language models (LLMs) and datasets are often insufficiently optimized for Italian, limiting their performance in Italian text retrieval tasks. This paper addresses this gap by proposing both a data collection and specialized models tailored for Italian text retrieval. Through extensive experimentation, we analyze the improvements and limitations in retrieval performance, paving the way for more effective Italian NLP applications.</abstract>
      <url hash="72414df3">2024.clicit-1.73</url>
      <bibkey>noviello-tamburini-2024-exploring</bibkey>
    </paper>
    <paper id="74">
      <title>Introducing <fixed-case>M</fixed-case>ulti<fixed-case>LS</fixed-case>-<fixed-case>IT</fixed-case>: A Dataset for Lexical Simplification in <fixed-case>I</fixed-case>talian</title>
      <author><first>Laura</first><last>Occhipinti</last><affiliation>University of Bologna</affiliation></author>
      <pages>662-669</pages>
      <abstract>Lexical simplification is a fundamental task in Natural Language Processing, aiming to replace complex words with simpler synonyms while preserving the original meaning of the text. This task is crucial for improving the accessibility of texts for different user groups. In this article, we present MultiLS-IT, the first dataset specifically designed for automatic lexical simplification in Italian, as part of the larger multilingual Multi-LS dataset. We offer a detailed description of the data collection and annotation process, along with a comprehensive statistical analysis of the dataset. Our dataset provides a basis for the development and evaluation of automatic simplification models, contributing to the broader goal of making texts more accessible to all readers.</abstract>
      <url hash="b90dbc40">2024.clicit-1.74</url>
      <bibkey>occhipinti-2024-introducing</bibkey>
    </paper>
    <paper id="75">
      <title>Enhancing Lexical Complexity Prediction in <fixed-case>I</fixed-case>talian through Automatic Morphological Segmentation</title>
      <author><first>Laura</first><last>Occhipinti</last><affiliation>University of Bologna</affiliation></author>
      <pages>670-678</pages>
      <abstract>Morphological analysis is vital for various NLP tasks as it provides insights into word structures and enhances the understanding of morphological and syntactic relationships. This study focuses on surface morphological segmentation for the Italian language, addressing the lack of detailed morphological representation in existing corpora. By utilizing an automatic segmenter, we aim to extract quantitative morphological parameters to understand their impact on word complexity perception. Our correlation analysis reveals that morphological features significantly influence the perceived complexity of words.</abstract>
      <url hash="9a12c34d">2024.clicit-1.75</url>
      <bibkey>occhipinti-2024-enhancing</bibkey>
    </paper>
    <paper id="76">
      <title>Measuring Bias in Instruction-Following Models with <fixed-case>I</fixed-case>ta<fixed-case>P</fixed-case>-<fixed-case>AT</fixed-case> for the <fixed-case>I</fixed-case>talian Language</title>
      <author><first>Dario</first><last>Onorati</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <author><first>Davide</first><last>Venditti</last><affiliation>Università degli studi di Tor Vergata</affiliation></author>
      <author><first>Elena Sofia</first><last>Ruzzetti</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <author><first>Federico</first><last>Ranaldi</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <author><first>Leonardo</first><last>Ranaldi</last><affiliation>UniTV</affiliation></author>
      <author><first>Fabio Massimo</first><last>Zanzotto</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <pages>679-706</pages>
      <abstract>Instruction-Following Language Models (IFLMs) are the state-of-the-art for solving many downstream tasks. Given their widespread use, there is an urgent need to measure whether the sentences they generate contain toxic information or social biases. In this paper, we propose Prompt Association Test for the Italian language (ItaP-AT): a new resource for testing the presence of social bias in different domains in IFLMs. This work also aims to understand whether it is possible to make the responses of these models more fair by using context learning, using “one-shot anti-stereotypical prompts”.</abstract>
      <url hash="fce6e556">2024.clicit-1.76</url>
      <bibkey>onorati-etal-2024-measuring</bibkey>
    </paper>
    <paper id="77">
      <title>Minerva <fixed-case>LLM</fixed-case>s: The First Family of Large Language Models Trained from Scratch on <fixed-case>I</fixed-case>talian Data</title>
      <author><first>Riccardo</first><last>Orlando</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Luca</first><last>Moroni</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Pere-Lluís</first><last>Huguet Cabot</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Simone</first><last>Conia</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Edoardo</first><last>Barba</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Sergio</first><last>Orlandini</last><affiliation>Cineca</affiliation></author>
      <author><first>Giuseppe</first><last>Fiameni</last><affiliation>Nvidia</affiliation></author>
      <author><first>Roberto</first><last>Navigli</last><affiliation>Sapienza University of Rome</affiliation></author>
      <pages>707-719</pages>
      <abstract>The increasing popularity of Large Language Models (LLMs) has led to a surge in research on adapting existing models to different languages. However, the pretraining of non-English LLMs is still an underexplored area and there is no open-source endeavor that explores what is achievable with open Italian data. To address this issue, we present Minerva, the first family of LLMs trained from scratch on Italian data. The creation of Minerva is an opportunity to explore and investigate the pretraining of LLMs for the Italian language, outlining the challenges that arise when training LLMs with native Italian texts. Minerva demonstrates that an LLM for a specific language brings a number of practical benefits compared to the adaptation of an existing one, including deep control over the composition of the vocabulary and the training data. With this paper, we aim to provide a comprehensive overview of the design choices, results, and evaluation of our Minerva models, showing promising results on Italian benchmarks and downstream tasks. Most importantly, we share what we learned and the findings obtained during the development of Minerva, as we believe that our experience will be valuable for the academic and industrial communities interested in training non-English LLMs from scratch.</abstract>
      <url hash="e21df67d">2024.clicit-1.77</url>
      <bibkey>orlando-etal-2024-minerva</bibkey>
    </paper>
    <paper id="78">
      <title>Benchmarking the Semantics of Taste: Towards the Automatic Extraction of Gustatory Language</title>
      <author><first>Teresa</first><last>Paccosi</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Sara</first><last>Tonelli</last><affiliation>FBK</affiliation></author>
      <pages>720-727</pages>
      <abstract>In this paper, we present a benchmark containing texts manually annotated with gustatory semantic information. We employ a FrameNet-like approach previously tested to address olfactory language, which we adapt to capture gustatory events. We then propose an exploration of the data in the benchmark to show the possible insights brought by this type of approach, addressing the investigation of emotional valence in text genres. Eventually, we present a supervised system trained with the taste benchmark for the extraction of gustatory information from historical and contemporary texts.</abstract>
      <url hash="776dc751">2024.clicit-1.78</url>
      <bibkey>paccosi-tonelli-2024-benchmarking</bibkey>
    </paper>
    <paper id="79">
      <title>Nominal Class Assignment in <fixed-case>S</fixed-case>wahili: A Computational Account</title>
      <author><first>Giada</first><last>Palmieri</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Konstantinos</first><last>Kogkalidis</last><affiliation>Aalto University</affiliation></author>
      <pages>728-734</pages>
      <abstract>We discuss the open question of the relation between semantics and nominal class assignment in Swahili. We approach theproblem from a computational perspective, aiming first to quantify the extent of this relation, and then to explicate its nature,taking extra care to suppress morphosyntactic confounds. Our results are the first of their kind, providing a quantitativeevaluation of the semantic cohesion of each nominal class, as well as a nuanced taxonomic description of its semantic content.</abstract>
      <url hash="57d6896b">2024.clicit-1.79</url>
      <bibkey>palmieri-kogkalidis-2024-nominal</bibkey>
    </paper>
    <paper id="80">
      <title>Did Somebody Say ‘Gest-<fixed-case>IT</fixed-case>’? A Pilot Exploration of Multimodal Data Management</title>
      <author><first>Ludovica</first><last>Pannitto</last><affiliation>LILEC - University of Bologna</affiliation></author>
      <author><first>Lorenzo</first><last>Albanesi</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Laura</first><last>Marion</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Federica</first><last>Martines</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Carmelo</first><last>Caruso</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Claudia</first><last>Bianchini</last><affiliation>University of Poitiers</affiliation></author>
      <author><first>Francesca</first><last>Masini</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Caterina</first><last>Mauri</last><affiliation>University of Bologna</affiliation></author>
      <pages>735-745</pages>
      <abstract>The paper presents a pilot exploration of the construction, management and analysis of a multimodal corpus. Through athree-layer annotation that provides orthographic, prosodic, and gestural transcriptions, the gest-IT resource allows oneto investigate the variation of gesture-making patterns in conversations between sighted people and people with visualimpairment. After discussing the transcription methods and technical procedures employed in our study, we will propose aunified CoNLL-U corpus and indicate our future steps.</abstract>
      <url hash="81fb775e">2024.clicit-1.80</url>
      <bibkey>pannitto-etal-2024-somebody</bibkey>
    </paper>
    <paper id="81">
      <title>Confronto tra Diversi Tipi di Valutazione del Miglioramento della Chiarezza di Testi Amministrativi in Lingua Italiana</title>
      <author><first>Mariachiara</first><last>Pascucci</last><affiliation>Università di Pisa</affiliation></author>
      <author><first>Mirko</first><last>Tavosanis</last><affiliation>Università di Pisa</affiliation></author>
      <pages>746-756</pages>
      <abstract>The paper presents a comparison of different types of evaluation of administrative texts in the Italian language on which a clarity improvement intervention was carried out. The clarity improvement was performed by human experts and ChatGPT. The evaluation was carried out in four different ways: by expert evaluators, used as a reference; by evaluators with good skills, subject to dedicated training; by generic evaluators recruited through a crowdsourcing platform; by ChatGPT. The results show that the closest match to the results of the evaluation by expert evaluators was reached, by a wide margin, by evaluators with good skills and dedicated training; the second best approach was reached by requesting evaluation from ChatGPT; the worst approach was reached by generic evaluators recruited through a crowdsourcing platform. Task features that may have influenced the outcome are also discussed.</abstract>
      <url hash="7198903e">2024.clicit-1.81</url>
      <bibkey>pascucci-tavosanis-2024-confronto</bibkey>
      <language>ita</language>
    </paper>
    <paper id="82">
      <title>Towards an Automatic Evaluation of (In)coherence in Student Essays</title>
      <author><first>Filippo</first><last>Pellegrino</last><affiliation>Eurac research</affiliation></author>
      <author><first>Jennifer</first><last>Frey</last><affiliation>Eurac research</affiliation></author>
      <author><first>Lorenzo</first><last>Zanasi</last><affiliation>Eurac Research</affiliation></author>
      <pages>757-765</pages>
      <abstract>Coherence modeling is an important task in natural language processing (NLP) with potential impact on other NLP taskssuch as Natural Language Understanding or Automated Essay Scoring. But it can also offer interesting linguistic insightswith pedagogical implications. Early work on coherence modeling has focused on exploring definitions of the phenomenonand in recent years, neural models have entered also this field of research allowing to successfully distinguish coherent fromincoherent (synthetically created) texts or to identify the correct continuation for a given sample of texts as demonstratedfor Italian in the DisCoTex task of EVALITA 2023. In this article, we target coherence modeling for Italian language in astrongly domain-specific scenario, i.e. education. We use a corpus of student essays, collected to analyse student’s textcoherence and data augmentation techniques to experiment with the effect of various linguistically informed features ofincoherent writing on current coherence modelling strategies used in NLP. Our results show the capabilities of encodermodels to capture features of (in)coherence in a domain-specific scenario discerning natural from artificially corrupted texts.Our code is available at the following url https://gitlab.inf.unibz.it/commul/itaca/automatic_eval</abstract>
      <url hash="76868cf7">2024.clicit-1.82</url>
      <bibkey>pellegrino-etal-2024-towards</bibkey>
    </paper>
    <paper id="83">
      <title><fixed-case>MONICA</fixed-case>: Monitoring Coverage and Attitudes of <fixed-case>I</fixed-case>talian Measures in Response to <fixed-case>COVID</fixed-case>-19</title>
      <author><first>Fabio</first><last>Pernisi</last><affiliation>Bocconi University</affiliation></author>
      <author><first>Giuseppe</first><last>Attanasio</last><affiliation>Instituto de Telecomunicações</affiliation></author>
      <author><first>Debora</first><last>Nozza</last><affiliation>Bocconi University</affiliation></author>
      <pages>766-773</pages>
      <abstract>Modern social media have long been observed as a mirror for public discourse and opinions. Especially in the face of exceptional events, computational language tools are valuable for understanding public sentiment and reacting quickly. During the coronavirus pandemic, the Italian government issued a series of financial measures, each unique in target, requirements, and benefits. Despite the widespread dissemination of these measures, it is currently unclear how they were perceived and whether they ultimately achieved their goal.In this paper, we document the collection and release of MONICA, a new social media dataset for MONItoring Coverage and Attitudes to such measures. Data include approximately ten thousand posts discussing a variety of measures in ten months. We collected annotations for sentiment, emotion, irony, and topics for each post. We conducted an extensive analysis using computational models to learn these aspects from text. We release a compliant version of the dataset to foster future research on computational approaches for understanding public opinion about government measures. We will release the data at URL.</abstract>
      <url hash="1b3c5e1e">2024.clicit-1.83</url>
      <bibkey>pernisi-etal-2024-monica</bibkey>
    </paper>
    <paper id="84">
      <title>Unraveling the Enigma of <fixed-case>SPLIT</fixed-case> in Large-Language Models: The Unforeseen Impact of System Prompts on <fixed-case>LLM</fixed-case>s with Dissociative Identity Disorder</title>
      <author><first>Marco</first><last>Polignano</last><affiliation>University of Bari</affiliation></author>
      <author><first>Marco</first><last>De Gemmis</last><affiliation>University of Bari Aldo Moro</affiliation></author>
      <author><first>Giovanni</first><last>Semeraro</last><affiliation>University of Bari Aldo Moro</affiliation></author>
      <pages>774-780</pages>
      <abstract>Our work delves into the unexplored territory of Large-Language Models (LLMs) and their interactions with System Prompts, unveiling the previously undiscovered implications of SPLIT (System Prompt Induced Linguistic Transmutation) in commonly used state-of-the-art LLMs. Dissociative Identity Disorder, a complex and multifaceted mental health condition, is characterized by the presence of two or more distinct identities or personas within an individual, often with varying levels of awareness and control. The advent of large-language models has raised intriguing questions about the presence of such conditions in LLMs. Our research investigates the phenomenon of SPLIT, in which the System Prompt, a seemingly innocuous input, profoundly impacts the linguistic outputs of LLMs. The findings of our study reveal a striking correlation between the System Prompt and the emergence of distinct, persona-like linguistic patterns in the LLM’s responses. These patterns are not only reminiscent of the dissociative identities present in the original data but also exhibit a level of coherence and consistency that is uncommon in typical LLM outputs. As we continue to explore the capabilities of LLMs, it is imperative that we maintain a keen awareness of the potential for SPLIT and its significant implications for the development of more human-like and empathetic AI systems.</abstract>
      <url hash="06a209cb">2024.clicit-1.84</url>
      <bibkey>polignano-etal-2024-unraveling</bibkey>
    </paper>
    <paper id="85">
      <title>The limits of <fixed-case>I</fixed-case>talian in Reasoning Tasks</title>
      <author><first>Leonardo</first><last>Ranaldi</last><affiliation>UniTV</affiliation></author>
      <author><first>Giulia</first><last>Pucci</last><affiliation>Independent</affiliation></author>
      <author><first>Federico</first><last>Ranaldi</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <author><first>Elena Sofia</first><last>Ruzzetti</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <author><first>Fabio Massimo</first><last>Zanzotto</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <pages>781-795</pages>
      <abstract>Previous studies have demonstrated the effectiveness of <i>reasoning methods</i> in eliciting multi-step reasoned answers from Large Language Models (LLMs) by leveraging in-context demonstrations. These methods, exemplified by Chain-of-Thought (CoT) and Program-Aided Language Models (PAL), have been shown to reason well in monolingual contexts, primarily in English. There has, however, been limited exploration of their abilities in other languages, especially in Italian.To gain a deeper understanding of the role of reasoning methods in in-context demonstrations, we propose a multidimensional analysis tailored to Italian, focusing on arithmetic and symbolic reasoning tasks. Our findings indicate that the effectiveness of reasoning methods varies significantly beyond English. Specifically, CoT, which relies on natural language demonstrations, is limited to English. Conversely, the structured nature of PAL in-context demonstrations facilitates multilingual comprehension, enabling LLMs to generate programmatic answers in Italian as well. Finally, for a more comprehensive overview, we observe that additional alignment methods do not improve downstream performances; in contrast, in some cases, they limit the abilities of the original models. This leads to significant improvements in the accuracy and quality of the generated responses.</abstract>
      <url hash="98035d9b">2024.clicit-1.85</url>
      <bibkey>ranaldi-etal-2024-limits</bibkey>
    </paper>
    <paper id="86">
      <title>How Far Does the Sequence of Compositions Impact Multilingual Pre-Training?</title>
      <author><first>Leonardo</first><last>Ranaldi</last><affiliation>UniTV</affiliation></author>
      <author><first>Giulia</first><last>Pucci</last><affiliation>Independent</affiliation></author>
      <author><first>Fabio Massimo</first><last>Zanzotto</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <pages>796-804</pages>
      <abstract>The most efficient strategy for conducting pre-training of language models is the concatenation of contiguous sequences of text of fixed length through causal masking that estimates the probability of each token given its context.However, the role of the composition sequence pre-training technique in the models’ generalization properties has yet to be explored.In this paper, we show that operating via causal masking impacts model performance because it could include misleading information from previous text sequences during pre-training.To fill this gap, we propose intra-context causal masking where the probability of each token is conditional only on the previous in the same chunk of text, avoiding misleading information from different contexts.Hence, we demonstrate that organizing text chunks based on a policy that aligns with text similarity effectively reduces the risk of misleading context during pre-training by enhancing language models’ in-context learning and factual knowledge storage capabilities while maintaining efficiency.</abstract>
      <url hash="af086834">2024.clicit-1.86</url>
      <bibkey>ranaldi-etal-2024-far</bibkey>
    </paper>
    <paper id="87">
      <title>From ‘It’s All <fixed-case>G</fixed-case>reek to Me’ to ‘Nur Bahnhof Verstehen’: An Investigation of m<fixed-case>BERT</fixed-case>’s Cross-Linguistic Capabilities</title>
      <author><first>Aria</first><last>Rastegar</last><affiliation>FAU Erlangen-Nuremberg</affiliation></author>
      <author><first>Pegah</first><last>Ramezani</last><affiliation>FAU Erlangen-Nuremberg</affiliation></author>
      <pages>805-812</pages>
      <abstract>This study investigates the impact of cross-linguistic similarities on idiom representation in mBERT, focusing on English and German idioms categorized by different degrees of similarity. We aim to determine whether different degrees of cross-linguistic similarities significantly affect mBERT’s representations and to observe how these representations change across its 12 layers. Contrary to our initial hypothesis, cross-linguistic similarity did not uniformly impact idiom representations across all layers. While early and middle layers showed no significant differences among idiom categories, higher layers (from Layer 8 onwards) revealed more nuanced processing. Specifically, significant differences between the control category and idioms with similar meaning (SM), as well as between idioms with similar lexical items (SL) and those with similar semantics (SM) were observed. Our analysis revealed that early layers provided general representations, while higher layers showed increased differentiation between literal and figurative meanings. This was evidenced by a general decrease in cosine similarities from Layer 5 onwards, with Layer 8 demonstrating the lowest cosine similarities across all categories. Interestingly, a trend suggests that mBERT performs slightly better with more literal hints. The order of cosine similarity for the categorizations was: idioms with a degree of formal similarity, control idioms, idioms with both formal and semantic similarity, and finally idioms with only semantic similarity. These findings indicate that mBERT’s processing of idioms evolves significantly across its layers, with cross-linguistic might affect more significantly in higher layers where more abstract semantic processing likely occurs.</abstract>
      <url hash="bbf8fdcc">2024.clicit-1.87</url>
      <bibkey>rastegar-ramezani-2024-greek</bibkey>
    </paper>
    <paper id="88">
      <title>Is Sentence Splitting a Solved Task? Experiments to the Intersection between <fixed-case>NLP</fixed-case> and <fixed-case>I</fixed-case>talian Linguistics</title>
      <author><first>Arianna</first><last>Redaelli</last><affiliation>Università di Parma</affiliation></author>
      <author><first>Rachele</first><last>Sprugnoli</last><affiliation>University of Parma</affiliation></author>
      <pages>813-820</pages>
      <abstract>Sentence splitting, that is the segmentation of the raw input text into sentences, is a fundamental step in text processing. Although it is considered a solved task for texts such as news articles and Wikipedia pages, the performance of systems can vary greatly depending on the text genre. This paper presents the evaluation of the performance of eight sentence splitting tools adopting different approaches (rule-based, supervised, semi-supervised, and unsupervised learning) on Italian 19th-century novels, a genre that has not received sufficient attention so far but which can be an interesting common ground between Natural Language Processing and Digital Humanities.</abstract>
      <url hash="8d606449">2024.clicit-1.88</url>
      <bibkey>redaelli-sprugnoli-2024-sentence</bibkey>
    </paper>
    <paper id="89">
      <title>From Explanation to Detection: Multimodal Insights into Disagreement in Misogynous Memes</title>
      <author><first>Giulia</first><last>Rizzi</last><affiliation>Universita’ degli Studi di Milano-Bicocca and Universitat Politecnica de Valencia</affiliation></author>
      <author><first>Paolo</first><last>Rosso</last><affiliation>Universitat Politècnica de València</affiliation></author>
      <author><first>Elisabetta</first><last>Fersini</last><affiliation>University of Milano-Bicocca</affiliation></author>
      <pages>821-828</pages>
      <abstract>This paper presents a probabilistic approach to identifying the disagreement-related elements in misogynistic memes by considering both modalities that compose a meme (i.e., visual and textual sources). Several methodologies to exploit such elements in the identification of disagreement among annotators have been investigated and evaluated on the Multimedia Automatic Misogyny Identification (MAMI) dataset. The proposed unsupervised approach reaches comparable performances, and in some cases even better, with state-of-the-art approaches, but with a reduced number of parameters to be estimated.</abstract>
      <url hash="9c5d94da">2024.clicit-1.89</url>
      <bibkey>rizzi-etal-2024-explanation</bibkey>
    </paper>
    <paper id="90">
      <title>To Click It or Not to Click It: An <fixed-case>I</fixed-case>talian Dataset for Neutralising Clickbait Headlines</title>
      <author><first>Daniel</first><last>Russo</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Oscar</first><last>Araque</last><affiliation>Universidad Politècnica de Madrid</affiliation></author>
      <author><first>Marco</first><last>Guerini</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <pages>829-841</pages>
      <abstract>Clickbait is a common technique aimed to attract reader’s attention, although it can result inaccurate and lead to misinformation. This work explores the role of current Natural Language Processing methods to reduce its negative impact. To do so, a novel Italian dataset is generated, containing manual annotations for classification, spoiling, and neutralisation of clickbait. Besides, several experimental evaluations are performed, assessing the performance of current language models. On the one hand, we evaluate the performance in the task of clickbait detection in a multilingual setting, showing that augmenting the data with English instance largely improves overall performance. On the other hand, the generation tasks of clickbait spoiling and neutralisation are explored. The latter is a novel task that is designed to increase the informativeness of a headline, thus removing the information gap. This work opens a new research avenue that has been largely uncharted in the Italian language.</abstract>
      <url hash="4adb9742">2024.clicit-1.90</url>
      <bibkey>russo-etal-2024-click</bibkey>
    </paper>
    <paper id="91">
      <title><fixed-case>AI</fixed-case> vs. Human: Effectiveness of <fixed-case>LLM</fixed-case>s in Simplifying <fixed-case>I</fixed-case>talian Administrative Documents</title>
      <author><first>Marco</first><last>Russodivito</last><affiliation>Università degli studi del Molise</affiliation></author>
      <author><first>Vittorio</first><last>Ganfi</last><affiliation>Università degli studi del Molise</affiliation></author>
      <author><first>Giuliana</first><last>Fiorentino</last><affiliation>Università degli studi del Molise</affiliation></author>
      <author><first>Rocco</first><last>Oliveto</last><affiliation>Università degli studi del Molise</affiliation></author>
      <pages>842-853</pages>
      <abstract>This study investigates the effectiveness of Large Language Models (LLMs) in simplifying Italian administrative texts compared to human informants. This research evaluates the performance of several well-known LLMs, including GPT-3.5-Turbo, GPT-4, LLaMA 3, and Phi 3, in simplifying a corpus of Italian administrative documents (s-ItaIst), a representative corpus of Italian administrative texts. To accurately compare the simplification abilities of humans and LLMs, six parallel corpora of a subsection of ItaIst are collected. These parallel corpora were analyzed using both complexity and similarity metrics to assess the outcomes of LLMs and human participants. Our findings indicate that while LLMs perform comparably to humans in many aspects, there are notable differences in structural and semantic changes. The results of our study underscore the potential and limitations of using AI for administrative text simplification, highlighting areas where LLMs need improvement to achieve human-level proficiency.</abstract>
      <url hash="8fb8f554">2024.clicit-1.91</url>
      <bibkey>russodivito-etal-2024-ai</bibkey>
    </paper>
    <paper id="92">
      <title>Assessing the Asymmetric Behaviour of <fixed-case>I</fixed-case>talian Large Language Models across Different Syntactic Structures</title>
      <author><first>Elena Sofia</first><last>Ruzzetti</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <author><first>Federico</first><last>Ranaldi</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <author><first>Dario</first><last>Onorati</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <author><first>Davide</first><last>Venditti</last><affiliation>Università degli studi di Tor Vergata</affiliation></author>
      <author><first>Leonardo</first><last>Ranaldi</last><affiliation>UniTV</affiliation></author>
      <author><first>Tommaso</first><last>Caselli</last><affiliation>Rijksuniversiteit Groningen</affiliation></author>
      <author><first>Fabio Massimo</first><last>Zanzotto</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <pages>854-863</pages>
      <abstract>While LLMs get more proficient at solving tasks and generating sentences, we aim to investigate the role that differentsyntactic structures have on models’ performances on a battery of Natural Language Understanding tasks. We analyze theperformance of five LLMs on semantically equivalent sentences that are characterized by different syntactic structures. Tocorrectly solve the tasks, a model is implicitly required to correctly parse the sentence. We found out that LLMs strugglewhen there are more complex syntactic structures, with an average drop of 16.13(±11.14) points in accuracy on Q&amp;A task.Additionally, we propose a method based on token attribution to spot which area of the LLMs encode syntactic knowledge,by identifying model heads and layers responsible for the generation of a correct answer</abstract>
      <url hash="e14be92b">2024.clicit-1.92</url>
      <bibkey>ruzzetti-etal-2024-assessing</bibkey>
    </paper>
    <paper id="93">
      <title>Morphological vs. Lexical Antonyms in <fixed-case>I</fixed-case>talian: A Computational Study on Lexical Competition</title>
      <author><first>Martina</first><last>Saccomando</last><affiliation>Alma Mater Studiorum - Università di Bologna</affiliation></author>
      <author><first>Andrea</first><last>Zaninello</last><affiliation>FBK Trento</affiliation></author>
      <author><first>Francesca</first><last>Masini</last><affiliation>Alma Mater Studiorum - Università di Bologna</affiliation></author>
      <pages>864-872</pages>
      <abstract>In this paper, we examine the competition between pairs of adjectives in Italian that are antonyms of the same term: one is a “morphological antonym” formed by negative prefixation, the other is a “lexical antonym” with no morphological relationship with the term in question. We consider pairs of adjectives that are reported as antonyms in lexicographic resources and extract the nouns that can be modified by both adjectives from a large corpus. We select a set of 8 nouns for each pair that present higher, lower, and comparable frequencies combined with each antonym respectively and then we perform two experiments with a LLM. Firstly, we perform experiments for masked-token prediction of the adjective, to study the correlation between prediction accuracy and the frequency of the noun-antonym pair. Secondly, we perform a polarity-flip experiment with a multilingual LLM, asking to change the adjective into its positive counterpart, and study the cases where the antonym is changed to the morphological antonym’s lexical base, under the hypothesis that a flip to the lexical base indicates a narrower set of senses of the antonymic counterpart.</abstract>
      <url hash="f1f8f4f3">2024.clicit-1.93</url>
      <bibkey>saccomando-etal-2024-morphological</bibkey>
    </paper>
    <paper id="94">
      <title>Multimodal Attention Is All You Need</title>
      <author><first>Marco</first><last>Saioni</last><affiliation>University of G. Marconi, Rome, IT</affiliation></author>
      <author><first>Cristina</first><last>Giannone</last><affiliation>Almawave spa</affiliation></author>
      <pages>873-879</pages>
      <abstract>In this paper, we present a multimodal model for classifying fake news. The main peculiarity of the proposed model is the <i>cross attention</i> mechanism. Cross-attention is an evolution of the attention mechanism that allows the model to examine intermodal relationships to better understand information from different modalities, enabling it to simultaneously focus on the relevant parts of the data extracted from each. We tested the model using <i>MULTI-Fake-DetectiVE</i> data from Evalita 2023. The presented model is particularly effective in both the tasks of classifying fake news and evaluating the intermodal relationship.</abstract>
      <url hash="99e3ff0d">2024.clicit-1.94</url>
      <bibkey>saioni-giannone-2024-multimodal</bibkey>
    </paper>
    <paper id="95">
      <title>Assessing <fixed-case>I</fixed-case>talian Large Language Models on Energy Feedback Generation: A Human Evaluation Study</title>
      <author><first>Manuela</first><last>Sanguinetti</last><affiliation>University of Cagliari, Department of Mathematics and Computer Science</affiliation></author>
      <author><first>Alessandro</first><last>Pani</last><affiliation>Department of Mathematics and Computer Science, University of Cagliari, Italy</affiliation></author>
      <author><first>Alessandra</first><last>Perniciano</last><affiliation>University of Cagliari</affiliation></author>
      <author><first>Luca</first><last>Zedda</last><affiliation>University of Cagliari</affiliation></author>
      <author><first>Andrea</first><last>Loddo</last><affiliation>University of Cagliari</affiliation></author>
      <author><first>Maurizio</first><last>Atzori</last><affiliation>University of Cagliari</affiliation></author>
      <pages>880-887</pages>
      <abstract>This work presents a comparison of some recently-released instruction-tuned large language models for Italian, focusing in particular on their effectiveness in a specific application scenario, i.e., that of delivering energy feedback. This work is part of a larger project aimed at developing a conversational interface for users of a renewable energy community, where clarity and accuracy of the provided feedback are important for a proper energy management. This comparison is based on the human evaluation of the output produced by such models using energy data as input. Specifically, the data pertains to information regarding the power flows within a household equipped with a photovoltaic (PV) plant and a battery storage system. The goal of the feedback is precisely that of providing the user with such information in a meaningful way based on the specific aspect they intend to monitor at a given moment (e.g., self-consumption levels, the power generated by the PV panels or imported from the main grid, or the battery state of charge). This evaluation experiment has the two-fold purpose of providing an exploratory analysis of the models’ abilities on this specific generation task solely relying on the information and instruction provided in the prompt, and as an initial investigation into their potential as reliable tools for generating user-friendly energy feedback in this intended scenario.</abstract>
      <url hash="0fa5d0c0">2024.clicit-1.95</url>
      <bibkey>sanguinetti-etal-2024-assessing</bibkey>
    </paper>
    <paper id="96">
      <title>Non Verbis, Sed Rebus: Large Language Models Are Weak Solvers of <fixed-case>I</fixed-case>talian Rebuses</title>
      <author><first>Gabriele</first><last>Sarti</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Tommaso</first><last>Caselli</last><affiliation>Rijksuniversiteit Groningen</affiliation></author>
      <author><first>Malvina</first><last>Nissim</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Arianna</first><last>Bisazza</last><affiliation>University of Groningen</affiliation></author>
      <pages>888-897</pages>
      <abstract>Rebuses are puzzles requiring constrained multi-step reasoning to identify a hidden phrase from a set of images and letters. In this work, we introduce a large collection of verbalized rebuses for the Italian language and use it to assess the rebus-solving capabilities of state-of-the-art large language models. While general-purpose systems such as LLaMA-3 and GPT-4o perform poorly on this task, ad-hoc fine-tuning seems to improve models’ performance. However, we find that performance gains from training are largely motivated by memorization. Our results suggest that rebus solving remains a challenging test bed to evaluate large language models’ linguistic proficiency and sequential instruction-following skills.</abstract>
      <url hash="e2a1c8dc">2024.clicit-1.96</url>
      <bibkey>sarti-etal-2024-non</bibkey>
    </paper>
    <paper id="97">
      <title>Leveraging Large Language Models for Fact Verification in <fixed-case>I</fixed-case>talian</title>
      <author><first>Antonio</first><last>Scaiella</last><affiliation>Reveal s.r.l. - University of Rome Tor Vergata, Italy</affiliation></author>
      <author><first>Stefano</first><last>Costanzo</last><affiliation>University of Rome Tor Vergata, Italy</affiliation></author>
      <author><first>Elisa</first><last>Passone</last><affiliation>University of Rome Tor Vergata, Italy</affiliation></author>
      <author><first>Danilo</first><last>Croce</last><affiliation>University of Roma, Tor Vergata</affiliation></author>
      <author><first>Giorgio</first><last>Gambosi</last><affiliation>University of Rome Tor Vergata, Italy</affiliation></author>
      <pages>898-908</pages>
      <abstract>In recent years, Automatic Fact Checking has become a crucial tool in combating fake news, leveraging AI to verify the accuracy of information. Despite significant advancements, most datasets and models are predominantly available in English, posing challenges for other languages. This paper presents an Italian resource based on the dataset made available in the FEVER evaluation campaign, created to train and evaluate fact-checking models in Italian. The dataset comprises approximately 240k examples, with over 2k test examples manually validated. Additionally, we fine-tuned a state-of-the-art LLM, namely LLaMA3, on both the original English and translated Italian datasets, demonstrating that fine-tuning significantly improves model performance. Our results suggest that the fine-tuned models achieve comparable accuracy in both languages, highlighting the value of the proposed resource.</abstract>
      <url hash="9a9774bb">2024.clicit-1.97</url>
      <bibkey>scaiella-etal-2024-leveraging</bibkey>
    </paper>
    <paper id="98">
      <title>A Gentle Push Funziona Benissimo: Making Instructed Models in <fixed-case>I</fixed-case>talian via Contrastive Activation Steering</title>
      <author><first>Daniel</first><last>Scalena</last><affiliation>University of Milano - Bicocca</affiliation></author>
      <author><first>Elisabetta</first><last>Fersini</last><affiliation>University of Milano-Bicocca</affiliation></author>
      <author><first>Malvina</first><last>Nissim</last><affiliation>University of Groningen</affiliation></author>
      <pages>909-920</pages>
      <abstract>Adapting models to a language that was only partially present in the pre-training data requires fine-tuning, which is expensive in terms of both data and computational resources. As an alternative to fine-tuning, we explore the potential of activation steering-based techniques to enhance model performance on Italian tasks. Through our experiments we show that Italian steering (i) can be successfully applied to different models, (ii) achieves performances comparable to, or even better than, fine-tuned models for Italian, and (iii) yields higher quality and consistency in Italian generations. We also discuss the utility of steering and fine-tuning in the contemporary LLM landscape where models are anyway getting high Italian performances even if not explicitly trained in this language.</abstract>
      <url hash="c64a4f7f">2024.clicit-1.98</url>
      <bibkey>scalena-etal-2024-gentle</bibkey>
    </paper>
    <paper id="99">
      <title>Subcategorization of <fixed-case>I</fixed-case>talian Verbs with <fixed-case>LLM</fixed-case>s and <fixed-case>T</fixed-case>-<fixed-case>PAS</fixed-case></title>
      <author><first>Luca</first><last>Simonetti</last><affiliation>Università degli Studi Guglielmo Marconi</affiliation></author>
      <author><first>Elisabetta</first><last>Jezek</last><affiliation>University of Pavia</affiliation></author>
      <author><first>Guido</first><last>Vetere</last><affiliation>Università Guglielmo Marconi</affiliation></author>
      <pages>921-928</pages>
      <abstract>This study explores the application of Large Language Models (LLMs) to verb subcategorization in Italian, focusing on the identification and classification of syntactic patterns in sentences. While LLMs have made lexical analysis more implicit, explicit argument structure identification remains crucial in domain-specific contexts. The research leverages T-PAS, a rich lexical resource for Italian verbs, to fine-tune the open multilingual model Mistral 7B using the Iterative Reasoning Preference Optimization (IRPO) technique. This approach aims to enhance the recognition and extraction of verbal patterns from Italian sentences, addressing challenges in resource quality, coverage, and frame extraction methods. By combining curated lexical-semantic resources with neural language models, this work contributes to improving verb subcategorization tasks, particularly for the Italian language, and demonstrates the potential of LLMs in refining linguistic analysis tools.</abstract>
      <url hash="719dd83f">2024.clicit-1.99</url>
      <bibkey>simonetti-etal-2024-subcategorization</bibkey>
    </paper>
    <paper id="100">
      <title>Unipa-<fixed-case>GPT</fixed-case>: A Framework to Assess Open-source Alternatives to Chat-<fixed-case>GPT</fixed-case> for <fixed-case>I</fixed-case>talian Chat-bots</title>
      <author><first>Irene</first><last>Siragusa</last><affiliation>University of Palermo</affiliation></author>
      <author><first>Roberto</first><last>Pirrone</last><affiliation>University of Palermo</affiliation></author>
      <pages>929-939</pages>
      <abstract>This paper illustrates the implementation of Open Unipa-GPT, an open source version of the Unipa-GPT chatbot that leverages on open-source Large Language Models for embeddings and text generation. The system relies on a Retrieval Augmented Generation approach, thus mitigating hallucination errors in the generation phase. A detailed comparison between different models is reported to illustrate their performance as regards embedding generation, retrieval, and text generation. In the last case, models were tested in simple inference setup after a fine-tuning procedure. Experiments demonstrate that an open-source LLMs can be efficiently used for embedding generation, but noon of the models does reach the performances obtained by closed models, such as gpt-3.5-turbo in generating answers.</abstract>
      <url hash="8bd2ee59">2024.clicit-1.100</url>
      <bibkey>siragusa-pirrone-2024-unipa</bibkey>
    </paper>
    <paper id="101">
      <title>Annotation and Detection of Emotion Polarity in “<fixed-case>I</fixed-case> Promessi Sposi”: Dataset and Experiments</title>
      <author><first>Rachele</first><last>Sprugnoli</last><affiliation>University of Parma</affiliation></author>
      <author><first>Arianna</first><last>Redaelli</last><affiliation>Università di Parma</affiliation></author>
      <pages>940-947</pages>
      <abstract>Emotions play a crucial role in literature and are studied by various disciplines, e.g. literary criticism, psychology, anthropology and, more recently, also with computational methods in NLP. However, studies in the Italian context are still limited. This work therefore aims to advance the state of the art in the field of emotion analysis applied to historical texts by proposing a new dataset and describing the results of a set of emotion polarity detection experiments. The text analyzed is “I Promessi Sposi” in its final edition (published in 1840), one of the most important novels in the Italian literary and linguistic canon.</abstract>
      <url hash="571d1f11">2024.clicit-1.101</url>
      <bibkey>sprugnoli-redaelli-2024-annotation</bibkey>
    </paper>
    <paper id="102">
      <title>Complexifying <fixed-case>BERT</fixed-case> Using <fixed-case>L</fixed-case>o<fixed-case>RA</fixed-case> Adapters</title>
      <author><first>Fabio</first><last>Tamburini</last><affiliation>FICLIT - University of Bologna</affiliation></author>
      <pages>948-954</pages>
      <abstract>This paper presents the first results of a pilot study for transforming a real-valued pre-trained transformer encoder into a complex-valued one. Following recent findings about pre-training using LoRA, the main idea is to employ complex-valued LoRA adapters to make the trick and continue the pre-training of a given Italian model for setting up the adapters. After pre-training, the proposed complex-valued model has been evaluated on a standardised benchmark for Italian natural-language understanding obtaining very encouraging results.</abstract>
      <url hash="7ea13668">2024.clicit-1.102</url>
      <bibkey>tamburini-2024-complexifying</bibkey>
    </paper>
    <paper id="103">
      <title>How Do We Counter Hate Speech in <fixed-case>I</fixed-case>taly?</title>
      <author><first>Vittoria</first><last>Tonini</last><affiliation>University of Turin</affiliation></author>
      <author><first>Simona</first><last>Frenda</last><affiliation>Heriot-Watt University</affiliation></author>
      <author><first>Marco Antonio</first><last>Stranisci</last><affiliation>University of Turin</affiliation></author>
      <author><first>Viviana</first><last>Patti</last><affiliation>University of Turin, Dipartimento di Informatica</affiliation></author>
      <pages>955-966</pages>
      <abstract>The phenomenon of online hate speech is a growing challenge and various organisations try to prevent its spread answering promptly to hateful messages online. In this context, we propose a new dataset of activists’ and users’ comments on Facebook reacting to specific news headlines: AmnestyCounterHS. Taking into account the literature on counterspeech, we defined a new schema of annotation and applied it to our dataset, in order to examine the most used counter-narrative strategies in Italy. This research aims to support the future development of automatic counterspeech generation. This paper presents also a comparative analysis of our dataset with other two datasets in Italian (Counter-TWIT and multilingual CONAN) containing hate speech and counter narratives. Through this analysis, we will understand how the environment (artificial vs. ecological) and the topics of discussions online influence the nature of counter narratives. Our findings highlight the predominance of negative sentiment and emotions, the varying presence of stereotypes, and the strategic differences in counter narratives across dataset.</abstract>
      <url hash="3aa0e5a0">2024.clicit-1.103</url>
      <bibkey>tonini-etal-2024-counter</bibkey>
    </paper>
    <paper id="104">
      <title>Nesciun Lengaz Lascià Endò: Machine Translation for Fassa <fixed-case>L</fixed-case>adin</title>
      <author><first>Giovanni</first><last>Valer</last><affiliation>University of Trento</affiliation></author>
      <author><first>Nicolò</first><last>Penzo</last><affiliation>University of Trento, Fondazione Bruno Kessler</affiliation></author>
      <author><first>Jacopo</first><last>Staiano</last><affiliation>University of Trento</affiliation></author>
      <pages>967-975</pages>
      <abstract>Despite the remarkable success recently obtained by Large Language Models, a significant gap in performance still exists when dealing with low-resource languages which are often poorly supported by off-the-shelf models. In this work we focus on Fassa Ladin, a Rhaeto-Romance linguistic variety spoken by less than ten thousand people in the Dolomitic regions, and set to build the first bidirectional Machine Translation system supporting Italian, English, and Fassa Ladin. To this end, we collected a small though representative corpus compounding 1135 parallel sentences in these three languages, and spanning five domains. We evaluated several models including the open (Meta AI’s No Language Left Behind, NLLB-200) and commercial (OpenAI’s gpt-4o) state-of-the-art, and indeed found that both obtain unsatisfactory performance. We therefore proceeded to finetune the NLLB-200 model on the data collected, using different approaches. We report a comparative analysis of the results obtained, showing that 1) jointly training for multilingual translation (Ladin-Italian and Ladin-English) significantly improves the performance, and 2) knowledge-transfer is highly effective (e.g., leveraging similarities between Ladin and Friulian), highlighting the importance of targeted data collection and model adaptation in the context of low-resource/endangered languages for which little textual data is available.</abstract>
      <url hash="c118ab07">2024.clicit-1.104</url>
      <bibkey>valer-etal-2024-nesciun</bibkey>
    </paper>
    <paper id="105">
      <title>Neutral Score Detection in Lexicon-based Sentiment Analysis: The Quartile-based Approach</title>
      <author><first>Marco</first><last>Vassallo</last><affiliation>CREA Research Centre for Agricultural Policies and Bio-economy</affiliation></author>
      <author><first>Giuliano</first><last>Gabrieli</last><affiliation>CREA Research Centre for Agricultural Policies and Bio-economy</affiliation></author>
      <author><first>Valerio</first><last>Basile</last><affiliation>University of Turin</affiliation></author>
      <author><first>Cristina</first><last>Bosco</last><affiliation>Dipartimento di Informatica - UniversitÃ di Torino</affiliation></author>
      <pages>976-982</pages>
      <abstract>The neutrality detection in Sentiment Analysis (SA) still constitutes an unsolved and debated issue. This work proposes an empirical method based on the quartiles of the polarity distribution for a lexicon-based SA approach. Our experiments are based on the Italian linguistic resource MAL (Morphologically-inflected Affective Lexicon) and applied to two annotated corpora. The findings provided a better detection of the neutral opinions with preserving a substantial overall polarity prediction.</abstract>
      <url hash="ac763862">2024.clicit-1.105</url>
      <bibkey>vassallo-etal-2024-neutral</bibkey>
    </paper>
    <paper id="106">
      <title>Sensitivity of Syllable-Based <fixed-case>ASR</fixed-case> Predictions to Token Frequency and Lexical Stress</title>
      <author><first>Alessandro</first><last>Vietti</last><affiliation>Free University of Bozen-Bolzano</affiliation></author>
      <author><first>Domenico</first><last>De Cristofaro</last><affiliation>Free University of Bozen-Bolzano</affiliation></author>
      <author><first>Picciau</first><last>Sara</last><affiliation>Free University of Bozen-Bolzano</affiliation></author>
      <pages>983-989</pages>
      <abstract>Automatic Speech Recognition systems (ASR) based on neural networks achieve great results, but it remains unclear which are the linguistic features and representations that the models leverage to perform the recognition. In our study, we used phonological syllables as tokens to fine-tune an end-to-end ASR model due to their relevance as linguistic units. Furthermore, this strategy allowed us to keep track of different types of linguistic features characterizing the tokens. The analysis of the transcriptions generated by the model reveals that factors such as token frequency and lexical stress have a variable impact on the prediction strategies adopted by the ASR system.</abstract>
      <url hash="a4fd0773">2024.clicit-1.106</url>
      <bibkey>vietti-etal-2024-sensitivity</bibkey>
    </paper>
    <paper id="107">
      <title>Modelling Filled Particles and Prolongation Using End-to-end Automatic Speech Recognition Systems: A Quantitative and Qualitative Analysis.</title>
      <author><first>Vincenzo Norman</first><last>Vitale</last><affiliation>University of Naples Federico II</affiliation></author>
      <author><first>Loredana</first><last>Schettino</last><affiliation>Free University of Bozen-Bolzano, Bozen, Italy</affiliation></author>
      <author><first>Francesco</first><last>Cutugno</last><affiliation>University of Naples Federico II</affiliation></author>
      <pages>990-996</pages>
      <abstract>State-of-the-art automatic speech recognition systems based on End-to-End models (E2E-ASRs) achieve remarkable perfor mances. However, phenomena that characterize spoken language such as fillers (eeh ehm) or segmental prolongations (theee) are still mostly considered as disrupting objects that should not be included to obtain optimal transcriptions, despite their acknowledged regularity and communicative value. A recent study showed that two types of pre-trained systems with the same Conformer-based encoding architecture but different decoders – a Connectionist Temporal Classification (CTC) decoder and a Transducer decoder – tend to model some speech features that are functional for the identification of filled pauses and prolongation in speech. This work builds upon these findings by investigating which of the two systems is better at fillers and prolongations detection tasks and by conducting an error analysis to deepen our understanding of how these systems work.</abstract>
      <url hash="8bc5fc81">2024.clicit-1.107</url>
      <bibkey>vitale-etal-2024-modelling</bibkey>
    </paper>
    <paper id="108">
      <title>Implicit Stereotypes: A Corpus-Based Study for <fixed-case>I</fixed-case>talian</title>
      <author><first>Wolfgang</first><last>Wolfgang Schmeisser-Nieto</last><affiliation>Universitat de Barcelona</affiliation></author>
      <author><first>Giacomo</first><last>Ricci</last><affiliation>Università degli Studi di Torino</affiliation></author>
      <author><first>Simona</first><last>Frenda</last><affiliation>Heriot-Watt University</affiliation></author>
      <author><first>Mariona</first><last>Taule</last><affiliation>University of Barcelona</affiliation></author>
      <author><first>Cristina</first><last>Bosco</last><affiliation>Dipartimento di Informatica - UniversitÃ di Torino</affiliation></author>
      <pages>997-1004</pages>
      <abstract>Detecting stereotypes is a challenging task, particularly when they are not expressed explicitly. In this study, we applied an annotation schema from the literature designed to formalize implicit stereotypes. We analyzed implicit stereotypes towards immigrants in two datasets: StereoHoax-IT and SterheoSchool, which are created from different sources. StereoHoax-IT consists of reactions on Twitter to specific hoaxes aimed at discriminating against immigrants, while SterheoSchool includes comments from teenagers on fake news generated in psychological experiments. We describe the annotation process, annotator disagreements, and provide both quantitative and qualitative analyses to shed light on how implicitness characterizes stereotypes in different texts. Our findings suggest that implicit stereotypes are often conveyed through logical linguistic relations, such as entailment and behavioral evaluations of immigrants.</abstract>
      <url hash="46466daf">2024.clicit-1.108</url>
      <bibkey>wolfgang-schmeisser-nieto-etal-2024-implicit</bibkey>
    </paper>
    <paper id="109">
      <title><fixed-case>SLIMER</fixed-case>-<fixed-case>IT</fixed-case>: Zero-Shot <fixed-case>NER</fixed-case> on <fixed-case>I</fixed-case>talian Language</title>
      <author><first>Andrew</first><last>Zamai</last><affiliation>Expert.ai, University of Siena</affiliation></author>
      <author><first>Leonardo</first><last>Rigutini</last><affiliation>expert.ai</affiliation></author>
      <author><first>Marco</first><last>Maggini</last><affiliation>University of Siena</affiliation></author>
      <author><first>Andrea</first><last>Zugarini</last><affiliation>Expert.ai</affiliation></author>
      <pages>1005-1012</pages>
      <abstract>Traditional approaches to Named Entity Recognition (NER) frame the task into a BIO sequence labeling problem. Although these systems often excel in the downstream task at hand, they require extensive annotated data and struggle to generalize to out-of-distribution input domains and unseen entity types. On the contrary, Large Language Models (LLMs) have demonstrated strong zero-shot capabilities. While several works address Zero-Shot NER in English, little has been done in other languages. In this paper, we define an evaluation framework for Zero-Shot NER, applying it to the Italian language. Furthermore, we introduce SLIMER-IT, the Italian version of SLIMER, an instruction-tuning approach for zero-shot NER leveraging prompts enriched with definition and guidelines. Comparisons with other state-of-the-art models, demonstrate the superiority of SLIMER-IT on never-seen-before entity tags.</abstract>
      <url hash="96620df3">2024.clicit-1.109</url>
      <bibkey>zamai-etal-2024-slimer</bibkey>
    </paper>
    <paper id="110">
      <title>Harnessing <fixed-case>LLM</fixed-case>s for Educational Content-Driven <fixed-case>I</fixed-case>talian Crossword Generation</title>
      <author><first>Kamyar</first><last>Zeinalipour</last><affiliation>University of Siena</affiliation></author>
      <author><first>Achille</first><last>Fusco</last><affiliation>IUSS Pavia</affiliation></author>
      <author><first>Asya</first><last>Zanollo</last><affiliation>University of Siena</affiliation></author>
      <author><first>Marco</first><last>Maggini</last><affiliation>University of Siena</affiliation></author>
      <author><first>Marco</first><last>Gori</last><affiliation>University of Siena</affiliation></author>
      <pages>1013-1023</pages>
      <abstract>In this work, we unveil a novel tool for generating Italian crossword puzzles from text, utilizing advanced language models such as GPT-4o, Mistral-7B-Instruct-v0.3, and Llama3-8B-Instruct. Crafted specifically for educational applications, this cutting-edge generator makes use of the comprehensive Italian-Clue-Instruct dataset, which comprises over 30,000 entries including diverse text, solutions, and types of clues. This carefully assembled dataset is designed to facilitate the creation of contextually relevant clues in various styles associated with specific texts and keywords.The study delves into four distinctive styles of crossword clues: those without format constraints, those formed as definite determiner phrases, copular sentences, and bare noun phrases. Each style introduces unique linguistic structures to diversify clue presentation.Given the lack of sophisticated educational tools tailored to the Italian language, this project seeks to enhance learning experiences and cognitive development through an engaging, interactive platform. By meshing state-of-the-art AI with contemporary educational strategies, our tool can dynamically generate crossword puzzles from Italian educational materials, thereby providing an enjoyable and interactive learning environment. This technological advancement not only redefines educational paradigms but also sets a new benchmark for interactive and cognitive language learning solutions.</abstract>
      <url hash="594601ef">2024.clicit-1.110</url>
      <bibkey>zeinalipour-etal-2024-harnessing</bibkey>
    </paper>
    <paper id="111">
      <title>Voice Activity Detection on <fixed-case>I</fixed-case>talian Language</title>
      <author><first>Shibingfeng</first><last>Zhang</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Gloria</first><last>Gagliardi</last><affiliation>Alma Mater Studiorum - University of Bologna</affiliation></author>
      <author><first>Fabio</first><last>Tamburini</last><affiliation>FICLIT - University of Bologna</affiliation></author>
      <pages>1024-1029</pages>
      <abstract>Voice Activity Detection (VAD) refers to the task of identifying human voice activity in noisy settings, playing a crucial role in fields like speech recognition and audio surveillance. However, most VAD research focuses on English, leaving other languages, such as Italian, under-explored. This study aims to evaluate and enhance VAD systems for Italian speech, with the goal of finding a solution for the speech segmentation component of the Digital Linguistic Biomarkers (DLBs) extraction pipeline for early mental disorder diagnosis. We experimented with various VAD systems and propose an ensemble VAD system that integrates the best-performing models. Our ensemble system shows significant improvements in speech event detection. This advancement lays a robust foundation for more accurate early detection of mental health issues using DLBs in Italian.</abstract>
      <url hash="bb081f0d">2024.clicit-1.111</url>
      <bibkey>zhang-etal-2024-voice</bibkey>
    </paper>
    <paper id="112">
      <title>Topic Modeling for Auditing Purposes in the Banking Sector</title>
      <author><first>Alessandro</first><last>Giaconia</last><affiliation>Università Cattolica del Sacro Cuore</affiliation></author>
      <author><first>Valeria</first><last>Chiariello</last><affiliation>Credem</affiliation></author>
      <author><first>Marco</first><last>Passarotti</last><affiliation>CIRCSE</affiliation></author>
      <pages>1030-1035</pages>
      <abstract>This study explores the application of topic modeling techniques for auditing purposes in the banking sector, focusing on the analysis of suspicious activity reports. We compare three topic modeling algorithms: Latent Dirichlet Allocation (LDA), Embedded Topic Model (ETM), and Product of Experts LDA (ProdLDA), using a dataset of 35,000 suspicious activity reports from an Italian bank. The models were evaluated using coherence score, NPMI coherence, and topic diversity metrics. Our results show that ProdLDA consistently outperformed LDA and ETM, with the best performance achieved using 1-gram word embeddings. The study reveals distinct topics related to specific client activities, cross-border transactions, and high-risk business sectors like gambling. These results demonstrate the potential of advanced topic modeling techniques in enhancing the efficiency and effectiveness of auditing processes in the banking sector, particularly in the analysis of suspicious activities, that could be tied to money laundering and terrorism.</abstract>
      <url hash="ce9b3147">2024.clicit-1.112</url>
      <bibkey>giaconia-etal-2024-topic</bibkey>
    </paper>
    <paper id="113">
      <title><fixed-case>IDRE</fixed-case>: <fixed-case>AI</fixed-case> Generated Dataset for Enhancing Empathetic Chatbot Interactions in <fixed-case>I</fixed-case>talian Language.</title>
      <author><first>Simone</first><last>Manai</last><affiliation>UNITN</affiliation></author>
      <author><first>Laura</first><last>Gemme</last><affiliation>Lutech-Softjam</affiliation></author>
      <author><first>Roberto</first><last>Zanoli</last><affiliation>Fondazione Bruno Kessler -FBK</affiliation></author>
      <author><first>Alberto</first><last>Lavelli</last><affiliation>FBK</affiliation></author>
      <pages>1036-1042</pages>
      <abstract>This paper introduces IDRE (Italian Dataset for Rephrasing with Empathy), a novel automatically generated Italian linguistic dataset. IDRE comprises typical chatbot user utterances in the healthcare domain, corresponding chatbot responses, and empathetically enhanced chatbot responses. The dataset was generated using the Llama2 language model and evaluated by human raters based on predefined metrics. The IDRE dataset offers a comprehensive and realistic collection of Italian chatbot-user interactions suitable for training and refining chatbot models in the healthcare domain. This facilitates the development of chatbots capable of natural and productive conversations with healthcare users. Notably, the dataset incorporates empathetically enhanced chatbot responses, enabling researchers to investigate the effects of empathetic language on fostering more positive and engaging human-machine interactions within healthcare settings. The methodology employed for the construction of the IDRE dataset can be extended to generate phrases in additional languages and domains, thereby expanding its applicability and utility. The IDRE dataset is publicly available for research purposes.</abstract>
      <url hash="a33b917e">2024.clicit-1.113</url>
      <bibkey>manai-etal-2024-idre</bibkey>
    </paper>
    <paper id="114">
      <title>Multimodal Online Manipulation: Empirical Analysis of Fact-Checking Reports</title>
      <author><first>Olga</first><last>Uryupina</last><affiliation>University of Trento</affiliation></author>
      <pages>1043-1048</pages>
      <abstract>This paper presents an in-depth exploratory quantitative study of the interaction between multimedia and textual components in online manipulative content. We discuss relations between content layers (such as proof or support) as well as unscrupulous techniques compromising visual content. The study is based on fakes reported and analyzed by PolitiFact and comprises documents from Facebook, Twitter and Instagram.</abstract>
      <url hash="dc3b0e61">2024.clicit-1.114</url>
      <bibkey>uryupina-2024-multimodal</bibkey>
    </paper>
    <paper id="115">
      <title>Life and Death of Fakes: On Data Persistence for Manipulative Social Media Content</title>
      <author><first>Olga</first><last>Uryupina</last><affiliation>University of Trento</affiliation></author>
      <pages>1049-1053</pages>
      <abstract>This work presents an in-depth investigation of the data decay for publicly fact-checked online content. We monitor compromised posts on major social media platforms for one year, tracking the changes in their visibility and availability. We show that data persistence is an important issue for manipulative content, on a larger scale than previously reported for online content in general. Our finding also suggest the (much) higher data decay rate for the platforms suffering most from online disinformation, indicating an important area for data collection/preservation.</abstract>
      <url hash="6333c5e9">2024.clicit-1.115</url>
      <bibkey>uryupina-2024-life</bibkey>
    </paper>
    <paper id="116">
      <title><fixed-case>CALAMITA</fixed-case>: Challenge the Abilities of <fixed-case>LA</fixed-case>nguage Models in <fixed-case>ITA</fixed-case>lian</title>
      <author><first>Giuseppe</first><last>Attanasio</last><affiliation>Instituto de Telecomunicacoes</affiliation></author>
      <author><first>Pierpaolo</first><last>Basile</last><affiliation>Department of Computer Science, University of Bari Aldo Moro</affiliation></author>
      <author><first>Federico</first><last>Borazio</last><affiliation>University of Roma, Tor Vergata</affiliation></author>
      <author><first>Danilo</first><last>Croce</last><affiliation>University of Roma, Tor Vergata</affiliation></author>
      <author><first>Maria</first><last>Francis</last><affiliation>University of Trento</affiliation></author>
      <author><first>Jacopo</first><last>Gili</last><affiliation>Università di Torino</affiliation></author>
      <author><first>Elio</first><last>Musacchio</last><affiliation>University of Bari / University of Pisa</affiliation></author>
      <author><first>Malvina</first><last>Nissim</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Viviana</first><last>Patti</last><affiliation>University of Turin, Dipartimento di Informatica</affiliation></author>
      <author><first>Matteo</first><last>Rinaldi</last><affiliation>Università di Torino</affiliation></author>
      <author><first>Daniel</first><last>Scalena</last><affiliation>University of Milano - Bicocca</affiliation></author>
      <pages>1054-1063</pages>
      <abstract>The rapid development of Large Language Models (LLMs) has called for robust benchmarks to assess their abilities, track progress, and compare iterations. While existing benchmarks provide extensive evaluations across diverse tasks, they predominantly focus on English, leaving other languages underserved. For Italian, the EVALITA campaigns have provided a long-standing tradition of classification-focused shared tasks. However, their scope does not fully align with the nuanced evaluation required for modern LLMs. To address this gap, we introduce “Challenge the Abilities of LAnguage Models in ITAlian” (CALAMITA), a collaborative effort to create a dynamic and growing benchmark tailored to Italian. CALAMITA emphasizes diversity in task design to test a wide range of LLM capabilities through resources natively developed in Italian by the community. This initiative includes a shared platform, live leaderboard, and centralized evaluation framework. This paper outlines the collaborative process, initial challenges, and evaluation framework of CALAMITA.</abstract>
      <url hash="7d29577d">2024.clicit-1.116</url>
      <bibkey>attanasio-etal-2024-calamita</bibkey>
    </paper>
    <paper id="117">
      <title><fixed-case>I</fixed-case>ta<fixed-case>E</fixed-case>val: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Giuseppe</first><last>Attanasio</last><affiliation>Instituto de Telecomunicacoes</affiliation></author>
      <author><first>Moreno</first><last>La Quatra</last><affiliation>Kore University of Enna</affiliation></author>
      <author><first>Andrea</first><last>Santilli</last><affiliation>Sapienza University of Rome</affiliation></author>
      <author><first>Beatrice</first><last>Savoldi</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <pages>1064-1073</pages>
      <abstract>In recent years, new language models for Italian have been spurring.However, evaluation methodologies for these models have not kept pace, remaining fragmented and often limited to the experimental sections of individual model releases. This paper introduces ItaEval, a multifaceted evaluation suite designed to address this gap. By reviewing recent literature on the evaluation of contemporary language models, we devise three overarching task categories—natural language understanding, commonsense and factual knowledge, and bias, fairness, and safety—that a contemporary model should be able to address. Next, we collect a set of 18 tasks encompassing existing and new datasets. The so-compiled ItaEval suite provides a standardized, multifaceted framework for evaluating Italian language models, facilitating more rigorous and comparative assessments of model performance. We release code and data at https://rita-nlp.org/sprints/itaeval.</abstract>
      <url hash="141ee9dd">2024.clicit-1.117</url>
      <bibkey>attanasio-etal-2024-itaeval-calamita</bibkey>
    </paper>
    <paper id="118">
      <title><fixed-case>PERSEID</fixed-case> - Perspectivist Irony Detection: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Valerio</first><last>Basile</last><affiliation>University of Turin</affiliation></author>
      <author><first>Silvia</first><last>Casola</last><affiliation>LMU Munich</affiliation></author>
      <author><first>Simona</first><last>Frenda</last><affiliation>Heriot-Watt University</affiliation></author>
      <author><first>Soda Marem</first><last>Lo</last><affiliation>University of Turin</affiliation></author>
      <pages>1074-1081</pages>
      <abstract>Works in perspectivism and human label variation have emphasized the need to collect and leverage various voices and points of view in the whole Natural Language Processing pipeline.PERSEID places itself in this line of work. We consider the task of irony detection from short social media conversations in Italian collected from Twitter (X) and Reddit. To do so, we leverage data from MultiPICO, a recent multilingual dataset with disaggregated annotations and annotators’ metadata, containing 1000 Post, Reply pairs with five annotations each on average.We aim to evaluate whether prompting LLMs with additional annotators’ demographic information (namely gender only, age only, and the combination of the two) results in improved performance compared to a baseline in which only the input text is provided.The evaluation is zero-shot; and we evaluate the results on the disaggregated annotations using f1.</abstract>
      <url hash="fda76bdf">2024.clicit-1.118</url>
      <bibkey>basile-etal-2024-perseid</bibkey>
    </paper>
    <paper id="119">
      <title><fixed-case>TRACE</fixed-case>-it: Testing Relative cl<fixed-case>A</fixed-case>uses Comprehension through Entailment in <fixed-case>IT</fixed-case>alian: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Dominique</first><last>Brunato</last><affiliation>Institute of Computational Linguistics “A. Zampolli” (ILC-CNR), Pisa</affiliation></author>
      <pages>1082-1088</pages>
      <abstract>Introduced in the context of CALAMITA 2024, TRACE-it (Testing Relative clAuses Comprehension through Entailment in ITalian) is a benchmark designed to evaluate the ability of Large Language Models (LLMs) to comprehend a specific type of complex syntactic construction in Italian: object relative clauses. In this report, we outline the theoretical framework that informed the creation of the dataset and provide a comprehensive overview of the linguistic materials used.</abstract>
      <url hash="77a62c2c">2024.clicit-1.119</url>
      <bibkey>brunato-2024-trace</bibkey>
    </paper>
    <paper id="120">
      <title><fixed-case>MAGNET</fixed-case> - <fixed-case>MA</fixed-case>chines <fixed-case>G</fixed-case>e<fixed-case>NE</fixed-case>rating Translations: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Mauro</first><last>Cettolo</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Andrea</first><last>Piergentili</last><affiliation>University of Trento</affiliation></author>
      <author><first>Sara</first><last>Papi</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Marco</first><last>Gaido</last><affiliation>Fondazione Bruno Kessler, University of Trento</affiliation></author>
      <author><first>Matteo</first><last>Negri</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Luisa</first><last>Bentivogli</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <pages>1089-1093</pages>
      <abstract>We propose MAGNET - MAchines GeNErating Translations, a CALAMITA Challenge which aims at testing the ability of large language models (LLMs) in the hot topic of automatic translation, focusing on Italian and English (in both directions) to overcome the marginality with which Italian is considered by the machine translation community. We propose a benchmark composed of two portions with different distribution policies (one free to use, the other not discloseable), allowing to handle data contamination issues. The publicly available section of the benchmark is distributed on Hugging Face, whereas in this report we describe the details of our challenge, including the prompt formats to be used. Additionally, we report the performance of five models, including a LLM and different sized translation models, in terms of four evaluation metrics, whose scores allow an overall evaluation of the quality of the automatically generated translations.</abstract>
      <url hash="8b9c4054">2024.clicit-1.120</url>
      <bibkey>cettolo-etal-2024-magnet</bibkey>
    </paper>
    <paper id="121">
      <title><fixed-case>GATTINA</fixed-case> - <fixed-case>G</fixed-case>ener<fixed-case>A</fixed-case>tion of <fixed-case>T</fixed-case>i<fixed-case>T</fixed-case>les for <fixed-case>I</fixed-case>talian News Articles: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Maria</first><last>Francis</last><affiliation/></author>
      <author><first>Matteo</first><last>Rinaldi</last><affiliation>Università di Torino</affiliation></author>
      <author><first>Jacopo</first><last>Gili</last><affiliation>Università di Torino</affiliation></author>
      <author><first>Leonardo</first><last>De Cosmo</last><affiliation>ANSA</affiliation></author>
      <author><first>Sandro</first><last>Iannaccone</last><affiliation>Galileo Net</affiliation></author>
      <author><first>Malvina</first><last>Nissim</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Viviana</first><last>Patti</last><affiliation>University of Turin, Dipartimento di Informatica</affiliation></author>
      <pages>1094-1105</pages>
      <abstract>We introduce a new benchmark designed to evaluate the ability of Large Language Models (LLMs) to generate Italian-language headlines for science news articles. The benchmark is based on a large dataset of science news articles obtained from Ansa Scienza and Galileo, two important Italian media outlets. Effective headline generation requires more than summarizing article content; headlines must also be informative, engaging, and suitable for the topic and target audience, making automatic evaluation particularly challenging. To address this, we propose two novel transformer-based metrics to assess headline quality. We aim for this benchmark to support the evaluation of Italian LLMs and to foster the development of tools to assist in editorial workflows.</abstract>
      <url hash="a2ad1b7f">2024.clicit-1.121</url>
      <bibkey>francis-etal-2024-gattina</bibkey>
    </paper>
    <paper id="122">
      <title><fixed-case>GFG</fixed-case> - Gender-Fair Generation: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Simona</first><last>Frenda</last><affiliation>Heriot-Watt University</affiliation></author>
      <author><first>Andrea</first><last>Piergentili</last><affiliation>University of Trento</affiliation></author>
      <author><first>Beatrice</first><last>Savoldi</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Marco</first><last>Madeddu</last><affiliation>University of Turin</affiliation></author>
      <author><first>Martina</first><last>Rosola</last><affiliation>Università degli Studi di Genova</affiliation></author>
      <author><first>Silvia</first><last>Casola</last><affiliation>LMU Munich</affiliation></author>
      <author><first>Chiara</first><last>Ferrando</last><affiliation>Università di Torino</affiliation></author>
      <author><first>Viviana</first><last>Patti</last><affiliation>University of Turin, Dipartimento di Informatica</affiliation></author>
      <author><first>Matteo</first><last>Negri</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Luisa</first><last>Bentivogli</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <pages>1106-1115</pages>
      <abstract>Gender-fair language aims at promoting gender equality by using terms and expressions that include all identities and avoid reinforcing gender stereotypes. Implementing gender-fair strategies is particularly challenging in heavily gender-marked languages, such as Italian. To address this, the Gender-Fair Generation challenge intends to help shift toward gender-fair language in written communication. The challenge, designed to assess and monitor the recognition and generation of gender-fair language in both mono- and cross-lingual scenarios, includes three tasks: (1) the detection of gendered expressions in Italian sentences, (2) the reformulation of gendered expressions into gender-fair alternatives, and (3) the generation of gender-fair language in automatic translation from English to Italian. The challenge relies on three different annotated datasets: the GFL-it corpus, which contains Italian texts extracted from administrative documents provided by the University of Brescia; GeNTE, a bilingual test set for gender-neutral rewriting and translation built upon a subset of the Europarl dataset; and Neo-GATE, a bilingual test set designed to assess the use of non-binary neomorphemes in Italian for both fairformulation and translation tasks. Finally, each task is evaluated with specific metrics: average of F1-score obtained by means of BERTScore computed on each entry of the datasets for task 1, an accuracy measured with a gender-neutral classifier, and a coverage-weighted accuracy for tasks 2 and 3.</abstract>
      <url hash="9f47f541">2024.clicit-1.122</url>
      <bibkey>frenda-etal-2024-gfg</bibkey>
    </paper>
    <paper id="123">
      <title><fixed-case>V</fixed-case>eryf<fixed-case>IT</fixed-case> - Benchmark of Fact-Checked Claims for <fixed-case>I</fixed-case>talian: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Jacopo</first><last>Gili</last><affiliation>Università di Torino</affiliation></author>
      <author><first>Viviana</first><last>Patti</last><affiliation>University of Turin, Dipartimento di Informatica</affiliation></author>
      <author><first>Lucia</first><last>Passaro</last><affiliation>University of Pisa</affiliation></author>
      <author><first>Tommaso</first><last>Caselli</last><affiliation>Rijksuniversiteit Groningen</affiliation></author>
      <pages>1116-1124</pages>
      <abstract>Achieving factual accuracy is a known pending issue for language models. Their design centered around the interactive component of user interaction and the extensive use of “spontaneous” training data, has made them highly adept at conversational tasks but not fully reliable in terms of factual correctness. VeryfIT addresses this issue by evaluating the in-memory factual knowledge of language models on data written by professional fact-checkers, posing it as a true or false question.Topics of the statements vary but most are in specific domains related to the Italian government, policies, and social issues. The task presents several challenges: extracting statements from segments of speeches, determining appropriate contextual relevance both temporally and factually, and ultimately verifying the accuracy of the statements.</abstract>
      <url hash="d2d30f25">2024.clicit-1.123</url>
      <bibkey>gili-etal-2024-veryfit</bibkey>
    </paper>
    <paper id="124">
      <title><fixed-case>AMELIA</fixed-case> - Argument Mining Evaluation on Legal documents in <fixed-case>I</fixed-case>t<fixed-case>A</fixed-case>lian: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Giulia</first><last>Grundler</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Andrea</first><last>Galassi</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Piera</first><last>Santin</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Alessia</first><last>Fidelangeli</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Federico</first><last>Galli</last><affiliation>CIRSFID-AI, University of Bologna</affiliation></author>
      <author><first>Elena</first><last>Palmieri</last><affiliation>Unibo</affiliation></author>
      <author><first>Francesca</first><last>Lagioia</last><affiliation>Cirsfid Alma-AI and Law department, University of Bologna, and Law Department, European University Institute</affiliation></author>
      <author><first>Giovanni</first><last>Sartor</last><affiliation>Cirsfid Alma-AI and Law department, University of Bologna, and Law Department, European University Institute</affiliation></author>
      <author><first>Paolo</first><last>Torroni</last><affiliation>Alma Mater - Università di Bologna</affiliation></author>
      <pages>1125-1134</pages>
      <abstract>This challenge consists of three classification tasks, in the context of argument mining in the legal domain. The tasks are based on a dataset of 225 Italian decisions on Value Added Tax, annotated to identify and categorize argumentative text. The objective of the first task is to classify each argumentative component as premise or conclusion, while the second and third tasks aim at classifying the type of premise: legal vs factual, and its corresponding argumentation scheme. The classes are highly unbalanced, hence evaluation is based on the macro F1 score.</abstract>
      <url hash="73f399cf">2024.clicit-1.124</url>
      <bibkey>grundler-etal-2024-amelia</bibkey>
    </paper>
    <paper id="125">
      <title><fixed-case>BLM</fixed-case>-It - Blackbird Language Matrices for <fixed-case>I</fixed-case>talian: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Chunyang</first><last>Jiang</last><affiliation>University of Geneva</affiliation></author>
      <author><first>Giuseppe</first><last>Samo</last><affiliation>University of Geneva</affiliation></author>
      <author><first>Vivi</first><last>Nastase</last><affiliation>University of Geneva</affiliation></author>
      <author><first>Paola</first><last>Merlo</last><affiliation>University of Geneva</affiliation></author>
      <pages>1135-1143</pages>
      <abstract>In this challenge, we propose Blackbird Language Matrices (BLMs), linguistic puzzles to learn language-related problems and delve into deeper formal and semantic properties of language, through a process of paradigm understanding. A BLM matrix consists of a context set and an answer set. The context is a sequence of sentences that encode implicitly an underlying generative linguistic rule. The contrastive multiple-choice answer set includes negative examples following corrupted generating rules. We propose three subtasks —agreement concord, causative and object-drop alternation detection— each in two variants of increasing lexical complexity.The datasets comprise a few prompts for few-shot learning and a large test set.</abstract>
      <url hash="9536975b">2024.clicit-1.125</url>
      <bibkey>jiang-etal-2024-blm</bibkey>
    </paper>
    <paper id="126">
      <title><fixed-case>DIMMI</fixed-case> - Drug <fixed-case>I</fixed-case>nfor<fixed-case>M</fixed-case>ation Mining in <fixed-case>I</fixed-case>talian: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Raffaele</first><last>Manna</last><affiliation>University of Naples “L’Orientale”</affiliation></author>
      <author><first>Maria Pia</first><last>Di Buono</last><affiliation>University of Naples “L’Orientale”</affiliation></author>
      <author><first>Luca</first><last>Giordano</last><affiliation>University of Naples “L’Orientale”</affiliation></author>
      <pages>1144-1152</pages>
      <abstract>Patients’ knowledge about drugs and medications is crucial as it allows them to administer them safely. This knowledgefrequently comes from written prescriptions, patient information leaflets (PILs), or from reading drug Web pages. DIMMI(Drug InforMation Mining in Italian) is a challenge aiming at evaluating the proficiency of Large Language Models in extractingdrug-specific information from PILs. The challenge seeks to advance the understanding of effectiveness in processing complexmedical information in Italian, and to enhance drug information extraction and pharmacovigilance efforts. Participants areprovided with a dataset of 600 Italian PILs and the objective is to develop models capable of accurately answering specificquestions related to drug dosage, usage, side effects, drug-drug interactions. The challenge should be approached as aninformation extraction task through a zero-shot mode, purely based on the model pre-existing knowledge and understandingor through in-context learning (Retrieval-Augmented Generation (RAG) or few-shot mode). The answers generated by themodels will be compared against the gold standard (GS), created to establish a reliable, accurate, and a comprehensive setof answers against which participant submissions can be evaluated. For each drug and each information category, the GScontains the correct information extracted from the leaflets through a manual annotation.</abstract>
      <url hash="238299b1">2024.clicit-1.126</url>
      <bibkey>manna-etal-2024-dimmi</bibkey>
    </paper>
    <paper id="127">
      <title><fixed-case>GITA</fixed-case>4<fixed-case>CALAMITA</fixed-case> - Evaluating the Physical Commonsense Understanding of <fixed-case>I</fixed-case>talian <fixed-case>LLM</fixed-case>s in a Multi-layered Approach: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Giulia</first><last>Pensa</last><affiliation>University of the Basque Country (UPV/EHU)</affiliation></author>
      <author><first>Ekhi</first><last>Azurmendi</last><affiliation>HiTZ Center - Ixa, University of the Basque Country UPV/EHU</affiliation></author>
      <author><first>Julen</first><last>Etxaniz</last><affiliation>HiTZ Center - Ixa, University of the Basque Country UPV/EHU</affiliation></author>
      <author><first>Begoña</first><last>Altuna</last><affiliation>Universidad del País Vasco - Euskal Herriko unibertsitatea</affiliation></author>
      <author><first>Itziar</first><last>Gonzalez-Dios</last><affiliation>HiTZ Basque Center for Language Technologies - Ixa, University of the Basque Country UPV/EHU</affiliation></author>
      <pages>1153-1160</pages>
      <abstract>In the context of the CALAMITA Challenge, we investigate the physical commonsense reasoning capabilities of large language models (LLMs) and introduce a methodology to assess their low-level understanding of the physical world. To this end, we use a test set designed to evaluate physical commonsense reasoning in LLMs for the Italian language. We present a tiered dataset, named the Graded Italian Annotated dataset (GITA), which is written and annotated by a professional linguist. This dataset enables us to focus on three distinct levels of commonsense understanding. Our benchmark aims to evaluate three specific tasks: identifying plausible and implausible stories within our dataset, identifying the conflict that generates an implausible story, and identifying the physical states that make a story implausible. We perform these tasks using LLAMA3, and Gemma. Our findings reveal that, although the models may excel at high-level classification tasks, their reasoning is inconsistent and unverifiable, as they fail to capture intermediate evidence.</abstract>
      <url hash="6ee3fa35">2024.clicit-1.127</url>
      <bibkey>pensa-etal-2024-gita4calamita</bibkey>
    </paper>
    <paper id="128">
      <title><fixed-case>ABRICOT</fixed-case> - <fixed-case>AB</fixed-case>st<fixed-case>R</fixed-case>actness and Inclusiveness in <fixed-case>CO</fixed-case>ntex<fixed-case>T</fixed-case>: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Giovanni</first><last>Puccetti</last><affiliation>information Science and Technologies Institute “A. Faedo”</affiliation></author>
      <author><first>Claudia</first><last>Collacciani</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Andrea Amelio</first><last>Ravelli</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Andrea</first><last>Esuli</last><affiliation>ISTI-CNR</affiliation></author>
      <author><first>Marianna</first><last>Bolognesi</last><affiliation>University of Bologna</affiliation></author>
      <pages>1161-1167</pages>
      <abstract>The ABRICOT Task is designed to evaluate Italian language models on their ability to understand and assess the abstractness and inclusiveness of language, two nuanced features that humans naturally convey in everyday communication. Unlike binary categorizations such as abstract/concrete or inclusive/exclusive, these features exist on a continuous spectrum with varying degrees of intensity. The task is based on a manual collection of sentences that present the same noun phrase (NP) in different contexts, allowing its interpretation to vary between the extremes of abstractness and inclusiveness. This challenge aims to verify the how LLMs perceive subtle linguistic variations and their implications in natural language.</abstract>
      <url hash="bb42571e">2024.clicit-1.128</url>
      <bibkey>puccetti-etal-2024-abricot</bibkey>
    </paper>
    <paper id="129">
      <title><fixed-case>INVALSI</fixed-case> - Mathematical and Language Understanding in <fixed-case>I</fixed-case>talian: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Giovanni</first><last>Puccetti</last><affiliation>information Science and Technologies Institute “A. Faedo”</affiliation></author>
      <author><first>Maria</first><last>Cassese</last><affiliation>ISTI - CNR</affiliation></author>
      <author><first>Andrea</first><last>Esuli</last><affiliation>ISTI-CNR</affiliation></author>
      <pages>1168-1175</pages>
      <abstract>While Italian is a high resource language, there are few Italian-native benchmarks to evaluate Language Models (LMs) generative abilities in this language. This work presents two new benchmarks: Invalsi MATE to evaluate models performance on mathematical understanding in Italian and Invalsi ITA to evaluate language understanding in Italian.These benchmarks are based on the Invalsi tests, which are administered to students of age between 6 and 18 within the Italian school system. These tests are prepared by expert pedagogists and have the explicit goal of testing average students’ performance over time across Italy. Therefore, the questions are well written, appropriate for the age of the students, and are developed with the goal of assessing students’ skills that are essential in the learning process, ensuring that the benchmark proposed here measures key knowledge for undergraduate students.Invalsi MATE is composed of 420 questions about mathematical understanding, these questions range from simple money counting problems to Cartesian geometry questions, e.g. determining if a point belongs to a given line. They are divided into 4 different types: scelta multipla (multiple choice), vero/falso (true/false), numero (number), completa frase (fill the gap). Invalsi ITA is composed of 1279 questions regarding language understanding, these questions involve both the ability to extract information and answer questions about a text passage as well as questions about grammatical knowledge. They are divided into 4 different types: scelta multipla (multiple choice), binaria (binary), domanda aperta (open question) and altro (other).We evaluate 4 powerful language models both English-first and tuned for Italian to see that best accuracy on Invalsi MATE is 55% while best accuracy on Invalsi ITA is 80%.</abstract>
      <url hash="8e72455f">2024.clicit-1.129</url>
      <bibkey>puccetti-etal-2024-invalsi</bibkey>
    </paper>
    <paper id="130">
      <title>Termite <fixed-case>I</fixed-case>talian Text-to-<fixed-case>SQL</fixed-case>: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Federico</first><last>Ranaldi</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <author><first>Elena Sofia</first><last>Ruzzetti</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <author><first>Dario</first><last>Onorati</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <author><first>Fabio Massimo</first><last>Zanzotto</last><affiliation>University of Rome Tor Vergata</affiliation></author>
      <author><first>Leonardo</first><last>Ranaldi</last><affiliation>UniTV</affiliation></author>
      <pages>1176-1183</pages>
      <abstract>We introduce Termite, which is a definitely unseen resource for evaluating Text-to-SQL in Italian. Specifically,we transfer evaluation pipelines beyond English, proposing novel, definitely unseen resources that avoid data-contamination phenomena while assessing the ability of models to perform Text-to-SQL tasks when natural language queries are written in Italian. We establish an evaluation grid based on execution accuracy.</abstract>
      <url hash="3dcc604a">2024.clicit-1.130</url>
      <bibkey>ranaldi-etal-2024-termite</bibkey>
    </paper>
    <paper id="131">
      <title>Mult-<fixed-case>IT</fixed-case> Multiple Choice Questions on Multiple Topics in <fixed-case>I</fixed-case>talian: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Matteo</first><last>Rinaldi</last><affiliation>Università di Torino</affiliation></author>
      <author><first>Jacopo</first><last>Gili</last><affiliation>Università di Torino</affiliation></author>
      <author><first>Maria</first><last>Francis</last><affiliation/></author>
      <author><first>Mattia</first><last>Goffetti</last><affiliation>Alpha Test s.r.l.</affiliation></author>
      <author><first>Viviana</first><last>Patti</last><affiliation>University of Turin, Dipartimento di Informatica</affiliation></author>
      <author><first>Malvina</first><last>Nissim</last><affiliation>University of Groningen</affiliation></author>
      <pages>1184-1201</pages>
      <abstract>Multi-choice question answering (MCQA) is a powerful tool for evaluating the factual knowledge and reasoning capacities of Large Language Models (LLMs). However, there is a lack of large-scale MCQA datasets originally written in Italian. Existing Italian MCQA benchmarks are often automatically translated from English, an approach with two key drawbacks: Firstly, automatic translations may sound unnatural, contain errors, or use linguistics constructions that do not align with the target language. Secondly, they may introduce topical and ideological biases reflecting Anglo-centric perspectives. To addressthis gap, we present Mult-IT, an MCQA dataset comprising over 110,000 manually written questions across a wide range of topics. All questions are sourced directly from preparation quizzes for Italian university entrance exams, or for exams for public sector employment in Italy. We are hopeful that this contribution enables a more comprehensive evaluation of LLMs’ proficiency, not only in the Italian language, but also in their grasp of Italian cultural and contextual knowledge.</abstract>
      <url hash="a4d4021b">2024.clicit-1.131</url>
      <bibkey>rinaldi-etal-2024-mult</bibkey>
    </paper>
    <paper id="132">
      <title><fixed-case>E</fixed-case>ureka<fixed-case>R</fixed-case>ebus - Verbalized Rebus Solving with <fixed-case>LLM</fixed-case>s: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Gabriele</first><last>Sarti</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Tommaso</first><last>Caselli</last><affiliation>Rijksuniversiteit Groningen</affiliation></author>
      <author><first>Arianna</first><last>Bisazza</last><affiliation>University of Groningen</affiliation></author>
      <author><first>Malvina</first><last>Nissim</last><affiliation>University of Groningen</affiliation></author>
      <pages>1202-1208</pages>
      <abstract>Language games can be valuable resources for testing the ability of large language models (LLMs) to conduct challenging multi-step, knowledge-intensive inferences while respecting predefined constraints. Our proposed challenge prompts LLMs to reason step-by-step to solve verbalized variants of rebus games recently introduced with the EurekaRebus dataset. Verbalized rebuses replace visual cues with crossword definitions to create an encrypted first pass, making the problem entirely text-based. We introduce a simplified task variant with word length hints and adopt a comprehensive set of metrics to obtain a granular overview of models’ performance in knowledge recall, constraints adherence, and re-segmentation abilities across reasoning steps.</abstract>
      <url hash="f88cd69f">2024.clicit-1.132</url>
      <bibkey>sarti-etal-2024-eurekarebus</bibkey>
    </paper>
    <paper id="133">
      <title><fixed-case>GEESE</fixed-case> - Generating and Evaluating Explanations for Semantic Entailment: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Andrea</first><last>Zaninello</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Bernardo</first><last>Magnini</last><affiliation>FBK</affiliation></author>
      <pages>1209-1216</pages>
      <abstract>In the GEESE challenge, we present a pipeline to evaluate generated explanations for the task of Recognizing Textual Entailment (RTE) in Italian. The challenge focuses on evaluating the impact of generated explanations on the predictive performance of language models. Using a dataset enriched with human-written explanations, we employ two large language models (LLMs) to generate and utilize explanations for semantic relationships between sentence pairs. Our methodology assesses the quality of generated explanations by measuring changes in prediction accuracy when explanations are provided. Through reproducible experimentation, we establish benchmarks against various baseline approaches, demonstrating the potential of explanation injection to enhance model interpretability and performance.</abstract>
      <url hash="e2fae932">2024.clicit-1.133</url>
      <bibkey>zaninello-magnini-2024-geese</bibkey>
    </paper>
    <paper id="134">
      <title><fixed-case>ITA</fixed-case>-<fixed-case>SENSE</fixed-case> - Evaluate <fixed-case>LLM</fixed-case>s’ ability for <fixed-case>ITA</fixed-case>lian word <fixed-case>SENSE</fixed-case> disambiguation: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Pierpaolo</first><last>Basile</last><affiliation>Department of Computer Science, University of Bari Aldo Moro</affiliation></author>
      <author><first>Elio</first><last>Musacchio</last><affiliation>University of Bari / University of Pisa</affiliation></author>
      <author><first>Lucia</first><last>Siciliani</last><affiliation>University of Bari Aldo Moro</affiliation></author>
      <pages>1217-1221</pages>
      <abstract>The challenge is designed to assess LLMs’ abilities in understanding lexical semantics through Word Sense Disambiguation, providing valuable insights into their performance.The idea is to cast the classical Word Sense Disambiguation task in a generative problem following two directions. Our idea is to propose two tasks: (T1) Given a target word and a sentence in which the word occurs, the LLM must generate the correct meaning definition, (T2) Given a target word and a sentence in which the word occurs, the LLM should choose from a predefined set the correct meaning definition.For T1, we compare the generated definition with respect to the correct one taken from a sense inventory, while for T2, a classical accuracy metric is used.In T1, we adopt metrics that measures the quality of the generated definition such as RougeL and the BERTscore.For CALAMITA, we test LLMs using a zero-shot setting.</abstract>
      <url hash="d0e2c494">2024.clicit-1.134</url>
      <bibkey>basile-etal-2024-ita</bibkey>
    </paper>
    <paper id="135">
      <title><fixed-case>BEEP</fixed-case> - <fixed-case>BE</fixed-case>st <fixed-case>D</fixed-case>riv<fixed-case>E</fixed-case>r’s License Performer: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Fabio</first><last>Mercorio</last><affiliation>University of Milan-Bicocca</affiliation></author>
      <author><first>Daniele</first><last>Potertì</last><affiliation>University of Milan-Bicocca</affiliation></author>
      <author><first>Antonio</first><last>Serino</last><affiliation>University of Milano-Bicocca</affiliation></author>
      <author><first>Andrea</first><last>Seveso</last><affiliation>University of Milano-Bicocca</affiliation></author>
      <pages>1222-1227</pages>
      <abstract>We present BEEP (BEst DrivEr’s License Performer), a benchmark challenge to evaluate large language models in the context of a simulated Italian driver’s license exam. This challenge tests the models’ ability to understand and apply traffic laws, road safety regulations, and vehicle-related knowledge through a series of true/false questions. The dataset is derived from official ministerial materials used in the Italian licensing process, specifically targeting Category B licenses.We evaluate models such as LLaMA and Mixtral across multiple categories. In addition, we simulate a driving license test to assess the models’ real-world applicability, where the pass rate is determined based on the number of errors allowed. While scaling up model size improved performance, even larger models struggled to pass the exam consistently. The challenge demonstrates the capabilities and limitations of LLMs in handling real-world, high-stakes scenarios, providing insights into their practical use and areas for further improvement.</abstract>
      <url hash="6112f01e">2024.clicit-1.135</url>
      <bibkey>mercorio-etal-2024-beep</bibkey>
    </paper>
    <paper id="136">
      <title><fixed-case>P</fixed-case>ejorativ<fixed-case>IT</fixed-case>y - In-Context Pejorative Language Disambiguation: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Arianna</first><last>Muti</last><affiliation>University of Bologna</affiliation></author>
      <pages>1228-1233</pages>
      <abstract>Misogyny is often expressed through figurative language. Some neutral words can assume a negative connotation when functioning as pejorative epithets, and they can be used to express misogyny. Disambiguating the meaning of such terms might help the detection of misogyny. This challenge addresses a) the disambiguation of specific ambiguous words in a given context; b) the detection of misogyny in instances that contain such polysemic words. In particular, framed as a binary classification, our task is divided into two parts. In Task A, the model is asked to define if, given a tweet, the target word is used in pejorative or non-pejorative way. In Task B, the model is asked whether the whole sentence is misogynous or not.</abstract>
      <url hash="72ba07ea">2024.clicit-1.136</url>
      <bibkey>muti-2024-pejorativity</bibkey>
    </paper>
    <paper id="137">
      <title><fixed-case>MACID</fixed-case> - Multimodal <fixed-case>AC</fixed-case>tion <fixed-case>ID</fixed-case>entification: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Andrea Amelio</first><last>Ravelli</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Rossella</first><last>Varvara</last><affiliation>University of Pavia</affiliation></author>
      <author><first>Lorenzo</first><last>Gregori</last><affiliation>University of Florence</affiliation></author>
      <pages>1234-1238</pages>
      <abstract>This paper presents the Multimodal ACtion IDentification challenge (MACID), part of the first CALAMITA competition. The objective of this task is to evaluate the ability of large language models (LLMs) to differentiate between closely related action concepts based on textual descriptions alone. The challenge is inspired by the “find the intruder” task, where models must identify an outlier among a set of 4 sentences that describe similar yet distinct actions. The dataset highlights action-predicate mismatches, where the same verb may describe different actions or different verbs may refer to the same action. Although currently mono-modal (text-only), the task is designed for future multimodal integration, linking visual and textual representations to enhance action recognition. By probing a model’s capacity to resolve subtle linguistic ambiguities, the challenge underscores the need for deeper cognitive understanding in action-language alignment, ultimately testing the boundaries of LLMs’ ability to interpret action verbs and their associated concepts.</abstract>
      <url hash="8a2d699a">2024.clicit-1.137</url>
      <bibkey>ravelli-etal-2024-macid</bibkey>
    </paper>
    <paper id="138">
      <title><fixed-case>ECWCA</fixed-case> - Educational <fixed-case>C</fixed-case>ross<fixed-case>W</fixed-case>ord Clues Answering: A <fixed-case>CALAMITA</fixed-case> Challenge</title>
      <author><first>Andrea</first><last>Zugarini</last><affiliation>Expert.ai</affiliation></author>
      <author><first>Kamyar</first><last>Zeinalipour</last><affiliation>University of Siena</affiliation></author>
      <author><first>Achille</first><last>Fusco</last><affiliation>IUSS Pavia</affiliation></author>
      <author><first>Asya</first><last>Zanollo</last><affiliation>IUSS Pavia</affiliation></author>
      <pages>1239-1244</pages>
      <abstract>This paper presents ECWCA (Educational CrossWord Clues Answering), a novel challenge designed to evaluate knowledge and reasoning capabilities of large language models through crossword clue-answering. The challenge consists of two tasks: a standard question-answering format where the LLM has to solve crossword clues, and a variation of it, where the model is receives hints about the word lengths of the answers, which is expected to help models with reasoning abilities. To construct the ECWCA dataset, synthetic clues were generated based on entities and facts extracted from Italian Wikipedia. Generated clues were then selected manually in order to ensure high-quality examples with factually correct and unambiguous clues.</abstract>
      <url hash="67c8ec97">2024.clicit-1.138</url>
      <bibkey>zugarini-etal-2024-ecwca</bibkey>
    </paper>
  </volume>
</collection>
