<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.ecnlp">
  <volume id="1" ingest-date="2024-05-18" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Seventh Workshop on e-Commerce and NLP @ LREC-COLING 2024</booktitle>
      <editor id="shervin-malmasi"><first>Shervin</first><last>Malmasi</last></editor>
      <editor><first>Besnik</first><last>Fetahu</last></editor>
      <editor><first>Nicola</first><last>Ueffing</last></editor>
      <editor><first>Oleg</first><last>Rokhlenko</last></editor>
      <editor><first>Eugene</first><last>Agichtein</last></editor>
      <editor><first>Ido</first><last>Guy</last></editor>
      <publisher>ELRA and ICCL</publisher>
      <address>Torino, Italia</address>
      <month>May</month>
      <year>2024</year>
      <url hash="9af0bd83">2024.ecnlp-1</url>
      <venue>ecnlp</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="bedf2395">2024.ecnlp-1.0</url>
      <bibkey>ecnlp-2024-e</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Learning Reasons for Product Returns on <fixed-case>E</fixed-case>-Commerce</title>
      <author><first>Miriam</first><last>Farber</last></author>
      <author><first>Slava</first><last>Novgorodov</last></author>
      <author><first>Ido</first><last>Guy</last></author>
      <pages>1–7</pages>
      <abstract>In the rapidly evolving landscape of e-commerce, product returns have become a significant economic burden for businesses, where the reasons for returns may vary from wrong sizing and defective products to simply no longer needing the purchased product. This paper presents, to the best of our knowledge, the first comprehensive study of the complexities of product returns across a variety of e-commerce domains, focusing on the task of predicting the return reason. We propose a supervised approach for predicting return likelihood and the underlying return reason. We test our approach over a real-world dataset from a large e-commerce platform.</abstract>
      <url hash="c007e5b3">2024.ecnlp-1.1</url>
      <bibkey>farber-etal-2024-learning</bibkey>
    </paper>
    <paper id="2">
      <title>Towards Multi-Modal Co-Reference Resolution in Conversational Shopping Agents</title>
      <author><first>Samuel</first><last>Osebe</last></author>
      <author><first>Prashan</first><last>Wanigasekara</last></author>
      <author><first>Thomas</first><last>Gueudre</last></author>
      <author><first>Thanh</first><last>Tran</last></author>
      <author><first>Rahul</first><last>Sharma</last></author>
      <author><first>Fan</first><last>Yang</last></author>
      <author><first>Qian</first><last>Hu</last></author>
      <author><first>Weitong</first><last>Ruan</last></author>
      <author><first>Emre</first><last>Barut</last></author>
      <author><first>Chengwei</first><last>Su</last></author>
      <pages>8–18</pages>
      <abstract>The context of modern smart voice assistants is often multi-modal, where images, audio and video content are consumed by users simultaneously. In such a setup, co-reference resolution is especially challenging, and runs across modalities and dialogue turns. We explore the problem of multi-modal co-reference resolution in multi-turn dialogues and quantify the performance of multi-modal LLMs on a specially curated dataset of long, image-interleaved conversations between a voice assistant and human in a shopping use case. We propose a custom architecture for multi-modal embedding alignment using a novel parameter augmentation technique. Our proposed Parameter Augmented LLM approach shows a 4.9% absolute F1 improvement above a cross-attention baseline while reducing the number of parameters being trained by 4x.</abstract>
      <url hash="a97d6f86">2024.ecnlp-1.2</url>
      <bibkey>osebe-etal-2024-towards</bibkey>
    </paper>
    <paper id="3">
      <title>Efficient and Interpretable Information Retrieval for Product Question Answering with Heterogeneous Data</title>
      <author><first>Biplob</first><last>Biswas</last></author>
      <author><first>Rajiv</first><last>Ramnath</last></author>
      <pages>19–28</pages>
      <abstract>Expansion-enhanced sparse lexical representation improves information retrieval (IR) by minimizing vocabulary mismatch problems during lexical matching. In this paper, we explore the potential of jointly learning dense semantic representation and combining it with the lexical one for ranking candidate information. We present a hybrid information retrieval mechanism that maximizes lexical and semantic matching while minimizing their shortcomings. Our architecture consists of dual hybrid encoders that independently encode queries and information elements. Each encoder jointly learns a dense semantic representation and a sparse lexical representation augmented by a learnable term expansion of the corresponding text through contrastive learning. We demonstrate the efficacy of our model in single-stage ranking of a benchmark product question-answering dataset containing the typical heterogeneous information available on online product pages. Our evaluation demonstrates that our hybrid approach outperforms independently trained retrievers by 10.95% (sparse) and 2.7% (dense) in MRR@5 score. Moreover, our model offers better interpretability and performs comparably to state-of-the-art cross-encoders while reducing response time by 30% (latency) and cutting computational load by approximately 38% (FLOPs).</abstract>
      <url hash="d893edc9">2024.ecnlp-1.3</url>
      <bibkey>biswas-ramnath-2024-efficient</bibkey>
    </paper>
    <paper id="4">
      <title>Hallucination Detection in <fixed-case>LLM</fixed-case>-enriched Product Listings</title>
      <author><first>Ling</first><last>Jiang</last></author>
      <author><first>Keer</first><last>Jiang</last></author>
      <author><first>Xiaoyu</first><last>Chu</last></author>
      <author><first>Saaransh</first><last>Gulati</last></author>
      <author><first>Pulkit</first><last>Garg</last></author>
      <pages>29–39</pages>
      <abstract>E-commerce faces persistent challenges with data quality issue of product listings. Recent advances in Large Language Models (LLMs) offer a promising avenue for automated product listing enrichment. However, LLMs are prone to hallucinations, which we define as the generation of content that is unfaithful to the source input. This poses significant risks in customer-facing applications. Hallucination detection is particularly challenging in the vast e-commerce domain, where billions of products are sold. In this paper, we propose a two-phase approach for detecting hallucinations in LLM-enriched product listings. The first phase prioritizes recall through cost-effective unsupervised techniques. The second phase maximizes precision by leveraging LLMs to validate candidate hallucinations detected in phase one. The first phase significantly reduces the inference space and enables the resource-intensive methods in the second phase to scale effectively. Experiments on two real-world datasets demonstrated that our approach achieved satisfactory recall on unstructured product attributes with suboptimal precision, primarily due to the inherent ambiguity of unstructured attributes and the presence of common sense reasoning. This highlights the necessity for a refined approach to distinguish between common sense and hallucination. On structured attributes with clearly de- fined hallucinations, our approach effectively detected hallucinations with precision and recall surpassing targeted level.</abstract>
      <url hash="6d2d846b">2024.ecnlp-1.4</url>
      <bibkey>jiang-etal-2024-hallucination</bibkey>
    </paper>
    <paper id="5">
      <title>Self-Improving Customer Review Response Generation Based on <fixed-case>LLM</fixed-case>s</title>
      <author><first>Guy</first><last>Azov</last></author>
      <author><first>Tatiana</first><last>Pelc</last></author>
      <author><first>Adi</first><last>Fledel Alon</last></author>
      <author><first>Gila</first><last>Kamhi</last></author>
      <pages>40–57</pages>
      <abstract>Previous studies have demonstrated that proactive interaction with user reviews has a positive impact on the perception of app users and encourages them to submit revised ratings. Nevertheless, developers encounter challenges in managing a high volume of reviews, particularly in the case of popular apps with a substantial influx of daily reviews. Consequently, there is a demand for automated solutions aimed at streamlining the process of responding to user reviews. To address this, we have developed a new system for generating automatic responses by leveraging user-contributed documents with the help of retrieval-augmented generation (RAG) and advanced Large Language Models (LLMs). Our solution, named SCRABLE, represents an adaptive customer review response automation that enhances itself with self-optimizing prompts and a judging mechanism based on LLMs. Additionally, we introduce an automatic scoring mechanism that mimics the role of a human evaluator to assess the quality of responses generated in customer review domains. Extensive experiments and analyses conducted on real-world datasets reveal that our method is effective in producing high-quality responses, yielding improvement of more than 8.5% compared to the baseline. Further validation through manual examination of the generated responses underscores the efficacy our proposed system.</abstract>
      <url hash="fba9d124">2024.ecnlp-1.5</url>
      <bibkey>azov-etal-2024-self</bibkey>
    </paper>
    <paper id="6">
      <title>Don’t Just Translate, Summarize Too: Cross-lingual Product Title Generation in <fixed-case>E</fixed-case>-commerce</title>
      <author><first>Bryan</first><last>Zhang</last></author>
      <author><first>Taichi</first><last>Nakatani</last></author>
      <author><first>Daniel Vidal</first><last>Hussey</last></author>
      <author><first>Stephan</first><last>Walter</last></author>
      <author><first>Liling</first><last>Tan</last></author>
      <pages>58–64</pages>
      <abstract>Making product titles informative and concise is vital to delighting e-commerce customers. Recent advances have successfully applied monolingual product title summarization to shorten lengthy product titles. This paper explores the cross-lingual product title generation task that summarizes and translates the source language product title to a shortened product title in the target language. Our main contributions are as follows, (i) we investigate the optimal product title length within the scope of e-commerce localization, (ii) we introduce a simple yet effective data filtering technique to train a length-aware machine translation system and compare it to a publicly available LLM, (iii) we propose an automatic approach to validate experimental results using an open-source LLM without human input and show that these evaluation results are consistent with human preferences.</abstract>
      <url hash="b1fe9323">2024.ecnlp-1.6</url>
      <bibkey>zhang-etal-2024-dont</bibkey>
    </paper>
    <paper id="7">
      <title><fixed-case>T</fixed-case>urkish Typo Correction for <fixed-case>E</fixed-case>-Commerce Search Engines</title>
      <author><first>Elif</first><last>Oral</last></author>
      <author><first>Koray</first><last>Mancuhan</last></author>
      <author><first>Hüseyin Varol</first><last>Erdem</last></author>
      <author><first>Pınar Ece</first><last>Hatipoglu</last></author>
      <pages>65–73</pages>
      <abstract>Typo correction is a challenging problem when it is developed for morphologically rich languages. The existing approaches in the literature are successful mainly for English, leaving the problem open for such languages. This creates an issue, because the typo correction is a critical component in practice for many systems such as search engines. Especially, the search engines of e-commerce platforms rely heavily on typo correction for product relevancy. A bad performing typo corrector could result in very few number of relevant products when a user is looking for a product on an e-commerce platform, resulting in significant revenue decrease. For the first time in the literature, this paper proposes a modern typo corrector for a morphologically rich language, Turkish; which is integrated to the search engine of one of the leading e-commerce platforms in Turkey, Hepsiburada. Our thorough experiments show that this new typo corrector performs very successful in practice, outperforming the existing Turkish specific propositions in the literature; even if it is applied out of the context of the search engines.</abstract>
      <url hash="b829cbc3">2024.ecnlp-1.7</url>
      <bibkey>oral-etal-2024-turkish</bibkey>
    </paper>
    <paper id="8">
      <title>Detecting <fixed-case>AI</fixed-case>-enhanced Opinion Spambots: a study on <fixed-case>LLM</fixed-case>-generated Hotel Reviews</title>
      <author><first>Vijini</first><last>Liyanage</last></author>
      <author><first>Davide</first><last>Buscaldi</last></author>
      <author><first>Penelope</first><last>Forcioli</last></author>
      <pages>74–78</pages>
      <abstract>Opinion spamming is the posting of fake opinions or reviews to promote or discredit target products, services, or individuals. The concern surrounding this activity has grown steadily especially because of the development of automated bots for this purpose (“spambots”). Nowadays, Large Language Models (LLMs) have proved their ability to generate text that is almost indistinguishable from human-written text. Therefore, there is a growing concern regarding the use of these models for malicious purposes, among them opinion spamming. In this paper, we carry out a study on LLM-generated reviews, in particular hotel reviews as we chose the well-known Opinion Spam corpus by Myle Ott as the seed for our dataset. We generated a set of fake reviews with various models and applied different classification algorithms to verify how difficult is it to detect this kind of generated content. The results show that by providing enough training data, it is not difficult to detect the fake reviews generated by such models, as they tend to associate the aspects in the reviews with the same attributes.</abstract>
      <url hash="ea53ee24">2024.ecnlp-1.8</url>
      <bibkey>liyanage-etal-2024-detecting</bibkey>
    </paper>
    <paper id="9">
      <title>Assessing Image-Captioning Models: A Novel Framework Integrating Statistical Analysis and Metric Patterns</title>
      <author><first>Qiaomu</first><last>Li</last></author>
      <author><first>Ying</first><last>Xie</last></author>
      <author><first>Nina</first><last>Grundlingh</last></author>
      <author><first>Varsha Rani</first><last>Chawan</last></author>
      <author><first>Cody</first><last>Wang</last></author>
      <pages>79–87</pages>
      <abstract>In this study, we present a novel evaluation framework for image-captioning models that integrate statistical analysis with common evaluation metrics, utilizing two popular datasets, FashionGen and Amazon, with contrasting dataset variation to evaluate four models: Video-LLaVa, BLIP, CoCa and ViT-GPT2. Our approach not only reveals the comparative strengths of models, offering insights into their adaptability and applicability in real-world scenarios but also contributes to the field by providing a comprehensive evaluation method that considers both statistical significance and practical relevance to guide the selection of models for specific applications. Specifically, we propose Rank Score as a new evaluation metric that is designed for e-commerce image search applications and employ CLIP Score to quantify dataset variation to offer a holistic view of model performance.</abstract>
      <url hash="bdedb76e">2024.ecnlp-1.9</url>
      <bibkey>li-etal-2024-assessing</bibkey>
    </paper>
    <paper id="10">
      <title>Frogs into princes: A generative model to understand the success of product descriptions</title>
      <author><first>Takehiro</first><last>Takayanagi</last></author>
      <author><first>Bruno</first><last>Charron</last></author>
      <author><first>Marco</first><last>Visentini-Scarzanella</last></author>
      <pages>88–96</pages>
      <abstract>In the dynamic marketplace, vendors continuously seek innovative ideas for new products and ways to improve existing ones. These ideas can be uncovered by analyzing text data, such as product descriptions and customer reviews. However, the ever-increasing volume of text data poses a challenge in extracting meaningful insights. Therefore, this study addresses the challenge of extracting actionable insights from the growing volume of text data, with a specific focus on product descriptions. To this end, we investigate two primary research questions: the predictive power of product descriptions for product success, and the capability of style transfer to highlight the successful factors of these descriptions. In response to the first question, our findings validate that product descriptions are indeed reliable indicators of product success. Addressing our second question, we propose a Successful Style Transfer Variational Autoencoder (SST-VAE), a VAE-based language model designed for effective successful style transfer. Qualitative analysis indicates that the SST-VAE effectively enables successful style transfer conditional on a given label. In addition, case studies suggest that the proposed approach could be useful in gaining insights about product success, by highlighting key factors that may contribute to their success. On the other hand, our approach confronts issues such as hallucinations and the need for factual accuracy. These challenges underscore the necessity for continued research in the field of e-commerce natural language processing.</abstract>
      <url hash="93eb2dc5">2024.ecnlp-1.10</url>
      <bibkey>takayanagi-etal-2024-frogs</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>STA</fixed-case>: Self-controlled Text Augmentation for Improving Text Classifications</title>
      <author><first>Congcong</first><last>Wang</last></author>
      <author><first>Gonzalo</first><last>Fiz Pontiveros</last></author>
      <author><first>Steven</first><last>Derby</last></author>
      <author><first>Tri</first><last>Kurniawan Wijaya</last></author>
      <pages>97–114</pages>
      <abstract>Despite recent advancements in Machine Learning, many tasks still involve working in low-data regimes which can make solving natural language problems difficult. Recently, a number of text augmentation techniques have emerged in the field of Natural Language Processing (NLP) which can enrich the training data with new examples, though they are not without their caveats. For instance, simple rule-based heuristic methods are effective, but lack variation in semantic content and syntactic structure with respect to the original text. On the other hand, more complex deep learning approaches can cause extreme shifts in the intrinsic meaning of the text and introduce unwanted noise into the training data. To more reliably control the quality of the augmented examples, we introduce a state-of-the-art approach for Self-Controlled Text Augmentation (STA). Our approach tightly controls the generation process by introducing a self-checking procedure to ensure that generated examples retain the semantic content of the original text. Experimental results on multiple benchmarking datasets demonstrate that STA substantially outperforms existing state-of-the-art techniques, whilst qualitative analysis reveals that the generated examples are both lexically diverse and semantically reliable.</abstract>
      <url hash="006cf33f">2024.ecnlp-1.11</url>
      <bibkey>wang-etal-2024-sta</bibkey>
    </paper>
    <paper id="12">
      <title>Multi-word Term Embeddings Improve Lexical Product Retrieval</title>
      <author><first>Viktor</first><last>Shcherbakov</last></author>
      <author><first>Fedor</first><last>Krasnov</last></author>
      <pages>115–124</pages>
      <abstract>Product search is uniquely different from search for documents, Internet resources or vacancies, therefore it requires the development of specialized search systems. The present work describes the H1 embdedding model, designed for an offline term indexing of product descriptions at e-commerce platforms. The model is compared to other state-of-the-art (SoTA) embedding models within a framework of hybrid product search system that incorporates the advantages of lexical methods for product retrieval and semantic embedding-based methods. We propose an approach to building semantically rich term vocabularies for search indexes. Compared to other production semantic models, H1 paired with the proposed approach stands out due to its ability to process multi-word product terms as one token. As an example, for search queries “new balance shoes”, “gloria jeans kids wear” brand entity will be represented as one token - “new balance”, “gloria jeans”. This results in an increased precision of the system without affecting the recall. The hybrid search system with proposed model scores mAP@12 = 56.1% and R@1k = 86.6% on the WANDS public dataset, beating other SoTA analogues.</abstract>
      <url hash="4f2462c5">2024.ecnlp-1.12</url>
      <bibkey>shcherbakov-krasnov-2024-multi</bibkey>
    </paper>
    <paper id="13">
      <title>Explicit Attribute Extraction in e-Commerce Search</title>
      <author><first>Robyn</first><last>Loughnane</last></author>
      <author><first>Jiaxin</first><last>Liu</last></author>
      <author><first>Zhilin</first><last>Chen</last></author>
      <author><first>Zhiqi</first><last>Wang</last></author>
      <author><first>Joseph</first><last>Giroux</last></author>
      <author><first>Tianchuan</first><last>Du</last></author>
      <author><first>Benjamin</first><last>Schroeder</last></author>
      <author><first>Weiyi</first><last>Sun</last></author>
      <pages>125–135</pages>
      <abstract>This paper presents a model architecture and training pipeline for attribute value extraction from search queries. The model uses weak labels generated from customer interactions to train a transformer-based NER model. A two-stage normalization process is then applied to deal with the problem of a large label space: first, the model output is normalized onto common generic attribute values, then it is mapped onto a larger range of actual product attribute values. This approach lets us successfully apply a transformer-based NER model to the extraction of a broad range of attribute values in a real-time production environment for e-commerce applications, contrary to previous research. In an online test, we demonstrate business value by integrating the model into a system for semantic product retrieval and ranking.</abstract>
      <url hash="31266768">2024.ecnlp-1.13</url>
      <bibkey>loughnane-etal-2024-explicit</bibkey>
      <revision id="1" href="2024.ecnlp-1.13v1" hash="c365fde8"/>
      <revision id="2" href="2024.ecnlp-1.13v2" hash="31266768" date="2024-05-30">Added references.</revision>
    </paper>
    <paper id="14">
      <title><fixed-case>TAAL</fixed-case>: Target-Aware Active Learning</title>
      <author><first>Kunal</first><last>Kotian</last></author>
      <author><first>Indranil</first><last>Bhattacharya</last></author>
      <author><first>Shikhar</first><last>Gupta</last></author>
      <author><first>Kaushik</first><last>Pavani</last></author>
      <author><first>Naval</first><last>Bhandari</last></author>
      <author><first>Sunny</first><last>Dasgupta</last></author>
      <pages>136–144</pages>
      <abstract>Pool-based active learning techniques have had success producing multi-class classifiers that achieve high accuracy with fewer labels com- pared to random labeling. However, in an industrial setting where we often have class-level business targets to achieve (e.g., 95% recall at 95% precision for each class), active learning techniques continue to acquire labels for classes that have already met their targets, thus consuming unnecessary manual annotations. We address this problem by proposing a framework called Target-Aware Active Learning that converts any active learning query strategy into its target-aware variant by leveraging the gap between each class’ current estimated accuracy and its corresponding business target. We show empirically that target-aware variants of state-of-the-art active learning techniques achieve business targets faster on 2 open-source image classification datasets and 2 proprietary product classification datasets.</abstract>
      <url hash="db3bb60c">2024.ecnlp-1.14</url>
      <bibkey>kotian-etal-2024-taal</bibkey>
    </paper>
    <paper id="15">
      <title>Cluster Language Model for Improved <fixed-case>E</fixed-case>-Commerce Retrieval and Ranking: Leveraging Query Similarity and Fine-Tuning for Personalized Results</title>
      <author><first>Duleep</first><last>Rathgamage Don</last></author>
      <author><first>Ying</first><last>Xie</last></author>
      <author><first>Le</first><last>Yu</last></author>
      <author><first>Simon</first><last>Hughes</last></author>
      <author><first>Yun</first><last>Zhu</last></author>
      <pages>145–153</pages>
      <abstract>This paper proposes a novel method to improve the accuracy of product search in e-commerce by utilizing a cluster language model. The method aims to address the limitations of the bi-encoder architecture while maintaining a minimal additional training burden. The approach involves labeling top products for each query, generating semantically similar query clusters using the K-Means clustering algorithm, and fine-tuning a global language model into cluster language models on individual clusters. The parameters of each cluster language model are fine-tuned to learn local manifolds in the feature space efficiently, capturing the nuances of various query types within each cluster. The inference is performed by assigning a new query to its respective cluster and utilizing the corresponding cluster language model for retrieval. The proposed method results in more accurate and personalized retrieval results, offering a superior alternative to the popular bi-encoder based retrieval models in semantic search.</abstract>
      <url hash="c59d7459">2024.ecnlp-1.15</url>
      <bibkey>rathgamage-don-etal-2024-cluster</bibkey>
    </paper>
  </volume>
</collection>
