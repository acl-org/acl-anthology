<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.africanlp">
  <volume id="1" ingest-date="2025-07-18" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Sixth Workshop on African Natural Language Processing (AfricaNLP 2025)</booktitle>
      <editor><first>Constantine</first><last>Lignos</last></editor>
      <editor><first>Idris</first><last>Abdulmumin</last></editor>
      <editor><first>David</first><last>Adelani</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vienna, Austria</address>
      <month>July</month>
      <year>2025</year>
      <url hash="68761bdd">2025.africanlp-1</url>
      <venue>africanlp</venue>
      <venue>ws</venue>
      <isbn>979-8-89176-257-2</isbn>
      <doi>10.18653/v1/2025.africanlp-1</doi>
    </meta>
    <frontmatter>
      <url hash="047cc38e">2025.africanlp-1.0</url>
      <bibkey>africanlp-ws-2025-1</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.0</doi>
    </frontmatter>
    <paper id="1">
      <title>Yankari: Monolingual <fixed-case>Y</fixed-case>oruba Dataset</title>
      <author><first>Maro</first><last>Akpobi</last><affiliation>African Center for Language Preservation</affiliation></author>
      <pages>1-6</pages>
      <abstract>This paper presents Yankari, a large-scale monolingual dataset for the Yoruba language, aimed at addressing the critical gap in Natural Language Processing (NLP) resources for this important West African language. Despite being spoken by over 30 million people, Yoruba has been severely underrepresented in NLP research and applications. We detail our methodology for creating this dataset, which includes careful source selection, automated quality control, and rigorous data cleaning processes. The Yankari dataset comprises 51,407 documents from 13 diverse sources, totaling over 30 million tokens. Our approach focuses on ethical data collection practices, avoiding problematic sources and addressing issues prevalent in existing datasets. We provide thorough automated evaluations of the dataset, demonstrating its quality compared to existing resources. The Yankari dataset represents a significant advancement in Yoruba language resources, providing a foundation for developing more accurate NLP models, supporting comparative linguistic studies, and contributing to the digital accessibility of the Yoruba language.</abstract>
      <url hash="1388fab6">2025.africanlp-1.1</url>
      <bibkey>akpobi-2025-yankari</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.1</doi>
    </paper>
    <paper id="2">
      <title>Supervised Machine Learning based <fixed-case>A</fixed-case>mharic Text Complexity Classification Using Automatic Annotator Tool</title>
      <author orcid="0000-0001-5060-9445"><first>Gebregziabihier</first><last>Nigusie</last></author>
      <pages>7-14</pages>
      <abstract>Understanding written content can vary significantly based on the linguistic complexity of the text. In the context of Amharic, a morphologically rich and low-resource language, the use of complex vocabulary and less frequent expressions often hinders understanding, particularly among readers with limited literacy skills. Such complexity poses challenges for both human comprehension and NLP applications. Addressing this complexity in Amharic is therefore important for text readability and accessibility. In this study, we developed a text complexity annotation tool using curated list of 1,113 complex Amharic terms. Utilizing this tool, we collected and annotated a dataset comprising 20,000 sentences. Based on the annotated corpus, we developed a text complexity classification model using both traditional and deep learning approaches. For traditional machine learning models, the dataset was vectorized using the Bag-of-Words representation. For deep learning and pre-trained models, we implemented embedding layers based on Word2Vec and BERT, trained on a vocabulary consisting of 24,148 tokens. The experiment is conducted using Support Vector Machine and Random Forest for classical machine learning, and Long Short-Term Memory, Bidirectional LSTM, and BERT for deep learning and pre-trained models. The classification accuracies achieved were 83.5% for SVM, 80.3% for RF, 84.1% for LSTM, 85.0% for BiLSTM, and 89.4% for the BERT-based model. Among these, the BERT-based approaches shows optimal performance for text complexity classifications which have abilityto capture long-range dependencies and contextual relationships within the text.</abstract>
      <url hash="1938f5cc">2025.africanlp-1.2</url>
      <bibkey>nigusie-2025-supervised</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.2</doi>
    </paper>
    <paper id="3">
      <title>On the Tolerance of Repetition Before Performance Degradation in Kiswahili Automatic Speech Recognition</title>
      <author><first>Kathleen</first><last>Siminyu</last></author>
      <author orcid="0000-0001-9205-0942"><first>Kathy</first><last>Reid</last><affiliation>Australian National University</affiliation></author>
      <author><first>Ryakitimboruby@gmail.com</first><last>Ryakitimboruby@gmail.com</last><affiliation>NA</affiliation></author>
      <author><first>Bmwasaru@gmail.com</first><last>Bmwasaru@gmail.com</last><affiliation>NA</affiliation></author>
      <author><first>Chenai@chenai.africa</first><last>Chenai@chenai.africa</last><affiliation>NA</affiliation></author>
      <pages>15-23</pages>
      <abstract>State of the art end-to-end automatic speech recognition (ASR) models require large speech datasets for training. The Mozilla Common Voice project crowd-sources read speech to address this need. However, this approach often results in many audio utterances being recorded for each written sentence. Using Kiswahili speech data, this paper first explores how much audio repetition in utterances is permissible in a training set before model degradation occurs, then examines the extent to which audio augmentation techniques can be employed to increase the diversity of speech characteristics and improve accuracy. We find that repetition up to a ratio of 1 sentence to 8 audio recordings improves performance, but performance degrades at a ratio of 1:16. We also find small improvements from frequency mask, time mask and tempo augmentation. Our findings provide guidance on training set construction for ASR practitioners, particularly those working in under-served languages.</abstract>
      <url hash="d99dc885">2025.africanlp-1.3</url>
      <bibkey>siminyu-etal-2025-tolerance</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.3</doi>
    </paper>
    <paper id="5">
      <title>Enhancing <fixed-case>AI</fixed-case>-Driven Farming Advisory in <fixed-case>K</fixed-case>enya with Efficient <fixed-case>RAG</fixed-case> Agents via Quantized Fine-Tuned Language Models</title>
      <author><first>Theophilus Lincoln</first><last>Owiti</last></author>
      <author><first>Andrew Kiprop</first><last>Kipkebut</last></author>
      <pages>24-30</pages>
      <abstract>The integration of Artificial Intelligence (Al) in agriculture has significantly impacted decision making processes for farmers, particularly in regions such as Kenya, where access to accurate and timely advisory services is crucial. This paper explores the deployment of Retrieval Augmented Generation (RAG) agents powered by fine-tuned quantized language models to enhance Al-driven agricultural advisory services. By optimizing model efficiency through quantization and fine-tuning, our aim is to deliver a specialized language model in agriculture and to ensure real-time, cost-effective and contextually relevant recommendations for smallholder farmers. Our approach takes advantage of localized agricultural datasets and natural language processing techniques to improve the accessibility and accuracy of advisory responses in local Kenyan languages. We show that the proposed model has the potential to improve information delivery and automation of complex and monotonous tasks, making it a viable solution to sustainable agricultural intelligence in Kenya and beyond.</abstract>
      <url hash="3601cbd6">2025.africanlp-1.5</url>
      <bibkey>owiti-kipkebut-2025-enhancing</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.5</doi>
    </paper>
    <paper id="6">
      <title>Pretraining Strategies using Monolingual and Parallel Data for Low-Resource Machine Translation</title>
      <author><first>Idriss Nguepi</first><last>Nguefack</last></author>
      <author><first>Mara</first><last>Finkelstein</last><affiliation>Google</affiliation></author>
      <author orcid="0000-0003-2617-081X"><first>Toadoum Sari</first><last>Sakayo</last></author>
      <pages>31-38</pages>
      <abstract>This research article examines the effectiveness of various pretraining strategies for developing machine translation models tailored to low-resource languages. Although this work considers several low-resource languages, including Afrikaans, Swahili, and Zulu, the translation model is specifically developed for Lingala, an under-resourced African language, building upon the pretraining approach introduced byReid and Artetxe (2021), originally designed for high-resource languages. Through a series of comprehensive experiments, we explore different pretraining methodologies, including the integration of multiple languages and the use of both monolingual and parallel data during the pretraining phase. Our findings indicate that pretraining on multiple languages and leveraging both monolingual and parallel data significantly enhance translation quality. This study offers valuable insights into effective pretraining strategies for low-resource machine translation, helping to bridge the performance gap between high-resource and low-resource languages. The results contribute to the broader goal of developing more inclusive and accurate NLP models for marginalized communities and underrepresented populations. The code and datasets used in this study are publicly available to facilitate further research and ensure reproducibility, with the exception of certain data that may no longer be accessible due to changes in public availability.</abstract>
      <url hash="09f9c353">2025.africanlp-1.6</url>
      <bibkey>nguefack-etal-2025-pretraining</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.6</doi>
    </paper>
    <paper id="7">
      <title>Designing and Contextualising Probes for <fixed-case>A</fixed-case>frican Languages</title>
      <author><first>Wisdom</first><last>Aduah</last><affiliation>University of Health and Allied Sciences</affiliation></author>
      <author><first>Francois</first><last>Meyer</last><affiliation>University of Cape Town</affiliation></author>
      <pages>39-51</pages>
      <abstract>Pretrained language models (PLMs) for African languages are continually improving, but the reasons behind these advances remain unclear. This paper presents the first systematic investigation into how knowledge about African languages is encoded in PLMs. We train layer-wise probes for six typologically diverse African languages to analyse how linguistic features are distributed. We also design control tasks, a way to interpret probe performance, for the MasakhaPOS dataset. We find PLMs adapted for African languages to encode more linguistic information about target languages than massively multilingual PLMs. Our results reaffirm previous findings that token-level syntactic information concentrates in middle-to-last layers, while sentence-level semantic information is distributed across all layers. Through control tasks and probing baselines, we confirm that performance reflects the internal knowledge of PLMs rather than probe memorisation. Our study applies established interpretability techniques to African-language PLMs. In doing so, we highlight the internal mechanisms underlying the success of strategies like active learning and multilingual adaptation.</abstract>
      <url hash="d79e136f">2025.africanlp-1.7</url>
      <bibkey>aduah-meyer-2025-designing</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.7</doi>
    </paper>
    <paper id="8">
      <title>Building a Functional Machine Translation Corpus for <fixed-case>K</fixed-case>pelle</title>
      <author><first>Kweku Andoh</first><last>Yamoah</last><affiliation>Ashesi University</affiliation></author>
      <author><first>Jackson</first><last>Weako</last></author>
      <author orcid="0000-0002-8624-7295"><first>Emmanuel</first><last>Dorley</last><affiliation>University of Florida</affiliation></author>
      <pages>52-63</pages>
      <abstract>In this paper, we introduce the first publicly available English-Kpelle dataset for machine translation, comprising over 2,000 sentence pairs drawn from everyday communication, religious texts, and educational materials. By fine-tuning Metas No Language Left Behind (NLLB) model on two versions of the dataset, we achieved BLEU scores of up to 30 in the Kpelle-to-English direction, demonstrating the benefits of data augmentation. Our findings align with NLLB-200 benchmarks on other African languages, underscoring Kpelles potential for competitive performance despite its low-resource status. Beyond machine translation, this dataset enables broader NLP tasks, including speech recognition and language modeling. We conclude with a roadmap for future dataset expansion, emphasizing orthographic consistency, community-driven validation, and interdisciplinary collaboration to advance inclusive language technology development for Kpelle and other low-resourced Mande languages.</abstract>
      <url hash="7ee2a9be">2025.africanlp-1.8</url>
      <bibkey>yamoah-etal-2025-building</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.8</doi>
    </paper>
    <paper id="10">
      <title>Exploring Transliteration-Based Zero-Shot Transfer for <fixed-case>A</fixed-case>mharic <fixed-case>ASR</fixed-case></title>
      <author><first>Hellina Hailu</first><last>Nigatu</last></author>
      <author orcid="0000-0003-1706-1777"><first>Hanan</first><last>Aldarmaki</last><affiliation>Mohamed bin Zayed University of Artificial Intelligence</affiliation></author>
      <pages>64-73</pages>
      <abstract>The performance of Automatic Speech Recognition (ASR) depends on the availability of transcribed speech datasets—often scarce ornon-existent for many of the worlds languages. This study investigates alternative strategies to bridge the data gap using zero-shot cross-lingual transfer, leveraging transliteration as a method to utilize data from other languages. We experiment with transliteration from various source languages and demonstrate ASR performance in a low-resourced language, Amharic. We find that source data that align with the character distribution of the test data achieves the best performance, regardless of language family. We also experiment with fine-tuning with minimal transcribed data in the target language. Our findings demonstrate that transliteration, particularly when combined with a strategic choice of source languages, is a viable approach for improving ASR in zero-shot and low-resourced settings.</abstract>
      <url hash="b2d9b603">2025.africanlp-1.10</url>
      <bibkey>nigatu-aldarmaki-2025-exploring</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.10</doi>
    </paper>
    <paper id="11">
      <title>Fine-tuning Whisper Tiny for <fixed-case>S</fixed-case>wahili <fixed-case>ASR</fixed-case>: Challenges and Recommendations for Low-Resource Speech Recognition</title>
      <author><first>Avinash Kumar</first><last>Sharma</last></author>
      <author><first>Manas</first><last>Pandya</last><affiliation>Indian Institute of Technology Madras, Zanzibar Campus</affiliation></author>
      <author><first>Arpit</first><last>Shukla</last></author>
      <pages>74-81</pages>
      <abstract>Automatic Speech Recognition (ASR) technologies have seen significant advancements, yet many widely spoken languages remain underrepresented. This paper explores the fine-tuning of OpenAI’s Whisper Tiny model (39M parameters) for Swahili, a lingua franca for over 100 million people across East Africa. Using a dataset of 5,520 Swahili audio samples, we analyze the model’s performance, error patterns, and limitations after fine-tuning. Our results demonstrate the potential of fine-tuning for improving transcription accuracy, while also highlighting persistent challenges such as phonetic misinterpretations, named entity recognition failures, and difficulties with morphologically complex words. We provide recommendations for improving Swahili ASR, including scaling to larger model variants, architectural adaptations for agglutinative languages, and data enhancement strategies. This work contributes to the growing body of research on adapting pre-trained multilingual ASR systems to low-resource languages, emphasizing the need for approaches that account for the unique linguistic features of Bantu languages.</abstract>
      <url hash="bbe192f4">2025.africanlp-1.11</url>
      <bibkey>sharma-etal-2025-fine</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.11</doi>
    </paper>
    <paper id="12">
      <title>Who Wrote This? Identifying Machine vs Human-Generated Text in <fixed-case>H</fixed-case>ausa</title>
      <author><first>Babangida</first><last>Sani</last></author>
      <author><first>Aakansha</first><last>Soy</last></author>
      <author><first>Sukairaj Hafiz</first><last>Imam</last></author>
      <author><first>Ahmad</first><last>Mustapha</last></author>
      <author orcid="0009-0009-4314-6919"><first>Lukman Jibril</first><last>Aliyu</last></author>
      <author orcid="0000-0002-3795-8381"><first>Idris</first><last>Abdulmumin</last><affiliation>Ahmadu Bello University</affiliation></author>
      <author orcid="0000-0001-9514-1807"><first>Ibrahim Said</first><last>Ahmad</last><affiliation>Northeastern University</affiliation></author>
      <author orcid="0000-0001-7708-0799"><first>Shamsuddeen Hassan</first><last>Muhammad</last><affiliation>Imperial College London and Bayero University, Kano-Nigeria</affiliation></author>
      <pages>82-88</pages>
      <abstract>The advancement of large language models (LLMs) has allowed them to be proficient in various tasks, including content generation. However, their unregulated usage can lead to malicious activities such as plagiarism and generating and spreading fake news, especially for low-resource languages. Most existing machine-generated text detectors are trained on high-resource languages like English, French, etc. In this study, we developed the first large-scale detector that can distinguish between human- and machine-generated content in Hausa. We scraped seven Hausa-language media outlets for the human-generated text and the Gemini-2.0 flash model to automatically generate the corresponding Hausa-language articles based on the human-generated article headlines. We fine-tuned four pre-trained African-centric models (AfriTeVa, AfriBERTa, AfroX LMR, and AfroXLMR-76L) on the resulting dataset and assessed their performance using accuracy and F1-score metrics. AfroXLMR achieved the highest performance with an accuracy of 99.23% and an F1 score of 99.21%, demonstrating its effectiveness for Hausa text detection. Our dataset is made publicly available to enable further research.</abstract>
      <url hash="213468e6">2025.africanlp-1.12</url>
      <bibkey>sani-etal-2025-wrote</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.12</doi>
    </paper>
    <paper id="13">
      <title>Automatic Speech Recognition for <fixed-case>A</fixed-case>frican Low-Resource Languages: Challenges and Future Directions</title>
      <author><first>Sukairaj Hafiz</first><last>Imam</last></author>
      <author><first>Babangida</first><last>Sani</last></author>
      <author orcid="0009-0008-5016-531X"><first>Dawit Ketema</first><last>Gete</last><affiliation>Wollo University</affiliation></author>
      <author><first>Bedru Yimam</first><last>Ahmed</last></author>
      <author orcid="0000-0001-9514-1807"><first>Ibrahim Said</first><last>Ahmad</last><affiliation>Northeastern University</affiliation></author>
      <author orcid="0000-0002-3795-8381"><first>Idris</first><last>Abdulmumin</last><affiliation>Ahmadu Bello University</affiliation></author>
      <author orcid="0000-0002-8289-388X"><first>Seid Muhie</first><last>Yimam</last><affiliation>Universität Hamburg</affiliation></author>
      <author><first>Muhammad Yahuza</first><last>Bello</last></author>
      <author orcid="0000-0001-7708-0799"><first>Shamsuddeen Hassan</first><last>Muhammad</last><affiliation>Imperial College London and Bayero University, Kano-Nigeria</affiliation></author>
      <pages>89-94</pages>
      <abstract>Automatic Speech Recognition (ASR) technologies have transformed human-computer interaction; however, low-resource languages in Africa remain significantly underrepresented in both research and practical applications. This study investigates the major challenges hindering the development of ASR systems for these languages, which include data scarcity, linguistic complexity, limited computational resources, acoustic variability, and ethical concerns surrounding bias and privacy. The primary goal is to critically analyze these barriers and identify practical, inclusive strategies to advance ASR technologies within the African context. Recent advances and case studies emphasize promising strategies such as community-driven data collection, self-supervised and multilingual learning, lightweight model architectures, and techniques that prioritize privacy. Evidence from pilot projects involving various African languages showcases the feasibility and impact of customized solutions, which encompass morpheme-based modeling and domain-specific ASR applications in sectors like healthcare and education. The findings highlight the importance of interdisciplinary collaboration and sustained investment to tackle the distinct linguistic and infrastructural challenges faced by the continent. This study offers a progressive roadmap for creating ethical, efficient, and inclusive ASR systems that not only safeguard linguistic diversity but also improve digital accessibility and promote socioeconomic participation for speakers of African languages.</abstract>
      <url hash="469edf37">2025.africanlp-1.13</url>
      <bibkey>imam-etal-2025-automatic</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.13</doi>
    </paper>
    <paper id="14">
      <title><fixed-case>S</fixed-case>abi<fixed-case>Y</fixed-case>arn: Advancing Low Resource Languages with Multitask <fixed-case>NLP</fixed-case> Pretraining</title>
      <author><first>Jeffrey</first><last>Otoibhi</last></author>
      <author><first>Oduguwa</first><last>Damilola</last></author>
      <author><first>Okpare</first><last>David</last></author>
      <pages>95-107</pages>
      <abstract>The rapid advancement of large language models (LLMs) has revolutionized natural language processing, yet a significant challenge persists: the under representation of low-resource languages. This paper introduces SabiYarn, a novel 125M parameter decoder-only language model specifically designed to address this gap for Nigerian languages.Our research demonstrates that a relatively small language model can achieve remarkable performance across multiple languages even in a low-resource setting when trained on carefully curated task-specific datasets. We introduce a multitask learning framework designed for computational efficiency, leveraging techniques such as sequence packing to maximize token throughput per batch. This allows SabiYarn to make the most of a limited compute budget while achieving strong performance across multiple NLP tasks.This paper not only highlights the effectiveness of our approach but also challenges the notion that only massive models can achieve high performance in diverse linguistic contexts, outperforming models over 100 times its parameter size on specific tasks such as translation (in both directions), Named Entity Recognition, Text Diacritization, and Sentiment Analysis in the low-resource languages it was trained on. SabiYarn-125M represents a significant step towards democratizing NLP technologies for low-resource languages, offering a blueprint for developing efficient, high-performing models tailored to specific linguistic regions. Our work paves the way for more inclusive and culturally sensitive AI systems, potentially transforming how language technologies are developed and deployed in linguistically diverse areas like Nigeria and beyond.</abstract>
      <url hash="62fda24d">2025.africanlp-1.14</url>
      <bibkey>otoibhi-etal-2025-sabiyarn</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.14</doi>
    </paper>
    <paper id="15">
      <title>Retrieval-Augmented Generation Meets Local Languages for Improved Drug Information Access and Comprehension.</title>
      <author orcid="0000-0002-6319-8339"><first>Ahmad Ibrahim</first><last>Ismail</last></author>
      <author><first>Bashirudeen Opeyemi</first><last>Ibrahim</last><affiliation>Data Science Nigeria</affiliation></author>
      <author orcid="0000-0002-1229-1779"><first>Olubayo</first><last>Adekanmbi</last><affiliation>City University London</affiliation></author>
      <author><first>Ife</first><last>Adebara</last></author>
      <pages>108-114</pages>
      <abstract>Medication errors are among the leading causes of avoidable harm in healthcare systems across the world. A large portion of these errors stem from inefficient information retrieval processes and lack of comprehension of drug information. In low-resource settings, these issues are exacerbated by limited access to updated and reliable sources, technological constraints, and linguistic barriers. Innovations to improve the retrieval and comprehension of drug-related information are therefore poised to reduce medication errors and improve patient outcomes. This research employed open-source Retrieval-Augmented Generation (RAG) integrated with multilingual translation and Text-to-Speech (TTS) systems. Using open-source tools, a corpus was created from prominent sources of medical information in Nigeria and stored as high-level text embeddings in a Chroma database. Upon user query, relevant drug information is retrieved and synthesized using a large language model. This can be translated into Yoruba, Igbo, and Hausa languages, and converted into speech through the TTS system, addressing the linguistic accessibility gap. Evaluation of the system by domain experts indicated impressive overall performance in translation, achieving an average accuracy of 73%, and the best performance observed in Hausa and Yoruba. TTS results were moderately effective (mean = 57%), with Igbo scoring highest in speech clarity (68%). However, tonal complexity, especially in Yoruba, posed challenges for accurate pronunciation, highlighting the need for language-specific model fine-tuning. Addressing these linguistic nuances is essential to optimize comprehension and practical utility in diverse healthcare settings. The results demonstrates systems the potential to improve access to drug information, enhance comprehension, and reduce linguistic barriers. These technologies could substantially mitigate medication errors and improve patient safety. This study offers valuable insights and practical guidelines for future implementations aimed at strengthening global medication safety practices.</abstract>
      <url hash="70aa733e">2025.africanlp-1.15</url>
      <bibkey>ismail-etal-2025-retrieval</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.15</doi>
    </paper>
    <paper id="16">
      <title>Story Generation with Large Language Models for <fixed-case>A</fixed-case>frican Languages</title>
      <author><first>Catherine Nana Nyaah</first><last>Essuman</last><affiliation>Umbaji</affiliation></author>
      <author orcid="0000-0003-1994-5832"><first>Jan</first><last>Buys</last><affiliation>University of Cape Town</affiliation></author>
      <pages>115-125</pages>
      <abstract>The development of Large Language Models (LLMs) for African languages has been hindered by the lack of large-scale textual data. Previous research has shown that relatively small language models, when trained on synthetic data generated by larger models, can produce fluent, short English stories, providing a data-efficient alternative to large-scale pretraining. In this paper, we apply a similar approach to develop and evaluate small language models for generating childrens stories in isiZulu and Yoruba, using synthetic datasets created through translation and multilingual prompting. We train six language-specific models varying in dataset size and source, and based on the GPT-2 architecture. Our results show that models trained on synthetic low-resource data are capable of producing coherent and fluent short stories in isiZulu and Yoruba. Models trained on larger synthetic datasets generally perform better in terms of coherence and grammar, and also tend to generalize better, as seen by their lower evaluation perplexities. Models trained on datasets generated through prompting instead of translation generate similar or more coherent stories and display more creativity, but perform worse in terms of generalization to unseen data. In addition to the potential educational applications of the automated story generation, our approach has the potential to be used as the foundation for more data-efficient low-resource language models.</abstract>
      <url hash="17773d74">2025.africanlp-1.16</url>
      <bibkey>essuman-buys-2025-story</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.16</doi>
    </paper>
    <paper id="17">
      <title>Command <fixed-case>R</fixed-case>7<fixed-case>B</fixed-case> <fixed-case>A</fixed-case>rabic: a small, enterprise-focused, multilingual, and culturally aware <fixed-case>A</fixed-case>rabic <fixed-case>LLM</fixed-case></title>
      <author orcid="0000-0002-2475-8719"><first>Yazeed</first><last>Alnumay</last><affiliation>Cohere</affiliation></author>
      <author><first>Alexandre</first><last>Barbet</last><affiliation>Cohere</affiliation></author>
      <author><first>Anna</first><last>Bialas</last></author>
      <author><first>William Michael</first><last>Darling</last><affiliation>Cohere</affiliation></author>
      <author><first>Shaan@cohere.com</first><last>Shaan@cohere.com</last><affiliation>NA</affiliation></author>
      <author><first>Joan@cohere.com</first><last>Joan@cohere.com</last><affiliation>NA</affiliation></author>
      <author><first>Kyle</first><last>Duffy</last></author>
      <author><first>Stephaniehowe@cohere.com</first><last>Stephaniehowe@cohere.com</last><affiliation>NA</affiliation></author>
      <author><first>Olivia</first><last>Lasche</last><affiliation>Cohere</affiliation></author>
      <author><first>Justin Seonyong</first><last>Lee</last><affiliation>Cohere</affiliation></author>
      <author><first>Anirudh@cohere.com</first><last>Anirudh@cohere.com</last><affiliation>NA</affiliation></author>
      <author><first>Jennifer@cohere.com</first><last>Jennifer@cohere.com</last><affiliation>NA</affiliation></author>
      <pages>126-135</pages>
      <abstract>Building high-quality large language models (LLMs) for enterprise Arabic applications remains challenging due to the limited availability of digitized Arabic data. In this work, we present a data synthesis and refinement strategy to help address this problem, namely, by leveraging synthetic data generation and human-in-the-loop annotation to expand our Arabic training corpus. We further present our iterative post training recipe that is essential to achieving state-of-the-art performance in aligning the model with human preferences, a critical aspect to enterprise use cases. The culmination of this effort is the release of a small, 7B, open-weight model that outperforms similarly sized peers in head-to-head comparisons and on Arabic-focused benchmarks covering cultural knowledge, instruction following, RAG, and contextual faithfulness.</abstract>
      <url hash="d5d00c61">2025.africanlp-1.17</url>
      <bibkey>alnumay-etal-2025-command</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.17</doi>
    </paper>
    <paper id="18">
      <title>Challenges and Limitations in Gathering Resources for Low-Resource Languages: The Case of <fixed-case>M</fixed-case>edumba</title>
      <author><first>Tatiana</first><last>Moteu Ngoli</last></author>
      <author><first>Mbuh</first><last>Christabel</last></author>
      <author><first>Njeunga</first><last>Yopa</last></author>
      <pages>136-142</pages>
      <abstract>Low-resource languages face significant challenges in natural language processing due to the scarcity of annotated data, linguistic resources, and the lack of language standardization, which leads to variations in grammar, vocabulary, and writing systems. This issue is particularly observed in many African languages, which significantly reduces their usability. To bridge this barrier, this paper investigates the challenges and limitations of collecting datasets for the Medumba language, a Grassfields Bantu language spoken in Cameroon, in the context of extremely low-resource natural language processing. We mainly focus on the specificity of this language, including its grammatical and lexical structure. Our findings highlight key barriers, including (1) the challenges in typing and encoding Latin scripts, (2) the absence of standardized translations for technical and scientific terms, and (3) the challenge of limited digital resources and financial constraints, highlighting the need to improve data strategies and collaboration to advance computational research on African languages. We hope that our study informs the development of better tools and policies to make knowledge platforms more accessible to extremely low-resource language speakers. We further discuss the representation of the language, data collection, parallel corpus development.</abstract>
      <url hash="52c2d9db">2025.africanlp-1.18</url>
      <bibkey>moteu-ngoli-etal-2025-challenges</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.18</doi>
    </paper>
    <paper id="20">
      <title><fixed-case>Y</fixed-case>odi<fixed-case>V</fixed-case>3: <fixed-case>NLP</fixed-case> for <fixed-case>T</fixed-case>ogolese Languages with Eyaa-Tom Dataset and the Lom Metric</title>
      <author orcid="0009-0008-2575-493X"><first>Bakoubolo Essowe</first><last>Justin</last><affiliation>Umbaji</affiliation></author>
      <author orcid="0009-0007-3888-5325"><first>Kodjo François</first><last>Xegbe</last></author>
      <author><first>Catherine Nana Nyaah</first><last>Essuman</last><affiliation>Umbaji</affiliation></author>
      <author><first>Afola Kossi Mawouéna</first><last>Samuel</last></author>
      <pages>143-149</pages>
      <abstract>Most of the 40+ languages spoken in Togo are severely under-represented in Natural Language Processing (NLP) resources. We present YodiV3, a comprehensive approach to developing NLP for ten Togolese languages (plus two major lingua francas) covering machine translation, speech recognition, text-to-speech, and language identification. We introduce Eyaa-Tom, a new multi-domain parallel corpus (religious, healthcare, financial, etc.) for these languages. We also propose the Lom metric, a scoring framework to quantify the AI-readiness of each language in terms of available resources. Our experiments demonstrate that leveraging large pretrained models (e.g.NLLB for translation, MMS for speech) with YodiV3 leads to significant improvements in low-resource translation and speech tasks. This work highlights the impact of integrating diverse data sources and pretrained models to bootstrap NLP for under-served languages, and outlines future steps for expanding coverage and capability.</abstract>
      <url hash="d700e10d">2025.africanlp-1.20</url>
      <bibkey>justin-etal-2025-yodiv3</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.20</doi>
    </paper>
    <paper id="22">
      <title>Challenging Multimodal <fixed-case>LLM</fixed-case>s with <fixed-case>A</fixed-case>frican Standardized Exams: A Document <fixed-case>VQA</fixed-case> Evaluation</title>
      <author><first>Victor Tolulope</first><last>Olufemi</last></author>
      <author><first>Oreoluwa Boluwatife</first><last>Babatunde</last><affiliation>LyngualLabs</affiliation></author>
      <author><first>Emmanuel</first><last>Bolarinwa</last><affiliation>Lynguallabs</affiliation></author>
      <author><first>Kausar Yetunde</first><last>Moshood</last><affiliation>LyngualLabs</affiliation></author>
      <pages>150-157</pages>
      <abstract>Despite rapid advancements in multimodal large language models (MLLMs), their ability to process low-resource African languages in document-based visual question answering (VQA) tasks remains limited. This paper evaluates three state-of-the-art MLLMs—GPT-4o, Claude-3.5 Haiku, and Gemini-1.5 Pro—on WAEC/NECO standardized exam questions in Yoruba, Igbo, and Hausa. We curate a dataset of multiple-choice questions from exam images and compare model accuracies across two prompting strategies: (1) using English prompts for African language questions, and (2) using native-language prompts. While GPT-4o achieves over 90% accuracy for English, performance drops below 40% for African languages, highlighting severe data imbalance in model training. Notably, native-language prompting improves accuracy for most models, yet no system approaches human-level performance, which reaches over 50% in Yoruba, Igbo, and Hausa. These findings emphasize the need for diverse training data, fine-tuning, and dedicated benchmarks that address the linguistic intricacies of African languages in multimodal tasks, paving the way for more equitable and effective AI systems in education.</abstract>
      <url hash="adfc7671">2025.africanlp-1.22</url>
      <bibkey>olufemi-etal-2025-challenging</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.22</doi>
    </paper>
    <paper id="23">
      <title><fixed-case>MOZ</fixed-case>-Smishing: A Benchmark Dataset for Detecting Mobile Money Frauds</title>
      <author orcid="0009-0003-4101-8979"><first>Felermino D. M. A.</first><last>Ali</last></author>
      <author orcid="0000-0003-1252-7515"><first>Henrique</first><last>Lopes Cardoso</last><affiliation>Faculty of Engineering of the University of Porto</affiliation></author>
      <author orcid="0000-0002-5249-0617"><first>Rui</first><last>Sousa-Silva</last></author>
      <author><first>Saide.saide@unilurio.ac.mz</first><last>Saide.saide@unilurio.ac.mz</last><affiliation>NA</affiliation></author>
      <pages>158-166</pages>
      <abstract>Despite the increasing prevalence of smishing attacks targeting Mobile Money Transfer systems, there is a notable lack of publicly available SMS phishing datasets in this domain. This study seeks to address this gap by creating a specialized dataset designed to detect smishing attacks aimed at Mobile Money Transfer users. The data set consists of crowd-sourced text messages from Mozambican mobile users, meticulously annotated into two categories: legitimate messages (ham) and fraudulent smishing attempts (spam). The messages are written in Portuguese, often incorporating microtext styles and linguistic nuances unique to the Mozambican context.We also investigate the effectiveness of LLMs in detecting smishing. Using in-context learning approaches, we evaluate the models’ ability to identify smishing attempts without requiring extensive task-specific training. The data set is released under an open license at the following link: huggingface-Anonymous</abstract>
      <url hash="adbf54a9">2025.africanlp-1.23</url>
      <bibkey>ali-etal-2025-moz</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.23</doi>
    </paper>
    <paper id="26">
      <title>In-Domain <fixed-case>A</fixed-case>frican Languages Translation Using <fixed-case>LLM</fixed-case>s and Multi-armed Bandits</title>
      <author><first>Pratik Rakesh</first><last>Singh</last><affiliation>Sony Research India</affiliation></author>
      <author><first>Kritarth</first><last>Prasad</last><affiliation>Sony Research India, Bangalore</affiliation></author>
      <author><first>Mohammadi</first><last>Zaki</last><affiliation>Sony Research India, Bangalore</affiliation></author>
      <author orcid="0000-0001-5602-2901"><first>Pankaj</first><last>Wasnik</last><affiliation>Sony Research India</affiliation></author>
      <pages>167-175</pages>
      <abstract>Neural Machine Translation (NMT) systems face significant challenges when working with low-resource languages, particularly in domain adaptation tasks. These difficulties arise due to limited training data and suboptimal model generalization, As a result, selecting an optimal model for translation is crucial for achieving strong performance on in-domain data, particularly in scenarios where fine-tuning is not feasible or practical. In this paper, we investigate strategies for selecting the most suitable NMT model for a given domain using bandit-based algorithms, including Upper Confidence Bound, Linear UCB, Neural Linear Bandit, and Thompson Sampling. Our method effectively addresses the resource constraints by facilitating optimal model selection with high confidence. We evaluate the approach across three African languages and domains, demonstrating its robustness and effectiveness in both scenarios where target data is available and where it is absent.</abstract>
      <url hash="5b4db947">2025.africanlp-1.26</url>
      <bibkey>singh-etal-2025-domain</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.26</doi>
    </paper>
    <paper id="27">
      <title><fixed-case>H</fixed-case>ausa<fixed-case>NLP</fixed-case>: Current Status, Challenges and Future Directions for <fixed-case>H</fixed-case>ausa Natural Language Processing</title>
      <author orcid="0000-0001-7708-0799"><first>Shamsuddeen Hassan</first><last>Muhammad</last><affiliation>Imperial College London and Bayero University, Kano-Nigeria</affiliation></author>
      <author orcid="0000-0001-9514-1807"><first>Ibrahim Said</first><last>Ahmad</last><affiliation>Northeastern University</affiliation></author>
      <author orcid="0000-0002-3795-8381"><first>Idris</first><last>Abdulmumin</last><affiliation>Ahmadu Bello University</affiliation></author>
      <author orcid="0000-0003-3310-0326"><first>Falalu Ibrahim</first><last>Lawan</last><affiliation>Kaduna State University</affiliation></author>
      <author><first>Sukairaj Hafiz</first><last>Imam</last></author>
      <author><first>Yusuf</first><last>Aliyu</last></author>
      <author><first>Sani Abdullahi</first><last>Sani</last></author>
      <author><first>Ali Usman</first><last>Umar</last><affiliation>Federal University of Lafia</affiliation></author>
      <author><first>Tajuddeen</first><last>Gwadabe</last><affiliation>Masakhane Research Foundation</affiliation></author>
      <author orcid="0000-0001-8378-6069"><first>Kenneth</first><last>Church</last><affiliation>Northeastern University</affiliation></author>
      <author orcid="0000-0002-6731-6267"><first>Vukosi</first><last>Marivate</last><affiliation>University of Pretoria</affiliation></author>
      <pages>176-191</pages>
      <abstract>Hausa Natural Language Processing (NLP) has gained increasing attention in recent years, yet remains understudied as a low-resource language despite having over 120 million first-language (L1) and 80 million second-language (L2) speakers worldwide. While significant advances have been made in high-resource languages, Hausa NLP faces persistent challenges including limited open-source datasets and inadequate model representation. This paper presents an overview of the current state of Hausa NLP, systematically examining existing resources, research contributions, and gaps across fundamental NLP tasks: text classification, machine translation, named entity recognition, speech recognition, and question answering. We introduce HausaNLP, a curated catalog that aggregates datasets, tools, and research works to enhance accessibility and drive further development. Furthermore, we discuss challenges in integrating Hausa into large language models (LLMs), addressing issues of suboptimal tokenization, and dialectal variation. Finally, we propose strategic research directions emphasizing dataset expansion, improved language modeling approaches, and strengthened community collaboration to advance Hausa NLP. Our work provides both a foundation for accelerating Hausa NLP progress and valuable insights for broader multilingual NLP research.</abstract>
      <url hash="673e3918">2025.africanlp-1.27</url>
      <bibkey>muhammad-etal-2025-hausanlp</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.27</doi>
    </paper>
    <paper id="28">
      <title>Beyond Generalization :Evaluating Multilingual <fixed-case>LLM</fixed-case>s for <fixed-case>Y</fixed-case>orùbá Animal Health Translation</title>
      <author><first>Godwin</first><last>Adegbehingbe</last><affiliation>Data Science Nigeria</affiliation></author>
      <author><first>Anthony</first><last>Soronnadi</last></author>
      <author><first>Ife</first><last>Adebara</last></author>
      <author orcid="0000-0002-1229-1779"><first>Olubayo</first><last>Adekanmbi</last><affiliation>City University London</affiliation></author>
      <pages>192-194</pages>
      <abstract>Machine translation (MT) has advanced significantly for high-resource languages, yet specialized domain translation remains a challenge for low-resource languages. This study evaluates the ability of state-of-the-art multilingual models to translate animal health reports from English to Yorùbá, a crucial task for veterinary communication in underserved regions. We curated a dataset of 1,468 parallel sentences and compared multiple MT models in zero-shot and fine-tuned settings. Our findings indicate substantial limitations in their ability to generalize to domain-specific translation, with common errors arising from vocabulary mismatch, training data scarcity, and morphological complexity. Fine-tuning improves performance, particularly for the NLLB 3.3B model, but challenges remain in preserving technical accuracy. These results underscore the need for more targeted approaches to multilingual and culturally aware LLMs for African languages.</abstract>
      <url hash="a69f4deb">2025.africanlp-1.28</url>
      <bibkey>adegbehingbe-etal-2025-beyond</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.28</doi>
    </paper>
    <paper id="29">
      <title>Evaluating Robustness of <fixed-case>LLM</fixed-case>s to Typographical Noise in <fixed-case>Y</fixed-case>orùbá <fixed-case>QA</fixed-case></title>
      <author><first>Paul</first><last>Okewunmi</last></author>
      <author><first>Favour</first><last>James</last></author>
      <author><first>Oluwadunsin</first><last>Fajemila</last></author>
      <pages>195-202</pages>
      <abstract>Generative AI models are primarily accessed through chat interfaces, where user queries often contain typographical errors. While these models perform well in English, their robustness to noisy inputs in low-resource languages like Yorùbá remains underexplored. This work investigates a Yorùbá question-answering (QA) task by introducing synthetic typographical noise into clean inputs. We design a probabilistic noise injection strategy that simulates realistic human typos. In our experiments, each character in a clean sentence is independently altered, with noise levels ranging from 10% to 40%. We evaluate performance across three strong multilingual models using two complementary metrics: (1) a multilingual BERTScore to assess semantic similarity between outputs on clean and noisy inputs, and (2) an LLM-as-judge approach, where the best Yorùbá-capable model rates fluency, comprehension, and accuracy on a 1–5 scale. Results show that while English QA performance degrades gradually, Yorùbá QA suffers a sharper decline. At 40% noise, GPT-4o experiences over a 50% drop in comprehension ability, with similar declines for Gemini 2.0 Flash and Claude 3.7 Sonnet. We conclude with recommendations for noise-aware training and dedicated noisy Yorùbá benchmarks to enhance LLM robustness in low-resource settings.</abstract>
      <url hash="7df52f11">2025.africanlp-1.29</url>
      <bibkey>okewunmi-etal-2025-evaluating</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.29</doi>
    </paper>
    <paper id="30">
      <title><fixed-case>S</fixed-case>wahili News Classification: Performance, Challenges, and Explainability Across <fixed-case>ML</fixed-case>, <fixed-case>DL</fixed-case>, and Transformers</title>
      <author><first>Manas</first><last>Pandya</last><affiliation>Indian Institute of Technology Madras, Zanzibar Campus</affiliation></author>
      <author><first>Avinash Kumar</first><last>Sharma</last></author>
      <author><first>Arpit</first><last>Shukla</last></author>
      <pages>203-209</pages>
      <abstract>In this paper, we propose a comprehensive framework for the classification of Swahili news articles using a combination of classical machine learning techniques, deep neural networks, and transformer-based models. By balancing two diverse datasets sourced from Harvard Dataverse and Kaggle, our approach addresses the inherent challenges of imbalanced data in low-resource languages. Our experiments demonstrate the effectiveness of the proposed methodology and set the stage for further advances in Swahili natural language processing.</abstract>
      <url hash="064b1439">2025.africanlp-1.30</url>
      <bibkey>pandya-etal-2025-swahili</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.30</doi>
    </paper>
    <paper id="31">
      <title>Neural Morphological Tagging for Nguni Languages</title>
      <author orcid="0009-0003-9420-6199"><first>Cael</first><last>Marquard</last><affiliation>University of Cape Town</affiliation></author>
      <author><first>Simbarashe</first><last>Mawere</last></author>
      <author><first>Francois</first><last>Meyer</last><affiliation>University of Cape Town</affiliation></author>
      <pages>210-220</pages>
      <abstract>Morphological parsing is the task of decomposing words into morphemes, the smallest units of meaning in a language, and labelling their grammatical roles. It is a particularly challenging task for agglutinative languages, such as the Nguni languages of South Africa, which construct words by concatenating multiple morphemes. A morphological parsing system can be framed as a pipeline with two separate components, a segmenter followed by a tagger. This paper investigates the use of neural methods to build morphological taggers for the four Nguni languages. We compare two classes of approaches: training neural sequence labellers (LSTMs and neural CRFs) from scratch and finetuning pretrained language models. We compare performance across these two categories, as well as to a traditional rule-based morphological parser. Neural taggers comfortably outperform the rule-based baseline and models trained from scratch tend to outperform pretrained models. We also compare parsing results across different upstream segmenters and with varying linguistic input features. Our findings confirm the viability of employing neural taggers based on pre-existing morphological segmenters for the Nguni languages.</abstract>
      <url hash="b92d3c9d">2025.africanlp-1.31</url>
      <bibkey>marquard-etal-2025-neural</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.31</doi>
    </paper>
    <paper id="32">
      <title>Multilingual <fixed-case>NLP</fixed-case> for <fixed-case>A</fixed-case>frican Healthcare: Bias, Translation, and Explainability Challenges</title>
      <author><first>Ugochi</first><last>Okafor</last><affiliation>Data Science Nigeria</affiliation></author>
      <pages>221-229</pages>
      <abstract>Despite advances in multilingual natural language processing (NLP) and machine translation (MT), African languages remain underrepresented due to data scarcity, tokenisation inefficiencies, and bias in AI models. Large-scale systems such as Meta AIs No Language Left Behind (NLLB) and the Flores-200 benchmark have improved low-resource language support, yet critical gaps persist, particularly in healthcare, where accuracy and trust are essential.This study systematically reviews over 30 peer-reviewed papers, technical reports, and datasets to assess the effectiveness of existing multilingual NLP models, specifically Masakhane-MT, Masakhane-NER, and AfromT, in African healthcare contexts. The analysis focuses on four languages with available evaluation data: Swahili, Yoruba, Hausa, and Igbo.Findings show that while AI tools such as medical chatbots and disease surveillance systems demonstrate promise, current models face persistent challenges including domain adaptation failures, cultural and linguistic bias, and limited explainability. Use cases like Ubenwas infant cry analysis tool and multilingual health translation systems illustrate both potential and risk, especially where translation errors or opacity may impact clinical decisions.The paper highlights the need for ethically grounded, domain-specific NLP approaches that reflect Africas linguistic diversity. We recommend strategies to address dataset imbalance, reduce bias, and improve explainability, while also calling for increased computational infrastructure and local AI governance. These steps are critical to making AI-driven healthcare solutions equitable, transparent, and effective for Africas multilingual populations.</abstract>
      <url hash="15c2b85c">2025.africanlp-1.32</url>
      <bibkey>okafor-2025-multilingual</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.32</doi>
    </paper>
    <paper id="33">
      <title>Beyond Metrics: Evaluating <fixed-case>LLM</fixed-case>s Effectiveness in Culturally Nuanced, Low-Resource Real-World Scenarios</title>
      <author orcid="0000-0003-4769-7039"><first>Millicent</first><last>Ochieng</last><affiliation>Microsoft</affiliation></author>
      <author orcid="0009-0002-5746-3017"><first>Varun</first><last>Gumma</last><affiliation>Microsoft</affiliation></author>
      <author><first>Sunayana</first><last>Sitaram</last><affiliation>Microsoft</affiliation></author>
      <author orcid="0000-0002-4833-0880"><first>Jindong</first><last>Wang</last><affiliation>William &amp; Mary</affiliation></author>
      <author><first>Vishrav</first><last>Chaudhary</last><affiliation>Microsoft</affiliation></author>
      <author orcid="0000-0001-5625-4884"><first>Keshet</first><last>Ronen</last><affiliation>University of Washington</affiliation></author>
      <author orcid="0000-0001-9275-742X"><first>Kalika</first><last>Bali</last><affiliation>Microsoft Research Labs</affiliation></author>
      <author><first>Jacki</first><last>O’Neill</last><affiliation>Microsoft</affiliation></author>
      <pages>230-247</pages>
      <abstract>The deployment of Large Language Models (LLMs) in real-world applications presents both opportunities and challenges, particularly in multilingual and code-mixed communication settings. This research evaluates the performance of seven leading LLMs in sentiment analysis on a dataset derived from multilingual and code-mixed WhatsApp chats, including Swahili, English and Sheng. Our evaluation includes both quantitative analysis using metrics like F1 score and qualitative assessment of LLMs’ explanations for their predictions. We find that, while Mistral-7b and Mixtral-8x7b achieved high F1 scores, they and other LLMs such as GPT-3.5-Turbo, Llama-2-70b, and Gemma-7b struggled with understanding linguistic and contextual nuances, as well as lack of transparency in their decision-making process as observed from their explanations. In contrast, GPT-4 and GPT-4-Turbo excelled in grasping diverse linguistic inputs and managing various contextual information, demonstrating high consistency with human alignment and transparency in their decision-making process. The LLMs however, encountered difficulties in incorporating cultural nuance especially in non-English settings with GPT-4s doing so inconsistently. The findings emphasize the necessity of continuous improvement of LLMs to effectively tackle the challenges of culturally nuanced, low-resource real-world settings and the need for developing evaluation benchmarks for capturing these issues.</abstract>
      <url hash="3d767c6d">2025.africanlp-1.33</url>
      <bibkey>ochieng-etal-2025-beyond</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.33</doi>
    </paper>
    <paper id="34">
      <title><fixed-case>Y</fixed-case>-<fixed-case>NQ</fixed-case>: <fixed-case>E</fixed-case>nglish-<fixed-case>Y</fixed-case>orùbá Evaluation dataset for Open-Book Reading Comprehension with Open-Ended Questions</title>
      <author><first>Marta R.</first><last>Costa-jussà</last><affiliation>Meta</affiliation></author>
      <author><first>Joy</first><last>Chen</last><affiliation>Georgia Institute of Technology and Facebook</affiliation></author>
      <author><first>Ife</first><last>Adebara</last></author>
      <author><first>Joe</first><last>Chuang</last><affiliation>FAIR</affiliation></author>
      <author><first>Christophe</first><last>Ropers</last><affiliation>Meta</affiliation></author>
      <author orcid="0009-0001-7574-4579"><first>Eduardo</first><last>Sánchez</last><affiliation>University College London, University of London and Meta</affiliation></author>
      <pages>248-254</pages>
      <abstract>The purpose of this work is to share an English-Yorùbá evaluation dataset for openbook reading comprehension with open-ended questions to assess the performance of models both in a high- and a low-resource language. The dataset contains 358 questions and answers on 338 English documents and 208 Yorùbá documents. Experiments show a consistent disparity in performance between the two languages, with Yorùbá falling behind English for automatic metrics even if documents are much shorter for this language. For a small set of documents with comparable length, performance of Yorùbá drops by 2.5 times and this comparison is validated with humanevaluation. When analyzing performance by length, we observe that Yorùbá decreases performance dramatically for documents that reach 1500 words while English performance is barely affected at that length. Our dataset opens the door to showcasing if English LLM reading comprehension capabilities extend to Yorùbá, which for the evaluated LLMs is not the case.</abstract>
      <url hash="477a9f26">2025.africanlp-1.34</url>
      <bibkey>costa-jussa-etal-2025-y</bibkey>
      <doi>10.18653/v1/2025.africanlp-1.34</doi>
    </paper>
  </volume>
</collection>
