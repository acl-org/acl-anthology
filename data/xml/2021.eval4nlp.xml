<?xml version='1.0' encoding='UTF-8'?>
<collection id="2021.eval4nlp">
  <volume id="1" ingest-date="2021-10-28">
    <meta>
      <booktitle>Proceedings of the 2nd Workshop on Evaluation and Comparison of NLP Systems</booktitle>
      <editor><first>Yang</first><last>Gao</last></editor>
      <editor><first>Steffen</first><last>Eger</last></editor>
      <editor><first>Wei</first><last>Zhao</last></editor>
      <editor><first>Piyawat</first><last>Lertvittayakumjorn</last></editor>
      <editor><first>Marina</first><last>Fomicheva</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Punta Cana, Dominican Republic</address>
      <month>November</month>
      <year>2021</year>
    </meta>
    <frontmatter>
      <url hash="af67d8dc">2021.eval4nlp-1.0</url>
      <bibkey>eval4nlp-2021-evaluation</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Differential Evaluation: a Qualitative Analysis of Natural Language Processing System Behavior Based Upon Data Resistance to Processing</title>
      <author><first>Lucie</first><last>Gianola</last></author>
      <author><first>Hicham</first><last>El Boukkouri</last></author>
      <author><first>Cyril</first><last>Grouin</last></author>
      <author><first>Thomas</first><last>Lavergne</last></author>
      <author><first>Patrick</first><last>Paroubek</last></author>
      <author><first>Pierre</first><last>Zweigenbaum</last></author>
      <pages>1–10</pages>
      <url hash="f991aeaf">2021.eval4nlp-1.1</url>
      <bibkey>gianola-etal-2021-differential</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/mimic-iii">MIMIC-III</pwcdataset>
    </paper>
    <paper id="2">
      <title>Validating Label Consistency in <fixed-case>NER</fixed-case> Data Annotation</title>
      <author><first>Qingkai</first><last>Zeng</last></author>
      <author><first>Mengxia</first><last>Yu</last></author>
      <author><first>Wenhao</first><last>Yu</last></author>
      <author><first>Tianwen</first><last>Jiang</last></author>
      <author><first>Meng</first><last>Jiang</last></author>
      <pages>11–15</pages>
      <url hash="5a339128">2021.eval4nlp-1.2</url>
      <bibkey>zeng-etal-2021-validating</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/scierc">SciERC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/conll">CoNLL++</pwcdataset>
    </paper>
    <paper id="3">
      <title>How Emotionally Stable is <fixed-case>ALBERT</fixed-case>? Testing Robustness with Stochastic Weight Averaging on a Sentiment Analysis Task</title>
      <author><first>Urja</first><last>Khurana</last></author>
      <author><first>Eric</first><last>Nalisnick</last></author>
      <author><first>Antske</first><last>Fokkens</last></author>
      <pages>16–31</pages>
      <url hash="51207096">2021.eval4nlp-1.3</url>
      <bibkey>khurana-etal-2021-emotionally</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
    </paper>
    <paper id="4">
      <title><fixed-case>S</fixed-case>tory<fixed-case>DB</fixed-case>: Broad Multi-language Narrative Dataset</title>
      <author><first>Alexey</first><last>Tikhonov</last></author>
      <author><first>Igor</first><last>Samenko</last></author>
      <author><first>Ivan</first><last>Yamshchikov</last></author>
      <pages>32–39</pages>
      <url hash="3a284190">2021.eval4nlp-1.4</url>
      <bibkey>tikhonov-etal-2021-storydb</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/storydb">StoryDB</pwcdataset>
    </paper>
    <paper id="5">
      <title><fixed-case>S</fixed-case>eq<fixed-case>S</fixed-case>core: Addressing Barriers to Reproducible Named Entity Recognition Evaluation</title>
      <author><first>Chester</first><last>Palen-Michel</last></author>
      <author><first>Nolan</first><last>Holley</last></author>
      <author><first>Constantine</first><last>Lignos</last></author>
      <pages>40–50</pages>
      <url hash="19ca8fed">2021.eval4nlp-1.5</url>
      <bibkey>palen-michel-etal-2021-seqscore</bibkey>
      <pwccode url="https://github.com/bltlab/seqscore" additional="false">bltlab/seqscore</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conll-2003">CoNLL-2003</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/masakhaner">MasakhaNER</pwcdataset>
    </paper>
    <paper id="6">
      <title>Trainable Ranking Models to Evaluate the Semantic Accuracy of Data-to-Text Neural Generator</title>
      <author><first>Nicolas</first><last>Garneau</last></author>
      <author><first>Luc</first><last>Lamontagne</last></author>
      <pages>51–61</pages>
      <url hash="ccb97ac7">2021.eval4nlp-1.6</url>
      <bibkey>garneau-lamontagne-2021-trainable</bibkey>
    </paper>
    <paper id="7">
      <title>Evaluation of Unsupervised Automatic Readability Assessors Using Rank Correlations</title>
      <author><first>Yo</first><last>Ehara</last></author>
      <pages>62–72</pages>
      <url hash="f733a36e">2021.eval4nlp-1.7</url>
      <bibkey>ehara-2021-evaluation</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/newsela">Newsela</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/onestopenglish">OneStopEnglish</pwcdataset>
    </paper>
    <paper id="8">
      <title>Testing Cross-Database Semantic Parsers With Canonical Utterances</title>
      <author><first>Heather</first><last>Lent</last></author>
      <author><first>Semih</first><last>Yavuz</last></author>
      <author><first>Tao</first><last>Yu</last></author>
      <author><first>Tong</first><last>Niu</last></author>
      <author><first>Yingbo</first><last>Zhou</last></author>
      <author><first>Dragomir</first><last>Radev</last></author>
      <author><first>Xi Victoria</first><last>Lin</last></author>
      <pages>73–83</pages>
      <url hash="eca24c2c">2021.eval4nlp-1.8</url>
      <bibkey>lent-etal-2021-testing</bibkey>
    </paper>
    <paper id="9">
      <title>Writing Style Author Embedding Evaluation</title>
      <author><first>Enzo</first><last>Terreau</last></author>
      <author><first>Antoine</first><last>Gourru</last></author>
      <author><first>Julien</first><last>Velcin</last></author>
      <pages>84–93</pages>
      <url hash="5de3bdb3">2021.eval4nlp-1.9</url>
      <attachment type="Software" hash="393e384a">2021.eval4nlp-1.9.Software.zip</attachment>
      <bibkey>terreau-etal-2021-writing</bibkey>
      <pwccode url="https://github.com/enzofleur/style_embedding_evaluation" additional="false">enzofleur/style_embedding_evaluation</pwccode>
    </paper>
    <paper id="10">
      <title><fixed-case>ESTIME</fixed-case>: Estimation of Summary-to-Text Inconsistency by Mismatched Embeddings</title>
      <author><first>Oleg</first><last>Vasilyev</last></author>
      <author><first>John</first><last>Bohannon</last></author>
      <pages>94–103</pages>
      <url hash="e9555da3">2021.eval4nlp-1.10</url>
      <bibkey>vasilyev-bohannon-2021-estime</bibkey>
    </paper>
    <paper id="11">
      <title>Statistically Significant Detection of Semantic Shifts using Contextual Word Embeddings</title>
      <author id="yang-liu-Helsinki"><first>Yang</first><last>Liu</last></author>
      <author><first>Alan</first><last>Medlar</last></author>
      <author><first>Dorota</first><last>Glowacka</last></author>
      <pages>104–113</pages>
      <url hash="704eb95b">2021.eval4nlp-1.11</url>
      <bibkey>liu-etal-2021-statistically</bibkey>
    </paper>
    <paper id="12">
      <title>Referenceless Parsing-Based Evaluation of <fixed-case>AMR</fixed-case>-to-<fixed-case>E</fixed-case>nglish Generation</title>
      <author><first>Emma</first><last>Manning</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>114–122</pages>
      <url hash="19638797">2021.eval4nlp-1.12</url>
      <bibkey>manning-schneider-2021-referenceless</bibkey>
    </paper>
    <paper id="13">
      <title><fixed-case>MIPE</fixed-case>: A Metric Independent Pipeline for Effective Code-Mixed <fixed-case>NLG</fixed-case> Evaluation</title>
      <author><first>Ayush</first><last>Garg</last></author>
      <author><first>Sammed</first><last>Kagi</last></author>
      <author><first>Vivek</first><last>Srivastava</last></author>
      <author><first>Mayank</first><last>Singh</last></author>
      <pages>123–132</pages>
      <url hash="013e0a03">2021.eval4nlp-1.13</url>
      <bibkey>garg-etal-2021-mipe</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>IST</fixed-case>-Unbabel 2021 Submission for the Explainable Quality Estimation Shared Task</title>
      <author><first>Marcos</first><last>Treviso</last></author>
      <author><first>Nuno M.</first><last>Guerreiro</last></author>
      <author><first>Ricardo</first><last>Rei</last></author>
      <author><first>André F. T.</first><last>Martins</last></author>
      <pages>133–145</pages>
      <url hash="49736ac9">2021.eval4nlp-1.14</url>
      <bibkey>treviso-etal-2021-ist</bibkey>
    </paper>
    <paper id="15">
      <title>Error Identification for Machine Translation with Metric Embedding and Attention</title>
      <author><first>Raphael</first><last>Rubino</last></author>
      <author><first>Atsushi</first><last>Fujita</last></author>
      <author><first>Benjamin</first><last>Marie</last></author>
      <pages>146–156</pages>
      <url hash="be9a2fa6">2021.eval4nlp-1.15</url>
      <bibkey>rubino-etal-2021-error</bibkey>
    </paper>
    <paper id="16">
      <title>Reference-Free Word- and Sentence-Level Translation Evaluation with Token-Matching Metrics</title>
      <author><first>Christoph Wolfgang</first><last>Leiter</last></author>
      <pages>157–164</pages>
      <url hash="65051d61">2021.eval4nlp-1.16</url>
      <bibkey>leiter-2021-reference</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/mlqe-pe">MLQE-PE</pwcdataset>
    </paper>
    <paper id="17">
      <title>The <fixed-case>E</fixed-case>val4<fixed-case>NLP</fixed-case> Shared Task on Explainable Quality Estimation: Overview and Results</title>
      <author><first>Marina</first><last>Fomicheva</last></author>
      <author><first>Piyawat</first><last>Lertvittayakumjorn</last></author>
      <author><first>Wei</first><last>Zhao</last></author>
      <author><first>Steffen</first><last>Eger</last></author>
      <author><first>Yang</first><last>Gao</last></author>
      <pages>165–178</pages>
      <url hash="40454036">2021.eval4nlp-1.17</url>
      <bibkey>fomicheva-etal-2021-eval4nlp</bibkey>
      <pwccode url="https://github.com/eval4nlp/sharedtask2021" additional="false">eval4nlp/sharedtask2021</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/mlqe-pe">MLQE-PE</pwcdataset>
    </paper>
    <paper id="18">
      <title>Developing a Benchmark for Reducing Data Bias in Authorship Attribution</title>
      <author><first>Benjamin</first><last>Murauer</last></author>
      <author><first>Günther</first><last>Specht</last></author>
      <pages>179–188</pages>
      <url hash="45fe0245">2021.eval4nlp-1.18</url>
      <bibkey>murauer-specht-2021-developing</bibkey>
    </paper>
    <paper id="19">
      <title>Error-Sensitive Evaluation for Ordinal Target Variables</title>
      <author><first>David</first><last>Chen</last></author>
      <author><first>Maury</first><last>Courtland</last></author>
      <author><first>Adam</first><last>Faulkner</last></author>
      <author><first>Aysu</first><last>Ezen-Can</last></author>
      <pages>189–199</pages>
      <url hash="13c8fc43">2021.eval4nlp-1.19</url>
      <bibkey>chen-etal-2021-error</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/imdb-movie-reviews">IMDb Movie Reviews</pwcdataset>
    </paper>
    <paper id="20">
      <title><fixed-case>H</fixed-case>in<fixed-case>GE</fixed-case>: A Dataset for Generation and Evaluation of Code-Mixed <fixed-case>H</fixed-case>inglish Text</title>
      <author><first>Vivek</first><last>Srivastava</last></author>
      <author><first>Mayank</first><last>Singh</last></author>
      <pages>200–208</pages>
      <url hash="253ab5a8">2021.eval4nlp-1.20</url>
      <bibkey>srivastava-singh-2021-hinge</bibkey>
    </paper>
    <paper id="21">
      <title>What is <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val evaluating? A Systematic Analysis of Evaluation Campaigns in <fixed-case>NLP</fixed-case></title>
      <author><first>Oskar</first><last>Wysocki</last></author>
      <author><first>Malina</first><last>Florea</last></author>
      <author><first>Dónal</first><last>Landers</last></author>
      <author><first>André</first><last>Freitas</last></author>
      <pages>209–229</pages>
      <url hash="cc8a3d19">2021.eval4nlp-1.21</url>
      <bibkey>wysocki-etal-2021-semeval</bibkey>
    </paper>
    <paper id="22">
      <title>The <fixed-case>UMD</fixed-case> Submission to the Explainable <fixed-case>MT</fixed-case> Quality Estimation Shared Task: Combining Explanation Models with Sequence Labeling</title>
      <author><first>Tasnim</first><last>Kabir</last></author>
      <author><first>Marine</first><last>Carpuat</last></author>
      <pages>230–237</pages>
      <url hash="3598babf">2021.eval4nlp-1.22</url>
      <bibkey>kabir-carpuat-2021-umd</bibkey>
    </paper>
    <paper id="23">
      <title>Explaining Errors in Machine Translation with Absolute Gradient Ensembles</title>
      <author><first>Melda</first><last>Eksi</last></author>
      <author><first>Erik</first><last>Gelbing</last></author>
      <author><first>Jonathan</first><last>Stieber</last></author>
      <author><first>Chi Viet</first><last>Vu</last></author>
      <pages>238–249</pages>
      <url hash="18898d31">2021.eval4nlp-1.23</url>
      <bibkey>eksi-etal-2021-explaining</bibkey>
      <pwccode url="https://github.com/sinisterthaumaturge/metascience-explainable-metrics" additional="false">sinisterthaumaturge/metascience-explainable-metrics</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/mlqe-pe">MLQE-PE</pwcdataset>
    </paper>
    <paper id="24">
      <title>Explainable Quality Estimation: <fixed-case>CUNI</fixed-case> <fixed-case>E</fixed-case>val4<fixed-case>NLP</fixed-case> Submission</title>
      <author><first>Peter</first><last>Polák</last></author>
      <author><first>Muskaan</first><last>Singh</last></author>
      <author><first>Ondřej</first><last>Bojar</last></author>
      <pages>250–255</pages>
      <url hash="b2104e7f">2021.eval4nlp-1.24</url>
      <bibkey>polak-etal-2021-explainable</bibkey>
      <pwccode url="https://github.com/pe-trik/eval4nlp-2021" additional="false">pe-trik/eval4nlp-2021</pwccode>
    </paper>
  </volume>
</collection>
