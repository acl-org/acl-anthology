<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.termtrends">
  <volume id="1" ingest-date="2025-09-27" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 5th Conference on Language, Data and Knowledge: TermTrends 2025</booktitle>
      <editor><first>Katerina</first><last>Gkirtzou</last><affiliation>ILSP ``Athena'' Research Center, Greece</affiliation></editor>
      <editor><first>Slavko</first><last>Žitnik</last><affiliation>University of Ljubljana, Slovenia</affiliation></editor>
      <editor><first>Jorge</first><last>Gracia</last><affiliation>University of Zaragoza, Spain</affiliation></editor>
      <editor><first>Dagmar</first><last>Gromann</last><affiliation>University of Vienna, Austria</affiliation></editor>
      <editor><first>Maria Pia</first><last>di Buono</last><affiliation>University of Naples “L’Orientale”, Italy</affiliation></editor>
      <editor><first>Johanna</first><last>Monti</last><affiliation>University of Naples “L’Orientale”, Italy</affiliation></editor>
      <editor><first>Maxim</first><last>Ionov</last><affiliation>University of Zaragoza, Spain</affiliation></editor>
      <publisher>Unior Press</publisher>
      <address>Naples, Italy</address>
      <month>September</month>
      <year>2025</year>
      <url hash="298db081">2025.termtrends-1</url>
      <venue>termtrends</venue>
      <venue>ws</venue>
      <isbn>978-88-6719-334-9</isbn>
    </meta>
    <frontmatter>
      <url hash="44196da8">2025.termtrends-1.0</url>
      <bibkey>termtrends-ws-2025-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title>The <fixed-case>LegISTyr</fixed-case> Test Set: Investigating Off-the-Shelf Instruction-Tuned <fixed-case>LLM</fixed-case>s for Terminology-Constrained Translation in a Low-Resource Language Variety</title>
      <author><first>Paolo</first><last>Di Natale</last></author>
      <author><first>Egon W.</first><last>Stemle</last></author>
      <author><first>Elena</first><last>Chiocchetti</last></author>
      <author><first>Marlies</first><last>Alber</last></author>
      <author><first>Natascia</first><last>Ralli</last></author>
      <author><first>Isabella</first><last>Stanizzi</last></author>
      <author><first>Elena</first><last>Benini</last></author>
      <pages>1-15</pages>
      <abstract>We investigate the effect of terminology injection for terminology-constrained translation in a low-resource language variety, with a particular focus on off-the-shelf instruction-tuned Large Language Models (LLMs). We compare a total of 9 models: 4 instruction-tuned LLMs from the Tower and EuroLLM suites, which have been specifically trained for translation-related tasks; 2 generic open-weight LLMs (LLaMA-8B and Mistral-7B); 3 Neural Machine Translation (NMT) systems (an adapted version of MarianMT and ModernMT with and without the glossary function). To this end, we release LegISTyr, a manually curated test set of 2,000 Italian sentences from the legal domain, paired with source Italian terms and target terms in the South Tyrolean standard variety of German. We select only real-world sources and design constraints on length, syntactic clarity, and referential coherence to ensure high quality. LegISTyr includes a homonym subset, which challenges systems on the selection of the correct homonym where sense disambiguation is deducible from the context. Results show that while generic LLMs achieve the highest raw term insertion rates (approximately 64%), translation-specialized LLMs deliver superior fluency (∆ COMET up to 0.04), reduce incorrect homonym selection by half, and generate more controllable output. We posit that models trained on translation-related data are better able to focus on source-side information, producing more coherent translations.</abstract>
      <url hash="23f8b917">2025.termtrends-1.1</url>
      <bibkey>di-natale-etal-2025-legistyr</bibkey>
    </paper>
    <paper id="2">
      <title>Terminology Management Meets <fixed-case>AI</fixed-case>: The <fixed-case>ISO</fixed-case>/<fixed-case>TC</fixed-case> 37/<fixed-case>SC</fixed-case> 3/<fixed-case>WG</fixed-case> 6 Initiative</title>
      <author><first>Mohamed</first><last>Khemakhem</last></author>
      <author><first>Cristina</first><last>Valentini</last></author>
      <author><first>Natascia</first><last>Ralli</last></author>
      <author><first>Sérgio</first><last>Barros</last></author>
      <author><first>Georg</first><last>Löckinger</last></author>
      <author><first>Federica</first><last>Vezzani</last></author>
      <author><first>Ana</first><last>Salgado</last></author>
      <author><first>Zhenling</first><last>Zhang</last></author>
      <author><first>Sabine</first><last>Mahr</last></author>
      <author><first>Sara</first><last>Carvalho</last></author>
      <author><first>Klaus</first><last>Fleischmann</last></author>
      <author><first>Rute</first><last>Costa</last></author>
      <pages>16-24</pages>
      <abstract>The integration of artificial intelligence (AI) with terminology management (TM) has opened new avenues for enhancing efficiency and precision in both fields, necessitating standardized approaches to ensure interoperability and ethical application. The newly formed ISO/TC 37/SC 3/WG 6 represents the first dedicated initiative to study the standardization of the mutual improvements of AI and TM. This group aims to develop standardized frameworks and guidelines that optimize the interaction between AI technologies and terminology resources, benefiting professionals, systems, and practices in both domains. This article presents the state-of-the-art in the mutual relationship between AI and TM, highlighting opportunities for bidirectional advancements. It also addresses limitations and challenges from a standardization perspective. By tackling these issues, ISO/TC 37/SC 3/WG 6 seeks to establish principles that ensure scalability, precision, and ethical considerations, shaping future standards to support global communication and knowledge exchange.</abstract>
      <url hash="f080f451">2025.termtrends-1.2</url>
      <bibkey>khemakhem-etal-2025-terminology</bibkey>
    </paper>
    <paper id="3">
      <title>Inferring Semantic Relations Between Terms with Large Language Models</title>
      <author><first>Giulia</first><last>Speranza</last></author>
      <pages>25-30</pages>
      <abstract>The purpose of this paper is to investigate the ability of Large Language Models (LLMs) to identify relations among terms, with the goal of facilitating and accelerating the construction of thesauri and terminological resources. We investigate whether the use of LLMs in this context can provide a valuable initial set of relations, serving as a basis upon which professional terminologists can build, validate, and enrich domain-specific knowledge representations.</abstract>
      <url hash="7cb365e0">2025.termtrends-1.3</url>
      <bibkey>speranza-2025-inferring</bibkey>
    </paper>
  </volume>
</collection>
