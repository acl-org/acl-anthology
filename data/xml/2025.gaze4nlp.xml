<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.gaze4nlp">
  <volume id="1" ingest-date="2026-01-07" type="proceedings">
    <meta>
      <booktitle>Proceedings of the First International Workshop on Gaze Data and Natural Language Processing</booktitle>
      <editor><first>Cengiz</first><last>Acarturk</last></editor>
      <editor id="jamal-a-nasir"><first>Jamal</first><last>Nasir</last></editor>
      <editor><first>Burcu</first><last>Can</last></editor>
      <editor><first>Cagrı</first><last>Coltekin</last></editor>
      <publisher>INCOMA Ltd., Shoumen, BULGARIA</publisher>
      <address>Varna, Bulgaria</address>
      <month>September</month>
      <year>2025</year>
      <url hash="917f56b5">2025.gaze4nlp-1</url>
      <venue>gaze4nlp</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="b31101a5">2025.gaze4nlp-1.0</url>
      <bibkey>gaze4nlp-ws-2025-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title>What Determines Where Readers Fixate Next? Leveraging <fixed-case>NLP</fixed-case> to Investigate Human Cognition</title>
      <author><first>Adrielli Tina Lopes</first><last>Rego</last></author>
      <author><first>Joshua</first><last>Snell</last></author>
      <author><first>Martijn</first><last>Meeter</last></author>
      <pages>1–6</pages>
      <abstract>During reading, readers perform rapid forward and backward eye movements through text, called saccades. How these saccades are targeted in the text is not yet fully known, particularly regarding the role of higher-order linguistic processes in guiding eye-movement behaviour in naturalistic reading. Current models of eye movement simulation in reading either limit the role of high-order linguistic information or lack explainability and cognitive plausibility. In this study, we investigate the influence of linguistic information on saccade targeting, i.e. determining where to move our eyes next, by predicting which word is fixated next based on a limited processing window that resembles the amount of information humans readers can presumably process in parallel within the visual field at each fixation. Our preliminary results suggest that, while word length and frequency are important factors for determining the target of forward saccades, the contextualized meaning of the previous sequence, as well as whether the context word had been fixated before and the distance of the previous saccade, are important factors for predicting backward saccades.</abstract>
      <url hash="7f47ee82">2025.gaze4nlp-1.1</url>
      <bibkey>rego-etal-2025-determines</bibkey>
    </paper>
    <paper id="2">
      <title>Benchmarking Language Model Surprisal for Eye-Tracking Predictions in <fixed-case>B</fixed-case>razilian <fixed-case>P</fixed-case>ortuguese</title>
      <author><first>Diego</first><last>Alves</last></author>
      <pages>7–17</pages>
      <abstract>This study evaluates the effectiveness of surprisal estimates from six publicly available large language models (LLMs) in predicting reading times in Brazilian Portuguese (BP), using eye-tracking data from the RastrOS corpus. We analyze three key reading time measures: first fixation duration, gaze duration, and total fixation time. Our results demonstrate that surprisal significantly predicts all three measures, with a consistently linear effect observed across all models and the strongest effect for total fixation duration. We also find that larger model size does not necessarily provide better surprisal estimates. Additionally, entropy reduction derived from Cloze norms adds minimal predictive value beyond surprisal, and only for first fixation duration. These findings replicate known surprisal effects in BP and provide novel insights into how different models and linguistic predictors influence reading time predictions.</abstract>
      <url hash="c57345e7">2025.gaze4nlp-1.2</url>
      <bibkey>alves-2025-benchmarking</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>E</fixed-case>go<fixed-case>D</fixed-case>rive: Egocentric Multimodal Driver Behavior Recognition Using Project Aria</title>
      <author><first>Michael</first><last>Rice</last></author>
      <author><first>Lorenz</first><last>Krause</last></author>
      <author><first>Waqar Shahid</first><last>Qureshi</last></author>
      <pages>18–25</pages>
      <abstract>Egocentric sensing using wearable devices offers a unique first-person perspective for driver behaviour analysis and monitoring, with the potential to accurately capture rich multimodal cues such as eye gaze, head motion, and hand activity directly from the driver’s viewpoint. In this paper, we introduce a multimodal driver behaviour recognition framework utilizing Meta’s Project Aria smart glasses, along with a novel, synchronized egocentric driving dataset comprising high-resolution Red Green Blue (RGB) video, gaze-tracking data, Inertial Measurement Unit (IMU) signals, hand pose landmarks, and YOLO-based semantic object detections. All sensor data streams are temporally aligned and segmented into fixed-length clips, each manually annotated with one of six distinct driver behavior classes: <i>Driving</i>, <i>Left Mirror Check</i>, <i>Right Wing Mirror Check</i>, <i>Rear-view Mirror Check</i>, <i>Mobile Phone Usage</i>, and <i>Idle</i>. We design a Transformer-based recognition framework in which each modality is processed by a specialized encoder and then fused via Temporal Transformer layers to capture cross-modal temporal dependencies. To investigate the trade-off between accuracy and efficiency for real-time deployment, we introduce two model variants: EgoDriveMax, optimized for maximum accuracy, and EgoDriveRT, designed for real-time performance. These models achieve classification accuracies of 98.6% and 97.4% respectively. Notably, EgoDriveRT delivers strong performance despite operating with only 104K parameters and requiring just 2.65 ms per inference without the use of a specialized GPU—highlighting its potential for efficient, real-time in-cabin driver monitoring.</abstract>
      <url hash="b3932e92">2025.gaze4nlp-1.3</url>
      <bibkey>rice-etal-2025-egodrive</bibkey>
    </paper>
    <paper id="4">
      <title>Comparing Eye-gaze and Transformer Attention Mechanisms in Reading Tasks</title>
      <author><first>Maria</first><last>Mouratidi</last></author>
      <author id="massimo-poesio"><first>Massimo</first><last>Poesio</last></author>
      <pages>26–36</pages>
      <abstract>As transformers become increasingly prevalent in NLP research, evaluating their cognitive alignment with human language processing has become essential for validating them as models of human language. This study compares eye-gaze patterns in human reading with transformer attention using different attention representations (raw attention, attention flow, gradient-based saliency). We employ both statistical correlation analysis and predictive modeling using PCA-reduced representations of eye-tracking features across two reading tasks. The findings reveal lower correlations and predictive capacity for the decoder model compared to the encoder model, with implications for the gap between behavioral performance and cognitive plausibility of different transformer designs.</abstract>
      <url hash="b701b705">2025.gaze4nlp-1.4</url>
      <bibkey>mouratidi-poesio-2025-comparing</bibkey>
    </paper>
    <paper id="5">
      <title>A <fixed-case>F</fixed-case>rench Eye-Tracking Corpus of Original and Simplified Medical, Clinical, and General Texts - <fixed-case>FETA</fixed-case></title>
      <author><first>Oksana</first><last>Ivchenko</last></author>
      <author><first>Natalia</first><last>Grabar</last></author>
      <pages>37–43</pages>
      <abstract>Eye tracking offers an objective window on real-time cognitive processing of information being read: longer fixations, more regressions, and wider pupil dilation reliably index linguistic difficulty. Yet, there is a paucity of the available corpora annotated with eye-tracking features. We introduce in this paper the FETA corpus – a French Eye-TrAcking corpus. It combines three types of texts (general, medical and clinical) in two versions (original and manually simplified). These texts are read by 46 participants, from which we collect eye-tracking data through dozens of eye-tracking features.</abstract>
      <url hash="ad81ace7">2025.gaze4nlp-1.5</url>
      <bibkey>ivchenko-grabar-2025-french</bibkey>
    </paper>
    <paper id="6">
      <title>Exploring Mouse Tracking for Reading on <fixed-case>R</fixed-case>omanian Data</title>
      <author><first>Cristina Maria</first><last>Popescu</last></author>
      <author><first>Sergiu</first><last>Nisioi</last></author>
      <pages>44–51</pages>
      <abstract>In this paper, we investigate the use of the Mouse Tracking for Reading (MoTR) method for a sample of Romanian texts. MoTR is a novel measurement tool that is meant to collect word-by-word reading times. In a typical MoTR trial, the text is blurred, except for a small area around the mouse pointer and the participants must move the mouse to reveal and read the text. In the current experiment, participants read such texts and afterwords answered comprehension questions, aiming to evaluate reading behavior and cognitive engagement. Mouse movement is recorded and analyzed to evaluate attention distribution across a sentence, providing insights into incremental language processing. Based on all the information gathered, the study confirms the feasibility of this method in a controlled setting and emphasizes MoTR’s potential as an accessible and naturalistic approach for studying text comprehension.</abstract>
      <url hash="97bfee1f">2025.gaze4nlp-1.6</url>
      <bibkey>popescu-nisioi-2025-exploring</bibkey>
    </paper>
    <paper id="7">
      <title>Where Patients Slow Down: Surprisal, Uncertainty, and Simplification in <fixed-case>F</fixed-case>rench Clinical Reading</title>
      <author><first>Oksana</first><last>Ivchenko</last></author>
      <author><first>Alamgir Munir</first><last>Qazi</last></author>
      <author><first>Jamal</first><last>Abdul Nasir</last></author>
      <pages>52–57</pages>
      <abstract>This eye-tracking study links language-model surprisal and contextual entropy to how 23 non-expert adults read French health texts. Participants read seven texts (clinical case, medical, general), each available in an Original and Simplified version. Surprisal and entropy were computed with eight autoregressive models (82M–8B parameters), and four complementary eye-tracking measures were analyzed. Surprisal correlates positively with early reading measures, peaking in the smallest GPT-2 models (r ≈ 0.26) and weakening with model size. Entropy shows the opposite pattern, with negative correlations strongest in the 7B-8B models (r ≈ −0.13), consistent with a skim-when-uncertain strategy. Surprisal effects are largest in Clinical Original passages and drop by ∼20% after simplification, whereas entropy effects are stable across domain and version. These findings expose a scaling paradox – where different model sizes are optimal for different cognitive signals – and suggest that French plain-language editing should focus on rewriting high-surprisal passages to reduce processing difficulty, and on avoiding high-entropy contexts for critical information.</abstract>
      <url hash="5e096833">2025.gaze4nlp-1.7</url>
      <bibkey>ivchenko-etal-2025-patients</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>A</fixed-case>l<fixed-case>EYE</fixed-case>gnment: Leveraging <fixed-case>E</fixed-case>ye‐<fixed-case>T</fixed-case>racking‐<fixed-case>W</fixed-case>hile‐<fixed-case>R</fixed-case>eading to Align Language Models with Human Preferences</title>
      <author><first>Anna</first><last>Bondar</last></author>
      <author><first>David Robert</first><last>Reich</last></author>
      <author><first>Lena Ann</first><last>Jäger</last></author>
      <pages>58–70</pages>
      <abstract>Direct Preference Optimisation (DPO) has emerged as an effective approach for aligning large language models (LLMs) with human preferences. However, its reliance on binary feedback restricts its ability to capture nuanced human judgements. To address this limitation, we introduce a gaze-informed extension that incorporates implicit, fine-grained signals from eye-tracking-while-reading into the DPO framework. Eye movements, reflecting real-time human cognitive processing, provide fine-grained signals about the linguistic characteristics of the text that is being read. We leverage these signals and modify DPO by introducing a gaze-based additional loss term, that quantifies the differences between the model’s internal sentence representations and cognitive (i.e., gaze-based) representations derived from the readers’ gaze patterns. We explore the use of both human and synthetic gaze signals, employing a generative model of eye movements in reading to generate supplementary training data, ensuring the scalability of our approach. We apply the proposed approach to modelling linguistic acceptability. Experiments conducted on the CoLA dataset demonstrate performance gains in grammatical acceptability classification tasks when the models are trained in the gaze-augmented setting. These results demonstrate the utility of leveraging gaze data to align language models with human preferences. All code and data are available from Github.</abstract>
      <url hash="f331a0b7">2025.gaze4nlp-1.8</url>
      <bibkey>bondar-etal-2025-aleyegnment</bibkey>
    </paper>
    <paper id="9">
      <title>Predicting Total Reading Time Using <fixed-case>R</fixed-case>omanian Eye-Tracking Data</title>
      <author><first>Anamaria</first><last>Hodivoianu</last></author>
      <author><first>Oleksandra</first><last>Kuvshynova</last></author>
      <author><first>Filip</first><last>Popovici</last></author>
      <author><first>Adrian</first><last>Luca</last></author>
      <author><first>Sergiu</first><last>Nisioi</last></author>
      <pages>71–75</pages>
      <abstract>This work introduces the first Romanian eye-tracking dataset for reading and investigates methods for predicting word-level total reading times. We develop and compare a range of models, from traditional machine learning using handcrafted linguistic features to fine-tuned Romanian BERT architectures, demonstrating strong correlations between predicted and observed reading times. Additionally, we propose a lexical simplification pipeline that leverages these TRT predictions to identify and substitute complex words, enhancing text readability. Our approach is integrated into an interactive web tool, illustrating the practical benefits of combining cognitive signals with NLP techniques for Romanian — a language with limited resources in this area.</abstract>
      <url hash="37c28291">2025.gaze4nlp-1.9</url>
      <bibkey>hodivoianu-etal-2025-predicting</bibkey>
    </paper>
  </volume>
</collection>
