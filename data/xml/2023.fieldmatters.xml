<?xml version='1.0' encoding='UTF-8'?>
<collection id="2023.fieldmatters">
  <volume id="1" ingest-date="2023-06-20" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Second Workshop on NLP Applications to Field Linguistics</booktitle>
      <editor><first>Oleg</first><last>Serikov</last></editor>
      <editor><first>Ekaterina</first><last>Voloshina</last></editor>
      <editor><first>Anna</first><last>Postnikova</last></editor>
      <editor><first>Elena</first><last>Klyachko</last></editor>
      <editor><first>Ekaterina</first><last>Vylomova</last></editor>
      <editor><first>Tatiana</first><last>Shavrina</last></editor>
      <editor><first>Eric</first><last>Le Ferrand</last></editor>
      <editor><first>Valentin</first><last>Malykh</last></editor>
      <editor><first>Francis</first><last>Tyers</last></editor>
      <editor><first>Timofey</first><last>Arkhangelskiy</last></editor>
      <editor><first>Vladislav</first><last>Mikhailov</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Dubrovnik, Croatia</address>
      <month>May</month>
      <year>2023</year>
      <url hash="eadc5e20">2023.fieldmatters-1</url>
      <venue>fieldmatters</venue>
    </meta>
    <frontmatter>
      <url hash="e1a753db">2023.fieldmatters-1.0</url>
      <bibkey>fieldmatters-2023-nlp</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Automated speech recognition of <fixed-case>I</fixed-case>ndonesian-<fixed-case>E</fixed-case>nglish language lessons on <fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube using transfer learning</title>
      <author><first>Zara</first><last>Maxwell-Smith</last><affiliation>Anu</affiliation></author>
      <author><first>Ben</first><last>Foley</last><affiliation>University of Queensland</affiliation></author>
      <pages>1-16</pages>
      <abstract>Experiments to fine-tune large multilingual models with limited data from a specific domain or setting has potential to improve automatic speech recognition (ASR) outcomes. This paper reports on the use of the Elpis ASR pipeline to fine-tune two pre-trained base models, Wav2Vec2-XLSR-53 and Wav2Vec2-Large-XLSR-Indonesian, with various mixes of data from 3 YouTube channels teaching Indonesian with English as the language of instruction. We discuss our results inferring new lesson audio (22-46% word error rate) in the context of speeding data collection in diverse and specialised settings. This study is an example of how ASR can be used to accelerate natural language research, expanding ethically sourced data in low-resource settings.</abstract>
      <url hash="d39f1fc8">2023.fieldmatters-1.1</url>
      <bibkey>maxwelll-smith-foley-2023-automated</bibkey>
      <video href="2023.fieldmatters-1.1.mp4"/>
      <doi>10.18653/v1/2023.fieldmatters-1.1</doi>
    </paper>
    <paper id="2">
      <title>Application of Speech Processes for the Documentation of Kréyòl Gwadloupéyen</title>
      <author><first>Éric</first><last>Le Ferrand</last><affiliation>Université d’Orléans</affiliation></author>
      <author><first>Fabiola</first><last>Henri</last><affiliation>University at Buffalo</affiliation></author>
      <author><first>Benjamin</first><last>Lecouteux</last><affiliation>Lig/getalp</affiliation></author>
      <author><first>Emmanuel</first><last>Schang</last><affiliation>Université d’Orléans</affiliation></author>
      <pages>17-22</pages>
      <abstract>In recent times, there has been a growing number of research studies focused on addressing the challenges posed by low-resource languages and the transcription bottleneck phenomenon. This phenomenon has driven the development of speech recognition methods to transcribe regional and Indigenous languages automatically. Although there is much talk about bridging the gap between speech technologies and field linguistics, there is a lack of documented efficient communication between NLP experts and documentary linguists. The models created for low-resource languages often remain within the confines of computer science departments, while documentary linguistics remain attached to traditional transcription workflows. This paper presents the early stage of a collaboration between NLP experts and field linguists, resulting in the successful transcription of Kréyòl Gwadloupéyen using speech recognition technology.</abstract>
      <url hash="994fcfe0">2023.fieldmatters-1.2</url>
      <bibkey>le-ferrand-etal-2023-application</bibkey>
      <doi>10.18653/v1/2023.fieldmatters-1.2</doi>
    </paper>
    <paper id="3">
      <title>Unsupervised part-of-speech induction for language description: Modeling documentation materials in Kolyma <fixed-case>Y</fixed-case>ukaghir</title>
      <author><first>Albert</first><last>Ventayol-boada</last><affiliation>University of California, Santa Barbara</affiliation></author>
      <author><first>Nathan</first><last>Roll</last><affiliation>University of California, Santa Barbara</affiliation></author>
      <author><first>Simon</first><last>Todd</last><affiliation>University of California, Santa Barbara</affiliation></author>
      <pages>23-29</pages>
      <abstract>This study investigates the clustering of words into Part-of-Speech (POS) classes in Kolyma Yukaghir. In grammatical descriptions, lexical items are assigned to POS classes based on their morphological paradigms. Discursively, however, these classes share a fair amount of morphology. In this study, we turn to POS induction to evaluate if classes based on quantification of the distributions in which roots and affixes are used can be useful for language description purposes, and, if so, what those classes might be. We qualitatively compare clusters of roots and affixes based on four different definitions of their distributions. The results show that clustering is more reliable for words that typically bear more morphology. Additionally, the results suggest that the number of POS classes in Kolyma Yukaghir might be smaller than stated in current descriptions. This study thus demonstrates how unsupervised learning methods can provide insights for language description, particularly for highly inflectional languages.</abstract>
      <url hash="415bb247">2023.fieldmatters-1.3</url>
      <bibkey>ventayol-boada-etal-2023-unsupervised</bibkey>
      <video href="2023.fieldmatters-1.3.mp4"/>
      <doi>10.18653/v1/2023.fieldmatters-1.3</doi>
    </paper>
    <paper id="4">
      <title>Speech Database (Speech-<fixed-case>DB</fixed-case>) – An on-line platform for storing, validating, searching, and recording spoken language data</title>
      <author><first>Jolene</first><last>Poulin</last><affiliation>University of Alberta</affiliation></author>
      <author><first>Daniel</first><last>Dacanay</last><affiliation>University of Alberta</affiliation></author>
      <author><first>Antti</first><last>Arppe</last><affiliation>University of Alberta</affiliation></author>
      <pages>30-39</pages>
      <abstract>The Speech Database (Speech-DB: URL: <url>https://speech-db.altlab.app</url>) is an on-line platform for language documentation, written and spoken language validation, and speech exploration; its code-base is available as open source. In its current state, Speech-DB has expanded to contain content for several Indigenous languages spoken in Western Canada, having started with audio for the dialect of Plains Cree spoken in Maskwacîs, Alberta, Canada. Currently, it is used primarily for validation and storage. It can be accessed by anyone with an internet connection in six levels of access rights. What follows is the rationale for the development of speech-DB, an exploration of its features, and a description of usage scenarios, as well as initial user feedback on the application.</abstract>
      <url hash="86b5d346">2023.fieldmatters-1.4</url>
      <bibkey>poulin-etal-2023-speech</bibkey>
      <video href="2023.fieldmatters-1.4.mp4"/>
      <doi>10.18653/v1/2023.fieldmatters-1.4</doi>
    </paper>
    <paper id="5">
      <title><fixed-case>ASR</fixed-case> pipeline for low-resourced languages: A case study on Pomak</title>
      <author><first>Chara</first><last>Tsoukala</last><affiliation>Athena Research Center</affiliation></author>
      <author><first>Kosmas</first><last>Kritsis</last><affiliation>Athena Research Center</affiliation></author>
      <author><first>Ioannis</first><last>Douros</last><affiliation>Athena Research Center</affiliation></author>
      <author><first>Athanasios</first><last>Katsamanis</last><affiliation>Athena R.C., Behavioral Signals</affiliation></author>
      <author><first>Nikolaos</first><last>Kokkas</last><affiliation>Athena Research Center</affiliation></author>
      <author><first>Vasileios</first><last>Arampatzakis</last><affiliation>Athena Research Center</affiliation></author>
      <author><first>Vasileios</first><last>Sevetlidis</last><affiliation>Athena Research Center</affiliation></author>
      <author><first>Stella</first><last>Markantonatou</last><affiliation>ILSP/R.C. “Athena”</affiliation></author>
      <author><first>George</first><last>Pavlidis</last><affiliation>Athena Research Center</affiliation></author>
      <pages>40-45</pages>
      <abstract>Automatic Speech Recognition (ASR) models can aid field linguists by facilitating the creation of text corpora from oral material. Training ASR systems for low-resource languages can be a challenging task not only due to lack of resources but also due to the work required for the preparation of a training dataset. We present a pipeline for data processing and ASR model training for low-resourced languages, based on the language family. As a case study, we collected recordings of Pomak, an endangered South East Slavic language variety spoken in Greece. Using the proposed pipeline, we trained the first Pomak ASR model.</abstract>
      <url hash="878e1623">2023.fieldmatters-1.5</url>
      <bibkey>tsoukala-etal-2023-asr</bibkey>
      <video href="2023.fieldmatters-1.5.mp4"/>
      <doi>10.18653/v1/2023.fieldmatters-1.5</doi>
    </paper>
    <paper id="6">
      <title>Improving Low-resource <fixed-case>RRG</fixed-case> Parsing with Structured Gloss Embeddings</title>
      <author><first>Roland</first><last>Eibers</last><affiliation>Heinrich Heine University Düsseldorf</affiliation></author>
      <author><first>Kilian</first><last>Evang</last><affiliation>Heinrich Heine University Düsseldorf</affiliation></author>
      <author><first>Laura</first><last>Kallmeyer</last><affiliation>University of Duesseldorf</affiliation></author>
      <pages>46-51</pages>
      <abstract>Treebanking for local languages is hampered by the lack of existing parsers to generate pre-annotations. However, it has been shown that reasonably accurate parsers can be bootstrapped with little initial training data when use is made of the information in interlinear glosses and translations that language documentation data for such treebanks typically comes with. In this paper, we improve upon such a bootstrapping model by representing glosses using a combination of morphological feature vectors and pre-trained lemma embeddings. We also contribute a mapping from glosses to Universal Dependencies morphological features.</abstract>
      <url hash="1df08bc9">2023.fieldmatters-1.6</url>
      <bibkey>eibers-etal-2023-improving</bibkey>
      <doi>10.18653/v1/2023.fieldmatters-1.6</doi>
    </paper>
    <paper id="7">
      <title>Approaches to Corpus Creation for Low-Resource Language Technology: the Case of <fixed-case>S</fixed-case>outhern <fixed-case>K</fixed-case>urdish and <fixed-case>L</fixed-case>aki</title>
      <author><first>Sina</first><last>Ahmadi</last><affiliation>George Mason University</affiliation></author>
      <author><first>Zahra</first><last>Azin</last><affiliation>School of Linguistics and Language Studies, Carleton University</affiliation></author>
      <author><first>Sara</first><last>Belelli</last><affiliation>Università degli Studi della Tuscia, Viterbo, Italy</affiliation></author>
      <author><first>Antonios</first><last>Anastasopoulos</last><affiliation>George Mason University</affiliation></author>
      <pages>52-63</pages>
      <abstract>One of the major challenges that under-represented and endangered language communities face in language technology is the lack or paucity of language data. This is also the case of the Southern varieties of the Kurdish and Laki languages for which very limited resources are available with insubstantial progress in tools. To tackle this, we provide a few approaches that rely on the content of local news websites, a local radio station that broadcasts content in Southern Kurdish and fieldwork for Laki. In this paper, we describe some of the challenges of such under-represented languages, particularly in writing and standardization, and also, in retrieving sources of data and retro-digitizing handwritten content to create a corpus for Southern Kurdish and Laki. In addition, we study the task of language identification in light of the other variants of Kurdish and Zaza-Gorani languages.</abstract>
      <url hash="ce444dd6">2023.fieldmatters-1.7</url>
      <bibkey>ahmadi-etal-2023-approaches</bibkey>
      <video href="2023.fieldmatters-1.7.mp4"/>
      <doi>10.18653/v1/2023.fieldmatters-1.7</doi>
    </paper>
    <paper id="8">
      <title><fixed-case>A</fixed-case>ra<fixed-case>D</fixed-case>ia<fixed-case>WER</fixed-case>: An Explainable Metric For Dialectical <fixed-case>A</fixed-case>rabic <fixed-case>ASR</fixed-case></title>
      <author><first>Abdulwahab</first><last>Sahyoun</last><affiliation>Graduate Researcher</affiliation></author>
      <author><first>Shady</first><last>Shehata</last><affiliation>Associate Professor (Affiliated) - Natural Language Processing</affiliation></author>
      <pages>64-73</pages>
      <abstract>Linguistic variability poses a challenge to many modern ASR systems, particularly Dialectical Arabic (DA) ASR systems dealing with low-resource dialects and resulting morphological and orthographic variations in text and speech. Traditional evaluation metrics such as the word error rate (WER) inadequately capture these complexities, leading to an incomplete assessment of DA ASR performance. We propose AraDiaWER, an ASR evaluation metric for Dialectical Arabic (DA) speech recognition systems, focused on the Egyptian dialect. AraDiaWER uses language model embeddings for the syntactic and semantic aspects of ASR errors to identify their root cause, not captured by traditional WER. MiniLM generates the semantic score, capturing contextual differences between reference and predicted transcripts. CAMeLBERT-Mix assigns morphological and lexical tags using a fuzzy matching algorithm to calculate the syntactic score. Our experiments validate the effectiveness of AraDiaWER. By incorporating language model embeddings, AraDiaWER enables a more interpretable evaluation, allowing us to improve DA ASR systems. We position the proposed metric as a complementary tool to WER, capturing syntactic and semantic features not represented by WER. Additionally, we use UMAP analysis to observe the quality of ASR embeddings in the proposed evaluation framework.</abstract>
      <url hash="008a6ca7">2023.fieldmatters-1.8</url>
      <bibkey>sahyoun-shehata-2023-aradiawer</bibkey>
      <video href="2023.fieldmatters-1.8.mp4"/>
      <doi>10.18653/v1/2023.fieldmatters-1.8</doi>
    </paper>
    <paper id="9">
      <title>A Quest for Paradigm Coverage: The Story of <fixed-case>N</fixed-case>en</title>
      <author><first>Saliha</first><last>Muradoglu</last><affiliation>The Australian National University</affiliation></author>
      <author><first>Hanna</first><last>Suominen</last><affiliation>The Australian National University and University of Turku</affiliation></author>
      <author><first>Nicholas</first><last>Evans</last><affiliation>The Australian National University</affiliation></author>
      <pages>74-85</pages>
      <abstract>Language documentation aims to collect a representative corpus of the language. Nevertheless, the question of how to quantify the comprehensive of the collection persists. We propose leveraging computational modelling to provide a supplementary metric to address this question in a low-resource language setting. We apply our proposed methods to the Papuan language Nen. Nen is actively in the process of being described and documented. Given the enormity of the task of language documentation, we focus on one subdomain, namely Nen verbal morphology. This study examines four verb types: copula, positional, middle, and transitive. We propose model-based paradigm generation for each verb type as a new way to measure completeness, where accuracy is analogous to the coverage of the paradigm. We contrast the paradigm attestation within the corpus (constructed from fieldwork data) and the accuracy of the paradigm generated by Transformer models trained for inflection. This analysis is extended by extrapolating from the learning curve established to provide predictions for the quantity of data required to generate a complete paradigm correctly. We also explore the correlation between high-frequency morphosyntactic features and model accuracy. We see a positive correlation between high-frequency feature combinations and model accuracy, but this is only sometimes the case. We also see high accuracy for low-frequency morphosyntactic features. Our results show that model coverage is significantly higher for the middle and transitive verbs but not the positional verb. This is an interesting finding, as the positional verb paradigm is the smallest of the four.</abstract>
      <url hash="0b2e5dbc">2023.fieldmatters-1.9</url>
      <bibkey>muradoglu-etal-2023-quest</bibkey>
      <video href="2023.fieldmatters-1.9.mp4"/>
      <doi>10.18653/v1/2023.fieldmatters-1.9</doi>
    </paper>
    <paper id="10">
      <title>Multilingual Automatic Extraction of Linguistic Data from Grammars</title>
      <author><first>Albert</first><last>Kornilov</last><affiliation>National Research University Higher School of Economics</affiliation></author>
      <pages>86-94</pages>
      <abstract>One of the goals of field linguistics is compilation of descriptive grammars for relatively little-studied languages. Until recently, extracting linguistic characteristics from grammatical descriptions and creating databases based on them was done manually. The aim of this paper is to apply methods of multilingual automatic information extraction to grammatical descriptions written in different languages of the world: we present a search engine for grammars, which would accelerate the tedious and time-consuming process of searching for information about linguistic features and facilitate research in the field of linguistic typology.</abstract>
      <url hash="320cecfd">2023.fieldmatters-1.10</url>
      <bibkey>kornilov-2023-multilingual</bibkey>
      <video href="2023.fieldmatters-1.10.mp4"/>
      <doi>10.18653/v1/2023.fieldmatters-1.10</doi>
    </paper>
  </volume>
</collection>
