<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.alta">
  <volume id="1" ingest-date="2025-01-29" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 22nd Annual Workshop of the Australasian Language Technology Association</booktitle>
      <editor><first>Tim</first><last>Baldwin</last></editor>
      <editor><first>Sergio José</first><last>Rodríguez Méndez</last></editor>
      <editor><first>Nicholas</first><last>Kuo</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Canberra, Australia</address>
      <month>December</month>
      <year>2024</year>
      <url hash="e77a07ac">2024.alta-1</url>
      <venue>alta</venue>
    </meta>
    <frontmatter>
      <url hash="bcdb6360">2024.alta-1.0</url>
      <bibkey>alta-2024-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Towards an Implementation of <fixed-case>R</fixed-case>hetorical <fixed-case>S</fixed-case>tructure <fixed-case>T</fixed-case>heory in Discourse Coherence Modelling</title>
      <author><first>Michael</first><last>Lambropoulos</last></author>
      <author><first>Shunichi</first><last>Ishihara</last></author>
      <pages>1-11</pages>
      <abstract>In this paper, we combine the discourse coherence principles of Elementary Discourse Unit segmentation and Rhetorical Structure Theory parsing to construct meaningful graph-based text representations. We then evaluate a Graph Convolutional Network and a Graph Attention Network on these representations. Our results establish a new benchmark in F1-score assessment for discourse coherence modelling while also showing that Graph Convolutional Network models are generally more computationally efficient and provide superior accuracy.</abstract>
      <url hash="d30b5e75">2024.alta-1.1</url>
      <bibkey>lambropoulos-ishihara-2024-towards</bibkey>
    </paper>
    <paper id="2">
      <title>Do <fixed-case>LLM</fixed-case>s Generate Creative and Visually Accessible Data visualisations?</title>
      <author><first>Clarissa</first><last>Miranda-Pena</last></author>
      <author><first>Andrew</first><last>Reeson</last></author>
      <author><first>Cécile</first><last>Paris</last></author>
      <author><first>Josiah</first><last>Poon</last></author>
      <author><first>Jonathan K.</first><last>Kummerfeld</last></author>
      <pages>12-29</pages>
      <abstract>Data visualisation is a valuable task that combines careful data processing with creative design. Large Language Models (LLMs) are now capable of responding to a data visualisation request in natural language with code that generates accurate data visualisations (e.g., using Matplotlib), but what about human-centered factors, such as the creativity and accessibility of the data visualisations? In this work, we study human perceptions of creativity in the data visualisations generated by LLMs, and propose metrics for accessibility. We generate a range of visualisations using GPT-4 and Claude-2 with controlled variations in prompt and inference parameters, to encourage the generation of different types of data visualisations for the same data. Subsets of these data visualisations are presented to people in a survey with questions that probe human perceptions of different aspects of creativity and accessibility. We find that the models produce visualisations that are novel, but not surprising. Our results also show that our accessibility metrics are consistent with human judgements. In all respects, the LLMs underperform visualisations produced by human-written code. To go beyond the simplest requests, these models need to become aware of human-centered factors, while maintaining accuracy.</abstract>
      <url hash="6495d186">2024.alta-1.2</url>
      <bibkey>miranda-pena-etal-2024-llms</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>G</fixed-case>en<fixed-case>ABSA</fixed-case>-Vec: Generative Aspect-Based Sentiment Feature Vectorization for Document-Level Sentiment Classification</title>
      <author><first>Liu</first><last>Minkang</last></author>
      <author><first>Jasy Liew</first><last>Suet Yan</last></author>
      <pages>30-40</pages>
      <abstract>Currently, document-level sentiment classification focuses on extracting text features directly using a deep neural network and representing the document through a high-dimensional vector. Such sentiment classifiers that directly accept text as input may not be able to capture more fine-grained sentiment representations based on different aspects in a review, which could be informative for document-level sentiment classification. We propose a method to construct a GenABSA feature vector containing five aspect-sentiment scores to represent each review document. We first generate an aspect-based sentiment analysis (ABSA) quadruple by finetuning the T5 pre-trained language model. The aspect term from each quadruple is then scored for sentiment using our sentiment lexicon fusion approach, SentLex-Fusion. For each document, we then aggregate the sentiment score belonging to the same aspect to derive the aspect-sentiment feature vector, which is subsequently used as input to train a document-level sentiment classifier. Based on a Yelp restaurant review corpus labeled with sentiment polarity containing 2040 documents, the sentiment classifier trained with ABSA features aggregated using geometric mean achieved the best performance compared to the baselines.</abstract>
      <url hash="55341300">2024.alta-1.3</url>
      <bibkey>minkang-suet-yan-2024-genabsa</bibkey>
    </paper>
    <paper id="4">
      <title>A Closer Look at Tool-based Logical Reasoning with <fixed-case>LLM</fixed-case>s: The Choice of Tool Matters</title>
      <author><first>Long Hei</first><last>Matthew Lam</last></author>
      <author><first>Ramya Keerthy</first><last>Thatikonda</last></author>
      <author><first>Ehsan</first><last>Shareghi</last></author>
      <pages>41-63</pages>
      <abstract>The emergence of Large Language Models (LLMs) has demonstrated promising progress in solving logical reasoning tasks effectively. Several recent approaches have proposed to change the role of the LLM from the reasoner into a translator between natural language statements and symbolic representations which are then sent to external symbolic solvers to resolve. This paradigm has established the current state-of-the-art result in logical reasoning (i.e., deductive reasoning). However, it remains unclear whether the variance in performance of these approaches stems from the methodologies employed or the specific symbolic solvers utilized. There is a lack of consistent comparison between symbolic solvers and how they influence the overall reported performance. This is important, as each symbolic solver also has its own input symbolic language, presenting varying degrees of challenge in the translation process. To address this gap, we perform experiments on 3 deductive reasoning benchmarks with LLMs augmented with widely used symbolic solvers: Z3, Pyke, and Prover9. The tool-executable rates of symbolic translation generated by different LLMs exhibit a near 50% performance variation. This highlights a significant difference in performance rooted in very basic choices of tools. The almost linear correlation between the executable rate of translations and the accuracy of the outcomes from Prover9 highlight a strong alignment between LLMs ability to translate into Prover9 symbolic language, and the correctness of those translations.</abstract>
      <url hash="144142a3">2024.alta-1.4</url>
      <bibkey>matthew-lam-etal-2024-closer</bibkey>
    </paper>
    <paper id="5">
      <title>Generating bilingual example sentences with large language models as lexicography assistants</title>
      <author><first>Raphael</first><last>Merx</last></author>
      <author><first>Ekaterina</first><last>Vylomova</last></author>
      <author><first>Kemal</first><last>Kurniawan</last></author>
      <pages>64-74</pages>
      <abstract>We present a study of LLMs’ performance in generating and rating example sentences for bilingual dictionaries across languages with varying resource levels: French (high-resource), Indonesian (mid-resource), and Tetun (low-resource), with English as the target language. We evaluate the quality of LLMgenerated examples against the GDEX (Good Dictionary EXample) criteria: typicality, informativeness, and intelligibility (Kilgarriff et al., 2008). Our findings reveal that while LLMs can generate reasonably good dictionary examples, their performance degrades significantly for lower-resourced languages. We also observe high variability in human preferences for example quality, reflected in low interannotator agreement rates. To address this, we demonstrate that in-context learning can successfully align LLMs with individual annotator preferences. Additionally, we explore the use of pre-trained language models for automated rating of examples, finding that sentence perplexity serves as a good proxy for “typicality” and “intelligibility” in higher-resourced languages. Our study also contributes a novel dataset of 600 ratings for LLM-generated sentence pairs, and provides insights into the potential of LLMs in reducing the cost of lexicographic work, particularly for low-resource languages.</abstract>
      <url hash="5b3308ab">2024.alta-1.5</url>
      <bibkey>merx-etal-2024-generating</bibkey>
    </paper>
    <paper id="6">
      <title><fixed-case>M</fixed-case>o<fixed-case>DEM</fixed-case>: Mixture of Domain Expert Models</title>
      <author><first>Toby</first><last>Simonds</last></author>
      <author><first>Kemal</first><last>Kurniawan</last></author>
      <author><first>Jey Han</first><last>Lau</last></author>
      <pages>75-88</pages>
      <abstract>We propose a novel approach to enhancing the performance and efficiency of large language models (LLMs) by combining domain prompt routing with domain-specialized models. We introduce a system that utilizes a BERT-based router to direct incoming prompts to the most appropriate domain expert model. These expert models are specifically tuned for domains such as health, mathematics and science. Our research demonstrates that this approach can significantly outperform general-purpose models of comparable size, leading to a superior performance-to-cost ratio across various benchmarks. The implications of this study suggest a potential shift in LLM development and deployment. Rather than focusing solely on creating increasingly large, general-purpose models, the future of AI may lie in developing ecosystems of smaller, highly specialized models coupled with sophisticated routing systems. This approach could lead to more efficient resource utilization, reduced computational costs, and superior overall performance.</abstract>
      <url hash="ccedf61a">2024.alta-1.6</url>
      <bibkey>simonds-etal-2024-modem</bibkey>
    </paper>
    <paper id="7">
      <title>Simultaneous Machine Translation with Large Language Models</title>
      <author><first>Minghan</first><last>Wang</last></author>
      <author><first>Thuy-Trang</first><last>Vu</last></author>
      <author><first>Jinming</first><last>Zhao</last></author>
      <author><first>Fatemeh</first><last>Shiri</last></author>
      <author><first>Ehsan</first><last>Shareghi</last></author>
      <author><first>Gholamreza</first><last>Haffari</last></author>
      <pages>89-103</pages>
      <abstract>Real-world simultaneous machine translation (SimulMT) systems face more challenges than just the quality-latency trade-off. They also need to address issues related to robustness with noisy input, processing long contexts, and flexibility for knowledge injection. These challenges demand models with strong language understanding and generation capabilities which may not often equipped by dedicated MT models. In this paper, we investigate the possibility of applying Large Language Models (LLM) to SimulMT tasks by using existing incremental-decoding methods with a newly proposed RALCP algorithm for latency reduction. We conducted experiments using the Llama2-7b-chat model on nine different languages from the MUST-C dataset. The results show that LLM outperforms dedicated MT models in terms of BLEU and LAAL metrics. Further analysis indicates that LLM has advantages in terms of tuning efficiency and robustness. However, it is important to note that the computational cost of LLM remains a significant obstacle to its application in SimulMT.</abstract>
      <url hash="326b94e8">2024.alta-1.7</url>
      <bibkey>wang-etal-2024-simultaneous</bibkey>
    </paper>
    <paper id="8">
      <title>Which Side Are You On? Investigating Politico-Economic Bias in <fixed-case>N</fixed-case>epali Language Models</title>
      <author><first>Surendrabikram</first><last>Thapa</last></author>
      <author><first>Kritesh</first><last>Rauniyar</last></author>
      <author><first>Ehsan</first><last>Barkhordar</last></author>
      <author><first>Hariram</first><last>Veeramani</last></author>
      <author><first>Usman</first><last>Naseem</last></author>
      <pages>104-117</pages>
      <abstract>Language models are trained on vast datasets sourced from the internet, which inevitably contain biases that reflect societal norms, stereotypes, and political inclinations. These biases can manifest in model outputs, influencing a wide range of applications. While there has been extensive research on bias detection and mitigation in large language models (LLMs) for widely spoken languages like English, there is a significant gap when it comes to low-resource languages such as Nepali. This paper addresses this gap by investigating the political and economic biases present in five fill-mask models and eleven generative models trained for the Nepali language. To assess these biases, we translated the Political Compass Test (PCT) into Nepali and evaluated the models’ outputs along social and economic axes. Our findings reveal distinct biases across models, with small LMs showing a right-leaning economic bias, while larger models exhibit more complex political orientations, including left-libertarian tendencies. This study emphasizes the importance of addressing biases in low-resource languages to promote fairness and inclusivity in AI-driven technologies. Our work provides a foundation for future research on bias detection and mitigation in underrepresented languages like Nepali, contributing to the broader goal of creating more ethical AI systems.</abstract>
      <url hash="78eeea37">2024.alta-1.8</url>
      <bibkey>thapa-etal-2024-side</bibkey>
    </paper>
    <paper id="9">
      <title>Advancing Community Directories: Leveraging <fixed-case>LLM</fixed-case>s for Automated Extraction in <fixed-case>MARC</fixed-case> Standard Venue Availability Notes</title>
      <author><first>Mostafa Didar</first><last>Mahdi</last></author>
      <author><first>Thushari</first><last>Atapattu</last></author>
      <author><first>Menasha</first><last>Thilakaratne</last></author>
      <pages>118-129</pages>
      <abstract>This paper addresses the challenge of efficiently managing and accessing community service information, specifically focusing on venue hire details within the SAcommunity directory. By leveraging Large Language Models (LLMs), particularly the RoBERTa transformer model, we developed an automated system to extract and structure venue availability information according to MARC (Machine-Readable Cataloging) standards. Our approach involved fine-tuning the RoBERTa model on a dataset of community service descriptions, enabling it to identify and categorize key elements such as facility names, capacities, equipment availability, and accessibility features. The model was then applied to process unstructured text data from the SAcommunity database, automatically extracting relevant information and organizing it into standardized fields. The results demonstrate the effectiveness of this method in transforming free-text summaries into structured, MARC-compliant data. This automation not only significantly reduces the time and effort required for data entry and categorization but also enhances the accessibility and usability of community information.</abstract>
      <url hash="7e01882c">2024.alta-1.9</url>
      <bibkey>mahdi-etal-2024-advancing</bibkey>
    </paper>
    <paper id="10">
      <title>Lesser the Shots, Higher the Hallucinations: Exploration of Genetic Information Extraction using Generative Large Language Models</title>
      <author><first>Milindi</first><last>Kodikara</last></author>
      <author><first>Karin</first><last>Verspoor</last></author>
      <pages>130-145</pages>
      <abstract>Organisation of information about genes, genetic variants, and associated diseases from vast quantities of scientific literature texts through automated information extraction (IE) strategies can facilitate progress in personalised medicine. We systematically evaluate the performance of generative large language models (LLMs) on the extraction of specialised genetic information, focusing on end-to-end IE encompassing both named entity recognition and relation extraction. We experiment across multilingual datasets with a range of instruction strategies, including zero-shot and few-shot prompting along with providing an annotation guideline. Optimal results are obtained with few-shot prompting. However, we also identify that generative LLMs failed to adhere to the instructions provided, leading to over-generation of entities and relations. We therefore carefully examine the effect of learning paradigms on the extent to which genetic entities are fabricated, and the limitations of exact matching to determine performance of the model.</abstract>
      <url hash="9e0f73d0">2024.alta-1.10</url>
      <bibkey>kodikara-verspoor-2024-lesser</bibkey>
    </paper>
    <paper id="11">
      <title>“Is Hate Lost in Translation?”: Evaluation of Multilingual <fixed-case>LGBTQIA</fixed-case>+ Hate Speech Detection</title>
      <author><first>Fai Leui</first><last>Chan</last></author>
      <author><first>Duke</first><last>Nguyen</last></author>
      <author><first>Aditya</first><last>Joshi</last></author>
      <pages>146-152</pages>
      <abstract>This paper explores the challenges of detecting LGBTQIA+ hate speech of large language models across multiple languages, including English, Italian, Chinese and (code-mixed) English-Tamil, examining the impact of machine translation and whether the nuances of hate speech are preserved across translation. We examine the hate speech detection ability of zero-shot and fine-tuned GPT. Our findings indicate that: (1) English has the highest performance and the code-mixing scenario of English-Tamil being the lowest, (2) fine-tuning improves performance consistently across languages whilst translation yields mixed results. Through simple experimentation with original text and machine-translated text for hate speech detection along with a qualitative error analysis, this paper sheds light on the socio-cultural nuances and complexities of languages that may not be captured by automatic translation.</abstract>
      <url hash="80df8ef1">2024.alta-1.11</url>
      <bibkey>chan-etal-2024-hate</bibkey>
    </paper>
    <paper id="12">
      <title>Personality Profiling: How informative are social media profiles in predicting personal information?</title>
      <author><first>Joshua</first><last>Watt</last></author>
      <author><first>Lewis</first><last>Mitchell</last></author>
      <author><first>Jonathan</first><last>Tuke</last></author>
      <pages>153-163</pages>
      <abstract>Personality profiling has been utilised by companies for targeted advertising, political campaigns and public health campaigns. However, the accuracy and versatility of such models remains relatively unknown. Here we explore the extent to which peoples’ online digital footprints can be used to profile their Myers- Briggs personality type. We analyse and compare four models: logistic regression, naive Bayes, support vector machines (SVMs) and random forests. We discover that a SVM model achieves the best accuracy of 20.95% for predicting a complete personality type. However, logistic regression models perform only marginally worse and are significantly faster to train and perform predictions. Moreover, we develop a statistical framework for assessing the importance of different sets of features in our models. We discover some features to be more informative than others in the Intuitive/Sensory (p = 0.032) and Thinking/Feeling (p = 0.019) models. Many labelled datasets present substantial class imbalances of personal characteristics on social media, including our own. We therefore highlight the need for attentive consideration when reporting model performance on such datasets and compare a number of methods to fix class-imbalance problems.</abstract>
      <url hash="3faa0256">2024.alta-1.12</url>
      <bibkey>watt-etal-2024-personality</bibkey>
    </paper>
    <paper id="13">
      <title>Rephrasing Electronic Health Records for Pretraining Clinical Language Models</title>
      <author><first>Jinghui</first><last>Liu</last></author>
      <author><first>Anthony</first><last>Nguyen</last></author>
      <pages>164-172</pages>
      <abstract>Clinical language models are important for many applications in healthcare, but their development depends on access to extensive clinical text for pretraining. However, obtaining clinical notes from electronic health records (EHRs) at scale is challenging due to patient privacy concerns. In this study, we rephrase existing clinical notes using LLMs to generate synthetic pretraining corpora, drawing inspiration from previous work on rephrasing web data. We examine four popular small-sized LLMs (&lt;10B) to create synthetic clinical text to pretrain both decoder-based and encoder-based language models. The method yields better results in language modeling and downstream tasks than previous synthesis approaches without referencing real clinical text. We find that augmenting original clinical notes with synthetic corpora from different LLMs improves performances even at a small token budget, showing the potential of this method to support pretraining at the institutional level or be scaled to synthesize large-scale clinical corpora.</abstract>
      <url hash="27e2ea72">2024.alta-1.13</url>
      <bibkey>liu-nguyen-2024-rephrasing</bibkey>
    </paper>
    <paper id="14">
      <title>Comparison of Multilingual and Bilingual Models for Satirical News Detection of <fixed-case>A</fixed-case>rabic and <fixed-case>E</fixed-case>nglish</title>
      <author><first>Omar W.</first><last>Abdalla</last></author>
      <author><first>Aditya</first><last>Joshi</last></author>
      <author><first>Rahat</first><last>Masood</last></author>
      <author><first>Salil S.</first><last>Kanhere</last></author>
      <pages>173-178</pages>
      <abstract>Satirical news is real news combined with a humorous comment or exaggerated content, and it often mimics the format and style of real news. However, satirical news is often misunderstood as misinformation, especially by individuals from different cultural and social backgrounds. This research addresses the challenge of distinguishing satire from truthful news by leveraging multilingual satire detection methods in English and Arabic. We explore both zero-shot and chain-of-thought (CoT) prompting using two language models, Jais-chat(13B) and LLaMA-2-chat(7B). Our results show that CoT prompting offers a significant advantage for the Jais-chat model over the LLaMA-2-chat model. Specifically, Jais-chat achieved the best performance, with an F1-score of 80% in English when using CoT prompting. These results high- light the importance of structured reasoning in CoT, which enhances contextual understanding and is vital for complex tasks like satire detection.</abstract>
      <url hash="7fac5699">2024.alta-1.14</url>
      <bibkey>abdalla-etal-2024-comparison</bibkey>
    </paper>
    <paper id="15">
      <title>Breaking the Silence: How Online Forums Address Lung Cancer Stigma and Offer Support</title>
      <author><first>Jiahe</first><last>Liu</last></author>
      <author><first>Mike</first><last>Conway</last></author>
      <author><first>Daniel Cabrera</first><last>Lozoya</last></author>
      <pages>179-188</pages>
      <abstract>Lung cancer remains a leading cause of cancer-related deaths, but public support for individuals living with lung cancer is often constrained by stigma and misconceptions, leading to serious emotional and social consequences for those diagnosed. Understanding how this stigma manifests and affects individuals is vital for developing inclusive interventions. Online discussion forums offer a unique opportunity to examine how lung cancer stigma is expressed and experienced. This study combines qualitative analysis and unsupervised learning (topic modelling) to explore stigma-related content within an online lung cancer forum. Our findings highlight the role of online forums as a key space for addressing anti-discriminatory attitudes and sharing experiences of lung cancer stigma. We found that users both with and with- out lung cancer engage in discussions pertaining to supportive and welcoming topics, high- lighting the online forum’s role in facilitating social and informational support.</abstract>
      <url hash="6694c418">2024.alta-1.15</url>
      <bibkey>liu-etal-2024-breaking</bibkey>
    </paper>
    <paper id="16">
      <title>Truth in the Noise: Unveiling Authentic Dementia Self-Disclosure Statements in Social Media with <fixed-case>LLM</fixed-case>s</title>
      <author><first>Daniel Cabrera</first><last>Lozoya</last></author>
      <author><first>Jude P</first><last>Mikal</last></author>
      <author><first>Yun Leng</first><last>Wong</last></author>
      <author><first>Laura S</first><last>Hemmy</last></author>
      <author><first>Mike</first><last>Conway</last></author>
      <pages>189-196</pages>
      <abstract>Identifying self-disclosed health diagnoses in social media data using regular expressions (e.g. “I’ve been diagnosed with &lt;Disease X&gt;”) is a well-established approach for creating ad hoc cohorts of individuals with specific health conditions. However there is evidence to suggest that this method of identifying individuals is unreliable when creating cohorts for some mental health and neurodegenerative conditions. In the case of dementia, the focus of this paper, diagnostic disclosures are frequently whimsical or sardonic, rather than indicative of an authentic diagnosis or underlying disease state (e.g. “I forgot my keys again. I’ve got dementia!”). With this work and utilising an annotated corpus of 14,025 dementia diagnostic self-disclosure posts derived from Twitter, we leveraged LLMs to distinguish between “authentic” dementia self-disclosures and “inauthentic” self-disclosures. Specifically, we implemented a genetic algorithm that evolves prompts using various state-of-the-art prompt engineering techniques, including chain of thought, self-critique, generated knowledge, and expert prompting. Our results showed that, of the methods tested, the evolved self-critique prompt engineering method achieved the best result, with an F1-score of 0.8.</abstract>
      <url hash="e0c57432">2024.alta-1.16</url>
      <bibkey>lozoya-etal-2024-truth</bibkey>
    </paper>
    <paper id="17">
      <title>Overview of the 2024 <fixed-case>ALTA</fixed-case> Shared Task: Detect Automatic <fixed-case>AI</fixed-case>-Generated Sentences for Human-<fixed-case>AI</fixed-case> Hybrid Articles</title>
      <author><first>Diego</first><last>Mollá</last></author>
      <author><first>Qiongkai</first><last>Xu</last></author>
      <author><first>Zijie</first><last>Zeng</last></author>
      <author><first>Zhuang</first><last>Li</last></author>
      <pages>197-202</pages>
      <abstract>The ALTA shared tasks have been running annually since 2010. In 2024, the purpose of the task is to detect machine-generated text in a hybrid setting where the text may contain portions of human text and portions machine-generated. In this paper, we present the task, the evaluation criteria, and the results of the systems participating in the shared task.</abstract>
      <url hash="eacf45f5">2024.alta-1.17</url>
      <bibkey>molla-etal-2024-overview</bibkey>
    </paper>
    <paper id="18">
      <title>Advancing <fixed-case>LLM</fixed-case> detection in the <fixed-case>ALTA</fixed-case> 2024 Shared Task: Techniques and Analysis</title>
      <author><first>Dima</first><last>Galat</last></author>
      <pages>203-206</pages>
      <abstract>The recent proliferation of AI-generated content has prompted significant interest in developing reliable detection methods. This study explores techniques for identifying AIgenerated text through sentence-level evaluation within hybrid articles. Our findings indicate that ChatGPT-3.5 Turbo exhibits distinct, repetitive probability patterns that enable consistent in-domain detection. Empirical tests show that minor textual modifications, such as rewording, have minimal impact on detection accuracy. These results provide valuable insights for advancing AI detection methodologies, offering a pathway toward robust solutions to address the complexities of synthetic text identification.</abstract>
      <url hash="0786bcde">2024.alta-1.18</url>
      <bibkey>galat-2024-advancing</bibkey>
    </paper>
    <paper id="19">
      <title>Simple models are all you need: Ensembling stylometric, part-of-speech, and information-theoretic models for the <fixed-case>ALTA</fixed-case> 2024 Shared Task</title>
      <author><first>Joel</first><last>Thomas</last></author>
      <author><first>Gia Bao</first><last>Hoang</last></author>
      <author><first>Lewis</first><last>Mitchell</last></author>
      <pages>207-212</pages>
      <abstract>The ALTA 2024 shared task concerned automated detection of AI-generated text. Large language models (LLM) were used to generate hybrid documents, where individual sentences were authored by either humans or a state-of-the-art LLM. Rather than rely on similarly computationally expensive tools like transformer-based methods, we decided to approach this task using only an ensemble of lightweight “traditional” methods that could be trained on a standard desktop machine. Our approach used models based on word counts, stylometric features, readability metrics, part-of-speech tagging, and an information-theoretic entropy estimator to predict authorship. These models, combined with a simple weighting scheme, performed well on a held-out test set, achieving an accuracy of 0.855 and a kappa score of 0.695. Our results show that relatively simple, interpretable models can perform effectively at tasks like authorship prediction, even on short texts, which is important for democratisation of AI as well as future applications in edge computing.</abstract>
      <url hash="aeb49ac4">2024.alta-1.19</url>
      <bibkey>thomas-etal-2024-simple</bibkey>
    </paper>
    <paper id="20">
      <title>Hands-On <fixed-case>NLP</fixed-case> with Hugging Face: <fixed-case>ALTA</fixed-case> 2024 Tutorial on Efficient Fine-Tuning and Quantisation</title>
      <author><first>Nicholas I-Hsien</first><last>Kuo</last></author>
      <pages>213-213</pages>
      <abstract>This tutorial, presented at ALTA 2024, focuses on efficient fine-tuning and quantisation techniques for large language models (LLMs), addressing challenges in deploying state-of-the-art models on resource-constrained hardware. It introduces parameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation (LoRA), and model quantisation strategies, which enable training and inference of LLMs on GPUs with limited memory (e.g., 16 GB VRAM). Participants will work with TinyLlama (1.1B) and the public domain text War and Peace as an accessible dataset, ensuring there are no barriers like credentialled access to Hugging Face or PhysioNet datasets. The tutorial also demonstrates common training challenges, such as OutOfMemoryError, and shows how PEFT can mitigate these issues, enabling large-scale fine-tuning even in resource-limited environments.</abstract>
      <url hash="56165061">2024.alta-1.20</url>
      <bibkey>kuo-2024-hands</bibkey>
    </paper>
  </volume>
</collection>
