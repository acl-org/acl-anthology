<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.jeptalnrecital">
  <volume id="taln" ingest-date="2025-09-28" type="proceedings">
    <meta>
      <booktitle>Actes des 32ème Conférence sur le Traitement Automatique des Langues Naturelles (TALN), volume 1 : articles scientifiques originaux</booktitle>
      <editor><first>Frédéric</first><last>Bechet</last></editor>
      <editor><first>Adrian-Gabriel</first><last>Chifu</last></editor>
      <editor><first>Karen</first><last>Pinel-sauvagnat</last></editor>
      <editor><first>Benoit</first><last>Favre</last></editor>
      <editor><first>Eliot</first><last>Maes</last></editor>
      <editor><first>Diana</first><last>Nurbakova</last></editor>
      <publisher>ATALA \\&amp; ARIA</publisher>
      <address>Marseille, France</address>
      <month>6</month>
      <year>2025</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="bfd82fc9">2025.jeptalnrecital-taln.0</url>
      <bibkey>jep-taln-recital-2025-taln</bibkey>
    </frontmatter>
    <paper id="1">
      <title>« De nos jours, ce sont les résultats qui comptent » : création et étude diachronique d’un corpus de revendications issues d’articles de <fixed-case>TAL</fixed-case></title>
      <author><first>Clementine</first><last>Bleuze</last></author>
      <author><first>Fanny</first><last>Ducel</last></author>
      <author><first>Maxime</first><last>Amblard</last></author>
      <author><first>Karën</first><last>Fort</last></author>
      <pages>1–21</pages>
      <abstract>Nous constituons un corpus de phrases issues de pré-tirages et d’articles de TAL, publiés en anglais entre 1952 et 2024, dont nous annotons manuellement un échantillon avec des catégories de revendications reflétant leur fonction rhétorique au sein des articles. Nous affinons un modèle SciBERT (Beltagy et al. , 2019) pour prédire les étiquettes restantes, que nous mettons, avec le corpus annoté, à la disposition de la communauté. Nous illustrons l’intérêt du corpus par des analyses exploratoires sur les caractéristiques des revendications relevées, ainsi qu’une étude diachronique de l’évolution de la structure des résumés; ceci est mis en lien avec une réflexion sur la notion d’exagération scientifique. Nous observons une importance croissante des séquences de contexte précédant l’exposé des contributions, lequel est également de plus en plus suivi de séquences de résultats.</abstract>
      <url hash="89f2573f">2025.jeptalnrecital-taln.1</url>
      <language>fra</language>
      <bibkey>bleuze-etal-2025-de</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>ALF</fixed-case> : Un jeu de données d’analogies françaises à grain fin pour l’évaluation de la connaissance lexicale des grands modèles de langue</title>
      <author><first>Alexander</first><last>Petrov</last></author>
      <author><first>Antoine</first><last>Venant</last></author>
      <author><first>François</first><last>Lareau</last></author>
      <author><first>Yves</first><last>Lepage</last></author>
      <author><first>Philippe</first><last>Langlais</last></author>
      <pages>22–49</pages>
      <abstract>La révolution apportée par les grands modèles de langue (LLM) provient de l’étonnante fluidité des textes qu’ils génèrent. Cette fluidité soulève une question scientifique essentielle : quelle quantité de connaissance lexicale les LLM capturent-ils réellement afin de produire un langage aussi fluide? Pour y répondre, nous présentons ALF, un jeu de données analogiqes librement accessible et doté de riches informations lexicographiques fondées sur la théorie Sens-Texte. Il comprend 2600 analogies lexicales à grain fin avec lesquelles nous évaluons la capacité lexicale de quatre LLM standards : ChatGPT-4o mini ,Llama3.0-8B ,Llama3.1-8B etQwen2.5-14B . En moyenne, ChatGPT et la série Llama obtiennent une précision aux environs de 55%, tandis que Qwen est juste en dessous du seuil des 60%, ce qui montre qu’ALF pose un défi considérable. Nous identifions en outre certains types d’analogies et de méthodes d’invite qui révèlent des disparités de performance.</abstract>
      <url hash="98bd5213">2025.jeptalnrecital-taln.2</url>
      <language>fra</language>
      <bibkey>petrov-etal-2025-alf</bibkey>
    </paper>
    <paper id="3">
      <title>Adaptation des connaissances médicales pour les grands modèles de langue : Stratégies et analyse comparative</title>
      <author><first>Ikram</first><last>Belmadani</last></author>
      <author><first>Benoit</first><last>Favre</last></author>
      <author><first>Richard</first><last>Dufour</last></author>
      <author><first>Frédéric</first><last>Béchet</last></author>
      <author><first>Carlos</first><last>Ramisch</last></author>
      <pages>50–72</pages>
      <abstract>Cet article présente une étude sur l’adaptation des grands modèles de langue (LLMs) à des domaines spécialisés disposant de données limitées. Bien que certaines recherches remettent en question le pré-entraînement adaptatif (DAPT) dans le contexte médical en anglais, nous montrons que l’adaptation au domaine peut être efficace sous certaines conditions. En prenant comme exemple l’adaptation au domaine médical en français, nous comparons de manière systématique le pré-entraînement continu (CPT), l’affinage supervisé (SFT) et une approche combinée (CPT suivi de SFT). Nos résultats indiquent que l’adaptation d’un modèle généraliste à de nouvelles données dans le domaine médical offre des améliorations notables (taux de réussite de 87%), tandis que l’adaptation supplémentaire de modèles déjà familiarisés avec ce domaine procure des bénéfices limités. Bien que CPT+SFT offre les meilleures performances globales, SFT-seul présente des résultats solides et requiert moins de ressources matérielles.</abstract>
      <url hash="75ed7c71">2025.jeptalnrecital-taln.3</url>
      <language>fra</language>
      <bibkey>belmadani-etal-2025-adaptation</bibkey>
    </paper>
    <paper id="4">
      <title>Alignement bi-textuel adaptatif basé sur des plongements multilingues</title>
      <author><first>Olivier</first><last>Kraif</last></author>
      <pages>73–83</pages>
      <abstract>Nous présentons dans cet article un système d’alignement bi-textuel adaptatif nommé AIlign. Cet aligneur s’appuie sur les embeddings de phrases pour extraire des points d’ancrage fiables susceptibles de guider le chemin d’alignement, même pour des textes dont le parallélisme est fragmentaire et non strictement monotone. Dans une expérimentation sur plusieurs jeux de données, nous montrons qu’AIlign obtient des résultats équivalents à l’état de l’art, avec une complexité quasi linéaire. En outre, AIlign est capable de traiter des textes dont les propriétés de parallélisme et de monotonie ne sont satisfaites que localement, contrairement à des systèmes tels que Vecalign ou Bertalign.</abstract>
      <url hash="1b46b348">2025.jeptalnrecital-taln.4</url>
      <language>fra</language>
      <bibkey>kraif-2025-alignement</bibkey>
    </paper>
    <paper id="5">
      <title>Alignements divisifs de textes parallèles: données, algorithme et évaluation</title>
      <author><first>Joanna</first><last>Radoła</last></author>
      <author><first>François</first><last>Yvon</last></author>
      <pages>84–99</pages>
      <abstract>Nous présentons Alibi - un corpus d’alignements hiérarchiques sous-phrastiques français-anglais, annoté manuellement à l’aide d’une stratégie divisive. Nous comparons globalement les alignements ainsi obtenus avec plusieurs corpus parallèles alignés mot-à-mot et étalonnons sa difficulté en réalisant des alignements automatiques par des méthodes de l’état de l’art. Nous proposons également un algorithme exploitant des représentations neuronales des mots et des groupes de mots afin de repro- duire les alignements hiérarchiques de référence. Enfin, nous proposons une métrique d’évaluation des arbres d’alignement avec laquelle nous comparons les performances de plusieurs variantes de l’algorithme d’alignement, obtenues en faisant varier les mesures d’appariemment de groupes de mots. Nos résultats montrent que (a) les arbres d’alignements de référence sont très ambigus et difficiles à reproduire automatiquement, cependant, les alignements mot-à-mot sont prédits de manière fiable ; (b) l’utilisation d’alternatives à la similarité cosinus pour évaluer l’appariemment de blocs permet d’améliorer significativement les résultats du système de base.</abstract>
      <url hash="ff6d73d4">2025.jeptalnrecital-taln.5</url>
      <language>fra</language>
      <bibkey>radola-yvon-2025-alignements</bibkey>
    </paper>
    <paper id="6">
      <title>Alignements entre attention et sémantique dans des modèles de langues pré-entraînés</title>
      <author><first>Frédéric</first><last>Charpentier</last></author>
      <author><first>Jairo</first><last>Cugliari Duhalde</last></author>
      <author><first>Adrien</first><last>Guille</last></author>
      <pages>100–116</pages>
      <abstract>Les AMR (Abstract Meaning Representation) sont une structure destinée à coder la sémantique de phrases sous forme de graphes. Les mots des phrases correspondantes peuvent être alignés avec les sommets de l’AMR, de telle sorte que les relations sémantiques entre les mots puissent être mises en correspondance avec les rôles sémantiques lus sur les arcs de l’AMR. Le mécanisme d’attention d’un modèle de langue (ML) peut être modélisé comme le calcul de vecteurs descripteurs pour les arêtes d’un graphe complet dont les sommets sont les mots d’une phrase ou d’un paragraphe entier. Dans cet article, nous projetons les graphes AMR sur les graphes d’attention et concevons des méthodes supervisées pour détecter les relations sémantiques étiquetant les arêtes à partir des poids d’attention. Pour cela, nous mettons en œuvre des méthodes opérant soit sur les arêtes une à une, soit sur le graphe d’attention entier afin de comparer les capacités sémantiques de ML pré-entraînés. Il ressort de cette étude que l’encodeur bidirectionnel RoBERTA-base est meilleur que les décodeurs causaux, jusqu’à Llama 3 8B.</abstract>
      <url hash="0cf21889">2025.jeptalnrecital-taln.6</url>
      <language>fra</language>
      <bibkey>charpentier-etal-2025-alignements</bibkey>
    </paper>
    <paper id="7">
      <title>Améliorer la Traduction Neuronale par Exemple avec des Données Monolingues</title>
      <author><first>Maxime</first><last>Bouthors</last></author>
      <author><first>Josep</first><last>Crego</last></author>
      <author><first>François</first><last>Yvon</last></author>
      <pages>117–133</pages>
      <abstract>Les systèmes de traduction neuronale augmentée par des exemples (RANMT) utilisent des corpus bilingues dits mémoires de traduction (TM). Pourtant, dans de nombreux cas, des corpus monolingues du domaine d’intérêt dans la langue cible sont disponibles. Nos travaux s’intéressent à l’exploitation de telles ressources, en recherchant les segments pertinents directement dans la langue cible, conditionnellement à une phrase source en requête. À cet effet, nous proposons d’améliorer les systèmes de recherche cross-lingue, en les entraînant à réaliser des association lexicales. Nos expériences avec deux architectures neuronales montrent l’avantage de notre méthode dans un cas contrôlé, conduisant à des performances de traduction qui peuvent surpasser les méthodes basées sur une mémoire de traduction. Enfin, nous évaluons notre méthode dans une configuration réaliste pour laquelle la quantité de données monolingues excède celle des données parallèles. Cette approche résulte en une nette amélioration des performances par rapport à des modèles de base ainsi que des encodeurs pré-entraînés.</abstract>
      <url hash="259a2433">2025.jeptalnrecital-taln.7</url>
      <language>fra</language>
      <bibkey>bouthors-etal-2025-ameliorer</bibkey>
    </paper>
    <paper id="8">
      <title>Analyse de la continuité référentielle dans le corpus d’écrits scolaires français et italien Scolinter</title>
      <author><first>Martina</first><last>Barletta</last></author>
      <author><first>Claude</first><last>Ponton</last></author>
      <pages>134–153</pages>
      <abstract>Cet article présente une étude sur la continuité référentielle dans des écrits scolaires en français et en italien, en s’appuyant sur le corpus Scolinter. L’objectif est d’analyser les mécanismes de cohérence textuelle à l’école primaire et de comparer les stratégies utilisées dans les deux langues à travers l’annotation et l’analyse des chaines de continuité référentielle. Une campagne d’annotation a été menée sur 150 textes par langue (CE1 et CE2), et le corpus de référence obtenu suite à l’adjudication a fait l’objet d’une analyse présentée ici. Les résultats montrent des différences notables. Par exemple, en français, les pronoms personnels sont privilégiés, tandis qu’en italien, l’anaphore zéro est plus fréquente. L’étude met également en évidence une tendance commune dans l’introduction des référents, souvent par des syntagmes nominaux indéfinis suivis d’une reprise pronominale. En revanche, la densité référentielle ne varie pas significativement entre les niveaux scolaires. Ces analyses apportent un éclairage sur le développement des compétences rédactionnelles et les spécificités linguistiques influençant la gestion de la référence dans chaque langue.</abstract>
      <url hash="1fdc5c4a">2025.jeptalnrecital-taln.8</url>
      <language>fra</language>
      <bibkey>barletta-ponton-2025-analyse</bibkey>
    </paper>
    <paper id="9">
      <title>Augmentation des données par <fixed-case>LLM</fixed-case> pour améliorer la détection automatique des erreurs de coordination</title>
      <author><first>Chunxiao</first><last>Yan</last></author>
      <author><first>Iris</first><last>Eshkol-Taravella</last></author>
      <author><first>Sarah</first><last>De V ogué</last></author>
      <author><first>Marianne</first><last>Desmets</last></author>
      <pages>154–166</pages>
      <abstract>Afin d’améliorer les performances d’un outil de détection automatique des erreurs de coordination, cette étude explore l’utilisation de grands modèles de langage (LLM) pour remédier au déséquilibre des classes et à la limitation des données. En générant des phrases erronées simulées par un LLM pour former un corpus synthétique, nous améliorons la détection d’une classe sous-représentée ainsi que les performances globales du modèle. Nous étudions également l’application des LLM à l’annotation des données, avec pour objectif d’intégrer ces annotations à l’entraînement afin d’optimiser l’apprentissage du modèle.</abstract>
      <url hash="8a262da9">2025.jeptalnrecital-taln.9</url>
      <language>fra</language>
      <bibkey>yan-etal-2025-augmentation</bibkey>
    </paper>
    <paper id="10">
      <title>Connaissances factuelles dans les modèles de langue : robustesse et anomalies face à des variations simples du contexte temporel</title>
      <author><first>Hichem</first><last>Ammar Khodja</last></author>
      <author><first>Frédéric</first><last>Béchet</last></author>
      <author><first>Quentin</first><last>Brabant</last></author>
      <author><first>Alexis</first><last>Nasr</last></author>
      <author><first>Gwénolé</first><last>Lecorvé</last></author>
      <pages>167–195</pages>
      <abstract>Ce papier explore la robustesse des modèles de langue (ML) face aux variations du contexte temporel dans les connaissances factuelles. Il examine si les ML peuvent associer correctement un contexte temporel à un fait passé valide sur une période de temps délimitée, en leur demandant de différencier les contextes corrects des contextes incorrects. La capacité de distinction des ML est analysée sur deux dimensions : la distance du contexte incorrect par rapport à la période de validité et la granularité du contexte. Pour cela, un jeu de données, TimeStress, est introduit, permettant de tester 18 ML variés. Les résultats révèlent que le meilleur ML n’atteint une distinction parfaite que pour 11% des faits étudiés, avec des erreurs critiques qu’un humain ne ferait pas. Ces travaux soulignent les limites des ML actuels en matière de représentation temporelle.</abstract>
      <url hash="3913c772">2025.jeptalnrecital-taln.10</url>
      <language>fra</language>
      <bibkey>ammar-khodja-etal-2025-connaissances</bibkey>
    </paper>
    <paper id="11">
      <title>Corpus multilingue annoté pour l’étude sémantique des expressions quantifiantes – Problèmes de segmentation du coréen et du japonais</title>
      <author><first>Raoul</first><last>Blin</last></author>
      <author><first>Jinnam</first><last>Choi</last></author>
      <pages>196–205</pages>
      <abstract>Le travail présenté dans cet article s’inscrit dans le projet de constitution d’un corpus comparable, annoté pour l’étude sémantique de la quantification en coréen, français, japonais et chinois mandarin. Le corpus est annoté en dépendances au format SUD. Nous montrons la nécessité d’adopter une segmentation plus fine que celle en usage habituellement pour le coréen et le japonais. Cette segmentation améliore la description de la quantification dans environ 5% des phrases par rapport à la segmentation usuelle. Elle permet aussi une analyse morpho-syntaxique plus fine.</abstract>
      <url hash="71bc3f69">2025.jeptalnrecital-taln.11</url>
      <language>fra</language>
      <bibkey>blin-choi-2025-corpus</bibkey>
    </paper>
    <paper id="12">
      <title>Détecter des comportements associés aux troubles alimentaires par l’analyse automatique des publications textuelles en ligne</title>
      <author><first>Yves</first><last>Ferstler</last></author>
      <author><first>Catherine</first><last>Lavoie</last></author>
      <author><first>Marie-Jean</first><last>Meurs</last></author>
      <pages>206–217</pages>
      <abstract>Cet article présente une méthode pour détecter des aspects du comportement liés aux troubles alimentaires à partir de publications textuelles échangées sur les réseaux sociaux. Nos travaux comparent différentes représentations d’historiques de publications permettant d’entraîner un modèle neuronal pour la prédiction. Les approches étudiées sont : (1) la représentation de sujet par fréquence, en calculant le nombre de sujets apparus dans un historique, (2) une représentation par plongement, en calculant la moyenne des représentations de sujets présents dans l’historique de publications, (3) une représentation par documents représentatifs, qui cherche à représenter un sujet par un document sémantiquement proche. Un filtrage de sujets est également étudié, pour sélectionner les sujets reliés aux troubles alimentaires. Les résultats montrent que l’utilisation de filtrage permet d’améliorer les performances des systèmes de détection. La méthode basée sur un document représentatif obtient les meilleurs résultats, parmi les autres représentations évaluées mais également parmi d’autres méthodes appliquées à la même tâche lors de la campagne d’évaluation eRisk 2024.</abstract>
      <url hash="0b634162">2025.jeptalnrecital-taln.12</url>
      <language>fra</language>
      <bibkey>ferstler-etal-2025-detecter</bibkey>
    </paper>
    <paper id="13">
      <title>Détection de métaphores dans les documents médicaux</title>
      <author><first>Coralie</first><last>Pottiez</last></author>
      <author><first>Thierry</first><last>Hamon</last></author>
      <author><first>Natalia</first><last>Grabar</last></author>
      <pages>218–232</pages>
      <abstract>La métaphore est une figure de style, qui permet de transférer le sens d’un terme source vers un terme cible, comme dans LE TEMPS C ‘EST DE L ‘ARGENT . De cette manière, la métaphore identifie des similarités cachées entre deux idées. La métaphore peut jouer plusieurs rôles dans la langue, comme l’embellir, structurer la pensée ou expliquer des notions complexes. Nous nous intéressons à la métaphore utilisée dans le domaine médical. Nous proposons d’abord une typologie de métaphores et un corpus de cas cliniques annoté avec des emplois métaphoriques. Nous effectuons également des expériences de détection automatique des métaphores avec un giga-modèle génératif. Plusieurs types de prompts sont testés. Les meilleurs résultats atteignent 67,50 de F-mesure, avec le rappel allant jusqu’à 74 % avec certains prompts . Le typage de métaphores montre que 45,51 % de métaphores sont typés correctement.</abstract>
      <url hash="0a2e2eb3">2025.jeptalnrecital-taln.13</url>
      <language>fra</language>
      <bibkey>pottiez-etal-2025-detection</bibkey>
    </paper>
    <paper id="14">
      <title>Détection des contaminations de <fixed-case>LLM</fixed-case> par extraction de données : une revue de littérature pratique</title>
      <author><first>Pierre</first><last>Lepagnol</last></author>
      <author><first>Thomas</first><last>Gerald</last></author>
      <author><first>Sahar</first><last>Ghannay</last></author>
      <author><first>Christophe</first><last>Servan</last></author>
      <author><first>Sophie</first><last>Rosset</last></author>
      <pages>233–251</pages>
      <abstract>Cet état de l’art examine le problème de la contamination des données d’entraînement dans les grands modèles de langue (LLM). Ce phénomène se produit lorsque les modèles sont évalués sur des données qu’ils ont déjà rencontrées durant leur entraînement, créant une fausse impression de performance. Cette étude propose une synthèse pratique pour la communauté scientifique du traitement automatique des langues (TAL). Nous présentons un cadre d’analyse qui distingue différents niveaux de contamination ainsi que différentes méthodes classées selon l’accès au modèle (White/Gray/BlackBox) et les techniques utilisées (Similarité/Probabilité/Extraction). Nous explorons particulièrement les méthodes d’extraction de données de LLM, les approches techniques, les mesures de performance et leurs limites. Dans une perspective pratique, nous avons synthétisé ces méthodes sous la forme d’un arbre de décision pour sélectionner la méthode de détection de contamination adéquate.</abstract>
      <url hash="5b801d3c">2025.jeptalnrecital-taln.14</url>
      <language>fra</language>
      <bibkey>lepagnol-etal-2025-detection</bibkey>
    </paper>
    <paper id="15">
      <title>Détection des omissions dans les résumés médicaux générés par les grands modèles de langue</title>
      <author><first>Achir</first><last>Oukelmoun</last></author>
      <author><first>Nasredine</first><last>Semmar</last></author>
      <author><first>Gaël</first><last>de Chalendar</last></author>
      <author><first>Clément</first><last>Cormi</last></author>
      <author><first>Mariame</first><last>Oukelmoun</last></author>
      <author><first>Eric</first><last>Vibert</last></author>
      <author><first>Marc-Antoine</first><last>Allard</last></author>
      <pages>252–267</pages>
      <abstract>Les grands modèles de langue (LLMs) sont de plus en plus utilisés pour résumer des textes médicaux, mais ils risquent d’omettre des informations critiques, compromettant ainsi la prise de décision. Contrairement aux hallucinations, les omissions concernent des faits essentiels absents. Cet article introduit un jeu de données validé en français pour détecter ces omissions et propose EmbedKDECheck, une approche frugale et sans référence. A l’opposé des méthodes basées sur les LLMs, cette approche utilise des plongements lexicaux issus d’un modèle de Traitement Automatique des Langues (TAL) léger combinant FastText et Word2Vec selon un algorithme précis couplé à un modèle non-supervisé fournissant un score d’anomalie. Cette approche permet d’identifier efficacement les omissions à faible coût computationnel. EmbedKDECheck a été évalué face aux frameworks de l’état de l’art (SelfCheckGPT, ChainPoll, G-Eval et GPTScore) et a montré de bonnes performances. Notre méthode renforce l’évaluation de la fiabilité des LLMs et contribue à une prise de décision médicale plus sûre.</abstract>
      <url hash="85c6166d">2025.jeptalnrecital-taln.15</url>
      <language>fra</language>
      <bibkey>oukelmoun-etal-2025-detection</bibkey>
    </paper>
    <paper id="16">
      <title>Détection et évaluation de la communication toxique pour la relation client par des <fixed-case>LLM</fixed-case>s</title>
      <author><first>Guillaume</first><last>De Murcia</last></author>
      <author><first>Ludovic</first><last>Meineri</last></author>
      <author><first>Laurent</first><last>Gillard</last></author>
      <author><first>Thomas</first><last>Gouritin</last></author>
      <author><first>Samy</first><last>Lastmann</last></author>
      <pages>268–283</pages>
      <abstract>Cet article présente une méthode de détection de la toxicité dans les interactions et dialogues client avant des générations par un LLM. En proposant une taxonomie originale, adaptée aux échanges conversationnels et à la relation client, nous avons conçu un processus d’évaluation rigoureux, accompagné de deux corpus annotés : Toximini-fr etToxiMaxi-multilingual . Ces corpus combinent des requêtes issues de données réelles — extraites de logs de nos chatbots en production — et de jeux de données de référence, ainsi que des exemples générés de manière synthétique afin de couvrir un large éventail de situations. Nos expérimentations comparent différents modèles, dont GPT-4o mini et Mistral Moderation , sur des requêtes multilingues dans des contextes variés. Les résultats montrent que notre approche permet une détection robuste, notamment sur les contenus bruités ou implicites. Cette étude ouvre la voie à une meilleure maîtrise des risques liés aux comportements toxiques dans les échanges conversationnels automatisés.</abstract>
      <url hash="d4754344">2025.jeptalnrecital-taln.16</url>
      <language>fra</language>
      <bibkey>de-murcia-etal-2025-detection</bibkey>
    </paper>
    <paper id="17">
      <title><fixed-case>ELITEC</fixed-case> : un corpus de conversations en microposts français annoté pour le liage d’entités <fixed-case>W</fixed-case>ikidata</title>
      <author><first>Vivien</first><last>Leonard</last></author>
      <author><first>Béatrice</first><last>Markhoff</last></author>
      <author><first>Jean-Yves</first><last>Antoine</last></author>
      <pages>284–294</pages>
      <abstract>Nous présentons un corpus de microposts en français pour l’évaluation de la tâche de liage des mentions présentes dans le texte à des entités de Wikidata. Ce corpus est annoté à la fois pour la reconnaissance des mentions (Named Entity Recognition - NER) et leur liaison à des entités de Wikidata (Entity Linking - EL). Il s’agit d’une collection de 2 500 microposts, ciblés sur des termes liés à la vie en ville et regroupés en 618 conversations. Construit en suivant les conventions d’annotation de Impresso-Quaero, ce corpus a été pseudo-anonymisé afin d’être mis librement à disposition de la communauté. Nommé ELITEC (EL for mIcroposTs in FrEnCh), son objectif est de compléter les ressources spécifiques au français. ELITEC sert de base de tests pour les tâches NER et EL, et nous l’avons utilisé pour l’évaluation d’un système d’EL que nous avons développé.</abstract>
      <url hash="12a2941e">2025.jeptalnrecital-taln.17</url>
      <language>fra</language>
      <bibkey>leonard-etal-2025-elitec</bibkey>
    </paper>
    <paper id="18">
      <title>Embeddings, topic models, <fixed-case>LLM</fixed-case> : un air de famille</title>
      <author><first>Ludovic</first><last>Tanguy</last></author>
      <author><first>Cécile</first><last>Fabre</last></author>
      <author><first>Nabil</first><last>Hathout</last></author>
      <author><first>Lydia-Mai</first><last>Ho-Dac</last></author>
      <pages>295–312</pages>
      <abstract>Word embeddings, topic models, LLMs: a family affair This article presents a study on terms denoting family relationships (brother, aunt, etc.) in French using three approaches: word embeddings, topic modeling, and pre-trained language models. The first two types of representations are built from the French version of Wikipedia, while the third is derived through direct interaction with ChatGPT. The aim is to compare how these three methods represent such terms, in two main ways: by evaluating them against a structural definition of family relations (in terms of features such as gender, lineage, etc.), and by comparing the topics associated with each term. These methods reveal different modes of structuring family-related vocabulary, while also underscoring the continued necessity of corpus-based and controlled analyses to obtain reliable results.</abstract>
      <url hash="dae817de">2025.jeptalnrecital-taln.18</url>
      <bibkey>tanguy-etal-2025-embeddings</bibkey>
    </paper>
    <paper id="19">
      <title>Estimation de l’inclusion entre tâches par projection spectrale de vecteurs de tâches</title>
      <author><first>Loïc</first><last>Fosse</last></author>
      <author><first>Benoît</first><last>Favre</last></author>
      <author><first>Frédéric</first><last>Béchet</last></author>
      <author><first>Géraldine</first><last>Damnati</last></author>
      <author><first>Gwénolé</first><last>Lecorvé</last></author>
      <pages>313–330</pages>
      <abstract>L’affinage des modèles a permis la plupart des avancées significatives récentes dans les tâches de TALN. Des études ont exploré les raisons de ces succès en étudiant le mécanisme d’attention, la manière dont les connaissances linguistiques et factuelles sont encodées, etc... . Il est cependant difficile d’interpréter les changements causés par l’affinage dans les poids des modèles. Pour mieux comprendre cela, nous proposons une méthode fondée théoriquement pour projeter et comparer les changements de poids (i.e. vecteurs de tâches) dans un espace à faible dimension. Cette approche permet de mieux comprendre les connaissances encodées dans un vecteur de tâches, relativement à un autre vecteur de tâche. Nous validons notre méthode en montrant qu’un modèle affiné sur une tâche de résumé encode des informations sur la reconnaissance d’entités nommées.</abstract>
      <url hash="0e0e5785">2025.jeptalnrecital-taln.19</url>
      <language>fra</language>
      <bibkey>fosse-etal-2025-estimation</bibkey>
    </paper>
    <paper id="20">
      <title>Étude comparative de réponses humaines et de grands modèles de langue à des <fixed-case>QCM</fixed-case> en pharmacie</title>
      <author><first>Ricardo</first><last>Rodriguez</last></author>
      <author><first>Stéphane</first><last>Huet</last></author>
      <author><first>Benoît</first><last>Favre</last></author>
      <author><first>Mickael</first><last>Rouvier</last></author>
      <pages>331–347</pages>
      <abstract>Cet article propose d’étudier les réponses générées par plusieurs Grands Modèles de Langue à un ensemble de Questions à Choix Multiple en pharmacie. Ces réponses sont comparées aux réponses données par des étudiants, afin de comprendre quelles sont les questions difficiles pour les modèles par rapport aux humains et pour quelles raisons. Nous utilisons les logits internes des modèles pour construire des distributions de probabilité et analyser les caractéristiques principales qui déterminent la difficulté des questions via une approche statistique. Nous apportons aussi une extension du jeu de données FRENCH MEDMCQA avec des paires question-réponses en pharmacie, enrichies avec les réponses des étudiants, la ponctuation assignée aux réponses, les thématiques cliniques correspondantes et des annotations manuelles sur la structure et certains traits sémantiques des questions.</abstract>
      <url hash="81ca1bb5">2025.jeptalnrecital-taln.20</url>
      <language>fra</language>
      <bibkey>rodriguez-etal-2025-etude</bibkey>
    </paper>
    <paper id="21">
      <title>Étude critique du corpus <fixed-case>CNN</fixed-case>/<fixed-case>D</fixed-case>aily<fixed-case>M</fixed-case>ail pour le résumé automatique</title>
      <author><first>Fanny</first><last>Bachey</last></author>
      <author><first>Christophe</first><last>Rodrigues</last></author>
      <author><first>Aurélien</first><last>Bossard</last></author>
      <pages>348–359</pages>
      <abstract>De nombreux modèles de génération et d’évaluation sont entraînés sur des corpus sans qu’il ait été démontré qu’ils étaient appropriés pour cette tâche. C’est pourquoi nous proposons l’étude critique des données de l’un des corpus les plus utilisés dans le domaine du résumé automatique : CNN/DailyMail. Nous montrons, par une analyse théorique, puis en comparant les résumés de référence du corpus et à des résumés écrits par des humains, que les résumés de référence de CNN/DailyMail ne correspondent pas à ce que doit être un résumé, et que le corpus n’est donc pas adapté à la tâche de résumé automatique.</abstract>
      <url hash="9e34e37d">2025.jeptalnrecital-taln.21</url>
      <language>fra</language>
      <bibkey>bachey-etal-2025-etude</bibkey>
    </paper>
    <paper id="22">
      <title>Évaluer la capacité des transformeurs à distinguer les significations compositionnelles et idiomatiques d’une même expression</title>
      <author><first>Nina</first><last>Nusbaumer</last></author>
      <author><first>Guillaume</first><last>Wisniewski</last></author>
      <author><first>Benoît</first><last>Crabbé</last></author>
      <pages>360–375</pages>
      <abstract>Cet article explore comment les modèles de langue fondés sur les transformeurs encodent les significations compositionnelles et non-compositionnelles de séquences en anglais comme big fish, qui, selon le contexte, peuvent signifier soit « grand poisson », soit « personne importante ». Nous avons mené des expériences pour évaluer : (1) la distinction entre les plongements lexicaux des groupes nominaux compositionnels et non compositionnels à travers les couches du modèle de langue, (2) leur séparabilité linéaire, et (3) l’unité lexicale des séquences non compositionnelle. Nos résultats montrent que le modèle différencie bien les deux significations, et ce dès les premières couches, avec néanmoins une variabilité selon les expressions. De plus, s’appuyant sur des informations contextuelles plus larges, le modèle ne traite pas les expressions idiomatiques comme lexicalement plus unifiées que leurs équivalents compositionnels.</abstract>
      <url hash="bcaeddda">2025.jeptalnrecital-taln.22</url>
      <language>fra</language>
      <bibkey>nusbaumer-etal-2025-evaluer</bibkey>
    </paper>
    <paper id="23">
      <title>Exploration de la modalité en français parlé et écrit</title>
      <author><first>Anna</first><last>Colli</last></author>
      <author><first>Delphine</first><last>Battistelli</last></author>
      <pages>376–389</pages>
      <abstract>Dans cet article, nous présentons une méthodologie pour comparer entre eux les profils modaux de corpus en français. Nous montrons quelles différences émergent ou non entre l’écrit et l’oral et pointons l’importance et la place des marqueurs polysémiques dans les deux cas. L’analyse de la polysémie du verbe pouvoir retient notre attention dans la mesure où ce verbe s’avère être un marqueur très présent dans l’ensemble des corpus.</abstract>
      <url hash="2fdcb0aa">2025.jeptalnrecital-taln.23</url>
      <language>fra</language>
      <bibkey>colli-battistelli-2025-exploration</bibkey>
    </paper>
    <paper id="24">
      <title>Exploration de la séparation en langues dans les modèles de traitement de la parole auto-supervisés multilingues préentraînés avec des données écologiques</title>
      <author><first>William</first><last>N. Havard</last></author>
      <author><first>Shrita</first><last>Hassamal</last></author>
      <author><first>Muhsina</first><last>Alleesaib</last></author>
      <author><first>Guilhem</first><last>Florigny</last></author>
      <author><first>Guillaume</first><last>Fon Sing</last></author>
      <author><first>Anne</first><last>Abeillé</last></author>
      <author><first>Benjamin</first><last>Lecouteux</last></author>
      <author><first>Emmanuel</first><last>Schang</last></author>
      <pages>390–403</pages>
      <abstract>Les modèles auto-supervisés omnilingues de traitement de la parole sont adaptables mais manquent de plausibilité écologique et cognitive. Entraînés sur des corpus monolingues, ils négligent le multi- linguisme réel et le code-switching. De précédents travaux suggèrent que de tels modèles procèdent à des regroupements en langues dans l’espace latent, mais cela pourrait être dû à des biais acoustiques ou paralinguistiques plutôt qu’à de véritables traitements linguistiques. Nous avons entraîné un modèle WAV2VEC2 sur des données multilingues de Maurice, incluant des locuteurs plurilingues et du code-switching, et avons étudié les représentations latentes du modèle. Nos analyses montrent que les facteurs acoustiques et paralinguistiques sont encodés sans apprentissage actif, tandis que le regroupement par langue émerge avec un réel apprentissage. Ces résultats éclairent ainsi sur les véritable capacités linguistiques et paralinguistiques des modèles auto-supervisés de la parole.</abstract>
      <url hash="2c721400">2025.jeptalnrecital-taln.24</url>
      <language>fra</language>
      <bibkey>n-havard-etal-2025-exploration</bibkey>
    </paper>
    <paper id="25">
      <title>Identification de mesures d’évaluation fiables pour la révision de textes scientifiques</title>
      <author><first>Léane</first><last>Jourdan</last></author>
      <author><first>Florian</first><last>Boudin</last></author>
      <author><first>Nicolas</first><last>Hernandez</last></author>
      <author><first>Richard</first><last>Dufour</last></author>
      <pages>404–435</pages>
      <abstract>L’évaluation de la révision des textes scientifiques reste un défi, car les métriques traditionnelles telles que ROUGE et BERTScore se concentrent sur la similarité à une référence plutôt que sur les améliorations réalisées. Nous analysons et identifions les limites de ces métriques et explorons des méthodes d’évaluation alternatives qui s’alignent mieux sur le jugement humain. Nous évaluons d’abord manuellement différentes révisions pour estimer leur qualité. Ensuite, nous examinons la possibilité d’utiliser des métriques d’évaluation sans référence provenant de domaines connexes du traitement automatique des langues (TAL) ainsi que des approches GML en tant que juge. Nos résultats montrent que GMLs évaluent efficacement le suivi des instructions mais peinent à évaluer l’acceptabilité, alors que les métriques spécifiques au domaine fournissent des informations complémentaires. Nous recommandons une approche hybride combinant l’évaluation GML en tant que juge et les mesures spécifiques à la tâche offrant l’évaluation la plus fiable de la qualité de la révision.</abstract>
      <url hash="16e4b85a">2025.jeptalnrecital-taln.25</url>
      <language>fra</language>
      <bibkey>jourdan-etal-2025-identification</bibkey>
    </paper>
    <paper id="26">
      <title>Intégration des relations inter-référents dans l’annotation de la coréférence : modèle et application</title>
      <author><first>Antoine</first><last>Boiteau</last></author>
      <author><first>Yann</first><last>Mathet</last></author>
      <author><first>Antoine</first><last>Widlöcher</last></author>
      <pages>436–449</pages>
      <abstract>La disponibilité de corpus annotés en coréférence demeure une nécessité pour de nombreux travaux en linguistique et en TAL. Toutefois, si de tels corpus sont bien disponibles, une part importante repose sur des modèles d’annotation ne permettant d’encoder qu’une partie des informations liées aux phénomènes coréférentiels. Après avoir redéfini un modèle élargi de la coréférence, nous montrerons les bénéfices d’une annotation menée à deux niveaux, celui de l’inscription des occurrences dans le texte (le repérage des maillons des chaînes de coréférence, niveau largement exploré) et celui des structures du modèle référentiel inféré (la clarification des rapports entre les entités désignées, domaine largement passé sous silence). Nous présenterons ensuite l’environnement OPERA destiné à l’annotation selon ce modèle repensé, et une campagne menée pour le tester.</abstract>
      <url hash="d608b0f7">2025.jeptalnrecital-taln.26</url>
      <language>fra</language>
      <bibkey>boiteau-etal-2025-integration</bibkey>
    </paper>
    <paper id="27">
      <title>L’Impact de la complexité textuelle sur le comportement de lecture : une analyse oculométrique et de la surprise des textes français</title>
      <author><first>Oksana</first><last>Ivchenko</last></author>
      <author><first>Natalia</first><last>Grabar</last></author>
      <pages>450–466</pages>
      <abstract>L’Impact de la complexité textuelle sur le comportement de lecture : une analyse oculométrique et de la surprise des textes français Cette étude examine comment la complexité du texte affecte les processus de lecture à travers différents types de textes en combinant la méthodologie d’oculométrie avec l’analyse de la surprise. Nous avons créé un corpus en français avec des textes généraux, cliniques et médicaux, dans leurs versions originales et simplifiées, annotés avec des mesures oculométriques complètes provenant de 23 participants. La modélisation linéaire à effets mixtes révèle que la surprise prédit significativement les temps de lecture pour tous les types de textes, les textes médicaux montrant une sensibilité accrue aux mots inattendus. De façon importante, la simplification a des effets différentiels selon le type de texte : bien qu’elle ne réduit pas significativement les temps de lecture pour les textes cliniques, elle diminue considérablement les temps de lecture pour les textes médicaux. De plus, la simplification atténue l’effet de la surprise spécifiquement dans les textes médicaux, réduisant le coût cognitif associé au traitement des mots inattendus.</abstract>
      <url hash="da6c960d">2025.jeptalnrecital-taln.27</url>
      <language>fra</language>
      <bibkey>ivchenko-grabar-2025-limpact</bibkey>
    </paper>
    <paper id="28">
      <title>La confiance de Mistral-7<fixed-case>B</fixed-case> est-elle justifiée ? Une évaluation en auto-estimation pour les questions biomédicales</title>
      <author><first>Laura</first><last>Zanella</last></author>
      <author><first>Ambroise</first><last>Baril</last></author>
      <pages>467–476</pages>
      <abstract>Évaluer la fiabilité des grands modèles de langage (LLMs) dans des tâches de question-réponse biomédicale est essentiel pour leur déploiement en toute sécurité dans des contextes médicaux. Dans cette étude, nous examinons si Mistral-7B est capable d’estimer avec précision la confiance qu’il accorde à ses propres réponses, en comparant ses scores de similarité auto-attribués à la similarité- cosinus avec des réponses de référence. Nos résultats montrent que Mistral-7B présente une forte tendance à la surconfiance, attribuant systématiquement des scores de similarité élevés, même lorsque la qualité des réponses varie. L’introduction de la génération augmentée par récupération (RAG) améliore la précision des réponses, comme en témoignent les valeurs plus élevées de similarité- cosinus, mais n’améliore pas significativement la calibration de la confiance. Bien que RAG réduise la surconfiance et améliore la corrélation entre les scores de similarité prédits et réels, le modèle continue de surestimer systématiquement la qualité de ses réponses. Ces résultats soulignent la nécessité de mécanismes d’estimation de confiance plus efficaces, afin d’aligner les auto-évaluations du modèle sur la précision réelle de ses réponses. Notre étude montre l’importance d’affiner les techniques de calibration des LLMs pour renforcer leur fiabilité dans les applications biomédicales.</abstract>
      <url hash="74cef0de">2025.jeptalnrecital-taln.28</url>
      <language>fra</language>
      <bibkey>zanella-baril-2025-la</bibkey>
    </paper>
    <paper id="29">
      <title>Latrumplang, instrument de destruction de la pensée : analyse de l’impact de la censure trumpiste sur la recherche en santé mentale</title>
      <author><first>Vincent</first><last>P. Martin</last></author>
      <author><first>Karën</first><last>Fort</last></author>
      <author><first>Jean-Arthur</first><last>Micoulaud-Franchi</last></author>
      <pages>477–487</pages>
      <abstract>Un processus de censure de l’activité scientifique est en cours aux États-Unis. À partir de listes de termes interdits, des dossiers de financements sont réétudiés, des articles scientifiques sont rétractés. Or, le langage structure les tranches du réel descriptibles — et donc celles qui peuvent être étudiées scientifiquement. Dans cet article, nous souhaitons afficher comment la mise en place d’une telle censure pourrait provoquer la disparition de la recherche portant sur la santé mentale. Pour cela, nous avons réalisé une analyse bibliographique des 64 434 articles contenant le terme « mental health » dans leur titre référencé dans PubMed. Nous avons ensuite extrait une liste de termes interdits de leur résumé, identifié les thèmes sous-jacents et généré un réseau lexical. Ces résultats démontrent l’impossibilité de penser la santé mentale sans les termes interdits par les directives trumpistes, dont la censure signerait l’abandon de plus de 50 ans de progrès en santé publique.</abstract>
      <url hash="432b8c3a">2025.jeptalnrecital-taln.29</url>
      <language>fra</language>
      <bibkey>p-martin-etal-2025-latrumplang</bibkey>
    </paper>
    <paper id="30">
      <title>Le rôle du contexte dans la classification séquentielle de phrases pour les documents longs</title>
      <author><first>Anas</first><last>Belfathi</last></author>
      <author><first>Nicolas</first><last>Hernandez</last></author>
      <author><first>Laura</first><last>Monceaux</last></author>
      <author><first>Richard</first><last>Dufour</last></author>
      <pages>488–501</pages>
      <abstract>La classification séquentielle de phrases étend la classification traditionnelle en intégrant un contexte plus large. Cependant, les approches de pointe rencontrent deux défis majeurs dans le traitement automatique des documents longs : les modèles de langue préentraînés sont limités par des contraintes de longueur d’entrée, tandis que les modèles hiérarchiques proposés introduisent souvent du contenu non pertinent. Nous proposons une approche de recherche d’information au niveau du document visant à extraire uniquement le contexte le plus pertinent. Nous introduisons deux types d’heuristiques : Séquentiel , qui capture l’information locale, et Sélectif, qui sélectionne les phrases les plus sémantiquement similaires. Nos expériences sur trois corpus juridiques en anglais montrent que ces heuristiques améliorent les performances. Les heuristiques séquentielles surpassent les modèles hiérarchiques sur deux des trois jeux de données. démontrant l’apport du contexte ciblé.</abstract>
      <url hash="53be79ae">2025.jeptalnrecital-taln.30</url>
      <language>fra</language>
      <bibkey>belfathi-etal-2025-le</bibkey>
    </paper>
    <paper id="31">
      <title><fixed-case>MOSAIC</fixed-case> : Mélange d’experts pour la détection de textes artificiels</title>
      <author><first>Matthieu</first><last>Dubois</last></author>
      <author><first>Pablo</first><last>Piantanida</last></author>
      <author><first>François</first><last>Yvon</last></author>
      <pages>502–525</pages>
      <abstract>La diffusion auprès du grand public de grands modèles de langue facilite la production de contenus nuisibles, médisants, malhonnêtes ou falsifiés. En réponse, plusieurs solutions ont été proposées pour identifier les textes ainsi produits, en traitant le problème comme une tâche de classification binaire. Les premières approches reposent sur l’analyse d’un document par un modèle détecteur, avec l’hypothèse qu’un faible score de perplexité indique que le contenu est artificiel. Des méthodes plus récentes proposent de comparer les distributions de probabilité calculées par deux modèles. Cependant, s’appuyer sur une paire fixe de modèles peut fragiliser les performances. Nous étendons ces méthodes en combinant plusieurs modèles et en développant une approche théoriquement fondée pour exploiter au mieux chacun d’entre eux.</abstract>
      <url hash="380e25a9">2025.jeptalnrecital-taln.31</url>
      <language>fra</language>
      <bibkey>dubois-etal-2025-mosaic-melange</bibkey>
    </paper>
    <paper id="32">
      <title>Mesurer les inégalités de genre en ligne avec le genre grammatical : Une étude du subreddit r/france</title>
      <author><first>Marie</first><last>Flesch</last></author>
      <author><first>Heather</first><last>Burnett</last></author>
      <pages>526–541</pages>
      <abstract>Cet article présente un système de détection du genre basé sur le genre grammatical, conçu pour le français, créé afin de mesurer les inégalités de genre dans les espaces francophones en ligne. Il décrit tout d’abord la création et le test du système, qui extrait le genre grammatical dans les expressions de type je suis depuis un lexique, sur un corpus étiqueté. Ensuite, il propose une étude de cas en deux parties, avec l’application du système sur un corpus de 11.8 millions de commentaires publiés sur r/france, le plus grand forum francophone de Reddit, suivie d’une étude des dynamiques de participation des femmes et des hommes dans cet espace. Cette recherche montre qu’un système de détection du genre simple, basé sur du pattern-matching, atteint une haute performance (précision de 96% dans le corpus test), et permet de dévoiler d’importantes inégalités de participation sur un forum francophone de premier plan.</abstract>
      <url hash="96bf6dd8">2025.jeptalnrecital-taln.32</url>
      <language>fra</language>
      <bibkey>flesch-burnett-2025-mesurer</bibkey>
    </paper>
    <paper id="33">
      <title>Modèles auto-supervisés de traitement de la parole pour le Créole Haitien</title>
      <author><first>William</first><last>N. Havard</last></author>
      <author><first>Renauld</first><last>Govain</last></author>
      <author><first>Benjamin</first><last>Lecouteux</last></author>
      <author><first>Emmanuel</first><last>Schang</last></author>
      <pages>542–554</pages>
      <abstract>Nous développons des modèles de traitement de la parole spécifiquement dédiés au créole haïtien (kreyòl), le positionnant ainsi comme une langue bien dotée en termes de modèles auto-supervisés de traitement de la parole. Pour ce faire, nous pré-entraînons des modèles monolingues WAV2VEC2BASE,WAV2VEC2-L ARGE etDATA 2VEC-AUDIO -BASEà partir de zéro, qui sont ensuite affinés pour une tâche de reconnaissance automatique de la parole. Nous comparons la performance de ces modèles avec des modèles affinés à partir de modèles multilingues (XLSR-53, XLSR2-300 M, MMS-1B) et monolingues basés sur le français (LEBENCHMARK 1 à 7K). Nos résultats démontrent l’efficacité du pré-entraînement monolingue, avec des performances pouvant rivaliser, voire surpasser, celle de grands modèles multilingues. Ce travail propose ainsi des modèles robustes de reconnaissance vocale pour le kreyòl , adaptables à d’autres créoles français des Caraïbes, contribuant ainsi au développement technologique de ces langues peu dotées.</abstract>
      <url hash="887137d3">2025.jeptalnrecital-taln.33</url>
      <language>fra</language>
      <bibkey>n-havard-etal-2025-modeles</bibkey>
    </paper>
    <paper id="34">
      <title>Modélisation de la lisibilité en français pour les personnes en situation d’illettrisme</title>
      <author><first>Wafa</first><last>Aissa</last></author>
      <author><first>Thibault</first><last>Bañeras-Roux</last></author>
      <author><first>Elodie</first><last>Vanzeveren</last></author>
      <author><first>Lingyun</first><last>Gao</last></author>
      <author><first>Alice</first><last>Pintard</last></author>
      <author><first>Rodrigo</first><last>Wilkens</last></author>
      <author><first>Thomas</first><last>François</last></author>
      <pages>555–572</pages>
      <abstract>Nous présentons une nouvelle formule de lisibilité en français spécifiquement conçue pour les personnes en situation d’illettrisme. À cette fin, nous avons construit un corpus de 461 textes annotés selon une échelle de difficulté spécialisée à ce public. Dans un second temps, nous avons systématiquement comparé les principales approches en lisibilité, incluant l’apprentissage automatique reposant sur des variables linguistiques, le fine-tuning de CamemBERT, une approche hybride combinant CamemBERT et des variables linguistiques et des modèles de langue génératifs (LLMs). Une analyse approfondie de ces modèles et de leurs performances est menée afin d’évaluer leur applicabilité dans des contextes réels.</abstract>
      <url hash="85902838">2025.jeptalnrecital-taln.34</url>
      <language>fra</language>
      <bibkey>aissa-etal-2025-modelisation</bibkey>
    </paper>
    <paper id="35">
      <title>Pensez: Moins de données, meilleur raisonnement – Repenser les <fixed-case>LLM</fixed-case> français</title>
      <author><first>Huy</first><last>Hoang Ha</last></author>
      <pages>573–598</pages>
      <abstract>Les grands modèles linguistiques (LLM) ont démontré des capacités remarquables dans diverses tâches de traitement automatique du langage naturel. Cependant, l’obtention de performances élevées dans des domaines spécialisés tels que le raisonnement mathématique et les langues autres que l’anglais nécessite souvent un entraînement intensif. Cet article étudie l’affinage stratégique sur un petit ensemble de données bilingue de haute qualité, afin d’améliorer à la fois les capacités de raisonnement et la maîtrise de la langue française d’un LLM. Nous démontrons des améliorations du raisonnement mathématique en utilisant seulement 2000 échantillons soigneusement sélectionnés. Ces résultats remettent en question l’hypothèse dominante selon laquelle des ensembles de données massifs sont une condition préalable à de solides performances de raisonnement pour les LLM.</abstract>
      <url hash="17af1cc3">2025.jeptalnrecital-taln.35</url>
      <language>fra</language>
      <bibkey>hoang-ha-2025-pensez</bibkey>
    </paper>
    <paper id="36">
      <title>Peut-on retrouver votre âge à partir de la transcription de votre parole ?</title>
      <author><first>Vanessa</first><last>Gaudray Bouju</last></author>
      <author><first>Menel</first><last>Mahamdi</last></author>
      <author><first>Iris</first><last>Eshkol-Taravella</last></author>
      <author><first>Angèle</first><last>Barbedette</last></author>
      <pages>599–613</pages>
      <abstract>L’identification et la classification des groupes sociaux à partir du langage constitue une préoccupation sociolinguistique majeure. Dans cet article, nous présentons une recherche de classification des locuteurs basée sur leur âge. Pour ce faire, nous exploitons un corpus de données du français oral, où chaque locuteur est associé à des métadonnées, dont son âge au moment de l’enregistrement. Notre objectif est de développer des méthodes d’apprentissage automatique capables de prédire la tranche d’âge d’un locuteur à partir de son discours transcrit de l’oral, allant de l’apprentissage supervisé à l’ingénierie de prompts sur des grands modèles de langage. Cette tâche n’est pas seulement un défi technique, elle soulève également des questions fondamentales sur la nature de la variation linguistique et sur les liens entre le langage et la société. En effet, en identifiant les corrélations entre certains traits linguistiques et l’âge, notre projet contribue à enrichir notre compréhension des mécanismes sous-jacents à la variation du langage et à ses implications dans la construction de l’identité sociale. Son autre apport est de questionner les traits linguistiques classiquement imputés à une tranche d’âge afin de montrer leurs limites.</abstract>
      <url hash="45329d8d">2025.jeptalnrecital-taln.36</url>
      <language>fra</language>
      <bibkey>gaudray-bouju-etal-2025-peut</bibkey>
    </paper>
    <paper id="37">
      <title>Plongement des constituants pour la représentation sémantique des phrases</title>
      <author><first>Eve</first><last>Sauvage</last></author>
      <author><first>Iskandar</first><last>Boucharenc</last></author>
      <author><first>Thomas</first><last>Gerald</last></author>
      <author><first>Julien</first><last>Tourille</last></author>
      <author><first>Sabrina</first><last>Campano</last></author>
      <author><first>Cyril</first><last>Grouin</last></author>
      <author><first>Sophie</first><last>Rosset</last></author>
      <pages>614–628</pages>
      <abstract>Les méthodes d’apprentissage profond en traitement automatique des langues reposent souvent sur une segmentation des textes en tokens avant leur vectorisation. Cette segmentation produit des sous-unités lexicales offrant une grande flexibilité. Toutefois, la réutilisation de tokens identiques dans des mots de sens différents peut favoriser des représentations basées sur la forme plutôt que sur la sémantique. Ce décalage entre la forme de surface et le sens peut induire des effets indésirables dans le traitement de la langue. Afin de limiter l’influence de la forme sur la sémantique des représentations vectorielles, nous proposons une représentation intermédiaire plus compacte et plus fidèle au sens des mots.</abstract>
      <url hash="113a7426">2025.jeptalnrecital-taln.37</url>
      <language>fra</language>
      <bibkey>sauvage-etal-2025-plongement</bibkey>
    </paper>
    <paper id="38">
      <title>Projeter pour mieux fusionner : une histoire de bandit et de lit</title>
      <author><first>Olivier</first><last>Ferret</last></author>
      <pages>629–641</pages>
      <abstract>La mise à disposition d’un nombre important de modèles de langue neuronaux affinés pour différentes tâches conduit assez naturellement à se poser la question de l’intérêt de les combiner, en particulier par le biais de la fusion de paramètres, option aboutissant au résultat demandant le moins de ressources. Dans cet article, nous proposons une nouvelle méthode entrant dans ce champ de recherche, fondé sur l’analyse procustéenne. Nous évaluons cette méthode pour la fusion de modèles affinés pour une même tâche à partir d’un même modèle de base, de type encodeur. En considérant neuf tâches du jeu de données GLUE et six méthodes de fusion de référence, nous montrons que notre proposition est capable d’améliorer les méthodes de fusion existantes dans la plupart des configurations testées.</abstract>
      <url hash="c12b2af3">2025.jeptalnrecital-taln.38</url>
      <language>fra</language>
      <bibkey>ferret-2025-projeter</bibkey>
    </paper>
    <paper id="39">
      <title><fixed-case>QUARTZ</fixed-case> : Approche abstractive non supervisée par question-réponse pour le résumé de dialogue orienté tâche</title>
      <author><first>Mohamed</first><last>Imed Eddine Ghebriout</last></author>
      <author><first>Gaël</first><last>Guibon</last></author>
      <author><first>Ivan</first><last>Lerner</last></author>
      <author><first>Emmanuel</first><last>Vincent</last></author>
      <pages>642–665</pages>
      <abstract>Le résumé de dialogues condense les conversations en un texte concis, réduisant la complexité des applications riches en interactions. Les approches existantes reposent souvent sur l’entraînement de modèles de langue à imiter des résumés humains. Cependant, cette approche est coûteuse et les résumés obtenus manquent souvent de pertinence, entraînant des performances sous-optimales, notamment en médecine. Dans cet article, nous introduisons QUARTZ , une méthode non supervisée pour le résumé de dialogues orienté tâche. QUARTZ génère plusieurs résumés et paires de questionsréponses à l’aide de grands modèles de langue (LLMs). Les résumés sont évalués en demandant aux LLMs de répondre à ces questions avant (i)de sélectionner les meilleures réponses et (ii)d’identifier le résumé le plus informatif. Enfin, nous affinons le meilleur LLM sur les résumés générés sélectionnés. Validé sur plusieurs ensembles de données, QUARTZ atteint des performances compétitives en zéro-shot, rivalisant avec les approches supervisées de pointe.</abstract>
      <url hash="fde48102">2025.jeptalnrecital-taln.39</url>
      <language>fra</language>
      <bibkey>imed-eddine-ghebriout-etal-2025-quartz</bibkey>
    </paper>
    <paper id="40">
      <title>Raffinage des représentations des tokens dans les modèles de langue pré-entraînés avec l’apprentissage contrastif : une étude entre modèles et entre langues</title>
      <author><first>Anna</first><last>Mosolova</last></author>
      <author><first>Marie</first><last>Candito</last></author>
      <author><first>Carlos</first><last>Ramisch</last></author>
      <pages>666–681</pages>
      <abstract>Les modèles de langue pré-entraînés ont apporté des avancées significatives dans les représentations contextuelles des phrases et des mots. Cependant, les tâches lexicales restent un défi pour ces représentations en raison des problèmes tels que la faible similarité des representations d’un même mot dans des contextes similaires. Mosolova et al. (2024) ont montré que l’apprentissage contrastif supervisé au niveau des tokens permettait d’améliorer les performances sur les tâches lexicales. Dans cet article, nous étudions la généralisabilité de leurs résultats obtenus en anglais au français, à d’autres modèles de langue et à plusieurs parties du discours. Nous démontrons que cette méthode d’apprentissage contrastif améliore systématiquement la performance sur les tâches de Word-in-Context et surpasse celle des modèles de langage pré-entraînés standards. L’analyse de l’espace des plongements lexicaux montre que l’affinage des modèles rapproche les exemples ayant le même sens et éloigne ceux avec des sens différents, ce qui indique une meilleure discrimination des sens dans l’espace vectoriel final.</abstract>
      <url hash="29134755">2025.jeptalnrecital-taln.40</url>
      <language>fra</language>
      <bibkey>mosolova-etal-2025-raffinage</bibkey>
    </paper>
    <paper id="41">
      <title>Repousser les limites des benchmarks actuels pour une évaluation réaliste des <fixed-case>LLM</fixed-case>s en migration de code</title>
      <author><first>Samuel</first><last>Mallet</last></author>
      <author><first>Joe</first><last>El Khoury</last></author>
      <author><first>Elõd</first><last>Egyed-Zsigmond</last></author>
      <pages>682–696</pages>
      <abstract>Les grands modèles de langage (LLMs) offrent un potentiel important pour la migration de code, mais les benchmarks actuels créent une illusion de maîtrise ne se traduisant pas par de bonnes performances sur des projets industriels complexes. Bien que des avancées comme RepoTransBench incluent des tâches à l’échelle de dépôts complets, ces benchmarks restent irréalistes : taille de projet trop limitée, gestion simplifiée des dépendances, faible diversité technologique et absence de génération ou adaptation automatique des tests. Dans cet article, nous analysons ces limites et nous suggérons de s’inspirer d’approches existantes dans des contextes monolingues, notamment la gestion des contextes longs et la génération automatique de tests, pour concevoir des benchmarks de migration plus réalistes. Notre contribution vise à encourager la communauté à développer des évaluations plus représentatives des défis industriels.</abstract>
      <url hash="cf078583">2025.jeptalnrecital-taln.41</url>
      <language>fra</language>
      <bibkey>mallet-etal-2025-repousser</bibkey>
    </paper>
    <paper id="42">
      <title>Supervision faible pour la classification des relations discursives</title>
      <author><first>Khalil</first><last>Maachou</last></author>
      <author><first>Chloé</first><last>Braud</last></author>
      <author><first>Philippe</first><last>Muller</last></author>
      <pages>697–714</pages>
      <abstract>L’identification des relations discursives est importante pour comprendre les liens sémantiques qui structurent un texte, mais cette tâche souffre d’un manque de données qui limite les performances. D’un autre côté, de nombreux corpus discursifs existent : les divergences entre les projets d’annotation empêchent cependant de combiner directement ces jeux de données à l’entraînement. Nous proposons de résoudre ce problème en exploitant le cadre de la supervision faible, dont l’objectif est de générer des annotations à partir de sources variées, comme des heuristiques ou des modèles pré-entraînés. Ces annotations bruitées et partielles sont ensuite combinées pour entraîner un modèle sur la tâche. En combinant cette méthode avec des stratégies permettant de gérer les différences dans les jeux d’étiquettes, nous démontrons qu’il est possible d’obtenir des performances proches d’un système entièrement supervisé en s’appuyant sur une très petite partie des données d’origine, ouvrant ainsi des perspectives d’amélioration pour des domaines ou des langages à faibles ressources.</abstract>
      <url hash="02f160b0">2025.jeptalnrecital-taln.42</url>
      <language>fra</language>
      <bibkey>maachou-etal-2025-supervision</bibkey>
    </paper>
    <paper id="43">
      <title>Syntaxe en dépendance avec les grammaires catégorielles abstraites : une application à la théorie sens-texte</title>
      <author><first>Marie</first><last>Cousin</last></author>
      <pages>715–728</pages>
      <abstract>L’implémentation de Cousin (2025) de la théorie sens-texte dans les grammaires catégorielles abstraites, un formalisme grammatical basé sur le λ-calcul, présente différentes limitations, en particulier l’articulation des dépendances au sein des structures, et le comportement des adjectifs et adverbes (rôle prédicatif des adjectifs et adverbes au niveau sémantique, nombre de modifieurs, etc.). Tout en utilisant la composition de grammaires catégorielles abstraites de Cousin (2025), nous proposons une représentation des structures syntaxiques en dépendances inspirée de de Groote (2023b) qui lève ces limitations.</abstract>
      <url hash="59a8a350">2025.jeptalnrecital-taln.43</url>
      <language>fra</language>
      <bibkey>cousin-2025-syntaxe</bibkey>
    </paper>
    <paper id="44">
      <title>Systèmes d’écriture et qualité des données : l’affinage de modèles de translittération dans un contexte de faibles ressources</title>
      <author><first>Emmett</first><last>Strickland</last></author>
      <author><first>Ilaine</first><last>Wang</last></author>
      <author><first>Damien</first><last>Nouvel</last></author>
      <author><first>Bénédicte</first><last>Diot-Parvaz Ahmad</last></author>
      <pages>729–740</pages>
      <abstract>Cet article présente une expérience visant à construire des modèles de romanisation affinés pour onze langues parmi lesquelles se trouvent des langues dites peu dotées. Nous démontrons qu’un modèle de romanisation efficace peut être créé en affinant un modèle de base entraîné sur un corpus important d’une ou plusieurs autres langues. Le système d’écriture semblerait jouer un rôle dans l’efficacité de certains modèles affinés. Nous présentons également des méthodes pour évaluer la qualité des données d’entraînement et d’évaluation, et comparons notre modèle arabe le plus performant à un modèle de référence.</abstract>
      <url hash="9d7c1393">2025.jeptalnrecital-taln.44</url>
      <language>fra</language>
      <bibkey>strickland-etal-2025-systemes</bibkey>
    </paper>
    <paper id="45">
      <title>Traitement automatique des évènements médiatiques : Détection, classification, segmentation et recherche sémantique</title>
      <author><first>Abdelkrim</first><last>Beloued</last></author>
      <pages>741–755</pages>
      <abstract>Cet article présente une méthodologie pour l’analyse automatique des évènements rapportés par les médias. Elle s’appuie sur des techniques de traitement automatique des langues, notamment la représentation sémantique des contenus médiatiques, la classification thématique, l’extraction d’évènements à partir de flux d’information, ainsi que la détection d’évènements par regroupement de représentations vectorielles issues de modèles de plongement sémantique. L’approche combine des modèles supervisés et non supervisés ainsi que des architectures capables de prendre en compte un contexte large. Plusieurs corpus sont utilisés pour l’entraînement et l’évaluation de ces modèles. Les résultats obtenus montrent une efficacité élevée dans la détection, le regroupement, la classification thématique et la recherche sémantique des évènements médiatiques. Cette approche offre ainsi des perspectives significatives pour structurer les faits réels, analyser leur représentation médiatique et comprendre l’influence exercée par les médias sur le traitement de ces faits.</abstract>
      <url hash="3a1d8438">2025.jeptalnrecital-taln.45</url>
      <language>fra</language>
      <bibkey>beloued-2025-traitement</bibkey>
    </paper>
    <paper id="46">
      <title>Une revue sur les hallucinations des <fixed-case>LLM</fixed-case></title>
      <author><first>Eleni</first><last>Metheniti</last></author>
      <author><first>Swarnadeep</first><last>Bhar</last></author>
      <author><first>Nicholas</first><last>Asher</last></author>
      <pages>756–779</pages>
      <abstract>Nous présentons une taxonomie des hallucinations dans les LLM, classées en trois catégories : hallucinations infidèles, contradictions factuelles et fabrications factuelles. Ces hallucinations peuvent se produire à cause des données de pré-entraînement et d’alignement, conduisant à des informations erronées, des préjugés et des erreurs de connaissance. Les méthodes d’entraînement peuvent introduire des problèmes tels que l’ajustement excessif, les effets boule de neige ou la sycophantie. Les stratégies de décodage peuvent également rendre les modèles trop confiants et enclins à attribuer des probabilités aux résultats incorrects. Une bibliographie sur la détection et atténuation des hallucinations est présentée: des méthodes de TALN, telles que la vérification des faits et la classification, de même que des méthodes basées sur les LLM. Les solutions d’atténuation des hallucinations comprennent l’amélioration de la qualité des données de pré-entraînement, l’injection de nouvelles connaissances (par ex. avec RAG), l’optimisation, SFT et RLHF, ainsi que des méthodes de décodage.</abstract>
      <url hash="f83b1004">2025.jeptalnrecital-taln.46</url>
      <language>fra</language>
      <bibkey>metheniti-etal-2025-une</bibkey>
    </paper>
    <paper id="47">
      <title>Vers l’entraînement de modèles de reconnaissance automatique de la parole auto-supervisés équitables sans étiquettes démographiques</title>
      <author><first>Laura</first><last>Alonzo-Canul</last></author>
      <author><first>Benjamin</first><last>Lecouteux</last></author>
      <author><first>François</first><last>Portet</last></author>
      <pages>780–790</pages>
      <abstract>Malgré des avancées importantes dans le domaine de la Reconnaissance Automatique de la Parole (RAP), les performances de reconnaissance restent inégales selon les groupes de locuteurs, ce qui pose des problèmes d’équité. Bien qu’il existe des méthodes pour réduire ces inégalités, elles dépendent de ressources externes au signal vocal, telles que des modèles de locuteur (speaker embeddings) ou des étiquettes démographiques textuelles, qui peuvent être indisponibles ou peu fiables. Dans ce travail, nous proposons une méthode pour améliorer l’équité dans la RAP qui ne dépend d’aucune de ces ressources. Notre approche utilise une méthode de clustering non supervisé à partir de représentations acoustiques classiques, auto-supervisées et hybrides. Nos expériences avec CommonV oice 16.1 démontrent que les modèles entraînés sur les clusters découverts améliorent les performances des groupes démographiques désavantagés tout en conservant des performances compétitives et en utilisant deux fois moins de données d’entraînement.</abstract>
      <url hash="cb9a0b81">2025.jeptalnrecital-taln.47</url>
      <language>fra</language>
      <bibkey>alonzo-canul-etal-2025-vers</bibkey>
    </paper>
    <paper id="48">
      <title>ding-01 :<fixed-case>ARG</fixed-case>0 Un corpus <fixed-case>AMR</fixed-case> pour le français parlé spontané</title>
      <author><first>Jeongwoo</first><last>Kang</last></author>
      <author><first>Maria</first><last>Boritchev</last></author>
      <author><first>Maximin</first><last>Coavoux</last></author>
      <pages>791–801</pages>
      <abstract>Nous présentons notre travail en cours sur l’annotation d’un corpus sémantique du français. Nous annotons le corpus DinG, constitué de transcriptions de dialogues spontanés en français enregistrées pendant des parties du jeu de plateau Catan , en Abstract Meaning Representation (AMR), un formalisme de représentation sémantique. Comme AMR a une couverture insuffisante de la dynamique de la parole spontanée, nous étendons le formalisme pour mieux représenter la parole spontanée et les structures de phrases spécifiques au français. En outre, nous diffusons un guide d’annotation détaillant ces extensions. Enfin, nous publions notre corpus sous licence libre (CC-SA-BY). Notre travail contribue au développement de ressources sémantiques pour le dialogue en français.</abstract>
      <url hash="2feed700">2025.jeptalnrecital-taln.48</url>
      <language>fra</language>
      <bibkey>kang-etal-2025-ding</bibkey>
    </paper>
    <paper id="49">
      <title>π-<fixed-case>YALLI</fixed-case> : un nouveau corpus pour des modèles de langue nahuatl / Yankuik nawatlahtolkorpus pampa tlahtolmachiotl</title>
      <author><first>Juan-José</first><last>Guzmán-Landa</last></author>
      <author><first>Juan-Manuel</first><last>Torres-Moreno</last></author>
      <author><first>Martha</first><last>Lorena Avendaño Garrido</last></author>
      <author><first>Miguel</first><last>Figueroa-Saavedra</last></author>
      <author><first>Ligia</first><last>Quintana-Torres</last></author>
      <author><first>Graham</first><last>Ranger</last></author>
      <author><first>Carlos-Emiliano</first><last>González-Gallardo</last></author>
      <author><first>Elvys</first><last>Linhares-Pontes</last></author>
      <author><first>Patricia</first><last>Velázquez-Morales</last></author>
      <author><first>Luis-Gil</first><last>Moreno-Jiménez</last></author>
      <pages>802–816</pages>
      <abstract>π-YALLI : a new corpus for Nahuatl Language Models The Nahuatl is a language with few computational resources, despite the fact that it is a living language spoken by around two million people. We built π-YALLI, a corpus that enables research and development of dynamic and static Language Models (LM). We measured the perplexity of π-YALLI, evaluating state-of-the-art LM performance on a manually annotated semantic similarity corpus relative to annotator agreement. The results show the difficulty of working with this π-language, but at the same time open up interesting perspectives for the study of other NLP tasks on Nahuatl.</abstract>
      <url hash="9a62a484">2025.jeptalnrecital-taln.49</url>
      <bibkey>guzman-landa-etal-2025-p</bibkey>
    </paper>
  </volume>
  <volume id="trad" ingest-date="2025-09-28" type="proceedings">
    <meta>
      <booktitle>Actes des 32ème Conférence sur le Traitement Automatique des Langues Naturelles (TALN), volume 2 : traductions d'articles publiés</booktitle>
      <editor><first>Frédéric</first><last>Bechet</last></editor>
      <editor><first>Adrian-Gabriel</first><last>Chifu</last></editor>
      <editor><first>Karen</first><last>Pinel-sauvagnat</last></editor>
      <editor><first>Benoit</first><last>Favre</last></editor>
      <editor><first>Eliot</first><last>Maes</last></editor>
      <editor><first>Diana</first><last>Nurbakova</last></editor>
      <publisher>ATALA \\&amp; ARIA</publisher>
      <address>Marseille, France</address>
      <month>6</month>
      <year>2025</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="85bc05d4">2025.jeptalnrecital-trad.0</url>
      <bibkey>jep-taln-recital-2025-trad</bibkey>
    </frontmatter>
    <paper id="1">
      <title>« Les femmes ne font pas de crise cardiaque ! » Étude des biais de genre dans les cas cliniques synthétiques en français</title>
      <author><first>Fanny</first><last>Ducel</last></author>
      <author><first>Nicolas</first><last>Hiebel</last></author>
      <author><first>Olivier</first><last>Ferret</last></author>
      <author><first>Karën</first><last>Fort</last></author>
      <author><first>Aurélie</first><last>Névéol</last></author>
      <pages>1–1</pages>
      <abstract>De plus en plus de professionnels de santé utilisent des modèles de langue. Cependant, ces modèles présentent et amplifient des biais stéréotypés qui peuvent mettre en danger des vies. Cette étude vise à évaluer les biais de genre dans des cas cliniques générés automatiquement en français concernant dix pathologies. Nous utilisons sept modèles de langue affinés et un outil de détection automatique du genre pour mesurer les associations entre pathologie et genre. Nous montrons que les modèles sur-génèrent des cas décrivant des patients masculins, allant à l’encontre des prévalences réelles. Par exemple, lorsque les invites ne spécifient pas de genre, les modèles génèrent huit fois plus de cas cliniques décrivant des patients (plutôt que des patientes) pour les crises cardiaques. Nous discutons des possibles dommages induits par les modèles de langue, en particulier pour les femmes et les personnes transgenres, de la définition d’un modèle de langue « idéal » et des moyens d’y parvenir.</abstract>
      <url hash="3a6de4bd">2025.jeptalnrecital-trad.1</url>
      <language>fra</language>
      <bibkey>ducel-etal-2025-les</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>ACL</fixed-case>-rlg : Un dataset pour la génération de listes de lecture</title>
      <author><first>Julien</first><last>Aubert-Béduchaud</last></author>
      <author><first>Florian</first><last>Boudin</last></author>
      <author><first>Béatrice</first><last>Daille</last></author>
      <author><first>Richard</first><last>Dufour</last></author>
      <pages>2–2</pages>
      <abstract>Se familiariser avec un nouveau domaine scientifique et sa littérature associée peut s’avérer complexe en raison du nombre considérable d’articles disponibles. Les listes de références académiques compilées par des experts, également appelées listes de lecture, offrent un moyen structuré et efficace d’acquérir une vue d’ensemble approfondie d’un domaine scientifique. Dans cet article, nous présentonsACL-rlg , le plus grand ensemble de données ouvertes rassemblant des listes de lecture annotées par des experts. Nous proposons également plusieurs bases de référence pour évaluer la génération de listes de lecture, que nous formalisons comme une tâche de récupération d’information. Notre étude qualitative met en évidence les performances limitées des moteurs de recherche académiques traditionnels et des méthodes d’indexation dans ce contexte, tandis que GPT-4o, bien que produisant de meilleurs résultats, présente des signes potentiels de contamination des données.</abstract>
      <url hash="b234b90f">2025.jeptalnrecital-trad.2</url>
      <language>fra</language>
      <bibkey>aubert-beduchaud-etal-2025-acl-rlg</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>A</fixed-case>dmin<fixed-case>S</fixed-case>et and <fixed-case>A</fixed-case>dmin<fixed-case>BERT</fixed-case> : un jeu de données et un modèle de langue pré-entraîné pour explorer le dédale non structuré des données administratives françaises</title>
      <author><first>Thomas</first><last>Sebbag</last></author>
      <author><first>Solen</first><last>Quiniou</last></author>
      <author><first>Nicolas</first><last>Stucky</last></author>
      <author><first>Emmanuel</first><last>Morin</last></author>
      <pages>3–4</pages>
      <abstract>Les modèles de langue pré-entraînés (PLM) sont largement utilisés en traitement automatique du langage naturel (TALN), mais peu adaptés aux textes administratifs, souvent non standardisés et spécialisés. En France, l’absence de réglementation uniforme et l’hétérogénéité des sources compliquent le traitement des documents administratifs. Pour pallier ce problème, nous proposons AdminBERT, le premier modèle de langue pré-entraîné en français dédié aux documents administratifs. Nous évaluons AdminBERT sur la tâche de reconnaissance des entités nommées (REN), en le comparant à des modèles génériques, un grand modèle de langue (LLM) et une variante du modèle BERT. Nos résultats montrent qu’un pré-entraînement sur des textes administratifs améliore significativement la reconnaissance des entités nommées. Nous mettons à disposition AdminBERT, AdminSet (un corpus de pré-entraînement) et AdminSet-NER, le premier jeu de données annoté pour la REN sur des textes administratifs français.</abstract>
      <url hash="0b4fa8a9">2025.jeptalnrecital-trad.3</url>
      <language>fra</language>
      <bibkey>sebbag-etal-2025-adminset-adminbert</bibkey>
    </paper>
    <paper id="4">
      <title>Anti-surprise : Une métrique complémentaire pour évaluer l’apprentissage lexical des (grands) modèles de langue</title>
      <author><first>Nazanin</first><last>Shafiabadi</last></author>
      <author><first>Guillaume</first><last>Wisniewski</last></author>
      <pages>5–5</pages>
      <abstract>Un grand nombre de travaux s’appuient sur l’analyse des courbes de surprise pour évaluer la manière dont les modèles de langue capture le sens des mots au cours de leur apprentissage. Toutefois, cette approche ne considère que la capacité d’un modèle à prédire un mot dans des contextes appropriés, sans prendre en compte sa capacité à ne pas produire ce mot dans des contextes inappropriés. Pour combler cette lacune, nous introduisons une nouvelle mesure complémentaire, que nous appelons l’anti-surpris, qui évalue la capacité d’un modèle à ne pas utiliser un mot dans des contextes où il serait surprenant voire erroné. Nous montrons que l’analyse conjointe des courbes de surprise et d’anti-surprise permet de mieux caractériser l’acquisition du lexique par les modèles de langue.</abstract>
      <url hash="060f55a6">2025.jeptalnrecital-trad.4</url>
      <language>fra</language>
      <bibkey>shafiabadi-wisniewski-2025-anti</bibkey>
    </paper>
    <paper id="5">
      <title>Apprentissage par renforcement pour l’alignement des agents <fixed-case>LLM</fixed-case>s avec des environnements interactifs : quantification et réduction du surapprentissage aux prompts</title>
      <author><first>Mohamed</first><last>Salim Aissi</last></author>
      <author><first>Clement</first><last>Romac</last></author>
      <author><first>Thomas</first><last>Carta</last></author>
      <author><first>Sylvain</first><last>Lamprier</last></author>
      <author><first>Pierre-Yves</first><last>Oudeyer</last></author>
      <author><first>Olivier</first><last>Sigaud</last></author>
      <author><first>Laure</first><last>Soulier</last></author>
      <author><first>Nicolas</first><last>Thome</last></author>
      <pages>6–7</pages>
      <abstract>L’apprentissage par renforcement constitue une approche prometteuse pour aligner les connaissances des Grands Modèles de Langue (LLMs) avec des tâches de prise de décision séquentielle. Cependant, peu d’études ont analysé en profondeur l’impact de l’ajustement des LLMs par apprentissage par renforcement dans un environnement spécifique. Dans cet article, nous proposons un nouveau cadre d’analyse pour évaluer la sensibilité des LLMs aux formulations de prompt après un entraînement par renforcement dans un environnement textuel. Nos résultats montrent que la performance des LLMs se dégrade lorsqu’ils sont confrontés à des formulations de prompt différentes de celles utilisées durant la phase d’entraînement par renforcement. Par ailleurs, nous analysons l’origine de cette sensibilité en examinant les représentations internes du modèle ainsi que les tokens saillants. Enfin, nous proposons l’utilisation d’une fonction de coût contrastive afin d’atténuer cette sensibilité et d’améliorer la robustesse et les capacités de généralisation des LLMs.</abstract>
      <url hash="e65d1f7b">2025.jeptalnrecital-trad.5</url>
      <language>fra</language>
      <bibkey>salim-aissi-etal-2025-apprentissage</bibkey>
    </paper>
    <paper id="6">
      <title>Attention Chaînée et Causale pour un Suivi Efficace des Entités</title>
      <author><first>Erwan</first><last>Fagnou</last></author>
      <author><first>Paul</first><last>Caillon</last></author>
      <author><first>Blaise</first><last>Delattre</last></author>
      <author><first>Alexandre</first><last>Allauzen</last></author>
      <pages>8–8</pages>
      <abstract>Ce travail met en évidence une limitation théorique des transformers pour les tâches de suivi d’entités, montrant qu’ils nécessitent log2(n+ 1) couches pour gérer n changements d’état. Pour surmonter cette contrainte, nous proposons ChaCAL (Chain and Causal Attention Layer), une modification de l’attention standard qui l’interprète comme une matrice d’adjacence, permettant de capturer efficacement les dépendances longues avec une seule couche. Les expériences menées sur un jeu de données synthétique et un autre de suivi d’objets démontrent que ChaCAL surpasse les transformers classiques en réduisant la profondeur du modèle, tout en maintenant des performances compétitives sur une tâche de modélisation du langage. Cette approche optimise l’efficacité des modèles tout en réduisant leur coût computationnel.</abstract>
      <url hash="32337ad4">2025.jeptalnrecital-trad.6</url>
      <language>fra</language>
      <bibkey>fagnou-etal-2025-attention</bibkey>
    </paper>
    <paper id="7">
      <title>Atténuer l’impact de la qualité des références sur l’évaluation des systèmes de résumé grâce aux métriques sans référence</title>
      <author><first>Théo</first><last>Gigant</last></author>
      <author><first>Camille</first><last>Guinaudeau</last></author>
      <author><first>Marc</first><last>Decombas</last></author>
      <author><first>Frédéric</first><last>Dufaux</last></author>
      <pages>9–9</pages>
      <abstract>Les métriques d’évaluation sont utilisées comme des indicateurs pour évaluer les systèmes de résumé abstractif lorsque les annotations sont trop coûteuses. Pour être utiles, ces métriques doivent permettre une évaluation fine, présenter une forte corrélation avec les annotations humaines, et idéalement ne pas dépendre de la qualité des références. Cependant la plupart des métriques d’évaluation standard pour le résumé sont basées sur des références, et les métriques sans références sont faiblement corrélées à la pertinence des résumés, en particulier pour des documents longs. Dans cet article, nous introduisons une métrique sans référence qui corrèle bien avec la pertinence telle qu’évaluée par des humains, tout en étant très peu coûteuse à calculer. Nous montrons également que cette métrique peut être utilisée en complément de métriques basées sur des références afin d’améliorer leur robustesse dans des situations où la qualité des références est faible.</abstract>
      <url hash="07e03c09">2025.jeptalnrecital-trad.7</url>
      <language>fra</language>
      <bibkey>gigant-etal-2025-attenuer</bibkey>
    </paper>
    <paper id="8">
      <title>Combler les lacunes de Wikipédia : tirer parti de la génération de texte pour améliorer la couverture encyclopédique des groupes sous-représentés</title>
      <author><first>Simon</first><last>Mille</last></author>
      <author><first>Massimiliano</first><last>Pronesti</last></author>
      <author><first>Craig</first><last>Thomson</last></author>
      <author><first>Michela</first><last>Lorandi</last></author>
      <author><first>Sophie</first><last>Fitzpatrick</last></author>
      <author><first>Rudali</first><last>Huidrom</last></author>
      <author><first>Mohammed</first><last>Sabry</last></author>
      <author><first>Amy</first><last>O’Riordan</last></author>
      <author><first>Anya</first><last>Belz</last></author>
      <pages>10–10</pages>
      <abstract>Wikipédia a des lacunes systématiques dans sa couverture des langues peu dotées ainsi que des groupes sous-représentés (par exemple, les femmes). Cet article présente un nouvel outil pour soutenir les efforts visant à combler ces lacunes en générant automatiquement des débuts d’articles en anglais, français et irlandais, et en facilitant la post-édition et la mise en ligne sur Wikipédia. Un générateur basé sur des règles et un LLM sont utilisés pour générer deux articles alternatifs à partir de graphes de connaissances DBpedia ou Wikidata sélectionnés par l’utilisateur, permettant à l’article généré via LLM, souvent plus fluide mais plus sujet aux erreurs, d’être vérifié en termes de contenu par rapport à l’article généré par des règles, plus fiable, mais moins fluide. Le code de l’outil est disponible sur https://github.com/dcu-nlg/wiki-gen-demo et il est actuellement déployé sur http://ec2-18-224-151-90.us-east-2.compute.amazonaws.com:3000/.</abstract>
      <url hash="90022f9c">2025.jeptalnrecital-trad.8</url>
      <language>fra</language>
      <bibkey>mille-etal-2025-combler</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>E</fixed-case>mo<fixed-case>D</fixed-case>ynami<fixed-case>X</fixed-case> : Prédiction de stratégies de dialogue pour le support émotionnel via la modélisation de mélange d’émotions et de la dynamique du discours</title>
      <author><first>Chenwei</first><last>Wan</last></author>
      <author><first>Matthieu</first><last>Labeau</last></author>
      <author><first>Chloé</first><last>Clavel</last></author>
      <pages>11–12</pages>
      <abstract>Concevoir des systèmes conversationnels dotés d’une intelligence émotionnelle pour apporter du réconfort et des conseils aux personnes en détresse constitue un domaine de recherche particulièrement prometteur. Récemment, grâce aux avancées des grands modèles de langue (LLMs), les agents conversationnels entraînés de bout en bout sans étapes explicites de prédiction de stratégie de dialogue sont devenus plus courants. Cependant, la planification implicite de stratégie manque de transparence, et des études récentes montrent que la préférence inhérente des LLMs pour certaines stratégies socioémotionnelles nuit à la qualité du soutien émotionnel fourni. Pour relever ce défi, nous proposons de dissocier la prédiction de stratégies de la génération du langage et introduisons un nouveau cadre de prédiction de stratégie conversationnelle, EmoDynamiX, qui modélise la dynamique du discours entre les émotions fines du côté de l’utilisateur et les stratégies du système au moyen d’un graphe hétérogène, afin d’améliorer à la fois les performances et la transparence. Les résultats expérimentaux sur deux jeux de données de conversations pour le support émotionnel (ESC) montrent qu’EmoDynamiX surpasse de manière significative les méthodes antérieures à l’état de l’art (avec une meilleure maîtrise et un biais de préférence plus faible). Notre approche offre également une meilleure transparence en permettant de retracer le processus de prise de décision.</abstract>
      <url hash="9256fba4">2025.jeptalnrecital-trad.9</url>
      <language>fra</language>
      <bibkey>wan-etal-2025-emodynamix-prediction</bibkey>
    </paper>
    <paper id="10">
      <title>Évaluation de la confidentialité des textes cliniques synthétiques générés par des modèles de langue</title>
      <author><first>Foucauld</first><last>Estignard</last></author>
      <author><first>Sahar</first><last>Ghannay</last></author>
      <author><first>Julien</first><last>Girard-Satabin</last></author>
      <author><first>Nicolas</first><last>Hiebel</last></author>
      <author><first>Aurélie</first><last>Névéol</last></author>
      <pages>13–13</pages>
      <abstract>Les grands modèles de langue (LLM) peuvent être utilisés pour produire des documents synthétiques similaires à des documents réels dont la disponibilité est limitée pour des raisons de confidentialité ou de droits d’auteur. Dans cet article, nous étudions les risques en lien avec la confidentialité dans les documents générés automatiquement. Nous utilisons des textes synthétiques générés à partir d’un modèle pré-entraîné et affiné sur des cas cliniques en français afin d’évaluer ces risques selon trois critères : (1) la similarité entre un corpus d’entraînement réel et le corpus synthétique (2) les corrélations entre les caractéristiques cliniques dans le corpus d’entraînement et le corpus synthétique et (3) une attaque par inférence d’appartenance (MIA, en anglais) utilisant un modèle affiné sur le corpus synthétique. Nous identifions des associations de caractéristiques cliniques qui suggèrent que le filtrage du corpus d’entraînement pourrait contribuer à la préservation de la confidentialité. Les attaques par inférence d’appartenance n’ont pas été concluantes.</abstract>
      <url hash="dedeb029">2025.jeptalnrecital-trad.10</url>
      <language>fra</language>
      <bibkey>estignard-etal-2025-evaluation</bibkey>
    </paper>
    <paper id="11">
      <title>Évaluation des <fixed-case>LLM</fixed-case>s pour l’Attribution de Citations dans les Textes Littéraires: une Étude de <fixed-case>LL</fixed-case>a<fixed-case>M</fixed-case>a3</title>
      <author><first>Gaspard</first><last>Michel</last></author>
      <author><first>Elena</first><last>V. Epure</last></author>
      <author><first>Romain</first><last>Hennequin</last></author>
      <author><first>Christophe</first><last>Cerisara</last></author>
      <pages>14–14</pages>
      <abstract>Les grands modèles de langage (LLMs) ont montré des résultats prometteurs dans diverses tâches littéraires, souvent liés la mémorisation de détails complexes sur la narration et les personnages fictifs. Dans cet article, nous évaluons la capacité de Llama-3 à attribuer les citations à leur locuteur dans les romans Anglais du 18ème au 20ème siècle. Le LLM obtient des résultats impressionnants sur un corpus de 28 romans, surpassant largement les performances publiées de ChatGPT et de modèles basés sur de puissants encodeurs de texte. Nous validons ensuite ces résultats en analysant l’impact de la mémorisation des passages de livres et d’une éventuelle contamination des annotations. Nos analyses montrent que ces formes de mémorisation n’expliquent pas l’important gain de performance, établissant ainsi Llama-3 comme le nouvel état de l’art pour l’attribution des citations dans la littérature anglaise. L’article est disponible sur le site suivant : https://aclanthology.org/ 2025.naacl-short.62/</abstract>
      <url hash="fe61f875">2025.jeptalnrecital-trad.11</url>
      <language>fra</language>
      <bibkey>michel-etal-2025-evaluation</bibkey>
    </paper>
    <paper id="12">
      <title>Extraction de mots-clés à partir d’articles scientifiques: comparaison entre modèles traditionnels et modèles de langue</title>
      <author><first>Motasem</first><last>Alrahabi</last></author>
      <author><first>Nacef</first><last>Ben Mansour</last></author>
      <author><first>Hamed</first><last>Rahimi</last></author>
      <pages>15–27</pages>
      <abstract>L’extraction automatique des mots-clés est cruciale pour résumer le contenu des documents et affiner la recherche d’informations. Dans cette étude, nous comparons les performances de plusieurs modèles d’extraction et de génération de mots-clés appliqués aux résumés d’articles issus des archives HAL : des approches basées sur des statistiques et des modèles vectoriels, ainsi que des approches génératives modernes utilisant les LLMs. Les résultats montrent que les LLMs surpassent largement les méthodes traditionnelles en termes de précision et de pertinence, même en configuration zero-shot, et que l’inclusion des titres d’articles améliore significativement les scores F1. Nous introduisons également une nouvelle métrique pour évaluer les performances des LLMs en tenant compte des coûts de traitement, offrant ainsi une perspective équilibrée entre efficacité et coût.</abstract>
      <url hash="a48b195f">2025.jeptalnrecital-trad.12</url>
      <language>fra</language>
      <bibkey>alrahabi-etal-2025-extraction</bibkey>
    </paper>
    <paper id="13">
      <title>Faut-il éliminer toutes les hallucinations dans un résumé abstractif pour le domaine juridique ?</title>
      <author><first>Nihed</first><last>Bendahman</last></author>
      <author><first>Karen</first><last>Pinel-Sauvagnat</last></author>
      <author><first>Gilles</first><last>Hubert</last></author>
      <author><first>Mokhtar</first><last>Boumedyen Billami</last></author>
      <pages>28–29</pages>
      <abstract>La génération automatique de résumés dans le domaine juridique requiert une compréhension approfondie des spécificités du domaine, notamment en ce qui concerne le vocabulaire employé par les experts. En effet, ces derniers s’appuient largement sur leurs connaissances externes lors de la rédaction des résumés, afin de contextualiser les principales entités juridiques (lois) du document. Cela conduit à des résumés de référence contenant de nombreuses abstractions, que les modèles de l’état de l’art peinent à reproduire. Dans cet article, nous proposons une approche de génération de résumé basée sur les entités, visant à apprendre au modèle à générer des hallucinations factuelles, aussi proches que possible des abstractions présentes dans les résumés de référence. Nous évaluons notre approche sur deux corpus juridiques différents, contenant des documents en anglais et en français. Les résultats montrent que notre approche permet de réduire les hallucinations non factuelles tout en maximisant la couverture des résumés et les hallucinations factuelles. De plus, la qualité globale des résumés est également améliorée, démontrant ainsi la pertinence de la génération de résumé guidée par les entités dans le domaine juridique.</abstract>
      <url hash="f85be619">2025.jeptalnrecital-trad.13</url>
      <language>fra</language>
      <bibkey>bendahman-etal-2025-faut</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>G</fixed-case>e<fixed-case>NR</fixed-case>e : un système de neutralisation automatique du genre exploitant les noms collectifs</title>
      <author><first>Enzo</first><last>Doyen</last></author>
      <author><first>Amalia</first><last>Todirascu</last></author>
      <pages>30–30</pages>
      <abstract>Les outils de traitement automatique des langues (TAL) ont tendance à introduire des biais de genre, notamment par une surutilisation du masculin générique. La tâche de réécriture du genre en TAL, qui vise à remplacer des formes genrées par des formes neutres, inclusives ou contraires, peut permettre de réduire ces biais. Bien que des travaux de neutralisation automatique du genre aient été conduits en anglais, aucun projet similaire n’existe pour le français. Cet article présente GeNRe, le tout premier système de neutralisation automatique du genre, qui exploite les noms collectifs. Nous présentons un modèle à base de règles (SBR) et affinons deux modèles de langue à partir des données générées. Nous nous intéressons aussi aux modèles d’instruction, jusque-là inutilisés pour cette tâche, en particulier Claude 3 Opus. Nous obtenons des résultats similaires pour le SBR et Claude 3 Opus lorsqu’il est utilisé conjointement avec notre dictionnaire.</abstract>
      <url hash="fe2a0ae0">2025.jeptalnrecital-trad.14</url>
      <language>fra</language>
      <bibkey>doyen-todirascu-2025-genre-un</bibkey>
    </paper>
    <paper id="15">
      <title>Graphes, <fixed-case>NER</fixed-case> et <fixed-case>LLM</fixed-case>s pour la classification non supervisée de documents</title>
      <author><first>Imed</first><last>Keraghel</last></author>
      <author><first>Mohamed</first><last>Nadif</last></author>
      <pages>31–31</pages>
      <abstract>Les récents progrès en apprentissage automatique, notamment les modèles de langage de grande taille (LLMs) tels que BERT et GPT, offrent des plongements contextuels riches qui améliorent la représentation des textes. Cependant, les approches actuelles de clustering de documents négligent souvent les relations profondes entre entités nommées ainsi que le potentiel des représentations issues des LLMs. Cet article propose une nouvelle approche qui intègre la reconnaissance d’entités nommées (NER) et les embeddings de LLMs dans un cadre fondé sur les graphes pour le clustering de documents. La méthode construit un graphe dont les nœuds représentent les documents et dont les arêtes sont pondérées par la similarité entre entités nommées, le tout optimisé au moyen d’un réseau de neurones convolutifs sur graphes (GCN). Cela permet un regroupement plus efficace des documents sémantiquement proches. Les résultats expérimentaux indiquent que notre approche surpasse les méthodes traditionnelles basées sur la cooccurrence, en particulier pour les documents riches en entités nommées.</abstract>
      <url hash="924764d9">2025.jeptalnrecital-trad.15</url>
      <language>fra</language>
      <bibkey>keraghel-nadif-2025-graphes</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>HISTOIRESMORALES</fixed-case>: Un jeu de données français pour évaluer l’alignement moral des modèles de langage</title>
      <author><first>Thibaud</first><last>Leteno</last></author>
      <author><first>Irina</first><last>Proskurina</last></author>
      <author><first>Antoine</first><last>Gourru</last></author>
      <author><first>Julien</first><last>Velcin</last></author>
      <author><first>Charlotte</first><last>Laclau</last></author>
      <author><first>Guillaume</first><last>Metzler</last></author>
      <author><first>Christophe</first><last>Gravier</last></author>
      <pages>32–32</pages>
      <abstract>L’alignement des modèles de langage avec les valeurs humaines est essentiel, à mesure qu’ils s’intègrent dans la vie quotidienne. Ces modèles sont souvent adaptés aux préférences des utilisateurs mais il est important de veiller à ce qu’ils respectent des normes morales en situation réelle. Malgré des avancées dans d’autres langues, le raisonnement moral des modèles en français reste peu étudié. Pour combler cette lacune, nous présentons HistoiresMorales, un jeu de données français dérivé de MoralStories, traduit puis affiné avec des locuteurs natifs pour assurer précision grammaticale et ajustement culturel. Afin de favoriser de futures recherches, nous menons des expériences préliminaires sur l’alignement des modèles multilingues en français et en anglais. Bien que les modèles de langage s’alignent généralement sur les normes morales humaines, nous observons qu’ils restent influençables, tant vers un alignement moral qu’immoral.</abstract>
      <url hash="1a97131a">2025.jeptalnrecital-trad.16</url>
      <language>fra</language>
      <bibkey>leteno-etal-2025-histoiresmorales-un</bibkey>
    </paper>
    <paper id="17">
      <title>Incorporation de Traits de Personnalité dans les Agents Conversationnels à base de <fixed-case>GML</fixed-case> : Étude de Cas de l’Assistance Client en Français</title>
      <author><first>Ahmed</first><last>Njifenjou</last></author>
      <author><first>Virgile</first><last>Sucal</last></author>
      <author><first>Bassam</first><last>Jabaian</last></author>
      <author><first>Fabrice</first><last>Lefèvre</last></author>
      <pages>33–33</pages>
      <abstract>Parmi les diverses théories élaborées pour capturer la complexité multidimensionnelle de la personnalité humaine, particulièrement en psychologie, le modèle des Big Five, aussi appelé « OCEAN », en raison de ses cinq dimensions principales, s’est affirmé comme un cadre analytique prééminent. Ce modèle a été incorporé dans le développement de chatbots mais les méthodes actuelles, comme l’emploi de paires binaires de traits ou l’analyse isolée de chaque trait, ne parviennent pas à rendre compte de la richesse nuancée de la personnalité humaine. Dans cette recherche, nous introduisons une approche fondée sur une représentation vectorielle, où chacune des dimensions représente l’intensité d’un trait OCEAN sur une échelle continue. Cette nouvelle méthode accroît la flexibilité et améliore la fidélité du modèle dans la capture de la diversité des personnalités. L’application aux scénarios d’assistance client en français démontre que, sur la base de conversations humains-bots ainsi que bots-bots, les vecteurs de personnalité attribués sont distinguables à la fois par les humains et par les GML. Leurs évaluations subjectives confirment les impacts mesurables de la personnalité attribuée sur l’expérience utilisateur, l’efficacité de l’agent et la qualité des conversations.</abstract>
      <url hash="1dc1c26b">2025.jeptalnrecital-trad.17</url>
      <language>fra</language>
      <bibkey>njifenjou-etal-2025-incorporation</bibkey>
    </paper>
    <paper id="18">
      <title>Inférence en langue naturelle appliquée au recrutement de patients pour les essais cliniques : le point de vue du patient</title>
      <author><first>Mathilde</first><last>Aguiar</last></author>
      <author><first>Pierre</first><last>Zweigenbaum</last></author>
      <author><first>Nona</first><last>Naderi</last></author>
      <pages>34–35</pages>
      <abstract>Recruter des patients pour les essais cliniques est long et complexe. Habituellement, le processus de recrutement est initié par un professionnel de santé qui propose à un patient de participer à l’essai clinique. Promouvoir les essais directement aux patients via des plateformes en ligne pourrait aider à en atteindre un plus grand nombre. Dans cette étude, nous nous intéressons au cas où le patient est l’initiateur de la démarche et veut savoir s’il est éligible à un essai clinique, tout cela en utilisant son propre langage patient. Pour déterminer si l’utilisation d’un tel langage permet tout de même au modèle de langue de déterminer l’égilibilité du patient pour l’essai clinique, nous construisons la tâche Natural Language Inference for Patient Recrutement (NLI4PR). Pour cela nous adaptons le jeu de données TREC 2022 Clinical Trial Track en réécrivant manuellement les profils médicaux en langage patient. Nous extrayons également les essais cliniques où les patients étaient labellisés « éligible » ou « exclu ». Nous soumettons des amorces à plusieurs grands modèles de langue, et obtenons un score F1 compris entre 56,6 et 71,8 avec le langage patient, contre 64,7 à 73,1 pour du langage médical. Nous observons que l’utilisation du langage patient ne mène qu’à une dégradation de performance relativement petite pour notre meilleur modèle. Cela suggère qu’avoir le patient en tant que point de départ du recrutement pourrait être réalisable. Nos scripts ainsi que nos jeux de données sont disponibles sur Github et HuggingFace(Aguiar et al. , 2025).</abstract>
      <url hash="7ec04e16">2025.jeptalnrecital-trad.18</url>
      <language>fra</language>
      <bibkey>aguiar-etal-2025-inference</bibkey>
    </paper>
    <paper id="19">
      <title>La structure du contenu textuel a-t-elle un impact sur les modèles linguistiques pour le résumé automatique ?</title>
      <author><first>Eve</first><last>Sauvage</last></author>
      <author><first>Sabrina</first><last>Campano</last></author>
      <author><first>Lydia</first><last>Ould-Ouali</last></author>
      <author><first>Cyril</first><last>Grouin</last></author>
      <pages>36–36</pages>
      <abstract>Le traitement de séquences longues par des modèles de langues reste un sujet à part entière, y compris pour le résumé automatique, malgré des améliorations récentes. Dans ce travail, nous présentons des expériences de résumé automatique d’articles scientifiques à l’aide de modèles BART, prenant en compte les informations textuelles provenant de passages distincts des textes à résumer. Nous démontrons que la prise en compte de la structure du document améliore les performances des modèles et se rapproche des performances de LongFormer en anglais.</abstract>
      <url hash="614a6047">2025.jeptalnrecital-trad.19</url>
      <language>fra</language>
      <bibkey>sauvage-etal-2025-la</bibkey>
    </paper>
    <paper id="20">
      <title>Lost In Variation : extraction non-supervisée de motifs lexico-syntaxiques dans des textes en moyen arabe</title>
      <author><first>Julien</first><last>Bezançon</last></author>
      <author><first>Rimane</first><last>Karam</last></author>
      <author><first>Gaël</first><last>Lejeune</last></author>
      <pages>37–50</pages>
      <abstract>Contrairement à l’arabe standard moderne ou à certains dialectes de l’arabe, le moyen arabe a peu été étudié en TAL. Pourtant, cette famille de variétés présente un défi majeur : elle mêle des traits de standard et des traits de dialecte en plus de posséder des caractéristiques qui lui sont propres. Nous présentons ici une méthode pour identifier, extraire et classer les variantes de 13 formules du moyen arabe, relevées manuellement. Ces formules proviennent des neuf premiers tomes du corpus SIRAT AL-MALIK AL-ZAHIR BAYBARS, un corpus de littérature populaire rédigé dans une variété de moyen arabe proche du dialecte damascène. Nous classons 20 386 séquences en se fondant sur leur similarité à plusieurs niveaux avec les formules étudiées. Ce classement nous permet d’observer que ces formules varient sur les plans lexical, morphologique et graphique tout en restant strictement invariables sémantiquement et syntaxiquement.</abstract>
      <url hash="859e08e1">2025.jeptalnrecital-trad.20</url>
      <language>fra</language>
      <bibkey>bezancon-etal-2025-lost-variation</bibkey>
    </paper>
    <paper id="21">
      <title><fixed-case>N</fixed-case>u<fixed-case>NER</fixed-case> : Pré-entraînement d’un encodeur pour la reconnaissance d’entités nommées avec des données annotées automatiquement</title>
      <author><first>Sergei</first><last>Bogdanov</last></author>
      <author><first>Alexandre</first><last>Constantin</last></author>
      <author><first>Timothée</first><last>Bernard</last></author>
      <author><first>Benoît</first><last>Crabbé</last></author>
      <author><first>Étienne</first><last>Bernard</last></author>
      <pages>51–52</pages>
      <abstract>Les grands modèles de langues (ou LLM, pour « large language models ») peuvent s’avérer très efficaces pour l’annotation de données, ouvrant la voie à de nouvelles approches pour développer des systèmes de traitement automatique des langues par apprentissage automatique. Dans cet article, nous détaillons l’utilisation d’un LLM dans le développement de NuNER, un modèle d’encodage du texte, compact et spécialisé dans la tâche de reconnaissance des entités nommées (ou NER, pour « named entity recognition »). NuNER fait ainsi partie de la famille des modèles de fondation spécialisés. L’intérêt de NuNER est qu’il ne nécessite que très peu de données d’affinage pour obtenir un système de NER performant, quel que soit le domaine cible. Nous montrons qu’en régime d’apprentissage avec peu d’exemples (« few-shot learning »), NuNER surpasse les principaux modèles de fondation de taille comparable et a des performances similaires à celles de modèles de bien plus grande taille. Nos expériences montrent que la taille du jeu de pré-entraînement mais aussi la diversité des types d’entités qui y occurrent jouent un rôle essentiel dans ces résultats. NuNER et l’ensemble de ses données d’entraînement sont disponibles sous licence libre MIT.</abstract>
      <url hash="0d0e0244">2025.jeptalnrecital-trad.21</url>
      <language>fra</language>
      <bibkey>bogdanov-etal-2025-nuner</bibkey>
    </paper>
    <paper id="22">
      <title><fixed-case>P</fixed-case>atient<fixed-case>D</fixed-case>x : Fusion des grands modèles de langue pour la protection de la confidentialité des données dans le domaine de la santé</title>
      <author><first>Jose</first><last>G. Moreno</last></author>
      <author><first>Jesús</first><last>Lovón-Melgarejo</last></author>
      <author><first>M’Rick</first><last>Robin-Charlet</last></author>
      <author><first/><last>Christine-Damase-Michel</last></author>
      <author><first>Lynda</first><last>Tamine</last></author>
      <pages>53–54</pages>
      <abstract>L’affinage des grands modèles de langue (abrégé LLM de l’anglais large language model) est devenu la pratique courante pour améliorer la performance des modèles sur une tâche donnée. Cependant, cette amélioration de performance s’accompagne d’un coût : l’entraînement sur de vastes quantités de données annotées potentiellement sensibles, ce qui soulève d’importantes préoccupations en matière de confidentialité des données. Le domaine de la santé constitue l’un des domaines les plus sensibles exposés aux problèmes de confidentialité des données. Dans cet article, nous présentons “PatientDx”, une architecture de fusion de modèles permettant de concevoir des LLM efficaces pour les tâches prédictives en santé sans nécessiter d’affinage ni d’adaptation sur les données des patients. Notre proposition repose sur des techniques récemment proposées connues sous le nom de fusion de LLM et vise à optimiser une stratégie de fusion modulaire. “PatientDx” utilise un modèle pivot adapté au raisonnement numérique et ajuste les hyperparamètres sur des exemples en fonction d’une métrique de performance, mais sans entraîner le LLM sur ces données. Les expériences utilisant les tâches de prédiction de mortalité de l’ensemble de données MIMIC-IV montrent des améliorations jusqu’à 7% en termes d’AUROC par rapport aux modèles initiaux. De plus, nous confirmons que, comparée aux modèles affinés, notre proposition est moins sujette aux problèmes de fuite de données sans nuire à la performance. Enfin, nous démontrons qualitativement les capacités de notre proposition à travers une étude de cas. Notre meilleur modèle est publiquement disponible : https://huggingface.co/Jgmorenof/mistral

_merged

_0

_4. Ceci est le résumé de l’article publié “PatientDx : Merging Large Language Models for Protecting Data-Privacy in Healthcare” dans l’atelier CL4Health, NAACL 2025 (Moreno et al., 2025).</abstract>
      <url hash="bedb3854">2025.jeptalnrecital-trad.22</url>
      <language>fra</language>
      <bibkey>g-moreno-etal-2025-patientdx</bibkey>
    </paper>
    <paper id="23">
      <title>Représenter le style au-delà des thématiques : une étude d’impact sur la dispersion vectorielle de différents modèles de langage</title>
      <author><first>Benjamin</first><last>Icard</last></author>
      <author><first>Evangelia</first><last>Zve</last></author>
      <author><first>Lila</first><last>Sainero</last></author>
      <author><first>Alice</first><last>Breton</last></author>
      <author><first>Jean-Gabriel</first><last>Ganascia</last></author>
      <pages>55–56</pages>
      <abstract>Cet article vise à étudier comment le style d’écriture influence la dispersion des plongements vectoriels de divers grands modèles de langage. Alors que les premiers modèles de type transformeur étaient prin- cipalement axés sur la modélisation thématique, cette étude examine le rôle du style d’écriture dans la configuration de l’espace vectoriel. À partir d’un corpus littéraire faisant varier thématiques et styles, nous comparons la sensibilité des modèles de langage en français et en anglais. En analysant ainsi l’impact spécifique du style sur la dispersion vectorielle, nous cherchons à mieux comprendre com- ment les modèles de langage traitent l’information stylistique, contribuant ainsi à leur interprétabilité globale. Ceci est un résumé de l’article “Embedding Style Beyond Topics: Analyzing Dispersion Effects Across Different Language Models” publié dans les actes de la conférence COLING 2025 (Icard et al., 2025) et accessible à l’URL : https://aclanthology.org/2025.coling-main.236/.</abstract>
      <url hash="ce20f9ec">2025.jeptalnrecital-trad.23</url>
      <language>fra</language>
      <bibkey>icard-etal-2025-representer</bibkey>
    </paper>
    <paper id="24">
      <title><fixed-case>SCOPE</fixed-case> : un cadre d’entrainement auto-supervisé pour améliorer la fidélité dans la génération conditionnelle de texte</title>
      <author><first>Song</first><last>Duong</last></author>
      <author><first>Florian</first><last>Le Bronnec</last></author>
      <author><first>Alexandre</first><last>Allauzen</last></author>
      <author><first>Vincent</first><last>Guigue</last></author>
      <author><first>Alberto</first><last>Lumbreras</last></author>
      <author><first>Laure</first><last>Soulier</last></author>
      <author><first>Patrick</first><last>Gallinari</last></author>
      <pages>57–57</pages>
      <abstract>Les modèles de langage (LLM) produisent souvent des hallucinations lors de la génération conditionnelle de texte, introduisant des informations non fidèles ou non ancrées dans le contexte. Ce phénomène est particulièrement problématique en résumé automatique et en génération texte-à-partirde-données, où les sorties doivent refléter précisément l’entrée. Nous proposons SCOPE, une méthode auto-supervisée innovante générant automatiquement des exemples non fidèles plausibles pour affiner les modèles par apprentissage par préférences. SCOPE pousse ainsi les modèles à préférer les sorties fidèles. Nous évaluons notre approche sur divers jeux de données de génération texte-à-partirde-données et de résumé. Simple à implémenter, notre méthode nettement les alternatives existantes selon des métriques automatiques et des évaluations humaines ainsi qu’avec GPT-4.</abstract>
      <url hash="36acd483">2025.jeptalnrecital-trad.24</url>
      <language>fra</language>
      <bibkey>duong-etal-2025-scope</bibkey>
    </paper>
    <paper id="25">
      <title><fixed-case>SELEXINI</fixed-case> – un grand corpus français, divers et parsé automatiquement</title>
      <author><first>Manon</first><last>Scholivet</last></author>
      <author><first>Agata</first><last>Savary</last></author>
      <author><first>Louis</first><last>Estève</last></author>
      <author><first>Marie</first><last>Candito</last></author>
      <author><first>Carlos</first><last>Ramisch</last></author>
      <pages>58–58</pages>
      <abstract>L’annotation de grands corpus de texte est essentielle pour de nombreuses tâches de Traitement Automatique des Langues. Dans cet article, nous présentons SELEXINI, un grand corpus français annoté automatiquement en syntaxe. Ce corpus est composé de deux parties : la partie BigScience, et la partie HPLT. Les documents de la partie HPLT ont été sélectionnés dans le but de maximiser la diversité lexicale du corpus total SELEXINI. Une analyse de l’impact de cette sélection sur la diversité syntaxique a été réalisée, ainsi qu’une étude de la qualité des nouveaux mots issus de la partie HPLT du corpus SELEXINI. Nous avons pu montrer que malgré l’introduction de nouveaux mots considérés comme intéressants (formes de conjugaison rares, néologismes, mots rares,...), les textes issus de HPLT sont extrêmement bruités. De plus, l’augmentation de la diversité lexicale n’a pas permis d’augmenter la diversité syntaxique.</abstract>
      <url hash="cb3468e2">2025.jeptalnrecital-trad.25</url>
      <language>fra</language>
      <bibkey>scholivet-etal-2025-selexini-un</bibkey>
    </paper>
    <paper id="26">
      <title>Sondage des Modèles de Langue sur leur Source de Connaissance</title>
      <author><first>Zineddine</first><last>Tighidet</last></author>
      <author><first>Andrea</first><last>Mogini</last></author>
      <author><first>Jiali</first><last>Mei</last></author>
      <author><first>Patrick</first><last>Gallinari</last></author>
      <author><first>Benjamin</first><last>Piwowarski</last></author>
      <pages>59–60</pages>
      <abstract>Les grands modèles de langue (GML) sont souvent confrontés à des conflits entre leurs connaissance interne (connaissance paramétrique, CP) et la connaissance externe fournie pendant l’inférence (connaissance contextuelle, CC). Comprendre comment les GML priorisent une source de connaissance par rapport à l’autre reste un défi. Dans cet article, nous proposons un nouveau cadre de sondage pour explorer les mécanismes régissant la sélection entre CP et CC dans les GML. En utilisant des prompts contrôlées conçues pour contredire la CP du modèle, nous démontrons que des activations spécifiques du modèle sont indicatives de la source de connaissance employée. Nous évaluons ce cadre sur divers GML de différentes tailles et démontrons que les activations des couches intermédiaires, en particulier celles liées aux relations dans l’entrée, sont cruciales pour prédire la sélection de la source de connaissances, ouvrant la voie à des modèles plus fiables capables de gérer efficacement les conflits de connaissances.</abstract>
      <url hash="fc2a652b">2025.jeptalnrecital-trad.26</url>
      <language>fra</language>
      <bibkey>tighidet-etal-2025-sondage</bibkey>
    </paper>
    <paper id="27">
      <title>Vers les Sens et Au-delà : Induire des Concepts Sémantiques Avec des Modèles de Langue Contextuels</title>
      <author><first>Bastien</first><last>Liétard</last></author>
      <author><first>Pascal</first><last>Denis</last></author>
      <author><first>Mikaela</first><last>Keller</last></author>
      <pages>61–61</pages>
      <abstract>La polysémie et la synonymie sont deux facettes cruciales et interdépendantes de l’ambiguïté lexicosémantique, mais elles sont souvent considérées indépendamment dans les problèmes pratiques en TAL. Dans cet article, nous introduisons l’induction de concepts, une tâche non-supervisée consistant à apprendre un partitionnement diffus de mots définissant un ensemble de concepts directement à partir de données. Cette tâche généralise l’induction du sens des mots (via l’appartenance d’un mot à de multiples groupes). Nous proposons une approche à deux niveaux pour l’induction de concepts, avec une vue centrée sur les lemmes et une vue globale du lexique. Nous évaluons le regroupement obtenu sur les données annotées de SemCor et obtenons de bonnes performances (BCubed-F1 supérieur à 0,60). Nous constatons que les deux niveaux sont mutuellement bénéfiques pour induire les concepts et les sens. Enfin, nous créons des plongements dits « statiques » représentant nos concepts induits et obtenons des performances compétitives par rapport à l’état de l’art en Word-in-Context.</abstract>
      <url hash="198584a2">2025.jeptalnrecital-trad.27</url>
      <language>fra</language>
      <bibkey>lietard-etal-2025-vers</bibkey>
    </paper>
  </volume>
  <volume id="industrielle" ingest-date="2025-09-28" type="proceedings">
    <meta>
      <booktitle>Actes de la session industrielle de CORIA-TALN 2025</booktitle>
      <editor><first>Frédéric</first><last>Bechet</last></editor>
      <editor><first>Adrian-Gabriel</first><last>Chifu</last></editor>
      <editor><first>Karen</first><last>Pinel-sauvagnat</last></editor>
      <editor><first>Benoit</first><last>Favre</last></editor>
      <editor><first>Eliot</first><last>Maes</last></editor>
      <editor><first>Diana</first><last>Nurbakova</last></editor>
      <publisher>ATALA \\&amp; ARIA</publisher>
      <address>Marseille, France</address>
      <month>6</month>
      <year>2025</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="5c962301">2025.jeptalnrecital-industrielle.0</url>
      <bibkey>jep-taln-recital-2025-industrielle</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Apprentissage Actif à l’ère des Grands Modèles de Langue (<fixed-case>LLM</fixed-case>s)</title>
      <author><first>Shami</first><last>Thirion Sen</last></author>
      <author><first>Rime</first><last>Abrougui</last></author>
      <author><first>Guillaume</first><last>Lechien</last></author>
      <author><first>Damien</first><last>Nouvel</last></author>
      <pages>1–16</pages>
      <abstract>En TAL, la performance des modèles dépend fortement de la qualité et de la quantité des données annotées. Lorsque ces ressources sont limitées, l’apprentissage actif (Active Learning) offre une solution efficace en sélectionnant les échantillons les plus pertinents à annoter. Traditionnellement, cette tâche est réalisée par des annotateurs humains, mais nous explorons ici le potentiel du grand modèle de langue Mixtral-8x7B pour générer automatiquement ces annotations. Nous analysons l’influence de l’augmentation des données dans un processus d’apprentissage actif pour la reconnaissance d’entités nommées, ainsi que l’impact du prompt et des hyper-paramètres sur la qualité des annotations. Les évaluations conduites sur le corpus WiNER montrent que, malgré l’absence d’annotations manuelles, cette approche permet d’obtenir des performances comparables à notre baseline, tout en réduisant de 80 % la quantité des données.</abstract>
      <url hash="9ae84942">2025.jeptalnrecital-industrielle.1</url>
      <language>fra</language>
      <bibkey>thirion-sen-etal-2025-apprentissage</bibkey>
    </paper>
    <paper id="2">
      <title>Backtesting des signaux de sentiment pour le trading : évaluer la viabilité de la génération d’alpha à partir de l’analyse de sentiment</title>
      <author><first>Elvys</first><last>Linhares Pontes</last></author>
      <author><first>Carlos-Emiliano</first><last>González-Gallardo</last></author>
      <author><first>Georgeta</first><last>Bordea</last></author>
      <author><first>Jose</first><last>G Moreno</last></author>
      <author><first>Mohamed</first><last>Ben Jannet</last></author>
      <author><first>Yuxuan</first><last>Zhao</last></author>
      <author><first>Antoine</first><last>Doucet</last></author>
      <pages>17–32</pages>
      <abstract>L’analyse de sentiment, largement utilisée dans les avis de produits, influence également les marchés financiers en affectant les prix des actifs à travers les microblogs et les articles de presse. Bien que la recherche sur la finance basée sur le sentiment soit abondante, de nombreuses études se concentrent sur la classification au niveau des phrases, négligeant son application pratique dans le trading. Cette étude comble cette lacune en évaluant des stratégies de trading basées sur le sentiment pour générer un alpha positif. Nous réalisons une analyse de backtesting en utilisant des prédictions de sentiment de trois modèles (deux basés sur la classification et un basé sur la régression) appliqués aux articles de presse concernant les actions du Dow Jones 30, en les comparant à la stgonzalezgallardo@univtours.frratégie de référence Buy&amp;Hold. Les résultats montrent que tous les modèles ont généré des rendements positifs, le modèle de régression enregistrant le rendement le plus élevé de 50,63% sur 28 mois, surpassant ainsi la stratégie Buy&amp;Hold. Cela souligne le potentiel de l’analyse de sentiment pour affiner les stratégies d’investissement et améliorer la prise de décisions financières.</abstract>
      <url hash="af42e220">2025.jeptalnrecital-industrielle.2</url>
      <language>fra</language>
      <bibkey>linhares-pontes-etal-2025-backtesting</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>COL</fixed-case>a<fixed-case>F</fixed-case> : Corpus et Outils pour les Langues de <fixed-case>F</fixed-case>rance et variétés de français</title>
      <author><first>Benoît</first><last>Sagot</last></author>
      <author><first>Slim</first><last>Ouni</last></author>
      <author><first>Sam</first><last>Bigeard</last></author>
      <author><first>Lucence</first><last>Ing</last></author>
      <author><first>Thibault</first><last>Clérice</last></author>
      <author><first>Rachel</first><last>Bawden</last></author>
      <author><first>Emmanuel</first><last>Vincent</last></author>
      <author><first>Malek</first><last>Yaich</last></author>
      <author><first>Panagiotis</first><last>Tsolakis</last></author>
      <author><first>Juliette</first><last>Janès</last></author>
      <author><first>Rasul</first><last>Dent</last></author>
      <author><first>Oriane</first><last>Nédey</last></author>
      <author><first>Vincent</first><last>Colotte</last></author>
      <author><first>Mostafa</first><last>Sadeghi</last></author>
      <pages>33–47</pages>
      <abstract>Nous présentons COLaF, un projet dédié à la collecte et au développement d’outils et de ressources de traitement automatique des langues (TAL) pour le français et les autres langues de France, avec une attention particulière sur les langues et variétés moins dotées. Le projet concerne les données textuelles, audio et vidéo, afin de fournir des corpus et des outils pour le langage écrit, parlé et signé. Le projet inclut la collecte, la normalisation et la documentation de données préexistantes, y compris des données actuellement non accessibles ou non exploitables à des fins de recherche, ainsi que le développement d’outils de TAL adaptés à ces langues, comme des outils pour l’annotation linguistique et pour la traduction automatique. Cet article permet la présentation des principaux défis posés par le projet et de premiers résultats.</abstract>
      <url hash="0aca8696">2025.jeptalnrecital-industrielle.3</url>
      <language>fra</language>
      <bibkey>sagot-etal-2025-colaf</bibkey>
    </paper>
    <paper id="4">
      <title>Les modèles multimodaux peuvent-ils aider à l’interprétation de cartes ? Une étude exploratoire avec <fixed-case>GPT</fixed-case>-4o</title>
      <author><first>Edith</first><last>Galy</last></author>
      <author><first>Ahmed</first><last>Moubtahij</last></author>
      <author><first>Azur</first><last>Handan</last></author>
      <author><first>Marc</first><last>Queudot</last></author>
      <pages>48–58</pages>
      <abstract>Cet article explore l’utilisation des modèles de langage multimodaux, en particulier GPT-4o, pour l’interprétation automatisée de cartes de risque d’inondation. Un prototype a été développé afin de permettre à des utilisateurs non-experts de poser des questions en langage naturel et d’obtenir des réponses ancrées sur des données géospatiales visuelles. Un jeu de données ad hoc a été constitué pour évaluer la capacité du modèle à répondre à des questions fermées, selon différentes stratégies de génération. Malgré certaines améliorations grâce à l’usage de schémas de génération structurée et de raisonnements intermédiaires, les résultats révèlent une forte tendance aux hallucinations et des performances insuffisantes pour une application en contexte critique. Cette étude met en évidence les limites actuelles des modèles multimodaux pour l’analyse cartographique, et souligne la nécessité de recherches fondamentales et de corpus plus étendus pour fiabiliser ces approches.</abstract>
      <url hash="e40c8b0f">2025.jeptalnrecital-industrielle.4</url>
      <language>fra</language>
      <bibkey>galy-etal-2025-les</bibkey>
    </paper>
    <paper id="5">
      <title><fixed-case>SIMI</fixed-case> v3 : Une liste de cas patients similaires pour la télé expertise médicale</title>
      <author><first>Pierre</first><last>Jourlin</last></author>
      <author><first>Marc-Antoine</first><last>Sulmon</last></author>
      <author><first>David</first><last>Bensoussan</last></author>
      <author><first>Émilie</first><last>Mercadal</last></author>
      <pages>59–68</pages>
      <abstract>Cet article présente SIMI v3, une brique logicielle hybridant deux approches d’IA, l’une symbolique et l’autre connexionniste intégrée dans la plateforme web ROFIM, une solution de télé-expertise, e−RCP et téléconsultation médicale. Lors d’une télé-expertise, SIMI v3 permet de rechercher automatiquement des cas patients issus de la littérature scientifique, similaires à celui décrit par le requérant. Une fois cette recherche documentaire accomplie, il propose au médecin requis de les consulter avant de produire son expertise. Ce logiciel, dont les aspect fondamentaux ont été développés au Laboratoire d’Informatique d’Avignon et qui a fait l’objet d’un programme de transfert technologique soutenu par la SATT Sud-Est est aujourd’hui en phase de déploiement sur la plateforme. Nous espérons qu’il permette en définitive de réduire l’errance diagnostique, de raccourcir les échanges entre médecin requérant et médecin requis et d’alerter ce dernier sur la possible existence de maladies rares dont les symptômes pourraient être confondus avec ceux de pathologies plus courantes.</abstract>
      <url hash="7dbd30d3">2025.jeptalnrecital-industrielle.5</url>
      <language>fra</language>
      <bibkey>jourlin-etal-2025-simi</bibkey>
    </paper>
    <paper id="6">
      <title><fixed-case>SPARK</fixed-case> : Exploiter les échanges techniques passés pour améliorer le support client</title>
      <author><first>Steve</first><last>Bellart</last></author>
      <author><first>Arnaud</first><last>Deleruyelle</last></author>
      <pages>69–81</pages>
      <abstract>S.P.A.R.K. (SAP Process Augmented Response Knowledge) est un projet qui vise à concevoir une architecture de génération augmentée par récupération (RAG) adaptée aux dialogues techniques issus de requêtes clients. L’objectif est d’améliorer l’efficacité des consultants SAP dans la résolution des demandes clients en exploitant les connaissances contenues dans des échanges antérieurs similaires. Chaque ticket résolu contient un dialogue entre un client décrivant un problème et un consultant proposant une solution technique détaillée. L’accès rapide à ces solutions déjà éprouvées constitue un atout majeur. Cet article aborde les défis spécifiques liés à l’exploitation des données conversationnelles techniques, présente les solutions proposées pour optimiser la récupération et la génération de réponses pertinentes, et traite des perspectives futures du projet.</abstract>
      <url hash="8705f5c2">2025.jeptalnrecital-industrielle.6</url>
      <language>fra</language>
      <bibkey>bellart-deleruyelle-2025-spark</bibkey>
    </paper>
  </volume>
  <volume id="coria" ingest-date="2025-09-28" type="proceedings">
    <meta>
      <booktitle>Actes de la 20e Conférence en Recherche d’Information et Applications (CORIA)</booktitle>
      <editor><first>Frédéric</first><last>Bechet</last></editor>
      <editor><first>Adrian-Gabriel</first><last>Chifu</last></editor>
      <editor><first>Karen</first><last>Pinel-sauvagnat</last></editor>
      <editor><first>Benoit</first><last>Favre</last></editor>
      <editor><first>Eliot</first><last>Maes</last></editor>
      <editor><first>Diana</first><last>Nurbakova</last></editor>
      <publisher>ATALA \\&amp; ARIA</publisher>
      <address>Marseille, France</address>
      <month>6</month>
      <year>2025</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="af1ee363">2025.jeptalnrecital-coria.0</url>
      <bibkey>jep-taln-recital-2025-coria</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Analyse Textuelle et Extraction Géospatiale pour la Surveillance des Crises Alimentaires en Afrique de l’Ouest</title>
      <author><first>Charles</first><last>Abdoulaye Ngom</last></author>
      <author><first>Maguelonne</first><last>Teisseire</last></author>
      <author><first>Sarah</first><last>Valentin</last></author>
      <pages>1–10</pages>
      <abstract>L’Afrique de l’Ouest fait face à une insécurité alimentaire récurrente, exacerbée par les conflits, le changement climatique et les chocs économiques. La collecte d’informations à une échelle spatiotemporelle appropriée est essentielle au suivi des crises liées à la sécurité alimentaire. Dans ce travail, nous nous intéressons à l’extraction géospatiale à partir de données textuelles, tâche qui s’inscrit dans une approche globale de suivi des crises alimentaires à partir d’articles de presse. Nous évaluons deux modèles d’extraction d’entités spatiales, GLiNER et CamemBERT, en configuration zéro-shot et après ajustement ( fine-tuning ), sur un corpus de 15 000 articles de presse en français couvrant l’actualité du Burkina Faso.</abstract>
      <url hash="46c8477d">2025.jeptalnrecital-coria.1</url>
      <language>fra</language>
      <bibkey>abdoulaye-ngom-etal-2025-analyse</bibkey>
    </paper>
    <paper id="2">
      <title>Application de Transformers multimodaux à l’extraction d’informations des documents de sondage des sols</title>
      <author><first>Stanislas</first><last>Bagnol</last></author>
      <author><first>Killian</first><last>Barrere</last></author>
      <author><first>Véronique</first><last>Eglin</last></author>
      <author><first>Elöd</first><last>Egyed-Zsigmond</last></author>
      <author><first>Jean-Marie</first><last>Côme</last></author>
      <author><first>David</first><last>Pitaval</last></author>
      <pages>11–20</pages>
      <abstract>L’extraction d’information de documents complexes est un domaine de recherche qui bénéficie d’une très grande attention tant dans la littérature, que dans l’industrie dans le cadre de la digitalisation des données. Les Transformers et leurs adaptations ont très largement contribué à faire progresser cette recherche en s’appuyant sur des modèles de langue qui ont introduit une compréhension sémantique de l’organisation de la structure des documents. Les coupes de sondage sont des documents industriels complexes et riches en informations, pour lesquels aucune solution d’extraction d’informations n’avait été proposée. Nous montrons les limites des approches de bout-en-bout par des expérimentations avec le modèle DONUT. Comme alternative, nous proposons une chaîne de traitement hybride reposant sur le fine-tuning de Transformers multimodaux et des algorithmes heuristiques. Nous comparons deux architectures de Transformers multimodaux pré-entrainés : BROS et LayoutLMv3.</abstract>
      <url hash="5e099ac7">2025.jeptalnrecital-coria.2</url>
      <language>fra</language>
      <bibkey>bagnol-etal-2025-application</bibkey>
    </paper>
    <paper id="3">
      <title>Approche méthodologique pour la génération de question-réponse portant sur plusieurs documents</title>
      <author><first>Hui</first><last>Huang</last></author>
      <author><first>Julien</first><last>Velcin</last></author>
      <author><first>Yacine</first><last>Kessaci</last></author>
      <pages>21–30</pages>
      <abstract>Les systèmes de questions-réponses (QA) actuels ont du mal à synthétiser les preuves dispersées dans les documents. Alors que les jeux de données QA scientifiques existants se concentrent sur le raisonnement portant sur un document seul, la tâche de recherche peut exiger l’intégration de contenus provenant de plusieurs articles. Pour répondre à cette limitation, nous proposons un cadre pour créer un jeu de données QA multi-documents qui s’appuie sur l’analyse de graphes de citations afin de regrouper des articles connexes et utilise un grand modèle de langage (LLM) pour générer des questions complexes. Des expériences préliminaires réalisées sur 23 882 articles démontrent la faisabilité de ce cadre, produisant 238 paires QA qui nécessitent une synthèse sur plusieurs articles. D’autres expériences indiquent que la recherche d’information dense actuelle obtient un rappel limité pour ces questions multi-documents, soulignant le besoin de mécanismes de recherche d’information et de raisonnement plus avancés. Il s’agit d’un projet en cours d’élaboration. Nous visons à terme à fournir un jeu de données QA robuste qui capture la complexité et la nature interconnectée des publications scientifiques, ouvrant la voie à des évaluations plus réalistes des systèmes de QA.</abstract>
      <url hash="396ada15">2025.jeptalnrecital-coria.3</url>
      <language>fra</language>
      <bibkey>huang-etal-2025-approche</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>A</fixed-case>uto<fixed-case>C</fixed-case>luster: Un agent pour le clustering basé sur les grands modèles de langue</title>
      <author><first>Erwan</first><last>Versmée</last></author>
      <author><first>Youcef</first><last>Remil</last></author>
      <author><first>Mehdi</first><last>Kaytoue</last></author>
      <author><first>Julien</first><last>Velcin</last></author>
      <pages>31–49</pages>
      <abstract>Cette recherche présente AutoCluster, un agent basé sur les grands modèles de langue pour des tâches de classification non supervisée. Nous concevons trois agents dont deux sont basés sur la littérature et l’un, AutoCluster, est une contribution originale. Une analyse détaillée de leur performance sur 26 jeux de données de clustering révèle la supériorité de notre agent par rapport aux solutions de l’état de l’art. Enfin, nous justifions l’efficacité de notre agent à travers les nombreuses améliorations empiriques apportées au fur et à mesure de son développement.</abstract>
      <url hash="2bf20772">2025.jeptalnrecital-coria.4</url>
      <language>fra</language>
      <bibkey>versmee-etal-2025-autocluster</bibkey>
    </paper>
    <paper id="5">
      <title>Cadre d’évaluation pour les systèmes de génération augmentée (<fixed-case>RAG</fixed-case>) : combinaison des performances de recherche d’informations et de <fixed-case>LLM</fixed-case></title>
      <author><first>Mohamed-Amine</first><last>El-Yagouby</last></author>
      <author><first>Philippe</first><last>Mulhem</last></author>
      <author><first>Jean-Pierre</first><last>Chevallet</last></author>
      <author><first>Eric</first><last>Gaussier</last></author>
      <pages>50–60</pages>
      <abstract>Cet article introduit un nouveau cadre d’évaluation pour les systèmes RAG, en comblant les lacunes des approches précédentes. La première phase consiste à concevoir un ensemble de données avec des parties pertinentes extraites pour chaque exemple, représentant les informations nécessaires pour répondre à une question donnée, et à proposer une métrique d’évaluation pour les systèmes IR basée sur la présence de ces parties dans le contenu récupéré. La deuxième phase explore la relation entre le système de RI et les évaluations RAG globales et utilise cette relation pour prédire les performances globales du RAG à partir des performances du SRI. Cette approche élimine le besoin de réponses coûteuses générées par LLM et d’évaluations ultérieures, réduisant ainsi les coûts et fournissant un cadre d’évaluation plus complet et plus robuste pour les systèmes RAG.</abstract>
      <url hash="b7746ad1">2025.jeptalnrecital-coria.5</url>
      <language>fra</language>
      <bibkey>el-yagouby-etal-2025-cadre</bibkey>
    </paper>
    <paper id="6">
      <title>Clarification des Ambiguïtés : Sur le Rôle des Types d’Ambiguïté dans les Méthodes d’Amorçage pour la Génération de Clarifications</title>
      <author><first>Anfu</first><last>Tang</last></author>
      <author><first>Laure</first><last>Soulier</last></author>
      <author><first>Vincent</first><last>Guigue</last></author>
      <pages>61–81</pages>
      <abstract>En recherche d’information (RI), il est essentiel de fournir des clarifications appropriées pour concevoir un système de dialogue proactif et guider l’utilisateur. Grâce au développement des grands modèles de langage (LLMs), des études récentes explorent des méthodes d’amorçage pour générer des clarifications à l’aide de chaîne de raisonnement (Chain of Thought, CoT). Cependant, l’amorçage CoT ne permet pas de distinguer les caractéristiques des différents besoins en information, impactant la résolution des ambiguïtés. Dans ce travail, nous cherchons à modéliser et intégrer les ambiguïtés liées au besoin en information dans le processus de génération de clarifications. Nous étudions l’impact des schémas d’amorçage en proposant Ambiguity Type-Chain of Thought (AT-CoT), qui impose à CoT de prédire d’abord les types d’ambiguïté, puis de générer les clarifications correspondantes. Des expériences sont menées sur divers jeux de données afin de comparer AT-CoT à plusieurs modèles de référence. Nous réalisons également des simulations utilisateur pour une évaluation extrinsèque.</abstract>
      <url hash="badbd7bc">2025.jeptalnrecital-coria.6</url>
      <language>fra</language>
      <bibkey>tang-etal-2025-clarification</bibkey>
    </paper>
    <paper id="7">
      <title>Clustering de résumés <fixed-case>LLM</fixed-case> guidés par l’utilisateur : vers une approche constructiviste et réaliste unifiée</title>
      <author><first>Carl</first><last>Hatoum</last></author>
      <author><first>Catherine</first><last>Combes</last></author>
      <author><first>Virginie</first><last>Fresse</last></author>
      <author><first>Christophe</first><last>Gravier</last></author>
      <author><first>Mathieu</first><last>Orzalesi</last></author>
      <pages>82–95</pages>
      <abstract>Nous introduisons un cadre hybride combinant grands modèles de langage et techniques de regroupement pour extraire, résumer, évaluer et structurer automatiquement les connaissances de larges collections textuelles. Après avoir sélectionné, via une métrique d’entropie sémantique, la stratégie de prompt la plus stable, un LLM génère des résumés modulables qui font l’objet d’une évaluation factuelle assurant leur fiabilité. Ces résumés validés sont ensuite vectorisés, projetés en basse dimension et regroupés en thématiques. Optionnellement, un second LLM affine ensuite leurs libellés pour renforcer l’interprétabilité. Expérimentée sur un corpus majeur d’incidents aériens, cette approche augmente la cohérence et la granularité des clusters thématiques par rapport à une analyse directe des textes, ouvrant de nouvelles perspectives pour la recherche d’information et l’exploration de bases documentaires.</abstract>
      <url hash="42f3ad10">2025.jeptalnrecital-coria.7</url>
      <language>fra</language>
      <bibkey>hatoum-etal-2025-clustering</bibkey>
    </paper>
    <paper id="8">
      <title>Comprendre la Nature des Signaux de Correspondance dans les Modèles Neuronaux pour la <fixed-case>RI</fixed-case></title>
      <author><first>Mathias</first><last>Vast</last></author>
      <author><first>Basile</first><last>Van Cooten</last></author>
      <author><first>Laure</first><last>Soulier</last></author>
      <author><first>Benjamin</first><last>Piwowarski</last></author>
      <pages>96–106</pages>
      <abstract>Les architectures de recherche d’information (RI) neuronale, en particulier celles basées sur l’interaction, sont des modèles très performants dont les mécanismes restent largement méconnus. La plupart des travaux visant à expliquer leur comportement se sont attachés à décrire des processus en surface (par exemple, quels éléments de l’entrée influencent la prédiction ? le modèle respecte t-il les axiomes connus de la RI ?) mais ne décrivent pas précisément le processus d’appariement. Dans cet article, nous apportons un nouvel éclairage sur le mécanisme de correspondance en analysant le processus d’attention, et en mettant en évidence le rôle crucial de certaines têtes d’attention ainsi que la nature des signaux qui sont manipulés.</abstract>
      <url hash="127037b1">2025.jeptalnrecital-coria.8</url>
      <language>fra</language>
      <bibkey>vast-etal-2025-comprendre</bibkey>
    </paper>
    <paper id="9">
      <title>Entraînement avec solveur pour l’intégration de contraintes logiques dans l’extraction de relations d’événements</title>
      <author><first>Baptiste</first><last>Brunet de la Charie</last></author>
      <author><first>Abdallah</first><last>Arioua</last></author>
      <author><first>Elöd</first><last>Egyed-Zsigmond</last></author>
      <author><first>Thomas</first><last>Veran</last></author>
      <pages>107–125</pages>
      <abstract>L’extraction de relations d’événements (ERE) est une tâche cruciale dans le traitement du langage naturel, impliquant l’identification et la classification des relations sémantiques entre les événements décrits dans des documents textuels. Malgré les avancées récentes grâce aux approches d’extraction conjointe, les modèles actuels rencontrent encore des défis importants, notamment une précision in- suffisante dans l’extraction des relations sous-représentées mais essentielles (telles que la causalité) et d’importantes incohérences logiques parmi les relations prédites. Pour remédier à ces limitations, nous proposons un framework pour l’ERE, conçu explicitement pour améliorer la performance d’extraction et assurer la cohérence logique globale. Notre approche combine l’encodage de documents basé sur les transformateurs avec un solveur de contraintes logiques dédié qui corrige systématiquement les prédictions brutes pour garantir la cohérence dans toutes les relations d’événements extraites. Nous introduisons le concept de relations fondamentales, un sous-ensemble de relations essentielles pour préserver la cohérence logique, et nous utilisons une stratégie d’entraînement consciente du solveur afin de prioriser explicitement ces relations. Des expérimentations approfondies sur l’en- semble de données complet MAVEN-ERE démontrent que notre framework obtient pas une précision d’extraction supérieures par rapport aux méthodes d’extraction conjointe existantes.</abstract>
      <url hash="c2a0fd40">2025.jeptalnrecital-coria.9</url>
      <language>fra</language>
      <bibkey>brunet-de-la-charie-etal-2025-entrainement</bibkey>
    </paper>
    <paper id="10">
      <title>Évaluation des capacités des grands modèles de langue à comprendre les dossiers médicaux de patients : Une étude approfondie de l’extraction et la recherche de données des patients</title>
      <author><first>Jesús</first><last>Lovón-Melgarejo</last></author>
      <author><first>Martin</first><last>Mouysset</last></author>
      <author><first>Jo</first><last>Oleiwan</last></author>
      <author><first>Jose</first><last>G. Moreno</last></author>
      <author><first/><last>Christine-Damase-Michel</last></author>
      <author><first>Lynda</first><last>Tamine</last></author>
      <pages>126–127</pages>
      <abstract>Les dossiers médicaux de patients (DMP) posent des défis uniques, notamment la présence de dépendances contextuelles cachées entre les caractéristiques médicales avec un niveau élevé de dimensionnalité et de disparité des données. Ce papier présente la première étude sur les capacités des grands modèles de langague à comprendre les DMP en vue d’en extraire ou rechercher des données. Nous menons des expérimentations approfondies en utilisant l’ensemble de données MIMICSQL pour explorer l’impact de la structure des prompts , des instructions, du contexte et des démonstrations de deux grands modèles de langue, Llama2 et Meditron, sur la performance des tâches d’extraction et recherche d’information. À travers des analyses quantitatives et qualitatives, nos résultats montrent que les méthodes optimales de sélection et de sérialisation des dossiers de patients peuvent améliorer la performance des tâches jusqu’à 26,79% par rapport aux approches naïves. De même, les scénarios d’apprentissage en contexte avec sélection d’exemples pertinents améliorent la performance d’extraction de données de 5,95%. Sur la base des résultats de notre étude, nous proposons des lignes directrices destinées à faciliter la conception de modèles basés sur les grands modèles de langue pour supporter la recherche d’information en santé. Les jeux de données et le code sont disponibles. Ceci est le résumé de l’article “Evaluating LLM Abilities to Understand Tabular Electronic Health Records : A Comprehensive Study of Patient Data Extraction and Retrieval” publié comme papier long à ECIR 2025 (Lovón-Melgarejo et al., 2025).</abstract>
      <url hash="fb116503">2025.jeptalnrecital-coria.10</url>
      <language>fra</language>
      <bibkey>lovon-melgarejo-etal-2025-evaluation</bibkey>
    </paper>
    <paper id="11">
      <title>Génération augmentée de récupération multi-niveau pour répondre à des questions visuelles</title>
      <author><first>Omar</first><last>Adjali</last></author>
      <author><first>Olivier</first><last>Ferret</last></author>
      <author><first>Sahar</first><last>Ghannay</last></author>
      <author><first>Hervé</first><last>Le Borgne</last></author>
      <pages>128–130</pages>
      <abstract>La tâche de réponse à des questions visuelles à propos d’entités nommées, qui s’appuie sur la désambiguïsation des entités à l’aide d’informations textuelles et visuelles ainsi que de connaissances, se décompose principalement en deux étapes : recherche d’information puis recherche des réponses, souvent abordées indépendamment l’une de l’autre. La génération augmentée de récupération (RAG) offre une solution à ce manque d’interaction en utilisant les réponses générées comme signal pour l’entraînement de la recherche d’information. Le RAG s’appuie généralement sur des passages pseudo-pertinents extraits de bases de connaissances externes, ce qui peut conduire à des erreurs au niveau de la génération de réponses. Dans ce travail, nous proposons une approche de RAG à plusieurs niveaux améliorant la génération de réponses en associant recherche d’entités et expansion de requête. Plus précisément, nous définissons une fonction de perte RAG permettant de conditionner la génération de réponses à la fois par la recherche d’entités et celle de passages. Cette approche permet de dépasser les travaux existants sur le jeu d’évaluation ViQuAE, démontrant ainsi que les connaissances qu’elle va chercher sont plus pertinentes pour la génération de réponses.</abstract>
      <url hash="9f8fcd99">2025.jeptalnrecital-coria.11</url>
      <language>fra</language>
      <bibkey>adjali-etal-2025-generation</bibkey>
    </paper>
    <paper id="12">
      <title>Génération augmentée de récupération pour les journaux historiques</title>
      <author><first>Trung</first><last>Tran</last></author>
      <author><first>Carlos-Emiliano</first><last>González-Gallardo</last></author>
      <author><first>Antoine</first><last>Doucet</last></author>
      <pages>131–134</pages>
      <abstract>La numérisation des archives historiques permet d’améliorer leur accessibilité et leur préservation à long terme, ouvrant ainsi de nouvelles perspectives de recherche interdisciplinaire. Cependant, l’ampleur des données disponibles pose des défis considérables. Diverses tâches de traitement automatique du langage naturel, telles que la reconnaissance d’entités nommées et la segmentation en articles, ont permis de faciliter l’accès du public en extrayant et structurant l’information. Néanmoins, l’agrégation des articles de presse historiques demeure largement inexplorée. Ce travail met en évidence le potentiel d’un cadre de génération augmentée de récupération (RAG), combinant des grands modèles de langage, un module de recherche sémantique et des bases de connaissances, pour agréger des articles de journaux historiques. Nous proposons également des métriques d’évaluation des systèmes génératifs ne nécessitant pas de vérité de terrain. Les premiers résultats de notre chaîne de traitement RAG sont prometteurs, démontrant que la récupération sémantique, renforcée par le reranking et la reconnaissance d’entités nommées, peut atténuer les erreurs d’océrisation et les fautes de frappe dans les requêtes.</abstract>
      <url hash="a4aeb846">2025.jeptalnrecital-coria.12</url>
      <language>fra</language>
      <bibkey>tran-etal-2025-generation</bibkey>
    </paper>
    <paper id="13">
      <title>Optimisation de la Recherche d’Information Juridiques à travers l’Agrégation des Signaux Contextuels Multi-niveaux des Modèles de Langue Préentraînés</title>
      <author><first>Eya</first><last>Hammami</last></author>
      <author><first>Mohand</first><last>Boughanem</last></author>
      <author><first>Taoufiq</first><last>Dkaki</last></author>
      <pages>135–150</pages>
      <abstract>L’accès croissant aux documents juridiques sous format numérique crée à la fois des opportunités et des défis pour les professionnels du droit et les chercheurs en intelligence artificielle. Cependant, bien que les Modèles de Langue Préentraînés (PLMs) excellent dans diverses tâches de TAL, leur efficacité dans le domaine juridique demeure limitée, en raison de la longueur et de la complexité des textes. Pour répondre à cette problématique, nous proposons une approche exploitant les couches intermédiaires des modèles du Transformer afin d’améliorer la représentation des documents juridiques. En particulier, cette méthode permet de capturer des relations syntaxiques et sémantiques plus riches, tout en maintenant les interactions contextuelles au sein du texte. Afin d’évaluer notre approche, nous avons mené des expérimentations sur des ensembles de données juridiques publiques, dont les résultats obtenus démontrent son efficacité pour diverses tâches, notamment la recherche et la classification de documents.</abstract>
      <url hash="2761c6c5">2025.jeptalnrecital-coria.13</url>
      <language>fra</language>
      <bibkey>hammami-etal-2025-optimisation</bibkey>
    </paper>
    <paper id="14">
      <title>Prédiction des préférences et génération de revue personnalisée basées sur les aspects et attention</title>
      <author><first>Ben</first><last>Kabongo</last></author>
      <author><first>Vincent</first><last>Guigue</last></author>
      <author><first>Pirmin</first><last>Lemberger</last></author>
      <pages>151–170</pages>
      <abstract>Le filtrage collaboratif alimente de nombreux systèmes de recommandation performants, mais il peine à saisir les interactions fines entre utilisateurs et articles et à fournir des explications claires. Face à la demande croissante de transparence, la génération d’explications textuelles via des modèles de langage est devenue un axe de recherche majeur. Nous proposons AURA, un modèle multi-tâches combinant prédiction de notes et génération de revues personnalisées. AURA apprend simultanément des représentations globales et spécifiques aux aspects en optimisant les notes globales, les notes par aspect et la génération de revues, avec une attention personnalisée. Ces représentations produisent une invite personnalisée qui guide un modèle de langage pour générer la revue finale. Implémenté avec le modèle T5 pré-entraîné et une stratégie de réglage par invite, AURA a été testé sur TripAdvisor et RateBeer. Les résultats montrent qu’il surpasse nettement les modèles de référence, surtout en génération de revues, renforçant ainsi la transparence des recommandations et la satisfaction des utilisateurs.</abstract>
      <url hash="4b353e71">2025.jeptalnrecital-coria.14</url>
      <language>fra</language>
      <bibkey>kabongo-etal-2025-prediction</bibkey>
    </paper>
    <paper id="15">
      <title>Quand les Bots Déjouent l’Apprentissage : Enjeux et Défis de la Détection</title>
      <author><first>Mohsine</first><last>Aabid</last></author>
      <author><first>Patrice</first><last>Bellot</last></author>
      <author><first>Simon</first><last>Dumas Primbault</last></author>
      <pages>171–179</pages>
      <abstract>Identifier les bots d’une une bibliothèque numérique est un défi crucial pour analyser avec précision le comportement des utilisateurs afin de mieux répondre à leurs besoins. Mais que se passe-t-il lorsque les modèles de détection sont confrontés à des données provenant d’une période différente de leur période d’entraînement ? Cet article explore cette question en extrayant des caractéristiques clés, telles que la durée de l’activité et le nombre de requêtes, nous comparons plusieurs modèles d’apprentissage supervisé et évaluons la robustesse de cette approche face aux variations temporelles. Nos observations préliminaires montrent que les modèles de détection tendent à être plus confiant sur les données issues de leur période d’entraînement, ce qui soulève des questions sur leur capacité à généraliser à des périodes différentes. Cette dépendance met en lumière la nécessité de stratégies adaptatives, telles que des mises à jour régulières des modèles et de nouvelles approches d’apprentissage, afin de saisir l’évolution des comportements automatisés et améliorer la robustesse de la détection.</abstract>
      <url hash="6d6ef118">2025.jeptalnrecital-coria.15</url>
      <language>fra</language>
      <bibkey>aabid-etal-2025-quand</bibkey>
    </paper>
    <paper id="16">
      <title>Rapido, interopérabilité et fouille de textes : vers un alignement des publications scientifiques en archéologie</title>
      <author><first>Justine</first><last>Revol</last></author>
      <author><first>Agnieszka</first><last>Halczuk</last></author>
      <author><first>Lucas</first><last>Anki</last></author>
      <author><first>Pascal</first><last>Cuxac</last></author>
      <pages>180–182</pages>
      <abstract>Le projet RAPIDO vise à enrichir les publications scientifiques en reliant automatiquement les toponymes archéologiques à des référentiels d’autorité grâce à des outils de reconnaissance d’entités nommées. Il s’appuie sur l’annotation manuelle et l’apprentissage automatique (Flair, BERT) pour extraire et aligner ces toponymes. L’article présente cette méthode, les résultats obtenus et les perspectives d’amélioration.</abstract>
      <url hash="d9062df4">2025.jeptalnrecital-coria.16</url>
      <language>fra</language>
      <bibkey>revol-etal-2025-rapido</bibkey>
    </paper>
    <paper id="17">
      <title>Restructuration de la Littérature Biomédicale dans une Architecture <fixed-case>RAG</fixed-case> pour la Génération de Réponse</title>
      <author><first>Mael</first><last>Lesavourey</last></author>
      <author><first>Gilles</first><last>Hubert</last></author>
      <pages>183–200</pages>
      <abstract>Le Question Answering Biomédical (BQA) présente des défis spécifiques liés au vocabulaire spécialisé et aux structures sémantiques complexes de la littérature biomédicale. Les grands modèles de langage (LLMs) ont montré d’excellentes performances dans plusieurs tâches de compréhension et de génération du langage naturel. Cependant, leur efficacité tend à diminuer dans des domaines spécifiques, comme la biomédecine. Pour remédier à ce problème, les architectures de génération augmentée de récupération (RAG) sont devenues une approche prometteuse, combinant les avantages des méthodes de recherche d’information et des LLMs afin d’intégrer des connaissances spécifiques au domaine dans le processus de génération. Dans cet article, nous étudions le rôle du contexte dans l’amélioration des performances des pipelines RAG pour le BQA. Nous montrons que l’intégration d’un contexte basé sur une restructuration appropriée de la littérature influence positivement la qualité des réponses générées, en améliorant à la fois les métriques sémantiques et lexicales.</abstract>
      <url hash="d9adfe23">2025.jeptalnrecital-coria.17</url>
      <language>fra</language>
      <bibkey>lesavourey-hubert-2025-restructuration</bibkey>
    </paper>
    <paper id="18">
      <title><fixed-case>SEBRAG</fixed-case> : Vers l’Utilisation des <fixed-case>LLM</fixed-case> pour une Tâche de Questions-Réponses Extractive</title>
      <author><first>Quentin</first><last>Signé</last></author>
      <author><first>Thiziri</first><last>Belkacem</last></author>
      <author><first>Jose</first><last>G. Moreno</last></author>
      <author><first>Mohand</first><last>Boughanem</last></author>
      <pages>201–216</pages>
      <abstract>L’émergence des grands modèles de langage (LLM) a révolutionné le domaine des questions-réponses (QR). Cependant, leur tendance à halluciner représente un défi majeur en recherche d’information (RI), notamment en domaines critiques comme la maintenance aéronautique. Pour répondre à cette problématique, cet article explore la capacité des LLM pour des tâches de QR extractives, à l’instar des modèles encodeurs. Ainsi, nous proposons une approche de génération augmentée par recherche d’information (RAG) utilisant un outil d’extraction de chaînes de caractères, permettant au LLM d’extraire une réponse plutôt que de la générer. Les expériences réalisées sur un jeu de données de maintenance aéronautique révèlent que cette approche permet de mieux contrôler l’hallucination par rapport aux méthodes RAG traditionnelles, tout en gardant une précision comparable aux modèles encodeurs extractifs. Cette approche montre son potentiel pour des applications hautement techniques où la précision et la fiabilité sont primordiales.</abstract>
      <url hash="32890aac">2025.jeptalnrecital-coria.18</url>
      <language>fra</language>
      <bibkey>signe-etal-2025-sebrag</bibkey>
    </paper>
    <paper id="19">
      <title>Seval-ex : Un paradigme basé sur les phrases atomiques pour une évaluation explicable de la qualité des résumés</title>
      <author><first>Tanguy</first><last>Herserant</last></author>
      <author><first>Vincent</first><last>Guigue</last></author>
      <pages>217–229</pages>
      <abstract>L’évaluation de la qualité des résumés de texte demeure un défi critique en Traitement Automatique du Langage Naturel. Les approches actuelles font face à un compromis entre performance et interprétabilité. Nous présentons SEval-Ex, un framework qui comble cette lacune en décomposant l’évaluation des résumés en phrases atomiques, permettant à la fois une haute performance et une explicabilité. SEval-Ex emploie un pipeline en deux étapes : extraction des phrases atomiques à partir du texte source et du résumé via un LLM, puis mise en correspondance de ces phrases. Contrairement aux approches existantes qui ne fournissent que des scores globaux, notre méthode génère un parcours détaillé des décisions grâce à un alignement entre les phrases. Les expériences sur SummEval démontrent que SEval-Ex atteint des performances état de l’art avec une corrélation de 0.580 sur la cohérence avec les jugements humains, surpassant GPT-4 (0.521) tout en maintenant l’interprétabilité et la robustesse contre l’hallucination.</abstract>
      <url hash="b603ebb8">2025.jeptalnrecital-coria.19</url>
      <language>fra</language>
      <bibkey>herserant-guigue-2025-seval</bibkey>
    </paper>
    <paper id="20">
      <title>Simplification de Textes Scientifiques (et <fixed-case>R</fixed-case>ien de Plus). Rapport sur l’Action <fixed-case>CLEF</fixed-case> 2025 <fixed-case>S</fixed-case>imple<fixed-case>T</fixed-case>ext</title>
      <author><first>Liana</first><last>Ermakova</last></author>
      <author><first>Hosein</first><last>Azarbonyad</last></author>
      <author><first>Jan</first><last>Bakker</last></author>
      <author><first>Benjamin</first><last>Vendeville</last></author>
      <author><first>Jaap</first><last>Kamps</last></author>
      <pages>230–232</pages>
      <abstract>Ces dernières années, l’action SimpleText a rassemblé une communauté active de chercheurs en traitement du langage naturel (TLN) et en recherche d’information (RI) autour d’un objectif commun : améliorer l’accessibilité des textes scientifiques. Ses références en matière de recherche d’extraits scientifiques, de détection et d’explication de terminologies scientifiques, ainsi que de simplification de textes scientifiques sont désormais des standards. En 2025, nous introduisons cette année des changements majeurs dans l’organisation et les missions de l’action. L’action CLEF 2025 SimpleText proposera trois tâches principales. . Tâche 1 sur Simplification de texte : simplification de texte scientifique. Tâche 2 sur Créativité contrôlée : identifier et éviter les hallucinations. Tâche 3 surSimpleText 2024 Revisité : tâches sélectionnées sur demande populaire.</abstract>
      <url hash="284ef016">2025.jeptalnrecital-coria.20</url>
      <language>fra</language>
      <bibkey>ermakova-etal-2025-simplification</bibkey>
    </paper>
    <paper id="21">
      <title>Transfert de modèles de langue pour la classification rhétorique des citations à travers les disciplines</title>
      <author><first>Anne-Sophie</first><last>Foussat</last></author>
      <author><first>Vincent</first><last>Guigue</last></author>
      <author><first>Nicolas</first><last>Sauvion</last></author>
      <author><first>Robert</first><last>Bossy</last></author>
      <author><first>Claire</first><last>Nédellec</last></author>
      <pages>233–248</pages>
      <abstract>La classification automatique des fonctions rhétoriques des citations contribue à l’étude des stratégies discursives d’un auteur lorsqu’il cite, et plus généralement, de son intention. Dans l’objectif d’estimer la fiabilité des découvertes citées en écologie, cet article analyse les capacités de transfert des modèles de langue affinés en linguistique computationnelle pour cette tâche, en les comparant aux méthodes par amorçage (prompting). Nous introduisons PD100cit, un nouveau corpus annoté, ainsi qu’un guide d’annotation, afin d’explorer la typologie rhétorique des citations relatives aux interactions biologiques. Nous explorons également la sensibilité des modèles aux longueurs des contextes des passages de citations. Nos résultats montrent de bonnes performances des modèles de langue transférés en écologie et l’intérêt de réviser la typologie pour évaluer la fiabilité des découvertes de la linguistique computationnelle à l’écologie.</abstract>
      <url hash="f98367c6">2025.jeptalnrecital-coria.21</url>
      <language>fra</language>
      <bibkey>foussat-etal-2025-transfert</bibkey>
    </paper>
    <paper id="22">
      <title><fixed-case>UC</fixed-case>-<fixed-case>FIR</fixed-case>e: Approche efficace pour la recherche d’informations non supervisée</title>
      <author><first>Maxime</first><last>Hanus</last></author>
      <author><first>Quentin</first><last>Guignard</last></author>
      <author><first>Christophe</first><last>Rodrigues</last></author>
      <author><first>Léonard</first><last>De Vinci</last></author>
      <pages>249–264</pages>
      <abstract>Nous présentons un modèle de recherche d’informations non supervisé conciliant efficacité et faible coût computationnel, fonctionnant uniquement sur CPU. Plutôt que de remplacer BM25, nous l’améliorons en réduisant l’écart lexical. Notre méthode repose sur l’entraînement de vecteurs de mots FastText et la construction de matrices de coexistence et de similarité pour regrouper des mots interchangeables en clusters. Documents et requêtes sont réécrits avec ces clusters, améliorant la pertinence des résultats sans alourdir l’inférence. Expérimenté sur plusieurs corpus de BEIR, notre modèle surpasse des approches plus coûteuses en calcul et obtient de meilleures performances que BM25 sur diverses métriques, tout en conservant une vitesse d’inférence similaire. Cette recherche démontre que notre méthode offre une alternative pratique, scalable et économique aux modèles denses et hybrides, facilitant son adoption dans des systèmes de recherche réels. UC-FIRe est disponible publiquement : https://github.com/Limekaaa/UC-FIRe.</abstract>
      <url hash="ced8506f">2025.jeptalnrecital-coria.22</url>
      <language>fra</language>
      <bibkey>hanus-etal-2025-uc</bibkey>
    </paper>
    <paper id="23">
      <title>Utilisation de mécanismes inférentiels dans le processus d’explication automatique de la métaphore à une inconnue</title>
      <author><first>Jérémie</first><last>Roux</last></author>
      <author><first>Hani</first><last>Guenoune</last></author>
      <author><first>Mathieu</first><last>Lafourcade</last></author>
      <author><first>Richard</first><last>Moot</last></author>
      <pages>265–282</pages>
      <abstract>Considérons la métaphore comme une analogie à une inconnue. L’expliquer revient à résoudre l’unique variable du carré analogique qui en résulte et dont les trois autres termes sont fixés. Nous proposons ici une méthode détaillée pour arriver à cet objectif en utilisant la base de connaissances JeuxDeMots . Nous procédons par reconnaissance de schémas de relations préalablement identifiés et qui permettent d’évaluer la force de la similarité relationnelle et celles des deux similarités attributionnelles pour en déduire celle de l’analogie dans sa globalité. Le terme candidat qui permet d’obtenir la meilleure force d’analogie entre les quatre termes de l’analogie à trou ainsi complétée est élu. Enfin, on cherche à démontrer que l’utilisation d’inférences dans ce processus permet d’aboutir à de meilleurs résultats, c’est-à-dire augmenter le nombre de fois où un bon candidat est élu.</abstract>
      <url hash="7e9ce517">2025.jeptalnrecital-coria.23</url>
      <language>fra</language>
      <bibkey>roux-etal-2025-utilisation</bibkey>
    </paper>
    <paper id="24">
      <title>Vers des interfaces favorisant l’engagement critique des utilisateurs : un prototype utilisant <fixed-case>RAG</fixed-case></title>
      <author><first>Petra</first><last>Dadić</last></author>
      <author><first>Liana</first><last>Ermakova</last></author>
      <pages>283–293</pages>
      <abstract>Les chatbots à LLM sont devenus omniprésents, mais produisent parfois des informations trompeuses (« hallucinations »), souvent difficiles à repérer pour les utilisateurs. Cet article de démonstration présente une interface prototype conçue pour aider les utilisateurs à identifier et vérifier les informations cruciales dans le contenu généré par l’IA. Dans le cadre de la génération augmentée de recherche (RAG), l’interface met en évidence les informations clés et fournit un accès en temps réel aux sources de soutien ou contradictoires. Nous avons mené une étude avec 80 participants pour recueillir des retours et affiner la conception, en mettant l’accent sur l’amélioration de la source d’information et de la confiance des utilisateurs. Cet article montre comment l’interface peut aider à repérer la désinformation et à améliorer l’usage des LLM pour la recherche d’informations scientifiques.</abstract>
      <url hash="7dd040ba">2025.jeptalnrecital-coria.24</url>
      <language>fra</language>
      <bibkey>dadic-ermakova-2025-vers</bibkey>
    </paper>
    <paper id="25">
      <title>Vers un élagage de tokens sans coût dans les modèles de récupération à interaction tardive</title>
      <author><first>Yuxuan</first><last>Zong</last></author>
      <author><first>Benjamin</first><last>Piwowarski</last></author>
      <pages>294–309</pages>
      <abstract>Les modèles de RI neuronaux à interaction tardive comme ColBERT offrent un compromis compétitif entre efficacité et efficience sur de nombreuses bases de référence. Cependant, ils nécessitent un espace mémoire considérable pour stocker les représentations contextuelles de tous les tokens des documents. Certains travaux ont proposé d’utiliser soit des heuristiques, soit des techniques basées sur les statistiques pour élaguer des tokens dans chaque document. Cependant, cela ne garantit pas que les tokens supprimés n’aient aucun impact sur le score de récupération. Notre travail utilise une approche méthodique pour définir comment élaguer des tokens sans affecter le score entre un document et une question. Nous introduisons trois coûts de régularisation, qui induisent une solution avec des taux d’élagage élevés, ainsi que deux stratégies d’élagage. Nous les étudions expérimentalement (en domaine interne et externe), démontrant que nous pouvons préserver les performances de ColBERT tout en n’utilisant que 30% des tokens.</abstract>
      <url hash="7fee7113">2025.jeptalnrecital-coria.25</url>
      <language>fra</language>
      <bibkey>zong-piwowarski-2025-vers</bibkey>
    </paper>
  </volume>
  <volume id="recital" ingest-date="2025-09-28" type="proceedings">
    <meta>
      <booktitle>Actes des 18e Rencontres Jeunes Chercheurs en RI (RJCRI) et 27ème Rencontre des Étudiants Chercheurs en Informatique pour le Traitement Automatique des Langues (RECITAL)</booktitle>
      <editor><first>Frédéric</first><last>Bechet</last></editor>
      <editor><first>Adrian-Gabriel</first><last>Chifu</last></editor>
      <editor><first>Karen</first><last>Pinel-sauvagnat</last></editor>
      <editor><first>Benoit</first><last>Favre</last></editor>
      <editor><first>Eliot</first><last>Maes</last></editor>
      <editor><first>Diana</first><last>Nurbakova</last></editor>
      <publisher>ATALA \\&amp; ARIA</publisher>
      <address>Marseille, France</address>
      <month>6</month>
      <year>2025</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="8ccf138e">2025.jeptalnrecital-recital.0</url>
      <bibkey>jep-taln-recital-2025-recital</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Amélioration de la lisibilité de textes via l’utilisation de <fixed-case>LLM</fixed-case></title>
      <author><first>Baptiste</first><last>Ramonda</last></author>
      <author><first>Isabelle</first><last>Ferrane</last></author>
      <author><first>Julien</first><last>Pinquier</last></author>
      <pages>1–13</pages>
      <abstract>La lisibilité d’un texte est essentielle pour garantir un accès équitable à l’information. Cet article propose une méthodologie visant à simplifier des textes complexes tout en préservant leur sens. Un indice global de lisibilité a été défini en combinant plusieurs scores normalisés. Ensuite, une chaîne de traitement automatique, basée sur l’API de Gemini (LLM de Google), a généré des versions simplifiées des textes. Les résultats montrent une amélioration significative de la lisibilité, selon l’indice global et les critères spécifiques. Pour vérifier la conservation des idées clés, des résumés ont été extraits des versions initiales et simplifiées. Une mesure de la distance sémantique confirme que les concepts essentiels sont préservés. Cette approche prouve qu’il est possible d’automatiser efficacement la simplification textuelle tout en maintenant la cohérence et la pertinence des contenus, améliorant ainsi l’accessibilité de l’information.</abstract>
      <url hash="b72151d9">2025.jeptalnrecital-recital.1</url>
      <language>fra</language>
      <bibkey>ramonda-etal-2025-amelioration</bibkey>
    </paper>
    <paper id="2">
      <title>Analyse de la littérature sur les stratégies d’augmentation de données dans des contextes à faible ressources</title>
      <author><first>Benedictus</first><last>Kent Rachmat</last></author>
      <pages>14–30</pages>
      <abstract>Les grands modèles de langage (LLMs) ont révolutionné le traitement automatique des langues (TAL), mais leur succès demeure largement limité aux domaines généralistes disposant de ressources abondantes. En revanche, l’application des LLMs à des domaines spécialisés à faibles ressources soulève des défis majeurs liés à la rareté des données d’entraînement, à la dérive de domaine et aux contraintes terminologiques strictes. Cette revue propose un état de l’art des approches actuelles pour le question-réponse (QA) en contexte spécialisé et à faibles ressources avec les LLMs. Nous commençons par analyser la couverture et la représentativité des jeux de données de QA spécialisés en les comparant à de grands ensembles de référence, que nous appelons ParentQA . Sur la base de cette analyse, nous passons en revue les stratégies centrées sur les données visant à accroître la diversité des entrées, notamment à travers des techniques d’augmentation. Nous abordons également les métriques d’évaluation adaptées aux tâches spécialisées et les considérations éthiques associées. En cartographiant les méthodologies existantes et en identifiant les questions de recherche ouvertes, cette étude vise à orienter les futurs travaux sur l’adaptation des LLMs pour une utilisation robuste et responsable dans des environnements contraints en ressources et spécifiques à un domaine.</abstract>
      <url hash="39ba64b2">2025.jeptalnrecital-recital.2</url>
      <language>fra</language>
      <bibkey>kent-rachmat-2025-analyse</bibkey>
    </paper>
    <paper id="3">
      <title>Annotation de Marqueurs Discursifs : le cas de la désambiguïsation de après</title>
      <author><first>Paola</first><last>Herreño Castañeda</last></author>
      <author><first>Maeva</first><last>Sillaire</last></author>
      <pages>31–46</pages>
      <abstract>Les marqueurs discursifs (désormais MD) sont des expressions souvent polysémiques, voire polyfonctionnelles dans la langue (quoi,enfin, bon, mais, voilà, là, etc.). Dans ce dernier cas, une tâche consiste d’abord à distinguer leurs emplois comme MD et non-MD, en fonction notamment du contexte d’apparition. Dans le cadre de CODIM, un corpus de français a été constitué et annoté semi-automatiquement pour identifier les expressions potentiellement employées comme MD, non-MD, ou MD-CAND (étiquette regroupant les cas ambigus qui n’ont pas pu être déterminés par l’annotation). Nous cherchons à enrichir le processus d’annotation pour les cas où après a été classé comme MD-CAND. Pour cela, nous proposons un protocole d’annotation manuelle supplémentaire visant à trier, parmi ces candidats, les emplois contrastifs et non-contrastifs de après . Nos résultats initient des réflexions plus larges sur les enjeux théoriques et méthodologiques liés à l’annotation des MD.</abstract>
      <url hash="30db9cf3">2025.jeptalnrecital-recital.3</url>
      <language>fra</language>
      <bibkey>herreno-castaneda-sillaire-2025-annotation</bibkey>
    </paper>
    <paper id="4">
      <title>Annotation et modélisation des émotions dans un corpus textuel : une approche évaluative</title>
      <author><first>Jonas</first><last>Noblet</last></author>
      <pages>47–63</pages>
      <abstract>L’émotion est un phénomène capital dans le fonctionnement de l’être humain en société. Elle reste pourtant un sujet encore largement ouvert, notamment dans ses manifestations textuelles. La présente communication examine un corpus industriel manuellement annoté selon une approche évaluative de l’émotion. Cette conception théorique aujourd’hui peu exploitée propose une perspective différente, en complément des approches traditionnelles. Partant du constat que les annotations que nous avons collectées présentent un fort désaccord, nous avons émis l’hypothèse que celles-ci suivent néanmoins des tendances statistiques stables. Par le biais de modèles de langue entraînés sur ces annotations, nous montrons qu’il est possible de modéliser le processus d’étiquetage, et que la variabilité est guidée par des caractéristiques linguistiques sous-jacentes. Réciproquement, nos résultats indiquent que les modèles de langue semblent en mesure de distinguer les situations émotionnelles sur la base des critères évaluatifs.</abstract>
      <url hash="fb21dce7">2025.jeptalnrecital-recital.4</url>
      <language>fra</language>
      <bibkey>noblet-2025-annotation</bibkey>
    </paper>
    <paper id="5">
      <title>Comparaison des approches basées sur <fixed-case>BERT</fixed-case> et sur l’agent <fixed-case>LLM</fixed-case> pour la classification hiérarchique de narratifs dans les articles de presse multilingues</title>
      <author><first>Yutong</first><last>Wang</last></author>
      <author><first>Mohamed-Nour</first><last>Eldjadiri</last></author>
      <pages>64–90</pages>
      <abstract>Nous présentons une étude comparative de deux paradigmes de classification hiérarchique multi-labels de texte dans le contexte de l’extraction des narratifs d’articles de presse. La première approche utilise un cadre séquentiel basé sur BERT qui identifie les narratifs et leurs sous-narratifs correspondants. La seconde utilise des agents LLM spécialisés, chacun effectuant une classification binaire pour des catégories narratives spécifiques. En évaluant les deux approches sur l’ensemble de données SemEval-2025 Task 10 dans cinq langues, nous constatons que l’approche basée sur BERT offre une efficacité de calcul et des performances interlinguistiques cohérentes (moyenne F1 macro : 0,475), tandis que la méthode basée sur les agents démontre une meilleure gestion des narratifs nuancés et de meilleures performances sur les données en anglais (F1 macro : 0,513). Notre analyse révèle des forces complémentaires entre ces paradigmes. Nous discutons des implications pratiques et proposons des orientations pour des systèmes hybrides potentiels.</abstract>
      <url hash="f34ef77d">2025.jeptalnrecital-recital.5</url>
      <language>fra</language>
      <bibkey>wang-eldjadiri-2025-comparaison</bibkey>
    </paper>
    <paper id="6">
      <title>Corpus bilingue sous-titrage et Langue des Signes Française : la problématique de l’alignement automatique des données</title>
      <author><first>Julie</first><last>Halbout</last></author>
      <author><first>Diandra</first><last>Fabre</last></author>
      <pages>91–103</pages>
      <abstract>Dans cet article, nous présentons une étude sur la problématique de l’alignement automatique des données dans un corpus constitué de discours en français parlé, sous-titrés en français écrit et interprétés en langue des signes française (LSF). Après une introduction précisant le processus bien particulier de l’interprétation en langue des signes, nous dressons un tour d’horizon des ensembles de données existants pour la LSF ainsi que les spécificités du corpus Matignon-LSF, constitué à partir des comptes-rendus vidéos hebdomadaires du conseil des ministres. Nous montrons ensuite sur quelques exemples certains des phénomènes observés sur la problématique de l’alignement temporel entre les sous-titres synchronisés avec l’audio, et la LSF interprétée qui subit un décalage temporel. Nous en concluons que le niveau d’alignement ne peut pas être celui des phrases en français écrit et proposons quelques pistes pour la suite.</abstract>
      <url hash="80993858">2025.jeptalnrecital-recital.6</url>
      <language>fra</language>
      <bibkey>halbout-fabre-2025-corpus</bibkey>
    </paper>
    <paper id="7">
      <title>État de l’art : évaluation, détection et mitigation des hallucinations des <fixed-case>LLM</fixed-case>s</title>
      <author><first>Aygalic</first><last>Jara–Mikolajczak</last></author>
      <pages>104–123</pages>
      <abstract>Cet article présente un état de l’art sur les hallucinations produites par les grands modèles de langue (LLMs). L’objectif de ce travail est double : dresser un panorama des recherches actuelles dans ce domaine et souligner l’importance de prendre en considération les hallucinations lors de la conception des systèmes incorporant des LLMs. Pour ce faire, nous commençons par la définition du problème. Nous présentons ensuite les différentes méthodes d’évaluation, suivis des techniques de détection et de mitigation des hallucinations, tout en discutant leurs forces et limites méthodologiques.</abstract>
      <url hash="1a2d7124">2025.jeptalnrecital-recital.7</url>
      <language>fra</language>
      <bibkey>jara-mikolajczak-2025-etat</bibkey>
    </paper>
    <paper id="8">
      <title>État de l’art sur les marqueurs discursifs en Traitement Automatique des Langues</title>
      <author><first>Fatou</first><last>Sow</last></author>
      <pages>124–142</pages>
      <abstract>Les marqueurs discursifs sont des éléments linguistiques qui peuvent être employés pour construire la cohérence d’un discours car ils expriment les relations entre les unités discursives. Ils constituent ainsi des indices utiles pour la résolution de problèmes de traitement de langue en rapport avec la sémantique du texte, le discours ou la compréhension de systèmes. Dans cet article, nous présentons un état de l’art des marqueurs discursifs en traitement automatique des langues (TAL). Nous introduisons les représentations textuelles des marqueurs discursifs puis nous nous intéressons à la détection des marqueurs et l’utilisation de leurs sens pour améliorer ou évaluer des tâches de TAL.</abstract>
      <url hash="bc26ba28">2025.jeptalnrecital-recital.8</url>
      <language>fra</language>
      <bibkey>sow-2025-etat</bibkey>
    </paper>
    <paper id="9">
      <title>Évaluation Automatique Explicable de l’Écriture Argumentative : État de l’Art, Lacunes et Proposition d’Architecture Modulaire Alignée sur des Grilles Éducatives</title>
      <author><first>Marcos</first><last>Moisés Crisóstomo de Oliveira</last></author>
      <pages>143–159</pages>
      <abstract>L’évaluation automatique de l’écriture constitue une frontière prometteuse du Traitement Automatique du Langage Naturel (TALN), en particulier pour l’enseignement de l’argumentation. Pourtant, la majorité des systèmes existants privilégient la prédiction de scores au détriment de la compréhension structurelle des textes et de la production de retours pédagogiques utiles. Cet article propose une architecture explicable, modulaire et adaptée à la Compétence III de l’ENEM (Brésil), axée sur trois piliers : l’alignement avec des grilles officielles, la transparence des décisions algorithmiques, et la valeur formative des retours générés. Articulant théorie de l’argumentation, évaluation de l’écriture et technologies récentes en TALN, cette architecture comprend quatre modules : segmentation des unités argumentatives, classification des relations discursives, alignement aux critères d’évaluation, et génération de feedback. Les résultats initiaux montrent un fort potentiel pour améliorer l’équité, l’auditabilité et l’utilité pédagogique du système, tout en ouvrant la voie à des adaptations multilingues dans d’autres contextes d’évaluation</abstract>
      <url hash="083c2d3b">2025.jeptalnrecital-recital.9</url>
      <language>fra</language>
      <bibkey>moises-crisostomo-de-oliveira-2025-evaluation</bibkey>
    </paper>
    <paper id="10">
      <title>Evaluation de la lisibilité des textes biomédicaux selon le profil du lecteur</title>
      <author><first>Anya</first><last>Nait Djoudi</last></author>
      <pages>160–174</pages>
      <abstract>La lisibilité des textes biomédicaux est perçue différemment selon le profil du lecteur, ce qui est amplifié par la complexité intrinsèque de ces documents et par l’inégale littératie en santé au sein de la population. Bien que 72% des internautes consultent des informations médicales en ligne, une part significative rencontre des difficultés de compréhension. Pour garantir l’accessibilité des textes à un public varié, l’évaluation de la lisibilité est donc essentielle. Or, les formules de lisibilité classiques, conçues pour des textes généraux, ne tiennent pas compte de cette diversité, soulignant la nécessité d’adapter les outils d’évaluation aux besoins spécifiques des textes biomédicaux et à l’hétérogénéité des lecteurs. Pour répondre à ce besoin, nous avons développé une méthode d’évaluation automatique de la lisibilité, adaptée à trois profils de lecteurs (adultes experts/non-experts, enfants). Cette méthode s’appuie sur un corpus biomédical bilingue de 20 008 documents (11 154 en anglais, 8 854 en français), que nous avons constitué et rendons accessible librement. Elle utilise une architecture hybride combinant embeddings de transformers et caractéristiques linguistiques, atteignant un score F1 macro-moyen de 0,987. Cette approche ouvre des perspectives pour l’évaluation fine de la lisibilité, la personnalisation de la recherche d’information, et la validation de la lisibilité des résumés générés automatiquement.</abstract>
      <url hash="d17d5179">2025.jeptalnrecital-recital.10</url>
      <language>fra</language>
      <bibkey>nait-djoudi-2025-evaluation</bibkey>
    </paper>
    <paper id="11">
      <title>Image incomplète : Une étude d’état de l’art sur les biais dans les grands modèles de langage</title>
      <author><first>Trung</first><last>Hieu Ngo</last></author>
      <pages>175–189</pages>
      <abstract>Les grands modèles de langage (LLM) pré-entraînés ont transformé le traitement du langage naturel (TALN) et les tâches quotidiennes, surpassant les méthodes traditionnelles. Leur utilisation a démocratisé l’accès, facilitant l’écriture, le codage et les conseils de santé. Entraînés sur d’immenses corpus textuels issus d’internet, les LLM héritent de biais, perpétuant des stéréotypes qui peuvent fausser les représentations linguistiques et causer des préjudices représentationnels ou allocationnels. Dans le domaine médical, où les LLM soutiennent la communication et la documentation, ces biais présentent des risques significatifs. Cette revue analyse les recherches sur les biais des LLM, identifie les lacunes concernant les déterminants sociaux de la santé (DSS) et discute de la nécessité d’un cadre pour les aborder de manière exhaustive, améliorant l’intégration sécurisée des LLM en santé.</abstract>
      <url hash="0a560afc">2025.jeptalnrecital-recital.11</url>
      <language>fra</language>
      <bibkey>hieu-ngo-2025-image</bibkey>
    </paper>
    <paper id="12">
      <title>La traduction automatique dialectale: état de l’art et étude préliminaire sur le continuum dialectal de l’occitan</title>
      <author><first>Oriane</first><last>Nédey</last></author>
      <pages>190–238</pages>
      <abstract>Cet article dresse un état de l’art de la traduction automatique et de son évaluation pour les langues à variation dialectale, et en particulier pour les continuums dialectaux. Pour illustrer cet état de l’art, nous proposons une série d’expériences préliminaires sur le continuum occitan, afin de dresser un état des performances des systèmes existants pour la traduction depuis et vers plusieurs variétés d’occitan. Nos résultats indiquent d’une part des performances globalement satisfaisantes pour la traduction vers le français et l’anglais. D’autre part, des analyses mélangées à des outils d’identification de langues sur les prédictions vers l’occitan mettent en lumière la capacité de la plupart des systèmes évalués à générer des textes dans cette langue (y compris en zero-shot ), mais révèlent aussi des limitations en termes d’évaluation de la diversité dialectale dans les traductions proposées.</abstract>
      <url hash="fe66a1c6">2025.jeptalnrecital-recital.12</url>
      <language>fra</language>
      <bibkey>nedey-2025-la</bibkey>
    </paper>
    <paper id="13">
      <title>Normaliser le moyen français : du graphématique au semi-diplomatique</title>
      <author><first>Sonia</first><last>Solfrini</last></author>
      <author><first>Mylène</first><last>Dejouy</last></author>
      <author><first>Aurélia</first><last>Marques Oliveira</last></author>
      <author><first>Pierre-Olivier</first><last>Beaulnes</last></author>
      <pages>239–252</pages>
      <abstract>La pré-éditorialisation des documents anciens, comprise comme une automatisation partielle de la préparation éditoriale des données textuelles, est récemment devenue l’un des nouveaux fronts de la recherche en philologie computationnelle. Dans un premier temps, nous définissons cette tâche de TAL (Traitement Automatique du Langage) pour le moyen français et la plaçons dans une chaîne de traitement numérique qui permet la création de données machine-actionable, depuis les sorties de l’OCR (Optical Character Recognition). Ensuite, nous présentons et rendons disponible un ensemble de données d’environ 40 000 lignes, tirées d’un corpus d’imprimés du XVIesiècle, ainsi que les règles de normalisation semi-diplomatique qui ont guidé la préparation des données. Enfin, nous proposons un premier modèle de normalisation automatique, afin de confirmer la faisabilité de la tâche.</abstract>
      <url hash="b008a72f">2025.jeptalnrecital-recital.13</url>
      <language>fra</language>
      <bibkey>solfrini-etal-2025-normaliser</bibkey>
    </paper>
    <paper id="14">
      <title>Réhabiliter l’écriture Ajami : un levier technologique pour l’alphabétisation en Afrique</title>
      <author><first>Samy</first><last>Ouzerrout</last></author>
      <author><first>Idriss</first><last>Saadallah</last></author>
      <pages>253–267</pages>
      <abstract>Cet article explore l’écriture Ajami, système basé sur l’alphabet arabe historiquement utilisé pour transcrire les langues africaines, comme levier technologique d’alphabétisation et d’inclusion nu- mérique en Afrique subsaharienne et au Maghreb. Nous présentons la création d’AjamiXTranslit, un corpus multilingue de paires de textes Latin–Ajami et de manuscrits annotés, accompagné d’une plateforme collaborative d’enrichissement par des locuteurs natifs. À partir de ces données, nous développons des modèles de translittération automatique et de reconnaissance optique de caractères (OCR) adaptés à la diversité graphique de l’Ajami. L’article discute les défis techniques (variabilité manuscrite, absence de standardisation), linguistiques (transcriptions phonétiques hétérogènes) et sociaux (acceptabilité, accessibilité) de cette réintégration scripturale. Nos travaux s’inscrivent dans une démarche transdisciplinaire alliant traitement automatique des langues, sciences sociales et politiques éducatives, en vue de préserver un patrimoine scriptural menacé et de renforcer l’accès équitable au savoir dans des contextes digraphiques.</abstract>
      <url hash="6e6378e9">2025.jeptalnrecital-recital.14</url>
      <language>fra</language>
      <bibkey>ouzerrout-saadallah-2025-rehabiliter</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>VERS</fixed-case> : Versification Et Représentation de Séquences</title>
      <author><first>Marceau</first><last>Hernandez</last></author>
      <pages>268–288</pages>
      <abstract>L’analyse métrique est une étape importante pour le traitement des textes versifiés. Le résultat d’une telle analyse permet, par exemple, de comparer les textes entre eux, ou, dans le cas de textes chantés, de les comparer avec différents airs. Nous proposons une méthode pour la création d’un modèle produisant diverses analyses métriques pour un vers donné, ainsi qu’une application en diachronie longue de cette méthode sur des données en français produites à partir du 16èmesiècle et jusqu’au début du 20èmesiècle. Cette méthode repose sur la prédiction des noyaux vocaliques d’un vers. Nous offrirons également un point de comparaison et nous poserons la question de la robustesse à la variation de ces méthodes selon l’état de langue considéré et le bruitage provenant de l’application de reconnaissance optique de caractères en amont.</abstract>
      <url hash="f85f4b5f">2025.jeptalnrecital-recital.15</url>
      <language>fra</language>
      <bibkey>hernandez-2025-vers</bibkey>
    </paper>
    <paper id="16">
      <title>Vers une taxonomie pour l’analyse des intentions dans les interactions textuelles numériques</title>
      <author><first>Senaid</first><last>Popovic</last></author>
      <pages>289–303</pages>
      <abstract>Cet article propose une taxonomie pour la détection d’intention dans les communications numériques, distinguant les intentions explicites des intentions implicites, basée sur des principes psychologiques de persuasion. Notre approche se distingue par sa capacité à analyser aussi bien les communications numériques légitimes que celles potentiellement malveillantes. Elle repose sur l’identification des intentions sous-jacentes, facilitant ainsi la détection de menaces telles que les arnaques par email (hameçonnage) ou les fraudes sur les réseaux sociaux. Chaque catégorie de la taxonomie est justifiée et illustrée par des exemples de communications correspondant à l’intention associée. Ce travail répond à un manque de ressources dans la recherche sur la détection automatique d’intentions. Il vise à fournir une taxonomie applicable à l’identification des menaces textuelles, notamment les tentatives d’hameçonnage, tout en servant d’outil pédagogique pour sensibiliser le grand public aux stratégies employées dans les communications malveillantes.</abstract>
      <url hash="3f22b819">2025.jeptalnrecital-recital.16</url>
      <language>fra</language>
      <bibkey>popovic-2025-vers</bibkey>
    </paper>
  </volume>
  <volume id="4as" ingest-date="2025-09-28" type="proceedings">
    <meta>
      <booktitle>Actes de l'atelier Avancement de l’AMR et de l’Analyse Sémantique 2025 (4AS)</booktitle>
      <editor><first>Frédéric</first><last>Bechet</last></editor>
      <editor><first>Adrian-Gabriel</first><last>Chifu</last></editor>
      <editor><first>Karen</first><last>Pinel-sauvagnat</last></editor>
      <editor><first>Benoit</first><last>Favre</last></editor>
      <editor><first>Eliot</first><last>Maes</last></editor>
      <editor><first>Diana</first><last>Nurbakova</last></editor>
      <publisher>ATALA \\&amp; ARIA</publisher>
      <address>Marseille, France</address>
      <month>6</month>
      <year>2025</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="2665b292">2025.jeptalnrecital-4as.0</url>
      <bibkey>jep-taln-recital-2025-4as</bibkey>
    </frontmatter>
    <paper id="1">
      <title>L’essentiel est invisible pour les représentations sémantiques</title>
      <author><first>Amandine</first><last>Decker</last></author>
      <author><first>Maxime</first><last>Amblard</last></author>
      <pages>1–8</pages>
      <abstract>L’analyse sémantique est un terrain de recherche dynamique cherchant à produire des représentations formelles du sens au-delà de la syntaxe. Ces représentations détaillées peuvent être utilisées comme base pour la compréhension de la langue ( Natural Language Understanding ) ou de la génération (Natural Language Generation ) par exemple. Bien que ces représentations permettent une analyse fine, elles ne couvrent pas certains aspects cruciaux des usages réels de la langue. La plupart des formalismes de représentation sémantiques comme les AMR, les DRS ou les UMR fonctionnent hors contexte, ce qui revient à ignorer une partie importante du contenu des énoncés analysés. Dans cet article nous discutons de différents aspects de l’usage de la langue laissés de côté par les formalismes de représentations sémantiques. Nous soutenons que les travaux futurs dans ce domaine devraient inclure l’aspect interactif du langage à l’extension de ces formalismes.</abstract>
      <url hash="c71d2b7f">2025.jeptalnrecital-4as.1</url>
      <language>fra</language>
      <bibkey>decker-amblard-2025-lessentiel</bibkey>
    </paper>
    <paper id="2">
      <title>Prétraitement syntaxique pour enrichir le Bag of Words en Topic Modeling</title>
      <author><first>Connor</first><last>MacLean</last></author>
      <author><first>Denis</first><last>Cavallucci</last></author>
      <pages>9–16</pages>
      <abstract>Cet article propose une méthode de prétraitement innovante pour la topic modeling avec les modèles Latent Dirichlet Allocation (LDA) (Blei et al. , 2003) et Embedding Topic Model (ETM) (Dieng et al. , 2019), qui repose sur l’analyse des dépendances syntaxiques afin de construire des représentations plus riches du texte. En extrayant les têtes des groupes nominaux et verbaux ainsi que leurs compléments, notre approche génère des n-grammes syntaxiques (sn-grammes) plus informatifs que des bigrammes linéaires. Nous démontrons que cette stratégie permet de capturer les structures sémantiques complexes dans un corpus scientifique en français sur les énergies. Une évaluation expérimentale montre que, comparée à un prétraitement classique basé sur des unigrammes, notre approche accroît la diversité des sujets générés, tout en maintenant une cohérence raisonnable. Nous recommandons l’usage de métriques supplémentaires, telles que l’ Inversed Rank-Biased Overlap (IRBO), pour évaluer cette diversité thématique. Nos résultats suggèrent que cette méthode enrichit la granularité des sujets extraits et permet des analyses plus fines de grands corpus textuels. Ce travail s’inscrit dans un projet de thèse de fouille de textes dans le but de mieux cibler des startups innovantes dans les énergies et les analyser selon la méthode TRIZ de résolution de contradictions techniques.</abstract>
      <url hash="305c174f">2025.jeptalnrecital-4as.2</url>
      <language>fra</language>
      <bibkey>maclean-cavallucci-2025-pretraitement</bibkey>
    </paper>
    <paper id="3">
      <title>Ressources lexicales pour la sémantique : <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et, <fixed-case>B</fixed-case>abel<fixed-case>N</fixed-case>et, <fixed-case>P</fixed-case>rop<fixed-case>B</fixed-case>ank, <fixed-case>F</fixed-case>rame<fixed-case>N</fixed-case>et, <fixed-case>DB</fixed-case>pedia et <fixed-case>SUMO</fixed-case></title>
      <author><first>Ahana</first><last>Chattopadhyay</last></author>
      <pages>17–23</pages>
      <abstract>Cet article offre un aperçu concis des ressources lexicales ci-après, dans le cadre de la sémantique computationnelle : WordNet, BabelNet, PropBank, FrameNet, DBpedia et SUMO. L’accent est mis sur leur structure et leur application.</abstract>
      <url hash="4e7edc1b">2025.jeptalnrecital-4as.3</url>
      <language>fra</language>
      <bibkey>chattopadhyay-2025-ressources</bibkey>
    </paper>
  </volume>
  <volume id="diagllm" ingest-date="2025-09-28" type="proceedings">
    <meta>
      <booktitle>Actes de l'atelier Accès à l’information basé sur le dialogue et grands modèles de langage 2025 (DIAG-LLM)</booktitle>
      <editor><first>Frédéric</first><last>Bechet</last></editor>
      <editor><first>Adrian-Gabriel</first><last>Chifu</last></editor>
      <editor><first>Karen</first><last>Pinel-sauvagnat</last></editor>
      <editor><first>Benoit</first><last>Favre</last></editor>
      <editor><first>Eliot</first><last>Maes</last></editor>
      <editor><first>Diana</first><last>Nurbakova</last></editor>
      <publisher>ATALA \\&amp; ARIA</publisher>
      <address>Marseille, France</address>
      <month>6</month>
      <year>2025</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="2a1c0136">2025.jeptalnrecital-diagllm.0</url>
      <bibkey>jep-taln-recital-2025-diagllm</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Explicabilité par Perturbations pour les Systèmes <fixed-case>RAG</fixed-case></title>
      <author><first>Yongxin</first><last>Zhou</last></author>
      <author><first>Philippe</first><last>Mulhem</last></author>
      <author><first>Didier</first><last>Schwab</last></author>
      <pages>1–6</pages>
      <abstract>Les systèmes de Génération Augmentée par Récupération (RAG) ont pour objectif d’améliorer les Grands Modèles de Langage (LLM) en intégrant des informations provenant de sources externes pour générer des réponses, mais leur manque de transparence en terme d’explicabilité soulève des préoccupations, particulièrement dans des domaines tels que la santé, la finance ou le droit. Les méthodes par perturbations fournissent une explicabilité post-hoc, avec des RAG considérés comme des boîtes noires, en modifiant systématiquement les entrées ou documents récupérés pour évaluer la stabilité des réponses et l’attribution des sources. Ce document présente un aperçu de l’explicabilité des systèmes RAG, en se concentrant sur les approches basées sur des exemples et des perturbations. Nous proposons une taxonomie des techniques de perturbation à différents niveaux de granularité, montrant comment elles offrent des indicateurs interprétables sur le comportement des modèles</abstract>
      <url hash="82209ae3">2025.jeptalnrecital-diagllm.1</url>
      <language>fra</language>
      <bibkey>zhou-etal-2025-explicabilite</bibkey>
    </paper>
    <paper id="2">
      <title>Représentations conditionnelles entité-centrées pour le raisonnement multi-saut dans les systèmes de question-réponse multi-document</title>
      <author><first>Romain</first><last>Bourgeois</last></author>
      <author><first>Adrian</first><last>Chifu</last></author>
      <author><first>Sébastien</first><last>Fournier</last></author>
      <pages>7–7</pages>
      <abstract>Les systèmes de question-réponse multi-document (MD-QA) nécessitent un raisonnement multi-saut fondé sur des informations éparses à travers plusieurs documents. Pour structurer cette information, de nombreuses approches s’appuient sur des graphes de connaissances où les passages textuels sont représentés comme des nœuds reliés par des relations lexicales, sémantiques ou symboliques. Dans ce contexte, ce papier propose EntEmbed, un encodeur conçu pour représenter un passage de manière conditionnelle à une entité spécifique qu’il contient. Cette représentation entité-centrée vise à capter les dimensions sémantiques associées à l’entité, tout en maintenant une contextualisation fine du passage. L’objectif est d’explorer comment ces représentations peuvent être construites et de les utiliser pour améliorer le raisonnement multi-saut dans les systèmes MD-QA.</abstract>
      <url hash="b7964dc4">2025.jeptalnrecital-diagllm.2</url>
      <language>fra</language>
      <bibkey>bourgeois-etal-2025-representations</bibkey>
    </paper>
  </volume>
  <volume id="dyntal" ingest-date="2025-09-28" type="proceedings">
    <meta>
      <booktitle>Actes de l'atelier Traitement de données langagières dynamiques par les outils et méthodes du TAL 2025 (DYN-TAL)</booktitle>
      <editor><first>Frédéric</first><last>Bechet</last></editor>
      <editor><first>Adrian-Gabriel</first><last>Chifu</last></editor>
      <editor><first>Karen</first><last>Pinel-sauvagnat</last></editor>
      <editor><first>Benoit</first><last>Favre</last></editor>
      <editor><first>Eliot</first><last>Maes</last></editor>
      <editor><first>Diana</first><last>Nurbakova</last></editor>
      <publisher>ATALA \\&amp; ARIA</publisher>
      <address>Marseille, France</address>
      <month>6</month>
      <year>2025</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="813b7e14">2025.jeptalnrecital-dyntal.0</url>
      <bibkey>jep-taln-recital-2025-dyntal</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>À</fixed-case> la poursuite de phrases: méthodes pour traiter des données dynamiques pour tracer la production de phrases</title>
      <author><first>Ulasik</first><last>Malgorzata Anna</last></author>
      <author><first>Mahlow</first><last>Cerstin</last></author>
      <pages>1–6</pages>
      <abstract>Nous présentons des méthodes de traitement des données dynamiques permettant de retracer le processus de production de phrases. En tant qu’activité incrémentielle et non linéaire, l’écriture produit des versions intermédiaires incomplètes ou mal formées qui évoluent au fil de fréquentes révisions. À l’aide d’outils d’enregistrement des frappes et de traitement du langage naturel (TALN), nous proposons un cadre permettant de reconstruire automatiquement l’historique des phrases. De plus, nous implémentons dans THEtool un modèle qui synchronise l’historique des phrases avec les événements de révision et les patterns de pause. Cette représentation multicouche facilite la compréhension détaillée des aspects cognitifs et linguistiques de la construction des phrases.</abstract>
      <url hash="3901849a">2025.jeptalnrecital-dyntal.1</url>
      <language>fra</language>
      <bibkey>malgorzata-anna-cerstin-2025-la</bibkey>
    </paper>
    <paper id="2">
      <title>Analyse exploratoire des traces numériques clavier pour la prédiction des niveaux d’apprenants</title>
      <author><first>Al</first><last>SAWAR Ahood</last></author>
      <author><first>Mallart</first><last>Cyriel</last></author>
      <author><first>Pacquetet</first><last>Erin</last></author>
      <author><first>Simpkin</first><last>Andrew</last></author>
      <author><first>Ballier</first><last>Nicolas</last></author>
      <pages>7–11</pages>
      <abstract>Cet article présente une typologie des métriques des traces numériques clavier en vue d’une analyse des stratégies d’écriture des différents profils d’apprenants appliquée à une tâche de prédiction du niveau CECRL.</abstract>
      <url hash="ca0c14ad">2025.jeptalnrecital-dyntal.2</url>
      <language>fra</language>
      <bibkey>sawar-ahood-etal-2025-analyse</bibkey>
    </paper>
    <paper id="3">
      <title>Bursted! Un outil d’agrégation des keystrokes</title>
      <author><first>Bordes</first><last>Caroline</last></author>
      <author><first>Olive</first><last>Thierry</last></author>
      <author><first>Cislaru</first><last>Georgeta</last></author>
      <pages>12–16</pages>
      <abstract>Bursted! est un outil qui permet d’analyser les jets textuels, c’est-à-dire dire les segments de textes produits sans interruption lors d’une ou plusieurs sessions d’écriture. Il analyse les fichiers d’enregistrement des frappes au clavier (keylogging) fournis par les logiciels comme Inputlog. Ce travail s’inscrit dans le cadre théorique proposé par Cislaru et Olive (2018) pour étudier le processus de textualisation. L’application Bursted! automatise l’extraction des jets textuels et des variables associées et fournit un fichier au format ‘.csv’ prêt pour des traitements ultérieurs.</abstract>
      <url hash="199bd1e1">2025.jeptalnrecital-dyntal.3</url>
      <language>fra</language>
      <bibkey>caroline-etal-2025-bursted</bibkey>
    </paper>
    <paper id="4">
      <title>Détection automatique des unités linguistiques permettant le maintien de la producton écrite</title>
      <author><first>Feltgen</first><last>Quentin</last></author>
      <author><first>Gilquin</first><last>Gaëtanelle</last></author>
      <pages>17–22</pages>
      <abstract>La production textuelle est segmentée par des pauses en jets textuels de longueur variable, interprétés comme manifestant une certaine cohérence cognitive dans la rédaction. Pour favoriser la fluence de ce processus, les scripteurs peuvent avoir recours à des unités linguistiques qui permettent de maintenir le flux de la production. L’objectif de cette contribution est de proposer une méthode de TAL pour détecter automatiquement ces unités. Nous l’appliquons à un corpus d’apprenants écrit en anglais L2 et montrons, d’une part, que les unités de structuration du texte (connecteurs, etc.) opèrent souvent de manière isolée, et d’autre part que la production peut être maintenue par le recours à des stratégies de complémentation (syntagme prépositionnel, proposition infinitive) qui permettent d’élaborer à partir d’un contenu déjà en place.</abstract>
      <url hash="e693d465">2025.jeptalnrecital-dyntal.4</url>
      <language>fra</language>
      <bibkey>quentin-gaetanelle-2025-detection</bibkey>
    </paper>
    <paper id="5">
      <title>Pré-traiter les données d’écriture en temps réel</title>
      <author><first>Jouvenel</first><last>Amandine</last></author>
      <author><first>Manseri</first><last>Kehina</last></author>
      <pages>23–27</pages>
      <abstract>Traiter les données d’écriture en temps réel est une tâche complexe, ces dernières combinant des informations spatiales et temporelles, et conservant les traces du processus d’écriture. Les outils actuels de traitement des données linguistiques - comme les tokenizeurs, les étiqueteurs morpho-syntaxiques ou les parseurs syntaxiques - ne sont pas conçus ni entraînés pour traiter ce type de corpus et de données à haute dimensionalité. Cela soulève donc la problématique du traitement automatique des données d’écriture dynamique. Le travail présenté ici constitue une série de premières expériences portant sur l’étiquetage morpho-syntaxique et le chunking de ces données. Il vise à annoter les données tout en prenant en compte les traces de l’écriture en temps réel, appelées ici disfluences.</abstract>
      <url hash="4e44ee50">2025.jeptalnrecital-dyntal.5</url>
      <language>fra</language>
      <bibkey>amandine-kehina-2025-pre</bibkey>
    </paper>
    <paper id="6">
      <title>Prédiction des pauses dans les données d’écriture en temps réel</title>
      <author><first>Eshkol-taravella</first><last>Iris</last></author>
      <author><first>Manseri</first><last>Kehina</last></author>
      <author><first>Silai</first><last>Ioana-Madalina</last></author>
      <pages>28–33</pages>
      <abstract>Cette étude explore la prédiction des pauses dans des données d’écriture enregistrées en temps réel. Deux hypothèses sont testées : (1) les pauses dépendent du contenu lexical des bursts, et (2) les catégories morpho-syntaxiques (POS) influencent leur distribution. Après prétraitement linguistique, plusieurs techniques de classification sont testées. CamemBERT atteint jusqu’à 90 % de précision en classification binaire, suggérant un lien fort entre structure linguistique et pauses.</abstract>
      <url hash="78180ee7">2025.jeptalnrecital-dyntal.6</url>
      <language>fra</language>
      <bibkey>iris-etal-2025-prediction</bibkey>
    </paper>
  </volume>
  <volume id="ealm" ingest-date="2025-09-28" type="proceedings">
    <meta>
      <booktitle>Actes de l'atelier Ethic and Alignment of (Large) Language Models 2025 (EALM)</booktitle>
      <editor><first>Frédéric</first><last>Bechet</last></editor>
      <editor><first>Adrian-Gabriel</first><last>Chifu</last></editor>
      <editor><first>Karen</first><last>Pinel-sauvagnat</last></editor>
      <editor><first>Benoit</first><last>Favre</last></editor>
      <editor><first>Eliot</first><last>Maes</last></editor>
      <editor><first>Diana</first><last>Nurbakova</last></editor>
      <publisher>ATALA \\&amp; ARIA</publisher>
      <address>Marseille, France</address>
      <month>6</month>
      <year>2025</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="09b47a52">2025.jeptalnrecital-ealm.0</url>
      <bibkey>jep-taln-recital-2025-ealm</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Comment mesurer les biais politiques des grands modèles de langue multilingues?</title>
      <author><first>Paul</first><last>Lerner</last></author>
      <author><first>Laurène</first><last>Cave</last></author>
      <author><first>Hal</first><last>Daumé</last></author>
      <author><first>Léo</first><last>Labat</last></author>
      <author><first>Gaël</first><last>Lejeune</last></author>
      <author><first>Pierre-Antoine</first><last>Lequeu</last></author>
      <author><first>Benjamin</first><last>Piwowarski</last></author>
      <author><first>Nazanin</first><last>Shafiabadi</last></author>
      <author><first>François</first><last>Yvon</last></author>
      <pages>1–7</pages>
      <abstract>Nous proposons une nouvelle méthode pour mesurer les biais politiques des grands modèles de langue multilingues pour la traduction automatique, l’aide à la rédaction et le résumé automatique. Nous nous appuyons sur une représentation dense des opinions politiques exprimées dans les textes, apprise de façon faiblement supervisée.</abstract>
      <url hash="fc66cc06">2025.jeptalnrecital-ealm.1</url>
      <language>fra</language>
      <bibkey>lerner-etal-2025-comment</bibkey>
    </paper>
    <paper id="2">
      <title>La Boussole Cassée de l’Alignement Politique</title>
      <author><first>Noé</first><last>Durandard</last></author>
      <pages>8–11</pages>
      <abstract>L’évaluation, la réglementation et l’alignement des Grands Modèles de Langue (LLM) sur des questions politiques sont devenus des préoccupations cruciales alors que ces technologies se répandent de plus en plus dans tous les secteurs de la société. Cependant, des méthodologies et des fondements théoriques clairs font encore défaut. S’appuyant sur l’œuvre de Converse sur l’opinion publique, nous examinons de manière critique les pratiques courantes d’évaluation idéologique. Nous plaidons également pour des approches alternatives, plus étroites, mieux alignées sur les systèmes de croyances du grand public.</abstract>
      <url hash="505c1e49">2025.jeptalnrecital-ealm.2</url>
      <language>fra</language>
      <bibkey>durandard-2025-la</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>M</fixed-case>ascu<fixed-case>L</fixed-case>ead : le premier tableau de bord de biais de genre</title>
      <author><first>Fanny</first><last>Ducel</last></author>
      <author><first>Jeffrey</first><last>André</last></author>
      <author><first>Aurélie</first><last>Névéol</last></author>
      <author><first>Karën</first><last>Fort</last></author>
      <pages>12–19</pages>
      <abstract>Nous présentons MascuLead, le premier tableau de bord centré sur une tâche de détection de biais de genre pour les langues fleuries. Nous appliquons un cadre existant sur plusieurs Grands Modèles de Langue et comparons leurs performances. Nous soulignons également l’importance d’inclure des références de biais dans les tableaux de bord, et nous questionnons la notion même de tableaux de bord.</abstract>
      <url hash="cb2589d9">2025.jeptalnrecital-ealm.3</url>
      <language>fra</language>
      <bibkey>ducel-etal-2025-masculead</bibkey>
    </paper>
  </volume>
  <volume id="evalllm" ingest-date="2025-09-28" type="proceedings">
    <meta>
      <booktitle>Actes de l'atelier Évaluation des modèles génératifs (LLM) et challenge 2025 (EvalLLM)</booktitle>
      <editor><first>Frédéric</first><last>Bechet</last></editor>
      <editor><first>Adrian-Gabriel</first><last>Chifu</last></editor>
      <editor><first>Karen</first><last>Pinel-sauvagnat</last></editor>
      <editor><first>Benoit</first><last>Favre</last></editor>
      <editor><first>Eliot</first><last>Maes</last></editor>
      <editor><first>Diana</first><last>Nurbakova</last></editor>
      <publisher>ATALA \\&amp; ARIA</publisher>
      <address>Marseille, France</address>
      <month>6</month>
      <year>2025</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="68c6e14b">2025.jeptalnrecital-evalllm.0</url>
      <bibkey>jep-taln-recital-2025-evalllm</bibkey>
    </frontmatter>
    <paper id="1">
      <title>“<fixed-case>POPCORN</fixed-case>-<fixed-case>RENS</fixed-case> : un nouveau jeu de données en français annoté en entités d’intérêts sur une thématique "“sécurité et défense”""</title>
      <author><first>Lucas</first><last>Aubertin</last></author>
      <author><first>Guillaume</first><last>Gadek</last></author>
      <author><first>Gilles</first><last>Sérasset</last></author>
      <author><first>Maxime</first><last>Prieur</last></author>
      <author><first>Nakanyseth</first><last>Vuth</last></author>
      <author><first>Bruno</first><last>Grilheres</last></author>
      <author><first>Didier</first><last>Schwab</last></author>
      <author><first>Cédric</first><last>Lopez</last></author>
      <pages>1–10</pages>
      <abstract/>
      <url hash="56882296">2025.jeptalnrecital-evalllm.1</url>
      <language>fra</language>
      <bibkey>aubertin-etal-2025-popcorn</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>A</fixed-case>ll<fixed-case>S</fixed-case>ummed<fixed-case>U</fixed-case>p : un framework open-source pour comparer les métriques d’évaluation de résumé</title>
      <author><first>Tanguy</first><last>Herserant</last></author>
      <author><first>Vincent</first><last>Guigue</last></author>
      <pages>11–21</pages>
      <abstract>Cet article examine les défis de reproductibilité dans l’évaluation automatique des résumés de textes. À partir d’expériences menées sur six métriques représentatives allant de méthodes classiques comme ROUGE à des approches récentes basées sur les LLM (G-Eval, SEval-Ex), nous mettons en évidence des écarts notables entre les performances rapportées dans la littérature et celles observées dans notre cadre expérimental. Nous proposons un framework unifié et open-source, appliqué au jeu de données SummEval et ouvert à de futurs jeux de données, facilitant une comparaison équitable et transparente des métriques. Nos résultats révèlent un compromis structurel : les métriques les mieux alignées avec les jugements humains sont aussi les plus coûteuses en calculs et les moins stables. Au-delà de cette analyse comparative, notre étude met en garde contre l’utilisation croissante des LLM dans l’évaluation, en soulignant leur nature stochastique, leur dépendance technique et leur faible reproductibilité.</abstract>
      <url hash="60000d32">2025.jeptalnrecital-evalllm.2</url>
      <language>fra</language>
      <bibkey>herserant-guigue-2025-allsummedup</bibkey>
    </paper>
    <paper id="3">
      <title>Amélioration et Automatisation de la Génération des Cas de Tests Logiciels à l’Aide du Modèle Llama</title>
      <author><first>Imane</first><last>Moughit</last></author>
      <author><first>Imad</first><last>Hafidi</last></author>
      <pages>22–35</pages>
      <abstract>L’émergence des Large Language Models (LLM) a révolutionné l’ingénierie logicielle grâce à leurs capacités de compréhension et de génération du langage naturel. Bien qu’ils soient utilisés pour la génération automatique de cas de test, les approches actuelles reposant uniquement sur les méthodes focales ou sur des descriptions textuelles présentent des limites: elles peinent à capturer les comportements attendus, les cas limites et les scénarios d’erreur, et sont peu compatibles avec le développement piloté par les tests (TDD). Pour répondre à ces contraintes, nous proposons une approche hybride (Texte, Méthodes focales → Cas de test), combinant les commentaires présents dans le code avec la logique de la méthode cible. En exploitant le modèle LLaMA 3-8B et des techniques de prompt engineering, ainsi que l’évaluation des cas de test générés à l’aide d’un LLM en tant que juge, notre méthode vise à automatiser et améliorer la génération des cas de test. Testée sur des projets open source, elle a permis de générer 7 606 cas de test, avec un taux de correction syntaxique de 97 %.</abstract>
      <url hash="ce92322f">2025.jeptalnrecital-evalllm.3</url>
      <language>fra</language>
      <bibkey>moughit-hafidi-2025-amelioration</bibkey>
    </paper>
    <paper id="4">
      <title>Approche générative de la conformation pragmatique : une étude de cas de l’analyse d’une conférence</title>
      <author><first>Julien</first><last>Perez</last></author>
      <author><first>Idir</first><last>Benouaret</last></author>
      <pages>36–50</pages>
      <abstract>La relecture en double aveugle est centrale dans les conférences scientifiques, mais des biais persistent. OpenReview a introduit plus de transparence en rendant publics les articles, les évaluations et les décisions. Ce travail explore l’utilisation des grands modèles de langage (LLMs) pour assister différentes étapes du processus de relecture : production de méta-revues, détection de biais et de subjectivité dans les évaluations. L’étude s’appuie sur les données ICLR de 2017 à 2022 et inclut des analyses quantitatives et des évaluations humaines à l’aveugle. Les résultats visent à encourager une relecture scientifique plus efficace et équitable.</abstract>
      <url hash="23e01d05">2025.jeptalnrecital-evalllm.4</url>
      <language>fra</language>
      <bibkey>perez-benouaret-2025-approche</bibkey>
    </paper>
    <paper id="5">
      <title>Comment évaluer un grand modèle de langue dans le domaine médical en français ?</title>
      <author><first>Christophe</first><last>Servan</last></author>
      <author><first>Cyril</first><last>Grouin</last></author>
      <author><first>Aurélie</first><last>Névéol</last></author>
      <author><first>Pierre</first><last>Zweigenbaum</last></author>
      <pages>51–67</pages>
      <abstract>Les récentes avancées en Traitement Automatique des Langues liées aux grands modèles de langue (LLM) auto-régressifs investissent également les domaines spécialisés dont celui de la santé. Cette étude examine les questions qui se posent dans l’évaluation de LLM appliqués au domaine de la santé en se focalisant sur le français. Après un bref tour d’horizon des tâches et des données d’évaluation disponibles pour ce domaine de spécialité, l’article examine le mode d’évaluation des LLM dans des tâches de nature discriminante (détection d’entités nommées, classification de textes) et génératives (résumé de comptes rendus, génération de cas cliniques). L’article n’a pas vocation à rapporter une évaluation concrète, mais à discuter et préparer la méthodologie pour le faire.</abstract>
      <url hash="e8abf48f">2025.jeptalnrecital-evalllm.5</url>
      <language>fra</language>
      <bibkey>servan-etal-2025-comment</bibkey>
    </paper>
    <paper id="6">
      <title>Culture et acculturation des grands modèles de langue</title>
      <author><first>Mathieu</first><last>Valette</last></author>
      <pages>68–76</pages>
      <abstract>Il s’agira d’évaluer la place octroyée à la culture dans les travaux industriels et académiques portant sur la constitution de grands modèles de langue (LLMs), notamment lorsqu’il s’agit de les aligner. Le premier constat effectué est que la culture y est appréhendée de manière restreinte à des problématiques axiologiques (valeurs morales). Le deuxième constat est que les travaux actuels portant sur les cultures dans les LLMs se divisent en deux catégories : (i) évaluation des biais culturels par la confrontation à des référentiels culturels tiers, (ii) alignement axiologique. Nous discuterons des conséquences de ces orientations épistémologiques.</abstract>
      <url hash="f22a0052">2025.jeptalnrecital-evalllm.6</url>
      <language>fra</language>
      <bibkey>valette-2025-culture</bibkey>
    </paper>
    <paper id="7">
      <title>Décoder le pouvoir de persuasion dans les concours d’éloquence : une étude sur la capacité des modèles de langues à évaluer la prise de parole en public</title>
      <author><first>Alisa</first><last>Barkar</last></author>
      <author><first>Mathieu</first><last>Chollet</last></author>
      <author><first>Matthieu</first><last>Labeau</last></author>
      <author><first>Beatrice</first><last>Biancardi</last></author>
      <author><first>Chloé</first><last>Clavel</last></author>
      <pages>77–90</pages>
      <abstract>L’importance des compétences en prise de parole en public (PPP) stimule le développement de systèmes d’évaluation automatisée, mais l’intégration des grandes modèles de langue (LLMs) reste peu explorée. Nous proposons un cadre où les LLMs évaluent des critères issus de la littérature et de retours de formateurs. Nous testons trois approches : des prédictions LLM directes à zéro coup (RMSE 0, 8) par rapport à des prédictions de persuasion basées sur des caractéristiques lexicales fabriquées à la main (RMSE 0, 51) ou basées sur des critères évalués par LLM 0, 6 insérés en entrée dans ElasticNet. L’analyse des liens entre critères et caractéristiques lexicales montre que seul le critère de niveau de langue évalué par LLM est prévisible (score F1 de 0, 56) soulignant les limites actuelles des LLMs pour l’analyse de la PPP. Code source et données disponibles sur GitHub.</abstract>
      <url hash="f8862253">2025.jeptalnrecital-evalllm.7</url>
      <language>fra</language>
      <bibkey>barkar-etal-2025-decoder</bibkey>
    </paper>
    <paper id="8">
      <title>Des Prompts aux Profils: Evaluation de la qualité des données générées par <fixed-case>LLM</fixed-case> pour la classification des soft skills</title>
      <author><first>Elena</first><last>Rozera</last></author>
      <author><first>Nédra</first><last>Mellouli-Nauwynck</last></author>
      <author><first>Patrick</first><last>Leguide</last></author>
      <author><first>William</first><last>Morcombe</last></author>
      <pages>91–107</pages>
      <abstract>L’extraction automatique des soft skills à partir de CV constitue un enjeu central du Traitement Automatique du Langage Naturel (TALN) pour les ressources humaines. Toutefois, le manque de données annotées et les contraintes de confidentialité limitent le développement de modèles robustes. Cette étude préliminaire explore le potentiel des Grands Modèles de Langage (LLMs) pour générer des CV synthétiques dédiés à la classification des soft skills. Deux corpus sont proposés, un jeu de données de référence généré à partir de prompts explicites, et un corpus de CV complets produits selon une structure réaliste. Un cadre d’évaluation combinant des métriques avec et sans référence est mis en place, afin de mesurer la diversité, la redondance et la fidélité sémantique. Les résultats révèlent des compromis importants entre diversité lexicale et réalisme contextuel, apportant des pistes pour guider la génération future de données synthétiques pour la classification des compétences comportementales.</abstract>
      <url hash="f2107613">2025.jeptalnrecital-evalllm.8</url>
      <language>fra</language>
      <bibkey>rozera-etal-2025-des</bibkey>
    </paper>
    <paper id="9">
      <title>Étude des déterminants impactant la qualité de l’information géographique chez les <fixed-case>LLM</fixed-case>s : famille, taille, langue, quantization et fine-tuning</title>
      <author><first>Rémy</first><last>Decoupes</last></author>
      <author><first>Adrien</first><last>Guille</last></author>
      <pages>108–119</pages>
      <abstract>Nous analysons l’impact de plusieurs facteurs d’optimisation sur la qualité des informations géographiques contenues dans des grands modèles de langue (LLMs) : famille, taille, «quantization», «instruction fine-tuning», prompt et langue. Nous évaluons également la qualité des représentations internes, en particulier pour les modèles génératifs ayant des difficultés à suivre les instructions. Nos résultats montrent que la quantization dégrade nettement les performances, tandis que les versions conversationnelles («Instruct») perdent généralement en qualité d’informations par rapport à leur version «base», à l’exception des modèles de petite taille. L’ensemble de notre protocole d’évaluation est entièrement reproductible et disponible en accès libre.</abstract>
      <url hash="8aadaac7">2025.jeptalnrecital-evalllm.9</url>
      <language>fra</language>
      <bibkey>decoupes-guille-2025-etude</bibkey>
    </paper>
    <paper id="10">
      <title>Evaluating <fixed-case>LLM</fixed-case>s Efficiency Using Successive Attempts on Binary-Outcome Tasks</title>
      <author><first>Mohamed Amine</first><last>El Yagouby</last></author>
      <author><first>Mehdi</first><last>Zekroum</last></author>
      <author><first>Abdelkader</first><last>Lahmadi</last></author>
      <author><first>Mounir</first><last>Ghogho</last></author>
      <author><first>Olivier</first><last>Festor</last></author>
      <pages>120–126</pages>
      <abstract>Evaluating Large Language Models (LLMs) using single-attempt metrics like Success Rate (SR) overlooks their capacity for iterative problem solving. In tasks with binary outcomes (success or failure), such as coding or planning, LLMs often benefit from multiple attempts. Existing multiattempt metrics like pass@k and success@k account for eventual success but ignore how efficiently it is achieved, making them more costly. We propose a new evaluation method with Successive Multiple Attempts, where a maximum number of retries is fixed, and introduce our Success Efficiency (SE) metric, which captures both success and efficiency in a single value by rewarding earlier successes and penalizing delays. Tested using the HumanEval dataset across six LLMs, SE captures how quickly an LLM solves tasks, which existing metrics do not offer. This work complements existing evaluation methods by measuring not only whether LLMs succeed but also how efficiently they do so.</abstract>
      <url hash="6909f341">2025.jeptalnrecital-evalllm.10</url>
      <bibkey>el-yagouby-etal-2025-evaluating</bibkey>
    </paper>
    <paper id="11">
      <title>Évaluation Comparative de la Génération Contrainte vs. du Post-Parsing pour l’Analyse de Contenu par <fixed-case>LLM</fixed-case>s : Étude sur le Corpus <fixed-case>EU</fixed-case>vs<fixed-case>D</fixed-case>isinfo</title>
      <author><first>Kévin</first><last>Séjourné</last></author>
      <author><first>Marine</first><last>Foucher</last></author>
      <author><first>Alexandru</first><last>Lata</last></author>
      <author><first>Jean-Fabrice</first><last>Lebraty</last></author>
      <pages>127–137</pages>
      <abstract>Les Grands Modèles de Langage (LLM) sont de plus en plus intégrés dans des applications nécessitant des sorties formatées. Deux approches principales existent : instruire le LLM de générer directement la structure (e.g., JSON, SQL) puis la parser (post-parsing), ou utiliser des techniques de génération contrainte garantissant la syntaxe. Cette étude compare rigoureusement ces deux méthodes sur une tâche d’analyse de désinformation à grande échelle ( 17k documents du corpus EUvsDisinfo) en utilisant quatre LLM (Llama-3.3 70B, DeepSeek R1 70B, Qwen 72B, Gemma 3 27B) et plusieurs températures de génération. Nos résultats indiquent que la génération contrainte offre une fiabilité syntaxique quasi parfaite, tandis que le post-parsing est opérationnellement plus robuste mais génère davantage d’erreurs de formatage.</abstract>
      <url hash="298a7b7e">2025.jeptalnrecital-evalllm.11</url>
      <language>fra</language>
      <bibkey>sejourne-etal-2025-evaluation</bibkey>
    </paper>
    <paper id="12">
      <title>Évaluation automatique du retour à la source dans un contexte historique long et bruité. Application aux débats parlementaires de la Troisième République française</title>
      <author><first>Julien</first><last>Perez</last></author>
      <author><first>Aurélien</first><last>Pellet</last></author>
      <author><first>Marie</first><last>Puren</last></author>
      <pages>138–150</pages>
      <abstract>Dans le contexte de l’utilisation croissante des LLM, le besoin d’un retour efficace et automatique aux sources devient essentiel, en particulier pour les documents historiques. La capacité des LLM à identifier les sources pertinentes ne constitue plus seulement un maillon dans une chaîne où l’objectif final est la génération de réponses ; elle représente un enjeu fondamental de l’analyse, justifiant une évaluation à part entière. Quelles stratégies, quels modèles et quels paramètres offrent aux historiens les meilleures capacités d’exploration d’un corpus vaste et bruité ? Cet article propose une première tentative d’évaluation du retriever dans un cadre de RAG appliqué aux débats parlementaires de la Troisième République.</abstract>
      <url hash="4ead0278">2025.jeptalnrecital-evalllm.12</url>
      <language>fra</language>
      <bibkey>perez-etal-2025-evaluation</bibkey>
    </paper>
    <paper id="13">
      <title>Évaluation de la Robustesse des <fixed-case>LLM</fixed-case> : Proposition d’un Cadre Méthodologique et Développement d’un Benchmark</title>
      <author><first>Fares</first><last>Grina</last></author>
      <author><first>Natalia</first><last>Kalashnikova</last></author>
      <pages>151–163</pages>
      <abstract>L’évaluation fiable des grands modèles de langage (LLM) demeure un défi. Nous présentons un framework systématique, basé sur des tests de robustesse et une évaluation hybride. Il génère des variantes de benchmarks pour tester la stabilité des LLM. Les réponses sont évaluées par une double approche automatique (LLM-as-a-judge et une évaluation quantitative). Comme contexte applicatif pour ce type d’évaluation, nous présentons la création et l’annotation d’un benchmark pour l’extraction d’information à partir d’appels d’offres. Un mécanisme de détection compare ensuite les évaluations automatiques ; les désaccords importants déclenchent une expertise humaine ciblée. En agrégeant les scores automatiques cohérents et les jugements humains, notre approche vise à fournir une mesure de performance et de robustesse plus fiable. Ce processus quantifie également le taux de désaccord entre méthodes automatiques, offrant le potentiel pour une comparaison plus transparente et équitable des LLM.</abstract>
      <url hash="7062224e">2025.jeptalnrecital-evalllm.13</url>
      <language>fra</language>
      <bibkey>grina-kalashnikova-2025-evaluation</bibkey>
    </paper>
    <paper id="14">
      <title>Évaluation de la description automatique de scènes audio par la tâche d’Audio Question Answering</title>
      <author><first>Marcel</first><last>Gibier</last></author>
      <author><first>Raphaël</first><last>Duroselle</last></author>
      <author><first>Pierre</first><last>Serrano</last></author>
      <author><first>Olivier</first><last>Boëffard</last></author>
      <author><first>Jean-François</first><last>Bonastre</last></author>
      <pages>164–177</pages>
      <abstract>Nous explorons l’évaluation de la tâche de description automatique de scènes audio à travers une approche indirecte basée sur la réponse aux questions sur des documents audio. En l’absence de métriques d’évaluation robustes et automatiques pour la tâche de description automatique de scènes audio, nous nous appuyons sur le benchmark MMAU, un jeu de questions à choix multiple sur des extraits audio variés. Nous introduisons une architecture en cascade qui dépasse les performances de certains modèles de référence de taille comparable. Toutefois, nos résultats mettent en évidence des limitations du benchmark MMAU, notamment un biais textuel et une capacité limitée à évaluer l’intégration conjointe des informations relatives à la parole et aux événements sonores. Nous suggérons des pistes d’amélioration pour rendre les évaluations futures plus fidèles aux enjeux de la tâche de description automatique de scènes audio.</abstract>
      <url hash="33e0ecfc">2025.jeptalnrecital-evalllm.14</url>
      <language>fra</language>
      <bibkey>gibier-etal-2025-evaluation</bibkey>
    </paper>
    <paper id="15">
      <title>Evaluation de petits modèles de langues (<fixed-case>SLM</fixed-case>) sur un corpus de Sciences Humaines et Sociales (<fixed-case>SHS</fixed-case>) en français</title>
      <author><first>Sam</first><last>Vallet</last></author>
      <author><first>Philippe</first><last>Suignard</last></author>
      <pages>178–187</pages>
      <abstract>Cet article évalue une série de plusieurs petits modèles de langues (SLM) sur une tâche de classification de tweets en français. Plusieurs stratégies d’optimisation sont testées : différents prompts (zero-shot, few-shot), fine-tuning avec une couche de classification, présence ou non d’une couche LoRa. Les résultats obtenus avec le modèle Qwen optimisé rivalisent avec un modèle beaucoup plus gros, ce qui valide notre intérêt pour les petits modèles.</abstract>
      <url hash="0ea020ea">2025.jeptalnrecital-evalllm.15</url>
      <language>fra</language>
      <bibkey>vallet-suignard-2025-evaluation</bibkey>
    </paper>
    <paper id="16">
      <title>Évaluation pédagogique du code à l’aide de grands modèles de langage. Une étude comparative à grande échelle contre les tests unitaires</title>
      <author><first>Julien</first><last>Perez</last></author>
      <author><first>Anton</first><last>Conrad</last></author>
      <author><first>Elkoussy</first><last>Laïla</last></author>
      <pages>188–201</pages>
      <abstract>L’évaluation automatisée en éducation par projet pour l’apprentissage de la programmation s’appuie traditionnellement sur les tests unitaires pour juger les soumissions de code des étudiants, mettant l’accent sur la correction fonctionnelle. Cependant, ces tests négligent souvent des aspects qualitatifs du code, comme la lisibilité ou la modularité. Cette étude examine le potentiel des grands modèles de langage (LLM) pour évaluer les soumissions de programmation, en comparant leurs résultats à ceux des tests unitaires. À partir d’un grand ensemble de données de rendus d’étudiants à une collection de projets de développement logiciel, nous appliquons des analyses statistiques, modélisations prédictives, ainsi que plusieurs comparaisons pour évaluer l’efficacité des LLMs. Nos résultats mettent en évidence une corrélation significative entre les évaluations des LLMs, pour des prompts donnés, et les tests unitaires. Les modèles prédictifs montrent que les scores des LLMs peuvent être approximés à partir des résultats des tests unitaires, et les classements d’étudiants issus des deux approches sont fortement corrélés. Ces constats restent robustes même en présence de bruit injecté dans les rendus étudiants. Ces résultats suggèrent que les LLM, en capturant des dimensions supplémentaires de la performance, peuvent enrichir les cadres d’évaluation éducative, offrant une approche totale plus nuancée et complète.</abstract>
      <url hash="64390752">2025.jeptalnrecital-evalllm.16</url>
      <language>fra</language>
      <bibkey>perez-etal-2025-evaluation-pedagogique</bibkey>
    </paper>
    <paper id="17">
      <title>Exploration de stratégies de prédiction de la complexité lexicale en contexte multilingue à l’aide de modèles de langage génératifs et d’approches supervisées.</title>
      <author><first>Abdelhak</first><last>Kelious</last></author>
      <pages>202–203</pages>
      <abstract>Cet article explore des méthodes permettant de prédire automatiquement la complexité lexicale dans un contexte multilingue à l’aide de modèles avancés de traitement automatique du langage naturel. Plus précisément, il étudie l’utilisation de l’apprentissage par transfert et des techniques d’augmentation de données dans un cadre d’apprentissage supervisé, mettant en lumière l’intérêt notable des approches multilingues. Nous évaluons également le potentiel des grands modèles de langage génératifs pour la prédiction de la complexité lexicale. À travers différentes stratégies de requêtage (zero-shot, one-shot et prompts avec raisonnement en chaîne), nous analysons les performances des modèles dans plusieurs langues. Nos résultats montrent que, bien que les modèles génératifs obtiennent des performances prometteuses, leur qualité prédictive reste variable, et les modèles optimisés pour une tâche spécifique continuent de les surpasser lorsqu’ils disposent de données d’entraînement suffisantes.</abstract>
      <url hash="c8b740d1">2025.jeptalnrecital-evalllm.17</url>
      <language>fra</language>
      <bibkey>kelious-2025-exploration</bibkey>
    </paper>
    <paper id="18">
      <title>Générer pour mieux tester : vers des datasets diversifiés pour une évaluation fiable des systèmes de Question Answering</title>
      <author><first>Louis</first><last>Jourdain</last></author>
      <author><first>Skander</first><last>Hellal</last></author>
      <pages>204–227</pages>
      <abstract>L’évaluation des modèles d’IA générative repose sur des datasets contenant des valeurs de référence attendues pour une entrée donnée. Cependant, la constitution de ces jeux de données est un processus complexe et coûteux. Cet article explore la génération automatique de datasets de questions diversifiées pour tester notamment les systèmes de RAG (Retrieval Augmented Generation). Nous proposons un cadre méthodologique combinant modèles de langage à grande échelle (LLMs) et techniques traditionnelles de traitement du langage naturel (NLP) et de data science, incluant les graphes de connaissances, la similarité sémantique voire le topic modeling. L’approche proposée repose sur un système modulaire exploitant diverses sources documentaires et intégrant des mécanismes avancés de filtrage afin de garantir la qualité et la diversité des questions produites.</abstract>
      <url hash="3bb13161">2025.jeptalnrecital-evalllm.18</url>
      <language>fra</language>
      <bibkey>jourdain-hellal-2025-generer</bibkey>
    </paper>
    <paper id="19">
      <title>Peut-on faire confiance aux juges ? Validation de méthodes d’évaluation de la factualité par perturbation des réponses</title>
      <author><first>Giovanni</first><last>Gatti Pinheiro</last></author>
      <author><first>Sarra</first><last>Gharsallah</last></author>
      <author><first>Adèle</first><last>Robaldo</last></author>
      <author><first>Mariia</first><last>Tokareva</last></author>
      <author><first>Ilyana</first><last>Guendouz</last></author>
      <author><first>Raphaël</first><last>Troncy</last></author>
      <author><first>Paolo</first><last>Papotti</last></author>
      <author><first>Pietro</first><last>Michiardi</last></author>
      <pages>228–252</pages>
      <abstract>Évaluer la véracité des grands modèles de langage (LLMs) est essentiel pour de nombreuses applications. Cependant, nos outils d’évaluation sont-ils eux-mêmes fiables ? Malgré la prolifération des métriques de factualité, leur sensibilité et leur fiabilité restent peu étudiées. Cet article introduit un cadre de méta-évaluation qui teste systématiquement ces métriques en appliquant des corruptions contrôlées à des réponses de référence. Notre méthode génère des sorties classées selon des degrés connus de dégradation afin d’analyser comment les métriques capturent les variations subtiles de véracité. Nos expériences montrent que les méthodes disponibles dans les framework d’évaluation, telles que la métrique factual correctness de RAGAS, suivent mieux la dégradation que les approches de type LLM-as-judge. Nous proposons également une nouvelle variante de la métrique de factualité, à la fois compétitive et économique.</abstract>
      <url hash="cc6e0e0d">2025.jeptalnrecital-evalllm.19</url>
      <language>fra</language>
      <bibkey>gatti-pinheiro-etal-2025-peut</bibkey>
    </paper>
    <paper id="20">
      <title><fixed-case>S</fixed-case>uper<fixed-case>GPQA</fixed-case>-<fixed-case>HCE</fixed-case>-<fixed-case>FR</fixed-case> : un corpus spécialisé en français pour le domaine hydraulique et le génie civil</title>
      <author><first>Markarit</first><last>Vartampetian</last></author>
      <author><first>Diandra</first><last>Fabre</last></author>
      <author><first>Philippe</first><last>Mulhem</last></author>
      <author><first>Sylvain</first><last>Joubert</last></author>
      <author><first>Didier</first><last>Schwab</last></author>
      <pages>253–276</pages>
      <abstract>Dans cet article, nous présentons SuperGPQA-HCE-FR, une adaptation française d’un sous-ensemble du benchmark SuperGPQA axé sur les domaines de l’ingénierie hydraulique et du génie civil. Il comprend 285 questions à choix multiples conçues pour évaluer et spécialiser des modèles de langue multilingues de grande taille (LLMs) sur des tâches techniques. La traduction réalisée automatiquement est ensuite évaluée par des experts des domaines. Enfin, nous présentons les premiers résultats sur des modèles Instruct généralistes multilingues en comparant les performances du corpus original en anglais à celles du corpus traduit en français.</abstract>
      <url hash="1b0a9797">2025.jeptalnrecital-evalllm.20</url>
      <language>fra</language>
      <bibkey>vartampetian-etal-2025-supergpqa</bibkey>
    </paper>
    <paper id="21">
      <title>Une Approche Linguistique pour l’Évaluation des Caractéristiques du Langage Parlé dans les Modèles Conversationnels</title>
      <author><first>Oussama</first><last>Silem</last></author>
      <author><first>Maïwenn</first><last>Fleig</last></author>
      <author><first>Philippe</first><last>Blache</last></author>
      <author><first>Houda</first><last>Oufaida</last></author>
      <author><first>Leonor</first><last>Becerra-Bonache</last></author>
      <pages>277–290</pages>
      <abstract>L’étude du traitement du langage et de ses bases cognitives chez l’humain repose de plus en plus sur des modèles de langue adaptés. Cependant, la majorité des modèles existants sont principalement entraînés sur des données écrites, ce qui limite leur pertinence pour l’étude du langage tel qu’il se manifeste dans des contextes naturels, comme lors de conversations spontanées. En effet, ces modèles ne sont pas entraînés pour traiter avec précision les caractéristiques spécifiques du langage parlé, telles que les disfluences et les hésitations. Dans cet article, nous proposons un ensemble de métriques inspirées par la recherche linguistique afin d’évaluer certains phénomènes du langage parlé (feedback, répétition et hésitation) dans des énoncés générés par différents modèles de langue, à travers une comparaison statistique avec des corpus de conversations humaines. Nos résultats, obtenus sur de petits modèles de langue fine-tunés sur des données de conversations parlées en français et en anglais, démontrent le potentiel de ces métriques pour évaluer la similarité des séquences générées avec celles produites par des locuteurs humains.</abstract>
      <url hash="89cd7144">2025.jeptalnrecital-evalllm.21</url>
      <language>fra</language>
      <bibkey>silem-etal-2025-une</bibkey>
    </paper>
    <paper id="22">
      <title>Vers une évaluation rigoureuse des systèmes <fixed-case>RAG</fixed-case> : le défi de la due diligence</title>
      <author><first>Grégoire</first><last>Martinon</last></author>
      <author><first>Alexandra</first><last>De Brionne Lorenzo</last></author>
      <author><first>Jérôme</first><last>Bohard</last></author>
      <author><first>Antoine</first><last>Lojou</last></author>
      <author><first>Damien</first><last>Hervault</last></author>
      <author><first>Nicolas</first><last>Brunel</last></author>
      <pages>291–308</pages>
      <abstract>L’IA générative se déploie dans des secteurs à haut risque comme la santé et la finance. L’architecture RAG (Retrieval Augmented Generation), qui combine modèles de langage (LLM) et moteurs de recherche, se distingue par sa capacité à générer des réponses à partir de corpus documentaires. Cependant, la fiabilité de ces systèmes en contextes critiques demeure préoccupante, notamment avec des hallucinations persistantes. Cette étude évalue un système RAG déployé chez un fonds d’investissement pour assister les due diligence. Nous proposons un protocole d’évaluation robuste combinant annotations humaines et LLM-Juge pour qualifier les défaillances du système, comme les hallucinations, les hors-sujets, les citations défaillantes ou les abstentions. Inspirés par la méthode Prediction Powered Inference (PPI), nous obtenons des mesures de performance robustes avec garanties statistiques. Nous fournissons le jeu de données complet. Nos contributions visent à améliorer la fiabilité et la scalabilité des protocoles d’évaluations de systèmes RAG en contexte industriel.</abstract>
      <url hash="33e53419">2025.jeptalnrecital-evalllm.22</url>
      <language>fra</language>
      <bibkey>martinon-etal-2025-vers</bibkey>
    </paper>
  </volume>
  <volume id="iaedu" ingest-date="2025-09-28" type="proceedings">
    <meta>
      <booktitle>Actes de l'atelier Intelligence Artificielle générative et ÉDUcation : Enjeux, Défis et Perspectives de Recherche 2025 (IA-ÉDU)</booktitle>
      <editor><first>Frédéric</first><last>Bechet</last></editor>
      <editor><first>Adrian-Gabriel</first><last>Chifu</last></editor>
      <editor><first>Karen</first><last>Pinel-sauvagnat</last></editor>
      <editor><first>Benoit</first><last>Favre</last></editor>
      <editor><first>Eliot</first><last>Maes</last></editor>
      <editor><first>Diana</first><last>Nurbakova</last></editor>
      <publisher>ATALA \\&amp; ARIA</publisher>
      <address>Marseille, France</address>
      <month>6</month>
      <year>2025</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="2e30cfaf">2025.jeptalnrecital-iaedu.0</url>
      <bibkey>jep-taln-recital-2025-iaedu</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Accessibilité visuelle et éducation inclusive : Étude préliminaire sur la génération de textes alternatifs</title>
      <author><first>Elise</first><last>Lincker</last></author>
      <author><first>Elisabeth</first><last>Olamisan</last></author>
      <author><first>Theodora</first><last>Pazakou</last></author>
      <author><first>Michèle</first><last>Gouiffès</last></author>
      <author><first>Camille</first><last>Guinaudeau</last></author>
      <author><first>Frédéric</first><last>Dufaux</last></author>
      <pages>1–9</pages>
      <abstract>Tout contenu numérique devrait garantir l’accessibilité visuelle en incluant des textes alternatifs aux images. En l’absence de système et de métrique d’évaluation adaptés, nous présentons nos recherches préliminaires sur la génération et l’évaluation de textes alternatifs, d’abord dans un contexte générique. Dans une démarche d’inclusion scolaire, nous mettons en lumière les limites des systèmes existants et les contraintes à prendre en compte pour envisager un système applicable aux manuels scolaires.</abstract>
      <url hash="e4520f9b">2025.jeptalnrecital-iaedu.1</url>
      <language>fra</language>
      <bibkey>lincker-etal-2025-accessibilite</bibkey>
    </paper>
    <paper id="2">
      <title>Annotation de résumés oraux d’élèves de primaire pour l’analyse automatique des capacités de compréhension de la lecture</title>
      <author><first>Etienne</first><last>Labbé</last></author>
      <author><first>Brice</first><last>Brossette</last></author>
      <author><first>Nathalie</first><last>Camelin</last></author>
      <author><first>Tiphaine</first><last>Caudrelier</last></author>
      <author><first>Eddy</first><last>Cavalli</last></author>
      <author><first>Isabelle</first><last>Ferrané</last></author>
      <author><first>Barbara</first><last>Lutz</last></author>
      <author><first>Véronique</first><last>Moriceau</last></author>
      <author><first>Thomas</first><last>Pellegrini</last></author>
      <author><first>Julien</first><last>Pinquier</last></author>
      <author><first>Cantin</first><last>Prat</last></author>
      <author><first>Lucile</first><last>Gelin</last></author>
      <pages>10–16</pages>
      <abstract>Le projet CHICA-AI vise à construire une activité assistée par ordinateur pour l’entraînement des compétences de compréhension de la lecture des élèves de primaire. Cette activité consiste à demander à l’élève de résumer à l’oral un texte narratif, afin d’identifier ses difficultés de compréhension et fournir un retour personnalisé à l’élève et à son enseignant. Pour cela, nous mettrons en place un système automatique d’analyse fine des résumés oraux, capable d’extraire les informations pertinentes et de les combiner pour remplir une grille de critères pédagogiques et psycho-cognitifs. Nous présentons ici les défis du projet, ainsi que les premiers travaux réalisés : création de l’activité dans la plateforme Lalilo et du contenu pédagogique, collecte d’enregistrements audios, construction du protocole d’annotation. Nous présentons enfin les analyses préliminaires faites sur les premières annotations, qui serviront à l’entraînement et l’évaluation de notre système automatique.</abstract>
      <url hash="5874a2c8">2025.jeptalnrecital-iaedu.2</url>
      <language>fra</language>
      <bibkey>labbe-etal-2025-annotation</bibkey>
    </paper>
    <paper id="3">
      <title>Apprentissage par renforcement contraint guidé par un graphe de connaissances pour personnaliser les parcours d’apprentissage</title>
      <author><first>Rania</first><last>Ait Chabane</last></author>
      <author><first>Armelle</first><last>Brun</last></author>
      <author><first>Azim</first><last>Roussanaly</last></author>
      <pages>17–20</pages>
      <abstract>Ce travail présente une architecture d’apprentissage adaptatif combinant graphes de connaissances enrichis et contraintes pédagogiques dans un cadre d’apprentissage par renforcement. Le graphe est construit à partir de ressources expertes (ex. manuel scolaire) et enrichi automatiquement par un modèle de langage pour compléter les relations et inférer des contraintes. Un module de knowledge tracing estime la progression de l’apprenant vers un objectif pédagogique donné. Un agent de renforcement, entraîné en environnement simulé, recommande des activités en maximisant la progression attendue tout en respectant les contraintes. Cette approche vise à renforcer la pertinence, la diversité et l’explicabilité des parcours proposés. Une évaluation sur des jeux de données réels est prévue en travaux futurs.</abstract>
      <url hash="b2577595">2025.jeptalnrecital-iaedu.3</url>
      <language>fra</language>
      <bibkey>ait-chabane-etal-2025-apprentissage</bibkey>
    </paper>
    <paper id="4">
      <title>Découverte de l’intelligence artificielle par des directeurs et directrices d’école primaire : une étude de cas dans deux circonscriptions marseillaises</title>
      <author><first>Hervé</first><last>Allesant</last></author>
      <author><first>Ismail</first><last>Badache</last></author>
      <author><first>Maria</first><last>Impedovo</last></author>
      <pages>21–28</pages>
      <abstract>Cet article présente une étude préliminaire sur l’engagement de directeurs et directrices d’écoles primaires à Marseille (France) vis-à-vis de l’intelligence artificielle (IA), en particulier de l’IA générative, dans le cadre du numérique éducatif et de la transformation digitale de l’école. L’étude analyse un atelier de formation visant à introduire l’évolution historique de l’IA, ses fondements ainsi que ses applications pédagogiques. Les résultats, issus de questionnaires administrés avant et après l’intervention, montrent que, malgré une connaissance initiale limitée des technologies d’IA, les participants ont manifesté un intérêt croissant pour l’exploration de ces outils, principalement dans une optique de gain de temps, tout en conservant une méfiance marquée. L’étude souligne la nécessité de formations contextualisées, combinant connaissances et compétences techno-pédagogiques en IA et réflexion critique, et appelle à une prise en compte des enjeux éthiques et des cadres de gouvernance pour une intégration responsable de l’IA en éducation.</abstract>
      <url hash="971a3214">2025.jeptalnrecital-iaedu.4</url>
      <language>fra</language>
      <bibkey>allesant-etal-2025-decouverte</bibkey>
    </paper>
    <paper id="5">
      <title>Exploration du <fixed-case>RAG</fixed-case> pour la génération de réponses à des questions en contexte éducatif: étude sur les données <fixed-case>SCIQ</fixed-case></title>
      <author><first>Sarah</first><last>Nouali</last></author>
      <author><first>Ismail</first><last>Badache</last></author>
      <author><first>Patrice</first><last>Bellot</last></author>
      <pages>29–41</pages>
      <abstract>Les systèmes basés sur le RAG (Retrieval-Augmented Generation) sont des systèmes qui optimisent la puissance des grands modèles de langue (LLM, en anglais, Large Language Models) avec une recherche d’information (RI) à partir de sources de connaissances externes, sans avoir besoin de réentraîner le modèle. Ce type d’approche est connu pour améliorer les réponses du LLM, en particulier pour répondre à des questions spécifiques à un domaine, et réduire le phénomène d’hallucination constaté avec ces derniers. Dans cet article, nous explorons l’application d’un tel système dans un contexte pédagogique, en utilisant le jeu de données SCIQ (SCIence Questions), un ensemble de questions scientifiques à choix multiples de niveau scolaire, qui nous permet d’évaluer la capacité des modèles à fournir des réponses précises, pédagogiques et vérifiables. Nous évaluons les performances du système par rapport à un modèle génératif standard (Llama3 8b et Mistral 7b) de réponse aux questions et analysons ses forces et ses limites dans un contexte éducatif. La performance la plus élevée en termes de précision a été enregistrée avec l’approche basée sur le RAG (rag-llama), qui a permis d’atteindre une précision globalement supérieure par rapport aux autres approches testées.</abstract>
      <url hash="7523088a">2025.jeptalnrecital-iaedu.5</url>
      <language>fra</language>
      <bibkey>nouali-etal-2025-exploration</bibkey>
    </paper>
    <paper id="6">
      <title><fixed-case>I</fixed-case>nit<fixed-case>IA</fixed-case>tion : développer l’agentivité numérique au collégial à l’ère de l’intelligence artificielle générative</title>
      <author><first>Fanny</first><last>Joussemet</last></author>
      <pages>42–62</pages>
      <abstract>Cet article présente la genèse, le cadre conceptuel et les principes pédagogiques de la trousse InitIAtion, conçue pour accompagner les étudiantes et étudiants du collégial dans un usage critique, responsable et créatif de l’intelligence artificielle générative (IAg). Issu de consultations et d’expérimentations menées au Cégep de Saint-Laurent, ce projet répond à un besoin identifié de formation structurée, face à une adoption rapide de l’IAg dans les pratiques étudiantes. Appuyé sur le référentiel international de l’UNESCO et sur les recommandations du Conseil supérieur de l’éducation du Québec, InitIAtion se structure autour des compétences associées au métier d’étudiant. Proposée sous forme modulaire, adaptable à divers contextes disciplinaires, la trousse de formation vise à développer l’agentivité numérique, la pensée critique et l’autonomie des étudiantes et des étudiants. L’article discute également des modalités d’implantation, dans une logique de mutualisation interordres, et appelle à une appropriation contextualisée de l’outil par les établissements d’enseignement supérieur québécois.</abstract>
      <url hash="03bc94fc">2025.jeptalnrecital-iaedu.6</url>
      <language>fra</language>
      <bibkey>joussemet-2025-initiation</bibkey>
    </paper>
    <paper id="7">
      <title>Intégration encadrée de l’<fixed-case>IA</fixed-case> générative dans une activité d’apprentissage par problème en école d’ingénieur</title>
      <author><first>Christophe</first><last>Tilmant</last></author>
      <author><first>Susan</first><last>Arbon-Leahy</last></author>
      <pages>63–69</pages>
      <abstract>Cet article présente une expérimentation pédagogique menée dans une école d’ingénieurs en informatique visant à encadrer l’usage de l’Intelligence Artificielle Générative (IAG) dans le cadre d’une activité d’apprentissage par problème. Intégrée à une Situation d’Apprentissage et d’Évaluation (SAÉ) de première année (niveau L3), l’activité proposée s’appuie sur l’analyse d’un brevet en anglais décrivant un algorithme de reconnaissance musicale de type Shazam. À partir de ce document, les étudiants sont amenés à produire un glossaire technique bilingue, en interaction réflexive avec une IAG. Le dispositif vise à développer conjointement des compétences disciplinaires (traitement du signal, mathématiques appliquées), linguistiques (anglais scientifique) et transversales (analyse distanciée, réflexivité sur l’usage des outils d’IAG). Les résultats observés montrent une forte implication des étudiants, une qualité linguistique et technique des productions, ainsi qu’une capacité à identifier et discuter les apports et limites de l’IAG. Cette activité constitue une première étape vers une intégration systémique et réfléchie des IAG dans les cursus d’ingénierie.</abstract>
      <url hash="f7dec874">2025.jeptalnrecital-iaedu.7</url>
      <language>fra</language>
      <bibkey>tilmant-arbon-leahy-2025-integration</bibkey>
    </paper>
    <paper id="8">
      <title>L’émergence de l’<fixed-case>IA</fixed-case> conversationnelle comme autorité cognitive : perspectives éducatives et éthiques à l’ère de Grok</title>
      <author><first>Amélie</first><last>Raoul</last></author>
      <pages>70–78</pages>
      <abstract>Cet article analyse l’émergence d’une nouvelle autorité cognitive incarnée par les intelligences artificielles conversationnelles, en se concentrant sur le cas de Grok. Positionnée comme alternative idéologique aux modèles existants, cette IA illustre comment nous déléguons de plus en plus notre jugement à des algorithmes perçus comme objectifs ou omniscients. En interrogeant les implications éducatives, éthiques et épistémologiques de cette évolution, l’article met en lumière les risques d’une dépendance envers des systèmes dont le fonctionnement reste obscur. Il plaide en faveur d’une littératie algorithmique appliquée, d’une pédagogie de l’incertitude algorithmique et d’un outillage critique capable d’outrepasser la fascination technologique pour favoriser une réflexion autonome face aux technologies d’IA.</abstract>
      <url hash="52bf759f">2025.jeptalnrecital-iaedu.8</url>
      <language>fra</language>
      <bibkey>raoul-2025-lemergence</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>MALIN</fixed-case> : <fixed-case>MA</fixed-case>nuels sco<fixed-case>L</fixed-case>aires <fixed-case>IN</fixed-case>clusifs</title>
      <author><first>Elise</first><last>Lincker</last></author>
      <author><first>Léa</first><last>Pacini</last></author>
      <author><first>Mohamed</first><last>Amine Lasheb</last></author>
      <author><first>Olivier</first><last>Pons</last></author>
      <author><first>Jérôme</first><last>Dupire</last></author>
      <author><first>Camille</first><last>Guinaudeau</last></author>
      <author><first>Céline</first><last>Hudelot</last></author>
      <author><first>Vincent</first><last>Mousseau</last></author>
      <author><first>Isabelle</first><last>Barbet</last></author>
      <author><first>Caroline</first><last>Huron</last></author>
      <pages>79–82</pages>
      <abstract>L’accès aux manuels scolaires constitue un enjeu majeur pour l’éducation inclusive. Le projet MALIN vise à automatiser l’adaptation des manuels scolaires, convertissant un manuel numérique au format PDF en une version structurée, puis en une version accessible. Le projet cible en priorité la dyspraxie, tout en posant les bases d’adaptations pour d’autres handicaps. Les adaptations proposées, conçues avec des experts de l’accessibilité, sont évaluées auprès d’enfants en situation de handicap.</abstract>
      <url hash="9dcccf62">2025.jeptalnrecital-iaedu.9</url>
      <language>fra</language>
      <bibkey>lincker-etal-2025-malin</bibkey>
    </paper>
    <paper id="10">
      <title>Profilage comportemental dans les jeux vidéo éducatifs via des réseaux convolutifs graphiques : le cas de <fixed-case>G</fixed-case>rapho<fixed-case>G</fixed-case>ame<fixed-case>F</fixed-case>rançais</title>
      <author><first>Emna</first><last>Ammari</last></author>
      <author><first>Patrice</first><last>Bellot</last></author>
      <author><first>Ambre</first><last>Denis-Noël</last></author>
      <author><first>Johannes</first><last>C. Ziegler</last></author>
      <pages>83–93</pages>
      <abstract>Les données comportementales des jeux vidéo ainsi que les traces de joueurs suscitent un intérêt croissant, tant pour la recherche que pour l’industrie du jeu. Ces données peuvent notamment enrichir l’expérience de jeu et améliorer l’identification automatique des profils des joueurs. Dans cet article, nous nous intéressons principalement aux données du jeu sérieux GraphoGame, un outil innovant d’aide à l’apprentissage de la lecture, offrant un environnement interactif pour les apprenants. Nous cherchons notamment à évaluer l’impact de ce jeu sur la performance des élèves en lecture via le profilage comportemental des joueurs et un apprentissage à base de graphes. Ainsi, deux techniques d’intégration basées sur des réseaux convolutifs, GraphSAGE et ECCConv, sont mises à profit pour classifier les graphes d’interactions des joueurs. Les résultats montrent qu’ECCConv surpasse GraphSAGE, mais que leurs prédictions combinées peuvent améliorer la classification, confirmant l’impact éducatif de GraphoGame même chez les élèves les plus avancés.</abstract>
      <url hash="9c2c0b7e">2025.jeptalnrecital-iaedu.10</url>
      <language>fra</language>
      <bibkey>ammari-etal-2025-profilage</bibkey>
    </paper>
    <paper id="11">
      <title>Recommandation de tests multi-objectifs pour l’apprentissage adaptatif</title>
      <author><first>Nassim</first><last>Bouarour</last></author>
      <author><first>Idir</first><last>Benouaret</last></author>
      <author><first>Sihem</first><last>Amer-Yahia</last></author>
      <pages>94–97</pages>
      <abstract>L’amélioration des compétences (upskilling) est un segment en forte croissance en éducation. Pourtant, peu de travaux algorithmiques se concentrent sur l’élaboration de stratégies dédiées pour atteindre une maîtrise avancée des compétences. Dans cet article, nous formalisons AdUp, un problème d’amélioration itérative des compétences combinant l’apprentissage par maîtrise et la théorie de la Zone de Développement Proximal. Nous étendons nos travaux précédents et concevons deux solutions pour AdUp : MOO et MAB.MOO est une approche d’optimisation multi-objectifs qui utilise une méthode de Hill Climbing pour adapter la difficulté des tests recommandés selon 3 objectifs : la performance prédite de l’apprenant, son aptitude, et son gap. MAB est une approche basée sur les bandits manchots (Multi-Armed Bandits) permettant d’apprendre la meilleure combinaison d’objectifs à optimiser à chaque itération. Nous montrons comment ces solutions peuvent être couplées avec deux modèles courants de simulation d’apprenants : BKT et IRT. Nos expérimentations démontrent la nécessité de prendre en compte les 3 objectifs et d’adapter dynamiquement les objectifs d’optimisation aux capacités de progression de l’apprenant, car MAB permet un taux de maîtrise plus élevé.</abstract>
      <url hash="bd6b89e3">2025.jeptalnrecital-iaedu.11</url>
      <language>fra</language>
      <bibkey>bouarour-etal-2025-recommandation</bibkey>
    </paper>
    <paper id="12">
      <title>Repenser les pratiques d’enseignement et d’apprentissage par la robotique éducative : le cas du robot socio-émotionnel Buddy</title>
      <author><first>Ismail</first><last>Badache</last></author>
      <author><first>Elisabeth</first><last>Colombo</last></author>
      <pages>98–110</pages>
      <abstract>Cet article explore l’utilisation de Buddy dans un contexte éducatif et d’apprentissage, avec un focus particulier sur deux usages. Premièrement, à l’Institut National Supérieur du Professorat et de l’Éducation d’Aix-Marseille avec des étudiants futurs profs des écoles, collèges et lycées ainsi que des étudiants en ingénierie pédagogique numérique. Deuxièmement, dans un contexte spécifique comme médiateur artistique et émotionnel dans l’apprentissage de l’art. Cet article s’intéresse à la façon dont ce robot peut enrichir les pratiques pédagogiques en stimulant la créativité, l’interaction et l’accompagnement pédagogique et émotionnel des apprenants. Buddy peut agir comme médiateur entre l’apprenant et son environnement, en particulier dans les domaines de la narration, de l’art et de l’assistance informationnelle. Cette expérimentation du robot Buddy, met en lumière les possibilités de la robotique dans le développement de pratiques pédagogiques inclusives, où l’art et la technologie convergent pour favoriser l’apprentissage et la résilience émotionnelle. À travers ces expériences, le robot devient un catalyseur d’apprentissage et de réflexion, tout en ouvrant des perspectives pour une recherche interdisciplinaire impliquant l’ingénierie informatique, la psychologie et l’éducation. Les limites techniques actuelles de Buddy, loin d’être des obstacles, offrent des opportunités pour concevoir des scénarios pédagogiques visant à démythifier l’intelligence artificielle, en mettant en lumière ses biais et ses limitations.</abstract>
      <url hash="4aa5b1b3">2025.jeptalnrecital-iaedu.12</url>
      <language>fra</language>
      <bibkey>badache-colombo-2025-repenser</bibkey>
    </paper>
    <paper id="13">
      <title><fixed-case>SEPT</fixed-case> : Détecter les difficultés des étudiants à travers le clustering de leurs trajectoires émotionnelles et physique lors d’évaluations en ligne sur <fixed-case>M</fixed-case>oodle</title>
      <author><first>Edouard</first><last>Nadaud</last></author>
      <author><first>Antoun</first><last>Yaacoub</last></author>
      <author><first>Bénédicte</first><last>Legrand</last></author>
      <author><first>Lionel</first><last>Prevost</last></author>
      <pages>111–125</pages>
      <abstract>Imaginez une salle de classe où les difficultés et réussites des étudiants s’expriment non par des mots, mais par l’expression de leurs visages et mouvements, captés en temps réel pendant un quiz. Les méthodes d’enseignement dans le supérieur se font de plus en plus hybride et à distance. Les interactions directes sont réduites, rendant difficile la détection des moments de décrochage. Pour y remédier, nous introduisons le concept de Trajectoires Émotionnelles et Physiques Étudiantes (SEPT). Grâce aux webcams de 89 étudiants de première année de Master, nous avons enregistré et analysé chaque seconde leurs expressions faciales (valence, arousal selon le modèle de Russell) et états physiques (orientation de la tête, distance à l’écran). Les séries temporelles ainsi obtenues révèlent des motifs distincts selon que les difficultés soient individuelles ou liées aux questions. SEPT offres des perspectives pour des systèmes intelligents de suivi affectif en contexte éducatif numérique.</abstract>
      <url hash="4e459562">2025.jeptalnrecital-iaedu.13</url>
      <language>fra</language>
      <bibkey>nadaud-etal-2025-sept</bibkey>
    </paper>
    <paper id="14">
      <title>Stimuler la Pensée Étudiante avec l’<fixed-case>AQG</fixed-case> : Vers une Génération Automatique de Questions de Type Étudiant</title>
      <author><first>Abdelbassat</first><last>Labeche</last></author>
      <author><first>Sébastien</first><last>Fournier</last></author>
      <pages>126–132</pages>
      <abstract>Les systèmes de génération automatique de questions (AQG) sont largement utilisés dans les contextes éducatifs pour évaluer les connaissances. Ces systèmes se concentrent presque exclusivement sur des questions de type enseignant, structurées et factuelles. Cet article propose une approche novatrice, le Student-AQG, qui vise à simuler des questions spontanées qu’un étudiant réel pourrait poser, reflétant ses incompréhensions, sa curiosité ou ses besoins d’approfondissement. En nous appuyant sur les travaux récents en génération de questions autonomes, nous concevons un système modulaire basé sur des LLMs guidés par du prompt engineering, tenant compte du profil cognitif de l’apprenant. Nous décrivons une stratégie d’évaluation combinant des métriques automatiques et des annotations humaines sur la fluidité, la pertinence et la valeur pédagogique. Ce travail vise à aider les élèves à formuler des questions, développant ainsi leur pensée critique, une compétence essentielle souvent négligée à cause du faible questionnement spontané observé en classe.</abstract>
      <url hash="7425372f">2025.jeptalnrecital-iaedu.14</url>
      <language>fra</language>
      <bibkey>labeche-fournier-2025-stimuler</bibkey>
    </paper>
    <paper id="15">
      <title>Un outil conversationnel basé sur un graphe de connaissances, des <fixed-case>LLM</fixed-case> et un modèle <fixed-case>BERT</fixed-case> pour les programmes d’alternance en <fixed-case>F</fixed-case>rance</title>
      <author><first/><last>Mbaye</last></author>
      <author><first>Diana</first><last>Nurbakova</last></author>
      <author><first>Duaa</first><last>Baig</last></author>
      <pages>133–144</pages>
      <abstract>Le suivi efficace de l’acquisition des compétences dans les programmes de l’alternance, présente des défis importants pour la technologie éducative. Cet article présente un nouvel agent conversationnel intégré dans un livret de formation numérique qui relève ces défis grâce à une architecture multimodale. Notre système intègre (1) un graphe de connaissances spécifique à un domaine, lié à des référentiels de compétences, (2) des grands modèles de langage (LLM) et (3) un composant génératif basé sur BERT. Cette approche hybride permet à la fois une représentation structurée des trajectoires d’apprentissage et des capacités d’interaction en langage naturel, ce qui permet un suivi nuancé des progrès et des interventions personnalisées. L’évaluation empirique démontre que le système fournit un retour d’information contextuellement pertinent qui s’adapte aux modèles d’apprentissage individuels, ce qui permet une acquisition plus efficace des compétences.</abstract>
      <url hash="6f399820">2025.jeptalnrecital-iaedu.15</url>
      <language>fra</language>
      <bibkey>mbaye-etal-2025-un</bibkey>
    </paper>
    <paper id="16">
      <title>Une approche hybride de l’<fixed-case>IA</fixed-case> pour les technologies éducatives : augmenter les <fixed-case>STI</fixed-case> avec l’<fixed-case>IA</fixed-case> générative</title>
      <author><first>Sofiya</first><last>Kobylyanskaya</last></author>
      <author><first>Pierre-Yves</first><last>Oudeyer</last></author>
      <author><first>Catherine</first><last>de Vulpillières</last></author>
      <pages>145–148</pages>
      <abstract>Nous proposons une approche hybride de l’IA au service de l’éducation, en combinant la personnalisation offerte par les Systèmes de Tutorat Intelligents (STI) avec de l’IA générative permettant de générer un grand nombre de contenus éducatifs de qualité, tout en respectant les contraintes pédagogiques et cognitives.</abstract>
      <url hash="ace7483e">2025.jeptalnrecital-iaedu.16</url>
      <language>fra</language>
      <bibkey>kobylyanskaya-etal-2025-une</bibkey>
    </paper>
    <paper id="17">
      <title>Vers des <fixed-case>RAG</fixed-case>s intégrant véracité, subjectivité et explicabilité</title>
      <author><first>Alae</first><last>Bouchiba</last></author>
      <author><first>Adrian-Gabriel</first><last>Chifu</last></author>
      <author><first>Sébastien</first><last>Fournier</last></author>
      <author><first>Lorraine</first><last>Goeuriot</last></author>
      <author><first>Philippe</first><last>Mulhem</last></author>
      <pages>149–155</pages>
      <abstract>Cet article introduit X-RAG-VS , un cadre pour intégrer véracité , subjectivité et explicabilité dans les systèmes RAG , en réponse aux besoins éducatifs. À travers des cas d’usage et l’analyse de modèles existants , nous montrons que ces dimensions restent insuffisamment prises en compte. Nous proposons une approche unifiée pour des réponses plus fiables , nuancées et explicables.</abstract>
      <url hash="1fd256f3">2025.jeptalnrecital-iaedu.17</url>
      <language>fra</language>
      <bibkey>bouchiba-etal-2025-vers</bibkey>
    </paper>
  </volume>
  <volume id="mlpllm" ingest-date="2025-09-28" type="proceedings">
    <meta>
      <booktitle>Actes de l'atelier Traitement du langage médical à l’époque des LLMs 2025 (MLP-LLM)</booktitle>
      <editor><first>Frédéric</first><last>Bechet</last></editor>
      <editor><first>Adrian-Gabriel</first><last>Chifu</last></editor>
      <editor><first>Karen</first><last>Pinel-sauvagnat</last></editor>
      <editor><first>Benoit</first><last>Favre</last></editor>
      <editor><first>Eliot</first><last>Maes</last></editor>
      <editor><first>Diana</first><last>Nurbakova</last></editor>
      <publisher>ATALA \\&amp; ARIA</publisher>
      <address>Marseille, France</address>
      <month>6</month>
      <year>2025</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="c8cb78d3">2025.jeptalnrecital-mlpllm.0</url>
      <bibkey>jep-taln-recital-2025-mlpllm</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Détection d’Hallucinations dans les Dossiers Médicaux Générés Automatiquement : Une Approche d’Optimisation pour les Couches Sémantiques et les Seuils Adaptatifs</title>
      <author><first>Souhir</first><last>Khessiba</last></author>
      <author><first>Nadège</first><last>Alavoine</last></author>
      <author><first>Damien</first><last>Forest</last></author>
      <pages>1–13</pages>
      <abstract>Les Modèles de Langage (LLM) sont susceptibles aux hallucinations, générant parfois des informations inexactes d’où un risque non négligeable, notamment dans le domaine médical où la fiabilité est essentielle. Cet article aborde deux objectifs : améliorer la qualité des dossiers médicaux et renforcer la fiabilité des cohortes de recherche. Nous présentons un système de détection des hallucinations dans les résumés médicaux générés par IA en optimisant les couches sémantiques de BERT. Notre méthodologie exploite BERT Score pour évaluer la similarité entre les phrases des rapports générés et des transcriptions originales. Notre contribution principale introduit un mécanisme à double seuil critique et alerte optimisé par l’algorithme Tree Parzen Estimator, contrairement aux approches traditionnelles à seuil unique. Les résultats démontrent des améliorations significatives dans la détection des hallucinations, avec une précision et un rappel supérieur aux méthodes de référence. Bien que notre étude soit limitée à la langue française, le système proposé assure améliore la fiabilité des informations médicales, répondant aux objectifs d’amélioration de la qualité documentaire et d’intégrité des données de recherche.</abstract>
      <url hash="e4d7ab78">2025.jeptalnrecital-mlpllm.1</url>
      <language>fra</language>
      <bibkey>khessiba-etal-2025-detection</bibkey>
    </paper>
    <paper id="2">
      <title>Evaluation et analyse des performances des grands modèles de langue sur des épreuves d’examen de médecine français</title>
      <author><first>Adrien</first><last>Kuhnast</last></author>
      <author><first>Loic</first><last>Verlingue</last></author>
      <pages>14–24</pages>
      <abstract>Les grands modèles de langue (GMLs) ont démontré leur capacité à répondre correctement à des questions de médecine sur des bases anglaises. Or, leur paramétrage par apprentissage profond les soumet au biais linguistique et doivent ainsi être évalués dans la langue de l’utilisateur. Nous avons évalué des GMLs sur 278 questions à choix multiples provenant d’examens de médecine (Lyon-Est 2024) de différentes spécialités et respectant les recommandations nationales. Nos résultats montrent que les GMLs sont aussi bons que les étudiants mais qu’il existe d’importantes variations selon les spécialités. Améliorer la consigne en précisant de s’appuyer sur les recommandations françaises modifie significativement les notes obtenues ce qui démontre la nécessité d’éprouver les GMLs selon différents contextes géographiques et linguistiques. Nous avons également analysé le type d’erreur que font les GMLs ce qui ouvre la porte à des améliorations plus ciblées.</abstract>
      <url hash="e7b1ece3">2025.jeptalnrecital-mlpllm.2</url>
      <language>fra</language>
      <bibkey>kuhnast-verlingue-2025-evaluation</bibkey>
    </paper>
    <paper id="3">
      <title>Les grands modèles de langue biomédicaux préentraînés sur des données hors <fixed-case>EHR</fixed-case> sont moins performants en contexte multilingue réel</title>
      <author><first>Alina</first><last>Kramchaninova</last></author>
      <author><first>Clara</first><last>L. Oeste</last></author>
      <author><first>Narges</first><last>Farokhshad</last></author>
      <author><first>Lucas</first><last>Sterckx</last></author>
      <pages>25–41</pages>
      <abstract>Des travaux récents ont démontré que les grands modèles de langue (LLMs) sont capables de traiter des données biomédicales. Cependant, leur déploiement en zéro-shot dans les hôpitaux présente de nombreux défis. Les modèles sont souvent trop coûteux pour une inférence et un ajustement local ; leur capacité multilingue est inférieure par rapport à leur performance en anglais ; les ensembles de données de préentraînement, souvent issus de publications biomédicales, sont trop génériques pour une performance optimale, compte tenu de la complexité des scénarios cliniques présents dans les données de santé. Nous abordons ces défis et d’autres encore dans un cas d’usage multilingue réel à travers le développement d’un pipeline de normalisation de concepts de bout en bout. Son objectif principal est de convertir l’information issue de dossiers de santé non structurés (multilingues) en ontologies codifiées, permettant ainsi la détection de concepts au sein de l’historique médical d’un patient. Dans cet article, nous démontrons quantitativement l’importance de données réelles et spécifiques au domaine pour des applications cliniques à grande échelle.</abstract>
      <url hash="62949d8b">2025.jeptalnrecital-mlpllm.3</url>
      <language>fra</language>
      <bibkey>kramchaninova-etal-2025-les</bibkey>
    </paper>
    <paper id="4">
      <title>Sélection ordonnée de phrases associées aux symptômes de la dépression par classification zéro-coup</title>
      <author><first>Yves</first><last>Ferstler</last></author>
      <author><first>Catherine</first><last>Lavoie</last></author>
      <author><first>Marie-Jean</first><last>Meurs</last></author>
      <pages>42–48</pages>
      <abstract>Cet article présente une méthode pour extraire d’un corpus les phrases les plus pertinentes pour répondre à un questionnaire d’auto-évaluation. Un modèle de classification zéro-coup évalue la similarité entre les phrases et les réponses du questionnaire. Les résultats obtenus par ce modèle frugal sont prometteurs par comparaison avec ceux d’autres grands modèles de langue.</abstract>
      <url hash="0849e19f">2025.jeptalnrecital-mlpllm.4</url>
      <language>fra</language>
      <bibkey>ferstler-etal-2025-selection</bibkey>
    </paper>
    <paper id="5">
      <title>Structuration Automatique de la Posologie en Français : Quel rôle pour les <fixed-case>LLM</fixed-case>s ?</title>
      <author><first>Natalia</first><last>Bobkova</last></author>
      <author><first>Laura</first><last>Zanella-Calzada</last></author>
      <author><first>Anyes</first><last>Tafoughalt</last></author>
      <author><first>Raphaël</first><last>Teboul</last></author>
      <author><first>François</first><last>Plesse</last></author>
      <author><first>Félix</first><last>Gaschi</last></author>
      <pages>49–67</pages>
      <abstract>La structuration automatique de posologie est essentielle pour fiabiliser la médication et permettre une assistance à la prescription médicale. Les textes de prescriptions en français présentent très souvent des ambiguïtés, des variabilités syntaxiques, et des expressions colloquiales, ce qui limite l’efficacité des approches classiques de machine learning. Nous étudions ici l’emploi de Grands Modèles de Langages (LLM) pour structurer les textes de posologie en comparant des méthodes fondées sur le prompt-engineering et le fine-tuning de LLM avec un système “pré-LLM” fondé sur un algorithme de reconnaissance et liaison d’entités nommées (NERL). Nos résultats montrent que seuls les LLM fine-tunés atteignent la précision du modèle de référence. L’analyse des erreurs révèle une complémentarité des deux approches : notre NERL permet une structuration plus précise, mais les LLMs captent plus efficacement les nuances sémantiques. Ainsi, nous proposons le modèle hybride suivant : faire appel à un LLM en cas de faible confiance en la sortie du NERL (&lt;0.8) selon notre propre score de confiance. Cette stratégie nous permet d’atteindre une précision de 91% tout en minimisant le temps de latence. Nos résultats suggèrent que cette approche hybride améliore la précision de la structuration de posologie tout en limitant le coût computationnel, ce qui en fait une solution scalable pour une application clinique en conditions réelles.</abstract>
      <url hash="de72340f">2025.jeptalnrecital-mlpllm.5</url>
      <language>fra</language>
      <bibkey>bobkova-etal-2025-structuration</bibkey>
    </paper>
    <paper id="6">
      <title>Summarization for Generative Relation Extraction in the Microbiome Domain</title>
      <author><first>Oumaima</first><last>El Khettari</last></author>
      <author><first>Solen</first><last>Quiniou</last></author>
      <author><first>Samuel</first><last>Chaffron</last></author>
      <pages>68–82</pages>
      <abstract>We explore a generative relation extraction (RE) pipeline tailored to the study of interactions in the intestinal microbiome, a complex and low-resource biomedical domain. Our method leverages summarization with large language models (LLMs) to refine context before extracting relations via instruction-tuned generation. Preliminary results on a dedicated corpus show that summarization improves generative RE performance by reducing noise and guiding the model. However, BERT-based RE approaches still outperform generative models. This ongoing work demonstrates the potential of generative methods to support the study of specialized domains in low-resources setting.</abstract>
      <url hash="d84aa30c">2025.jeptalnrecital-mlpllm.6</url>
      <bibkey>el-khettari-etal-2025-summarization</bibkey>
    </paper>
  </volume>
  <volume id="parcol" ingest-date="2025-09-28" type="proceedings">
    <meta>
      <booktitle>Actes de l'atelier Science Participative pour les Données et Corpus Linguistiques 2025 (ParCol)</booktitle>
      <editor><first>Frédéric</first><last>Bechet</last></editor>
      <editor><first>Adrian-Gabriel</first><last>Chifu</last></editor>
      <editor><first>Karen</first><last>Pinel-sauvagnat</last></editor>
      <editor><first>Benoit</first><last>Favre</last></editor>
      <editor><first>Eliot</first><last>Maes</last></editor>
      <editor><first>Diana</first><last>Nurbakova</last></editor>
      <publisher>ATALA \\&amp; ARIA</publisher>
      <address>Marseille, France</address>
      <month>6</month>
      <year>2025</year>
      <venue>jeptalnrecital</venue>
    </meta>
    <frontmatter>
      <url hash="9e9955e4">2025.jeptalnrecital-parcol.0</url>
      <bibkey>jep-taln-recital-2025-parcol</bibkey>
    </frontmatter>
    <paper id="1">
      <title>La science participative en pratique : comment réussir (et ne pas le faire) ?</title>
      <author><first>Laure</first><last>Turcati</last></author>
      <author><first>Alice</first><last>Millour</last></author>
      <author><first>Renaud</first><last>Debailly</last></author>
      <author><first>Karën</first><last>Fort</last></author>
      <author><first>Asma</first><last>Steinhausser</last></author>
      <author><first>Corentin</first><last>Biets</last></author>
      <author><first>Anne</first><last>Dozières</last></author>
      <pages>1–2</pages>
      <abstract>Cet article présente un travail collectif mené par des chercheurs et des porteurs de projets dans le domaine des sciences participatives (SP). Notre démarche s’inscrit dans la « culture de l’erreur » dans les SP, introduite par Westreicher et al. (2021) : nous partageons notre vision des erreurs et des difficultés que nous avons expérimentées, ce que nous en avons appris et ce que nous ferions différemment. Ce travail s’appuie sur dix projets français couvrant une variété d’objectifs, de disciplines, et de publics. Cette diversité nous a permis de mener une réflexion transversale et libre de toute spécificité sur nos pratiques. Nous avons identifié 3 types d’erreurs ou de difficultés, que nous illustrons par des exemples tirés de notre propre expérience. Le premier type d’erreurs concerne celles que nous ne répéterions pas. Contrairement à ces erreurs « réelles », les deux types de difficultés suivants sont une invitation à défendre une vision plus réaliste des SP. Le deuxième type fait en effet référence aux incertitudes inhérentes à la plasticité des projets de SP. Le dernier type concerne enfin les obstacles et difficultés qui peuvent conduire à des conséquences positives inattendues, à la fois en termes d’objectifs scientifiques et vis-à-vis de la communauté des participant(e)s. Dans cet article, nous encourageons donc un changement dans la façon dont nous considérons les erreurs et les difficultés : l’incertitude est inhérente aux SP et nous affirmons notre droit d’expérimenter, de faire des erreurs et de changer de pratiques au cours de la vie d’un projet.</abstract>
      <url hash="85c5d2ae">2025.jeptalnrecital-parcol.1</url>
      <language>fra</language>
      <bibkey>turcati-etal-2025-la</bibkey>
    </paper>
    <paper id="2">
      <title>La science participative et l’<fixed-case>ANR</fixed-case> <fixed-case>D</fixed-case>i<fixed-case>LS</fixed-case>i</title>
      <author><first>Pierre</first><last>Magistry</last></author>
      <author><first>Ilaine</first><last>Wang</last></author>
      <pages>3–5</pages>
      <abstract>Cette communication propose un retour d’expérience sur les interactions entre le projet DiLSi et les communautés de locuteurs du teochew de la diaspora et du tâigí.</abstract>
      <url hash="48a37895">2025.jeptalnrecital-parcol.2</url>
      <language>fra</language>
      <bibkey>magistry-wang-2025-la</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>L</fixed-case>i<fixed-case>LA</fixed-case> : Outil d’augmentation automatisée des données vocales participatives de Lingua Libre</title>
      <author><first>Mathilde</first><last>Hutin</last></author>
      <author><first>Marc</first><last>Allassonnière-Tang</last></author>
      <author><first>Lucas</first><last>Prégaldiny</last></author>
      <author><first>Lucas</first><last>Lévêque</last></author>
      <pages>6–10</pages>
      <abstract>La constitution de corpus vocaux, nécessaires à l’exploration de la phonétique et de la phonologie des langues du monde, soulève de nombreux défis. La constitution de corpus multi-dialectes, permettant d’explorer la variation dialectale, ou de corpus multilingues, permettant de comparer plusieurs langues, est d’autant plus difficile que, pour que chaque dialecte /langue soit comparable aux autres dans le corpus, les données doivent avoir été enregistrées dans les mêmes conditions (même matériel, même protocole ...). Une solution à ces défis semble envisageable aujourd’hui grâce aux données participatives, par définition administrées et enregistrées par des volontaires, et donc moins coûteuses à tous points de vue pour la communauté scientifique. En mars 2025, Lingua Libre, la médiathèque linguistique participative de Wikimédia France ouverte depuis 2018, compte ~1,4M enregistrements en 284 langues par 2.547 individus à travers le monde : notre projet est de créer un outil pour rendre ces données brutes exploitables par les linguistes.</abstract>
      <url hash="1f9af01b">2025.jeptalnrecital-parcol.3</url>
      <language>fra</language>
      <bibkey>hutin-etal-2025-lila</bibkey>
    </paper>
    <paper id="4">
      <title>Lingua Libre à l’ère de l’automatisation: l’<fixed-case>I</fixed-case>.<fixed-case>A</fixed-case>. au service du crowdsourcing d’un corpus oral</title>
      <author><first>Camille</first><last>Lavigne</last></author>
      <author><first>Florian</first><last>Cuny</last></author>
      <pages>11–24</pages>
      <abstract>Lingua Libre, projet participatif collectant de la production orale, a amassé plus de 380 heures d’enregistrements, 1 350 000 fichiers audio, dans près de 300 langues différentes. Le potentiel d’un tel jeu de données pour tester des hypothèses linguistiques ou pour des tâches d’ASR est prometteur, mais diminué par le manque d’harmonisation et de nettoyage systématique des données. Ce travail est un pas supplémentaire vers un jeu de données issu de Lingua Libre de grande qualité et standardisé. Ce travail révèle des disparités récurrentes entre les enregistrements et la transcription qui en est fournie. Ces erreurs, bien que rares, sont régulières, et potentiellement évitables. En effet, le modèle d’ASR Wav2Vec 2.0-Base après affinage est capable de détecter une large part de ces erreurs. Il pourrait être un puissant outil à la disposition du contributorat, pour les assister à la tâche de patrouille.</abstract>
      <url hash="957a9e98">2025.jeptalnrecital-parcol.4</url>
      <language>fra</language>
      <bibkey>lavigne-cuny-2025-lingua</bibkey>
    </paper>
  </volume>
</collection>
