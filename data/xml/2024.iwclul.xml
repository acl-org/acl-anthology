<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.iwclul">
  <volume id="1" ingest-date="2024-11-28" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 9th International Workshop on Computational Linguistics for Uralic Languages</booktitle>
      <editor><first>Mika</first><last>Hämäläinen</last></editor>
      <editor><first>Flammie</first><last>Pirinen</last></editor>
      <editor><first>Melany</first><last>Macias</last></editor>
      <editor><first>Mario</first><last>Crespo Avila</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Helsinki, Finland</address>
      <month>November</month>
      <year>2024</year>
      <url hash="d97ffb66">2024.iwclul-1</url>
      <venue>iwclul</venue>
    </meta>
    <frontmatter>
      <url hash="8a5acc3a">2024.iwclul-1.0</url>
      <bibkey>iwclul-2024-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Aspect Based Sentiment Analysis of <fixed-case>F</fixed-case>innish Neighborhoods: Insights from Suomi24</title>
      <author><first>Laleh</first><last>Davoodi</last><affiliation>Faculty of Social Sciences, Business and Economics, and Law, Åbo Akademi University</affiliation></author>
      <author><first>Anssi</first><last>Öörni</last><affiliation>Faculty of Social Sciences, Business and Economics, and Law, Åbo Akademi University</affiliation></author>
      <author><first>Ville</first><last>Harkke</last><affiliation>Faculty of Social Sciences, Business and Economics, and Law, Åbo Akademi University</affiliation></author>
      <pages>1-11</pages>
      <abstract>This study presents an approach to Aspect-Based Sentiment Analysis (ABSA) using Natural Language Processing (NLP) techniques to explore public sentiment across 12 suburban neighborhoods in Finland. We employed and compared a range of machine learning models for sentiment classification, with the RoBERTa model emerging as the best performer. Using RoBERTa, we conducted a comprehensive sentiment analysis(SA) on a manually annotated dataset and a predicted dataset comprising 32,183 data points to investigate sentiment trends over time in these areas. The results provide insights into fluctuations in public sentiment, highlighting both the robustness of the RoBERTa model and significant shifts in sentiment for specific neighborhoods over time. This research contributes to a deeper understanding of neighborhood sentiment dynamics in Finland, with potential implications for social research and urban development.</abstract>
      <url hash="8ba7372d">2024.iwclul-1.1</url>
      <bibkey>davoodi-etal-2024-aspect</bibkey>
    </paper>
    <paper id="2">
      <title>Political Stance Detection in <fixed-case>E</fixed-case>stonian News Media</title>
      <author><first>Lauri</first><last>Lüüsi</last><affiliation>University of Tartu</affiliation></author>
      <author><first>Uku</first><last>Kangur</last><affiliation>University of Tartu</affiliation></author>
      <author><first>Roshni</first><last>Chakraborty</last><affiliation>ABV IIITM Gwalior</affiliation></author>
      <author><first>Rajesh</first><last>Sharma</last><affiliation>University of Tartu</affiliation></author>
      <pages>12-28</pages>
      <abstract>Newspapers have always remained an important medium for disseminating information to the masses. With continuous access and availability of news, there is a severe competition among news media agencies to attract user attention. Therefore, ensuring fairness in news reporting, such as, politically stance neutral reporting has become more crucial than before. Although several research studies have explored and detected political stance in English news articles, there is a lack of research focusing on low-resource languages like Estonian. To address this gap, this paper examines the effectiveness of established stance-detection features that have been successful for English news media, while also proposing novel features tailored specifically for Estonian. Our study consists of 32 different features comprising of lexical, Estonian-specific, framing and sentiment-related features out of which we identify 15 features as useful for stance detection.</abstract>
      <url hash="e1d0661e">2024.iwclul-1.2</url>
      <bibkey>luusi-etal-2024-political</bibkey>
    </paper>
    <paper id="3">
      <title>Universal-<fixed-case>WER</fixed-case>: Enhancing <fixed-case>WER</fixed-case> with Segmentation and Weighted Substitution for Varied Linguistic Contexts</title>
      <author><first>Samy</first><last>Ouzerrout</last><affiliation>University of Orléans, France</affiliation></author>
      <pages>29-35</pages>
      <abstract>Word Error Rate (WER) is a crucial metric for evaluating the performance of automatic speech recognition (ASR) systems. However, its traditional calculation, based on Levenshtein distance, does not account for lexical similarity between words and treats each substitution in a binary manner, while also ignoring segmentation errors. This paper proposes an improvement to WER by introducing a weighted substitution method, based on lexical similarity measures, and incorporating splitting and merging operations to better handle segmentation errors. Unlike other WER variants, our approach is easily integrable and generalizable to various languages, providing a more nuanced and accurate evaluation of ASR transcriptions, particularly for morphologically complex or low-resource languages.</abstract>
      <url hash="34f9fd10">2024.iwclul-1.3</url>
      <bibkey>ouzerrout-2024-universal</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>DAG</fixed-case>: Dictionary-Augmented Generation for Disambiguation of Sentences in Endangered <fixed-case>U</fixed-case>ralic Languages using <fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case></title>
      <author><first>Mika</first><last>Hämäläinen</last><affiliation>Metropolia University of Applied Sciences, Helsinki, Finland</affiliation></author>
      <pages>36-40</pages>
      <abstract>We showcase that ChatGPT can be used to disambiguate lemmas in two endangered languages ChatGPT is not proficient in, namely Erzya and Skolt Sami. We augment our prompt by providing dictionary translations of the candidate lemmas to a majority language - Finnish in our case. This dictionary augmented generation approach results in 50% accuracy for Skolt Sami and 41% accuracy for Erzya. On a closer inspection, many of the error types were of the kind even an untrained human annotator would make.</abstract>
      <url hash="c89d81c9">2024.iwclul-1.4</url>
      <bibkey>hamalainen-2024-dag</bibkey>
    </paper>
    <paper id="5">
      <title>Leveraging Transformer-Based Models for Predicting Inflection Classes of Words in an Endangered <fixed-case>S</fixed-case>ami Language</title>
      <author><first>Khalid</first><last>Alnajjar</last><affiliation>Rootroo Ltd</affiliation></author>
      <author><first>Mika</first><last>Hämäläinen</last><affiliation>Metropolia University of Applied Sciences</affiliation></author>
      <author><first>Jack</first><last>Rueter</last><affiliation>University of Helsinki</affiliation></author>
      <pages>41-48</pages>
      <abstract>This paper presents a methodology for training a transformer-based model to classify lexical and morphosyntactic features of Skolt Sami, an endangered Uralic language characterized by complex morphology. The goal of our approach is to create an effective system for understanding and analyzing Skolt Sami, given the limited data availability and linguistic intricacies inherent to the language. Our end-to-end pipeline includes data extraction, augmentation, and training a transformer-based model capable of predicting inflection classes. The motivation behind this work is to support language preservation and revitalization efforts for minority languages like Skolt Sami. Accurate classification not only helps improve the state of Finite-State Transducers (FSTs) by providing greater lexical coverage but also contributes to systematic linguistic documentation for researchers working with newly discovered words from literature and native speakers. Our model achieves an average weighted F1 score of 1.00 for POS classification and 0.81 for inflection class classification. The trained model and code will be released publicly to facilitate future research in endangered NLP.</abstract>
      <url hash="c142af13">2024.iwclul-1.5</url>
      <bibkey>alnajjar-etal-2024-leveraging</bibkey>
    </paper>
    <paper id="6">
      <title>Multilingual Approaches to Sentiment Analysis of Texts in Linguistically Diverse Languages: A Case Study of <fixed-case>F</fixed-case>innish, <fixed-case>H</fixed-case>ungarian, and <fixed-case>B</fixed-case>ulgarian</title>
      <author><first>Mikhail</first><last>Krasitskii</last><affiliation>Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Mexico City, Mexico</affiliation></author>
      <author><first>Olga</first><last>Kolesnikova</last><affiliation>Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Mexico City, Mexico</affiliation></author>
      <author><first>Liliana</first><last>Chanona Hernandez</last><affiliation>Instituto Politécnico Nacional (IPN), Escuela Superior de Ingeniería Mecánica y Eléctrica (ESIME), Mexico City, Mexico</affiliation></author>
      <author><first>Grigori</first><last>Sidorov</last><affiliation>Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Mexico City, Mexico</affiliation></author>
      <author><first>Alexander</first><last>Gelbukh</last><affiliation>Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC), Mexico City, Mexico</affiliation></author>
      <pages>49-58</pages>
      <abstract>This article is dedicated to the study of multilingual approaches to sentiment analysis of texts in Finnish, Hungarian, and Bulgarian. For Finnish and Hungarian, which are characterized by complex morphology and agglutinative grammar, an analysis was conducted using both traditional rule-based methods and modern machine learning techniques. In the study, BERT, XLM-R, and mBERT models were used for sentiment analysis, demonstrating high accuracy in sentiment classification. The inclusion of Bulgarian was motivated by the opportunity to compare results across languages with varying degrees of morphological complexity, which allowed for a better understanding of how these models can adapt to different linguistic structures. Datasets such as the Hungarian Emotion Corpus, FinnSentiment, and SentiFi were used to evaluate model performance. The results showed that transformer-based models, particularly BERT, XLM-R, and mBERT, significantly outperformed traditional methods, achieving high accuracy in sentiment classification tasks for all the languages studied.</abstract>
      <url hash="3c164ecd">2024.iwclul-1.6</url>
      <bibkey>krasitskii-etal-2024-multilingual</bibkey>
    </paper>
    <paper id="7">
      <title>Towards standardized inflected lexicons for the Finnic languages</title>
      <author><first>Jules</first><last>Bouton</last><affiliation>Université Paris-Cité, LLF, CNRS</affiliation></author>
      <pages>59-66</pages>
      <abstract>We introduce three richly annotated lexicons of nouns for Livonian, standard Finnish and Livvi Karelian. Our datasets are distributed in the machine-readable Paralex standard, which consists of linked CSV tables described in a JSON metadata file. We built on the morphological dictionary of Livonian, the VepKar database and the Omorfi software to provide inflected forms. All noun forms were transcribed with grapheme-to-phoneme conversion rules and the paradigms annotated for both overabundance and defectivity. The resulting datasets are usable for quantitative studies of morphological systems and for qualitative investigations. They are linked to the original resources and can be easily updated.</abstract>
      <url hash="e7f67bc1">2024.iwclul-1.7</url>
      <bibkey>bouton-2024-towards</bibkey>
    </paper>
    <paper id="8">
      <title>On <fixed-case>E</fixed-case>rzya and <fixed-case>M</fixed-case>oksha Corpora and Analyzer Development, <fixed-case>ERME</fixed-case>-<fixed-case>PSLA</fixed-case> 1950s</title>
      <author><first>Jack</first><last>Rueter</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Olga</first><last>Erina</last><affiliation>Independent researcher</affiliation></author>
      <author><first>Nadezhda</first><last>Kabaeva</last><affiliation>Mordovian State University</affiliation></author>
      <pages>67-75</pages>
      <abstract>This paper describes materials and annotation facilitation pertinent to the «Erzya-Moksha Electronic Resources and Linguistic Diversity» (EMERALD) project. It addresses work following the construction of finite-state analyzers for the Mordvin languages, the gathering of test corpora, and the development of metadata strategies for descriptive research. In this paper, we provide three descriptors for a set of new Erzya and Moksha research materials at the Language Bank of Finland. The descriptors illustrate (1) a low-annotation subcorpora set of the «Electronic Resources for Moksha and Erzya» (ERME); (2) the state of the open-source analyzers used in their automatic annotation, and (3) the development of metadata documentation for the «EMERALD» project, associated with this endeavor. Outcomes of the article include an introduction to new research materials, an illustration of the state of the Mordvin annotation pipeline, and perspectives for the further enhancement of the annotation pipeline.</abstract>
      <url hash="47aed37c">2024.iwclul-1.8</url>
      <bibkey>rueter-etal-2024-erzya</bibkey>
    </paper>
    <paper id="9">
      <title>Towards the speech recognition for <fixed-case>L</fixed-case>ivonian</title>
      <author><first>Valts</first><last>Ernštreits</last><affiliation>University of Latvia Livonian Institute</affiliation></author>
      <pages>76-80</pages>
      <abstract>This article outlines the path toward the development of speech synthesis and speech recognition technologies for Livonian, a critically endangered Uralic language with around 20 contemporary fluent speakers. It presents the rationale behind the creation of these technologies and introduces the hypotheses and planned approaches to achieve this goal. The article discusses the four-stage approach of leveraging existing data and multiplying voice data through speech synthesis and voice cloning to generate the necessary data for building and training speech recognition for Livonian.</abstract>
      <url hash="8abacc41">2024.iwclul-1.9</url>
      <bibkey>ernstreits-2024-towards</bibkey>
    </paper>
    <paper id="10">
      <title>Using Large Language Models to Transliterate Endangered <fixed-case>U</fixed-case>ralic Languages</title>
      <author><first>Niko</first><last>Partanen</last><affiliation>Department of Finnish, Finno-Ugrian and Scandinavian Studies, University of Helsinki</affiliation></author>
      <pages>81-88</pages>
      <abstract>This study investigates whether the Large Language Models are able to transliterate and normalize endangered Uralic languages, specifically when they have been written in early 20th century Latin script based transcription systems. We test commercially available closed source systems where there is no reason to expect that the models would be particularly adjusted to this task or these languages. The output of the transliteration in all experiments is contemporary Cyrillic orthography. We conclude that some of the newer LLMs, especially Claude 3.5 Sonnet, are able to produce high quality transliterations even in the smaller languages in our test set, both in zero-shot scenarios and with a prompt that contains an example of the desired output. We assume that the good result is connected to the large presence of materials in these languages online, which the LLM has learned to represent.</abstract>
      <url hash="c716065e">2024.iwclul-1.10</url>
      <bibkey>partanen-2024-using</bibkey>
    </paper>
    <paper id="11">
      <title>Specialized Monolingual <fixed-case>BPE</fixed-case> Tokenizers for <fixed-case>U</fixed-case>ralic Languages Representation in Large Language Models</title>
      <author><first>Iaroslav</first><last>Chelombitko</last><affiliation>Neapolis University Pafos, Paphos, Cyprus</affiliation></author>
      <author><first>Aleksey</first><last>Komissarov</last><affiliation>Neapolis University Pafos, Paphos, Cyprus</affiliation></author>
      <pages>89-95</pages>
      <abstract>Large language models show significant inequality in language representation, particularly for Uralic languages. Our analysis found that existing tokenizers allocate minimal tokens to Uralic languages, highlighting this imbalance. To address this, we developed a pipeline to create clean monolingual datasets from Wikipedia articles for four Uralic languages. We trained Byte Pair Encoding (BPE) tokenizers with a vocabulary size of 256,000 tokens, though Northern Sami had only 93,187 due to limited data. Our findings revealed most tokens are unique to each language, with 8,102 shared across all four, and 25,876 shared among Estonian, Finnish, and Hungarian. Using the Compression Ratio metric, our tokenizers outperformed popular ones like LLaMA-2 and Gemma 2, reducing Finnish’s compression ratio from 3.41 to 1.18. These results demonstrate the importance of specialized tokenizers for underrepresented languages, improving model performance and lowering costs. By sharing our tokenizers and datasets, we provide crucial resources for further research, emphasizing the need for equitable language representation.</abstract>
      <url hash="7c2eadba">2024.iwclul-1.11</url>
      <bibkey>chelombitko-komissarov-2024-specialized</bibkey>
    </paper>
    <paper id="12">
      <title>Compressing Noun Phrases to Discover Mental Constructions in Corpora – A Case Study for Auxiliaries in <fixed-case>H</fixed-case>ungarian</title>
      <author><first>Balázs</first><last>Indig</last><affiliation>Doctoral School of Linguistics, National Laboratory for Digital Heritage, Eötvös Loránd University Department of Digital Humanities</affiliation></author>
      <author><first>Tímea</first><last>Borbála Bajzát</last><affiliation>Doctoral School of Linguistics, National Laboratory for Digital Heritage, Eötvös Loránd University Department of Digital Humanities</affiliation></author>
      <pages>96-103</pages>
      <abstract>The quantitative turn in functional linguistics has emphasised the importance of data-oriented methods in describing linguistic patterns. However, there are significant differences between constructions and the examples they cover, which need to be properly formalised. For example, noun chains introduce significant variation in the examples, making it difficult to identify underlying patterns. The compression of noun chains into their minimal form (e.g. as they appear in abstract constructions) is a promising method for revealing linguistic patterns in corpora through their examples. This method, combined with identifying the appropriate level of abstraction for the additional elements present, allows for the systematic extraction of good construction candidates. A pilot has been developed for Hungarian infinitive structures, but is adaptable for various linguistic structures and other agglutinative languages.</abstract>
      <url hash="ba774bdc">2024.iwclul-1.12</url>
      <bibkey>indig-borbala-bajzat-2024-compressing</bibkey>
    </paper>
    <paper id="13">
      <title>On <fixed-case>E</fixed-case>rzya and <fixed-case>M</fixed-case>oksha Corpora and Analyzer Development, <fixed-case>ERME</fixed-case>-<fixed-case>PSLA</fixed-case> 1950s</title>
      <author><first>Aleksei</first><last>Dorkin</last><affiliation>Institute of Computer Science, University of Tartu</affiliation></author>
      <author><first>Taido</first><last>Purason</last><affiliation>Institute of Computer Science, University of Tartu</affiliation></author>
      <author><first>Kairit</first><last>Sirts</last><affiliation>Institute of Computer Science, University of Tartu</affiliation></author>
      <pages>104-108</pages>
      <abstract>Adapting multilingual language models to specific languages can enhance both their efficiency and performance. In this study, we explore how modifying the vocabulary of a multilingual encoder model to better suit the Estonian language affects its downstream performance on the Named Entity Recognition (NER) task. The motivations for adjusting the vocabulary are twofold: practical benefits affecting the computational cost, such as reducing the input sequence length and the model size, and performance enhancements by tailoring the vocabulary to the particular language. We evaluate the effectiveness of two vocabulary adaptation approaches—retraining the tokenizer and pruning unused tokens—and assess their impact on the model’s performance, particularly after continual training. While retraining the tokenizer degraded the performance of the NER task, suggesting that longer embedding tuning might be needed, we observed no negative effects on pruning.</abstract>
      <url hash="dd77498a">2024.iwclul-1.13</url>
      <bibkey>dorkin-etal-2024-erzya</bibkey>
    </paper>
    <paper id="14">
      <title>On the Role of New Technologies in the Documentation and Revitalization of <fixed-case>U</fixed-case>ralic Languages of <fixed-case>R</fixed-case>ussia in Historical and Contemporary Contexts</title>
      <author><first>Alexander</first><last>Nazarenko</last><affiliation>Independent researcher and enthusiast of Uralic languages, amateur database and software developer</affiliation></author>
      <pages>109-114</pages>
      <abstract>The Uralic languages spoken in Russia face significant challenges due to historical and sociopolitical factors, resulting in their endangered status. While only Finnish, Estonian, and Hungarian enjoy solid support as official languages, most Uralic languages suffer from limited resources and declining speaker populations. This paper examines the development of written Uralic languages, the impact of Russian language and its writing system to them, and the consequences of the lack of state interest in these languages for preservation efforts. Despite these challenges, technological advancements present valuable opportunities for revitalization. Existing projects, such as dictionaries and language corpora, highlight both the potential and shortcomings of current linguistic resources. Innovative approaches, including AI-based applications and user-driven platforms, can enhance engagement among people. By emphasizing the importance of high-quality linguistic data, this study advocates for a more proactive and collaborative effort in the preservation and promotion of Uralic languages.</abstract>
      <url hash="5574ae60">2024.iwclul-1.14</url>
      <bibkey>nazarenko-2024-role</bibkey>
    </paper>
    <paper id="15">
      <title>Applying the transformer architecture on the task of headline selection for <fixed-case>F</fixed-case>innish news texts</title>
      <author><first>Maria</first><last>Adamova</last><affiliation>St Petersburg State University, Universitetskaya emb., 7-9-11, 199034 St Petersburg, Russia</affiliation></author>
      <author><first>Maria</first><last>Khokhlova</last><affiliation>St Petersburg State University, Universitetskaya emb., 7-9-11, 199034 St Petersburg, Russia</affiliation></author>
      <pages>115-122</pages>
      <abstract>The paper evaluates the possibilities of using transformer architecture in creating headlines for news texts in Finnish. The authors statistically analyse the original and generated headlines according to three criteria: informativeness, relevance and impact. The study also substantiates for the first time the effectiveness of a fine-tuned text-to-text transfer transformer model within the task of generating headlines for news articles in Finnish. The results show that there is no statistically significant difference between the scores obtained by the original and generated headlines on the mentioned criteria of informativeness, relevance and impact.</abstract>
      <url hash="9d1e5a57">2024.iwclul-1.15</url>
      <bibkey>adamova-khokhlova-2024-applying</bibkey>
    </paper>
    <paper id="16">
      <title>Keeping Up Appearances—or how to get all <fixed-case>U</fixed-case>ralic languages included into bleeding edge research and software: generate, convert, and <fixed-case>LLM</fixed-case> your way into multilingual datasets</title>
      <author><first>Flammie</first><last>A Pirinen</last><affiliation>Divvun, UiT—Norgga árktalaš universitehta, Tromsø, Norway</affiliation></author>
      <pages>123-131</pages>
      <abstract>The current trends in natural language processing strongly favor large language models and generative AIs as the basis for everything. For Uralic languages that are not largely present in publically available data on the Internet, this can be problematic. In the current computational linguistic scene, it is very important to have representation of your language in popular datasets. Languages that are included in well-known datasets are also included in shared tasks, products by large technology corporations, and so forth. This inclusion will become especially important for under-resourced, under-studied minority, and Indigenous languages, which will otherwise be easily forgotten. In this article, we present the resources that are often deemed necessary for digital presence of a language in the large language model obsessed world of today. We show that there are methods and tricks available to alleviate the problems with a lack of data and a lack of creators and annotators of the data, some more successful than others.</abstract>
      <url hash="4e521931">2024.iwclul-1.16</url>
      <bibkey>a-pirinen-2024-keeping</bibkey>
    </paper>
    <paper id="17">
      <title>Scaling Sustainable Development Goal Predictions across Languages: From <fixed-case>E</fixed-case>nglish to <fixed-case>F</fixed-case>innish</title>
      <author><first>Melany</first><last>Macias</last><affiliation>Metropolia University of Applied Sciences, Helsinki, Finland</affiliation></author>
      <author><first>Lev</first><last>Kharlashkin,</last><affiliation>Metropolia University of Applied Sciences, Helsinki, Finland</affiliation></author>
      <author><first>Leo</first><last>Huovinen</last><affiliation>Metropolia University of Applied Sciences, Helsinki, Finland</affiliation></author>
      <author><first>Mika</first><last>Hämäläinen</last><affiliation>Metropolia University of Applied Sciences, Helsinki, Finland</affiliation></author>
      <pages>132-137</pages>
      <abstract>In this paper, we leverage an exclusive English dataset to train diverse multilingual classifiers, investigating their efficacy in adapting to Finnish data. We employ an exclusively English classification dataset of UN Sustainable Development Goals (SDG) in an education context, to train various multilingual classifiers and examine how well these models can adapt to recognizing the same classes within Finnish university course descriptions. It’s worth noting that Finnish, with a mere 5 million native speakers, presents a significantly less-resourced linguistic context compared to English. The best performing model in our experiments was mBART with an F1-score of 0.843.</abstract>
      <url hash="d269d44b">2024.iwclul-1.17</url>
      <bibkey>macias-etal-2024-scaling</bibkey>
    </paper>
    <paper id="18">
      <title>Kola Saami Christian Text Corpus</title>
      <author><first>Michael</first><last>Rießler</last><affiliation>University of Eastern Finland</affiliation></author>
      <pages>138-144</pages>
      <abstract>Christian texts have been known to be printed in Kola Saami languages since 1828; the most extensive publication is the Gospel of Matthew, different translations of which have been published three times since 1878, most recently in 2022. The Lord’s Prayer was translated in several more versions in Kildin Saami and Skolt Saami, first in 1828. All of these texts seem to go back to translations from Rus- sian. Such characteristics make these pub- lications just right for parallel text align- ment. This paper describes ongoing work with building a Kola Saami Christian Text Cor- pus, including conceptional and technical decisions. Thus, it describes a resource, rather than a study. However, compu- tational studies based on these data will hopefully take place in the near future, af- ter the Kildin Saami subset of this corpus is finished and published by the end of 2024. In addition to computation, this resource will also allow for comparative linguistic studies on diachronic and synchronic vari- ation and change in Kola Saami languages, which are among the most endangered and least described Uralic languages.</abstract>
      <url hash="19780139">2024.iwclul-1.18</url>
      <bibkey>riessler-2024-kola</bibkey>
    </paper>
  </volume>
</collection>
