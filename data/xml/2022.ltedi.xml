<?xml version='1.0' encoding='UTF-8'?>
<collection id="2022.ltedi">
  <volume id="1" ingest-date="2022-05-15">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Language Technology for Equality, Diversity and Inclusion</booktitle>
      <editor><first>Bharathi Raja</first><last>Chakravarthi</last></editor>
      <editor><first>B</first><last>Bharathi</last></editor>
      <editor><first>John P</first><last>McCrae</last></editor>
      <editor><first>Manel</first><last>Zarrouk</last></editor>
      <editor><first>Kalika</first><last>Bali</last></editor>
      <editor><first>Paul</first><last>Buitelaar</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Dublin, Ireland</address>
      <month>May</month>
      <year>2022</year>
      <url hash="0def7aed">2022.ltedi-1</url>
      <venue>ltedi</venue>
    </meta>
    <frontmatter>
      <url hash="eeb844c5">2022.ltedi-1.0</url>
      <bibkey>ltedi-2022-language</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Mind the data gap(s): Investigating power in speech and language datasets</title>
      <author><first>Nina</first><last>Markl</last></author>
      <pages>1-12</pages>
      <abstract>Algorithmic oppression is an urgent and persistent problem in speech and language technologies. Considering power relations embedded in datasets before compiling or using them to train or test speech and language technologies is essential to designing less harmful, more just technologies. This paper presents a reflective exercise to recognise and challenge gaps and the power relations they reveal in speech and language datasets by applying principles of Data Feminism and Design Justice, and building on work on dataset documentation and sociolinguistics.</abstract>
      <url hash="523a9cba">2022.ltedi-1.1</url>
      <bibkey>markl-2022-mind</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.1</doi>
      <video href="2022.ltedi-1.1.mp4"/>
      <pwcdataset url="https://paperswithcode.com/dataset/common-voice">Common Voice</pwcdataset>
    </paper>
    <paper id="2">
      <title>Regex in a Time of Deep Learning: The Role of an Old Technology in Age Discrimination Detection in Job Advertisements</title>
      <author><first>Anna</first><last>Pillar</last></author>
      <author><first>Kyrill</first><last>Poelmans</last></author>
      <author><first>Martha</first><last>Larson</last></author>
      <pages>13-18</pages>
      <abstract>Deep learning holds great promise for detecting discriminatory language in the public sphere. However, for the detection of illegal age discrimination in job advertisements, regex approaches are still strong performers. In this paper, we investigate job advertisements in the Netherlands. We present a qualitative analysis of the benefits of the ‘old’ approach based on regexes and investigate how neural embeddings could address its limitations.</abstract>
      <url hash="c571dddd">2022.ltedi-1.2</url>
      <bibkey>pillar-etal-2022-regex</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.2</doi>
      <video href="2022.ltedi-1.2.mp4"/>
    </paper>
    <paper id="3">
      <title>Doing not Being: Concrete Language as a Bridge from Language Technology to Ethnically Inclusive Job Ads</title>
      <author><first>Jetske</first><last>Adams</last></author>
      <author><first>Kyrill</first><last>Poelmans</last></author>
      <author><first>Iris</first><last>Hendrickx</last></author>
      <author><first>Martha</first><last>Larson</last></author>
      <pages>19-25</pages>
      <abstract>This paper makes the case for studying concreteness in language as a bridge that will allow language technology to support the understanding and improvement of ethnic inclusivity in job advertisements. We propose an annotation scheme that guides the assignment of sentences in job ads to classes that reflect concrete actions, i.e., what the employer needs people to <tex-math>do</tex-math>, and abstract dispositions, i.e., who the employer expects people to <tex-math>be</tex-math>. Using an annotated dataset of Dutch-language job ads, we demonstrate that machine learning technology is effectively able to distinguish these classes.</abstract>
      <url hash="cb31980e">2022.ltedi-1.3</url>
      <bibkey>adams-etal-2022-concrete</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.3</doi>
      <video href="2022.ltedi-1.3.mp4"/>
    </paper>
    <paper id="4">
      <title>Measuring Harmful Sentence Completion in Language Models for <fixed-case>LGBTQIA</fixed-case>+ Individuals</title>
      <author><first>Debora</first><last>Nozza</last></author>
      <author><first>Federico</first><last>Bianchi</last></author>
      <author><first>Anne</first><last>Lauscher</last></author>
      <author><first>Dirk</first><last>Hovy</last></author>
      <pages>26-34</pages>
      <abstract>Current language technology is ubiquitous and directly influences individuals’ lives worldwide. Given the recent trend in AI on training and constantly releasing new and powerful large language models (LLMs), there is a need to assess their biases and potential concrete consequences. While some studies have highlighted the shortcomings of these models, there is only little on the negative impact of LLMs on LGBTQIA+ individuals. In this paper, we investigated a state-of-the-art template-based approach for measuring the harmfulness of English LLMs sentence completion when the subjects belong to the LGBTQIA+ community. Our findings show that, on average, the most likely LLM-generated completion is an identity attack 13% of the time. Our results raise serious concerns about the applicability of these models in production environments.</abstract>
      <url hash="d4ef5de0">2022.ltedi-1.4</url>
      <bibkey>nozza-etal-2022-measuring</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.4</doi>
      <video href="2022.ltedi-1.4.mp4"/>
      <pwccode url="https://github.com/milanlproc/honest" additional="false">milanlproc/honest</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/honest-en">HONEST</pwcdataset>
    </paper>
    <paper id="5">
      <title>Using <fixed-case>BERT</fixed-case> Embeddings to Model Word Importance in Conversational Transcripts for Deaf and Hard of Hearing Users</title>
      <author><first>Akhter Al</first><last>Amin</last></author>
      <author><first>Saad</first><last>Hassan</last></author>
      <author><first>Cecilia</first><last>Alm</last></author>
      <author><first>Matt</first><last>Huenerfauth</last></author>
      <pages>35-40</pages>
      <abstract>Deaf and hard of hearing individuals regularly rely on captioning while watching live TV. Live TV captioning is evaluated by regulatory agencies using various caption evaluation metrics. However, caption evaluation metrics are often not informed by preferences of DHH users or how meaningful the captions are. There is a need to construct caption evaluation metrics that take the relative importance of words in transcript into account. We conducted correlation analysis between two types of word embeddings and human-annotated labelled word-importance scores in existing corpus. We found that normalized contextualized word embeddings generated using BERT correlated better with manually annotated importance scores than word2vec-based word embeddings. We make available a pairing of word embeddings and their human-annotated importance scores. We also provide proof-of-concept utility by training word importance models, achieving an F1-score of 0.57 in the 6-class word importance classification task.</abstract>
      <url hash="453b5472">2022.ltedi-1.5</url>
      <bibkey>amin-etal-2022-using</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.5</doi>
      <video href="2022.ltedi-1.5.mp4"/>
    </paper>
    <paper id="6">
      <title>Detoxifying Language Models with a Toxic Corpus</title>
      <author><first>Yoona</first><last>Park</last></author>
      <author><first>Frank</first><last>Rudzicz</last></author>
      <pages>41-46</pages>
      <abstract>Existing studies have investigated the tendency of autoregressive language models to generate contexts that exhibit undesired biases and toxicity. Various debiasing approaches have been proposed, which are primarily categorized into data-based and decoding-based. In our study, we investigate the ensemble of the two debiasing paradigms, proposing to use toxic corpus as an additional resource to reduce the toxicity. Our result shows that toxic corpus can indeed help to reduce the toxicity of the language generation process substantially, complementing the existing debiasing methods.</abstract>
      <url hash="d4ba48ea">2022.ltedi-1.6</url>
      <bibkey>park-rudzicz-2022-detoxifying</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.6</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/webtext">WebText</pwcdataset>
    </paper>
    <paper id="7">
      <title>Inferring Gender: A Scalable Methodology for Gender Detection with Online Lexical Databases</title>
      <author><first>Marion</first><last>Bartl</last></author>
      <author><first>Susan</first><last>Leavy</last></author>
      <pages>47-58</pages>
      <abstract>This paper presents a new method for automatic detection of gendered terms in large-scale language datasets. Currently, the evaluation of gender bias in natural language processing relies on the use of manually compiled lexicons of gendered expressions, such as pronouns and words that imply gender. However, manual compilation of lists with lexical gender can lead to static information if lists are not periodically updated and often involve value judgements by individual annotators and researchers. Moreover, terms not included in the lexicons fall out of the range of analysis.To address these issues, we devised a scalable dictionary-based method to automatically detect lexical gender that can provide a dynamic, up-to-date analysis with high coverage. Our approach reaches over 80% accuracy in determining the lexical gender of words retrieved randomly from a Wikipedia sample and when testing on a list of gendered words used in previous research.</abstract>
      <url hash="8c1b52db">2022.ltedi-1.7</url>
      <bibkey>bartl-leavy-2022-inferring</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.7</doi>
      <video href="2022.ltedi-1.7.mp4"/>
      <pwccode url="https://github.com/marionbartl/lexical-gender" additional="false">marionbartl/lexical-gender</pwccode>
    </paper>
    <paper id="8">
      <title>Debiasing Pre-Trained Language Models via Efficient Fine-Tuning</title>
      <author><first>Michael</first><last>Gira</last></author>
      <author><first>Ruisu</first><last>Zhang</last></author>
      <author><first>Kangwook</first><last>Lee</last></author>
      <pages>59-69</pages>
      <abstract>An explosion in the popularity of transformer-based language models (such as GPT-3, BERT, RoBERTa, and ALBERT) has opened the doors to new machine learning applications involving language modeling, text generation, and more. However, recent scrutiny reveals that these language models contain inherent biases towards certain demographics reflected in their training data. While research has tried mitigating this problem, existing approaches either fail to remove the bias completely, degrade performance (“catastrophic forgetting”), or are costly to execute. This work examines how to reduce gender bias in a GPT-2 language model by fine-tuning less than 1% of its parameters. Through quantitative benchmarks, we show that this is a viable way to reduce prejudice in pre-trained language models while remaining cost-effective at scale.</abstract>
      <url hash="ce82efcb">2022.ltedi-1.8</url>
      <bibkey>gira-etal-2022-debiasing</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.8</doi>
      <video href="2022.ltedi-1.8.mp4"/>
      <pwccode url="https://github.com/michaelgira23/debiasing-lms" additional="false">michaelgira23/debiasing-lms</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/crows-pairs">CrowS-Pairs</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/stereoset">StereoSet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/winobias">WinoBias</pwcdataset>
    </paper>
    <paper id="9">
      <title>Disambiguation of morpho-syntactic features of <fixed-case>A</fixed-case>frican <fixed-case>A</fixed-case>merican <fixed-case>E</fixed-case>nglish – the case of habitual be</title>
      <author><first>Harrison</first><last>Santiago</last></author>
      <author><first>Joshua</first><last>Martin</last></author>
      <author><first>Sarah</first><last>Moeller</last></author>
      <author><first>Kevin</first><last>Tang</last></author>
      <pages>70-75</pages>
      <abstract>Recent research has highlighted that natural language processing (NLP) systems exhibit a bias againstAfrican American speakers. These errors are often caused by poor representation of linguistic features unique to African American English (AAE), which is due to the relatively low probability of occurrence for many such features. We present a workflow to overcome this issue in the case of habitual “be”. Habitual “be” is isomorphic, and therefore ambiguous, with other forms of uninflected “be” found in both AAE and General American English (GAE). This creates a clear challenge for bias in NLP technologies. To overcome the scarcity, we employ a combination of rule-based filters and data augmentation that generate a corpus balanced between habitual and non-habitual instances. This balanced corpus trains unbiased machine learning classifiers, as demonstrated on a corpus of AAE transcribed texts, achieving .65 F<tex-math>_1</tex-math> score at classifying habitual “be”.</abstract>
      <url hash="979578b7">2022.ltedi-1.9</url>
      <bibkey>santiago-etal-2022-disambiguation</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.9</doi>
      <video href="2022.ltedi-1.9.mp4"/>
    </paper>
    <paper id="10">
      <title>Behind the Mask: Demographic bias in name detection for <fixed-case>PII</fixed-case> masking</title>
      <author><first>Courtney</first><last>Mansfield</last></author>
      <author><first>Amandalynne</first><last>Paullada</last></author>
      <author><first>Kristen</first><last>Howell</last></author>
      <pages>76-89</pages>
      <abstract>Many datasets contain personally identifiable information, or PII, which poses privacy risks to individuals. PII masking is commonly used to redact personal information such as names, addresses, and phone numbers from text data. Most modern PII masking pipelines involve machine learning algorithms. However, these systems may vary in performance, such that individuals from particular demographic groups bear a higher risk for having their personal information exposed. In this paper, we evaluate the performance of three off-the-shelf PII masking systems on name detection and redaction. We generate data using names and templates from the customer service domain. We find that an open-source RoBERTa-based system shows fewer disparities than the commercial models we test. However, all systems demonstrate significant differences in error rate based on demographics. In particular, the highest error rates occurred for names associated with Black and Asian/Pacific Islander individuals.</abstract>
      <url hash="1de9fb7e">2022.ltedi-1.10</url>
      <bibkey>mansfield-etal-2022-behind</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.10</doi>
      <video href="2022.ltedi-1.10.mp4"/>
      <pwccode url="https://github.com/csmansfield/pii-masking-bias" additional="false">csmansfield/pii-masking-bias</pwccode>
    </paper>
    <paper id="11">
      <title>Mapping the Multilingual Margins: Intersectional Biases of Sentiment Analysis Systems in <fixed-case>E</fixed-case>nglish, <fixed-case>S</fixed-case>panish, and <fixed-case>A</fixed-case>rabic</title>
      <author><first>António</first><last>Câmara</last></author>
      <author><first>Nina</first><last>Taneja</last></author>
      <author><first>Tamjeed</first><last>Azad</last></author>
      <author><first>Emily</first><last>Allaway</last></author>
      <author><first>Richard</first><last>Zemel</last></author>
      <pages>90-106</pages>
      <abstract>As natural language processing systems become more widespread, it is necessary to address fairness issues in their implementation and deployment to ensure that their negative impacts on society are understood and minimized. However, there is limited work that studies fairness using a multilingual and intersectional framework or on downstream tasks. In this paper, we introduce four multilingual Equity Evaluation Corpora, supplementary test sets designed to measure social biases, and a novel statistical framework for studying unisectional and intersectional social biases in natural language processing. We use these tools to measure gender, racial, ethnic, and intersectional social biases across five models trained on emotion regression tasks in English, Spanish, and Arabic. We find that many systems demonstrate statistically significant unisectional and intersectional social biases. We make our code and datasets available for download.</abstract>
      <url hash="79beaa13">2022.ltedi-1.11</url>
      <bibkey>camara-etal-2022-mapping</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.11</doi>
      <video href="2022.ltedi-1.11.mp4"/>
    </paper>
    <paper id="12">
      <title><fixed-case>M</fixed-case>onte <fixed-case>C</fixed-case>arlo Tree Search for Interpreting Stress in Natural Language</title>
      <author><first>Kyle</first><last>Swanson</last></author>
      <author><first>Joy</first><last>Hsu</last></author>
      <author><first>Mirac</first><last>Suzgun</last></author>
      <pages>107-119</pages>
      <abstract>Natural language processing can facilitate the analysis of a person’s mental state from text they have written. Previous studies have developed models that can predict whether a person is experiencing a mental health condition from social media posts with high accuracy. Yet, these models cannot explain why the person is experiencing a particular mental state. In this work, we present a new method for explaining a person’s mental state from text using Monte Carlo tree search (MCTS). Our MCTS algorithm employs trained classification models to guide the search for key phrases that explain the writer’s mental state in a concise, interpretable manner. Furthermore, our algorithm can find both explanations that depend on the particular context of the text (e.g., a recent breakup) and those that are context-independent. Using a dataset of Reddit posts that exhibit stress, we demonstrate the ability of our MCTS algorithm to identify interpretable explanations for a person’s feeling of stress in both a context-dependent and context-independent manner.</abstract>
      <url hash="1de1b1ec">2022.ltedi-1.12</url>
      <bibkey>swanson-etal-2022-monte</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.12</doi>
      <video href="2022.ltedi-1.12.mp4"/>
      <pwccode url="https://github.com/swansonk14/mcts_interpretability" additional="false">swansonk14/mcts_interpretability</pwccode>
    </paper>
    <paper id="13">
      <title><fixed-case>IIITS</fixed-case>urat@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Hope Speech Detection using Machine Learning</title>
      <author><first>Pradeep</first><last>Roy</last></author>
      <author><first>Snehaan</first><last>Bhawal</last></author>
      <author><first>Abhinav</first><last>Kumar</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <pages>120-126</pages>
      <abstract>This paper addresses the issue of Hope Speech detection using machine learning techniques. Designing a robust model that helps in predicting the target class with higher accuracy is a challenging task in machine learning, especially when the distribution of the class labels is highly imbalanced. This study uses and compares the experimental outcomes of the different oversampling techniques. Many models are implemented to classify the comments into Hope and Non-Hope speech, and it found that machine learning algorithms perform better than deep learning models. The English language dataset used in this research was developed by collecting YouTube comments and is part of the task “ACL-2022:Hope Speech Detection for Equality, Diversity, and Inclusion”. The proposed model achieved a weighted F1-score of 0.55 on the test dataset and secured the first rank among the participated teams.</abstract>
      <url hash="69a45d6f">2022.ltedi-1.13</url>
      <bibkey>roy-etal-2022-iiitsurat</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.13</doi>
    </paper>
    <paper id="14">
      <title>The Best of both Worlds: Dual Channel Language modeling for Hope Speech Detection in low-resourced <fixed-case>K</fixed-case>annada</title>
      <author><first>Adeep</first><last>Hande</last></author>
      <author><first>Siddhanth</first><last>U Hegde</last></author>
      <author><first>Sangeetha</first><last>S</last></author>
      <author><first>Ruba</first><last>Priyadharshini</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <pages>127-135</pages>
      <abstract>In recent years, various methods have been developed to control the spread of negativity by removing profane, aggressive, and offensive comments from social media platforms. There is, however, a scarcity of research focusing on embracing positivity and reinforcing supportive and reassuring content in online forums. As a result, we concentrate our research on developing systems to detect hope speech in code-mixed Kannada. As a result, we present DC-LM, a dual-channel language model that sees hope speech by using the English translations of the code-mixed dataset for additional training. The approach is jointly modelled on both English and code-mixed Kannada to enable effective cross-lingual transfer between the languages. With a weighted F1-score of 0.756, the method outperforms other models. We aim to initiate research in Kannada while encouraging researchers to take a pragmatic approach to inspire positive and supportive online content.</abstract>
      <url hash="17b95867">2022.ltedi-1.14</url>
      <bibkey>hande-etal-2022-best</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.14</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/kanhope">KanHope</pwcdataset>
    </paper>
    <paper id="15">
      <title><fixed-case>NYCU</fixed-case>_<fixed-case>TWD</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Ensemble Models with <fixed-case>VADER</fixed-case> and Contrastive Learning for Detecting Signs of Depression from Social Media</title>
      <author><first>Wei-Yao</first><last>Wang</last></author>
      <author><first>Yu-Chien</first><last>Tang</last></author>
      <author><first>Wei-Wei</first><last>Du</last></author>
      <author><first>Wen-Chih</first><last>Peng</last></author>
      <pages>136-139</pages>
      <abstract>This paper presents a state-of-the-art solution to the LT-EDI-ACL 2022 Task 4: <i>Detecting Signs of Depression from Social Media Text</i>. The goal of this task is to detect the severity levels of depression of people from social media posts, where people often share their feelings on a daily basis. To detect the signs of depression, we propose a framework with pre-trained language models using rich information instead of training from scratch, gradient boosting and deep learning models for modeling various aspects, and supervised contrastive learning for the generalization ability. Moreover, ensemble techniques are also employed in consideration of the different advantages of each method. Experiments show that our framework achieves a 2nd prize ranking with a macro F1-score of 0.552, showing the effectiveness and robustness of our approach.</abstract>
      <url hash="d5c8365b">2022.ltedi-1.15</url>
      <bibkey>wang-etal-2022-nycu</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.15</doi>
      <video href="2022.ltedi-1.15.mp4"/>
    </paper>
    <paper id="16">
      <title><fixed-case>UMUT</fixed-case>eam@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Detecting homophobic and transphobic comments in <fixed-case>T</fixed-case>amil</title>
      <author><first>José</first><last>García-Díaz</last></author>
      <author><first>Camilo</first><last>Caparros-Laiz</last></author>
      <author><first>Rafael</first><last>Valencia-García</last></author>
      <pages>140-144</pages>
      <abstract>This working-notes are about the participation of the UMUTeam in a LT-EDI shared task concerning the identification of homophobic and transphobic comments in YouTube. These comments are written in English, which has high availability to machine-learning resources; Tamil, which has fewer resources; and a transliteration from Tamil to Roman script combined with English sentences. To carry out this shared task, we train a neural network that combines several feature sets applying a knowledge integration strategy. These features are linguistic features extracted from a tool developed by our research group and contextual and non-contextual sentence embeddings. We ranked 7th for English subtask (macro f1-score of 45%), 3rd for Tamil subtask (macro f1-score of 82%), and 2nd for Tamil-English subtask (macro f1-score of 58%).</abstract>
      <url hash="f32f88a2">2022.ltedi-1.16</url>
      <bibkey>garcia-diaz-etal-2022-umuteam-lt</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.16</doi>
      <video href="2022.ltedi-1.16.mp4"/>
    </paper>
    <paper id="17">
      <title><fixed-case>UMUT</fixed-case>eam@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Detecting Signs of Depression from text</title>
      <author><first>José</first><last>García-Díaz</last></author>
      <author><first>Rafael</first><last>Valencia-García</last></author>
      <pages>145-148</pages>
      <abstract>Depression is a mental condition related to sadness and the lack of interest in common daily tasks. In this working-notes, we describe the proposal of the UMUTeam in the LT-EDI shared task (ACL 2022) concerning the identification of signs of depression in social network posts. This task is somehow related to other relevant Natural Language Processing tasks such as Emotion Analysis. In this shared task, the organisers challenged the participants to distinguish between moderate and severe signs of depression (or no signs of depression at all) in a set of social posts written in English. Our proposal is based on the combination of linguistic features and several sentence embeddings using a knowledge integration strategy. Our proposal achieved the 6th position, with a macro f1-score of 53.82 in the official leader board.</abstract>
      <url hash="7a96f69d">2022.ltedi-1.17</url>
      <bibkey>garcia-diaz-valencia-garcia-2022-umuteam</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.17</doi>
      <video href="2022.ltedi-1.17.mp4"/>
    </paper>
    <paper id="18">
      <title>bitsa_nlp@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Leveraging Pretrained Language Models for Detecting Homophobia and Transphobia in Social Media Comments</title>
      <author><first>Vitthal</first><last>Bhandari</last></author>
      <author><first>Poonam</first><last>Goyal</last></author>
      <pages>149-154</pages>
      <abstract>Online social networks are ubiquitous and user-friendly. Nevertheless, it is vital to detect and moderate offensive content to maintain decency and empathy. However, mining social media texts is a complex task since users don’t adhere to any fixed patterns. Comments can be written in any combination of languages and many of them may be low-resource.In this paper, we present our system for the LT-EDI shared task on detecting homophobia and transphobia in social media comments. We experiment with a number of monolingual and multilingual transformer based models such as mBERT along with a data augmentation technique for tackling class imbalance. Such pretrained large models have recently shown tremendous success on a variety of benchmark tasks in natural language processing. We observe their performance on a carefully annotated, real life dataset of YouTube comments in English as well as Tamil.Our submission achieved ranks 9, 6 and 3 with a macro-averaged F1-score of 0.42, 0.64 and 0.58 in the English, Tamil and Tamil-English subtasks respectively. The code for the system has been open sourced.</abstract>
      <url hash="8d387f84">2022.ltedi-1.18</url>
      <bibkey>bhandari-goyal-2022-bitsa</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.18</doi>
      <video href="2022.ltedi-1.18.mp4"/>
      <pwccode url="https://github.com/vitthal-bhandari/homophobia-transphobia-detection" additional="false">vitthal-bhandari/homophobia-transphobia-detection</pwccode>
    </paper>
    <paper id="19">
      <title><fixed-case>ABLIMET</fixed-case> @<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: A Roberta based Approach for Homophobia/Transphobia Detection in Social Media</title>
      <author><first>Abulimiti</first><last>Maimaitituoheti</last></author>
      <pages>155-160</pages>
      <abstract>This paper describes our system that participated in LT-EDI-ACL2022- Homophobia/Transphobia Detection in Social Media. Sexual minorities face a lot of unfair treatment and discrimination in our world. This creates enormous stress and many psychological problems for sexual minorities. There is a lot of hate speech on the internet, and Homophobia/Transphobia is the one against sexual minorities. Identifying and processing Homophobia/ Transphobia through natural language processing technology can improve the efficiency of processing Homophobia/ Transphobia, and can quickly screen out Homophobia/Transphobia on the Internet. The organizer of LT-EDI-ACL2022- Homophobia/Transphobia Detection in Social Media constructs a Homophobia/ Transphobia detection dataset based on YouTube comments for English and Tamil. We use a Roberta -based approach to conduct Homophobia/ Transphobia detection experiments on the dataset of the competition, and get better results.</abstract>
      <url hash="fbe03eaf">2022.ltedi-1.19</url>
      <bibkey>maimaitituoheti-2022-ablimet</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.19</doi>
      <video href="2022.ltedi-1.19.mp4"/>
    </paper>
    <paper id="20">
      <title><fixed-case>MUCIC</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Hope Speech Detection using Data Re-Sampling and 1<fixed-case>D</fixed-case> Conv-<fixed-case>LSTM</fixed-case></title>
      <author><first>Anusha</first><last>Gowda</last></author>
      <author><first>Fazlourrahman</first><last>Balouchzahi</last></author>
      <author><first>Hosahalli</first><last>Shashirekha</last></author>
      <author><first>Grigori</first><last>Sidorov</last></author>
      <pages>161-166</pages>
      <abstract>Spreading positive vibes or hope content on social media may help many people to get motivated in their life. To address Hope Speech detection in YouTube comments, this paper presents the description of the models submitted by our team - MUCIC, to the Hope Speech Detection for Equality, Diversity, and Inclusion (HopeEDI) shared task at Association for Computational Linguistics (ACL) 2022. This shared task consists of texts in five languages, namely: English, Spanish (in Latin scripts), and Tamil, Malayalam, and Kannada (in code-mixed native and Roman scripts) with the aim of classifying the YouTube comment into “Hope”, “Not-Hope” or “Not-Intended” categories. The proposed methodology uses the re-sampling technique to deal with imbalanced data in the corpus and obtained 1st rank for English language with a macro-averaged F1-score of 0.550 and weighted-averaged F1-score of 0.860. The code to reproduce this work is available in GitHub.</abstract>
      <url hash="4a9ca6e1">2022.ltedi-1.20</url>
      <bibkey>gowda-etal-2022-mucic</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.20</doi>
      <video href="2022.ltedi-1.20.mp4"/>
    </paper>
    <paper id="21">
      <title><fixed-case>D</fixed-case>eep<fixed-case>B</fixed-case>lues@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Depression level detection modelling through domain specific <fixed-case>BERT</fixed-case> and short text Depression classifiers</title>
      <author><first>Nawshad</first><last>Farruque</last></author>
      <author><first>Osmar</first><last>Zaiane</last></author>
      <author><first>Randy</first><last>Goebel</last></author>
      <author><first>Sudhakar</first><last>Sivapalan</last></author>
      <pages>167-171</pages>
      <abstract>We discuss a variety of approaches to build a robust Depression level detection model from longer social media posts (i.e., Reddit Depression forum posts) using a mental health text pre-trained BERT model. Further, we report our experimental results based on a strategy to select excerpts from long text and then fine-tune the BERT model to combat the issue of memory constraints while processing such texts. We show that, with domain specific BERT, we can achieve reasonable accuracy with fixed text size (in this case 200 tokens) for this task. In addition we can use short text classifiers to extract relevant text from the long text and achieve slightly better accuracy, albeit, trading off with the processing time for extracting such excerpts.</abstract>
      <url hash="656c9e88">2022.ltedi-1.21</url>
      <bibkey>farruque-etal-2022-deepblues</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.21</doi>
      <video href="2022.ltedi-1.21.mp4"/>
    </paper>
    <paper id="22">
      <title><fixed-case>SSN</fixed-case>_<fixed-case>ARMM</fixed-case>@ <fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case> -<fixed-case>ACL</fixed-case>2022: Hope Speech Detection for Equality, Diversity, and Inclusion Using <fixed-case>ALBERT</fixed-case> model</title>
      <author><first>Praveenkumar</first><last>Vijayakumar</last></author>
      <author><first>Prathyush</first><last>S</last></author>
      <author><first>Aravind</first><last>P</last></author>
      <author><first>Angel</first><last>S</last></author>
      <author><first>Rajalakshmi</first><last>Sivanaiah</last></author>
      <author><first>Sakaya Milton</first><last>Rajendram</last></author>
      <author><first>Mirnalinee</first><last>T T</last></author>
      <pages>172-176</pages>
      <abstract>In recent years social media has become one of the major forums for expressing human views and emotions. With the help of smartphones and high-speed internet, anyone can express their views on Social media. However, this can also lead to the spread of hatred and violence in society. Therefore it is necessary to build a method to find and support helpful social media content. In this paper, we studied Natural Language Processing approach for detecting Hope speech in a given sentence. The task was to classify the sentences into ‘Hope speech’ and ‘Non-hope speech’. The dataset was provided by LT-EDI organizers with text from Youtube comments. Based on the task description, we developed a system using the pre-trained language model BERT to complete this task. Our model achieved 1st rank in the Kannada language with a weighted average F1 score of 0.750, 2nd rank in the Malayalam language with a weighted average F1 score of 0.740, 3rd rank in the Tamil language with a weighted average F1 score of 0.390 and 6th rank in the English language with a weighted average F1 score of 0.880.</abstract>
      <url hash="950617e9">2022.ltedi-1.22</url>
      <bibkey>vijayakumar-etal-2022-ssn</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.22</doi>
      <video href="2022.ltedi-1.22.mp4"/>
    </paper>
    <paper id="23">
      <title><fixed-case>SUH</fixed-case>_<fixed-case>ASR</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Transformer based Approach for Speech Recognition for Vulnerable Individuals in <fixed-case>T</fixed-case>amil</title>
      <author><first>Suhasini</first><last>S</last></author>
      <author><first>Bharathi</first><last>B</last></author>
      <pages>177-182</pages>
      <abstract>An Automatic Speech Recognition System is developed for addressing the Tamil conversational speech data of the elderly people andtransgender. The speech corpus used in this system is collected from the people who adhere their communication in Tamil at some primary places like bank, hospital, vegetable markets. Our ASR system is designed with pre-trained model which is used to recognize the speechdata. WER(Word Error Rate) calculation is used to analyse the performance of the ASR system. This evaluation could help to make acomparison of utterances between the elderly people and others. Similarly, the comparison between the transgender and other people isalso done. Our proposed ASR system achieves the word error rate as 39.65%.</abstract>
      <url hash="682ada8c">2022.ltedi-1.23</url>
      <bibkey>s-b-2022-suh</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.23</doi>
      <video href="2022.ltedi-1.23.mp4"/>
    </paper>
    <paper id="24">
      <title><fixed-case>LPS</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022:An Ensemble Approach about Hope Speech Detection</title>
      <author><first>Yue</first><last>Zhu</last></author>
      <pages>183-189</pages>
      <abstract>The task shared by sponsor about Hope Speech Detection for Equality, Diversity, and Inclusion at LT-EDI-ACL-2022.The goal of this task is to identify whether a given comment contains hope speech or not,and hope is considered significant for the well-being, recuperation and restoration of human life.Our work aims to change the prevalent way of thinking by moving away from a preoccupation with discrimination, loneliness or the worst things in life to building the confidence, support and good qualities based on comments by individuals. In response to the need to detect equality, diversity and inclusion of hope speech in a multilingual environment, we built an integration model and achieved well performance on multiple datasets presented by the sponsor and the specific results can be referred to the experimental results section.</abstract>
      <url hash="52a48826">2022.ltedi-1.24</url>
      <bibkey>zhu-2022-lps</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.24</doi>
      <video href="2022.ltedi-1.24.mp4"/>
    </paper>
    <paper id="25">
      <title><fixed-case>CURAJ</fixed-case>_<fixed-case>IIITDWD</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case> 2022: Hope Speech Detection in <fixed-case>E</fixed-case>nglish <fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube Comments using Deep Learning Techniques</title>
      <author><first>Vanshita</first><last>Jha</last></author>
      <author><first>Ankit</first><last>Mishra</last></author>
      <author><first>Sunil</first><last>Saumya</last></author>
      <pages>190-195</pages>
      <abstract>Hope Speech are positive terms that help to promote or criticise a point of view without hurting the user’s or community’s feelings. Non-Hope Speech, on the other side, includes expressions that are harsh, ridiculing, or demotivating. The goal of this article is to find the hope speech comments in a YouTube dataset. The datasets were created as part of the “LT-EDI-ACL 2022: Hope Speech Detection for Equality, Diversity, and Inclusion” shared task. The shared task dataset was proposed in Malayalam, Tamil, English, Spanish, and Kannada languages. In this paper, we worked at English-language YouTube comments. We employed several deep learning based models such as DNN (dense or fully connected neural network), CNN (Convolutional Neural Network), Bi-LSTM (Bidirectional Long Short Term Memory Network), and GRU(Gated Recurrent Unit) to identify the hopeful comments. We also used Stacked LSTM-CNN and Stacked LSTM-LSTM network to train the model. The best macro average F1-score 0.67 for development dataset was obtained using the DNN model. The macro average F1-score of 0.67 was achieved for the classification done on the test data as well.</abstract>
      <url hash="8e4c1537">2022.ltedi-1.25</url>
      <bibkey>jha-etal-2022-curaj</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.25</doi>
      <video href="2022.ltedi-1.25.mp4"/>
    </paper>
    <paper id="26">
      <title><fixed-case>SSN</fixed-case>_<fixed-case>MLRG</fixed-case>3 @<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022-Depression Detection System from Social Media Text using Transformer Models</title>
      <author><first>Sarika</first><last>Esackimuthu</last></author>
      <author><first>Shruthi</first><last>Hariprasad</last></author>
      <author><first>Rajalakshmi</first><last>Sivanaiah</last></author>
      <author><first>Angel</first><last>S</last></author>
      <author><first>Sakaya Milton</first><last>Rajendram</last></author>
      <author><first>Mirnalinee</first><last>T T</last></author>
      <pages>196-199</pages>
      <abstract>Depression is a common mental illness that involves sadness and lack of interest in all day-to-day activities. The task is to classify the social media text as signs of depression into three labels namely “not depressed”, “moderately depressed”, and “severely depressed”. We have build a system using Deep Learning Model “Transformers”. Transformers provides thousands of pretrained models to perform tasks on different modalities such as text, vision, and audio. The multi-class classification model used in our system is based on the ALBERT model. In the shared task ACL 2022, Our team SSN_MLRG3 obtained a Macro F1 score of 0.473.</abstract>
      <url hash="1aa67cf7">2022.ltedi-1.26</url>
      <bibkey>esackimuthu-etal-2022-ssn</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.26</doi>
      <video href="2022.ltedi-1.26.mp4"/>
    </paper>
    <paper id="27">
      <title><fixed-case>BERT</fixed-case> 4<fixed-case>EVER</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022-Detecting signs of Depression from Social Media:Detecting Depression in Social Media using Prompt-Learning and Word-Emotion Cluster</title>
      <author><first>Xiaotian</first><last>Lin</last></author>
      <author><first>Yingwen</first><last>Fu</last></author>
      <author><first>Ziyu</first><last>Yang</last></author>
      <author><first>Nankai</first><last>Lin</last></author>
      <author><first>Shengyi</first><last>Jiang</last></author>
      <pages>200-205</pages>
      <abstract>In this paper, we report the solution of the team BERT 4EVER for the LT-EDI-2022 shared task2: Homophobia/Transphobia Detection in social media comments in ACL 2022, which aims to classify Youtube comments into one of the following categories: no,moderate, or severe depression. We model the problem as a text classification task and a text generation task and respectively propose two different models for the tasks.To combine the knowledge learned from these two different models, we softly fuse the predicted probabilities of the models above and then select the label with the highest probability as the final output.In addition, multiple augmentation strategies are leveraged to improve the model generalization capability, such as back translation and adversarial training.Experimental results demonstrate the effectiveness of the proposed models and two augmented strategies.</abstract>
      <url hash="c16cfaf8">2022.ltedi-1.27</url>
      <bibkey>lin-etal-2022-bert</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.27</doi>
      <video href="2022.ltedi-1.27.mp4"/>
    </paper>
    <paper id="28">
      <title><fixed-case>CIC</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Are transformers the only hope? Hope speech detection for <fixed-case>S</fixed-case>panish and <fixed-case>E</fixed-case>nglish comments</title>
      <author><first>Fazlourrahman</first><last>Balouchzahi</last></author>
      <author><first>Sabur</first><last>Butt</last></author>
      <author><first>Grigori</first><last>Sidorov</last></author>
      <author><first>Alexander</first><last>Gelbukh</last></author>
      <pages>206-211</pages>
      <abstract>Hope is an inherent part of human life and essential for improving the quality of life. Hope increases happiness and reduces stress and feelings of helplessness. Hope speech is the desired outcome for better and can be studied using text from various online sources where people express their desires and outcomes. In this paper, we address a deep-learning approach with a combination of linguistic and psycho-linguistic features for hope-speech detection. We report our best results submitted to LT-EDI-2022 which ranked 2nd and 3rd in English and Spanish respectively.</abstract>
      <url hash="af9c8baf">2022.ltedi-1.28</url>
      <bibkey>balouchzahi-etal-2022-cic</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.28</doi>
      <video href="2022.ltedi-1.28.mp4"/>
    </paper>
    <paper id="29">
      <title>scube<fixed-case>MSEC</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Detection of Depression using Transformer Models</title>
      <author><first>Sivamanikandan</first><last>S</last></author>
      <author><first>Santhosh</first><last>V</last></author>
      <author><first>Sanjaykumar</first><last>N</last></author>
      <author><first>Jerin Mahibha</first><last>C</last></author>
      <author><first>Thenmozhi</first><last>Durairaj</last></author>
      <pages>212-217</pages>
      <abstract>Social media platforms play a major role in our day-to-day life and are considered as a virtual friend by many users, who use the social media to share their feelings all day. Many a time, the content which is shared by users on social media replicate their internal life. Nowadays people love to share their daily life incidents like happy or unhappy moments and their feelings in social media and it makes them feel complete and it has become a habit for many users. Social media provides a new chance to identify the feelings of a person through their posts. The aim of the shared task is to develop a model in which the system is capable of analyzing the grammatical markers related to onset and permanent symptoms of depression. We as a team participated in the shared task Detecting Signs of Depression from Social Media Text at LT-EDI 2022- ACL 2022 and we have proposed a model which predicts depression from English social media posts using the data set shared for the task. The prediction is done based on the labels Moderate, Severe and Not Depressed. We have implemented this using different transformer models like DistilBERT, RoBERTa and ALBERT by which we were able to achieve a Macro F1 score of 0.337, 0.457 and 0.387 respectively. Our code is publicly available in the github</abstract>
      <url hash="7bd2faef">2022.ltedi-1.29</url>
      <bibkey>s-etal-2022-scubemsec</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.29</doi>
    </paper>
    <paper id="30">
      <title><fixed-case>SSNCSE</fixed-case>_<fixed-case>NLP</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022:Hope Speech Detection for Equality, Diversity and Inclusion using sentence transformers</title>
      <author><first>Bharathi</first><last>B</last></author>
      <author><first>Dhanya</first><last>Srinivasan</last></author>
      <author><first>Josephine</first><last>Varsha</last></author>
      <author><first>Thenmozhi</first><last>Durairaj</last></author>
      <author><first>Senthil Kumar</first><last>B</last></author>
      <pages>218-222</pages>
      <abstract>In recent times, applications have been developed to regulate and control the spread of negativity and toxicity on online platforms. The world is filled with serious problems like political &amp; religious conflicts, wars, pandemics, and offensive hate speech is the last thing we desire. Our task was to classify a text into ‘Hope Speech’ and ‘Non-Hope Speech’. We searched for datasets acquired from YouTube comments that offer support, reassurance, inspiration, and insight, and the ones that don’t. The datasets were provided to us by the LTEDI organizers in English, Tamil, Spanish, Kannada, and Malayalam. To successfully identify and classify them, we employed several machine learning transformer models such as m-BERT, MLNet, BERT, XLMRoberta, and XLM_MLM. The observed results indicate that the BERT and m-BERT have obtained the best results among all the other techniques, gaining a weighted F1- score of 0.92, 0.71, 0.76, 0.87, and 0.83 for English, Tamil, Spanish, Kannada, and Malayalam respectively. This paper depicts our work for the Shared Task on Hope Speech Detection for Equality, Diversity, and Inclusion at LTEDI 2021.</abstract>
      <url hash="8ad795b0">2022.ltedi-1.30</url>
      <bibkey>b-etal-2022-ssncse</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.30</doi>
      <video href="2022.ltedi-1.30.mp4"/>
    </paper>
    <paper id="31">
      <title><fixed-case>SOA</fixed-case>_<fixed-case>NLP</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: An Ensemble Model for Hope Speech Detection from <fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube Comments</title>
      <author><first>Abhinav</first><last>Kumar</last></author>
      <author><first>Sunil</first><last>Saumya</last></author>
      <author><first>Pradeep</first><last>Roy</last></author>
      <pages>223-228</pages>
      <abstract>Language should be accommodating of equality and diversity as a fundamental aspect of communication. The language of internet users has a big impact on peer users all over the world. On virtual platforms such as Facebook, Twitter, and YouTube, people express their opinions in different languages. People respect others’ accomplishments, pray for their well-being, and cheer them on when they fail. Such motivational remarks are hope speech remarks. Simultaneously, a group of users encourages discrimination against women, people of color, people with disabilities, and other minorities based on gender, race, sexual orientation, and other factors. To recognize hope speech from YouTube comments, the current study offers an ensemble approach that combines a support vector machine, logistic regression, and random forest classifiers. Extensive testing was carried out to discover the best features for the aforementioned classifiers. In the support vector machine and logistic regression classifiers, char-level TF-IDF features were used, whereas in the random forest classifier, word-level features were used. The proposed ensemble model performed significantly well among English, Spanish, Tamil, Malayalam, and Kannada YouTube comments.</abstract>
      <url hash="20541550">2022.ltedi-1.31</url>
      <bibkey>kumar-etal-2022-soa</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.31</doi>
    </paper>
    <paper id="32">
      <title><fixed-case>IIT</fixed-case> Dhanbad @<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022- Hope Speech Detection for Equality, Diversity, and Inclusion</title>
      <author><first>Vishesh</first><last>Gupta</last></author>
      <author><first>Ritesh</first><last>Kumar</last></author>
      <author><first>Rajendra</first><last>Pamula</last></author>
      <pages>229-233</pages>
      <abstract>Hope is considered significant for the wellbeing,recuperation and restoration of humanlife by health professionals. Hope speech reflectsthe belief that one can discover pathwaysto their desired objectives and become rousedto utilise those pathways. Hope speech offerssupport, reassurance, suggestions, inspirationand insight. Hate speech is a prevalent practicethat society has to struggle with everyday.The freedom of speech and ease of anonymitygranted by social media has also resulted inincitement to hatred. In this paper, we workto identify and promote positive and supportivecontent on these platforms. We work withseveral machine learning models to classify socialmedia comments as hope speech or nonhopespeech in English. This paper portraysour work for the Shared Task on Hope SpeechDetection for Equality, Diversity, and Inclusionat LT-EDI-ACL 2022.</abstract>
      <url hash="a756987e">2022.ltedi-1.32</url>
      <bibkey>gupta-etal-2022-iit</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.32</doi>
    </paper>
    <paper id="33">
      <title><fixed-case>IISERB</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: A Bag of Words and Document Embeddings Based Framework to Identify Severity of Depression Over Social Media</title>
      <author><first>Tanmay</first><last>Basu</last></author>
      <pages>234-238</pages>
      <abstract>The DepSign-LT-EDI-ACL2022 shared task focuses on early prediction of severity of depression over social media posts. The BioNLP group at Department of Data Science and Engineering in Indian Institute of Science Education and Research Bhopal (IISERB) has participated in this challenge and submitted three runs based on three different text mining models. The severity of depression were categorized into three classes, viz., no depression, moderate, and severe and the data to build models were released as part of this shared task. The objective of this work is to identify relevant features from the given social media texts for effective text classification. As part of our investigation, we explored features derived from text data using document embeddings technique and simple bag of words model following different weighting schemes. Subsequently, adaptive boosting, logistic regression, random forest and support vector machine (SVM) classifiers were used to identify the scale of depression from the given texts. The experimental analysis on the given validation data show that the SVM classifier using the bag of words model following term frequency and inverse document frequency weighting scheme outperforms the other models for identifying depression. However, this framework could not achieve a place among the top ten runs of the shared task. This paper describes the potential of the proposed framework as well as the possible reasons behind mediocre performance on the given data.</abstract>
      <url hash="7cedc79e">2022.ltedi-1.33</url>
      <bibkey>basu-2022-iiserb</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.33</doi>
      <video href="2022.ltedi-1.33.mp4"/>
    </paper>
    <paper id="34">
      <title><fixed-case>SSNCSE</fixed-case>_<fixed-case>NLP</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Homophobia/Transphobia Detection in Multiple Languages using <fixed-case>SVM</fixed-case> Classifiers and <fixed-case>BERT</fixed-case>-based Transformers</title>
      <author><first>Krithika</first><last>Swaminathan</last></author>
      <author><first>Bharathi</first><last>B</last></author>
      <author><first>Gayathri</first><last>G L</last></author>
      <author><first>Hrishik</first><last>Sampath</last></author>
      <pages>239-244</pages>
      <abstract>Over the years, there has been a slow but steady change in the attitude of society towards different kinds of sexuality. However, on social media platforms, where people have the license to be anonymous, toxic comments targeted at homosexuals, transgenders and the LGBTQ+ community are not uncommon. Detection of homophobic comments on social media can be useful in making the internet a safer place for everyone. For this task, we used a combination of word embeddings and SVM Classifiers as well as some BERT-based transformers. We achieved a weighted F1-score of 0.93 on the English dataset, 0.75 on the Tamil dataset and 0.87 on the Tamil-English Code-Mixed dataset.</abstract>
      <url hash="8cd772cb">2022.ltedi-1.34</url>
      <bibkey>swaminathan-etal-2022-ssncse</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.34</doi>
      <video href="2022.ltedi-1.34.mp4"/>
    </paper>
    <paper id="35">
      <title><fixed-case>KUCST</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Detecting Signs of Depression from Social Media Text</title>
      <author><first>Manex</first><last>Agirrezabal</last></author>
      <author><first>Janek</first><last>Amann</last></author>
      <pages>245-250</pages>
      <abstract>In this paper we present our approach for detecting signs of depression from social media text. Our model relies on word unigrams, part-of-speech tags, readabilitiy measures and the use of first, second or third person and the number of words. Our best model obtained a macro F1-score of 0.439 and ranked 25th, out of 31 teams. We further take advantage of the interpretability of the Logistic Regression model and we make an attempt to interpret the model coefficients with the hope that these will be useful for further research on the topic.</abstract>
      <url hash="d4fe8de2">2022.ltedi-1.35</url>
      <bibkey>agirrezabal-amann-2022-kucst</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.35</doi>
      <video href="2022.ltedi-1.35.mp4"/>
    </paper>
    <paper id="36">
      <title>E8-<fixed-case>IJS</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022 - <fixed-case>BERT</fixed-case>, <fixed-case>A</fixed-case>uto<fixed-case>ML</fixed-case> and Knowledge-graph backed Detection of Depression</title>
      <author><first>Ilija</first><last>Tavchioski</last></author>
      <author><first>Boshko</first><last>Koloski</last></author>
      <author><first>Blaž</first><last>Škrlj</last></author>
      <author><first>Senja</first><last>Pollak</last></author>
      <pages>251-257</pages>
      <abstract>Depression is a mental illness that negatively affects a person’s well-being and can, if left untreated, lead to serious consequences such as suicide. Therefore, it is important to recognize the signs of depression early. In the last decade, social media has become one of the most common places to express one’s feelings. Hence, there is a possibility of text processing and applying machine learning techniques to detect possible signs of depression. In this paper, we present our approaches to solving the shared task titled Detecting Signs of Depression from Social Media Text. We explore three different approaches to solve the challenge: fine-tuning BERT model, leveraging AutoML for the construction of features and classifier selection and finally, we explore latent spaces derived from the combination of textual and knowledge-based representations. We ranked 9th out of 31 teams in the competition. Our best solution, based on knowledge graph and textual representations, was 4.9% behind the best model in terms of Macro F1, and only 1.9% behind in terms of Recall.</abstract>
      <url hash="92ac5dd7">2022.ltedi-1.36</url>
      <bibkey>tavchioski-etal-2022-e8</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.36</doi>
      <video href="2022.ltedi-1.36.mp4"/>
    </paper>
    <paper id="37">
      <title>Nozza@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Ensemble Modeling for Homophobia and Transphobia Detection</title>
      <author><first>Debora</first><last>Nozza</last></author>
      <pages>258-264</pages>
      <abstract>In this paper, we describe our approach for the task of homophobia and transphobia detection in English social media comments. The dataset consists of YouTube comments, and it has been released for the shared task on Homophobia/Transphobia Detection in social media comments. Given the high class imbalance, we propose a solution based on data augmentation and ensemble modeling. We fine-tuned different large language models (BERT, RoBERTa, and HateBERT) and used the weighted majority vote on their predictions.Our proposed model obtained 0.48 and 0.94 for macro and weighted F1-score, respectively, ranking at the third position.</abstract>
      <url hash="547de08c">2022.ltedi-1.37</url>
      <bibkey>nozza-2022-nozza</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.37</doi>
      <video href="2022.ltedi-1.37.mp4"/>
    </paper>
    <paper id="38">
      <title><fixed-case>KADO</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: <fixed-case>BERT</fixed-case>-based Ensembles for Detecting Signs of Depression from Social Media Text</title>
      <author><first>Morteza</first><last>Janatdoust</last></author>
      <author><first>Fatemeh</first><last>Ehsani-Besheli</last></author>
      <author><first>Hossein</first><last>Zeinali</last></author>
      <pages>265-269</pages>
      <abstract>Depression is a common and serious mental illness that early detection can improve the patient’s symptoms and make depression easier to treat. This paper mainly introduces the relevant content of the task “Detecting Signs of Depression from Social Media Text at DepSign-LT-EDI@ACL-2022”. The goal of DepSign is to classify the signs of depression into three labels namely “not depressed”, “moderately depressed”, and “severely depressed” based on social media’s posts. In this paper, we propose a predictive ensemble model that utilizes the fine-tuned contextualized word embedding, ALBERT, DistilBERT, RoBERTa, and BERT base model. We show that our model outperforms the baseline models in all considered metrics and achieves an F1 score of 54% and accuracy of 61%, ranking 5th on the leader-board for the DepSign task.</abstract>
      <url hash="6d48753e">2022.ltedi-1.38</url>
      <bibkey>janatdoust-etal-2022-kado</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.38</doi>
    </paper>
    <paper id="39">
      <title>Sammaan@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Ensembled Transformers Against Homophobia and Transphobia</title>
      <author><first>Ishan Sanjeev</first><last>Upadhyay</last></author>
      <author><first>Kv Aditya</first><last>Srivatsa</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <pages>270-275</pages>
      <abstract>Hateful and offensive content on social media platforms can have negative effects on users and can make online communities more hostile towards certain people and hamper equality, diversity and inclusion. In this paper, we describe our approach to classify homophobia and transphobia in social media comments. We used an ensemble of transformer-based models to build our classifier. Our model ranked 2nd for English, 8th for Tamil and 10th for Tamil-English.</abstract>
      <url hash="5c20606c">2022.ltedi-1.39</url>
      <bibkey>upadhyay-etal-2022-sammaan</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.39</doi>
      <video href="2022.ltedi-1.39.mp4"/>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
    </paper>
    <paper id="40">
      <title><fixed-case>OPI</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Detecting Signs of Depression from Social Media Text using <fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a Pre-trained Language Models</title>
      <author><first>Rafał</first><last>Poświata</last></author>
      <author><first>Michał</first><last>Perełkiewicz</last></author>
      <pages>276-282</pages>
      <abstract>This paper presents our winning solution for the Shared Task on Detecting Signs of Depression from Social Media Text at LT-EDI-ACL2022. The task was to create a system that, given social media posts in English, should detect the level of depression as ‘not depressed’, ‘moderately depressed’ or ‘severely depressed’. We based our solution on transformer-based language models. We fine-tuned selected models: BERT, RoBERTa, XLNet, of which the best results were obtained for RoBERTa. Then, using the prepared corpus, we trained our own language model called DepRoBERTa (RoBERTa for Depression Detection). Fine-tuning of this model improved the results. The third solution was to use the ensemble averaging, which turned out to be the best solution. It achieved a macro-averaged F1-score of 0.583. The source code of prepared solution is available at https://github.com/rafalposwiata/depression-detection-lt-edi-2022.</abstract>
      <url hash="5ce2a429">2022.ltedi-1.40</url>
      <bibkey>poswiata-perelkiewicz-2022-opi</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.40</doi>
      <video href="2022.ltedi-1.40.mp4"/>
      <pwccode url="https://github.com/rafalposwiata/depression-detection-lt-edi-2022" additional="false">rafalposwiata/depression-detection-lt-edi-2022</pwccode>
    </paper>
    <paper id="41">
      <title><fixed-case>F</fixed-case>ilip<fixed-case>N</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022-Detecting signs of Depression from Social Media: Examining the use of summarization methods as data augmentation for text classification</title>
      <author><first>Filip</first><last>Nilsson</last></author>
      <author><first>György</first><last>Kovács</last></author>
      <pages>283-286</pages>
      <abstract>Depression is a common mental disorder that severely affects the quality of life, and can lead to suicide. When diagnosed in time, mild, moderate, and even severe depression can be treated. This is why it is vital to detect signs of depression in time. One possibility for this is the use of text classification models on social media posts. Transformers have achieved state-of-the-art performance on a variety of similar text classification tasks. One drawback, however, is that when the dataset is imbalanced, the performance of these models may be negatively affected. Because of this, in this paper, we examine the effect of balancing a depression detection dataset using data augmentation. In particular, we use abstractive summarization techniques for data augmentation. We examine the effect of this method on the LT-EDI-ACL2022 task. Our results show that when increasing the multiplicity of the minority classes to the right degree, this data augmentation method can in fact improve classification scores on the task.</abstract>
      <url hash="ae782f9e">2022.ltedi-1.41</url>
      <bibkey>nilsson-kovacs-2022-filipn</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.41</doi>
      <video href="2022.ltedi-1.41.mp4"/>
      <pwccode url="https://github.com/flippe3/dsdsm_augmentation" additional="false">flippe3/dsdsm_augmentation</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/c4">C4</pwcdataset>
    </paper>
    <paper id="42">
      <title><fixed-case>NAYEL</fixed-case> @<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Homophobia/Transphobia Detection for Equality, Diversity, and Inclusion using <fixed-case>SVM</fixed-case></title>
      <author><first>Nsrin</first><last>Ashraf</last></author>
      <author><first>Mohamed</first><last>Taha</last></author>
      <author><first>Ahmed</first><last>Abd Elfattah</last></author>
      <author><first>Hamada</first><last>Nayel</last></author>
      <pages>287-290</pages>
      <abstract>Analysing the contents of social media platforms such as YouTube, Facebook and Twitter gained interest due to the vast number of users. One of the important tasks is homophobia/transphobia detection. This paper illustrates the system submitted by our team for the homophobia/transphobia detection in social media comments shared task. A machine learning-based model has been designed and various classification algorithms have been implemented for automatic detection of homophobia in YouTube comments. TF/IDF has been used with a range of bigram model for vectorization of comments. Support Vector Machines has been used to develop the proposed model and our submission reported 0.91, 0.92, 0.88 weighted f1-score for English, Tamil and Tamil-English datasets respectively.</abstract>
      <url hash="5832b66d">2022.ltedi-1.42</url>
      <bibkey>ashraf-etal-2022-nayel</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.42</doi>
      <video href="2022.ltedi-1.42.mp4"/>
    </paper>
    <paper id="43">
      <title>gini<fixed-case>U</fixed-case>s @<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Aasha: Transformers based Hope-<fixed-case>EDI</fixed-case></title>
      <author><first>Harshul</first><last>Surana</last></author>
      <author><first>Basavraj</first><last>Chinagundi</last></author>
      <pages>291-295</pages>
      <abstract>This paper describes team giniUs’ submission to the Hope Speech Detection for Equality, Diversity and Inclusion Shared Task organised by LT-EDI ACL 2022. We have fine-tuned the Roberta-large pre-trained model and extracted the last four decoder layers to build a classifier. Our best result on the leaderboard achieve a weighted F1 score of 0.86 and a Macro F1 score of 0.51 for English. We have secured a rank of 4 for the English task. We have open-sourced our code implementations on GitHub to facilitate easy reproducibility by the scientific community.</abstract>
      <url hash="3c2229ba">2022.ltedi-1.43</url>
      <bibkey>surana-chinagundi-2022-ginius</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.43</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/hopeedi">HopeEDI</pwcdataset>
    </paper>
    <paper id="44">
      <title><fixed-case>SSN</fixed-case>_<fixed-case>MLRG</fixed-case>1@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Multi-Class Classification using <fixed-case>BERT</fixed-case> models for Detecting Depression Signs from Social Media Text</title>
      <author><first>Karun</first><last>Anantharaman</last></author>
      <author><first>Angel</first><last>S</last></author>
      <author><first>Rajalakshmi</first><last>Sivanaiah</last></author>
      <author><first>Saritha</first><last>Madhavan</last></author>
      <author><first>Sakaya Milton</first><last>Rajendram</last></author>
      <pages>296-300</pages>
      <abstract>DepSign-LT-EDI@ACL-2022 aims to ascer-tain the signs of depression of a person fromtheir messages and posts on social mediawherein people share their feelings and emo-tions. Given social media postings in English,the system should classify the signs of depres-sion into three labels namely “not depressed”,“moderately depressed”, and “severely de-pressed”. To achieve this objective, we haveadopted a fine-tuned BERT model. This solu-tion from team SSN_MLRG1 achieves 58.5%accuracy on the DepSign-LT-EDI@ACL-2022test set.</abstract>
      <url hash="3e4039dd">2022.ltedi-1.44</url>
      <bibkey>anantharaman-etal-2022-ssn</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.44</doi>
      <video href="2022.ltedi-1.44.mp4"/>
    </paper>
    <paper id="45">
      <title><fixed-case>D</fixed-case>epression<fixed-case>O</fixed-case>ne@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Using Machine Learning with <fixed-case>SMOTE</fixed-case> and Random <fixed-case>U</fixed-case>nder<fixed-case>S</fixed-case>ampling to Detect Signs of Depression on Social Media Text.</title>
      <author><first>Suman</first><last>Dowlagar</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <pages>301-305</pages>
      <abstract>Depression is a common and serious medical illness that negatively affects how you feel, the way you think, and how you act. Detecting depression is essential as it must be treated early to avoid painful consequences. Nowadays, people are broadcasting how they feel via posts and comments. Using social media, we can extract many comments related to depression and use NLP techniques to train and detect depression. This work presents the submission of the DepressionOne team at LT-EDI-2022 for the shared task, detecting signs of depression from social media text. The depression data is small and unbalanced. Thus, we have used oversampling and undersampling methods such as SMOTE and RandomUnderSampler to represent the data. Later, we used machine learning methods to train and detect the signs of depression.</abstract>
      <url hash="ca3be52f">2022.ltedi-1.45</url>
      <bibkey>dowlagar-mamidi-2022-depressionone</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.45</doi>
    </paper>
    <paper id="46">
      <title><fixed-case>L</fixed-case>eaning<fixed-case>T</fixed-case>ower@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: When Hope and Hate Collide</title>
      <author><first>Arianna</first><last>Muti</last></author>
      <author><first>Marta</first><last>Marchiori Manerba</last></author>
      <author><first>Katerina</first><last>Korre</last></author>
      <author><first>Alberto</first><last>Barrón-Cedeño</last></author>
      <pages>306-311</pages>
      <abstract>The 2022 edition of LT-EDI proposed two tasks in various languages. Task Hope Speech Detection required models for the automatic identification of hopeful comments for equality, diversity, and inclusion. Task Homophobia/Transphobia Detection focused on the identification of homophobic and transphobic comments. We targeted both tasks in English by using reinforced BERT-based approaches. Our core strategy aimed at exploiting the data available for each given task to augment the amount of supervised instances in the other. On the basis of an active learning process, we trained a model on the dataset for Task <tex-math>i</tex-math> and applied it to the dataset for Task <tex-math>j</tex-math> to iteratively integrate new silver data for Task <tex-math>i</tex-math>. Our official submissions to the shared task obtained a macro-averaged F<tex-math>_1</tex-math> score of 0.53 for Hope Speech and 0.46 for Homo/Transphobia, placing our team in the third and fourth positions out of 11 and 12 participating teams respectively. </abstract>
      <url hash="0215aee4">2022.ltedi-1.46</url>
      <bibkey>muti-etal-2022-leaningtower</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.46</doi>
      <video href="2022.ltedi-1.46.mp4"/>
    </paper>
    <paper id="47">
      <title><fixed-case>MUCS</fixed-case>@Text-<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>@<fixed-case>ACL</fixed-case> 2022: Detecting Sign of Depression from Social Media Text using Supervised Learning Approach</title>
      <author><first>Asha</first><last>Hegde</last></author>
      <author><first>Sharal</first><last>Coelho</last></author>
      <author><first>Ahmad Elyas</first><last>Dashti</last></author>
      <author><first>Hosahalli</first><last>Shashirekha</last></author>
      <pages>312-316</pages>
      <abstract>Social media has seen enormous growth in its users recently and knowingly or unknowingly the behavior of a person will be reflected in the comments she/he posts on social media. Users having the sign of depression may post negative or disturbing content seeking the attention of other users. Hence, social media data can be analysed to check whether the users’ have the sign of depression and help them to get through the situation if required. However, as analyzing the increasing amount of social media data manually in laborious and error-prone, automated tools have to be developed for the same. To address the issue of detecting the sign of depression content on social media, in this paper, we - team MUCS, describe an Ensemble of Machine Learning (ML) models and a Transfer Learning (TL) model submitted to “Detecting Signs of Depression from Social Media Text-LT-EDI@ACL 2022” (DepSign-LT-EDI@ACL-2022) shared task at Association for Computational Linguistics (ACL) 2022. Both frequency and text based features are used to train an Ensemble model and Bidirectional Encoder Representations from Transformers (BERT) fine-tuned with raw text is used to train the TL model. Among the two models, the TL model performed better with a macro averaged F-score of 0.479 and placed 18th rank in the shared task. The code to reproduce the proposed models is available in github page1.</abstract>
      <url hash="355d7bc3">2022.ltedi-1.47</url>
      <bibkey>hegde-etal-2022-mucs-text</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.47</doi>
      <video href="2022.ltedi-1.47.mp4"/>
    </paper>
    <paper id="48">
      <title><fixed-case>SSNCSE</fixed-case>_<fixed-case>NLP</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Speech Recognition for Vulnerable Individuals in <fixed-case>T</fixed-case>amil using pre-trained <fixed-case>XLSR</fixed-case> models</title>
      <author><first>Dhanya</first><last>Srinivasan</last></author>
      <author><first>Bharathi</first><last>B</last></author>
      <author><first>Thenmozhi</first><last>Durairaj</last></author>
      <author><first>Senthil Kumar</first><last>B</last></author>
      <pages>317-320</pages>
      <abstract>Automatic speech recognition is a tool used to transform human speech into a written form. It is used in a variety of avenues, such as in voice commands, customer, service and more. It has emerged as an essential tool in the digitisation of daily life. It has been known to be of vital importance in making the lives of elderly and disabled people much easier. In this paper we describe an automatic speech recognition model, determined by using three pre-trained models, fine-tuned from the Facebook XLSR Wav2Vec2 model, which was trained using the Common Voice Dataset. The best model for speech recognition in Tamil is determined by finding the word error rate of the data. This work explains the submission made by SSNCSE_NLP in the shared task organized by LT-EDI at ACL 2022. A word error rate of 39.4512 is achieved.</abstract>
      <url hash="1229dc1e">2022.ltedi-1.48</url>
      <bibkey>srinivasan-etal-2022-ssncse</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.48</doi>
      <video href="2022.ltedi-1.48.mp4"/>
    </paper>
    <paper id="49">
      <title><fixed-case>IDIAP</fixed-case>_<fixed-case>TIET</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022 : Hope Speech Detection in Social Media using Contextualized <fixed-case>BERT</fixed-case> with Attention Mechanism</title>
      <author><first>Deepanshu</first><last>Khanna</last></author>
      <author><first>Muskaan</first><last>Singh</last></author>
      <author><first>Petr</first><last>Motlicek</last></author>
      <pages>321-325</pages>
      <abstract>With the increase of users on social media platforms, manipulating or provoking masses of people has become a piece of cake. This spread of hatred among people, which has become a loophole for freedom of speech, must be minimized. Hence, it is essential to have a system that automatically classifies the hatred content, especially on social media, to take it down. This paper presents a simple modular pipeline classifier with BERT embeddings and attention mechanism to classify hope speech content in the Hope Speech Detection shared task for Equality, Diversity, and Inclusion-ACL 2022. Our system submission ranks fourth with an F1-score of 0.84. We release our code-base here https://github.com/Deepanshu-beep/hope-speech-attention .</abstract>
      <url hash="e83f6bb5">2022.ltedi-1.49</url>
      <bibkey>khanna-etal-2022-idiap</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.49</doi>
      <video href="2022.ltedi-1.49.mp4"/>
      <pwccode url="https://github.com/deepanshu-beep/hope-speech-attention" additional="false">deepanshu-beep/hope-speech-attention</pwccode>
    </paper>
    <paper id="50">
      <title><fixed-case>SSN</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Transfer Learning using <fixed-case>BERT</fixed-case> for Detecting Signs of Depression from Social Media Texts</title>
      <author><first>Adarsh</first><last>S</last></author>
      <author><first>Betina</first><last>Antony</last></author>
      <pages>326-330</pages>
      <abstract>Depression is one of the most common mentalissues faced by people. Detecting signs ofdepression early on can help in the treatmentand prevention of extreme outcomes like suicide.Since the advent of the internet, peoplehave felt more comfortable discussing topicslike depression online due to the anonymityit provides. This shared task has used datascraped from various social media sites andaims to develop models that detect signs andthe severity of depression effectively. In thispaper, we employ transfer learning by applyingenhanced BERT model trained for Wikipediadataset to the social media text and performtext classification. The model gives a F1-scoreof 63.8% which was reasonably better than theother competing models.</abstract>
      <url hash="fddb4aa7">2022.ltedi-1.50</url>
      <bibkey>s-antony-2022-ssn</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.50</doi>
      <video href="2022.ltedi-1.50.mp4"/>
    </paper>
    <paper id="51">
      <title>Findings of the Shared Task on Detecting Signs of Depression from Social Media</title>
      <author><first>Kayalvizhi</first><last>S</last></author>
      <author><first>Thenmozhi</first><last>Durairaj</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Jerin Mahibha</first><last>C</last></author>
      <pages>331-338</pages>
      <abstract>Social media is considered as a platform whereusers express themselves. The rise of social me-dia as one of humanity’s most important publiccommunication platforms presents a potentialprospect for early identification and manage-ment of mental illness. Depression is one suchillness that can lead to a variety of emotionaland physical problems. It is necessary to mea-sure the level of depression from the socialmedia text to treat them and to avoid the nega-tive consequences. Detecting levels of depres-sion is a challenging task since it involves themindset of the people which can change period-ically. The aim of the DepSign-LT-EDI@ACL-2022 shared task is to classify the social me-dia text into three levels of depression namely“Not Depressed”, “Moderately Depressed”, and“Severely Depressed”. This overview presentsa description on the task, the data set, method-ologies used and an analysis on the results ofthe submissions. The models that were submit-ted as a part of the shared task had used a va-riety of technologies from traditional machinelearning algorithms to deep learning models.It could be observed from the result that thetransformer based models have outperformedthe other models. Among the 31 teams whohad submitted their results for the shared task,the best macro F1-score of 0.583 was obtainedusing transformer based model.</abstract>
      <url hash="44d75e4e">2022.ltedi-1.51</url>
      <bibkey>s-etal-2022-findings</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.51</doi>
      <video href="2022.ltedi-1.51.mp4"/>
    </paper>
    <paper id="52">
      <title>Findings of the Shared Task on Speech Recognition for Vulnerable Individuals in <fixed-case>T</fixed-case>amil</title>
      <author><first>Bharathi</first><last>B</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Subalalitha</first><last>Cn</last></author>
      <author><first>Sripriya</first><last>N</last></author>
      <author><first>Arunaggiri</first><last>Pandian</last></author>
      <author><first>Swetha</first><last>Valli</last></author>
      <pages>339-345</pages>
      <abstract>This paper illustrates the overview of the sharedtask on automatic speech recognition in the Tamillanguage. In the shared task, spontaneousTamil speech data gathered from elderly andtransgender people was given for recognitionand evaluation. These utterances were collected from people when they communicatedin the public locations such as hospitals, markets, vegetable shop, etc. The speech corpusincludes utterances of male, female, and transgender and was split into training and testingdata. The given task was evaluated using WER(Word Error Rate). The participants used thetransformer-based model for automatic speechrecognition. Different results using differentpre-trained transformer models are discussedin this overview paper.</abstract>
      <url hash="759a72ea">2022.ltedi-1.52</url>
      <bibkey>b-etal-2022-findings-shared</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.52</doi>
      <video href="2022.ltedi-1.52.mp4"/>
    </paper>
    <paper id="53">
      <title><fixed-case>DLRG</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022:Detecting signs of Depression from Social Media using <fixed-case>XGB</fixed-case>oost Method</title>
      <author><first>Herbert</first><last>Sharen</last></author>
      <author><first>Ratnavel</first><last>Rajalakshmi</last></author>
      <pages>346-349</pages>
      <abstract>Depression is linked to the development of dementia.Cognitive functions such as thinkingand remembering generally deteriorate in dementiapatients. Social media usage has beenincreased among the people in recent days. Thetechnology advancements help the communityto express their views publicly. Analysing thesigns of depression from texts has become animportant area of research now, as it helps toidentify this kind of mental disorders among thepeople from their social media posts. As part ofthe shared task on detecting signs of depressionfrom social media text, a dataset has been providedby the organizers (Sampath et al.). Weapplied different machine learning techniquessuch as Support Vector Machine, Random Forestand XGBoost classifier to classify the signsof depression. Experimental results revealedthat, the XGBoost model outperformed othermodels with the highest classification accuracyof 0.61% and an Macro F1 score of 0.54.</abstract>
      <url hash="89608bd9">2022.ltedi-1.53</url>
      <bibkey>sharen-rajalakshmi-2022-dlrg</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.53</doi>
    </paper>
    <paper id="54">
      <title><fixed-case>IDIAP</fixed-case> Submission@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022 : Hope Speech Detection for Equality, Diversity and Inclusion</title>
      <author><first>Muskaan</first><last>Singh</last></author>
      <author><first>Petr</first><last>Motlicek</last></author>
      <pages>350-355</pages>
      <abstract>Social media platforms have been provoking masses of people. The individual comments affect a prevalent way of thinking by moving away from preoccupation with discrimination, loneliness, or influence in building confidence, support, and good qualities. This paper aims to identify hope in these social media posts. Hope significantly impacts the well-being of people, as suggested by health professionals. It reflects the belief to achieve an objective, discovers a new path, or become motivated to formulate pathways.In this paper we classify given a social media post, hope speech or not hope speech, using ensembled voting of BERT, ERNIE 2.0 and RoBERTa for English language with 0.54 macro F1-score (<tex-math>2^{st}</tex-math> rank). For non-English languages Malayalam, Spanish and Tamil we utilized XLM RoBERTA with 0.50, 0.81, 0.3 macro F1 score (<tex-math>1^{st}</tex-math>, <tex-math>1^{st}</tex-math>,<tex-math>3^{rd}</tex-math> rank) respectively. For Kannada, we use Multilingual BERT with 0.32 F1 score(<tex-math>5^{th}</tex-math>)position. We release our code-base here: https://github.com/Muskaan-Singh/Hate-Speech-detection.git.</abstract>
      <url hash="272f8a6f">2022.ltedi-1.54</url>
      <bibkey>singh-motlicek-2022-idiap</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.54</doi>
      <video href="2022.ltedi-1.54.mp4"/>
      <pwccode url="https://github.com/muskaan-singh/hate-speech-detection" additional="false">muskaan-singh/hate-speech-detection</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/hopeedi">HopeEDI</pwcdataset>
    </paper>
    <paper id="55">
      <title><fixed-case>IDIAP</fixed-case> Submission@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Homophobia/Transphobia Detection in social media comments</title>
      <author><first>Muskaan</first><last>Singh</last></author>
      <author><first>Petr</first><last>Motlicek</last></author>
      <pages>356-361</pages>
      <abstract>The increased expansion of abusive content on social media platforms negatively affects online users. Transphobic/homophobic content indicates hatred comments for lesbian, gay, transgender, or bisexual people. It leads to offensive speech and causes severe social problems that can make online platforms toxic and unpleasant to LGBT+people, endeavoring to eliminate equality, diversity, and inclusion. In this paper, we present our classification system; given comments, it predicts whether or not it contains any form of homophobia/transphobia with a Zero-Shot learning framework. Our system submission achieved 0.40, 0.85, 0.89 F1-score for Tamil and Tamil-English, English with (<tex-math>1^{st}</tex-math>, <tex-math>1^{st}</tex-math>,<tex-math>8^{th}</tex-math>) ranks respectively. We release our codebase here: https://github.com/Muskaan-Singh/Homophobia-and-Transphobia-ACL-Submission.git.</abstract>
      <url hash="368de3ca">2022.ltedi-1.55</url>
      <bibkey>singh-motlicek-2022-idiap-submission</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.55</doi>
      <video href="2022.ltedi-1.55.mp4"/>
      <pwccode url="https://github.com/muskaan-singh/homophobia-and-transphobia-acl-submission" additional="false">muskaan-singh/homophobia-and-transphobia-acl-submission</pwccode>
    </paper>
    <paper id="56">
      <title><fixed-case>IDIAP</fixed-case> Submission@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>ACL</fixed-case>2022: Detecting Signs of Depression from Social Media Text</title>
      <author><first>Muskaan</first><last>Singh</last></author>
      <author><first>Petr</first><last>Motlicek</last></author>
      <pages>362-368</pages>
      <abstract>Depression is a common illness involving sadness and lack of interest in all day-to-day activities. It is important to detect depression at an early stage as it is treated at an early stage to avoid consequences. In this paper, we present our system submission of ARGUABLY for DepSign-LT-EDI@ACL-2022. We aim to detect the signs of depression of a person from their social media postings wherein people share their feelings and emotions. The proposed system is an ensembled voting model with fine-tuned BERT, RoBERTa, and XLNet. Given social media postings in English, the submitted system classify the signs of depression into three labels, namely “not depressed,” “moderately depressed,” and “severely depressed.” Our best model is ranked <tex-math>3^{rd}</tex-math> position with 0.54% accuracy . We make our codebase accessible here.</abstract>
      <url hash="fcf0dce7">2022.ltedi-1.56</url>
      <bibkey>singh-motlicek-2022-idiap-submission-lt</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.56</doi>
      <video href="2022.ltedi-1.56.mp4"/>
    </paper>
    <paper id="57">
      <title>Overview of The Shared Task on Homophobia and Transphobia Detection in Social Media Comments</title>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Ruba</first><last>Priyadharshini</last></author>
      <author><first>Thenmozhi</first><last>Durairaj</last></author>
      <author><first>John</first><last>McCrae</last></author>
      <author><first>Paul</first><last>Buitelaar</last></author>
      <author><first>Prasanna</first><last>Kumaresan</last></author>
      <author><first>Rahul</first><last>Ponnusamy</last></author>
      <pages>369-377</pages>
      <abstract>Homophobia and Transphobia Detection is the task of identifying homophobia, transphobia, and non-anti-LGBT+ content from the given corpus. Homophobia and transphobia are both toxic languages directed at LGBTQ+ individuals that are described as hate speech. This paper summarizes our findings on the “Homophobia and Transphobia Detection in social media comments” shared task held at LT-EDI 2022 - ACL 2022 1. This shared taskfocused on three sub-tasks for Tamil, English, and Tamil-English (code-mixed) languages. It received 10 systems for Tamil, 13 systems for English, and 11 systems for Tamil-English. The best systems for Tamil, English, and Tamil-English scored 0.570, 0.870, and 0.610, respectively, on average macro F1-score.</abstract>
      <url hash="2a5c8557">2022.ltedi-1.57</url>
      <bibkey>chakravarthi-etal-2022-overview</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.57</doi>
      <video href="2022.ltedi-1.57.mp4"/>
    </paper>
    <paper id="58">
      <title>Overview of the Shared Task on Hope Speech Detection for Equality, Diversity, and Inclusion</title>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Vigneshwaran</first><last>Muralidaran</last></author>
      <author><first>Ruba</first><last>Priyadharshini</last></author>
      <author><first>Subalalitha</first><last>Cn</last></author>
      <author><first>John</first><last>McCrae</last></author>
      <author><first>Miguel Ángel</first><last>García</last></author>
      <author><first>Salud María</first><last>Jiménez-Zafra</last></author>
      <author><first>Rafael</first><last>Valencia-García</last></author>
      <author><first>Prasanna</first><last>Kumaresan</last></author>
      <author><first>Rahul</first><last>Ponnusamy</last></author>
      <author><first>Daniel</first><last>García-Baena</last></author>
      <author><first>José</first><last>García-Díaz</last></author>
      <pages>378-388</pages>
      <abstract>Hope Speech detection is the task of classifying a sentence as hope speech or non-hope speech given a corpus of sentences. Hope speech is any message or content that is positive, encouraging, reassuring, inclusive and supportive that inspires and engenders optimism in the minds of people. In contrast to identifying and censoring negative speech patterns, hope speech detection is focussed on recognising and promoting positive speech patterns online. In this paper, we report an overview of the findings and results from the shared task on hope speech detection for Tamil, Malayalam, Kannada, English and Spanish languages conducted in the second workshop on Language Technology for Equality, Diversity and Inclusion (LT-EDI-2022) organised as a part of ACL 2022. The participants were provided with annotated training &amp; development datasets and unlabelled test datasets in all the five languages. The goal of the shared task is to classify the given sentences into one of the two hope speech classes. The performances of the systems submitted by the participants were evaluated in terms of micro-F1 score and weighted-F1 score. The datasets for this challenge are openly available</abstract>
      <url hash="0ea1187a">2022.ltedi-1.58</url>
      <bibkey>chakravarthi-etal-2022-overview-shared</bibkey>
      <doi>10.18653/v1/2022.ltedi-1.58</doi>
      <video href="2022.ltedi-1.58.mp4"/>
    </paper>
  </volume>
</collection>
