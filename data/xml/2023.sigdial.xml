<?xml version='1.0' encoding='UTF-8'?>
<collection id="2023.sigdial">
  <volume id="1" ingest-date="2023-10-01" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 24th Annual Meeting of the Special Interest Group on Discourse and Dialogue</booktitle>
      <editor><first>Svetlana</first><last>Stoyanchev</last></editor>
      <editor><first>Shafiq</first><last>Joty</last></editor>
      <editor><first>David</first><last>Schlangen</last></editor>
      <editor><first>Ondrej</first><last>Dusek</last></editor>
      <editor><first>Casey</first><last>Kennington</last></editor>
      <editor><first>Malihe</first><last>Alikhani</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Prague, Czechia</address>
      <month>September</month>
      <year>2023</year>
      <url hash="a1180f22">2023.sigdial-1</url>
      <venue>sigdial</venue>
    </meta>
    <frontmatter>
      <url hash="6c16ebac">2023.sigdial-1.0</url>
      <bibkey>sigdial-2023-special</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Sources of Noise in Dialogue and How to Deal with Them</title>
      <author><first>Derek</first><last>Chen</last></author>
      <author><first>Zhou</first><last>Yu</last></author>
      <pages>1–20</pages>
      <abstract>Training dialogue systems often entails dealing with noisy training examples and unexpected user inputs. Despite their prevalence, there currently lacks an accurate survey of dialogue noise, nor is there a clear sense of the impact of each noise type on task performance. This paper addresses this gap by first constructing a taxonomy of noise encountered by dialogue systems. In addition, we run a series of experiments to show how different models behave when subjected to varying levels of noise and types of noise. Our results reveal that models are quite robust to label errors commonly tackled by existing denoising algorithms, but that performance suffers from dialogue-specific noise. Driven by these observations, we design a data cleaning algorithm specialized for conversational settings and apply it as a proof-of-concept for targeted dialogue denoising.</abstract>
      <url hash="11a386f2">2023.sigdial-1.1</url>
      <bibkey>chen-yu-2023-sources</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.1</doi>
    </paper>
    <paper id="2">
      <title>Investigating Explicitation of Discourse Connectives in Translation using Automatic Annotations</title>
      <author><first>Frances</first><last>Yung</last></author>
      <author><first>Merel</first><last>Scholman</last></author>
      <author><first>Ekaterina</first><last>Lapshinova-Koltunski</last></author>
      <author><first>Christina</first><last>Pollkläsener</last></author>
      <author><first>Vera</first><last>Demberg</last></author>
      <pages>21–30</pages>
      <abstract>Discourse relations have different patterns of marking across different languages. As a result, discourse connectives are often added, omitted, or rephrased in translation. Prior work has shown a tendency for explicitation of discourse connectives, but such work was conducted using restricted sample sizes due to difficulty of connective identification and alignment. The current study exploits automatic methods to facilitate a large-scale study of connectives in English and German parallel texts. Our results based on over 300 types and 18000 instances of aligned connectives and an empirical approach to compare the cross-lingual specificity gap provide strong evidence of the Explicitation Hypothesis. We conclude that discourse relations are indeed more explicit in translation than texts written originally in the same language. Automatic annotations allow us to carry out translation studies of discourse relations on a large scale. Our methodology using relative entropy to study the specificity of connectives also provides more fine-grained insights into translation patterns.</abstract>
      <url hash="939cc996">2023.sigdial-1.2</url>
      <bibkey>yung-etal-2023-investigating</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.2</doi>
    </paper>
    <paper id="3">
      <title>What’s Hard in <fixed-case>E</fixed-case>nglish <fixed-case>RST</fixed-case> Parsing? Predictive Models for Error Analysis</title>
      <author><first>Yang Janet</first><last>Liu</last></author>
      <author><first>Tatsuya</first><last>Aoyama</last></author>
      <author><first>Amir</first><last>Zeldes</last></author>
      <pages>31–42</pages>
      <abstract>Despite recent advances in Natural Language Processing (NLP), hierarchical discourse parsing in the framework of Rhetorical Structure Theory remains challenging, and our understanding of the reasons for this are as yet limited. In this paper, we examine and model some of the factors associated with parsing difficulties in previous work: the existence of implicit discourse relations, challenges in identifying long-distance relations, out-of-vocabulary items, and more. In order to assess the relative importance of these variables, we also release two annotated English test-sets with explicit correct and distracting discourse markers associated with gold standard RST relations. Our results show that as in shallow discourse parsing, the explicit/implicit distinction plays a role, but that long-distance dependencies are the main challenge, while lack of lexical overlap is less of a problem, at least for in-domain parsing. Our final model is able to predict where errors will occur with an accuracy of 76.3% for the bottom-up parser and 76.6% for the top-down parser.</abstract>
      <url hash="8e058de6">2023.sigdial-1.3</url>
      <bibkey>liu-etal-2023-whats</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.3</doi>
    </paper>
    <paper id="4">
      <title>Grounded Complex Task Segmentation for Conversational Assistants</title>
      <author><first>Rafael</first><last>Ferreira</last></author>
      <author><first>David</first><last>Semedo</last></author>
      <author><first>Joao</first><last>Magalhaes</last></author>
      <pages>43–54</pages>
      <abstract>Following complex instructions in conversational assistants can be quite daunting due to the shorter attention and memory spans when compared to reading the same instructions. Hence, when conversational assistants walk users through the steps of complex tasks, there is a need to structure the task into manageable pieces of information of the right length and complexity. In this paper, we tackle the recipes domain and convert reading structured instructions into conversational structured ones. We annotated the structure of instructions according to a conversational scenario, which provided insights into what is expected in this setting. To computationally model the conversational step’s characteristics, we tested various Transformer-based architectures, showing that a token-based approach delivers the best results. A further user study showed that users tend to favor steps of manageable complexity and length, and that the proposed methodology can improve the original web-based instructional text. Specifically, 86% of the evaluated tasks were improved from a conversational suitability point of view.</abstract>
      <url hash="c6868f37">2023.sigdial-1.4</url>
      <bibkey>ferreira-etal-2023-grounded</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.4</doi>
    </paper>
    <paper id="5">
      <title>A Statistical Approach for Quantifying Group Difference in Topic Distributions Using Clinical Discourse Samples</title>
      <author><first>Grace O.</first><last>Lawley</last></author>
      <author><first>Peter A.</first><last>Heeman</last></author>
      <author><first>Jill K.</first><last>Dolata</last></author>
      <author><first>Eric</first><last>Fombonne</last></author>
      <author><first>Steven</first><last>Bedrick</last></author>
      <pages>55–65</pages>
      <abstract>Topic distribution matrices created by topic models are typically used for document classification or as features in a separate machine learning algorithm. Existing methods for evaluating these topic distributions include metrics such as coherence and perplexity; however, there is a lack of statistically grounded evaluation tools. We present a statistical method for investigating group differences in the document-topic distribution vectors created by Latent Dirichlet Allocation (LDA) that uses Aitchison geometry to transform the vectors, multivariate analysis of variance (MANOVA) to compare sample means, and partial eta squared to calculate effect size. Using a corpus of dialogues between Autistic and Typically Developing (TD) children and trained examiners, we found that the topic distributions of Autistic children differed from those of TD children when responding to questions about social difficulties (p = .0083, partial eta squared = .19). Furthermore, the examiners’ topic distributions differed between the Autistic and TD groups when discussing emotions (p = .0035, partial eta squared = .20), social difficulties (p &lt; .001, partial eta squared = .30), and friends (p = .0224, partial eta squared = .17). These results support the use of topic modeling in studying clinically relevant features of social communication such as topic maintenance.</abstract>
      <url hash="048a1263">2023.sigdial-1.5</url>
      <bibkey>lawley-etal-2023-statistical</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.5</doi>
    </paper>
    <paper id="6">
      <title><fixed-case>O</fixed-case>pinion<fixed-case>C</fixed-case>onv: Conversational Product Search with Grounded Opinions</title>
      <author><first>Vahid</first><last>Sadiri Javadi</last></author>
      <author><first>Martin</first><last>Potthast</last></author>
      <author><first>Lucie</first><last>Flek</last></author>
      <pages>66–76</pages>
      <abstract>When searching for products, the opinions of others play an important role in making informed decisions. Subjective experiences about a product can be a valuable source of information. This is also true in sales conversations, where a customer and a sales assistant exchange facts and opinions about products. However, training an AI for such conversations is complicated by the fact that language models do not possess authentic opinions for their lack of real-world experience. We address this problem by leveraging product reviews as a rich source of product opinions to ground conversational AI in true subjective narratives. With OpinionConv, we develop the first conversational AI for simulating sales conversations. To validate the generated conversations, we conduct several user studies showing that the generated opinions are perceived as realistic. Our assessors also confirm the importance of opinions as an informative basis for decision making.</abstract>
      <url hash="48c60bdd">2023.sigdial-1.6</url>
      <bibkey>sadiri-javadi-etal-2023-opinionconv</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.6</doi>
    </paper>
    <paper id="7">
      <title>Dial-<fixed-case>M</fixed-case>: A Masking-based Framework for Dialogue Evaluation</title>
      <author><first>Suvodip</first><last>Dey</last></author>
      <author><first>Maunendra Sankar</first><last>Desarkar</last></author>
      <pages>77–84</pages>
      <abstract>In dialogue systems, automatically evaluating machine-generated responses is critical and challenging. Despite the tremendous progress in dialogue generation research, its evaluation heavily depends on human judgments. The standard word-overlapping based evaluation metrics are ineffective for dialogues. As a result, most of the recently proposed metrics are model-based and reference-free, which learn to score different aspects of a conversation. However, understanding each aspect requires a separate model, which makes them computationally expensive. To this end, we propose Dial-M, a Masking-based reference-free framework for Dialogue evaluation. The main idea is to mask the keywords of the current utterance and predict them, given the dialogue history and various conditions (like knowledge, persona, etc.), thereby making the evaluation framework simple and easily extensible for multiple datasets. Regardless of its simplicity, Dial-M achieves comparable performance to state-of-the-art metrics on several dialogue evaluation datasets. We also discuss the interpretability of our proposed metric along with error analysis.</abstract>
      <url hash="344b77e3">2023.sigdial-1.7</url>
      <bibkey>dey-desarkar-2023-dial</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.7</doi>
    </paper>
    <paper id="8">
      <title>From Chatter to Matter: Addressing Critical Steps of Emotion Recognition Learning in Task-oriented Dialogue</title>
      <author><first>Shutong</first><last>Feng</last></author>
      <author><first>Nurul</first><last>Lubis</last></author>
      <author><first>Benjamin</first><last>Ruppik</last></author>
      <author><first>Christian</first><last>Geishauser</last></author>
      <author><first>Michael</first><last>Heck</last></author>
      <author><first>Hsien-chin</first><last>Lin</last></author>
      <author><first>Carel</first><last>van Niekerk</last></author>
      <author><first>Renato</first><last>Vukovic</last></author>
      <author><first>Milica</first><last>Gasic</last></author>
      <pages>85–103</pages>
      <abstract>Emotion recognition in conversations (ERC) is a crucial task for building human-like conversational agents. While substantial efforts have been devoted to ERC for chit-chat dialogues, the task-oriented counterpart is largely left unattended. Directly applying chit-chat ERC models to task-oriented dialogues (ToDs) results in suboptimal performance as these models overlook key features such as the correlation between emotions and task completion in ToDs. In this paper, we propose a framework that turns a chit-chat ERC model into a task-oriented one, addressing three critical aspects: data, features and objective. First, we devise two ways of augmenting rare emotions to improve ERC performance. Second, we use dialogue states as auxiliary features to incorporate key information from the goal of the user. Lastly, we leverage a multi-aspect emotion definition in ToDs to devise a multi-task learning objective and a novel emotion-distance weighted loss function. Our framework yields significant improvements for a range of chit-chat ERC models on EmoWOZ, a large-scale dataset for user emotions in ToDs. We further investigate the generalisability of the best resulting model to predict user satisfaction in different ToD datasets. A comparison with supervised baselines shows a strong zero-shot capability, highlighting the potential usage of our framework in wider scenarios.</abstract>
      <url hash="bee946dc">2023.sigdial-1.8</url>
      <bibkey>feng-etal-2023-chatter</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.8</doi>
    </paper>
    <paper id="9">
      <title>Analyzing Differences in Subjective Annotations by Participants and Third-party Annotators in Multimodal Dialogue Corpus</title>
      <author><first>Kazunori</first><last>Komatani</last></author>
      <author><first>Ryu</first><last>Takeda</last></author>
      <author><first>Shogo</first><last>Okada</last></author>
      <pages>104–113</pages>
      <abstract>Estimating the subjective impressions of human users during a dialogue is necessary when constructing a dialogue system that can respond adaptively to their emotional states. However, such subjective impressions (e.g., how much the user enjoys the dialogue) are inherently ambiguous, and the annotation results provided by multiple annotators do not always agree because they depend on the subjectivity of the annotators. In this paper, we analyzed the annotation results using 13,226 exchanges from 155 participants in a multimodal dialogue corpus called Hazumi that we had constructed, where each exchange was annotated by five third-party annotators. We investigated the agreement between the subjective annotations given by the third-party annotators and the participants themselves, on both per-exchange annotations (i.e., participant’s sentiments) and per-dialogue (-participant) annotations (i.e., questionnaires on rapport and personality traits). We also investigated the conditions under which the annotation results are reliable. Our findings demonstrate that the dispersion of third-party sentiment annotations correlates with agreeableness of the participants, one of the Big Five personality traits.</abstract>
      <url hash="d13818bf">2023.sigdial-1.9</url>
      <bibkey>komatani-etal-2023-analyzing</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.9</doi>
    </paper>
    <paper id="10">
      <title>Frame-oriented Summarization of Argumentative Discussions</title>
      <author><first>Shahbaz</first><last>Syed</last></author>
      <author><first>Timon</first><last>Ziegenbein</last></author>
      <author><first>Philipp</first><last>Heinisch</last></author>
      <author><first>Henning</first><last>Wachsmuth</last></author>
      <author><first>Martin</first><last>Potthast</last></author>
      <pages>114–129</pages>
      <abstract>Online discussions on controversial topics with many participants frequently include hundreds of arguments that cover different framings of the topic. But these arguments and frames are often spread across the various branches of the discussion tree structure. This makes it difficult for interested participants to follow the discussion in its entirety as well as to introduce new arguments. In this paper, we present a new rank-based approach to extractive summarization of online discussions focusing on argumentation frames that capture the different aspects of a discussion. Our approach includes three retrieval tasks to find arguments in a discussion that are (1) relevant to a frame of interest, (2) relevant to the topic under discussion, and (3) informative to the reader. Based on a joint ranking by these three criteria for a set of user-selected frames, our approach allows readers to quickly access an ongoing discussion. We evaluate our approach using a test set of 100 controversial Reddit ChangeMyView discussions, for which the relevance of a total of 1871 arguments was manually annotated.</abstract>
      <url hash="10d816d4">2023.sigdial-1.10</url>
      <bibkey>syed-etal-2023-frame</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.10</doi>
    </paper>
    <paper id="11">
      <title>Towards Multilingual Automatic Open-Domain Dialogue Evaluation</title>
      <author><first>John</first><last>Mendonca</last></author>
      <author><first>Alon</first><last>Lavie</last></author>
      <author><first>Isabel</first><last>Trancoso</last></author>
      <pages>130–141</pages>
      <abstract>The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.</abstract>
      <url hash="7ffdd50a">2023.sigdial-1.11</url>
      <bibkey>mendonca-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.11</doi>
    </paper>
    <paper id="12">
      <title>Dialog Action-Aware Transformer for Dialog Policy Learning</title>
      <author><first>Huimin</first><last>Wang</last></author>
      <author><first>Wai Chung</first><last>Kwan</last></author>
      <author><first>Kam-Fai</first><last>Wong</last></author>
      <pages>142–148</pages>
      <abstract>Recent works usually address Dialog policy learning DPL by training a reinforcement learning (RL) agent to determine the best dialog action. However, existing works on deep RL require a large volume of agent-user interactions to achieve acceptable performance. In this paper, we propose to make full use of the plain text knowledge from the pre-trained language model to accelerate the RL agent’s learning speed. Specifically, we design a dialog action-aware transformer encoder (DaTrans), which integrates a new fine-tuning procedure named masked last action task to encourage DaTrans to be dialog-aware and distill action-specific features. Then, DaTrans is further optimized in an RL setting with ongoing interactions and evolves through exploration in the dialog action space toward maximizing long-term accumulated rewards. The effectiveness and efficiency of the proposed model are demonstrated with both simulator evaluation and human evaluation.</abstract>
      <url hash="20aeb91f">2023.sigdial-1.12</url>
      <bibkey>wang-etal-2023-dialog</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.12</doi>
    </paper>
    <paper id="13">
      <title>The Wizard of Curiosities: Enriching Dialogues with Fun Facts</title>
      <author><first>Frederico</first><last>Vicente</last></author>
      <author><first>Rafael</first><last>Ferreira</last></author>
      <author><first>David</first><last>Semedo</last></author>
      <author><first>Joao</first><last>Magalhaes</last></author>
      <pages>149–155</pages>
      <abstract>Introducing curiosities in a conversation is a way to teach something new to the person in a pleasant and enjoyable way. Enriching dialogues with contextualized curiosities can improve the users’ perception of a dialog system and their overall user experience. In this paper, we introduce a set of curated curiosities, targeting dialogues in the cooking and DIY domains. In particular, we use real human-agent conversations collected in the context of the Amazon Alexa TaskBot challenge, a multimodal and multi-turn conversational setting. According to an A/B test with over 1000 conversations, curiosities not only increase user engagement, but provide an average relative rating improvement of 9.7%.</abstract>
      <url hash="b7a49295">2023.sigdial-1.13</url>
      <bibkey>vicente-etal-2023-wizard</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.13</doi>
    </paper>
    <paper id="14">
      <title>The Road to Quality is Paved with Good Revisions: A Detailed Evaluation Methodology for Revision Policies in Incremental Sequence Labelling</title>
      <author><first>Brielen</first><last>Madureira</last></author>
      <author><first>Patrick</first><last>Kahardipraja</last></author>
      <author><first>David</first><last>Schlangen</last></author>
      <pages>156–167</pages>
      <abstract>Incremental dialogue model components produce a sequence of output prefixes based on incoming input. Mistakes can occur due to local ambiguities or to wrong hypotheses, making the ability to revise past outputs a desirable property that can be governed by a policy. In this work, we formalise and characterise edits and revisions in incremental sequence labelling and propose metrics to evaluate revision policies. We then apply our methodology to profile the incremental behaviour of three Transformer-based encoders in various tasks, paving the road for better revision policies.</abstract>
      <url hash="74619e78">2023.sigdial-1.14</url>
      <bibkey>madureira-etal-2023-road</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.14</doi>
    </paper>
    <paper id="15">
      <title>The effect of conversation type on entrainment: Evidence from laughter</title>
      <author><first>Bogdan</first><last>Ludusan</last></author>
      <author><first>Petra</first><last>Wagner</last></author>
      <pages>168–174</pages>
      <abstract>Entrainment is a phenomenon that occurs across several modalities and at different linguistic levels in conversation. Previous work has shown that its effects may be modulated by conversation extrinsic factors, such as the relation between the interlocutors or the speakers’ traits. The current study investigates the role of conversation type on laughter entrainment. Employing dyadic interaction materials in German, containing two conversation types (free dialogues and task-based interactions), we analyzed three measures of entrainment previously proposed in the literature. The results show that the entrainment effects depend on the type of conversation, with two of the investigated measures being affected by this factor. These findings represent further evidence towards the role of situational aspects as a mediating factor in conversation.</abstract>
      <url hash="c3551418">2023.sigdial-1.15</url>
      <bibkey>ludusan-wagner-2023-effect</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.15</doi>
    </paper>
    <paper id="16">
      <title>‘What are you referring to?’ Evaluating the Ability of Multi-Modal Dialogue Models to Process Clarificational Exchanges</title>
      <author><first>Javier</first><last>Chiyah-Garcia</last></author>
      <author><first>Alessandro</first><last>Suglia</last></author>
      <author><first>Arash</first><last>Eshghi</last></author>
      <author><first>Helen</first><last>Hastie</last></author>
      <pages>175–182</pages>
      <abstract>Referential ambiguities arise in dialogue when a referring expression does not uniquely identify the intended referent for the addressee. Addressees usually detect such ambiguities immediately and work with the speaker to repair it using meta-communicative, Clarificational Exchanges (CE): a Clarification Request (CR) and a response. Here, we argue that the ability to generate and respond to CRs imposes specific constraints on the architecture and objective functions of multi-modal, visually grounded dialogue models. We use the SIMMC 2.0 dataset to evaluate the ability of different state-of-the-art model architectures to process CEs, with a metric that probes the contextual updates that arise from them in the model. We find that language-based models are able to encode simple multi-modal semantic information and process some CEs, excelling with those related to the dialogue history, whilst multi-modal models can use additional learning objectives to obtain disentangled object representations, which become crucial to handle complex referential ambiguities across modalities overall.</abstract>
      <url hash="17d8f74d">2023.sigdial-1.16</url>
      <bibkey>chiyah-garcia-etal-2023-referring</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.16</doi>
    </paper>
    <paper id="17">
      <title><fixed-case>PGT</fixed-case>ask: Introducing the Task of Profile Generation from Dialogues</title>
      <author><first>Rui</first><last>Ribeiro</last></author>
      <author><first>Joao Paulo</first><last>Carvalho</last></author>
      <author><first>Luisa</first><last>Coheur</last></author>
      <pages>183–189</pages>
      <abstract>Recent approaches have attempted to personalize dialogue systems by leveraging profile information into models. However, this knowledge is scarce and difficult to obtain, which makes the extraction/generation of profile information from dialogues a fundamental asset. To surpass this limitation, we introduce the Profile Generation Task (PGTask). We contribute with a new dataset for this problem, comprising profile sentences aligned with related utterances, extracted from a corpus of dialogues. Furthermore, using state-of-the-art methods, we provide a benchmark for profile generation on this novel dataset. Our experiments disclose the challenges of profile generation, and we hope that this introduces a new research direction.</abstract>
      <url hash="dadbdc5c">2023.sigdial-1.17</url>
      <bibkey>ribeiro-etal-2023-pgtask</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.17</doi>
    </paper>
    <paper id="18">
      <title>Question Generation to Elicit Users’ Food Preferences by Considering the Semantic Content</title>
      <author><first>Jie</first><last>Zeng</last></author>
      <author><first>Yukiko</first><last>Nakano</last></author>
      <author><first>Tatsuya</first><last>Sakato</last></author>
      <pages>190–196</pages>
      <abstract>To obtain a better understanding of user preferences in providing tailored services, dialogue systems have to generate semi-structured interviews that require flexible dialogue control while following a topic guide to accomplish the purpose of the interview. Toward this goal, this study proposes a semantics-aware GPT-3 fine-tuning model that generates interviews to acquire users’ food preferences. The model was trained using dialogue history and semantic representation constructed from the communicative function and semantic content of the utterance. Using two baseline models: zero-shot ChatGPT and fine-tuned GPT-3, we conducted a user study for subjective evaluations alongside automatic objective evaluations. In the user study, in impression rating, the outputs of the proposed model were superior to those of baseline models and comparable to real human interviews in terms of eliciting the interviewees’ food preferences.</abstract>
      <url hash="d629de5e">2023.sigdial-1.18</url>
      <bibkey>zeng-etal-2023-question</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.18</doi>
    </paper>
    <paper id="19">
      <title>Roll Up Your Sleeves: Working with a Collaborative and Engaging Task-Oriented Dialogue System</title>
      <author><first>Lingbo</first><last>Mo</last></author>
      <author><first>Shijie</first><last>Chen</last></author>
      <author><first>Ziru</first><last>Chen</last></author>
      <author><first>Xiang</first><last>Deng</last></author>
      <author><first>Ashley</first><last>Lewis</last></author>
      <author><first>Sunit</first><last>Singh</last></author>
      <author><first>Samuel</first><last>Stevens</last></author>
      <author><first>Chang-You</first><last>Tai</last></author>
      <author><first>Zhen</first><last>Wang</last></author>
      <author><first>Xiang</first><last>Yue</last></author>
      <author><first>Tianshu</first><last>Zhang</last></author>
      <author><first>Yu</first><last>Su</last></author>
      <author><first>Huan</first><last>Sun</last></author>
      <pages>197–201</pages>
      <abstract>We introduce TacoBot, a user-centered task-oriented digital assistant designed to guide users through complex real-world tasks with multiple steps. Covering a wide range of cooking and how-to tasks, we aim to deliver a collaborative and engaging dialogue experience. Equipped with language understanding, dialogue management, and response generation components supported by a robust search engine, TacoBot ensures efficient task assistance. To enhance the dialogue experience, we explore a series of data augmentation strategies using LLMs to train advanced neural models continuously. TacoBot builds upon our successful participation in the inaugural Alexa Prize TaskBot Challenge, where our team secured third place among ten competing teams. We offer TacoBot as an open-source framework that serves as a practical example for deploying task-oriented dialogue systems.</abstract>
      <url hash="03e58437">2023.sigdial-1.19</url>
      <bibkey>mo-etal-2023-roll</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.19</doi>
    </paper>
    <paper id="20">
      <title>Leveraging Large Language Models for Automated Dialogue Analysis</title>
      <author><first>Sarah E.</first><last>Finch</last></author>
      <author><first>Ellie S.</first><last>Paek</last></author>
      <author><first>Jinho D.</first><last>Choi</last></author>
      <pages>202–215</pages>
      <abstract>Developing high-performing dialogue systems benefits from the automatic identification of undesirable behaviors in system responses. However, detecting such behaviors remains challenging, as it draws on a breadth of general knowledge and understanding of conversational practices. Although recent research has focused on building specialized classifiers for detecting specific dialogue behaviors, the behavior coverage is still incomplete and there is a lack of testing on real-world human-bot interactions. This paper investigates the ability of a state-of-the-art large language model (LLM), ChatGPT-3.5, to perform dialogue behavior detection for nine categories in real human-bot dialogues. We aim to assess whether ChatGPT can match specialized models and approximate human performance, thereby reducing the cost of behavior detection tasks. Our findings reveal that neither specialized models nor ChatGPT have yet achieved satisfactory results for this task, falling short of human performance. Nevertheless, ChatGPT shows promising potential and often outperforms specialized detection models. We conclude with an in-depth examination of the prevalent shortcomings of ChatGPT, offering guidance for future research to enhance LLM capabilities.</abstract>
      <url hash="79093a5d">2023.sigdial-1.20</url>
      <bibkey>finch-etal-2023-leveraging</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.20</doi>
    </paper>
    <paper id="21">
      <title>Are Large Language Models All You Need for Task-Oriented Dialogue?</title>
      <author><first>Vojtěch</first><last>Hudeček</last></author>
      <author><first>Ondrej</first><last>Dusek</last></author>
      <pages>216–228</pages>
      <abstract>Instruction-finetuned large language models (LLMs) gained a huge popularity recently, thanks to their ability to interact with users through conversation. In this work, we aim to evaluate their ability to complete multi-turn tasks and interact with external databases in the context of established task-oriented dialogue benchmarks. We show that in explicit belief state tracking, LLMs underperform compared to specialized task-specific models. Nevertheless, they show some ability to guide the dialogue to a successful ending through their generated responses if they are provided with correct slot values. Furthermore, this ability improves with few-shot in-domain examples.</abstract>
      <url hash="a0826b1a">2023.sigdial-1.21</url>
      <bibkey>hudecek-dusek-2023-large</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.21</doi>
    </paper>
    <paper id="22">
      <title>Multi-party Goal Tracking with <fixed-case>LLM</fixed-case>s: Comparing Pre-training, Fine-tuning, and Prompt Engineering</title>
      <author><first>Angus</first><last>Addlesee</last></author>
      <author><first>Weronika</first><last>Sieińska</last></author>
      <author><first>Nancie</first><last>Gunson</last></author>
      <author><first>Daniel</first><last>Hernandez Garcia</last></author>
      <author><first>Christian</first><last>Dondrup</last></author>
      <author><first>Oliver</first><last>Lemon</last></author>
      <pages>229–241</pages>
      <abstract>This paper evaluates the extent to which current LLMs can capture task-oriented multi-party conversations (MPCs). We have recorded and transcribed 29 MPCs between patients, their companions, and a social robot in a hospital. We then annotated this corpus for multi-party goal-tracking and intent-slot recognition. People share goals, answer each other’s goals, and provide other people’s goals in MPCs - none of which occur in dyadic interactions. To understand user goals in MPCs, we compared three methods in zero-shot and few-shot settings: we fine-tuned T5, created pre-training tasks to train DialogLM using LED, and employed prompt engineering techniques with GPT-3.5-turbo, to determine which approach can complete this novel task with limited data. GPT-3.5-turbo significantly outperformed the others in a few-shot setting. The ‘reasoning’ style prompt, when given 7% of the corpus as example annotated conversations, was the best performing method. It correctly annotated 62.32% of the goal tracking MPCs, and 69.57% of the intent-slot recognition MPCs. A ‘story’ style prompt increased model hallucination, which could be detrimental if deployed in safety-critical settings. We conclude that multi-party conversations still challenge state-of-the-art LLMs.</abstract>
      <url hash="2955a99a">2023.sigdial-1.22</url>
      <bibkey>addlesee-etal-2023-multi</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.22</doi>
    </paper>
    <paper id="23">
      <title><fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> vs. Crowdsourcing vs. Experts: Annotating Open-Domain Conversations with Speech Functions</title>
      <author><first>Lidiia</first><last>Ostyakova</last></author>
      <author><first>Veronika</first><last>Smilga</last></author>
      <author><first>Kseniia</first><last>Petukhova</last></author>
      <author><first>Maria</first><last>Molchanova</last></author>
      <author><first>Daniel</first><last>Kornev</last></author>
      <pages>242–254</pages>
      <abstract>This paper deals with the task of annotating open-domain conversations with speech functions. We propose a semi-automated method for annotating dialogs following the topic-oriented, multi-layered taxonomy of speech functions with the use of hierarchical guidelines using Large Language Models. These guidelines comprise simple questions about the topic and speaker change, sentence types, pragmatic aspects of the utterance, and examples that aid untrained annotators in understanding the taxonomy. We compare the results of dialog annotation performed by experts, crowdsourcing workers, and ChatGPT. To improve the performance of ChatGPT, several experiments utilising different prompt engineering techniques were conducted. We demonstrate that in some cases large language models can achieve human-like performance following a multi-step tree-like annotation pipeline on complex discourse annotation, which is usually challenging and costly in terms of time and money when performed by humans.</abstract>
      <url hash="f580941a">2023.sigdial-1.23</url>
      <bibkey>ostyakova-etal-2023-chatgpt</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.23</doi>
    </paper>
    <paper id="24">
      <title><fixed-case>D</fixed-case>iact<fixed-case>TOD</fixed-case>: Learning Generalizable Latent Dialogue Acts for Controllable Task-Oriented Dialogue Systems</title>
      <author><first>Qingyang</first><last>Wu</last></author>
      <author><first>James</first><last>Gung</last></author>
      <author><first>Raphael</first><last>Shu</last></author>
      <author><first>Yi</first><last>Zhang</last></author>
      <pages>255–267</pages>
      <abstract>Dialogue act annotations are important to improve response generation quality in task-oriented dialogue systems. However, it can be challenging to use dialogue acts to control response generation in a generalizable way because different datasets and tasks may have incompatible annotations. While alternative methods that utilize latent action spaces or reinforcement learning do not require explicit annotations, they may lack interpretability or face difficulties defining task-specific rewards. In this work, we present a novel end-to-end latent dialogue act model (DiactTOD) that represents dialogue acts in a latent space. DiactTOD, when pre-trained on a large corpus, is able to predict and control dialogue acts to generate controllable responses using these latent representations in a zero-shot fashion. Our approach demonstrates state-of-the-art performance across a wide range of experimental settings on the MultiWOZ dataset, including zero-shot, few-shot, and full data fine-tuning with both end-to-end and policy optimization configurations.</abstract>
      <url hash="fab36604">2023.sigdial-1.24</url>
      <bibkey>wu-etal-2023-diacttod</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.24</doi>
    </paper>
    <paper id="25">
      <title>Approximating Online Human Evaluation of Social Chatbots with Prompting</title>
      <author><first>Ekaterina</first><last>Svikhnushina</last></author>
      <author><first>Pearl</first><last>Pu</last></author>
      <pages>268–281</pages>
      <abstract>With conversational models becoming increasingly available to the general public, developing scalable and robust evaluation metrics is crucial to minimize potential social and psychological risks for the users. Existing evaluation metrics aim to automate offline user evaluation and approximate human judgment of pre-curated dialogs. However, they are limited in their ability to capture subjective perceptions of users who actually interact with the chatbots and might not generalize to real-world settings. To address this limitation, we propose an approach to approximate online human evaluation, leveraging large language models (LLMs) from the GPT-family. We introduce a new Dialog system Evaluation framework based on Prompting (DEP), which enables a fully automatic evaluation pipeline that replicates live user studies and achieves an impressive correlation with human judgment (up to Pearson r=0.95 on a system level). The DEP approach involves collecting synthetic chat logs of evaluated bots with an LLM in the other-play setting, where the LLM is carefully conditioned to follow a specific scenario. We further explore different prompting approaches to produce evaluation scores with the same LLM. The best-performing prompts, which contain few-shot demonstrations and instructions, show outstanding performance on the tested dataset and demonstrate the ability to generalize to other dialog corpora.</abstract>
      <url hash="9d8e4c86">2023.sigdial-1.25</url>
      <bibkey>svikhnushina-pu-2023-approximating</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.25</doi>
    </paper>
    <paper id="26">
      <title>Dialogue Response Generation Using Completion of Omitted Predicate Arguments Based on Zero Anaphora Resolution</title>
      <author><first>Ayaka</first><last>Ueyama</last></author>
      <author><first>Yoshinobu</first><last>Kano</last></author>
      <pages>282–296</pages>
      <abstract>Human conversation attempts to build common ground consisting of shared beliefs, knowledge, and perceptions that form the premise for understanding utterances. Recent deep learning-based dialogue systems use human dialogue data to train a mapping from a dialogue history to responses, but common ground not directly expressed in words makes it difficult to generate coherent responses by learning statistical patterns alone. We propose Dialogue Completion using Zero Anaphora Resolution (DCZAR), a framework that explicitly completes omitted information in the dialogue history and generates responses from the completed dialogue history. In this study, we conducted automatic and human evaluations by applying several pretraining methods and datasets in Japanese in various combinations. Experimental results show that the DCZAR framework contributes to the generation of more coherent and engaging responses.</abstract>
      <url hash="2a175dfc">2023.sigdial-1.26</url>
      <bibkey>ueyama-kano-2023-dialogue</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.26</doi>
    </paper>
    <paper id="27">
      <title>Syndicom: Improving Conversational Commonsense with Error-Injection and Natural Language Feedback</title>
      <author><first>Christopher</first><last>Richardson</last></author>
      <author><first>Anirudh</first><last>Sundar</last></author>
      <author><first>Larry</first><last>Heck</last></author>
      <pages>297–308</pages>
      <abstract>Commonsense reasoning is a critical aspect of human communication. Despite recent advances in conversational AI driven by large language models, commonsense reasoning remains a challenging task. In this work, we introduce Syndicom - a method for improving commonsense in dialogue response generation. Syndicom consists of two components. The first component is a dataset composed of commonsense dialogues created from a knowledge graph and synthesized into natural language. This dataset includes both valid and invalid responses to dialogue contexts, along with natural language feedback (NLF) for the invalid responses. The second contribution is a two-step procedure: training a model to predict natural language feedback (NLF) for invalid responses, and then training a response generation model conditioned on the predicted NLF, the invalid response, and the dialogue. Syndicom is scalable and does not require reinforcement learning. Empirical results on three tasks are evaluated using a broad range of metrics. Syndicom achieves a relative improvement of 53% over ChatGPT on ROUGE-1, and human evaluators prefer Syndicom over ChatGPT 57% of the time. We will publicly release the code and the full dataset.</abstract>
      <url hash="3875dd3a">2023.sigdial-1.27</url>
      <bibkey>richardson-heck-2023-syndicom</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.27</doi>
    </paper>
    <paper id="28">
      <title>“What do others think?”: Task-Oriented Conversational Modeling with Subjective Knowledge</title>
      <author><first>Chao</first><last>Zhao</last></author>
      <author><first>Spandana</first><last>Gella</last></author>
      <author><first>Seokhwan</first><last>Kim</last></author>
      <author><first>Di</first><last>Jin</last></author>
      <author><first>Devamanyu</first><last>Hazarika</last></author>
      <author><first>Alexandros</first><last>Papangelis</last></author>
      <author><first>Behnam</first><last>Hedayatnia</last></author>
      <author><first>Mahdi</first><last>Namazifar</last></author>
      <author id="yang-liu-icsi"><first>Yang</first><last>Liu</last></author>
      <author><first>Dilek</first><last>Hakkani-Tur</last></author>
      <pages>309–323</pages>
      <abstract>Task-oriented Dialogue (TOD) Systems aim to build dialogue systems that assist users in accomplishing specific goals, such as booking a hotel or a restaurant. Traditional TODs rely on domain-specific APIs/DBs or external factual knowledge to generate responses, which cannot accommodate subjective user requests (e.g.,”Is the WIFI reliable?” or “Does the restaurant have a good atmosphere?”). To address this issue, we propose a novel task of subjective-knowledge-based TOD (SK-TOD). We also propose the first corresponding dataset, which contains subjective knowledge-seeking dialogue contexts and manually annotated responses grounded in subjective knowledge sources. When evaluated with existing TOD approaches, we find that this task poses new challenges such as aggregating diverse opinions from multiple knowledge snippets. We hope this task and dataset can promote further research on TOD and subjective content understanding. The code and the dataset are available at https://github.com/alexa/dstc11-track5.</abstract>
      <url hash="7787c3f4">2023.sigdial-1.28</url>
      <bibkey>zhao-etal-2023-others</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.28</doi>
    </paper>
    <paper id="29">
      <title><fixed-case>UD</fixed-case>_<fixed-case>J</fixed-case>apanese-<fixed-case>CEJC</fixed-case>: Dependency Relation Annotation on Corpus of Everyday <fixed-case>J</fixed-case>apanese Conversation</title>
      <author><first>Mai</first><last>Omura</last></author>
      <author><first>Hiroshi</first><last>Matsuda</last></author>
      <author><first>Masayuki</first><last>Asahara</last></author>
      <author><first>Aya</first><last>Wakasa</last></author>
      <pages>324–335</pages>
      <abstract>In this study, we have developed Universal Dependencies (UD) resources for spoken Japanese in the Corpus of Everyday Japanese Conversation (CEJC). The CEJC is a large corpus of spoken language that encompasses various everyday conversations in Japanese, and includes word delimitation and part-of-speech annotation. We have newly annotated Long Word Unit delimitation and Bunsetsu (Japanese phrase)-based dependencies, including Bunsetsu boundaries, for CEJC. The UD of Japanese resources was constructed in accordance with hand-maintained conversion rules from the CEJC with two types of word delimitation, part-of-speech tags and Bunsetsu-based syntactic dependency relations. Furthermore, we examined various issues pertaining to the construction of UD in the CEJC by comparing it with the written Japanese corpus and evaluating UD parsing accuracy.</abstract>
      <url hash="0d7344f2">2023.sigdial-1.29</url>
      <bibkey>omura-etal-2023-ud</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.29</doi>
    </paper>
    <paper id="30">
      <title>Unravelling Indirect Answers to Wh-Questions: Corpus Construction, Analysis, and Generation</title>
      <author><first>Zulipiye</first><last>Yusupujiang</last></author>
      <author><first>Jonathan</first><last>Ginzburg</last></author>
      <pages>336–348</pages>
      <abstract>Indirect answers, crucial in human communication, serve to maintain politeness, avoid conflicts, and align with social customs. Although there has been a substantial number of studies on recognizing and understanding indirect answers to polar questions (often known as yes/no questions), there is a dearth of such work regarding wh-questions. This study takes up the challenge by constructing what is, to our knowledge, the first corpus of indirect answers to wh-questions. We analyze and interpret indirect answers to different wh-questions based on our carefully compiled corpus. In addition, we conducted a pilot study on generating indirect answers to wh-questions by fine-tuning the pre-trained generative language model DialoGPT (Zhang et al., 2020). Our results suggest this is a task that GPT finds difficult.</abstract>
      <url hash="4e63bfb9">2023.sigdial-1.30</url>
      <bibkey>yusupujiang-ginzburg-2023-unravelling</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.30</doi>
    </paper>
    <paper id="31">
      <title>A New Dataset for Causality Identification in Argumentative Texts</title>
      <author><first>Khalid</first><last>Al Khatib</last></author>
      <author><first>Michael</first><last>Voelske</last></author>
      <author><first>Anh</first><last>Le</last></author>
      <author><first>Shahbaz</first><last>Syed</last></author>
      <author><first>Martin</first><last>Potthast</last></author>
      <author><first>Benno</first><last>Stein</last></author>
      <pages>349–354</pages>
      <abstract>Existing datasets for causality identification in argumentative texts have several limitations, such as the type of input text (e.g., only claims), causality type (e.g., only positive), and the linguistic patterns investigated (e.g., only verb connectives). To resolve these limitations, we build the Webis-Causality-23 dataset, with sophisticated inputs (all units from arguments), a balanced distribution of causality types, and a larger number of linguistic patterns denoting causality. The dataset contains 1485 examples derived by combining the two paradigms of distant supervision and uncertainty sampling to identify diverse, high-quality samples of causality relations, and annotate them in a cost-effective manner.</abstract>
      <url hash="e6a8b40a">2023.sigdial-1.31</url>
      <bibkey>al-khatib-etal-2023-new</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.31</doi>
    </paper>
    <paper id="32">
      <title>Controllable Generation of Dialogue Acts for Dialogue Systems via Few-Shot Response Generation and Ranking</title>
      <author><first>Angela</first><last>Ramirez</last></author>
      <author><first>Kartik</first><last>Agarwal</last></author>
      <author><first>Juraj</first><last>Juraska</last></author>
      <author><first>Utkarsh</first><last>Garg</last></author>
      <author><first>Marilyn</first><last>Walker</last></author>
      <pages>355–369</pages>
      <abstract>Dialogue systems need to produce responses that realize multiple types of dialogue acts (DAs) with high semantic fidelity. In the past, natural language generators (NLGs) for dialogue were trained on large parallel corpora that map from a domain-specific DA and its semantic attributes to an output utterance. Recent work shows that pretrained language models (LLMs) offer new possibilities for controllable NLG using prompt-based learning. Here we develop a novel few-shot overgenerate-and-rank approach that achieves the controlled generation of DAs. We compare eight few-shot prompt styles that include a novel method of generating from textual pseudo-references using a textual style transfer approach. We develop six automatic ranking functions that identify outputs with both the correct DA and high semantic accuracy at generation time. We test our approach on three domains and four LLMs. To our knowledge, this is the first work on NLG for dialogue that automatically ranks outputs using both DA and attribute accuracy. For completeness, we compare our results to fine-tuned few-shot models trained with 5 to 100 instances per DA. Our results show that several prompt settings achieve perfect DA accuracy, and near perfect semantic accuracy (99.81%) and perform better than few-shot fine-tuning.</abstract>
      <url hash="0819a538">2023.sigdial-1.32</url>
      <bibkey>ramirez-etal-2023-controllable</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.32</doi>
    </paper>
    <paper id="33">
      <title>Reference Resolution and New Entities in Exploratory Data Visualization: From Controlled to Unconstrained Interactions with a Conversational Assistant</title>
      <author><first>Abari</first><last>Bhattacharya</last></author>
      <author><first>Abhinav</first><last>Kumar</last></author>
      <author><first>Barbara</first><last>Di Eugenio</last></author>
      <author><first>Roderick</first><last>Tabalba</last></author>
      <author><first>Jillian</first><last>Aurisano</last></author>
      <author><first>Veronica</first><last>Grosso</last></author>
      <author><first>Andrew</first><last>Johnson</last></author>
      <author><first>Jason</first><last>Leigh</last></author>
      <author><first>Moira</first><last>Zellner</last></author>
      <pages>370–380</pages>
      <abstract>In the context of data visualization, as in other grounded settings, referents are created by the task the agents engage in and are salient because they belong to the shared physical setting. Our focus is on resolving references to visualizations on large displays; crucially, reference resolution is directly involved in the process of creating new entities, namely new visualizations. First, we developed a reference resolution model for a conversational assistant. We trained the assistant on controlled dialogues for data visualizations involving a single user. Second, we ported the conversational assistant including its reference resolution model to a different domain, supporting two users collaborating on a data exploration task. We explore how the new setting affects reference detection and resolution; we compare the performance in the controlled vs unconstrained setting, and discuss the general lessons that we draw from this adaptation.</abstract>
      <url hash="7ddc5276">2023.sigdial-1.33</url>
      <bibkey>bhattacharya-etal-2023-reference</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.33</doi>
    </paper>
    <paper id="34">
      <title><fixed-case>CONVERSER</fixed-case>: Few-shot Conversational Dense Retrieval with Synthetic Data Generation</title>
      <author><first>Chao-Wei</first><last>Huang</last></author>
      <author><first>Chen-Yu</first><last>Hsu</last></author>
      <author><first>Tsu-Yuan</first><last>Hsu</last></author>
      <author><first>Chen-An</first><last>Li</last></author>
      <author><first>Yun-Nung</first><last>Chen</last></author>
      <pages>381–387</pages>
      <abstract>Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https://github.com/MiuLab/CONVERSER</abstract>
      <url hash="7bd46af3">2023.sigdial-1.34</url>
      <bibkey>huang-etal-2023-converser</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.34</doi>
    </paper>
    <paper id="35">
      <title>Speaker Role Identification in Call Centre Dialogues: Leveraging Opening Sentences and Large Language Models</title>
      <author><first>Minh-Quoc</first><last>Nghiem</last></author>
      <author><first>Nichola</first><last>Roberts</last></author>
      <author><first>Dmitry</first><last>Sityaev</last></author>
      <pages>388–392</pages>
      <abstract>This paper addresses the task of speaker role identification in call centre dialogues, focusing on distinguishing between the customer and the agent. We propose a text-based approach that utilises the identification of the agent’s opening sentence as a key feature for role classification. The opening sentence is identified using a model trained through active learning. By combining this information with a large language model, we accurately classify the speaker roles. The proposed approach is evaluated on a dataset of call centre dialogues and achieves 93.61% accuracy. This work contributes to the field by providing an effective solution for speaker role identification in call centre settings, with potential applications in interaction analysis and information retrieval.</abstract>
      <url hash="c9c8ffb0">2023.sigdial-1.35</url>
      <bibkey>nghiem-etal-2023-speaker</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.35</doi>
    </paper>
    <paper id="36">
      <title>Synthesising Personality with Neural Speech Synthesis</title>
      <author><first>Shilin</first><last>Gao</last></author>
      <author><first>Matthew P.</first><last>Aylett</last></author>
      <author><first>David A.</first><last>Braude</last></author>
      <author><first>Catherine</first><last>Lai</last></author>
      <pages>393–399</pages>
      <abstract>Matching the personality of conversational agent to the personality of the user can significantly improve the user experience, with many successful examples in text-based chatbots. It is also important for a voice-based system to be able to alter the personality of the speech as perceived by the users. In this pilot study, fifteen voices were rated using Big Five personality traits. Five content-neutral sentences were chosen for the listening tests. The audio data, together with two rated traits (Extroversion and Agreeableness), were used to train a neural speech synthesiser based on one male and one female voices. The effect of altering the personality trait features was evaluated by a second listening test. Both perceived extroversion and agreeableness in the synthetic voices were affected significantly. The controllable range was limited due to a lack of variance in the source audio data. The perceived personality traits correlated with each other and with the naturalness of the speech. Future work can be making a chatbot speak in a voice with a pre-defined or adaptive personality by using personality synthesis in speech together with text-based personality generation.</abstract>
      <url hash="80026bcd">2023.sigdial-1.36</url>
      <bibkey>gao-etal-2023-synthesising</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.36</doi>
    </paper>
    <paper id="37">
      <title>Prompting, Retrieval, Training: An exploration of different approaches for task-oriented dialogue generation</title>
      <author><first>Gonçalo</first><last>Raposo</last></author>
      <author><first>Luisa</first><last>Coheur</last></author>
      <author><first>Bruno</first><last>Martins</last></author>
      <pages>400–412</pages>
      <abstract>Task-oriented dialogue systems need to generate appropriate responses to help fulfill users’ requests. This paper explores different strategies, namely prompting, retrieval, and fine-tuning, for task-oriented dialogue generation. Through a systematic evaluation, we aim to provide valuable insights and guidelines for researchers and practitioners working on developing efficient and effective dialogue systems for real-world applications. Evaluation is performed on the MultiWOZ and Taskmaster-2 datasets, and we test various versions of FLAN-T5, GPT-3.5, and GPT-4 models. Costs associated with running these models are analyzed, and dialogue evaluation is briefly discussed. Our findings suggest that when testing data differs from the training data, fine-tuning may decrease performance, favoring a combination of a more general language model and a prompting mechanism based on retrieved examples.</abstract>
      <url hash="5a332f7c">2023.sigdial-1.37</url>
      <bibkey>raposo-etal-2023-prompting</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.37</doi>
    </paper>
    <paper id="38">
      <title>Bootstrapping a Conversational Guide for Colonoscopy Prep</title>
      <author><first>Pulkit</first><last>Arya</last></author>
      <author><first>Madeleine</first><last>Bloomquist</last></author>
      <author><first>Subhankar</first><last>Chakraborty</last></author>
      <author><first>Andrew</first><last>Perrault</last></author>
      <author><first>William</first><last>Schuler</last></author>
      <author><first>Eric</first><last>Fosler-Lussier</last></author>
      <author><first>Michael</first><last>White</last></author>
      <pages>413–420</pages>
      <abstract>Creating conversational systems for niche domains is a challenging task, further exacerbated by a lack of quality datasets. We explore the construction of safer conversational systems for guiding patients in preparing for colonoscopies. This has required a data generation pipeline to generate a minimum viable dataset to bootstrap a semantic parser, augmented by automatic paraphrasing. Our study suggests large language models (e.g., GPT-3.5 and GPT-4) are a viable alternative to crowd sourced paraphrasing, but conversational systems that rely upon language models’ ability to do temporal reasoning struggle to provide accurate responses. A neural-symbolic system that performs temporal reasoning on an intermediate representation of user queries shows promising results compared to an end-to-end dialogue system, improving the number of correct responses while vastly reducing the number of incorrect or misleading ones.</abstract>
      <url hash="22c90b02">2023.sigdial-1.38</url>
      <bibkey>arya-etal-2023-bootstrapping</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.38</doi>
    </paper>
    <paper id="39">
      <title>Applying Item Response Theory to Task-oriented Dialogue Systems for Accurately Determining User’s Task Success Ability</title>
      <author><first>Ryu</first><last>Hirai</last></author>
      <author><first>Ao</first><last>Guo</last></author>
      <author><first>Ryuichiro</first><last>Higashinaka</last></author>
      <pages>421–427</pages>
      <abstract>While task-oriented dialogue systems have improved, not all users can fully accomplish their tasks. Users with limited knowledge about the system may experience dialogue breakdowns or fail to achieve their tasks because they do not know how to interact with the system. For addressing this issue, it would be desirable to construct a system that can estimate the user’s task success ability and adapt to that ability. In this study, we propose a method that estimates this ability by applying item response theory (IRT), commonly used in education for estimating examinee abilities, to task-oriented dialogue systems. Through experiments predicting the probability of a correct answer to each slot by using the estimated task success ability, we found that the proposed method significantly outperformed baselines.</abstract>
      <url hash="8cf80326">2023.sigdial-1.39</url>
      <bibkey>hirai-etal-2023-applying</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.39</doi>
    </paper>
    <paper id="40">
      <title>An Open-Domain Avatar Chatbot by Exploiting a Large Language Model</title>
      <author><first>Takato</first><last>Yamazaki</last></author>
      <author><first>Tomoya</first><last>Mizumoto</last></author>
      <author><first>Katsumasa</first><last>Yoshikawa</last></author>
      <author><first>Masaya</first><last>Ohagi</last></author>
      <author><first>Toshiki</first><last>Kawamoto</last></author>
      <author><first>Toshinori</first><last>Sato</last></author>
      <pages>428–432</pages>
      <abstract>With the ambition to create avatars capable of human-level casual conversation, we developed an open-domain avatar chatbot, situated in a virtual reality environment, that employs a large language model (LLM). Introducing the LLM posed several challenges for multimodal integration, such as developing techniques to align diverse outputs and avatar control, as well as addressing the issue of slow generation speed. To address these challenges, we integrated various external modules into our system. Our system is based on the award-winning model from the Dialogue System Live Competition 5. Through this work, we hope to stimulate discussions within the research community about the potential and challenges of multimodal dialogue systems enhanced with LLMs.</abstract>
      <url hash="fe832c67">2023.sigdial-1.40</url>
      <bibkey>yamazaki-etal-2023-open</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.40</doi>
    </paper>
    <paper id="41">
      <title>Learning Multimodal Cues of Children’s Uncertainty</title>
      <author><first>Qi</first><last>Cheng</last></author>
      <author><first>Mert</first><last>Inan</last></author>
      <author><first>Rahma</first><last>Mbarki</last></author>
      <author><first>Grace</first><last>Grmek</last></author>
      <author><first>Theresa</first><last>Choi</last></author>
      <author><first>Yiming</first><last>Sun</last></author>
      <author><first>Kimele</first><last>Persaud</last></author>
      <author><first>Jenny</first><last>Wang</last></author>
      <author><first>Malihe</first><last>Alikhani</last></author>
      <pages>433–443</pages>
      <abstract>Understanding uncertainty plays a critical role in achieving common ground (Clark et al., 1983). This is especially important for multimodal AI systems that collaborate with users to solve a problem or guide the user through a challenging concept. In this work, for the first time, we present a dataset annotated in collaboration with developmental and cognitive psychologists for the purpose of studying nonverbal cues of uncertainty. We then present an analysis of the data, studying different roles of uncertainty and its relationship with task difficulty and performance. Lastly, we present a multimodal machine learning model that can predict uncertainty given a real-time video clip of a participant, which we find improves upon a baseline multimodal transformer model. This work informs research on cognitive coordination between human-human and human-AI and has broad implications for gesture understanding and generation. The anonymized version of our data and code will be publicly available upon the completion of the required consent forms and data sheets.</abstract>
      <url hash="7cbbb74b">2023.sigdial-1.41</url>
      <bibkey>cheng-etal-2023-learning</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.41</doi>
    </paper>
    <paper id="42">
      <title>Grounding Description-Driven Dialogue State Trackers with Knowledge-Seeking Turns</title>
      <author><first>Alexandru</first><last>Coca</last></author>
      <author><first>Bo-Hsiang</first><last>Tseng</last></author>
      <author><first>Jinghong</first><last>Chen</last></author>
      <author><first>Weizhe</first><last>Lin</last></author>
      <author><first>Weixuan</first><last>Zhang</last></author>
      <author><first>Tisha</first><last>Anders</last></author>
      <author id="bill-byrne"><first>Bill</first><last>Byrne</last></author>
      <pages>444–456</pages>
      <abstract>Schema-guided dialogue state trackers can generalise to new domains without further training, yet they are sensitive to the writing style of the schemata. Augmenting the training set with human or synthetic schema paraphrases improves the model robustness to these variations but can be either costly or difficult to control. We propose to circumvent these issues by grounding the state tracking model in knowledge-seeking turns collected from the dialogue corpus as well as the schema. Including these turns in prompts during finetuning and inference leads to marked improvements in model robustness, as demonstrated by large average joint goal accuracy and schema sensitivity improvements on SGD and SGD-X.</abstract>
      <url hash="35382728">2023.sigdial-1.42</url>
      <bibkey>coca-etal-2023-grounding</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.42</doi>
    </paper>
    <paper id="43">
      <title>Resolving References in Visually-Grounded Dialogue via Text Generation</title>
      <author><first>Bram</first><last>Willemsen</last></author>
      <author><first>Livia</first><last>Qian</last></author>
      <author><first>Gabriel</first><last>Skantze</last></author>
      <pages>457–469</pages>
      <abstract>Vision-language models (VLMs) have shown to be effective at image retrieval based on simple text queries, but text-image retrieval based on conversational input remains a challenge. Consequently, if we want to use VLMs for reference resolution in visually-grounded dialogue, the discourse processing capabilities of these models need to be augmented. To address this issue, we propose fine-tuning a causal large language model (LLM) to generate definite descriptions that summarize coreferential information found in the linguistic context of references. We then use a pretrained VLM to identify referents based on the generated descriptions, zero-shot. We evaluate our approach on a manually annotated dataset of visually-grounded dialogues and achieve results that, on average, exceed the performance of the baselines we compare against. Furthermore, we find that using referent descriptions based on larger context windows has the potential to yield higher returns.</abstract>
      <url hash="635628f9">2023.sigdial-1.43</url>
      <bibkey>willemsen-etal-2023-resolving</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.43</doi>
    </paper>
    <paper id="44">
      <title>Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning</title>
      <author><first>Hoang</first><last>Nguyen</last></author>
      <author><first>Chenwei</first><last>Zhang</last></author>
      <author><first>Ye</first><last>Liu</last></author>
      <author><first>Philip</first><last>Yu</last></author>
      <pages>470–481</pages>
      <abstract>Recent advanced methods in Natural Language Understanding for Task-oriented Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a large amount of annotated data to achieve competitive performance. In reality, token-level annotations (slot labels) are time-consuming and difficult to acquire. In this work, we study the Slot Induction (SI) task whose objective is to induce slot boundaries without explicit knowledge of token-level slot annotations. We propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised semantic knowledge extracted from PLM, and (2) additional sentence-level intent label signals available from TOD. Our approach is shown to be effective in SI task and capable of bridging the gaps with token-level supervised models on two NLU benchmark datasets. When generalized to emerging intents, our SI objectives also provide enhanced slot label representations, leading to improved performance on the Slot Filling tasks.</abstract>
      <url hash="db1acca5">2023.sigdial-1.44</url>
      <bibkey>nguyen-etal-2023-slot</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.44</doi>
    </paper>
    <paper id="45">
      <title>The timing bottleneck: Why timing and overlap are mission-critical for conversational user interfaces, speech recognition and dialogue systems</title>
      <author><first>Andreas</first><last>Liesenfeld</last></author>
      <author><first>Alianda</first><last>Lopez</last></author>
      <author><first>Mark</first><last>Dingemanse</last></author>
      <pages>482–495</pages>
      <abstract>Speech recognition systems are a key intermediary in voice-driven human-computer interaction. Although speech recognition works well for pristine monologic audio, real-life use cases in open-ended interactive settings still present many challenges. We argue that timing is mission-critical for dialogue systems, and evaluate 5 major commercial ASR systems for their conversational and multilingual support. We find that word error rates for natural conversational data in 6 languages remain abysmal, and that overlap remains a key challenge (study 1). This impacts especially the recognition of conversational words (study 2), and in turn has dire consequences for downstream intent recognition (study 3). Our findings help to evaluate the current state of conversational ASR, contribute towards multidimensional error analysis and evaluation, and identify phenomena that need most attention on the way to build robust interactive speech technologies.</abstract>
      <url hash="a5e58b5d">2023.sigdial-1.45</url>
      <bibkey>liesenfeld-etal-2023-timing</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.45</doi>
    </paper>
    <paper id="46">
      <title>Enhancing Task Bot Engagement with Synthesized Open-Domain Dialog</title>
      <author><first>Miaoran</first><last>Li</last></author>
      <author><first>Baolin</first><last>Peng</last></author>
      <author><first>Michel</first><last>Galley</last></author>
      <author><first>Jianfeng</first><last>Gao</last></author>
      <author><first>Zhu (Drew)</first><last>Zhang</last></author>
      <pages>496–508</pages>
      <abstract>The construction of dialog systems for various types of conversations, such as task-oriented dialog (TOD) and open-domain dialog (ODD), has been an active area of research. In order to more closely mimic human-like conversations that often involve the fusion of different dialog modes, it is important to develop systems that can effectively handle both TOD and ODD and access different knowledge sources. In this work, we present a new automatic framework to enrich TODs with synthesized ODDs. We also introduce the PivotBot model, which is capable of handling both TOD and ODD modes and can access different knowledge sources to generate informative responses. Evaluation results indicate the superior ability of the proposed model to switch smoothly between TOD and ODD tasks.</abstract>
      <url hash="bb2aeac5">2023.sigdial-1.46</url>
      <bibkey>li-etal-2023-enhancing-task</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.46</doi>
    </paper>
    <paper id="47">
      <title>Enhancing Performance on Seen and Unseen Dialogue Scenarios using Retrieval-Augmented End-to-End Task-Oriented System</title>
      <author><first>Jianguo</first><last>Zhang</last></author>
      <author><first>Stephen</first><last>Roller</last></author>
      <author><first>Kun</first><last>Qian</last></author>
      <author><first>Zhiwei</first><last>Liu</last></author>
      <author><first>Rui</first><last>Meng</last></author>
      <author><first>Shelby</first><last>Heinecke</last></author>
      <author><first>Huan</first><last>Wang</last></author>
      <author><first>Silvio</first><last>Savarese</last></author>
      <author><first>Caiming</first><last>Xiong</last></author>
      <pages>509–518</pages>
      <abstract>End-to-end task-oriented dialogue (TOD) systems have achieved promising performance by leveraging sophisticated natural language understanding and natural language generation capabilities of pre-trained models. This work enables the TOD systems with more flexibility through a simple cache. The cache provides the flexibility to dynamically update the TOD systems and handle both existing and unseen dialogue scenarios. Towards this end, we first fine-tune a retrieval module to effectively retrieve the most relevant information entries from the cache. We then train end-to-end TOD models that can refer to and ground on both dialogue history and retrieved information during TOD generation. The introduced cache is straightforward to construct, and the backbone models of TOD systems are compatible with existing pre-trained generative models. Extensive experiments demonstrate the superior performance of our framework, with a notable improvement in non-empty joint goal accuracy by 6.7% compared to strong baselines.</abstract>
      <url hash="b68c02e0">2023.sigdial-1.47</url>
      <bibkey>zhang-etal-2023-enhancing-performance</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.47</doi>
    </paper>
    <paper id="48">
      <title>Transformer-based Multi-Party Conversation Generation using Dialogue Discourse Acts Planning</title>
      <author><first>Alexander</first><last>Chernyavskiy</last></author>
      <author><first>Dmitry</first><last>Ilvovsky</last></author>
      <pages>519–529</pages>
      <abstract>Recent transformer-based approaches to multi-party conversation generation may produce syntactically coherent but discursively inconsistent dialogues in some cases. To address this issue, we propose an approach to integrate a dialogue act planning stage into the end-to-end transformer-based generation pipeline. This approach consists of a transformer fine-tuning procedure based on linearized dialogue representations that include special discourse tokens. The obtained results demonstrate that incorporating discourse tokens into training sequences is sufficient to significantly improve dialogue consistency and overall generation quality. The suggested approach performs well, including for automatically annotated data. Apart from that, it is observed that increasing the weight of the discourse planning task in the loss function accelerates learning convergence.</abstract>
      <url hash="e9d7f0b3">2023.sigdial-1.48</url>
      <bibkey>chernyavskiy-ilvovsky-2023-transformer</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.48</doi>
    </paper>
    <paper id="49">
      <title>Incorporating Annotator Uncertainty into Representations of Discourse Relations</title>
      <author><first>S. Magalí</first><last>López Cortez</last></author>
      <author><first>Cassandra L.</first><last>Jacobs</last></author>
      <pages>530–537</pages>
      <abstract>Annotation of discourse relations is a known difficult task, especially for non-expert annotators. In this paper, we investigate novice annotators’ uncertainty on the annotation of discourse relations on spoken conversational data. We find that dialogue context (single turn, pair of turns within speaker, and pair of turns across speakers) is a significant predictor of confidence scores. We compute distributed representations of discourse relations from co-occurrence statistics that incorporate information about confidence scores and dialogue context. We perform a hierarchical clustering analysis using these representations and show that weighting discourse relation representations with information about confidence and dialogue context coherently models our annotators’ uncertainty about discourse relation labels.</abstract>
      <url hash="b86c1b9a">2023.sigdial-1.49</url>
      <bibkey>lopez-cortez-jacobs-2023-incorporating</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.49</doi>
    </paper>
    <paper id="50">
      <title>Investigating the Representation of Open Domain Dialogue Context for Transformer Models</title>
      <author><first>Vishakh</first><last>Padmakumar</last></author>
      <author><first>Behnam</first><last>Hedayatnia</last></author>
      <author><first>Di</first><last>Jin</last></author>
      <author><first>Patrick</first><last>Lange</last></author>
      <author><first>Seokhwan</first><last>Kim</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <author id="yang-liu-icsi"><first>Yang</first><last>Liu</last></author>
      <author><first>Dilek</first><last>Hakkani-Tur</last></author>
      <pages>538–547</pages>
      <abstract>The bulk of work adapting transformer models to open-domain dialogue represents dialogue context as the concatenated set of turns in natural language. However, it is unclear if this is the best approach. In this work, we investigate this question by means of an empirical controlled experiment varying the dialogue context format from text-only formats (all recent utterances, summaries, selected utterances) as well as variants that are more structurally different (triples, AMR). We compare these formats based on fine-tuned model performance on two downstream tasks—knowledge selection and response generation. We find that simply concatenating the utterances works as a strong baseline in most cases, but is outperformed in longer contexts by a hybrid approach of combining a summary of the context with recent utterances. Through empirical analysis, our work highlights the need to examine the format of context representation and offers recommendations on adapting general-purpose language models to dialogue tasks.</abstract>
      <url hash="439af716">2023.sigdial-1.50</url>
      <bibkey>padmakumar-etal-2023-investigating</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.50</doi>
    </paper>
    <paper id="51">
      <title>C3: Compositional Counterfactual Contrastive Learning for Video-grounded Dialogues</title>
      <author><first>Hung</first><last>Le</last></author>
      <author><first>Nancy</first><last>Chen</last></author>
      <author><first>Steven C.H.</first><last>Hoi</last></author>
      <pages>548–561</pages>
      <abstract>Video-grounded dialogue systems aim to integrate video understanding and dialogue understanding to generate responses that are relevant to both the dialogue and video context. Most existing approaches employ deep learning models and have achieved remarkable performance, given the relatively small datasets available. However, the results are partially accomplished by exploiting biases in the datasets rather than developing multimodal reasoning, resulting in limited generalization. In this paper, we propose a novel approach of Compositional Counterfactual Contrastive Learning (C3) to develop contrastive training between factual and counterfactual samples in video-grounded dialogues. Specifically, we design factual/counterfactual samples based on the temporal steps in videos and tokens in dialogues and propose contrastive loss functions that exploit object-level or action-level variance. Different from prior approaches, we focus on contrastive hidden state representations among compositional output tokens to optimize the representation space in a generation setting. We achieved promising performance gains on the Audio-Visual Scene-Aware Dialogues (AVSD) benchmark and showed the benefits of our approach in grounding video and dialogue context.</abstract>
      <url hash="fa1e3263">2023.sigdial-1.51</url>
      <bibkey>le-etal-2023-c3</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.51</doi>
    </paper>
    <paper id="52">
      <title>No that’s not what <fixed-case>I</fixed-case> meant: Handling Third Position Repair in Conversational Question Answering</title>
      <author><first>Vevake</first><last>Balaraman</last></author>
      <author><first>Arash</first><last>Eshghi</last></author>
      <author><first>Ioannis</first><last>Konstas</last></author>
      <author><first>Ioannis</first><last>Papaioannou</last></author>
      <pages>562–571</pages>
      <abstract>The ability to handle miscommunication is crucial to robust and faithful conversational AI. People usually deal with miscommunication immediately as they detect it, using highly systematic interactional mechanisms called repair. One important type of repair is Third Position Repair (TPR) whereby a speaker is initially misunderstood but then corrects the misunderstanding as it becomes apparent after the addressee’s erroneous response. Here, we collect and publicly release REPAIR-QA, the first large dataset of TPRs in a conversational question answering (QA) setting. The data is comprised of the TPR turns, corresponding dialogue contexts, and candidate repairs of the original turn for execution of TPRs. We demonstrate the usefulness of the data by training and evaluating strong baseline models for executing TPRs. For stand-alone TPR execution, we perform both automatic and human evaluations on a fine-tuned T5 model, as well as OpenAI’s GPT-3 LLMs. Additionally, we extrinsically evaluate the LLMs’ TPR processing capabilities in the downstream conversational QA task. The results indicate poor out-of-the-box performance on TPR’s by the GPT-3 models, which then significantly improves when exposed to REPAIR-QA.</abstract>
      <url hash="17eb34c6">2023.sigdial-1.52</url>
      <bibkey>balaraman-etal-2023-thats</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.52</doi>
    </paper>
    <paper id="53">
      <title>When to generate hedges in peer-tutoring interactions</title>
      <author><first>Alafate</first><last>Abulimiti</last></author>
      <author><first>Chloé</first><last>Clavel</last></author>
      <author><first>Justine</first><last>Cassell</last></author>
      <pages>572–583</pages>
      <abstract>This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model’s performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.</abstract>
      <url hash="3f6d61e3">2023.sigdial-1.53</url>
      <bibkey>abulimiti-etal-2023-generate</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.53</doi>
    </paper>
    <paper id="54">
      <title><fixed-case>P</fixed-case>aper<fixed-case>P</fixed-case>ersi<fixed-case>C</fixed-case>hat: Scientific Paper Discussion Chatbot using Transformers and Discourse Flow Management</title>
      <author><first>Alexander</first><last>Chernyavskiy</last></author>
      <author><first>Max</first><last>Bregeda</last></author>
      <author><first>Maria</first><last>Nikiforova</last></author>
      <pages>584–587</pages>
      <abstract>The rate of scientific publications is increasing exponentially, necessitating a significant investment of time in order to read and comprehend the most important articles. While ancillary services exist to facilitate this process, they are typically closed-model and paid services or have limited capabilities. In this paper, we present <i>PaperPersiChat</i>, an open chatbot-system designed for the discussion of scientific papers. This system supports summarization and question-answering modes within a single end-to-end chatbot pipeline, which is guided by discourse analysis. To expedite the development of similar systems, we also release the gathered dataset, which has no publicly available analogues.</abstract>
      <url hash="5bfe4c7b">2023.sigdial-1.54</url>
      <bibkey>chernyavskiy-etal-2023-paperpersichat</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.54</doi>
    </paper>
    <paper id="55">
      <title><fixed-case>F</fixed-case>ur<fixed-case>C</fixed-case>hat: An Embodied Conversational Agent using <fixed-case>LLM</fixed-case>s, Combining Open and Closed-Domain Dialogue with Facial Expressions</title>
      <author><first>Neeraj</first><last>Cherakara</last></author>
      <author><first>Finny</first><last>Varghese</last></author>
      <author><first>Sheena</first><last>Shabana</last></author>
      <author><first>Nivan</first><last>Nelson</last></author>
      <author><first>Abhiram</first><last>Karukayil</last></author>
      <author><first>Rohith</first><last>Kulothungan</last></author>
      <author><first>Mohammed</first><last>Afil Farhan</last></author>
      <author><first>Birthe</first><last>Nesset</last></author>
      <author><first>Meriam</first><last>Moujahid</last></author>
      <author><first>Tanvi</first><last>Dinkar</last></author>
      <author><first>Verena</first><last>Rieser</last></author>
      <author><first>Oliver</first><last>Lemon</last></author>
      <pages>588–592</pages>
      <abstract>We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of open and closed-domain dialogue along with facial expressions, by using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.</abstract>
      <url hash="3001ab5b">2023.sigdial-1.55</url>
      <bibkey>cherakara-etal-2023-furchat</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.55</doi>
    </paper>
    <paper id="56">
      <title>Towards Breaking the Self-imposed Filter Bubble in Argumentative Dialogues</title>
      <author><first>Annalena</first><last>Aicher</last></author>
      <author><first>Daniel</first><last>Kornmueller</last></author>
      <author><first>Yuki</first><last>Matsuda</last></author>
      <author><first>Stefan</first><last>Ultes</last></author>
      <author><first>Wolfgang</first><last>Minker</last></author>
      <author><first>Keiichi</first><last>Yasumoto</last></author>
      <pages>593–604</pages>
      <abstract>Human users tend to selectively ignore information that contradicts their pre-existing beliefs or opinions in their process of information seeking. These “self-imposed filter bubbles” (SFB) pose a significant challenge for cooperative argumentative dialogue systems aiming to build an unbiased opinion and a better understanding of the topic at hand. To address this issue, we develop a strategy for overcoming users’ SFB within the course of the interaction. By continuously modeling the user’s position in relation to the SFB, we are able to identify the respective arguments which maximize the probability to get outside the SFB and present them to the user. We implemented this approach in an argumentative dialogue system and evaluated in a laboratory user study with 60 participants to show its validity and applicability. The findings suggest that the strategy was successful in breaking users’ SFBs and promoting a more reflective and comprehensive discussion of the topic.</abstract>
      <url hash="b8ddc231">2023.sigdial-1.56</url>
      <bibkey>aicher-etal-2023-towards</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.56</doi>
    </paper>
    <paper id="57">
      <title>The Open-domain Paradox for Chatbots: Common Ground as the Basis for Human-like Dialogue</title>
      <author><first>Gabriel</first><last>Skantze</last></author>
      <author><first>A. Seza</first><last>Doğruöz</last></author>
      <pages>605–614</pages>
      <abstract>There is a surge in interest in the development of open-domain chatbots, driven by the recent advancements of large language models. The “openness” of the dialogue is expected to be maximized by providing minimal information to the users about the common ground they can expect, including the presumed joint activity. However, evidence suggests that the effect is the opposite. Asking users to “just chat about anything” results in a very narrow form of dialogue, which we refer to as the “open-domain paradox”. In this position paper, we explain this paradox through the theory of common ground as the basis for human-like communication. Furthermore, we question the assumptions behind open-domain chatbots and identify paths forward for enabling common ground in human-computer dialogue.</abstract>
      <url hash="152a0922">2023.sigdial-1.57</url>
      <bibkey>skantze-dogruoz-2023-open</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.57</doi>
    </paper>
    <paper id="58">
      <title><fixed-case>MERCY</fixed-case>: Multiple Response Ranking Concurrently in Realistic Open-Domain Conversational Systems</title>
      <author><first>Sarik</first><last>Ghazarian</last></author>
      <author><first>Behnam</first><last>Hedayatnia</last></author>
      <author><first>Di</first><last>Jin</last></author>
      <author><first>Sijia</first><last>Liu</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <author id="yang-liu-icsi"><first>Yang</first><last>Liu</last></author>
      <author><first>Dilek</first><last>Hakkani-Tur</last></author>
      <pages>615–631</pages>
      <abstract>Automatic Evaluation (AE) and Response Selection (RS) models assign quality scores to various candidate responses and rank them in conversational setups. Prior response ranking research compares various models’ performance on synthetically generated test sets. In this work, we investigate the performance of model-based reference-free AE and RS models on our constructed response ranking datasets that mirror real-case scenarios of ranking candidates during inference time. Metrics’ unsatisfying performance can be interpreted as their low generalizability over more pragmatic conversational domains such as human-chatbot dialogs. To alleviate this issue we propose a novel RS model called MERCY that simulates human behavior in selecting the best candidate by taking into account distinct candidates concurrently and learns to rank them. In addition, MERCY leverages natural language feedback as another component to help the ranking task by explaining why each candidate response is relevant/irrelevant to the dialog context. These feedbacks are generated by prompting large language models in a few-shot setup. Our experiments show the better performance of MERCY over baselines for the response ranking task in our curated realistic datasets.</abstract>
      <url hash="83e346a7">2023.sigdial-1.58</url>
      <bibkey>ghazarian-etal-2023-mercy</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.58</doi>
    </paper>
    <paper id="59">
      <title>Empathetic Response Generation for Distress Support</title>
      <author><first>Anuradha</first><last>Welivita</last></author>
      <author><first>Chun-Hung</first><last>Yeh</last></author>
      <author><first>Pearl</first><last>Pu</last></author>
      <pages>632–644</pages>
      <abstract>AI-driven chatbots are seen as an attractive solution to support people undergoing emotional distress. One of the main components of such a chatbot is the ability to empathize with the user. But a significant limitation in achieving this goal is the lack of a large dialogue dataset containing empathetic support for those undergoing distress. In this work, we curate a large-scale dialogue dataset that contains ≈1.3M peer support dialogues spanning across more than 4K distress-related topics. We analyze the empathetic characteristics of this dataset using statistical and visual means. To demonstrate the utility of this dataset, we train four baseline neural dialogue models that can respond empathetically to distress prompts. Two of the baselines adapt existing architecture and the other two incorporate a framework identifying levels of cognitive and emotional empathy in responses. Automatic and human evaluation of these models validate the utility of the dataset in generating empathetic responses for distress support and show that identifying levels of empathy in peer-support responses facilitates generating responses that are lengthier, richer in empathy, and closer to the ground truth.</abstract>
      <url hash="d0b2444d">2023.sigdial-1.59</url>
      <bibkey>welivita-etal-2023-empathetic</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.59</doi>
    </paper>
    <paper id="60">
      <title>Reasoning before Responding: Integrating Commonsense-based Causality Explanation for Empathetic Response Generation</title>
      <author><first>Yahui</first><last>Fu</last></author>
      <author><first>Koji</first><last>Inoue</last></author>
      <author><first>Chenhui</first><last>Chu</last></author>
      <author><first>Tatsuya</first><last>Kawahara</last></author>
      <pages>645–656</pages>
      <abstract>Recent approaches to empathetic response generation try to incorporate commonsense knowledge or reasoning about the causes of emotions to better understand the user’s experiences and feelings. However, these approaches mainly focus on understanding the causalities of context from the user’s perspective, ignoring the system’s perspective. In this paper, we propose a commonsense-based causality explanation approach for diverse empathetic response generation that considers both the user’s perspective (user’s desires and reactions) and the system’s perspective (system’s intentions and reactions). We enhance ChatGPT’s ability to reason for the system’s perspective by integrating in-context learning with commonsense knowledge. Then, we integrate the commonsense-based causality explanation with both ChatGPT and a T5-based model. Experimental evaluations demonstrate that our method outperforms other comparable methods on both automatic and human evaluations.</abstract>
      <url hash="4718ebc4">2023.sigdial-1.60</url>
      <bibkey>fu-etal-2023-reasoning</bibkey>
      <doi>10.18653/v1/2023.sigdial-1.60</doi>
    </paper>
  </volume>
  <event id="sigdial-2023">
    <colocated>
      <volume-id>2023.inlg-main</volume-id>
      <volume-id>2023.inlg-demos</volume-id>
      <volume-id>2023.inlg-genchal</volume-id>
      <volume-id>2023.dstc-1</volume-id>
      <volume-id>2023.icard-1</volume-id>
      <volume-id>2023.cs4oa-1</volume-id>
      <volume-id>2023.mmnlg-1</volume-id>
      <volume-id>2023.tllm-1</volume-id>
      <volume-id>2023.yrrsds-1</volume-id>
    </colocated>
  </event>
</collection>
