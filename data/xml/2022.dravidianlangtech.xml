<?xml version='1.0' encoding='UTF-8'?>
<collection id="2022.dravidianlangtech">
  <volume id="1" ingest-date="2022-05-15" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Speech and Language Technologies for Dravidian Languages</booktitle>
      <editor><first>Bharathi Raja</first><last>Chakravarthi</last></editor>
      <editor><first>Ruba</first><last>Priyadharshini</last></editor>
      <editor><first>Anand Kumar</first><last>Madasamy</last></editor>
      <editor><first>Parameswari</first><last>Krishnamurthy</last></editor>
      <editor><first>Elizabeth</first><last>Sherly</last></editor>
      <editor><first>Sinnathamby</first><last>Mahesan</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Dublin, Ireland</address>
      <month>May</month>
      <year>2022</year>
      <url hash="91fda806">2022.dravidianlangtech-1</url>
      <venue>dravidianlangtech</venue>
    </meta>
    <frontmatter>
      <url hash="fdb380c0">2022.dravidianlangtech-1.0</url>
      <bibkey>dravidianlangtech-2022-speech</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>BERT</fixed-case>-Based Sequence Labelling Approach for Dependency Parsing in <fixed-case>T</fixed-case>amil</title>
      <author><first>C S Ayush</first><last>Kumar</last></author>
      <author><first>Advaith</first><last>Maharana</last></author>
      <author><first>Srinath</first><last>Murali</last></author>
      <author><first>Premjith</first><last>B</last></author>
      <author><first>Soman</first><last>Kp</last></author>
      <pages>1-8</pages>
      <abstract>Dependency parsing is a method for doing surface-level syntactic analysis on natural language texts. The scarcity of any viable tools for doing these tasks in Dravidian Languages has introduced a new line of research into these topics. This paper focuses on a novel approach that uses word-to-word dependency tagging using BERT models to improve the malt parser performance. We used Tamil, a morphologically rich and free word language. The individual words are tokenized using BERT models and the dependency relations are recognized using Machine Learning Algorithms. Oversampling algorithms such as SMOTE (Chawla et al., 2002) and ADASYN (He et al., 2008) are used to tackle data imbalance and consequently improve parsing results. The results obtained are used in the malt parser and this can be accustomed to further highlight that feature-based approaches can be used for such tasks.</abstract>
      <url hash="bfaf020b">2022.dravidianlangtech-1.1</url>
      <bibkey>kumar-etal-2022-bert</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.1</doi>
      <video href="2022.dravidianlangtech-1.1.mp4"/>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="2">
      <title>A Dataset for Detecting Humor in <fixed-case>T</fixed-case>elugu Social Media Text</title>
      <author><first>Sriphani</first><last>Bellamkonda</last></author>
      <author><first>Maithili</first><last>Lohakare</last></author>
      <author><first>Shaswat</first><last>Patel</last></author>
      <pages>9-14</pages>
      <abstract>Increased use of online social media sites has given rise to tremendous amounts of user generated data. Social media sites have become a platform where users express and voice their opinions in a real-time environment. Social media sites such as Twitter limit the number of characters used to express a thought in a tweet, leading to increased use of creative, humorous and confusing language in order to convey the message. Due to this, automatic humor detection has become a difficult task, especially for low-resource languages such as the Dravidian languages. Humor detection has been a well studied area for resource rich languages due to the availability of rich and accurate data. In this paper, we have attempted to solve this issue by working on low-resource languages, such as, Telugu, a Dravidian language, by collecting and annotating Telugu tweets and performing automatic humor detection on the collected data. We experimented on the corpus using various transformer models such as Multilingual BERT, Multilingual DistillBERT and XLM-RoBERTa to establish a baseline classification system. We concluded that XLM-RoBERTa was the best-performing model and it achieved an F1-score of 0.82 with 81.5% accuracy.</abstract>
      <url hash="23db0d91">2022.dravidianlangtech-1.2</url>
      <bibkey>bellamkonda-etal-2022-dataset</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.2</doi>
      <video href="2022.dravidianlangtech-1.2.mp4"/>
      <pwccode url="https://github.com/shaswa123/telugu_humour_dataset" additional="false">shaswa123/telugu_humour_dataset</pwccode>
    </paper>
    <paper id="3">
      <title><fixed-case>M</fixed-case>u<fixed-case>C</fixed-case>o<fixed-case>T</fixed-case>: Multilingual Contrastive Training for Question-Answering in Low-resource Languages</title>
      <author><first>Gokul Karthik</first><last>Kumar</last></author>
      <author><first>Abhishek</first><last>Gehlot</last></author>
      <author><first>Sahal Shaji</first><last>Mullappilly</last></author>
      <author><first>Karthik</first><last>Nandakumar</last></author>
      <pages>15-24</pages>
      <abstract>Accuracy of English-language Question Answering (QA) systems has improved significantly in recent years with the advent of Transformer-based models (e.g., BERT). These models are pre-trained in a self-supervised fashion with a large English text corpus and further fine-tuned with a massive English QA dataset (e.g., SQuAD). However, QA datasets on such a scale are not available for most of the other languages. Multi-lingual BERT-based models (mBERT) are often used to transfer knowledge from high-resource languages to low-resource languages. Since these models are pre-trained with huge text corpora containing multiple languages, they typically learn language-agnostic embeddings for tokens from different languages. However, directly training an mBERT-based QA system for low-resource languages is challenging due to the paucity of training data. In this work, we augment the QA samples of the target language using translation and transliteration into other languages and use the augmented data to fine-tune an mBERT-based QA model, which is already pre-trained in English. Experiments on the Google ChAII dataset show that fine-tuning the mBERT model with translations from the same language family boosts the question-answering performance, whereas the performance degrades in the case of cross-language families. We further show that introducing a contrastive loss between the translated question-context feature pairs during the fine-tuning process, prevents such degradation with cross-lingual family translations and leads to marginal improvement. The code for this work is available at <url>https://github.com/gokulkarthik/mucot</url>.</abstract>
      <url hash="5b9b1675">2022.dravidianlangtech-1.3</url>
      <bibkey>kumar-etal-2022-mucot</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.3</doi>
      <video href="2022.dravidianlangtech-1.3.mp4"/>
      <pwccode url="https://github.com/gokulkarthik/mucot" additional="false">gokulkarthik/mucot</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/chaii-hindi-and-tamil-question-answering">ChAII - Hindi and Tamil Question Answering</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
    <paper id="4">
      <title><fixed-case>T</fixed-case>amil<fixed-case>ATIS</fixed-case>: Dataset for Task-Oriented Dialog in <fixed-case>T</fixed-case>amil</title>
      <author><first>Ramaneswaran</first><last>S</last></author>
      <author><first>Sanchit</first><last>Vijay</last></author>
      <author><first>Kathiravan</first><last>Srinivasan</last></author>
      <pages>25-32</pages>
      <abstract>Task-Oriented Dialogue (TOD) systems allow users to accomplish tasks by giving directions to the system using natural language utterances. With the widespread adoption of conversational agents and chat platforms, TOD has become mainstream in NLP research today. However, developing TOD systems require massive amounts of data, and there has been limited work done for TOD in low-resource languages like Tamil. Towards this objective, we introduce TamilATIS - a TOD dataset for Tamil which contains 4874 utterances. We present a detailed account of the entire data collection and data annotation process. We train state-of-the-art NLU models and report their performances. The joint BERT model with XLM-Roberta as utterance encoder achieved the highest score with an intent accuracy of 96.26% and slot F1 of 94.01%.</abstract>
      <url hash="d6f840c3">2022.dravidianlangtech-1.4</url>
      <bibkey>s-etal-2022-tamilatis</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.4</doi>
      <pwcdataset url="https://paperswithcode.com/dataset/atis">ATIS</pwcdataset>
    </paper>
    <paper id="5">
      <title><fixed-case>DE</fixed-case>-<fixed-case>ABUSE</fixed-case>@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case> 2022: Transliteration as Data Augmentation for Abuse Detection in <fixed-case>T</fixed-case>amil</title>
      <author><first>Vasanth</first><last>Palanikumar</last></author>
      <author><first>Sean</first><last>Benhur</last></author>
      <author><first>Adeep</first><last>Hande</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <pages>33-38</pages>
      <abstract>With the rise of social media and internet, thereis a necessity to provide an inclusive space andprevent the abusive topics against any gender,race or community. This paper describes thesystem submitted to the ACL-2022 shared taskon fine-grained abuse detection in Tamil. In ourapproach we transliterated code-mixed datasetas an augmentation technique to increase thesize of the data. Using this method we wereable to rank 3rd on the task with a 0.290 macroaverage F1 score and a 0.590 weighted F1score</abstract>
      <url hash="db791b78">2022.dravidianlangtech-1.5</url>
      <bibkey>palanikumar-etal-2022-de</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.5</doi>
      <video href="2022.dravidianlangtech-1.5.mp4"/>
    </paper>
    <paper id="6">
      <title><fixed-case>UMUT</fixed-case>eam@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022: Emotional Analysis in <fixed-case>T</fixed-case>amil</title>
      <author><first>José</first><last>García-Díaz</last></author>
      <author><first>Miguel Ángel</first><last>Rodríguez García</last></author>
      <author><first>Rafael</first><last>Valencia-García</last></author>
      <pages>39-44</pages>
      <abstract>This working notes summarises the participation of the UMUTeam on the TamilNLP (ACL 2022) shared task concerning emotion analysis in Tamil. We participated in the two multi-classification challenges proposed with a neural network that combines linguistic features with different feature sets based on contextual and non-contextual sentence embeddings. Our proposal achieved the 1st result for the second subtask, with an f1-score of 15.1% discerning among 30 different emotions. However, our results for the first subtask were not recorded in the official leader board. Accordingly, we report our results for this subtask with the validation split, reaching a macro f1-score of 32.360%.</abstract>
      <url hash="7fed5723">2022.dravidianlangtech-1.6</url>
      <bibkey>garcia-diaz-etal-2022-umuteam</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.6</doi>
      <video href="2022.dravidianlangtech-1.6.mp4"/>
    </paper>
    <paper id="7">
      <title><fixed-case>UMUT</fixed-case>eam@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022: Abusive Detection in <fixed-case>T</fixed-case>amil using Linguistic Features and Transformers</title>
      <author><first>José</first><last>García-Díaz</last></author>
      <author><first>Manuel</first><last>Valencia-Garcia</last></author>
      <author><first>Rafael</first><last>Valencia-García</last></author>
      <pages>45-50</pages>
      <abstract>Social media has become a dangerous place as bullies take advantage of the anonymity the Internet provides to target and intimidate vulnerable individuals and groups. In the past few years, the research community has focused on developing automatic classification tools for detecting hate-speech, its variants, and other types of abusive behaviour. However, these methods are still at an early stage in low-resource languages. With the aim of reducing this barrier, the TamilNLP shared task has proposed a multi-classification challenge for Tamil written in Tamil script and code-mixed to detect abusive comments and hope-speech. Our participation consists of a knowledge integration strategy that combines sentence embeddings from BERT, RoBERTa, FastText and a subset of language-independent linguistic features. We achieved our best result in code-mixed, reaching 3rd position with a macro-average f1-score of 35%.</abstract>
      <url hash="e9a35d75">2022.dravidianlangtech-1.7</url>
      <bibkey>garcia-diaz-etal-2022-umuteam-tamilnlp</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.7</doi>
      <video href="2022.dravidianlangtech-1.7.mp4"/>
    </paper>
    <paper id="8">
      <title>hate-alert@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>ACL</fixed-case>2022: Ensembling Multi-Modalities for <fixed-case>T</fixed-case>amil <fixed-case>T</fixed-case>roll<fixed-case>M</fixed-case>eme Classification</title>
      <author><first>Mithun</first><last>Das</last></author>
      <author><first>Somnath</first><last>Banerjee</last></author>
      <author><first>Animesh</first><last>Mukherjee</last></author>
      <pages>51-57</pages>
      <abstract>Social media platforms often act as breeding grounds for various forms of trolling or malicious content targeting users or communities. One way of trolling users is by creating memes, which in most cases unites an image with a short piece of text embedded on top of it. The situation is more complex for multilingual(e.g., Tamil) memes due to the lack of benchmark datasets and models. We explore several models to detect Troll memes in Tamil based on the shared task, “Troll Meme Classification in DravidianLangTech2022” at ACL-2022. We observe while the text-based model MURIL performs better for Non-troll meme classification, the image-based model VGG16 performs better for Troll-meme classification. Further fusing these two modalities help us achieve stable outcomes in both classes. Our fusion model achieved a 0.561 weighted average F1 score and ranked second in this task.</abstract>
      <url hash="0fd4067e">2022.dravidianlangtech-1.8</url>
      <bibkey>das-etal-2022-hate</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.8</doi>
      <video href="2022.dravidianlangtech-1.8.mp4"/>
    </paper>
    <paper id="9">
      <title><fixed-case>J</fixed-case>udith<fixed-case>J</fixed-case>eyafreeda<fixed-case>A</fixed-case>ndrew@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022:<fixed-case>CNN</fixed-case> for Emotion Analysis in <fixed-case>T</fixed-case>amil</title>
      <author><first>Judith Jeyafreeda</first><last>Andrew</last></author>
      <pages>58-63</pages>
      <abstract>Using technology for analysis of human emotion is a relatively nascent research area. There are several types of data where emotion recognition can be employed, such as - text, images, audio and video. In this paper, the focus is on emotion recognition in text data. Emotion recognition in text can be performed from both written comments and from conversations. In this paper, the dataset used for emotion recognition is a list of comments. While extensive research is being performed in this area, the language of the text plays a very important role. In this work, the focus is on the Dravidian language of Tamil. The language and its script demands an extensive pre-processing. The paper contributes to this by adapting various pre-processing methods to the Dravidian Language of Tamil. A CNN method has been adopted for the task at hand. The proposed method has achieved a comparable result.</abstract>
      <url hash="f9ff50ad">2022.dravidianlangtech-1.9</url>
      <bibkey>andrew-2022-judithjeyafreedaandrew</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.9</doi>
      <video href="2022.dravidianlangtech-1.9.mp4"/>
    </paper>
    <paper id="10">
      <title><fixed-case>MUCIC</fixed-case>@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022: Abusive Comment Detection in <fixed-case>T</fixed-case>amil Language using 1<fixed-case>D</fixed-case> Conv-<fixed-case>LSTM</fixed-case></title>
      <author><first>Fazlourrahman</first><last>Balouchzahi</last></author>
      <author><first>Anusha</first><last>Gowda</last></author>
      <author><first>Hosahalli</first><last>Shashirekha</last></author>
      <author><first>Grigori</first><last>Sidorov</last></author>
      <pages>64-69</pages>
      <abstract>Abusive language content such as hate speech, profanity, and cyberbullying etc., which is common in online platforms is creating lot of problems to the users as well as policy makers. Hence, detection of such abusive language in user-generated online content has become increasingly important over the past few years. Online platforms strive hard to moderate the abusive content to reduce societal harm, comply with laws, and create a more inclusive environment for their users. In spite of various methods to automatically detect abusive languages in online platforms, the problem still persists. To address the automatic detection of abusive languages in online platforms, this paper describes the models submitted by our team - MUCIC to the shared task on “Abusive Comment Detection in Tamil-ACL 2022”. This shared task addresses the abusive comment detection in native Tamil script texts and code-mixed Tamil texts. To address this challenge, two models: i) n-gram-Multilayer Perceptron (n-gram-MLP) model utilizing MLP classifier fed with char-n gram features and ii) 1D Convolutional Long Short-Term Memory (1D Conv-LSTM) model, were submitted. The n-gram-MLP model fared well among these two models with weighted F1-scores of 0.560 and 0.430 for code-mixed Tamil and native Tamil script texts, respectively. This work may be reproduced using the code available in <url>https://github.com/anushamdgowda/abusive-detection</url>.</abstract>
      <url hash="73f7b689">2022.dravidianlangtech-1.10</url>
      <bibkey>balouchzahi-etal-2022-mucic</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.10</doi>
      <pwccode url="https://github.com/anushamdgowda/abusive-detection" additional="false">anushamdgowda/abusive-detection</pwccode>
    </paper>
    <paper id="11">
      <title><fixed-case>CEN</fixed-case>-<fixed-case>T</fixed-case>amil@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>ACL</fixed-case>2022: Abusive Comment detection in <fixed-case>T</fixed-case>amil using <fixed-case>TF</fixed-case>-<fixed-case>IDF</fixed-case> and Random Kitchen Sink Algorithm</title>
      <author><first>Prasanth</first><last>S N</last></author>
      <author><first>R</first><last>Aswin Raj</last></author>
      <author><first>Adhithan</first><last>P</last></author>
      <author><first>Premjith</first><last>B</last></author>
      <author><first>Soman</first><last>Kp</last></author>
      <pages>70-74</pages>
      <abstract>This paper describes the approach of team CEN-Tamil used for abusive comment detection in Tamil. This task aims to identify whether a given comment contains abusive comments. We used TF-IDF with char-wb analyzers with Random Kitchen Sink (RKS) algorithm to create feature vectors and the Support Vector Machine (SVM) classifier with polynomial kernel for classification. We used this method for both Tamil and Tamil-English datasets and secured first place with an f1-score of 0.32 and seventh place with an f1-score of 0.25, respectively. The code for our approach is shared in the GitHub repository.</abstract>
      <url hash="693d1759">2022.dravidianlangtech-1.11</url>
      <bibkey>s-n-etal-2022-cen</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.11</doi>
      <video href="2022.dravidianlangtech-1.11.mp4"/>
    </paper>
    <paper id="12">
      <title><fixed-case>NITK</fixed-case>-<fixed-case>IT</fixed-case>_<fixed-case>NLP</fixed-case>@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022: Transformer based model for Toxic Span Identification in <fixed-case>T</fixed-case>amil</title>
      <author><first>Hariharan</first><last>LekshmiAmmal</last></author>
      <author><first>Manikandan</first><last>Ravikiran</last></author>
      <author><first>Anand Kumar</first><last>Madasamy</last></author>
      <pages>75-78</pages>
      <abstract>Toxic span identification in Tamil is a shared task that focuses on identifying harmful content, contributing to offensiveness. In this work, we have built a model that can efficiently identify the span of text contributing to offensive content. We have used various transformer-based models to develop the system, out of which the fine-tuned MuRIL model was able to achieve the best overall character F1-score of 0.4489.</abstract>
      <url hash="9855dad8">2022.dravidianlangtech-1.12</url>
      <bibkey>lekshmiammal-etal-2022-nitk</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.12</doi>
      <video href="2022.dravidianlangtech-1.12.mp4"/>
    </paper>
    <paper id="13">
      <title><fixed-case>T</fixed-case>eam<fixed-case>X</fixed-case>@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>ACL</fixed-case>2022: A Comparative Analysis for Troll-Based Meme Classification</title>
      <author><first>Rabindra Nath</first><last>Nandi</last></author>
      <author><first>Firoj</first><last>Alam</last></author>
      <author><first>Preslav</first><last>Nakov</last></author>
      <pages>79-85</pages>
      <abstract>The spread of fake news, propaganda, misinformation, disinformation, and harmful content online raised concerns among social mediaplatforms, government agencies, policymakers, and society as a whole. This is because such harmful or abusive content leads to several consequences to people such as physical, emotional, relational, and financial. Among different harmful content trolling-based online content is one of them, where the idea is to post a message that is provocative, offensive, or menacing with an intent to mislead the audience. The content can be textual, visual, a combination of both, or a meme. In this study, we provide a comparative analysis of troll-based memes classification using the textual, visual, and multimodal content. We report several interesting findings in terms of code-mixed text, multimodal setting, and combining an additional dataset, which shows improvements over the majority baseline.</abstract>
      <url hash="141f0715">2022.dravidianlangtech-1.13</url>
      <bibkey>nandi-etal-2022-teamx</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.13</doi>
      <video href="2022.dravidianlangtech-1.13.mp4"/>
      <pwcdataset url="https://paperswithcode.com/dataset/hateful-memes">Hateful Memes</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/hateful-memes-challenge">Hateful Memes Challenge</pwcdataset>
    </paper>
    <paper id="14">
      <title><fixed-case>GJG</fixed-case>@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022: Emotion Analysis and Classification in <fixed-case>T</fixed-case>amil using Transformers</title>
      <author><first>Janvi</first><last>Prasad</last></author>
      <author><first>Gaurang</first><last>Prasad</last></author>
      <author><first>Gunavathi</first><last>C</last></author>
      <pages>86-92</pages>
      <abstract>This paper describes the systems built by our team for the “Emotion Analysis in Tamil” shared task at the Second Workshop on Speech and Language Technologies for Dravidian Languages at ACL 2022. There were two multi-class classification sub-tasks as a part of this shared task. The dataset for sub-task A contained 11 types of emotions while sub-task B was more fine-grained with 31 emotions. We fine-tuned an XLM-RoBERTa and DeBERTA base model for each sub-task. For sub-task A, the XLM-RoBERTa model achieved an accuracy of 0.46 and the DeBERTa model achieved an accuracy of 0.45. We had the best classification performance out of 11 teams for sub-task A. For sub-task B, the XLM-RoBERTa model’s accuracy was 0.33 and the DeBERTa model had an accuracy of 0.26. We ranked 2nd out of 7 teams for sub-task B.</abstract>
      <url hash="67785674">2022.dravidianlangtech-1.14</url>
      <bibkey>prasad-etal-2022-gjg</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.14</doi>
      <video href="2022.dravidianlangtech-1.14.mp4"/>
    </paper>
    <paper id="15">
      <title><fixed-case>GJG</fixed-case>@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022: Using Transformers for Abusive Comment Classification in <fixed-case>T</fixed-case>amil</title>
      <author><first>Gaurang</first><last>Prasad</last></author>
      <author><first>Janvi</first><last>Prasad</last></author>
      <author><first>Gunavathi</first><last>C</last></author>
      <pages>93-99</pages>
      <abstract>This paper presents transformer-based models for the “Abusive Comment Detection” shared task at the Second Workshop on Speech and Language Technologies for Dravidian Languages at ACL 2022. Our team participated in both the multi-class classification sub-tasks as a part of this shared task. The dataset for sub-task A was in Tamil text; while B was code-mixed Tamil-English text. Both the datasets contained 8 classes of abusive comments. We trained an XLM-RoBERTa and DeBERTA base model on the training splits for each sub-task. For sub-task A, the XLM-RoBERTa model achieved an accuracy of 0.66 and the DeBERTa model achieved an accuracy of 0.62. For sub-task B, both the models achieved a classification accuracy of 0.72; however, the DeBERTa model performed better in other classification metrics. Our team ranked 2nd in the code-mixed classification sub-task and 8th in Tamil-text sub-task.</abstract>
      <url hash="bbcf8d95">2022.dravidianlangtech-1.15</url>
      <bibkey>prasad-etal-2022-gjg-tamilnlp</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.15</doi>
      <video href="2022.dravidianlangtech-1.15.mp4"/>
    </paper>
    <paper id="16">
      <title><fixed-case>IIITDWD</fixed-case>@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022: Transformer-based approach to classify abusive content in <fixed-case>D</fixed-case>ravidian Code-mixed text</title>
      <author><first>Shankar</first><last>Biradar</last></author>
      <author><first>Sunil</first><last>Saumya</last></author>
      <pages>100-104</pages>
      <abstract>Identifying abusive content or hate speech in social media text has raised the research community’s interest in recent times. The major driving force behind this is the widespread use of social media websites. Further, it also leads to identifying abusive content in low-resource regional languages, which is an important research problem in computational linguistics. As part of ACL-2022, organizers of DravidianLangTech@ACL 2022 have released a shared task on abusive category identification in Tamil and Tamil-English code-mixed text to encourage further research on offensive content identification in low-resource Indic languages. This paper presents the working notes for the model submitted by IIITDWD at DravidianLangTech@ACL 2022. Our team competed in Sub-Task B and finished in 9th place among the participating teams. In our proposed approach, we used a pre-trained transformer model such as Indic-bert for feature extraction, and on top of that, SVM classifier is used for stance detection. Further, our model achieved 62 % accuracy on code-mixed Tamil-English text.</abstract>
      <url hash="0d05868b">2022.dravidianlangtech-1.16</url>
      <bibkey>biradar-saumya-2022-iiitdwd</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.16</doi>
      <video href="2022.dravidianlangtech-1.16.mp4"/>
    </paper>
    <paper id="17">
      <title><fixed-case>PANDAS</fixed-case>@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022: Emotion Analysis in <fixed-case>T</fixed-case>amil Text using Language Agnostic Embeddings</title>
      <author><first>Divyasri</first><last>K</last></author>
      <author><first>Gayathri</first><last>G L</last></author>
      <author><first>Krithika</first><last>Swaminathan</last></author>
      <author><first>Thenmozhi</first><last>Durairaj</last></author>
      <author><first>Bharathi</first><last>B</last></author>
      <author><first>Senthil Kumar</first><last>B</last></author>
      <pages>105-111</pages>
      <abstract>As the world around us continues to become increasingly digital, it has been acknowledged that there is a growing need for emotion analysis of social media content. The task of identifying the emotion in a given text has many practical applications ranging from screening public health to business and management. In this paper, we propose a language-agnostic model that focuses on emotion analysis in Tamil text. Our experiments yielded an F1-score of 0.010.</abstract>
      <url hash="a06198bc">2022.dravidianlangtech-1.17</url>
      <bibkey>k-etal-2022-pandas</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.17</doi>
      <video href="2022.dravidianlangtech-1.17.mp4"/>
    </paper>
    <paper id="18">
      <title><fixed-case>PANDAS</fixed-case>@Abusive Comment Detection in <fixed-case>T</fixed-case>amil Code-Mixed Data Using Custom Embeddings with <fixed-case>L</fixed-case>a<fixed-case>BSE</fixed-case></title>
      <author><first>Gayathri</first><last>G L</last></author>
      <author><first>Krithika</first><last>Swaminathan</last></author>
      <author><first>Divyasri</first><last>K</last></author>
      <author><first>Thenmozhi</first><last>Durairaj</last></author>
      <author><first>Bharathi</first><last>B</last></author>
      <pages>112-119</pages>
      <abstract>Abusive language has lately been prevalent in comments on various social media platforms. The increasing hostility observed on the internet calls for the creation of a system that can identify and flag such acerbic content, to prevent conflict and mental distress. This task becomes more challenging when low-resource languages like Tamil, as well as the often-observed Tamil-English code-mixed text, are involved. The approach used in this paper for the classification model includes different methods of feature extraction and the use of traditional classifiers. We propose a novel method of combining language-agnostic sentence embeddings with the TF-IDF vector representation that uses a curated corpus of words as vocabulary, to create a custom embedding, which is then passed to an SVM classifier. Our experimentation yielded an accuracy of 52% and an F1-score of 0.54.</abstract>
      <url hash="c5e342d7">2022.dravidianlangtech-1.18</url>
      <bibkey>swaminathan-etal-2022-pandas</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.18</doi>
      <video href="2022.dravidianlangtech-1.18.mp4"/>
    </paper>
    <paper id="19">
      <title>Translation Techies @<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>ACL</fixed-case>2022-Machine Translation in <fixed-case>D</fixed-case>ravidian Languages</title>
      <author><first>Piyushi</first><last>Goyal</last></author>
      <author><first>Musica</first><last>Supriya</last></author>
      <author><first>Dinesh</first><last>U</last></author>
      <author><first>Ashalatha</first><last>Nayak</last></author>
      <pages>120-124</pages>
      <abstract>This paper discusses the details of submission made by team Translation Techies to the Shared Task on Machine Translation in Dravidian languages- ACL 2022. In connection to the task, five language pairs were provided to test the accuracy of submitted model. A baseline transformer model with Neural Machine Translation(NMT) technique is used which has been taken directly from the OpenNMT framework. On this baseline model, tokenization is applied using the IndicNLP library. Finally, the evaluation is performed using the BLEU scoring mechanism.</abstract>
      <url hash="5840c154">2022.dravidianlangtech-1.19</url>
      <bibkey>goyal-etal-2022-translation</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.19</doi>
      <video href="2022.dravidianlangtech-1.19.mp4"/>
    </paper>
    <paper id="20">
      <title><fixed-case>SSNCSE</fixed-case>_<fixed-case>NLP</fixed-case>@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022: Transformer based approach for Emotion analysis in <fixed-case>T</fixed-case>amil language</title>
      <author><first>Bharathi</first><last>B</last></author>
      <author><first>Josephine</first><last>Varsha</last></author>
      <pages>125-131</pages>
      <abstract>Emotion analysis is the process of identifying and analyzing the underlying emotions expressed in textual data. Identifying emotions from a textual conversation is a challenging task due to the absence of gestures, vocal intonation, and facial expressions. Once the chatbots and messengers detect and report the emotions of the user, a comfortable conversation can be carried out with no misunderstandings. Our task is to categorize text into a predefined notion of emotion. In this thesis, it is required to classify text into several emotional labels depending on the task. We have adopted the transformer model approach to identify the emotions present in the text sequence. Our task is to identify whether a given comment contains emotion, and the emotion it stands for. The datasets were provided to us by the LT-EDI organizers (CITATION) for two tasks, in the Tamil language. We have evaluated the datasets using the pretrained transformer models and we have obtained the micro-averaged F1 scores as 0.19 and 0.12 for Task1 and Task 2 respectively.</abstract>
      <url hash="4c2d8857">2022.dravidianlangtech-1.20</url>
      <bibkey>b-varsha-2022-ssncse</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.20</doi>
      <video href="2022.dravidianlangtech-1.20.mp4"/>
    </paper>
    <paper id="21">
      <title><fixed-case>SSN</fixed-case>_<fixed-case>MLRG</fixed-case>1@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>ACL</fixed-case>2022: Troll Meme Classification in <fixed-case>T</fixed-case>amil using Transformer Models</title>
      <author><first>Shruthi</first><last>Hariprasad</last></author>
      <author><first>Sarika</first><last>Esackimuthu</last></author>
      <author><first>Saritha</first><last>Madhavan</last></author>
      <author><first>Rajalakshmi</first><last>Sivanaiah</last></author>
      <author><first>Angel</first><last>S</last></author>
      <pages>132-137</pages>
      <abstract>The ACL shared task of DravidianLangTech-2022 for Troll Meme classification is a binary classification task that involves identifying Tamil memes as troll or not-troll. Classification of memes is a challenging task since memes express humour and sarcasm in an implicit way. Team SSN_MLRG1 tested and compared results obtained by using three models namely BERT, ALBERT and XLNET. The XLNet model outperformed the other two models in terms of various performance metrics. The proposed XLNet model obtained the 3rd rank in the shared task with a weighted F1-score of 0.558.</abstract>
      <url hash="06d628a1">2022.dravidianlangtech-1.21</url>
      <bibkey>hariprasad-etal-2022-ssn</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.21</doi>
    </paper>
    <paper id="22">
      <title><fixed-case>B</fixed-case>p<fixed-case>H</fixed-case>igh@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022: Effects of Data Augmentation on Indic-Transformer based classifier for Abusive Comments Detection in <fixed-case>T</fixed-case>amil</title>
      <author><first>Bhavish</first><last>Pahwa</last></author>
      <pages>138-144</pages>
      <abstract>Social Media platforms have grown their reach worldwide. As an effect of this growth, many vernacular social media platforms have also emerged, focusing more on the diverse languages in the specific regions. Tamil has also emerged as a popular language for use on social media platforms due to the increasing penetration of vernacular media like Sharechat and Moj, which focus more on local Indian languages than English and encourage their users to converse in Indic languages. Abusive language remains a significant challenge in the social media framework and more so when we consider languages like Tamil, which are low-resource languages and have poor performance on multilingual models and lack language-specific models. Based on this shared task, “Abusive Comment detection in Tamil@DravidianLangTech-ACL 2022”, we present an exploration of different techniques used to tackle and increase the accuracy of our models using data augmentation in NLP. We also show the results of these techniques.</abstract>
      <url hash="c09537c8">2022.dravidianlangtech-1.22</url>
      <bibkey>pahwa-2022-bphigh</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.22</doi>
      <video href="2022.dravidianlangtech-1.22.mp4"/>
    </paper>
    <paper id="23">
      <title><fixed-case>MUCS</fixed-case>@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech@<fixed-case>ACL</fixed-case>2022: Ensemble of Logistic Regression Penalties to Identify Emotions in <fixed-case>T</fixed-case>amil Text</title>
      <author><first>Asha</first><last>Hegde</last></author>
      <author><first>Sharal</first><last>Coelho</last></author>
      <author><first>Hosahalli</first><last>Shashirekha</last></author>
      <pages>145-150</pages>
      <abstract>Emotion Analysis (EA) is the process of automatically analyzing and categorizing the input text into one of the predefined sets of emotions. In recent years, people have turned to social media to express their emotions, opinions or feelings about news, movies, products, services, and so on. These users’ emotions may help the public, governments, business organizations, film producers, and others in devising strategies, making decisions, and so on. The increasing number of social media users and the increasing amount of user generated text containing emotions on social media demands automated tools for the analysis of such data as handling this data manually is labor intensive and error prone. Further, the characteristics of social media data makes the EA challenging. Most of the EA research works have focused on English language leaving several Indian languages including Tamil unexplored for this task. To address the challenges of EA in Tamil texts, in this paper, we - team MUCS, describe the model submitted to the shared task on Emotion Analysis in Tamil at DravidianLangTech@ACL 2022. Out of the two subtasks in this shared task, our team submitted the model only for Task a. The proposed model comprises of an Ensemble of Logistic Regression (LR) classifiers with three penalties, namely: L1, L2, and Elasticnet. This Ensemble model trained with Term Frequency - Inverse Document Frequency (TF-IDF) of character bigrams and trigrams secured 4th rank in Task a with a macro averaged F1-score of 0.04. The code to reproduce the proposed models is available in github1.</abstract>
      <url hash="ac3b5cd3">2022.dravidianlangtech-1.23</url>
      <bibkey>hegde-etal-2022-mucs</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.23</doi>
      <video href="2022.dravidianlangtech-1.23.mp4"/>
    </paper>
    <paper id="24">
      <title><fixed-case>BPHC</fixed-case>@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>ACL</fixed-case>2022-A comparative analysis of classical and pre-trained models for troll meme classification in <fixed-case>T</fixed-case>amil</title>
      <author><first>Achyuta</first><last>V</last></author>
      <author><first>Mithun Kumar</first><last>S R</last></author>
      <author><first>Aruna</first><last>Malapati</last></author>
      <author><first>Lov</first><last>Kumar</last></author>
      <pages>151-157</pages>
      <abstract>Trolling refers to any user behaviour on the internet to intentionally provoke or instigate conflict predominantly in social media. This paper aims to classify troll meme captions in Tamil-English code-mixed form. Embeddings are obtained for raw code-mixed text and the translated and transliterated version of the text and their relative performances are compared. Furthermore, this paper compares the performances of 11 different classification algorithms using Accuracy and F1- Score. We conclude that we were able to achieve a weighted F1 score of 0.74 through MuRIL pretrained model.</abstract>
      <url hash="df670fc7">2022.dravidianlangtech-1.24</url>
      <bibkey>v-etal-2022-bphc</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.24</doi>
      <video href="2022.dravidianlangtech-1.24.mp4"/>
    </paper>
    <paper id="25">
      <title><fixed-case>SSNCSE</fixed-case> <fixed-case>NLP</fixed-case>@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022: Transformer based approach for detection of abusive comment for <fixed-case>T</fixed-case>amil language</title>
      <author><first>Bharathi</first><last>B</last></author>
      <author><first>Josephine</first><last>Varsha</last></author>
      <pages>158-164</pages>
      <abstract>Social media platforms along with many other public forums on the Internet have shown a significant rise in the cases of abusive behavior such as Misogynism, Misandry, Homophobia, and Cyberbullying. To tackle these concerns, technologies are being developed and applied, as it is a tedious and time-consuming task to identify, report and block these offenders. Our task was to automate the process of identifying abusive comments and classify them into appropriate categories. The datasets provided by the DravidianLangTech@ACL2022 organizers were a code-mixed form of Tamil text. We trained the datasets using pre-trained transformer models such as BERT,m-BERT, and XLNET and achieved a weighted average of F1 scores of 0.96 for Tamil-English code mixed text and 0.59 for Tamil text.</abstract>
      <url hash="81547dcb">2022.dravidianlangtech-1.25</url>
      <bibkey>b-varsha-2022-ssncse-nlp</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.25</doi>
      <video href="2022.dravidianlangtech-1.25.mp4"/>
    </paper>
    <paper id="26">
      <title><fixed-case>V</fixed-case>arsini_and_<fixed-case>K</fixed-case>irthanna@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>ACL</fixed-case>2022-Emotional Analysis in <fixed-case>T</fixed-case>amil</title>
      <author><first>Varsini</first><last>S</last></author>
      <author><first>Kirthanna</first><last>Rajan</last></author>
      <author><first>Angel</first><last>S</last></author>
      <author><first>Rajalakshmi</first><last>Sivanaiah</last></author>
      <author><first>Sakaya Milton</first><last>Rajendram</last></author>
      <author><first>Mirnalinee</first><last>T T</last></author>
      <pages>165-169</pages>
      <abstract>In this paper, we present our system for the task of Emotion analysis in Tamil. Over 3.96 million people use these platforms to send messages formed using texts, images, videos, audio or combinations of these to express their thoughts and feelings. Text communication on social media platforms is quite overwhelming due to its enormous quantity and simplicity. The data must be processed to understand the general feeling felt by the author. We present a lexicon-based approach for the extraction emotion in Tamil texts. We use dictionaries of words labelled with their respective emotions. The process of assigning an emotional label to each text, and then capture the main emotion expressed in it. Finally, the F1-score in the official test set is 0.0300 and our method ranks 5th.</abstract>
      <url hash="40bd322b">2022.dravidianlangtech-1.26</url>
      <bibkey>s-etal-2022-varsini</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.26</doi>
    </paper>
    <paper id="27">
      <title><fixed-case>CUET</fixed-case>-<fixed-case>NLP</fixed-case>@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>ACL</fixed-case>2022: Investigating Deep Learning Techniques to Detect Multimodal Troll Memes</title>
      <author><first>Md</first><last>Hasan</last></author>
      <author><first>Nusratul</first><last>Jannat</last></author>
      <author><first>Eftekhar</first><last>Hossain</last></author>
      <author><first>Omar</first><last>Sharif</last></author>
      <author><first>Mohammed Moshiul</first><last>Hoque</last></author>
      <pages>170-176</pages>
      <abstract>With the substantial rise of internet usage, social media has become a powerful communication medium to convey information, opinions, and feelings on various issues. Recently, memes have become a popular way of sharing information on social media. Usually, memes are visuals with text incorporated into them and quickly disseminate hatred and offensive content. Detecting or classifying memes is challenging due to their region-specific interpretation and multimodal nature. This work presents a meme classification technique in Tamil developed by the CUET NLP team under the shared task (DravidianLangTech-ACL2022). Several computational models have been investigated to perform the classification task. This work also explored visual and textual features using VGG16, ResNet50, VGG19, CNN and CNN+LSTM models. Multimodal features are extracted by combining image (VGG16) and text (CNN, LSTM+CNN) characteristics. Results demonstrate that the textual strategy with CNN+LSTM achieved the highest weighted <tex-math>f_1</tex-math>-score (0.52) and recall (0.57). Moreover, the CNN-Text+VGG16 outperformed the other models concerning the multimodal memes detection by achieving the highest <tex-math>f_1</tex-math>-score of 0.49, but the LSTM+CNN model allowed the team to achieve <tex-math>4^{th}</tex-math> place in the shared task.</abstract>
      <url hash="406c975e">2022.dravidianlangtech-1.27</url>
      <bibkey>hasan-etal-2022-cuet</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.27</doi>
      <video href="2022.dravidianlangtech-1.27.mp4"/>
    </paper>
    <paper id="28">
      <title><fixed-case>PICT</fixed-case>@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>ACL</fixed-case>2022: Neural Machine Translation On <fixed-case>D</fixed-case>ravidian Languages</title>
      <author><first>Aditya</first><last>Vyawahare</last></author>
      <author><first>Rahul</first><last>Tangsali</last></author>
      <author><first>Aditya</first><last>Mandke</last></author>
      <author><first>Onkar</first><last>Litake</last></author>
      <author><first>Dipali</first><last>Kadam</last></author>
      <pages>177-183</pages>
      <abstract>This paper presents a summary of the findings that we obtained based on the shared task on machine translation of Dravidian languages. As a part of this shared task, we carried out neural machine translations for the following five language pairs: Kannada to Tamil, Kannada to Telugu, Kannada to Malayalam, Kannada to Sanskrit, and Kannada to Tulu. The datasets for each of the five language pairs were used to train various translation models, including Seq2Seq models such as LSTM, bidirectional LSTM, Conv Seq2Seq, and training state-of-the-art as transformers from scratch, and fine-tuning already pre-trained models. For some models involving monolingual corpora, we implemented backtranslation as well. These models’ accuracy was later tested with a part of the same dataset using BLEU score as an evaluation metric.</abstract>
      <url hash="9110ff71">2022.dravidianlangtech-1.28</url>
      <bibkey>vyawahare-etal-2022-pict</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.28</doi>
      <video href="2022.dravidianlangtech-1.28.mp4"/>
      <pwcdataset url="https://paperswithcode.com/dataset/indiccorp">IndicCorp</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/samanantar">Samanantar</pwcdataset>
    </paper>
    <paper id="29">
      <title>Sentiment Analysis on Code-Switched <fixed-case>D</fixed-case>ravidian Languages with Kernel Based Extreme Learning Machines</title>
      <author><first>Mithun Kumar</first><last>S R</last></author>
      <author><first>Lov</first><last>Kumar</last></author>
      <author><first>Aruna</first><last>Malapati</last></author>
      <pages>184-190</pages>
      <abstract>Code-switching refers to the textual or spoken data containing multiple languages. Application of natural language processing (NLP) tasks like sentiment analysis is a harder problem on code-switched languages due to the irregularities in the sentence structuring and ordering. This paper shows the experiment results of building a Kernel based Extreme Learning Machines(ELM) for sentiment analysis for code-switched Dravidian languages with English. Our results show that ELM performs better than traditional machine learning classifiers on various metrics as well as trains faster than deep learning models. We also show that Polynomial kernels perform better than others in the ELM architecture. We were able to achieve a median AUC of 0.79 with a polynomial kernel.</abstract>
      <url hash="d68d97c8">2022.dravidianlangtech-1.29</url>
      <bibkey>s-r-etal-2022-sentiment</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.29</doi>
    </paper>
    <paper id="30">
      <title><fixed-case>CUET</fixed-case>-<fixed-case>NLP</fixed-case>@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>ACL</fixed-case>2022: Exploiting Textual Features to Classify Sentiment of Multimodal Movie Reviews</title>
      <author><first>Nasehatul</first><last>Mustakim</last></author>
      <author><first>Nusratul</first><last>Jannat</last></author>
      <author><first>Md</first><last>Hasan</last></author>
      <author><first>Eftekhar</first><last>Hossain</last></author>
      <author><first>Omar</first><last>Sharif</last></author>
      <author><first>Mohammed Moshiul</first><last>Hoque</last></author>
      <pages>191-198</pages>
      <abstract>With the proliferation of internet usage, a massive growth of consumer-generated content on social media has been witnessed in recent years that provide people’s opinions on diverse issues. Through social media, users can convey their emotions and thoughts in distinctive forms such as text, image, audio, video, and emoji, which leads to the advancement of the multimodality of the content users on social networking sites. This paper presents a technique for classifying multimodal sentiment using the text modality into five categories: highly positive, positive, neutral, negative, and highly negative categories. A shared task was organized to develop models that can identify the sentiments expressed by the videos of movie reviewers in both Malayalam and Tamil languages. This work applied several machine learning techniques (LR, DT, MNB, SVM) and deep learning (BiLSTM, CNN+BiLSTM) to accomplish the task. Results demonstrate that the proposed model with the decision tree (DT) outperformed the other methods and won the competition by acquiring the highest macro <tex-math>f_1</tex-math>-score of 0.24.</abstract>
      <url hash="f62eef95">2022.dravidianlangtech-1.30</url>
      <bibkey>mustakim-etal-2022-cuet</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.30</doi>
      <video href="2022.dravidianlangtech-1.30.mp4"/>
    </paper>
    <paper id="31">
      <title><fixed-case>CUET</fixed-case>-<fixed-case>NLP</fixed-case>@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022: Multi-Class Textual Emotion Detection from Social Media using Transformer</title>
      <author><first>Nasehatul</first><last>Mustakim</last></author>
      <author><first>Rabeya</first><last>Rabu</last></author>
      <author><first>Golam</first><last>Md. Mursalin</last></author>
      <author><first>Eftekhar</first><last>Hossain</last></author>
      <author><first>Omar</first><last>Sharif</last></author>
      <author><first>Mohammed Moshiul</first><last>Hoque</last></author>
      <pages>199-206</pages>
      <abstract>Recently, emotion analysis has gained increased attention by NLP researchers due to its various applications in opinion mining, e-commerce, comprehensive search, healthcare, personalized recommendations and online education. Developing an intelligent emotion analysis model is challenging in resource-constrained languages like Tamil. Therefore a shared task is organized to identify the underlying emotion of a given comment expressed in the Tamil language. The paper presents our approach to classifying the textual emotion in Tamil into 11 classes: ambiguous, anger, anticipation, disgust, fear, joy, love, neutral, sadness, surprise and trust. We investigated various machine learning (LR, DT, MNB, SVM), deep learning (CNN, LSTM, BiLSTM) and transformer-based models (Multilingual-BERT, XLM-R). Results reveal that the XLM-R model outdoes all other models by acquiring the highest macro <tex-math>f_1</tex-math>-score (0.33).</abstract>
      <url hash="6b362444">2022.dravidianlangtech-1.31</url>
      <bibkey>mustakim-etal-2022-cuet-nlp</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.31</doi>
      <video href="2022.dravidianlangtech-1.31.mp4"/>
    </paper>
    <paper id="32">
      <title><fixed-case>DLRG</fixed-case>@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>ACL</fixed-case>2022: Abusive Comment Detection in <fixed-case>T</fixed-case>amil using Multilingual Transformer Models</title>
      <author><first>Ratnavel</first><last>Rajalakshmi</last></author>
      <author><first>Ankita</first><last>Duraphe</last></author>
      <author><first>Antonette</first><last>Shibani</last></author>
      <pages>207-213</pages>
      <abstract>Online Social Network has let people to connect and interact with each other. It does, however, also provide a platform for online abusers to propagate abusive content. The vast majority of abusive remarks are written in a multilingual style, which allows them to easily slip past internet inspection. This paper presents a system developed for the Shared Task on Abusive Comment Detection (Misogyny, Misandry, Homophobia, Transphobic, Xenophobia, CounterSpeech, Hope Speech) in Tamil DravidianLangTech@ACL 2022 to detect the abusive category of each comment. We approach the task with three methodologies - Machine Learning, Deep Learning and Transformer-based modeling, for two sets of data - Tamil and Tamil+English language dataset. The dataset used in our system can be accessed from the competition on CodaLab. For Machine Learning, eight algorithms were implemented, among which Random Forest gave the best result with Tamil+English dataset, with a weighted average F1-score of 0.78. For Deep Learning, Bi-Directional LSTM gave best result with pre-trained word embeddings. In Transformer-based modeling, we used IndicBERT and mBERT with fine-tuning, among which mBERT gave the best result for Tamil dataset with a weighted average F1-score of 0.7.</abstract>
      <url hash="e75c6065">2022.dravidianlangtech-1.32</url>
      <bibkey>rajalakshmi-etal-2022-dlrg</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.32</doi>
      <video href="2022.dravidianlangtech-1.32.mp4"/>
    </paper>
    <paper id="33">
      <title>Aanisha@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022:Abusive Detection in <fixed-case>T</fixed-case>amil</title>
      <author><first>Aanisha</first><last>Bhattacharyya</last></author>
      <pages>214-220</pages>
      <abstract>In social media, there are instances where people present their opinions in strong language, resorting to abusive/toxic comments. There are instances of communal hatred, hate-speech, toxicity and bullying. And, in this age of social media, it’s very important to find means to keep check on these toxic comments, as to preserve the mental peace of people in social media. While there are tools, models to detect andpotentially filter these kind of content, developing these kinds of models for the low resource language space is an issue of research. In this paper, the task of abusive comment identification in Tamil language, is seen upon as a multi-class classification problem. There are different pre-processing as well as modelling approaches discussed in this paper. The different approaches are compared on the basis of weighted average accuracy.</abstract>
      <url hash="6d849255">2022.dravidianlangtech-1.33</url>
      <bibkey>bhattacharyya-2022-aanisha</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.33</doi>
      <video href="2022.dravidianlangtech-1.33.mp4"/>
    </paper>
    <paper id="34">
      <title><fixed-case>COMBATANT</fixed-case>@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022: Fine-grained Categorization of Abusive Comments using Logistic Regression</title>
      <author><first>Alamgir</first><last>Hossain</last></author>
      <author><first>Mahathir</first><last>Bishal</last></author>
      <author><first>Eftekhar</first><last>Hossain</last></author>
      <author><first>Omar</first><last>Sharif</last></author>
      <author><first>Mohammed Moshiul</first><last>Hoque</last></author>
      <pages>221-228</pages>
      <abstract>With the widespread usage of social media and effortless internet access, millions of posts and comments are generated every minute. Unfortunately, with this substantial rise, the usage of abusive language has increased significantly in these mediums. This proliferation leads to many hazards such as cyber-bullying, vulgarity, online harassment and abuse. Therefore, it becomes a crucial issue to detect and mitigate the usage of abusive language. This work presents our system developed as part of the shared task to detect the abusive language in Tamil. We employed three machine learning (LR, DT, SVM), two deep learning (CNN+BiLSTM, CNN+BiLSTM with FastText) and a transformer-based model (Indic-BERT). The experimental results show that Logistic regression (LR) and CNN+BiLSTM models outperformed the others. Both Logistic Regression (LR) and CNN+BiLSTM with FastText achieved the weighted <tex-math>F_1</tex-math>-score of 0.39. However, LR obtained a higher recall value (0.44) than CNN+BiLSTM (0.36). This leads us to stand the <tex-math>2^{nd}</tex-math> rank in the shared task competition.</abstract>
      <url hash="b9d0f212">2022.dravidianlangtech-1.34</url>
      <bibkey>hossain-etal-2022-combatant</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.34</doi>
      <video href="2022.dravidianlangtech-1.34.mp4"/>
    </paper>
    <paper id="35">
      <title><fixed-case>O</fixed-case>ptimize_<fixed-case>P</fixed-case>rime@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>ACL</fixed-case>2022: Emotion Analysis in <fixed-case>T</fixed-case>amil</title>
      <author><first>Omkar</first><last>Gokhale</last></author>
      <author><first>Shantanu</first><last>Patankar</last></author>
      <author><first>Onkar</first><last>Litake</last></author>
      <author><first>Aditya</first><last>Mandke</last></author>
      <author><first>Dipali</first><last>Kadam</last></author>
      <pages>229-234</pages>
      <abstract>This paper aims to perform an emotion analysis of social media comments in Tamil. Emotion analysis is the process of identifying the emotional context of the text. In this paper, we present the findings obtained by Team Optimize_Prime in the ACL 2022 shared task “Emotion Analysis in Tamil.” The task aimed to classify social media comments into categories of emotion like Joy, Anger, Trust, Disgust, etc. The task was further divided into two subtasks, one with 11 broad categories of emotions and the other with 31 specific categories of emotion. We implemented three different approaches to tackle this problem: transformer-based models, Recurrent Neural Networks (RNNs), and Ensemble models. XLM-RoBERTa performed the best on the first task with a macro-averaged f1 score of 0.27, while MuRIL provided the best results on the second task with a macro-averaged f1 score of 0.13.</abstract>
      <url hash="4880a9f5">2022.dravidianlangtech-1.35</url>
      <bibkey>gokhale-etal-2022-optimize</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.35</doi>
      <video href="2022.dravidianlangtech-1.35.mp4"/>
    </paper>
    <paper id="36">
      <title><fixed-case>O</fixed-case>ptimize_<fixed-case>P</fixed-case>rime@<fixed-case>D</fixed-case>ravidian<fixed-case>L</fixed-case>ang<fixed-case>T</fixed-case>ech-<fixed-case>ACL</fixed-case>2022: Abusive Comment Detection in <fixed-case>T</fixed-case>amil</title>
      <author><first>Shantanu</first><last>Patankar</last></author>
      <author><first>Omkar</first><last>Gokhale</last></author>
      <author><first>Onkar</first><last>Litake</last></author>
      <author><first>Aditya</first><last>Mandke</last></author>
      <author><first>Dipali</first><last>Kadam</last></author>
      <pages>235-239</pages>
      <abstract>This paper tries to address the problem of abusive comment detection in low-resource indic languages. Abusive comments are statements that are offensive to a person or a group of people. These comments are targeted toward individuals belonging to specific ethnicities, genders, caste, race, sexuality, etc. Abusive Comment Detection is a significant problem, especially with the recent rise in social media users. This paper presents the approach used by our team — Optimize_Prime, in the ACL 2022 shared task “Abusive Comment Detection in Tamil.” This task detects and classifies YouTube comments in Tamil and Tamil-English Codemixed format into multiple categories. We have used three methods to optimize our results: Ensemble models, Recurrent Neural Networks, and Transformers. In the Tamil data, MuRIL and XLM-RoBERTA were our best performing models with a macro-averaged f1 score of 0.43. Furthermore, for the Code-mixed data, MuRIL and M-BERT provided sublime results, with a macro-averaged f1 score of 0.45.</abstract>
      <url hash="b7ebb9c9">2022.dravidianlangtech-1.36</url>
      <bibkey>patankar-etal-2022-optimize</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.36</doi>
      <video href="2022.dravidianlangtech-1.36.mp4"/>
    </paper>
    <paper id="37">
      <title>Zero-shot Code-Mixed Offensive Span Identification through Rationale Extraction</title>
      <author><first>Manikandan</first><last>Ravikiran</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <pages>240-247</pages>
      <abstract>This paper investigates the effectiveness of sentence-level transformers for zero-shot offensive span identification on a code-mixed Tamil dataset. More specifically, we evaluate rationale extraction methods of Local Interpretable Model Agnostic Explanations (LIME) (CITATION) and Integrated Gradients (IG) (CITATION) for adapting transformer based offensive language classification models for zero-shot offensive span identification. To this end, we find that LIME and IG show baseline <tex-math>F_{1}</tex-math> of 26.35% and 44.83%, respectively. Besides, we study the effect of data set size and training process on the overall accuracy of span identification. As a result, we find both LIME and IG to show significant improvement with Masked Data Augmentation and Multilabel Training, with <tex-math>F_{1}</tex-math> of 50.23% and 47.38% respectively. <i>Disclaimer : This paper contains examples that may be considered profane, vulgar, or offensive. The examples do not represent the views of the authors or their employers/graduate schools towards any person(s), group(s), practice(s), or entity/entities. Instead they are used to emphasize only the linguistic research challenges.</i></abstract>
      <url hash="764dda12">2022.dravidianlangtech-1.37</url>
      <bibkey>ravikiran-chakravarthi-2022-zero</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.37</doi>
      <video href="2022.dravidianlangtech-1.37.mp4"/>
      <pwccode url="https://github.com/manikandan-ravikiran/zero-shot-offensive-span" additional="false">manikandan-ravikiran/zero-shot-offensive-span</pwccode>
    </paper>
    <paper id="38">
      <title><fixed-case>DLRG</fixed-case>@<fixed-case>T</fixed-case>amil<fixed-case>NLP</fixed-case>-<fixed-case>ACL</fixed-case>2022: Offensive Span Identification in <fixed-case>T</fixed-case>amil using<fixed-case>B</fixed-case>i<fixed-case>LSTM</fixed-case>-<fixed-case>CRF</fixed-case> approach</title>
      <author><first>Ratnavel</first><last>Rajalakshmi</last></author>
      <author><first>Mohit</first><last>More</last></author>
      <author><first>Bhamatipati</first><last>Shrikriti</last></author>
      <author><first>Gitansh</first><last>Saharan</last></author>
      <author><first>Hanchate</first><last>Samyuktha</last></author>
      <author><first>Sayantan</first><last>Nandy</last></author>
      <pages>248-253</pages>
      <abstract>Identifying offensive speech is an exciting andessential area of research, with ample tractionin recent times. This paper presents our sys-tem submission to the subtask 1, focusing onusing supervised approaches for extracting Of-fensive spans from code-mixed Tamil-Englishcomments. To identify offensive spans, wedeveloped the Bidirectional Long Short-TermMemory (BiLSTM) model with Glove Em-bedding. To this end, the developed systemachieved an overall F1 of 0.1728. Addition-ally, for comments with less than 30 characters,the developed system shows an F1 of 0.3890,competitive with other submissions.</abstract>
      <url hash="8dba2428">2022.dravidianlangtech-1.38</url>
      <bibkey>rajalakshmi-etal-2022-dlrg-tamilnlp</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.38</doi>
    </paper>
    <paper id="39">
      <title>Findings of the Shared Task on Multimodal Sentiment Analysis and Troll Meme Classification in <fixed-case>D</fixed-case>ravidian Languages</title>
      <author><first>Premjith</first><last>B</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Malliga</first><last>Subramanian</last></author>
      <author><first>Bharathi</first><last>B</last></author>
      <author><first>Soman</first><last>Kp</last></author>
      <author><first>Dhanalakshmi</first><last>V</last></author>
      <author><first>Sreelakshmi</first><last>K</last></author>
      <author><first>Arunaggiri</first><last>Pandian</last></author>
      <author><first>Prasanna</first><last>Kumaresan</last></author>
      <pages>254-260</pages>
      <abstract>This paper presents the findings of the shared task on Multimodal Sentiment Analysis and Troll meme classification in Dravidian languages held at ACL 2022. Multimodal sentiment analysis deals with the identification of sentiment from video. In addition to video data, the task requires the analysis of corresponding text and audio features for the classification of movie reviews into five classes. We created a dataset for this task in Malayalam and Tamil. The Troll meme classification task aims to classify multimodal Troll memes into two categories. This task assumes the analysis of both text and image features for making better predictions. The performance of the participating teams was analysed using the F1-score. Only one team submitted their results in the Multimodal Sentiment Analysis task, whereas we received six submissions in the Troll meme classification task. The only team that participated in the Multimodal Sentiment Analysis shared task obtained an F1-score of 0.24. In the Troll meme classification task, the winning team achieved an F1-score of 0.596.</abstract>
      <url hash="f16a9dd8">2022.dravidianlangtech-1.39</url>
      <bibkey>b-etal-2022-findings</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.39</doi>
      <video href="2022.dravidianlangtech-1.39.mp4"/>
    </paper>
    <paper id="40">
      <title>Findings of the Shared Task on Offensive Span Identification from<fixed-case>C</fixed-case>ode-Mixed <fixed-case>T</fixed-case>amil-<fixed-case>E</fixed-case>nglish Comments</title>
      <author><first>Manikandan</first><last>Ravikiran</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Anand Kumar</first><last>Madasamy</last></author>
      <author><first>Sangeetha</first><last>S</last></author>
      <author><first>Ratnavel</first><last>Rajalakshmi</last></author>
      <author><first>Sajeetha</first><last>Thavareesan</last></author>
      <author><first>Rahul</first><last>Ponnusamy</last></author>
      <author><first>Shankar</first><last>Mahadevan</last></author>
      <pages>261-270</pages>
      <abstract>Offensive content moderation is vital in social media platforms to support healthy online discussions. However, their prevalence in code-mixed Dravidian languages is limited to classifying whole comments without identifying part of it contributing to offensiveness. Such limitation is primarily due to the lack of annotated data for offensive spans. Accordingly, in this shared task, we provide Tamil-English code-mixed social comments with offensive spans. This paper outlines the dataset so released, methods, and results of the submitted systems.</abstract>
      <url hash="0dbfadd8">2022.dravidianlangtech-1.40</url>
      <bibkey>ravikiran-etal-2022-findings</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.40</doi>
      <video href="2022.dravidianlangtech-1.40.mp4"/>
    </paper>
    <paper id="41">
      <title>Overview of the Shared Task on Machine Translation in <fixed-case>D</fixed-case>ravidian Languages</title>
      <author><first>Anand Kumar</first><last>Madasamy</last></author>
      <author><first>Asha</first><last>Hegde</last></author>
      <author><first>Shubhanker</first><last>Banerjee</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Ruba</first><last>Priyadharshini</last></author>
      <author><first>Hosahalli</first><last>Shashirekha</last></author>
      <author><first>John</first><last>McCrae</last></author>
      <pages>271-278</pages>
      <abstract>This paper presents an outline of the shared task on translation of under-resourced Dravidian languages at DravidianLangTech-2022 workshop to be held jointly with ACL 2022. A description of the datasets used, approach taken for analysis of submissions and the results have been illustrated in this paper. Five sub-tasks organized as a part of the shared task include the following translation pairs: Kannada to Tamil, Kannada to Telugu, Kannada to Sanskrit, Kannada to Malayalam and Kannada to Tulu. Training, development and test datasets were provided to all participants and results were evaluated on the gold standard datasets. A total of 16 research groups participated in the shared task and a total of 12 submission runs were made for evaluation. Bilingual Evaluation Understudy (BLEU) score was used for evaluation of the translations.</abstract>
      <url hash="686c25fe">2022.dravidianlangtech-1.41</url>
      <bibkey>madasamy-etal-2022-overview</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.41</doi>
      <video href="2022.dravidianlangtech-1.41.mp4"/>
      <pwcdataset url="https://paperswithcode.com/dataset/samanantar">Samanantar</pwcdataset>
    </paper>
    <paper id="42">
      <title>Findings of the Shared Task on Emotion Analysis in <fixed-case>T</fixed-case>amil</title>
      <author><first>Anbukkarasi</first><last>Sampath</last></author>
      <author><first>Thenmozhi</first><last>Durairaj</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Ruba</first><last>Priyadharshini</last></author>
      <author><first>Subalalitha</first><last>Cn</last></author>
      <author><first>Kogilavani</first><last>Shanmugavadivel</last></author>
      <author><first>Sajeetha</first><last>Thavareesan</last></author>
      <author><first>Sathiyaraj</first><last>Thangasamy</last></author>
      <author><first>Parameswari</first><last>Krishnamurthy</last></author>
      <author><first>Adeep</first><last>Hande</last></author>
      <author><first>Sean</first><last>Benhur</last></author>
      <author><first>Kishore</first><last>Ponnusamy</last></author>
      <author><first>Santhiya</first><last>Pandiyan</last></author>
      <pages>279-285</pages>
      <abstract>This paper presents the overview of the shared task on emotional analysis in Tamil. The result of the shared task is presented at the workshop. This paper presents the dataset used in the shared task, task description, and the methodology used by the participants and the evaluation results of the submission. This task is organized as two Tasks. Task A is carried with 11 emotions annotated data for social media comments in Tamil and Task B is organized with 31 fine-grained emotion annotated data for social media comments in Tamil. For conducting experiments, training and development datasets were provided to the participants and results are evaluated for the unseen data. Totally we have received around 24 submissions from 13 teams. For evaluating the models, Precision, Recall, micro average metrics are used.</abstract>
      <url hash="72666233">2022.dravidianlangtech-1.42</url>
      <bibkey>sampath-etal-2022-findings</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.42</doi>
    </paper>
    <paper id="43">
      <title>Findings of the Shared Task on Multi-task Learning in <fixed-case>D</fixed-case>ravidian Languages</title>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Ruba</first><last>Priyadharshini</last></author>
      <author><first>Subalalitha</first><last>Cn</last></author>
      <author><first>Sangeetha</first><last>S</last></author>
      <author><first>Malliga</first><last>Subramanian</last></author>
      <author><first>Kogilavani</first><last>Shanmugavadivel</last></author>
      <author><first>Parameswari</first><last>Krishnamurthy</last></author>
      <author><first>Adeep</first><last>Hande</last></author>
      <author><first>Siddhanth</first><last>U Hegde</last></author>
      <author><first>Roshan</first><last>Nayak</last></author>
      <author><first>Swetha</first><last>Valli</last></author>
      <pages>286-291</pages>
      <abstract>We present our findings from the first shared task on Multi-task Learning in Dravidian Languages at the second Workshop on Speech and Language Technologies for Dravidian Languages. In this task, a sentence in any of three Dravidian Languages is required to be classified into two closely related tasks namely <i>Sentiment Analyis</i> (<b>SA</b>) and <i>Offensive Language Identification</i> (<b>OLI</b>). The task spans over three Dravidian Languages, namely, Kannada, Malayalam, and Tamil. It is one of the first shared tasks that focuses on Multi-task Learning for closely related tasks, especially for a very low-resourced language family such as the Dravidian language family. In total, 55 people signed up to participate in the task, and due to the intricate nature of the task, especially in its first iteration, 3 submissions have been received.</abstract>
      <url hash="49778f1e">2022.dravidianlangtech-1.43</url>
      <bibkey>chakravarthi-etal-2022-findings</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.43</doi>
    </paper>
    <paper id="44">
      <title>Overview of Abusive Comment Detection in <fixed-case>T</fixed-case>amil-<fixed-case>ACL</fixed-case> 2022</title>
      <author><first>Ruba</first><last>Priyadharshini</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Subalalitha</first><last>Cn</last></author>
      <author><first>Thenmozhi</first><last>Durairaj</last></author>
      <author><first>Malliga</first><last>Subramanian</last></author>
      <author><first>Kogilavani</first><last>Shanmugavadivel</last></author>
      <author><first>Siddhanth</first><last>U Hegde</last></author>
      <author><first>Prasanna</first><last>Kumaresan</last></author>
      <pages>292-298</pages>
      <abstract>The social media is one of the significantdigital platforms that create a huge im-pact in peoples of all levels. The commentsposted on social media is powerful enoughto even change the political and businessscenarios in very few hours. They alsotend to attack a particular individual ora group of individuals. This shared taskaims at detecting the abusive comments in-volving, Homophobia, Misandry, Counter-speech, Misogyny, Xenophobia, Transpho-bic. The hope speech is also identified. Adataset collected from social media taggedwith the above said categories in Tamiland Tamil-English code-mixed languagesare given to the participants. The par-ticipants used different machine learningand deep learning algorithms. This paperpresents the overview of this task compris-ing the dataset details and results of theparticipants.</abstract>
      <url hash="11b875cf">2022.dravidianlangtech-1.44</url>
      <bibkey>priyadharshini-etal-2022-overview</bibkey>
      <doi>10.18653/v1/2022.dravidianlangtech-1.44</doi>
      <video href="2022.dravidianlangtech-1.44.mp4"/>
    </paper>
  </volume>
</collection>
