<?xml version='1.0' encoding='UTF-8'?>
<collection id="2023.rail">
  <volume id="1" ingest-date="2023-05-07" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Fourth workshop on Resources for African Indigenous Languages (RAIL 2023)</booktitle>
      <editor><first>Rooweither</first><last>Mabuya</last></editor>
      <editor><first>Don</first><last>Mthobela</last></editor>
      <editor><first>Mmasibidi</first><last>Setaka</last></editor>
      <editor><first>Menno</first><last>Van Zaanen</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Dubrovnik, Croatia</address>
      <month>May</month>
      <year>2023</year>
      <url hash="3d3e13d9">2023.rail-1</url>
      <venue>rail</venue>
    </meta>
    <frontmatter>
      <url hash="43aef86f">2023.rail-1.0</url>
      <bibkey>rail-2023-resources</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Automatic Spell Checker and Correction for Under-represented Spoken Languages: Case Study on <fixed-case>W</fixed-case>olof</title>
      <author><first>Thierno Ibrahima</first><last>Cissé</last><affiliation>Uqam</affiliation></author>
      <author><first>Fatiha</first><last>Sadat</last><affiliation>Uqam</affiliation></author>
      <pages>1-10</pages>
      <abstract>This paper presents a spell checker and correction tool specifically designed for Wolof, an under-represented spoken language in Africa. The proposed spell checker leverages a combination of a trie data structure, dynamic programming, and the weighted Levenshtein distance to generate suggestions for misspelled words. We created novel linguistic resources for Wolof, such as a lexicon and a corpus of misspelled words, using a semi-automatic approach that combines manual and automatic annotation methods. Despite the limited data available for the Wolof language, the spell checker’s performance showed a predictive accuracy of 98.31% and a suggestion accuracy of 93.33%.Our primary focus remains the revitalization and preservation of Wolof as an Indigenous and spoken language in Africa, providing our efforts to develop novel linguistic resources. This work represents a valuable contribution to the growth of computational tools and resources for the Wolof language and provides a strong foundation for future studies in the automatic spell checking and correction field.</abstract>
      <url hash="4422059e">2023.rail-1.1</url>
      <bibkey>cisse-sadat-2023-automatic</bibkey>
      <video href="2023.rail-1.1.mp4"/>
      <doi>10.18653/v1/2023.rail-1.1</doi>
    </paper>
    <paper id="2">
      <title>Unsupervised Cross-lingual Word Embedding Representation for <fixed-case>E</fixed-case>nglish-isi<fixed-case>Z</fixed-case>ulu</title>
      <author><first>Derwin</first><last>Ngomane</last><affiliation>University of Pretoria</affiliation></author>
      <author><first>Rooweither</first><last>Mabuya</last><affiliation>North-West University: South African Centre for Digital Language Resources</affiliation></author>
      <author><first>Jade</first><last>Abbott</last><affiliation>Retro Rabbit</affiliation></author>
      <author><first>Vukosi</first><last>Marivate</last><affiliation>University of Pretoria, Lelapa AI</affiliation></author>
      <pages>11-17</pages>
      <abstract>In this study, we investigate the effectiveness of using cross-lingual word embeddings for zero-shot transfer learning between a language with an abundant resource, English, and a languagewith limited resource, isiZulu. IsiZulu is a part of the South African Nguni language family, which is characterised by complex agglutinating morphology. We use VecMap, an open source tool, to obtain cross-lingual word embeddings. To perform an extrinsic evaluation of the effectiveness of the embeddings, we train a news classifier on labelled English data in order to categorise unlabelled isiZulu data using zero-shot transfer learning. In our study, we found our model to have a weighted average F1-score of 0.34. Our findings demonstrate that VecMap generates modular word embeddings in the cross-lingual space that have an impact on the downstream classifier used for zero-shot transfer learning.</abstract>
      <url hash="5d4cd2cc">2023.rail-1.2</url>
      <bibkey>ngomane-etal-2023-unsupervised</bibkey>
      <video href="2023.rail-1.2.mp4"/>
      <doi>10.18653/v1/2023.rail-1.2</doi>
    </paper>
    <paper id="3">
      <title>Preparing the Vuk’uzenzele and <fixed-case>ZA</fixed-case>-gov-multilingual <fixed-case>S</fixed-case>outh <fixed-case>A</fixed-case>frican multilingual corpora</title>
      <author><first>Richard</first><last>Lastrucci</last><affiliation>University Of Pretoria</affiliation></author>
      <author><first>Jenalea</first><last>Rajab</last><affiliation>The University of the Witwatersrand</affiliation></author>
      <author><first>Matimba</first><last>Shingange</last><affiliation>University of Pretoria</affiliation></author>
      <author><first>Daniel</first><last>Njini</last><affiliation>University of Pretoria</affiliation></author>
      <author><first>Vukosi</first><last>Marivate</last><affiliation>University of Pretoria, Lelapa AI</affiliation></author>
      <pages>18-25</pages>
      <abstract>This paper introduces two multilingual government themed corpora in various South African languages. The corpora were collected by gathering South African government speeches (ZA-gov-multilingual), as well as the South African Government newspaper (Vuk’uzenzele), that are translated into all 11 South African official languages. The corpora can be used for a myriad of downstream NLP tasks. The corpora were created to allow researchers to study the language used in South African government publications, with a focus on understanding how South African government officials communicate with their constituents. In this paper we highlight the process of gathering, cleaning and making available the corpora. We create parallel sentence corpora for Neural Machine Translation tasks using Language-Agnostic Sentence Representations (LASER) embeddings. With these aligned sentences we then provide NMT benchmarks for 9 indigenous languages by fine-tuning massively multilingual pre-trained language model.</abstract>
      <url hash="3990f7cb">2023.rail-1.3</url>
      <bibkey>lastrucci-etal-2023-preparing</bibkey>
      <video href="2023.rail-1.3.mp4"/>
      <doi>10.18653/v1/2023.rail-1.3</doi>
    </paper>
    <paper id="4">
      <title><fixed-case>S</fixed-case>peech<fixed-case>R</fixed-case>eporting Corpus: annotated corpora of <fixed-case>W</fixed-case>est <fixed-case>A</fixed-case>frican traditional narratives</title>
      <author><first>Ekaterina</first><last>Aplonova</last><affiliation>Llacan, Cnrs</affiliation></author>
      <author><first>Izabela</first><last>Jordanoska</last><affiliation>Lacito, Cnrs</affiliation></author>
      <author><first>Timofey</first><last>Arkhangelskiy</last><affiliation>Universität Hamburg</affiliation></author>
      <author><first>Tatiana</first><last>Nikitina</last><affiliation>Lacito, Cnrs</affiliation></author>
      <pages>26-31</pages>
      <abstract>This paper describes the SpeechReporting database, an online collection of corpora annotated for a range of discourse phenomena. The corpora contain folktales from 7 lesser-studied West African languages. Apart from its value for theoretical linguistics, especially for the study of reported speech, the database is an important resource for the preservation of intangible cultural heritage of minority languages and the development and testing of cross-linguistically applicable computational tools.</abstract>
      <url hash="280c619d">2023.rail-1.4</url>
      <bibkey>aplonova-etal-2023-speechreporting</bibkey>
      <doi>10.18653/v1/2023.rail-1.4</doi>
    </paper>
    <paper id="5">
      <title>A Corpus-Based List of Frequently Used Words in Sesotho</title>
      <author><first>Johannes</first><last>Sibeko</last><affiliation>Nelson Mandela University</affiliation></author>
      <author><first>Orphée</first><last>De Clercq</last><affiliation>Universiteit Gent</affiliation></author>
      <pages>32-41</pages>
      <abstract>This paper describes the SpeechReporting Corpus, an online collection of corpora annotated for a range of discourse phenomena. The corpora contain folktales from 7 lesser-studied West African languages. Apart from its value for theoretical linguistics, especially for the study of reported speech, the database is an important resource for the preservation of intangible cultural heritage of minority languages and the development and testing of cross-linguistically applicable computational tools.</abstract>
      <url hash="5f58e1e9">2023.rail-1.5</url>
      <bibkey>sibeko-de-clercq-2023-corpus</bibkey>
      <video href="2023.rail-1.5.mp4"/>
      <doi>10.18653/v1/2023.rail-1.5</doi>
    </paper>
    <paper id="6">
      <title>Deep learning and low-resource languages: How much data is enough? A case study of three linguistically distinct <fixed-case>S</fixed-case>outh <fixed-case>A</fixed-case>frican languages</title>
      <author><first>Roald</first><last>Eiselen</last><affiliation>North-West University</affiliation></author>
      <author><first>Tanja</first><last>Gaustad</last><affiliation>Centre for Text Technology (CTexT), North-West University</affiliation></author>
      <pages>42-53</pages>
      <abstract>In this paper we present a case study for three under-resourced linguistically distinct South African languages (Afrikaans, isiZulu, and Sesotho sa Leboa) to investigate the influence of data size and linguistic nature of a language on the performance of different embedding types. Our experimental setup consists of training embeddings on increasing amounts of data and then evaluating the impact of data size for the downstream task of part of speech tagging. We find that relatively little data can produce useful representations for this specific task for all three languages. Our analysis also shows that the influence of linguistic and orthographic differences between languages should not be underestimated: morphologically complex, conjunctively written languages (isiZulu in our case) need substantially more data to achieve good results, while disjunctively written languages require substantially less data. This is not only the case with regard to the data for training the embedding model, but also annotated training material for the task at hand. It is therefore imperative to know the characteristics of the language you are working on to make linguistically informed choices about the amount of data and the type of embeddings to use.</abstract>
      <url hash="6cd686d9">2023.rail-1.6</url>
      <bibkey>eiselen-gaustad-2023-deep</bibkey>
      <video href="2023.rail-1.6.mp4"/>
      <doi>10.18653/v1/2023.rail-1.6</doi>
    </paper>
    <paper id="7">
      <title><fixed-case>I</fixed-case>si<fixed-case>X</fixed-case>hosa Intellectual Traditions Digital Archive: Digitizing isi<fixed-case>X</fixed-case>hosa texts from 1870-1914</title>
      <author><first>Jonathan</first><last>Schoots</last><affiliation>Stellenbosch Univerity, LEAP, Department of Economics</affiliation></author>
      <author><first>Amandla</first><last>Ngwendu</last><affiliation>University of Cape Town, Department of African Languages and Literature</affiliation></author>
      <author><first>Jacques</first><last>De Wet</last><affiliation>University of Cape Town, Department of Sociology</affiliation></author>
      <author><first>Sanjin</first><last>Muftic</last><affiliation>Digital Library Services, UCT Libraries, University of Cape Town https://orcid.org/0000-0002-8571-7777</affiliation></author>
      <pages>54-64</pages>
      <abstract>This article offers an overview of the IsiXhosa Intellectual Traditions Digital Archive, which hosts digitized texts and images of early isiXhosa newspapers and books from 1870-1914. The archive offers new opportunities for a range of research across multiple fields, and responds to debates around the importance of African intellectual traditions and their indigenous language sources in generating African social sciences which is contextually relevant. We outline the content and context of these materials and offer qualitative and quantitative details with the aim of providing an overview for interested scholars and a reference for those using the archive.</abstract>
      <url hash="a456683a">2023.rail-1.7</url>
      <bibkey>schoots-etal-2023-isixhosa</bibkey>
      <video href="2023.rail-1.7.mp4"/>
      <doi>10.18653/v1/2023.rail-1.7</doi>
    </paper>
    <paper id="8">
      <title>Analyzing political formation through historical isi<fixed-case>X</fixed-case>hosa text analysis: Using frequency analysis to examine emerging <fixed-case>A</fixed-case>frican Nationalism in <fixed-case>S</fixed-case>outh <fixed-case>A</fixed-case>frica</title>
      <author><first>Jonathan</first><last>Schoots</last><affiliation>Stellenbosch Univerity, LEAP, Department of Economics</affiliation></author>
      <pages>65-75</pages>
      <abstract>This paper showcases new research avenues made possible by applying computational methods to historical isiXhosa text. I outline a method for isiXhosa computational text analysis which adapts word frequency analysis to be applied to isiXhosa texts focusing on root words. The paper showcases the value of the approach in a study of emerging political identities in early African nationalism, examining a novel dataset of isiXhosa newspapers from 1874 to 1890. The analysis shows how a shared identity of ‘Blackness’ (Abantsundu and Abamnyama) dynamically emerged, and follows the impact of leading intellectuals as well as African voter mobilization in shaping communal political discourse.</abstract>
      <url hash="a57828d8">2023.rail-1.8</url>
      <bibkey>schoots-2023-analyzing</bibkey>
      <video href="2023.rail-1.8.mp4"/>
      <doi>10.18653/v1/2023.rail-1.8</doi>
    </paper>
    <paper id="9">
      <title>Evaluating the Sesotho rule-based syllabification system on Sepedi and Setswana words</title>
      <author><first>Johannes</first><last>Sibeko</last><affiliation>Nelson Mandela University</affiliation></author>
      <author><first>Mmasibidi</first><last>Setaka</last><affiliation>Sadilar</affiliation></author>
      <pages>76-85</pages>
      <abstract>The purpose of this article is to demonstrate that the recently developed automated rule-based syllabification system for Sesotho can be used broadly across the officially recognised South African Sotho-Tswana language group encompassing Sepedi, Sesotho and Setswana. We evaluate the automatic syllabification system on 400 words comprising 100 most frequently used words and 100 least-used words in Sepedi and Setswana as evident in the Autshumato corpus publicly available online. It is found that the Sesotho rule-based syllabification system can be used to correctly identify vowel-only syllables, consonant-vowel syllables and consonant-only syllables in Sepedi and Setswana. Among other findings, it has been demonstrated that words with diacritics as in the case of Sepedi are correctly broken down into syllables. We make two main recommendations. First, the rules for syllabification should be updated so that Sepedi diacritics are accommodated. Second, the syllabification system should be updated so that it reflects the broader Sotho-Tswana language group instead of being limited to Sesotho. Further research is needed to ascertain whether the complex consonant [ny] behaves similarly in all three officially recognised Sotho-Tswana languages and evaluate the need for a specific rule for the [ny] digraph.</abstract>
      <url hash="74e2b6e2">2023.rail-1.9</url>
      <bibkey>sibeko-setaka-2023-evaluating</bibkey>
      <video href="2023.rail-1.9.mp4"/>
      <doi>10.18653/v1/2023.rail-1.9</doi>
    </paper>
    <paper id="10">
      <title>Towards a <fixed-case>S</fixed-case>wahili <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependency Treebank: Leveraging the Annotations of the <fixed-case>H</fixed-case>elsinki Corpus of <fixed-case>S</fixed-case>wahili</title>
      <author><first>Kenneth</first><last>Steimel</last><affiliation>Indiana University</affiliation></author>
      <author><first>Sandra</first><last>Kübler</last><affiliation>Indiana University</affiliation></author>
      <pages>86-96</pages>
      <abstract>Dependency annotation can be a laborious process for under-resourced languages. However, in some cases, other resources are available. We investigate whether we can leverage such resources in the case of Swahili: We use the Helsinki Corpus of Swahili for creating a Universal Depedencies treebank for Swahili. The Helsinki Corpus of Swahili provides word-level annotations for part of speech tags, morphological features, and functional syntactic tags. We train neural taggers for these types of annotations, then use those models to annotate our target corpus, the Swahili portion of the OPUS Global Voices Corpus. Based on those annotations, we then manually create constraint grammar rules to annotate the target corpus for Universal Dependencies. In this paper, we describe the process, discuss the annotation decisions we had to make, and we evaluate the approach.</abstract>
      <url hash="0575d46a">2023.rail-1.10</url>
      <bibkey>steimel-etal-2023-towards</bibkey>
      <video href="2023.rail-1.10.mp4"/>
      <doi>10.18653/v1/2023.rail-1.10</doi>
    </paper>
    <paper id="11">
      <title>Comparing methods of orthographic conversion for Bàsàá, a language of <fixed-case>C</fixed-case>ameroon</title>
      <author><first>Alexandra</first><last>O’neil</last><affiliation>Indiana University</affiliation></author>
      <author><first>Daniel</first><last>Swanson</last><affiliation>Indiana University</affiliation></author>
      <author><first>Robert</first><last>Pugh</last><affiliation>Indiana University</affiliation></author>
      <author><first>Francis</first><last>Tyers</last><affiliation>Indiana University</affiliation></author>
      <author><first>Emmanuel</first><last>Ngue Um</last><affiliation>University of Yaoundé I</affiliation></author>
      <pages>97-105</pages>
      <abstract>Orthographical standardization is a milestone in a language’s documentation and the development of its resources. However, texts written in former orthographies remain relevant to the language’s history and development and therefore must be converted to the standardized orthography. Ensuring a language has access to the orthographically standardized version of all of its recorded texts is important in the development of resources as it provides additional textual resources for training, supports contribution of authors using former writing systems, and provides information about the development of the language. This paper evaluates the performance of natural language processing methods, specifically Finite State Transducers and Long Short-term Memory networks, for the orthographical conversion of Bàsàá texts from the Protestant missionary orthography to the now-standard AGLC orthography, with the conclusion that LSTMs are somewhat more effective in the absence of explicit lexical information.</abstract>
      <url hash="79adf233">2023.rail-1.11</url>
      <bibkey>oneil-etal-2023-comparing</bibkey>
      <video href="2023.rail-1.11.mp4"/>
      <doi>10.18653/v1/2023.rail-1.11</doi>
    </paper>
    <paper id="12">
      <title>Vowels and the <fixed-case>I</fixed-case>gala Language Resources</title>
      <author><first>Mahmud</first><last>Momoh</last><affiliation>Prince Abubakar Audu University</affiliation></author>
      <pages>106-114</pages>
      <abstract>The aim of this article is to provide some insight into the use of the diacritic orthography in the writing of the Igala Language corpus. The aim was to use a lexical approach in identifying some of the words inherent in the language. Examples with sentences and interpretation were also provided with footnotes illustrations to better expiate some of the words and examples that could not be reflected upon in the main body of the work. The article as a matter of fact combines up to seven diacritic forms in order to better tackle the oft en-counter problem of pronouncing words in texts written in foreign language with supporting indicators provided in the work to guide users on how to pronounce the words using the diacritic forms that were adopted for the sake of this work. A total of 30 vowels were identified (5 short vowels and 25 long vowels of different variety) plus 8 diphthongs.</abstract>
      <url hash="ff8c56c6">2023.rail-1.12</url>
      <bibkey>momoh-2023-vowels</bibkey>
      <video href="2023.rail-1.12.mp4"/>
      <doi>10.18653/v1/2023.rail-1.12</doi>
    </paper>
    <paper id="13">
      <title>Investigating Sentiment-Bearing Words- and Emoji-based Distant Supervision Approaches for Sentiment Analysis</title>
      <author><first>Ronny</first><last>Mabokela</last><affiliation>University of Johannesburg</affiliation></author>
      <author><first>Mpho</first><last>Roborife</last><affiliation>Uj</affiliation></author>
      <author><first>Turguy</first><last>Celik</last><affiliation>Wits</affiliation></author>
      <pages>115-125</pages>
      <abstract>Sentiment analysis focuses on the automatic detection and classification of opinions expressed in texts. Emojis can be used to determine the sentiment polarities of the texts (i.e. positive, negative, or neutral). Several studies demonstrated how sentiment analysis is accurate when emojis are used (Kaity and Balakrishnan, 2020). While they have used emojis as features to improve the performance of sentiment analysis systems, in this paper we analyse the use of emojis to reduce the manual effort inlabelling text for training those systems. Furthermore, we investigate the manual effort reduction in the sentiment labelling process with the help of sentiment-bearing words as well as the combination of sentiment-bearing words and emojis. In addition to English, we evaluated the approaches with the low-resource African languages Sepedi, Setswana, and Sesotho. The combination of emojis and words sentiment lexicon shows better performance compared to emojis-only lexicons and words-based lexicons. Our results show that our emoji sentiment lexicon approach is effective, with an accuracy of 75% more than other sentiment lexicon approaches, which have an average accuracy of 69.1%. Furthermore, our distant supervision method obtained an accuracy of 76%. We anticipate that only 24% of the tweets will need to be changed as a result of our annotation strategies</abstract>
      <url hash="ae6f7e0b">2023.rail-1.13</url>
      <bibkey>mabokela-etal-2023-investigating</bibkey>
      <video href="2023.rail-1.13.mp4"/>
      <doi>10.18653/v1/2023.rail-1.13</doi>
    </paper>
    <paper id="14">
      <title>Natural Language Processing in <fixed-case>E</fixed-case>thiopian Languages: Current State, Challenges, and Opportunities</title>
      <author><first>Atnafu Lambebo</first><last>Tonja</last><affiliation>Instituto Politécnico Nacional (IPN), Centro de Investigación en Computación (CIC)</affiliation></author>
      <author><first>Tadesse Destaw</first><last>Belay</last><affiliation>Wollo University</affiliation></author>
      <author><first>Israel Abebe</first><last>Azime</last><affiliation>Aims-ammi</affiliation></author>
      <author><first>Abinew Ali</first><last>Ayele</last><affiliation>Bahir Dar University</affiliation></author>
      <author><first>Moges Ahmed</first><last>Mehamed</last><affiliation>Wuhan University of Technology</affiliation></author>
      <author><first>Olga</first><last>Kolesnikova</last><affiliation>Instituto Politecnico Nacional</affiliation></author>
      <author><first>Seid Muhie</first><last>Yimam</last><affiliation>Universität Hamburg</affiliation></author>
      <pages>126-139</pages>
      <abstract>This survey delves into the current state of natural language processing (NLP) for four Ethiopian languages: Amharic, Afaan Oromo, Tigrinya, and Wolaytta. Through this paper, we identify key challenges and opportunities for NLP research in Ethiopia.Furthermore, we provide a centralized repository on GitHub that contains publicly available resources for various NLP tasks in these languages. This repository can be updated periodically with contributions from other researchers. Our objective is to disseminate information to NLP researchers interested in Ethiopian languages and encourage future research in this domain.</abstract>
      <url hash="63e618fd">2023.rail-1.14</url>
      <bibkey>tonja-etal-2023-natural</bibkey>
      <video href="2023.rail-1.14.mp4"/>
      <doi>10.18653/v1/2023.rail-1.14</doi>
    </paper>
  </volume>
</collection>
