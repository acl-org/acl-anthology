<?xml version='1.0' encoding='UTF-8'?>
<collection id="2020.nlpcovid19">
  <volume id="acl" ingest-date="2020-10-13">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on <fixed-case>NLP</fixed-case> for <fixed-case>COVID-19</fixed-case> at <fixed-case>ACL</fixed-case> 2020</booktitle>
      <editor><first>Karin</first><last>Verspoor</last></editor>
      <editor><first>Kevin Bretonnel</first><last>Cohen</last></editor>
      <editor><first>Mark</first><last>Dredze</last></editor>
      <editor><first>Emilio</first><last>Ferrara</last></editor>
      <editor><first>Jonathan</first><last>May</last></editor>
      <editor><first>Robert</first><last>Munro</last></editor>
      <editor><first>Cecile</first><last>Paris</last></editor>
      <editor><first>Byron</first><last>Wallace</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>July</month>
      <year>2020</year>
      <venue>nlpcovid19</venue>
    </meta>
    <frontmatter>
      <url hash="fddac610">2020.nlpcovid19-acl.0</url>
      <bibkey>nlp-covid19-2020-nlp</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>CORD-19</fixed-case>: The <fixed-case>COVID-19</fixed-case> Open Research Dataset</title>
      <author><first>Lucy Lu</first><last>Wang</last></author>
      <author><first>Kyle</first><last>Lo</last></author>
      <author><first>Yoganand</first><last>Chandrasekhar</last></author>
      <author><first>Russell</first><last>Reas</last></author>
      <author><first>Jiangjiang</first><last>Yang</last></author>
      <author><first>Doug</first><last>Burdick</last></author>
      <author><first>Darrin</first><last>Eide</last></author>
      <author><first>Kathryn</first><last>Funk</last></author>
      <author><first>Yannis</first><last>Katsis</last></author>
      <author><first>Rodney Michael</first><last>Kinney</last></author>
      <author><first>Yunyao</first><last>Li</last></author>
      <author><first>Ziyang</first><last>Liu</last></author>
      <author><first>William</first><last>Merrill</last></author>
      <author><first>Paul</first><last>Mooney</last></author>
      <author><first>Dewey A.</first><last>Murdick</last></author>
      <author><first>Devvret</first><last>Rishi</last></author>
      <author><first>Jerry</first><last>Sheehan</last></author>
      <author><first>Zhihong</first><last>Shen</last></author>
      <author><first>Brandon</first><last>Stilson</last></author>
      <author><first>Alex D.</first><last>Wade</last></author>
      <author><first>Kuansan</first><last>Wang</last></author>
      <author><first>Nancy Xin Ru</first><last>Wang</last></author>
      <author><first>Christopher</first><last>Wilhelm</last></author>
      <author><first>Boya</first><last>Xie</last></author>
      <author><first>Douglas M.</first><last>Raymond</last></author>
      <author><first>Daniel S.</first><last>Weld</last></author>
      <author><first>Oren</first><last>Etzioni</last></author>
      <author><first>Sebastian</first><last>Kohlmeier</last></author>
      <abstract>The COVID-19 Open Research Dataset (CORD-19) is a growing resource of scientific papers on COVID-19 and related historical coronavirus research. CORD-19 is designed to facilitate the development of text mining and information retrieval systems over its rich collection of metadata and structured full text papers. Since its release, CORD-19 has been downloaded over 200K times and has served as the basis of many COVID-19 text mining and discovery systems. In this article, we describe the mechanics of dataset construction, highlighting challenges and key design decisions, provide an overview of how CORD-19 has been used, and describe several shared tasks built around the dataset. We hope this resource will continue to bring together the computing community, biomedical experts, and policy makers in the search for effective treatments and management policies for COVID-19.</abstract>
      <url hash="f3ee0bb6">2020.nlpcovid19-acl.1</url>
      <bibkey>wang-etal-2020-cord</bibkey>
      <pwccode url="https://github.com/allenai/cord19" additional="true">allenai/cord19</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cord-19">CORD-19</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/s2orc">S2ORC</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/trec-covid">TREC-COVID</pwcdataset>
    </paper>
    <paper id="2">
      <title>Rapidly Deploying a Neural Search Engine for the <fixed-case>COVID-19</fixed-case> <fixed-case>Open</fixed-case> <fixed-case>Research</fixed-case> <fixed-case>Dataset</fixed-case></title>
      <author><first>Edwin</first><last>Zhang</last></author>
      <author><first>Nikhil</first><last>Gupta</last></author>
      <author><first>Rodrigo</first><last>Nogueira</last></author>
      <author><first>Kyunghyun</first><last>Cho</last></author>
      <author><first>Jimmy</first><last>Lin</last></author>
      <abstract>The Neural Covidex is a search engine that exploits the latest neural ranking architectures to provide information access to the COVID-19 Open Research Dataset (CORD-19) curated by the Allen Institute for AI. It exists as part of a suite of tools we have developed to help domain experts tackle the ongoing global pandemic. We hope that improved information access capabilities to the scientific literature can inform evidence-based decision making and insight generation.</abstract>
      <url hash="5ecb67c9">2020.nlpcovid19-acl.2</url>
      <bibkey>zhang-etal-2020-rapidly</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cord-19">CORD-19</pwcdataset>
    </paper>
    <paper id="3">
      <title>Document Classification for <fixed-case>COVID-19</fixed-case> Literature</title>
      <author><first>Bernal</first><last>Jiménez Gutiérrez</last></author>
      <author><first>Juncheng</first><last>Zeng</last></author>
      <author><first>Dongdong</first><last>Zhang</last></author>
      <author><first>Ping</first><last>Zhang</last></author>
      <author><first>Yu</first><last>Su</last></author>
      <abstract>The global pandemic has made it more important than ever to quickly and accurately retrieve relevant scientific literature for effective consumption by researchers in a wide range of fields. We provide an analysis of several multi-label document classification models on the LitCovid dataset. We find that pre-trained language models outperform other models in both low and high data regimes, achieving a maximum F1 score of around 86%. We note that even the highest performing models still struggle with label correlation, distraction from introductory text and CORD-19 generalization. Both data and code are available on GitHub.</abstract>
      <url hash="e5936d8e">2020.nlpcovid19-acl.3</url>
      <bibkey>jimenez-gutierrez-etal-2020-document-classification</bibkey>
    </paper>
    <paper id="4">
      <title>Enabling Low-Resource Transfer Learning across <fixed-case>COVID-19</fixed-case> Corpora by Combining Event-Extraction and Co-Training</title>
      <author><first>Alexander</first><last>Spangher</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <author><first>Jonathan</first><last>May</last></author>
      <author><first>Emilio</first><last>Ferrara</last></author>
      <url hash="55e5fca9">2020.nlpcovid19-acl.4</url>
      <bibkey>spangher-etal-2020-enabling</bibkey>
    </paper>
    <paper id="5">
      <title>Self-supervised context-aware <fixed-case>COVID-19</fixed-case> document exploration through atlas grounding</title>
      <author><first>Dusan</first><last>Grujicic</last></author>
      <author><first>Gorjan</first><last>Radevski</last></author>
      <author><first>Tinne</first><last>Tuytelaars</last></author>
      <author><first>Matthew</first><last>Blaschko</last></author>
      <abstract>In this paper, we aim to develop a self-supervised grounding of Covid-related medical text based on the actual spatial relationships between the referred anatomical concepts. More specifically, we learn to project sentences into a physical space defined by a three-dimensional anatomical atlas, allowing for a visual approach to navigating Covid-related literature. We design a straightforward and empirically effective training objective to reduce the curated data dependency issue. We use BERT as the main building block of our model and perform a quantitative analysis that demonstrates that the model learns a context-aware mapping. We illustrate two potential use-cases for our approach, one in interactive, 3D data exploration, and the other in document retrieval. To accelerate research in this direction, we make public all trained models, codebase and the developed tools, which can be accessed at https://github.com/gorjanradevski/macchina/.</abstract>
      <url hash="ea5b60e4">2020.nlpcovid19-acl.5</url>
      <bibkey>grujicic-etal-2020-self</bibkey>
      <pwccode url="https://github.com/gorjanradevski/macchina" additional="false">gorjanradevski/macchina</pwccode>
    </paper>
    <paper id="6">
      <title><fixed-case>CODA-19</fixed-case>: Using a Non-Expert Crowd to Annotate Research Aspects on 10,000+ Abstracts in the <fixed-case>COVID-19</fixed-case> Open Research Dataset</title>
      <author><first>Ting-Hao Kenneth</first><last>Huang</last></author>
      <author><first>Chieh-Yang</first><last>Huang</last></author>
      <author><first>Chien-Kuang Cornelia</first><last>Ding</last></author>
      <author><first>Yen-Chia</first><last>Hsu</last></author>
      <author><first>C. Lee</first><last>Giles</last></author>
      <abstract>This paper introduces CODA-19, a human-annotated dataset that codes the Background, Purpose, Method, Finding/Contribution, and Other sections of 10,966 English abstracts in the COVID-19 Open Research Dataset. CODA-19 was created by 248 crowd workers from Amazon Mechanical Turk within 10 days, and achieved labeling quality comparable to that of experts. Each abstract was annotated by nine different workers, and the final labels were acquired by majority vote. The inter-annotator agreement (Cohen’s kappa) between the crowd and the biomedical expert (0.741) is comparable to inter-expert agreement (0.788). CODA-19’s labels have an accuracy of 82.2% when compared to the biomedical expert’s labels, while the accuracy between experts was 85.0%. Reliable human annotations help scientists access and integrate the rapidly accelerating coronavirus literature, and also serve as the battery of AI/NLP research, but obtaining expert annotations can be slow. We demonstrated that a non-expert crowd can be rapidly employed at scale to join the fight against COVID-19.</abstract>
      <url hash="549ba9fe">2020.nlpcovid19-acl.6</url>
      <bibkey>huang-etal-2020-coda</bibkey>
      <pwccode url="https://github.com/windx0303/CODA-19" additional="false">windx0303/CODA-19</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/coda-19">CODA-19</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/cord-19">CORD-19</pwcdataset>
    </paper>
    <paper id="7">
      <title>Information Retrieval and Extraction on <fixed-case>COVID-19</fixed-case> Clinical Articles Using Graph Community Detection and <fixed-case>Bio-BERT</fixed-case> Embeddings</title>
      <author><first>Debasmita</first><last>Das</last></author>
      <author><first>Yatin</first><last>Katyal</last></author>
      <author><first>Janu</first><last>Verma</last></author>
      <author><first>Shashank</first><last>Dubey</last></author>
      <author><first>AakashDeep</first><last>Singh</last></author>
      <author><first>Kushagra</first><last>Agarwal</last></author>
      <author><first>Sourojit</first><last>Bhaduri</last></author>
      <author><first>RajeshKumar</first><last>Ranjan</last></author>
      <abstract>In this paper, we present an information retrieval system on a corpus of scientific articles related to COVID-19. We build a similarity network on the articles where similarity is determined via shared citations and biological domain-specific sentence embeddings. Ego-splitting community detection on the article network is employed to cluster the articles and then the queries are matched with the clusters. Extractive summarization using BERT and PageRank methods is used to provide responses to the query. We also provide a Question-Answer bot on a small set of intents to demonstrate the efficacy of our model for an information extraction module.</abstract>
      <url hash="689b3e4a">2020.nlpcovid19-acl.7</url>
      <bibkey>das-etal-2020-information</bibkey>
    </paper>
    <paper id="8">
      <title>What Are People Asking About <fixed-case>COVID-19</fixed-case>? A Question Classification Dataset</title>
      <author><first>Jerry</first><last>Wei</last></author>
      <author><first>Chengyu</first><last>Huang</last></author>
      <author><first>Soroush</first><last>Vosoughi</last></author>
      <author><first>Jason</first><last>Wei</last></author>
      <abstract>We present COVID-Q, a set of 1,690 questions about COVID-19 from 13 sources, which we annotate into 15 question categories and 207 question clusters. The most common questions in our dataset asked about transmission, prevention, and societal effects of COVID, and we found that many questions that appeared in multiple sources were not answered by any FAQ websites of reputable organizations such as the CDC and FDA. We post our dataset publicly at https://github.com/JerryWei03/COVID-Q. For classifying questions into 15 categories, a BERT baseline scored 58.1% accuracy when trained on 20 examples per category, and for a question clustering task, a BERT + triplet loss baseline achieved 49.5% accuracy. We hope COVID-Q can help either for direct use in developing applied systems or as a domain-specific resource for model evaluation.</abstract>
      <url hash="490f073d">2020.nlpcovid19-acl.8</url>
      <bibkey>wei-etal-2020-people</bibkey>
      <pwccode url="https://github.com/JerryWei03/COVID-Q" additional="false">JerryWei03/COVID-Q</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/covid-q">COVID-Q</pwcdataset>
    </paper>
    <paper id="9">
      <title>Jennifer for <fixed-case>COVID-19</fixed-case>: An <fixed-case>NLP</fixed-case>-Powered Chatbot Built for the People and by the People to Combat Misinformation</title>
      <author><first>Yunyao</first><last>Li</last></author>
      <author><first>Tyrone</first><last>Grandison</last></author>
      <author><first>Patricia</first><last>Silveyra</last></author>
      <author><first>Ali</first><last>Douraghy</last></author>
      <author><first>Xinyu</first><last>Guan</last></author>
      <author><first>Thomas</first><last>Kieselbach</last></author>
      <author><first>Chengkai</first><last>Li</last></author>
      <author><first>Haiqi</first><last>Zhang</last></author>
      <abstract>Just as SARS-CoV-2, a new form of coronavirus continues to infect a growing number of people around the world, harmful misinformation about the outbreak also continues to spread. With the goal of combating misinformation, we designed and built Jennifer–a chatbot maintained by a global group of volunteers. With Jennifer, we hope to learn whether public information from reputable sources could be more effectively organized and shared in the wake of a crisis as well as to understand issues that the public were most immediately curious about. In this paper, we introduce Jennifer and describe the design of this proof-of-principle system. We also present lessons learned and discuss open challenges. Finally, to facilitate future research, we release COVID-19 Question Bank, a dataset of 3,924 COVID-19-related questions in 944 groups, gathered from our users and volunteers.</abstract>
      <url hash="375d78fd">2020.nlpcovid19-acl.9</url>
      <bibkey>li-etal-2020-jennifer</bibkey>
    </paper>
    <paper id="10">
      <title>A Natural Language Processing System for National <fixed-case>COVID-19</fixed-case> Surveillance in the <fixed-case>US Department of Veterans Affairs</fixed-case></title>
      <author><first>Alec</first><last>Chapman</last></author>
      <author><first>Kelly</first><last>Peterson</last></author>
      <author><first>Augie</first><last>Turano</last></author>
      <author><first>Tamára</first><last>Box</last></author>
      <author><first>Katherine</first><last>Wallace</last></author>
      <author><first>Makoto</first><last>Jones</last></author>
      <abstract>Timely and accurate accounting of positive cases has been an important part of the response to the COVID-19 pandemic. While most positive cases within Veterans Affairs (VA) are identified through structured laboratory results, some patients are tested or diagnosed outside VA so their clinical status is documented only in free-text narratives. We developed a Natural Language Processing pipeline for identifying positively diagnosed COVID19 patients and deployed this system to accelerate chart review. As part of the VA national response to COVID-19, this process identified 6,360 positive cases which did not have corresponding laboratory data. These cases accounted for 36.1% of total confirmed positive cases in VA to date. With available data, performance of the system is estimated as 82.4% precision and 94.2% recall. A public-facing implementation is released as open source and available to the community.</abstract>
      <url hash="cf291cd4">2020.nlpcovid19-acl.10</url>
      <bibkey>chapman-etal-2020-natural</bibkey>
      <pwccode url="https://github.com/abchapman93/VA_COVID-19_NLP_BSV" additional="false">abchapman93/VA_COVID-19_NLP_BSV</pwccode>
    </paper>
    <paper id="11">
      <title>Measuring <fixed-case>Emotions</fixed-case> in the <fixed-case>COVID</fixed-case>-19 <fixed-case>Real</fixed-case> <fixed-case>World</fixed-case> <fixed-case>Worry</fixed-case> <fixed-case>Dataset</fixed-case></title>
      <author><first>Bennett</first><last>Kleinberg</last></author>
      <author><first>Isabelle</first><last>van der Vegt</last></author>
      <author><first>Maximilian</first><last>Mozes</last></author>
      <abstract>The COVID-19 pandemic is having a dramatic impact on societies and economies around the world. With various measures of lockdowns and social distancing in place, it becomes important to understand emotional responses on a large scale. In this paper, we present the first ground truth dataset of emotional responses to COVID-19. We asked participants to indicate their emotions and express these in text. This resulted in the Real World Worry Dataset of 5,000 texts (2,500 short + 2,500 long texts). Our analyses suggest that emotional responses correlated with linguistic measures. Topic modeling further revealed that people in the UK worry about their family and the economic situation. Tweet-sized texts functioned as a call for solidarity, while longer texts shed light on worries and concerns. Using predictive modeling approaches, we were able to approximate the emotional responses of participants from text within 14% of their actual value. We encourage others to use the dataset and improve how we can use automated methods to learn about emotional responses and worries about an urgent problem.</abstract>
      <url hash="3d5f99d0">2020.nlpcovid19-acl.11</url>
      <bibkey>kleinberg-etal-2020-measuring</bibkey>
      <pwccode url="https://github.com/ben-aaron188/covid19worry" additional="true">ben-aaron188/covid19worry</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/rwwd">RWWD</pwcdataset>
    </paper>
    <paper id="12">
      <title>Estimating the effect of <fixed-case>COVID-19</fixed-case> on mental health: Linguistic indicators of depression during a global pandemic</title>
      <author><first>JT</first><last>Wolohan</last></author>
      <abstract>This preliminary analysis uses a deep LSTM neural network with fastText embeddings to predict population rates of depression on Reddit in order to estimate the effect of COVID-19 on mental health. We find that year over year, depression rates on Reddit are up 50% , suggesting a 15-million person increase in the number of depressed Americans and a $7.5 billion increase in depression related spending. This finding suggests that utility in NLP approaches to longitudinal public-health surveillance.</abstract>
      <url hash="9bd09de3">2020.nlpcovid19-acl.12</url>
      <bibkey>wolohan-2020-estimating</bibkey>
    </paper>
    <paper id="13">
      <title>Exploration of Gender Differences in <fixed-case>COVID-19</fixed-case> Discourse on <fixed-case>R</fixed-case>eddit</title>
      <author><first>Jai</first><last>Aggarwal</last></author>
      <author><first>Ella</first><last>Rabinovich</last></author>
      <author><first>Suzanne</first><last>Stevenson</last></author>
      <abstract>Decades of research on differences in the language of men and women have established postulates about the nature of lexical, topical, and emotional preferences between the two genders, along with their sociological underpinnings. Using a novel dataset of male and female linguistic productions collected from the Reddit discussion platform, we further confirm existing assumptions about gender-linked affective distinctions, and demonstrate that these distinctions are amplified in social media postings involving emotionally-charged discourse related to COVID-19. Our analysis also confirms considerable differences in topical preferences between male and female authors in pandemic-related discussions.</abstract>
      <url hash="a2380764">2020.nlpcovid19-acl.13</url>
      <bibkey>aggarwal-etal-2020-exploration</bibkey>
      <pwccode url="https://github.com/ellarabi/covid19-demography" additional="false">ellarabi/covid19-demography</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/rwwd">RWWD</pwcdataset>
    </paper>
    <paper id="14">
      <title>Cross-language sentiment analysis of <fixed-case>European</fixed-case> <fixed-case>Twitter</fixed-case> messages during the <fixed-case>COVID-19</fixed-case> pandemic</title>
      <author><first>Anna</first><last>Kruspe</last></author>
      <author><first>Matthias</first><last>Häberle</last></author>
      <author><first>Iona</first><last>Kuhn</last></author>
      <author><first>Xiao Xiang</first><last>Zhu</last></author>
      <abstract>In this paper, we analyze Twitter messages (tweets) collected during the first months of the COVID-19 pandemic in Europe with regard to their sentiment. This is implemented with a neural network for sentiment analysis using multilingual sentence embeddings. We separate the results by country of origin, and correlate their temporal development with events in those countries. This allows us to study the effect of the situation on people’s moods. We see, for example, that lockdown announcements correlate with a deterioration of mood in almost all surveyed countries, which recovers within a short time span.</abstract>
      <url hash="10474aa7">2020.nlpcovid19-acl.14</url>
      <bibkey>kruspe-etal-2020-cross</bibkey>
    </paper>
    <paper id="15">
      <title>Cross-lingual Transfer Learning for <fixed-case>COVID-19</fixed-case> Outbreak Alignment</title>
      <author><first>Sharon</first><last>Levy</last></author>
      <author><first>William Yang</first><last>Wang</last></author>
      <abstract>The spread of COVID-19 has become a significant and troubling aspect of society in 2020. With millions of cases reported across countries, new outbreaks have occurred and followed patterns of previously affected areas. Many disease detection models do not incorporate the wealth of social media data that can be utilized for modeling and predicting its spread. It is useful to ask, can we utilize this knowledge in one country to model the outbreak in another? To answer this, we propose the task of cross-lingual transfer learning for epidemiological alignment. Utilizing both macro and micro text features, we train on Italy’s early COVID-19 outbreak through Twitter and transfer to several other countries. Our experiments show strong results with up to 0.85 Spearman correlation in cross-country predictions.</abstract>
      <url hash="b944647e">2020.nlpcovid19-acl.15</url>
      <bibkey>levy-wang-2020-cross</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>COVID-19</fixed-case> and <fixed-case>Arabic</fixed-case> <fixed-case>Twitter</fixed-case>: How can <fixed-case>Arab</fixed-case> World Governments and Public Health Organizations Learn from Social Media?</title>
      <author><first>Lama</first><last>Alsudias</last></author>
      <author><first>Paul</first><last>Rayson</last></author>
      <abstract>In March 2020, the World Health Organization announced the COVID-19 outbreak as a pandemic. Most previous social media related research has been on English tweets and COVID-19. In this study, we collect approximately 1 million Arabic tweets from the Twitter streaming API related to COVID-19. Focussing on outcomes that we believe will be useful for Public Health Organizations, we analyse them in three different ways: identifying the topics discussed during the period, detecting rumours, and predicting the source of the tweets. We use the k-means algorithm for the first goal with k=5. The topics discussed can be grouped as follows: COVID-19 statistics, prayers for God, COVID-19 locations, advise and education for prevention, and advertising. We sample 2000 tweets and label them manually for false information, correct information, and unrelated. Then, we apply three different machine learning algorithms, Logistic Regression, Support Vector Classification, and Naïve Bayes with two sets of features, word frequency approach and word embeddings. We find that Machine Learning classifiers are able to correctly identify the rumour related tweets with 84% accuracy. We also try to predict the source of the rumour related tweets depending on our previous model which is about classifying tweets into five categories: academic, media, government, health professional, and public. Around (60%) of the rumour related tweets are classified as written by health professionals and academics.</abstract>
      <url hash="f2d170a8">2020.nlpcovid19-acl.16</url>
      <bibkey>alsudias-rayson-2020-covid</bibkey>
    </paper>
    <paper id="17">
      <title><fixed-case>NLP</fixed-case>-based Feature Extraction for the Detection of <fixed-case>COVID</fixed-case>-19 Misinformation Videos on <fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube</title>
      <author><first>Juan Carlos</first><last>Medina Serrano</last></author>
      <author><first>Orestis</first><last>Papakyriakopoulos</last></author>
      <author><first>Simon</first><last>Hegelich</last></author>
      <abstract>We present a simple NLP methodology for detecting COVID-19 misinformation videos on YouTube by leveraging user comments. We use transfer learning pre-trained models to generate a multi-label classifier that can categorize conspiratorial content. We use the percentage of misinformation comments on each video as a new feature for video classification.</abstract>
      <url hash="2520463f">2020.nlpcovid19-acl.17</url>
      <bibkey>medina-serrano-etal-2020-nlp</bibkey>
      <pwccode url="https://github.com/JuanCarlosCSE/YouTube_misinfo" additional="false">JuanCarlosCSE/YouTube_misinfo</pwccode>
    </paper>
    <paper id="18">
      <title><fixed-case>COVID-QA</fixed-case>: A Question Answering Dataset for <fixed-case>COVID</fixed-case>-19</title>
      <author><first>Timo</first><last>Möller</last></author>
      <author><first>Anthony</first><last>Reina</last></author>
      <author><first>Raghavan</first><last>Jayakumar</last></author>
      <author><first>Malte</first><last>Pietsch</last></author>
      <abstract>We present COVID-QA, a Question Answering dataset consisting of 2,019 question/answer pairs annotated by volunteer biomedical experts on scientific articles related to COVID-19. To evaluate the dataset we compared a RoBERTa base model fine-tuned on SQuAD with the same model trained on SQuAD and our COVID-QA dataset. We found that the additional training on this domain-specific data leads to significant gains in performance. Both the trained model and the annotated dataset have been open-sourced at: https://github.com/deepset-ai/COVID-QA</abstract>
      <url hash="8552b8ac">2020.nlpcovid19-acl.18</url>
      <bibkey>moller-etal-2020-covid</bibkey>
      <pwccode url="https://github.com/deepset-ai/COVID-QA" additional="false">deepset-ai/COVID-QA</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
    </paper>
  </volume>
  <volume id="2" ingest-date="2020-11-06">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on <fixed-case>NLP</fixed-case> for <fixed-case>COVID</fixed-case>-19 (Part 2) at <fixed-case>EMNLP</fixed-case> 2020</booktitle>
      <editor><first>Karin</first><last>Verspoor</last></editor>
      <editor><first>Kevin Bretonnel</first><last>Cohen</last></editor>
      <editor><first>Michael</first><last>Conway</last></editor>
      <editor><first>Berry</first><last>de Bruijn</last></editor>
      <editor><first>Mark</first><last>Dredze</last></editor>
      <editor><first>Rada</first><last>Mihalcea</last></editor>
      <editor><first>Byron</first><last>Wallace</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>December</month>
      <year>2020</year>
      <venue>nlpcovid19</venue>
    </meta>
    <frontmatter>
      <url hash="27ecd857">2020.nlpcovid19-2.0</url>
      <bibkey>nlp-covid19-2020-nlp-covid</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Answering Questions on <fixed-case>COVID</fixed-case>-19 in Real-Time</title>
      <author><first>Jinhyuk</first><last>Lee</last></author>
      <author><first>Sean S.</first><last>Yi</last></author>
      <author><first>Minbyul</first><last>Jeong</last></author>
      <author><first>Mujeen</first><last>Sung</last></author>
      <author><first>WonJin</first><last>Yoon</last></author>
      <author><first>Yonghwa</first><last>Choi</last></author>
      <author><first>Miyoung</first><last>Ko</last></author>
      <author><first>Jaewoo</first><last>Kang</last></author>
      <abstract>The recent outbreak of the novel coronavirus is wreaking havoc on the world and researchers are struggling to effectively combat it. One reason why the fight is difficult is due to the lack of information and knowledge. In this work, we outline our effort to contribute to shrinking this knowledge vacuum by creating covidAsk, a question answering (QA) system that combines biomedical text mining and QA techniques to provide answers to questions in real-time. Our system also leverages information retrieval (IR) approaches to provide entity-level answers that are complementary to QA models. Evaluation of covidAsk is carried out by using a manually created dataset called COVID-19 Questions which is based on information from various sources, including the CDC and the WHO. We hope our system will be able to aid researchers in their search for knowledge and information not only for COVID-19, but for future pandemics as well.</abstract>
      <url hash="05624108">2020.nlpcovid19-2.1</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.1</doi>
      <video href="https://slideslive.com/38939843"/>
      <bibkey>lee-etal-2020-answering</bibkey>
      <pwccode url="https://github.com/dmis-lab/covidAsk" additional="false">dmis-lab/covidAsk</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cord-19">CORD-19</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/natural-questions">Natural Questions</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/squad">SQuAD</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/trec-covid">TREC-COVID</pwcdataset>
    </paper>
    <paper id="2">
      <title><fixed-case>CORA</fixed-case>: A Deep Active Learning Covid-19 Relevancy Algorithm to Identify Core Scientific Articles</title>
      <author><first>Zubair</first><last>Afzal</last></author>
      <author><first>Vikrant</first><last>Yadav</last></author>
      <author><first>Olga</first><last>Fedorova</last></author>
      <author><first>Vaishnavi</first><last>Kandala</last></author>
      <author><first>Janneke</first><last>van de Loo</last></author>
      <author><first>Saber A.</first><last>Akhondi</last></author>
      <author><first>Pascal</first><last>Coupet</last></author>
      <author><first>George</first><last>Tsatsaronis</last></author>
      <abstract>Ever since the COVID-19 pandemic broke out, the academic and scientific research community, as well as industry and governments around the world have joined forces in an unprecedented manner to fight the threat. Clinicians, biologists, chemists, bioinformaticians, nurses, data scientists, and all of the affiliated relevant disciplines have been mobilized to help discover efficient treatments for the infected population, as well as a vaccine solution to prevent further the virus spread. In this combat against the virus responsible for the pandemic, key for any advancements is the timely, accurate, peer-reviewed, and efficient communication of any novel research findings. In this paper we present a novel framework to address the information need of filtering efficiently the scientific bibliography for relevant literature around COVID-19. The contributions of the paper are summarized in the following: we define and describe the information need that encompasses the major requirements for COVID-19 articles relevancy, we present and release an expert-curated benchmark set for the task, and we analyze the performance of several state-of-the-art machine learning classifiers that may distinguish the relevant from the non-relevant COVID-19 literature.</abstract>
      <url hash="69f2481e">2020.nlpcovid19-2.2</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.2</doi>
      <video href="https://slideslive.com/38939846"/>
      <bibkey>afzal-etal-2020-cora</bibkey>
    </paper>
    <paper id="3">
      <title>Frugal neural reranking: evaluation on the Covid-19 literature</title>
      <author><first>Tiago</first><last>Almeida</last></author>
      <author><first>Sérgio</first><last>Matos</last></author>
      <abstract>The Covid-19 pandemic urged the scientific community to join efforts at an unprecedented scale, leading to faster than ever dissemination of data and results, which in turn motivated more research works. This paper presents and discusses information retrieval models aimed at addressing the challenge of searching the large number of publications that stem from these studies. The model presented, based on classical baselines followed by an interaction based neural ranking model, was evaluated and evolved within the TREC Covid challenge setting. Results on this dataset show that, when starting with a strong baseline, our light neural ranking model can achieve results that are comparable to other model architectures that use very large number of parameters.</abstract>
      <url hash="228d89ee">2020.nlpcovid19-2.3</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.3</doi>
      <video href="https://slideslive.com/38939845"/>
      <bibkey>almeida-matos-2020-frugal</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cord-19">CORD-19</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/trec-covid">TREC-COVID</pwcdataset>
    </paper>
    <paper id="4">
      <title><fixed-case>COVID</fixed-case>-19 Literature Topic-Based Search via Hierarchical <fixed-case>NMF</fixed-case></title>
      <author><first>Rachel</first><last>Grotheer</last></author>
      <author><first>Longxiu</first><last>Huang</last></author>
      <author><first>Yihuan</first><last>Huang</last></author>
      <author><first>Alona</first><last>Kryshchenko</last></author>
      <author><first>Oleksandr</first><last>Kryshchenko</last></author>
      <author><first>Pengyu</first><last>Li</last></author>
      <author><first>Xia</first><last>Li</last></author>
      <author><first>Elizaveta</first><last>Rebrova</last></author>
      <author><first>Kyung</first><last>Ha</last></author>
      <author><first>Deanna</first><last>Needell</last></author>
      <abstract>A dataset of COVID-19-related scientific literature is compiled, combining the articles from several online libraries and selecting those with open access and full text available. Then, hierarchical nonnegative matrix factorization is used to organize literature related to the novel coronavirus into a tree structure that allows researchers to search for relevant literature based on detected topics. We discover eight major latent topics and 52 granular subtopics in the body of literature, related to vaccines, genetic structure and modeling of the disease and patient studies, as well as related diseases and virology. In order that our tool may help current researchers, an interactive website is created that organizes available literature using this hierarchical structure.</abstract>
      <url hash="d807d8ef">2020.nlpcovid19-2.4</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.4</doi>
      <video href="https://slideslive.com/38939856"/>
      <bibkey>grotheer-etal-2020-covid</bibkey>
    </paper>
    <paper id="5">
      <title><fixed-case>TICO</fixed-case>-19: the Translation Initiative for <fixed-case>CO</fixed-case>vid-19</title>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <author><first>Alessandro</first><last>Cattelan</last></author>
      <author><first>Zi-Yi</first><last>Dou</last></author>
      <author><first>Marcello</first><last>Federico</last></author>
      <author><first>Christian</first><last>Federmann</last></author>
      <author><first>Dmitriy</first><last>Genzel</last></author>
      <author><first>Franscisco</first><last>Guzmán</last></author>
      <author><first>Junjie</first><last>Hu</last></author>
      <author><first>Macduff</first><last>Hughes</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <author><first>Rosie</first><last>Lazar</last></author>
      <author><first>Will</first><last>Lewis</last></author>
      <author><first>Graham</first><last>Neubig</last></author>
      <author><first>Mengmeng</first><last>Niu</last></author>
      <author><first>Alp</first><last>Öktem</last></author>
      <author><first>Eric</first><last>Paquin</last></author>
      <author><first>Grace</first><last>Tang</last></author>
      <author><first>Sylwia</first><last>Tur</last></author>
      <abstract>The COVID-19 pandemic is the worst pandemic to strike the world in over a century. Crucial to stemming the tide of the SARS-CoV-2 virus is communicating to vulnerable populations the means by which they can protect themselves. To this end, the collaborators forming the Translation Initiative for COvid-19 (TICO-19) have made test and development data available to AI and MT researchers in 35 different languages in order to foster the development of tools and resources for improving access to information about COVID-19 in these languages. In addition to 9 high-resourced, ”pivot” languages, the team is targeting 26 lesser resourced languages, in particular languages of Africa, South Asia and South-East Asia, whose populations may be the most vulnerable to the spread of the virus. The same data is translated into all of the languages represented, meaning that testing or development can be done for any pairing of languages in the set. Further, the team is converting the test and development data into translation memories (TMXs) that can be used by localizers from and to any of the languages.</abstract>
      <url hash="69a14574">2020.nlpcovid19-2.5</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.5</doi>
      <video href="https://slideslive.com/38939854"/>
      <bibkey>anastasopoulos-etal-2020-tico</bibkey>
    </paper>
    <paper id="6">
      <title>Expressive Interviewing: A Conversational System for Coping with <fixed-case>COVID</fixed-case>-19</title>
      <author><first>Charles</first><last>Welch</last></author>
      <author><first>Allison</first><last>Lahnala</last></author>
      <author><first>Veronica</first><last>Perez-Rosas</last></author>
      <author><first>Siqi</first><last>Shen</last></author>
      <author><first>Sarah</first><last>Seraj</last></author>
      <author><first>Larry</first><last>An</last></author>
      <author><first>Kenneth</first><last>Resnicow</last></author>
      <author><first>James</first><last>Pennebaker</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <abstract>The ongoing COVID-19 pandemic has raised concerns for many regarding personal and public health implications, financial security and economic stability. Alongside many other unprecedented challenges, there are increasing concerns over social isolation and mental health. We introduce Expressive Interviewing – an interview-style conversational system that draws on ideas from motivational interviewing and expressive writing. Expressive Interviewing seeks to encourage users to express their thoughts and feelings through writing by asking them questions about how COVID-19 has impacted their lives. We present relevant aspects of the system’s design and implementation as well as quantitative and qualitative analyses of user interactions with the system. In addition, we conduct a comparative evaluation with a general purpose dialogue system for mental health that shows our system potential in helping users to cope with COVID-19 issues.</abstract>
      <url hash="1a68441c">2020.nlpcovid19-2.6</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.6</doi>
      <video href="https://slideslive.com/38939850"/>
      <bibkey>welch-etal-2020-expressive</bibkey>
    </paper>
    <paper id="7">
      <title>Temporal Mental Health Dynamics on Social Media</title>
      <author><first>Tom</first><last>Tabak</last></author>
      <author><first>Matthew</first><last>Purver</last></author>
      <abstract>We describe a set of experiments for building a temporal mental health dynamics system. We utilise a pre-existing methodology for distant- supervision of mental health data mining from social media platforms and deploy the system during the global COVID-19 pandemic as a case study. Despite the challenging nature of the task, we produce encouraging results, both explicit to the global pandemic and implicit to a global phenomenon, Christmas Depres- sion, supported by the literature. We propose a methodology for providing insight into tem- poral mental health dynamics to be utilised for strategic decision-making.</abstract>
      <url hash="bf433642">2020.nlpcovid19-2.7</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.7</doi>
      <video href="https://slideslive.com/38939853"/>
      <bibkey>tabak-purver-2020-temporal</bibkey>
    </paper>
    <paper id="8">
      <title>Quantifying the Effects of <fixed-case>COVID</fixed-case>-19 on Mental Health Support Forums</title>
      <author><first>Laura</first><last>Biester</last></author>
      <author><first>Katie</first><last>Matton</last></author>
      <author><first>Janarthanan</first><last>Rajendran</last></author>
      <author><first>Emily Mower</first><last>Provost</last></author>
      <author><first>Rada</first><last>Mihalcea</last></author>
      <abstract>The COVID-19 pandemic, like many of the disease outbreaks that have preceded it, is likely to have a profound effect on mental health. Understanding its impact can inform strategies for mitigating negative consequences. In this work, we seek to better understand the effects of COVID-19 on mental health by examining discussions within mental health support communities on Reddit. First, we quantify the rate at which COVID-19 is discussed in each community, or subreddit, in order to understand levels of pandemic-related discussion. Next, we examine the volume of activity in order to determine whether the number of people discussing mental health has risen. Finally, we analyze how COVID-19 has influenced language use and topics of discussion within each subreddit.</abstract>
      <url hash="8cb6aca4">2020.nlpcovid19-2.8</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.8</doi>
      <video href="https://slideslive.com/38939847"/>
      <bibkey>biester-etal-2020-quantifying</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>COVID</fixed-case>-19 Surveillance through <fixed-case>T</fixed-case>witter using Self-Supervised and Few Shot Learning</title>
      <author><first>Brandon</first><last>Lwowski</last></author>
      <author><first>Peyman</first><last>Najafirad</last></author>
      <abstract>Public health surveillance and tracking virus via social media can be a useful digital tool for contact tracing and preventing the spread of the virus. Nowadays, large volumes of COVID-19 tweets can quickly be processed in real-time to offer information to researchers. Nonetheless, due to the absence of labeled data for COVID-19, the preliminary supervised classifier or semi-supervised self-labeled methods will not handle non-spherical data with adequate accuracy. With the seasonal influenza and novel Coronavirus having many similar symptoms, we propose using few shot learning to fine-tune a semi-supervised model built on unlabeled COVID-19 and previously labeled influenza dataset that can provide in- sights into COVID-19 that have not been investigated. The experimental results show the efficacy of the proposed model with an accuracy of 86%, identification of Covid-19 related discussion using recently collected tweets.</abstract>
      <url hash="8298be59">2020.nlpcovid19-2.9</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.9</doi>
      <bibkey>lwowski-najafirad-2020-covid</bibkey>
    </paper>
    <paper id="10">
      <title>Explaining the Trump Gap in Social Distancing Using <fixed-case>COVID</fixed-case> Discourse</title>
      <author><first>Austin Van</first><last>Loon</last></author>
      <author><first>Sheridan</first><last>Stewart</last></author>
      <author><first>Brandon</first><last>Waldon</last></author>
      <author><first>Shrinidhi K</first><last>Lakshmikanth</last></author>
      <author><first>Ishan</first><last>Shah</last></author>
      <author><first>Sharath Chandra</first><last>Guntuku</last></author>
      <author><first>Garrick</first><last>Sherman</last></author>
      <author><first>James</first><last>Zou</last></author>
      <author><first>Johannes</first><last>Eichstaedt</last></author>
      <abstract>Our ability to limit the future spread of COVID-19 will in part depend on our understanding of the psychological and sociological processes that lead people to follow or reject coronavirus health behaviors. We argue that the virus has taken on heterogeneous meanings in communities across the United States and that these disparate meanings shaped communities’ response to the virus during the early, vital stages of the outbreak in the U.S. Using word embeddings, we demonstrate that counties where residents socially distanced less on average (as measured by residential mobility) more semantically associated the virus in their COVID discourse with concepts of fraud, the political left, and more benign illnesses like the flu. We also show that the different meanings the virus took on in different communities explains a substantial fraction of what we call the “”Trump Gap”, or the empirical tendency for more Trump-supporting counties to socially distance less. This work demonstrates that community-level processes of meaning-making in part determined behavioral responses to the COVID-19 pandemic and that these processes can be measured unobtrusively using Twitter.</abstract>
      <url hash="354be9b1">2020.nlpcovid19-2.10</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.10</doi>
      <bibkey>loon-etal-2020-explaining</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>COVIDL</fixed-case>ies: Detecting <fixed-case>COVID</fixed-case>-19 Misinformation on Social Media</title>
      <author><first>Tamanna</first><last>Hossain</last></author>
      <author><first>Robert L.</first><last>Logan IV</last></author>
      <author><first>Arjuna</first><last>Ugarte</last></author>
      <author><first>Yoshitomo</first><last>Matsubara</last></author>
      <author><first>Sean</first><last>Young</last></author>
      <author><first>Sameer</first><last>Singh</last></author>
      <abstract>The ongoing pandemic has heightened the need for developing tools to flag COVID-19-related misinformation on the internet, specifically on social media such as Twitter. However, due to novel language and the rapid change of information, existing misinformation detection datasets are not effective for evaluating systems designed to detect misinformation on this topic. Misinformation detection can be divided into two sub-tasks: (i) retrieval of misconceptions relevant to posts being checked for veracity, and (ii) stance detection to identify whether the posts Agree, Disagree, or express No Stance towards the retrieved misconceptions. To facilitate research on this task, we release COVIDLies (https://ucinlp.github.io/covid19 ), a dataset of 6761 expert-annotated tweets to evaluate the performance of misinformation detection systems on 86 different pieces of COVID-19 related misinformation. We evaluate existing NLP systems on this dataset, providing initial benchmarks and identifying key challenges for future models to improve upon.</abstract>
      <url hash="b9655333">2020.nlpcovid19-2.11</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.11</doi>
      <video href="https://slideslive.com/38939851"/>
      <bibkey>hossain-etal-2020-covidlies</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
    </paper>
    <paper id="12">
      <title>Improved Topic Representations of Medical Documents to Assist <fixed-case>COVID</fixed-case>-19 Literature Exploration</title>
      <author><first>Yulia</first><last>Otmakhova</last></author>
      <author><first>Karin</first><last>Verspoor</last></author>
      <author><first>Timothy</first><last>Baldwin</last></author>
      <author><first>Simon</first><last>Šuster</last></author>
      <abstract>Efficient discovery and exploration of biomedical literature has grown in importance in the context of the COVID-19 pandemic, and topic-based methods such as latent Dirichlet allocation (LDA) are a useful tool for this purpose. In this study we compare traditional topic models based on word tokens with topic models based on medical concepts, and propose several ways to improve topic coherence and specificity.</abstract>
      <url hash="4bee2d49">2020.nlpcovid19-2.12</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.12</doi>
      <video href="https://slideslive.com/38939857"/>
      <bibkey>otmakhova-etal-2020-improved</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cord-19">CORD-19</pwcdataset>
    </paper>
    <paper id="13">
      <title>A System for Worldwide <fixed-case>COVID</fixed-case>-19 Information Aggregation</title>
      <author><first>Akiko</first><last>Aizawa</last></author>
      <author><first>Frederic</first><last>Bergeron</last></author>
      <author><first>Junjie</first><last>Chen</last></author>
      <author><first>Fei</first><last>Cheng</last></author>
      <author><first>Katsuhiko</first><last>Hayashi</last></author>
      <author><first>Kentaro</first><last>Inui</last></author>
      <author><first>Hiroyoshi</first><last>Ito</last></author>
      <author><first>Daisuke</first><last>Kawahara</last></author>
      <author><first>Masaru</first><last>Kitsuregawa</last></author>
      <author><first>Hirokazu</first><last>Kiyomaru</last></author>
      <author><first>Masaki</first><last>Kobayashi</last></author>
      <author><first>Takashi</first><last>Kodama</last></author>
      <author><first>Sadao</first><last>Kurohashi</last></author>
      <author><first>Qianying</first><last>Liu</last></author>
      <author><first>Masaki</first><last>Matsubara</last></author>
      <author><first>Yusuke</first><last>Miyao</last></author>
      <author><first>Atsuyuki</first><last>Morishima</last></author>
      <author><first>Yugo</first><last>Murawaki</last></author>
      <author><first>Kazumasa</first><last>Omura</last></author>
      <author><first>Haiyue</first><last>Song</last></author>
      <author><first>Eiichiro</first><last>Sumita</last></author>
      <author><first>Shinji</first><last>Suzuki</last></author>
      <author><first>Ribeka</first><last>Tanaka</last></author>
      <author><first>Yu</first><last>Tanaka</last></author>
      <author><first>Masashi</first><last>Toyoda</last></author>
      <author><first>Nobuhiro</first><last>Ueda</last></author>
      <author><first>Honai</first><last>Ueoka</last></author>
      <author><first>Masao</first><last>Utiyama</last></author>
      <author><first>Ying</first><last>Zhong</last></author>
      <abstract>The global pandemic of COVID-19 has made the public pay close attention to related news, covering various domains, such as sanitation, treatment, and effects on education. Meanwhile, the COVID-19 condition is very different among the countries (e.g., policies and development of the epidemic), and thus citizens would be interested in news in foreign countries. We build a system for worldwide COVID-19 information aggregation containing reliable articles from 10 regions in 7 languages sorted by topics. Our reliable COVID-19 related website dataset collected through crowdsourcing ensures the quality of the articles. A neural machine translation module translates articles in other languages into Japanese and English. A BERT-based topic-classifier trained on our article-topic pair dataset helps users find their interested information efficiently by putting articles into different categories.</abstract>
      <url hash="32e7dbc3">2020.nlpcovid19-2.13</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.13</doi>
      <video href="https://slideslive.com/38939852"/>
      <bibkey>aizawa-etal-2020-system</bibkey>
    </paper>
    <paper id="14">
      <title><fixed-case>CA</fixed-case>i<fixed-case>RE</fixed-case>-<fixed-case>COVID</fixed-case>: A Question Answering and Query-focused Multi-Document Summarization System for <fixed-case>COVID</fixed-case>-19 Scholarly Information Management</title>
      <author><first>Dan</first><last>Su</last></author>
      <author><first>Yan</first><last>Xu</last></author>
      <author><first>Tiezheng</first><last>Yu</last></author>
      <author><first>Farhad Bin</first><last>Siddique</last></author>
      <author><first>Elham</first><last>Barezi</last></author>
      <author><first>Pascale</first><last>Fung</last></author>
      <abstract>We present CAiRE-COVID, a real-time question answering (QA) and multi-document summarization system, which won one of the 10 tasks in the Kaggle COVID-19 Open Research Dataset Challenge, judged by medical experts. Our system aims to tackle the recent challenge of mining the numerous scientific articles being published on COVID-19 by answering high priority questions from the community and summarizing salient question-related information. It combines information extraction with state-of-the-art QA and query-focused multi-document summarization techniques, selecting and highlighting evidence snippets from existing literature given a query. We also propose query-focused abstractive and extractive multi-document summarization methods, to provide more relevant information related to the question. We further conduct quantitative experiments that show consistent improvements on various metrics for each module. We have launched our website CAiRE-COVID for broader use by the medical community, and have open-sourced the code for our system, to bootstrap further study by other researches.</abstract>
      <url hash="af6d574b">2020.nlpcovid19-2.14</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.14</doi>
      <video href="https://slideslive.com/38939844"/>
      <bibkey>su-etal-2020-caire</bibkey>
      <pwccode url="https://github.com/HLTCHKUST/CAiRE-COVID" additional="false">HLTCHKUST/CAiRE-COVID</pwccode>
    </paper>
    <paper id="15">
      <title>Automatic Evaluation vs. User Preference in Neural Textual <fixed-case>Q</fixed-case>uestion<fixed-case>A</fixed-case>nswering over <fixed-case>COVID</fixed-case>-19 Scientific Literature</title>
      <author><first>Arantxa</first><last>Otegi</last></author>
      <author><first>Jon Ander</first><last>Campos</last></author>
      <author><first>Gorka</first><last>Azkune</last></author>
      <author><first>Aitor</first><last>Soroa</last></author>
      <author><first>Eneko</first><last>Agirre</last></author>
      <abstract>We present a Question Answering (QA) system that won one of the tasks of the Kaggle CORD-19 Challenge, according to the qualitative evaluation of experts. The system is a combination of an Information Retrieval module and a reading comprehension module that finds the answers in the retrieved passages. In this paper we present a quantitative and qualitative analysis of the system. The quantitative evaluation using manually annotated datasets contradicted some of our design choices, e.g. the fact that using QuAC for fine-tuning provided better answers over just using SQuAD. We analyzed this mismatch with an additional A/B test which showed that the system using QuAC was indeed preferred by users, confirming our intuition. Our analysis puts in question the suitability of automatic metrics and its correlation to user preferences. We also show that automatic metrics are highly dependent on the characteristics of the gold standard, such as the average length of the answers.</abstract>
      <url hash="da24810c">2020.nlpcovid19-2.15</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.15</doi>
      <video href="https://slideslive.com/38939858"/>
      <bibkey>otegi-etal-2020-automatic</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cord-19">CORD-19</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/quac">QuAC</pwcdataset>
    </paper>
    <paper id="16">
      <title>A Multilingual Neural Machine Translation Model for Biomedical Data</title>
      <author><first>Alexandre</first><last>Bérard</last></author>
      <author><first>Zae Myung</first><last>Kim</last></author>
      <author><first>Vassilina</first><last>Nikoulina</last></author>
      <author><first>Eunjeong Lucy</first><last>Park</last></author>
      <author><first>Matthias</first><last>Gallé</last></author>
      <abstract>We release a multilingual neural machine translation model, which can be used to translate text in the biomedical domain. The model can translate from 5 languages (French, German, Italian, Korean and Spanish) into English. It is trained with large amounts of generic and biomedical data, using domain tags. Our benchmarks show that it performs near state-of-the-art both on news (generic domain) and biomedical test sets, and that it outperforms the existing publicly released models. We believe that this release will help the large-scale multilingual analysis of the digital content of the COVID-19 crisis and of its effects on society, economy, and healthcare policies. We also release a test set of biomedical text for Korean-English. It consists of 758 sentences from official guidelines and recent papers, all about COVID-19.</abstract>
      <url hash="d944c234">2020.nlpcovid19-2.16</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.16</doi>
      <video href="https://slideslive.com/38939842"/>
      <bibkey>berard-etal-2020-multilingual</bibkey>
      <pwccode url="https://github.com/naver/covid19-nmt" additional="false">naver/covid19-nmt</pwccode>
    </paper>
    <paper id="17">
      <title>Public Sentiment on Governmental <fixed-case>COVID</fixed-case>-19 Measures in <fixed-case>D</fixed-case>utch Social Media</title>
      <author><first>Shihan</first><last>Wang</last></author>
      <author><first>Marijn</first><last>Schraagen</last></author>
      <author><first>Erik</first><last>Tjong Kim Sang</last></author>
      <author><first>Mehdi</first><last>Dastani</last></author>
      <abstract>Public sentiment (the opinion, attitude or feeling that the public expresses) is a factor of interest for government, as it directly influences the implementation of policies. Given the unprecedented nature of the COVID-19 crisis, having an up-to-date representation of public sentiment on governmental measures and announcements is crucial. In this paper, we analyse Dutch public sentiment on governmental COVID-19 measures from text data collected across three online media sources (Twitter, Reddit and Nu.nl) from February to September 2020. We apply sentiment analysis methods to analyse polarity over time, as well as to identify stance towards two specific pandemic policies regarding social distancing and wearing face masks. The presented preliminary results provide valuable insights into the narratives shown in vast social media text data, which help understand the influence of COVID-19 measures on the general public.</abstract>
      <url hash="d680dc23">2020.nlpcovid19-2.17</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.17</doi>
      <video href="https://slideslive.com/38939855"/>
      <bibkey>wang-etal-2020-public</bibkey>
    </paper>
    <paper id="18">
      <title>Exploratory Analysis of <fixed-case>COVID</fixed-case>-19 Related Tweets in <fixed-case>N</fixed-case>orth <fixed-case>A</fixed-case>merica to Inform Public Health Institutes</title>
      <author><first>Hyeju</first><last>Jang</last></author>
      <author><first>Emily</first><last>Rempel</last></author>
      <author><first>Giuseppe</first><last>Carenini</last></author>
      <author><first>Naveed</first><last>Janjua</last></author>
      <abstract>Social media is a rich source where we can learn about people’s reactions to social issues. As COVID-19 has significantly impacted on people’s lives, it is essential to capture how people react to public health interventions and understand their concerns. In this paper, we aim to investigate people’s reactions and concerns about COVID-19 in North America, especially focusing on Canada. We analyze COVID-19 related tweets using topic modeling and aspect-based sentiment analysis, and interpret the results with public health experts. We compare timeline of topics discussed with timing of implementation of public health interventions for COVID-19. We also examine people’s sentiment about COVID-19 related issues. We discuss how the results can be helpful for public health agencies when designing a policy for new interventions. Our work shows how Natural Language Processing (NLP) techniques could be applied to public health questions with domain expert involvement.</abstract>
      <url hash="b808e680">2020.nlpcovid19-2.18</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.18</doi>
      <video href="https://slideslive.com/38939848"/>
      <bibkey>jang-etal-2020-exploratory</bibkey>
    </paper>
    <paper id="19">
      <title><fixed-case>T</fixed-case>witter Data Augmentation for Monitoring Public Opinion on <fixed-case>COVID</fixed-case>-19 Intervention Measures</title>
      <author><first>Lin</first><last>Miao</last></author>
      <author><first>Mark</first><last>Last</last></author>
      <author><first>Marina</first><last>Litvak</last></author>
      <abstract>The COVID-19 outbreak is an ongoing worldwide pandemic that was announced as a global health crisis in March 2020. Due to the enormous challenges and high stakes of this pandemic, governments have implemented a wide range of policies aimed at containing the spread of the virus and its negative effect on multiple aspects of our life. Public responses to various intervention measures imposed over time can be explored by analyzing the social media. Due to the shortage of available labeled data for this new and evolving domain, we apply data distillation methodology to labeled datasets from related tasks and a very small manually labeled dataset. Our experimental results show that data distillation outperforms other data augmentation methods on our task.</abstract>
      <url hash="ba1547e6">2020.nlpcovid19-2.19</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.19</doi>
      <video href="https://slideslive.com/38939859"/>
      <bibkey>miao-etal-2020-twitter</bibkey>
    </paper>
    <paper id="20">
      <title><fixed-case>COVID</fixed-case>-19: A Semantic-Based Pipeline for Recommending Biomedical Entities</title>
      <author><first>Marcia Afonso</first><last>Barros</last></author>
      <author><first>Andre</first><last>Lamurias</last></author>
      <author><first>Diana</first><last>Sousa</last></author>
      <author><first>Pedro</first><last>Ruas</last></author>
      <author><first>Francisco M.</first><last>Couto</last></author>
      <abstract>With the increasing number of publications about COVID-19, it is a challenge to extract personalized knowledge suitable for each researcher. This work aims to build a new semantic-based pipeline for recommending biomedical entities to scientific researchers. To this end, we developed a pipeline that creates an implicit feedback matrix based on Named Entity Recognition (NER) on a corpus of documents, using multidisciplinary ontologies for recognizing and linking the entities. Our hypothesis is that by using ontologies from different fields in the NER phase, we can improve the results for state-of-the-art collaborative-filtering recommender systems applied to the dataset created. The tests performed using the COVID-19 Open Research Dataset (CORD-19) dataset show that when using four ontologies, the results for precision@k, for example, reach the 80%, whereas when using only one ontology, the results for precision@k drops to 20%, for the same users. Furthermore, the use of multi-fields entities may help in the discovery of new items, even if the researchers do not have items from that field in their set of preferences.</abstract>
      <url hash="921db543">2020.nlpcovid19-2.20</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.20</doi>
      <bibkey>barros-etal-2020-covid</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cord-19">CORD-19</pwcdataset>
    </paper>
    <paper id="21">
      <title>Vapur: A Search Engine to Find Related Protein - Compound Pairs in <fixed-case>COVID</fixed-case>-19 Literature</title>
      <author><first>Abdullatif</first><last>Köksal</last></author>
      <author><first>Hilal</first><last>Dönmez</last></author>
      <author><first>Rıza</first><last>Özçelik</last></author>
      <author><first>Elif</first><last>Ozkirimli</last></author>
      <author><first>Arzucan</first><last>Özgür</last></author>
      <abstract>Coronavirus Disease of 2019 (COVID-19) created dire consequences globally and triggered an intense scientific effort from different domains. The resulting publications created a huge text collection in which finding the studies related to a biomolecule of interest is challenging for general purpose search engines because the publications are rich in domain specific terminology. Here, we present Vapur: an online COVID-19 search engine specifically designed to find related protein - chemical pairs. Vapur is empowered with a relation-oriented inverted index that is able to retrieve and group studies for a query biomolecule with respect to its related entities. The inverted index of Vapur is automatically created with a BioNLP pipeline and integrated with an online user interface. The online interface is designed for the smooth traversal of the current literature by domain researchers and is publicly available at https://tabilab.cmpe.boun.edu.tr/vapur/.</abstract>
      <url hash="f78d2f74">2020.nlpcovid19-2.21</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.21</doi>
      <bibkey>koksal-etal-2020-vapur</bibkey>
      <pwccode url="https://github.com/boun-tabi/vapur" additional="false">boun-tabi/vapur</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/cord-19">CORD-19</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/genia">GENIA</pwcdataset>
    </paper>
    <paper id="22">
      <title>Knowledge Discovery in <fixed-case>COVID</fixed-case>-19 Research Literature</title>
      <author><first>Alejandro</first><last>Piad-Morffis</last></author>
      <author><first>Suilan</first><last>Estevez-Velarde</last></author>
      <author><first>Ernesto Luis</first><last>Estevanell-Valladares</last></author>
      <author><first>Yoan</first><last>Gutiérrez</last></author>
      <author><first>Andrés</first><last>Montoyo</last></author>
      <author><first>Rafael</first><last>Muñoz</last></author>
      <author><first>Yudivián</first><last>Almeida-Cruz</last></author>
      <abstract>This paper presents the preliminary results of an ongoing project that analyzes the growing body of scientific research published around the COVID-19 pandemic. In this research, a general-purpose semantic model is used to double annotate a batch of $500$ sentences that were manually selected by the researchers from the CORD-19 corpus. Afterwards, a baseline text-mining pipeline is designed and evaluated via a large batch of $100,959$ sentences. We present a qualitative analysis of the most interesting facts automatically extracted and highlight possible future lines of development. The preliminary results show that general-purpose semantic models are a useful tool for discovering fine-grained knowledge in large corpora of scientific documents.</abstract>
      <url hash="25a99692">2020.nlpcovid19-2.22</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.22</doi>
      <bibkey>piad-morffis-etal-2020-knowledge</bibkey>
    </paper>
    <paper id="23">
      <title>Identifying pandemic-related stress factors from social-media posts – <fixed-case>E</fixed-case>ffects on students and young-adults</title>
      <author><first>Sachin</first><last>Thukral</last></author>
      <author><first>Suyash</first><last>Sangwan</last></author>
      <author><first>Arnab</first><last>Chatterjee</last></author>
      <author><first>Lipika</first><last>Dey</last></author>
      <abstract>The COVID-19 pandemic has thrown natural life out of gear across the globe. Strict measures are deployed to curb the spread of the virus that is causing it, and the most effective of them have been social isolation. This has led to wide-spread gloom and depression across society but more so among the young and the elderly. There are currently more than 200 million college students in 186 countries worldwide, affected due to the pandemic. The mode of education has changed suddenly, with the rapid adaptation of e-learning, whereby teaching is undertaken remotely and on digital platforms. This study presents insights gathered from social media posts that were posted by students and young adults during the COVID times. Using statistical and NLP techniques, we analyzed the behavioural issues reported by users themselves in their posts in depression related communities on Reddit. We present methodologies to systematically analyze content using linguistic techniques to find out the stress-inducing factors. Online education, losing jobs, isolation from friends and abusive families emerge as key stress factors</abstract>
      <url hash="c77c6b47">2020.nlpcovid19-2.23</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.23</doi>
      <bibkey>thukral-etal-2020-identifying</bibkey>
    </paper>
    <paper id="24">
      <title>Tracking And Understanding Public Reaction During <fixed-case>COVID</fixed-case>-19: <fixed-case>S</fixed-case>audi <fixed-case>A</fixed-case>rabia As A Use Case</title>
      <author><first>Aseel</first><last>Addawood</last></author>
      <author><first>Alhanouf</first><last>Alsuwailem</last></author>
      <author><first>Ali</first><last>Alohali</last></author>
      <author><first>Dalal</first><last>Alajaji</last></author>
      <author><first>Mashail</first><last>Alturki</last></author>
      <author><first>Jaida</first><last>Alsuhaibani</last></author>
      <author><first>Fawziah</first><last>Aljabli</last></author>
      <abstract>The coronavirus disease of 2019 (COVID-19) has a huge impact on economies and societies around the world. While governments are taking extreme measures to reduce the spread of the virus, people are getting affected by these new measures. With restrictions like lockdown and social distancing, it became important to understand the emotional response of the public towards the pandemic. In this paper, we study the reaction of Saudi Arabia citizens towards the pandemic. We utilize a collection of Arabic tweets that were sent during 2020, primarily through hashtags that were originated from Saudi Arabia. Our results showed that people had kept a positive reaction towards the pandemic. This positive reaction was at its highest at the beginning of the COVID-19 crisis and started to decline as time passes. Overall, the results showed that people were so supportive of each other through this pandemic. This research can help researchers and policymakers in understanding the emotional effect of a pandemic on societies.</abstract>
      <url hash="2f7fda9c">2020.nlpcovid19-2.24</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.24</doi>
      <revision id="1" href="2020.nlpcovid19-2.24v1" hash="f25a00f9"/>
      <revision id="2" href="2020.nlpcovid19-2.24v2" hash="2f7fda9c" date="2021-06-03">Changed section 5.3 and figure 3, added section 6.</revision>
      <bibkey>addawood-etal-2020-tracking</bibkey>
    </paper>
    <paper id="25">
      <title>Characterizing drug mentions in <fixed-case>COVID</fixed-case>-19 <fixed-case>T</fixed-case>witter Chatter</title>
      <author><first>Ramya</first><last>Tekumalla</last></author>
      <author><first>Juan M</first><last>Banda</last></author>
      <abstract>Since the classification of COVID-19 as a global pandemic, there have been many attempts to treat and contain the virus. Although there is no specific antiviral treatment recommended for COVID-19, there are several drugs that can potentially help with symptoms. In this work, we mined a large twitter dataset of 424 million tweets of COVID-19 chatter to identify discourse around drug mentions. While seemingly a straightforward task, due to the informal nature of language use in Twitter, we demonstrate the need of machine learning alongside traditional automated methods to aid in this task. By applying these complementary methods, we are able to recover almost 15% additional data, making misspelling handling a needed task as a pre-processing step when dealing with social media data.</abstract>
      <url hash="60be302a">2020.nlpcovid19-2.25</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.25</doi>
      <bibkey>tekumalla-banda-2020-characterizing</bibkey>
    </paper>
    <paper id="26">
      <title>Content analysis of <fixed-case>P</fixed-case>ersian/<fixed-case>F</fixed-case>arsi Tweets during <fixed-case>COVID</fixed-case>-19 pandemic in <fixed-case>I</fixed-case>ran using <fixed-case>NLP</fixed-case></title>
      <author><first>Pedram</first><last>Hosseini</last></author>
      <author><first>Poorya</first><last>Hosseini</last></author>
      <author><first>David</first><last>Broniatowski</last></author>
      <abstract>Iran, along with China, South Korea, and Italy was among the countries that were hit hard in the first wave of the COVID-19 spread. Twitter is one of the widely-used online platforms by Iranians inside and abroad for sharing their opinion, thoughts, and feelings about a wide range of issues. In this study, using more than 530,000 original tweets in Persian/Farsi on COVID-19, we analyzed the topics discussed among users, who are mainly Iranians, to gauge and track the response to the pandemic and how it evolved over time. We applied a combination of manual annotation of a random sample of tweets and topic modeling tools to classify the contents and frequency of each category of topics. We identified the top 25 topics among which living experience under home quarantine emerged as a major talking point. We additionally categorized the broader content of tweets that shows satire, followed by news, is the dominant tweet type among Iranian users. While this framework and methodology can be used to track public response to ongoing developments related to COVID-19, a generalization of this framework can become a useful framework to gauge Iranian public reaction to ongoing policy measures or events locally and internationally.</abstract>
      <url hash="278a30d4">2020.nlpcovid19-2.26</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.26</doi>
      <bibkey>hosseini-etal-2020-content</bibkey>
      <pwccode url="https://github.com/phosseini/COVID19-fa" additional="false">phosseini/COVID19-fa</pwccode>
    </paper>
    <paper id="27">
      <title>Annotating the Pandemic: Named Entity Recognition and Normalisation in <fixed-case>COVID</fixed-case>-19 Literature</title>
      <author><first>Nico</first><last>Colic</last></author>
      <author><first>Lenz</first><last>Furrer</last></author>
      <author><first>Fabio</first><last>Rinaldi</last></author>
      <abstract>The COVID-19 pandemic has been accompanied by such an explosive increase in media coverage and scientific publications that researchers find it difficult to keep up. We are presenting a publicly available pipeline to perform named entity recognition and normalisation in parallel to help find relevant publications and to aid in downstream NLP tasks such as text summarisation. In our approach, we are using a dictionary-based system for its high recall in conjunction with two models based on BioBERT for their accuracy. Their outputs are combined according to different strategies depending on the entity type. In addition, we are using a manually crafted dictionary to increase performance for new concepts related to COVID-19. We have previously evaluated our work on the CRAFT corpus, and make the output of our pipeline available on two visualisation platforms.</abstract>
      <url hash="11b14ec9">2020.nlpcovid19-2.27</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.27</doi>
      <bibkey>colic-etal-2020-annotating</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cord-19">CORD-19</pwcdataset>
    </paper>
    <paper id="28">
      <title><fixed-case>A</fixed-case>sk<fixed-case>M</fixed-case>e: A <fixed-case>LAPPS</fixed-case> <fixed-case>G</fixed-case>rid-based <fixed-case>NLP</fixed-case> Query and Retrieval System for Covid-19 Literature</title>
      <author><first>Keith</first><last>Suderman</last></author>
      <author><first>Nancy</first><last>Ide</last></author>
      <author><first>Verhagen</first><last>Marc</last></author>
      <author><first>Brent</first><last>Cochran</last></author>
      <author><first>James</first><last>Pustejovsky</last></author>
      <abstract>In a recent project, the Language Application Grid was augmented to support the mining of scientific publications. The results of that ef- fort have now been repurposed to focus on Covid-19 literature, including modification of the LAPPS Grid “AskMe” query and retrieval engine. We describe the AskMe system and discuss its functionality as compared to other query engines available to search covid-related publications.</abstract>
      <url hash="9c6532e1">2020.nlpcovid19-2.28</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.28</doi>
      <bibkey>suderman-etal-2020-askme</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cord-19">CORD-19</pwcdataset>
    </paper>
    <paper id="29">
      <title>Concept Wikification for <fixed-case>COVID</fixed-case>-19</title>
      <author><first>Panagiotis</first><last>Lymperopoulos</last></author>
      <author><first>Haoling</first><last>Qiu</last></author>
      <author><first>Bonan</first><last>Min</last></author>
      <abstract>Understanding scientific articles related to COVID-19 requires broad knowledge about concepts such as symptoms, diseases and medicine. Given the very large and ever-growing scientific articles related to COVID-19, it is a daunting task even for experts to recognize the large set of concepts mentioned in these articles. In this paper, we address the problem of concept wikification for COVID-19, which is to automatically recognize mentions of concepts related to COVID-19 in text and resolve them into Wikipedia titles. We develop an approach to curate a COVID-19 concept wikification dataset by mining Wikipedia text and the associated intra-Wikipedia links. We also develop an end-to-end system for concept wikification for COVID-19. Preliminary experiments show very encouraging results. Our dataset, code and pre-trained model are available at github.com/panlybero/Covid19_wikification.</abstract>
      <url hash="297d9ae7">2020.nlpcovid19-2.29</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.29</doi>
      <bibkey>lymperopoulos-etal-2020-concept</bibkey>
      <pwccode url="https://github.com/panlybero/covid19_wikification" additional="false">panlybero/covid19_wikification</pwccode>
    </paper>
    <paper id="30">
      <title>Developing a Curated Topic Model for <fixed-case>COVID</fixed-case>-19 Medical Research Literature</title>
      <author><first>Philip</first><last>Resnik</last></author>
      <author><first>Katherine E.</first><last>Goodman</last></author>
      <author><first>Mike</first><last>Moran</last></author>
      <abstract>Topic models can facilitate search, navigation, and knowledge discovery in large document collections. However, automatic generation of topic models can produce results that fail to meet the needs of users. We advocate for a set of user-focused desiderata in topic modeling for the COVID-19 literature, and describe an effort in progress to develop a curated topic model for COVID-19 articles informed by subject matter expertise and the way medical researchers engage with medical literature.</abstract>
      <url hash="95ab831e">2020.nlpcovid19-2.30</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.30</doi>
      <bibkey>resnik-etal-2020-developing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/cord-19">CORD-19</pwcdataset>
    </paper>
    <paper id="31">
      <title>Collecting Verified <fixed-case>COVID</fixed-case>-19 Question Answer Pairs</title>
      <author><first>Adam</first><last>Poliak</last></author>
      <author><first>Max</first><last>Fleming</last></author>
      <author><first>Cash</first><last>Costello</last></author>
      <author><first>Kenton</first><last>Murray</last></author>
      <author><first>Mahsa</first><last>Yarmohammadi</last></author>
      <author><first>Shivani</first><last>Pandya</last></author>
      <author><first>Darius</first><last>Irani</last></author>
      <author><first>Milind</first><last>Agarwal</last></author>
      <author><first>Udit</first><last>Sharma</last></author>
      <author><first>Shuo</first><last>Sun</last></author>
      <author><first>Nicola</first><last>Ivanov</last></author>
      <author><first>Lingxi</first><last>Shang</last></author>
      <author><first>Kaushik</first><last>Srinivasan</last></author>
      <author><first>Seolhwa</first><last>Lee</last></author>
      <author><first>Xu</first><last>Han</last></author>
      <author><first>Smisha</first><last>Agarwal</last></author>
      <author><first>João</first><last>Sedoc</last></author>
      <abstract>We release a dataset of over 2,100 COVID19 related Frequently asked Question-Answer pairs scraped from over 40 trusted websites. We include an additional 24, 000 questions pulled from online sources that have been aligned by experts with existing answered questions from our dataset. This paper describes our efforts in collecting the dataset and summarizes the resulting data. Our dataset is automatically updated daily and available at https://github.com/JHU-COVID-QA/ scraping-qas. So far, this data has been used to develop a chatbot providing users information about COVID-19. We encourage others to build analytics and tools upon this dataset as well.</abstract>
      <url hash="15cb8c4d">2020.nlpcovid19-2.31</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.31</doi>
      <bibkey>poliak-etal-2020-collecting</bibkey>
      <pwccode url="https://github.com/JHU-COVID-QA/scraping-qas" additional="false">JHU-COVID-QA/scraping-qas</pwccode>
    </paper>
    <paper id="32">
      <title>A Comprehensive Dictionary and Term Variation Analysis for <fixed-case>COVID</fixed-case>-19 and <fixed-case>SARS</fixed-case>-<fixed-case>C</fixed-case>o<fixed-case>V</fixed-case>-2</title>
      <author><first>Robert</first><last>Leaman</last></author>
      <author><first>Zhiyong</first><last>Lu</last></author>
      <abstract>The number of unique terms in the scientific literature used to refer to either SARS-CoV-2 or COVID-19 is remarkably large and has continued to increase rapidly despite well-established standardized terms. This high degree of term variation makes high recall identification of these important entities difficult. In this manuscript we present an extensive dictionary of terms used in the literature to refer to SARS-CoV-2 and COVID-19. We use a rule-based approach to iteratively generate new term variants, then locate these variants in a large text corpus. We compare our dictionary to an extensive collection of terminological resources, demonstrating that our resource provides a substantial number of additional terms. We use our dictionary to analyze the usage of SARS-CoV-2 and COVID-19 terms over time and show that the number of unique terms continues to grow rapidly. Our dictionary is freely available at https://github.com/ncbi-nlp/CovidTermVar.</abstract>
      <url hash="801231c0">2020.nlpcovid19-2.32</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.32</doi>
      <bibkey>leaman-lu-2020-comprehensive</bibkey>
      <pwccode url="https://github.com/ncbi-nlp/CovidTermVar" additional="false">ncbi-nlp/CovidTermVar</pwccode>
    </paper>
    <paper id="33">
      <title>Using the Poly-encoder for a <fixed-case>COVID</fixed-case>-19 Question Answering System</title>
      <author><first>Seolhwa</first><last>Lee</last></author>
      <author><first>João</first><last>Sedoc</last></author>
      <abstract>To combat misinformation regarding COVID- 19 during this unprecedented pandemic, we propose a conversational agent that answers questions related to COVID-19. We adapt the Poly-encoder (Humeau et al., 2020) model for informational retrieval from FAQs. We show that after fine-tuning, the Poly-encoder can achieve a higher F1 score. We make our code publicly available for other researchers to use.</abstract>
      <url hash="50d20968">2020.nlpcovid19-2.33</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.33</doi>
      <bibkey>lee-sedoc-2020-using</bibkey>
      <pwccode url="https://github.com/sseol11/Parlai_ver2" additional="true">sseol11/Parlai_ver2</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/wikiqa">WikiQA</pwcdataset>
    </paper>
    <paper id="34">
      <title><fixed-case>W</fixed-case>eibo-<fixed-case>COV</fixed-case>: A Large-Scale <fixed-case>COVID</fixed-case>-19 Social Media Dataset from <fixed-case>W</fixed-case>eibo</title>
      <author><first>Yong</first><last>Hu</last></author>
      <author><first>Heyan</first><last>Huang</last></author>
      <author><first>Anfan</first><last>Chen</last></author>
      <author><first>Xian-Ling</first><last>Mao</last></author>
      <abstract>With the rapid development of COVID-19 around the world, people are requested to maintain “social distance” and “stay at home”. In this scenario, extensive social interactions transfer to cyberspace, especially on social media platforms like Twitter and Sina Weibo. People generate posts to share information, express opinions and seek help during the pandemic outbreak, and these kinds of data on social media are valuable for studies to prevent COVID-19 transmissions, such as early warning and outbreaks detection. Therefore, in this paper, we release a novel and fine-grained large-scale COVID-19 social media dataset collected from Sina Weibo, named Weibo-COV, contains more than 40 million posts ranging from December 1, 2019 to April 30, 2020. Moreover, this dataset includes comprehensive information nuggets like post-level information, interactive information, location information, and repost network. We hope this dataset can promote studies of COVID-19 from multiple perspectives and enable better and rapid researches to suppress the spread of this pandemic.</abstract>
      <url hash="af947758">2020.nlpcovid19-2.34</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.34</doi>
      <bibkey>hu-etal-2020-weibo</bibkey>
      <pwccode url="https://github.com/nghuyong/weibo-public-opinion-datasets" additional="false">nghuyong/weibo-public-opinion-datasets</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/weibo-cov">Weibo-COV</pwcdataset>
    </paper>
    <paper id="35">
      <title>Detecting Emerging Symptoms of <fixed-case>COVID</fixed-case>-19 using Context-based <fixed-case>T</fixed-case>witter Embeddings</title>
      <author><first>Roshan</first><last>Santosh</last></author>
      <author><first>H. Andrew</first><last>Schwartz</last></author>
      <author><first>Johannes</first><last>Eichstaedt</last></author>
      <author><first>Lyle</first><last>Ungar</last></author>
      <author><first>Sharath Chandra</first><last>Guntuku</last></author>
      <abstract>In this paper, we present an iterative graph-based approach for the detection of symptoms of COVID-19, the pathology of which seems to be evolving. More generally, the method can be applied to finding context-specific words and texts (e.g. symptom mentions) in large imbalanced corpora (e.g. all tweets mentioning }#COVID-19). Given the novelty of COVID-19, we also test if the proposed approach generalizes to the problem of detecting Adverse Drug Reaction (ADR). We find that the approach applied to Twitter data can detect symptom mentions substantially before to their being reported by the Centers for Disease Control (CDC).</abstract>
      <url hash="0289281f">2020.nlpcovid19-2.35</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.35</doi>
      <bibkey>santosh-etal-2020-detecting</bibkey>
      <pwccode url="https://github.com/rsk2327/Covid-Symptoms-NLP" additional="false">rsk2327/Covid-Symptoms-NLP</pwccode>
    </paper>
    <paper id="36">
      <title>Hate and Toxic Speech Detection in the Context of Covid-19 Pandemic using <fixed-case>XAI</fixed-case>: Ongoing Applied Research</title>
      <author><first>David</first><last>Hardage</last></author>
      <author><first>Peyman</first><last>Najafirad</last></author>
      <abstract>As social distancing, self-quarantines, and travel restrictions have shifted a lot of pandemic conversations to social media so does the spread of hate speech. While recent machine learning solutions for automated hate and offensive speech identification are available on Twitter, there are issues with their interpretability. We propose a novel use of learned feature importance which improves upon the performance of prior state-of-the-art text classification techniques, while producing more easily interpretable decisions. We also discuss both technical and practical challenges that remain for this task.</abstract>
      <url hash="1f9fe901">2020.nlpcovid19-2.36</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.36</doi>
      <bibkey>hardage-najafirad-2020-hate</bibkey>
    </paper>
    <paper id="37">
      <title>Real-time Classification, Geolocation and Interactive Visualization of <fixed-case>COVID</fixed-case>-19 Information Shared on Social Media to Better Understand Global Developments</title>
      <author><first>Andrei</first><last>Mircea</last></author>
      <abstract>As people communicate on social media during COVID-19, it can be an invaluable source of useful and up-to-date information. However, the large volume and noise-to-signal ratio of social media can make this impractical. We present a prototype dashboard for the real-time classification, geolocation and interactive visualization of COVID-19 tweets that addresses these issues. We also describe a novel L2 classification layer that outperforms linear layers on a dataset of respiratory virus tweets.</abstract>
      <url hash="bedde0d1">2020.nlpcovid19-2.37</url>
      <doi>10.18653/v1/2020.nlpcovid19-2.37</doi>
      <bibkey>mircea-2020-real</bibkey>
      <pwccode url="https://github.com/mirandrom/crisistweetmap" additional="false">mirandrom/crisistweetmap</pwccode>
    </paper>
  </volume>
</collection>
