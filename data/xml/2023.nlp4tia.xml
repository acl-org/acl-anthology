<?xml version='1.0' encoding='UTF-8'?>
<collection id="2023.nlp4tia">
  <volume id="1" ingest-date="2023-10-31" type="proceedings">
    <meta>
      <booktitle>Proceedings of the First Workshop on NLP Tools and Resources for Translation and Interpreting Applications</booktitle>
      <editor><first>Raquel Lázaro</first><last>Gutiérrez</last></editor>
      <editor><first>Antonio</first><last>Pareja</last></editor>
      <editor><first>Ruslan</first><last>Mitkov</last></editor>
      <publisher>INCOMA Ltd., Shoumen, Bulgaria</publisher>
      <address>Varna, Bulgaria</address>
      <month>September</month>
      <year>2023</year>
      <url hash="a7d70b72">2023.nlp4tia-1</url>
      <venue>nlp4tia</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="ddac674c">2023.nlp4tia-1.0</url>
      <bibkey>nlp4tia-2023-nlp</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Natural Language Processing tools and resources for translation and interpreting applications. Introduction</title>
      <author><first>Raquel</first><last>Lazaro Gutierrez</last></author>
      <pages>1–3</pages>
      <abstract/>
      <url hash="cb4a6c4f">2023.nlp4tia-1.1</url>
      <bibkey>lazaro-gutierrez-2023-natural</bibkey>
    </paper>
    <paper id="2">
      <title>Machine translation, translation errors, and adequacy: <fixed-case>S</fixed-case>panish-<fixed-case>E</fixed-case>nglish vs. <fixed-case>S</fixed-case>panish-<fixed-case>R</fixed-case>omanian</title>
      <author><first>Laura</first><last>Monguilod</last></author>
      <author><first>Bianca</first><last>Vitalaru</last></author>
      <pages>4–12</pages>
      <abstract>This paper has two objectives: 1. To analyse the adequacy of using neural machine translation (NMT) for the translation of health information (from Spanish into English and Romanian) used in Spanish public health campaigns; and 2. To compare results considering these two linguistic combinations. Results show that post-editing is essential to improve the quality of the translations for both language combinations since they cannot be used as a primary resource for informing foreign users without post-editing. Moreover, Romanian translations require more post-editing. However, using NMT for informative texts combined with human post-editing can be used as a strategy to benefit from the potential of MT while at the same time ensuring the quality of the public service translations depending on the language combination and on the amount of time allotted for the task.</abstract>
      <url hash="fd6ae23e">2023.nlp4tia-1.2</url>
      <bibkey>monguilod-vitalaru-2023-machine</bibkey>
    </paper>
    <paper id="3">
      <title>Cross-Lingual Idiom Sense Clustering in <fixed-case>G</fixed-case>erman and <fixed-case>E</fixed-case>nglish</title>
      <author><first>Mohammed</first><last>Absar</last></author>
      <pages>13–19</pages>
      <abstract>Idioms are expressions with non-literal and non-compositional meanings. For this reason, they pose a unique challenge for various NLP tasks including Machine Translation and Sentiment Analysis. In this paper, we propose an approach to clustering idioms in different languages by their sense. We leverage pre-trained cross-lingual transformer models and fine-tune them to produce cross-lingual vector representations of idioms according to their sense.</abstract>
      <url hash="b14244b4">2023.nlp4tia-1.3</url>
      <bibkey>absar-2023-cross</bibkey>
    </paper>
    <paper id="4">
      <title>Performance Evaluation on Human-Machine Teaming Augmented Machine Translation Enabled by <fixed-case>GPT</fixed-case>-4</title>
      <author><first>Ming</first><last>Qian</last></author>
      <pages>20–31</pages>
      <abstract>Translation has been modeled as a multiple-phase process where pre-editing analyses guide meaning transfer and interlingual restructure. Present-day machine translation (MT) tools provide no means for source text analyses. Generative AI with Large language modeling (LLM), equipped with prompt engineering and fine-tuning capabilities, can enable augmented MT solutions by explicitly including AI or human generated analyses/instruction, and/or human-generated reference translation as pre-editing or interactive inputs. Using an English-to-Chinese translation piece that had been carefully studied during a translator slam event, Four types of translation outputs on 20 text segments were evaluated: human-generated translation, Google Translate MT, instruction-augmented MT using GPT4-LLM, and Human-Machine-Teaming (HMT)-augmented translation based on both human reference translation and instruction using GPT4-LLM. While human translation had the best performance, both augmented MT approaches performed better than un-augmented MT. The HMT-augmented MT performed better than instruction-augmented MT because it combined the guidance and knowledge provided by both human reference translation and style instruction. However, since it is unrealistic to generate sentence-by-sentence human translation as MT input, better approaches to HMT-augmented MT need to be invented. The evaluation showed that generative AI with LLM can enable new MT workflow facilitating pre-editing analyses and interactive restructuring and achieving better performance.</abstract>
      <url hash="07fc4c00">2023.nlp4tia-1.4</url>
      <bibkey>qian-2023-performance</bibkey>
    </paper>
    <paper id="5">
      <title>The Interpretation System of <fixed-case>A</fixed-case>frican Languages in the Senegalese Parliament Debates</title>
      <author><first>Jean Christophe</first><last>Faye</last></author>
      <pages>32–38</pages>
      <abstract>The present work deals with the interpretation system of local languages in the Senegalese parliament. In other words, it is devoted to the implementation of the simultaneous interpretation system in the Senegalese Parliament debates. The Senegalese parliament, in cooperation with the European Parliament and the European Union, implemented, some years ago, a system of interpretation devoted to translating (into) six local languages. But what does the interpretation system consist in? What motivates the choice of six local languages and not more or less than six? Why does the Senegalese parliament implement such system in a country whose official language is French? What are the linguistic consequences of this interpretation system on the local and foreign languages spoken in the Senegalese parliament? How is the recruitment of interpreters done? To answer these questions, we have explored the documents and writings related to the implementation of the simultaneous interpretation system in the Senegalese parliament, in particular, and of the interpretation system, in general. Field surveys as well as interviews of some deputies, some interpreters and other people from the administration have also been organized and analyzed in this study. This research has helped us have a lot of information and collect data for the corpus. After the data collection, we have moved on to data analysis and we have ended up with results that we have presented in the body of the text.</abstract>
      <url hash="2bc58621">2023.nlp4tia-1.5</url>
      <bibkey>faye-2023-interpretation</bibkey>
    </paper>
    <paper id="6">
      <title><fixed-case>N</fixed-case>gambay-<fixed-case>F</fixed-case>rench Neural Machine Translation (sba-Fr)</title>
      <author><first>Toadoum Sari</first><last>Sakayo</last></author>
      <author><first>Angela</first><last>Fan</last></author>
      <author><first>Lema Logamou</first><last>Seknewna</last></author>
      <pages>39–47</pages>
      <abstract>In Africa, and the world at large, there is an increasing focus on developing Neural Machine Translation (NMT) systems to overcome language barriers. NMT for Low-resource language is particularly compelling as it involves learning with limited labelled data. However, obtaining a well-aligned parallel corpus for low-resource languages can be challenging. The disparity between the technological advancement of a few global languages and the lack of research on NMT for local languages in Chad is striking. End-to-end NMT trials on low-resource Chad languages have not been attempted. Additionally, there is a dearth of online and well-structured data gathering for research in Natural Language Processing, unlike some African languages. However, a guided approach for data gathering can produce bitext data for many Chadian language translation pairs with well-known languages that have ample data. In this project, we created the first sba-Fr Dataset, which is a corpus of Ngambay-to-French translations, and fine-tuned three pre-trained models using this dataset. Our experiments show that the M2M100 model outperforms other models with high BLEU scores on both original and original+synthetic data. The publicly available bitext dataset can be used for research purposes.</abstract>
      <url hash="858df4a9">2023.nlp4tia-1.6</url>
      <bibkey>sakayo-etal-2023-ngambay</bibkey>
    </paper>
    <paper id="7">
      <title>Machine Translation of literary texts: genres, times and systems</title>
      <author><first>Ana Isabel</first><last>Cespedosa Vázquez</last></author>
      <author><first>Ruslan</first><last>Mitkov</last></author>
      <pages>48–53</pages>
      <abstract>Machine Translation (MT) has taken off dramatically in recent years due to the advent of Deep Learning methods and Neural Machine Translation (NMT) has enhanced the quality of automatic translation significantly. While most work has covered the automatic translation of technical, legal and medical texts, the application of MT to literary texts and the human role in this process have been underexplored. In an effort to bridge the gap of this under-researched area, this paper presents the results of a study which seeks to evaluate the performance of three MT systems applied to two different literary genres, two novels (1984 by George Orwell and Pride and Prejudice by Jane Austen) and two poems (I Felt a Funeral in my Brain by Emily Dickinson and Siren Song by Margaret Atwood) representing different literary periods and timelines. The evaluation was conducted by way of the automatic evaluation metric BLEU to objectively assess the performance that the MT system shows on each genre. The limitations of this study are also outlined.</abstract>
      <url hash="6b2a6d98">2023.nlp4tia-1.7</url>
      <bibkey>cespedosa-vazquez-mitkov-2023-machine</bibkey>
    </paper>
    <paper id="8">
      <title>s<fixed-case>TMS</fixed-case> Cloud – A Boutique Translation Project Management System</title>
      <author><first>Nenad</first><last>Angelov</last></author>
      <pages>54–56</pages>
      <abstract>Demonstration of a Cloud-based Translation Project Management System, called sTMS, de- veloped with the financial support of Opera- tional Programme “Innovation and Competi- tiveness” 2014 2020 (OPIC) focusing to en- hance the operational activities of LSPs and MLPs. The idea behind was to concentrate mainly on the management processes, and not to integrate CAT or MT tools, because we be- lieve that the more functional such systems be- come, the harder to technically support and easy to operate they become. The key features sTMS provides are developed as a result of the broad experience of Project Managers, the increased requirements of our customers, the digital capabilities of our vendors and as last to meet the constantly changing environment of the translation industry.</abstract>
      <url hash="a6ac73ee">2023.nlp4tia-1.8</url>
      <bibkey>angelov-2023-stms</bibkey>
    </paper>
    <paper id="9">
      <title>Leveraging Large Language Models to Extract Terminology</title>
      <author><first>Julie</first><last>Giguere</last></author>
      <pages>57–60</pages>
      <abstract>Large Language Models (LLMs) have brought us efficient tools for various natural language processing (NLP) tasks. This paper explores the application of LLMs for extracting domain-specific terms from textual data. We will present the advantages and limitations of using LLMs for this task and will highlight the significant improvements they offer over traditional terminology extraction methods such as rule-based and statistical approaches.</abstract>
      <url hash="5060e8e0">2023.nlp4tia-1.9</url>
      <bibkey>giguere-2023-leveraging</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>C</fixed-case>hat<fixed-case>GPT</fixed-case> for translators: a survey</title>
      <author><first>Constantin</first><last>Orăsan</last></author>
      <pages>61–63</pages>
      <abstract>This article surveys the most important ways in which translators can use ChatGPT. The focus is on scenarios where ChatGPT supports the work of translators, rather than tries to replace them. A discussion of issues that translators need to consider when using large language models, and ChatGPT in particular, is also provided.</abstract>
      <url hash="6d1f3c65">2023.nlp4tia-1.10</url>
      <bibkey>orasan-2023-chatgpt</bibkey>
    </paper>
  </volume>
</collection>
