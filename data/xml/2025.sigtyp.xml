<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.sigtyp">
  <volume id="1" ingest-date="2025-07-22" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 7th Workshop on Research in Computational Linguistic Typology and Multilingual NLP</booktitle>
      <editor><first>Michael</first><last>Hahn</last></editor>
      <editor><first>Priya</first><last>Rani</last></editor>
      <editor><first>Ritesh</first><last>Kumar</last></editor>
      <editor><first>Andreas</first><last>Shcherbakov</last></editor>
      <editor><first>Alexey</first><last>Sorokin</last></editor>
      <editor><first>Oleg</first><last>Serikov</last></editor>
      <editor><first>Ryan</first><last>Cotterell</last></editor>
      <editor><first>Ekaterina</first><last>Vylomova</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Vinenna. Austria</address>
      <month>August</month>
      <year>2025</year>
      <url hash="7a0644bb">2025.sigtyp-1</url>
      <venue>sigtyp</venue>
      <venue>ws</venue>
      <isbn>979-8-89176-281-7</isbn>
      <doi>10.18653/v1/2025.sigtyp-1</doi>
    </meta>
    <frontmatter>
      <url hash="c40c870b">2025.sigtyp-1.0</url>
      <bibkey>sigtyp-ws-2025-1</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.0</doi>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>I</fixed-case>nstruction<fixed-case>CP</fixed-case>: A Simple yet Effective Approach for Transferring Large Language Models to Target Languages</title>
      <author><first>Kuang-Ming</first><last>Chen</last></author>
      <author><first>Jenq-Neng</first><last>Hwang</last></author>
      <author><first>Hung-yi</first><last>Lee</last><affiliation>National Taiwan University</affiliation></author>
      <pages>1-6</pages>
      <abstract>The rapid development of large language models (LLMs) in recent years has largely focused on English, resulting in models that respond exclusively in English. To adapt these models to other languages, continual pre-training (CP) is often employed, followed by supervised fine-tuning (SFT) to maintain conversational abilities. However, CP and SFT can reduce a model’s ability to filter harmful content. We propose Instruction Continual Pre-training (InsCP), which integrates instruction tags—also known as chat templates—into the CP process to prevent loss of conversational proficiency while acquiring new languages. Our experiments demonstrate that InsCP retains conversational and Reinforcement Learning from Human Feedback (RLHF) abilities. Empirical evaluations on language alignment, reliability, and knowledge benchmarks confirm the efficacy of InsCP. Notably, this approach requires only 0.1 billion tokens of high-quality instruction-following data, thereby reducing resource consumption.</abstract>
      <url hash="9c5da308">2025.sigtyp-1.1</url>
      <bibkey>chen-etal-2025-instructioncp</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.1</doi>
    </paper>
    <paper id="2">
      <title>Analyzing the Linguistic Priors of Language Models with Synthetic Languages</title>
      <author><first>Alessio</first><last>Tosolini</last></author>
      <author><first>Terra</first><last>Blevins</last><affiliation>Universität Vienna</affiliation></author>
      <pages>7-15</pages>
      <abstract>While modern language model architectures are often assumed to be language-agnostic, there is limited evidence as to whether these models actually process the wide diversity of natural languages equally well. We investigate this question by analyzing how well LMs learn carefully constructed artificial languages containing a variety of verbal complexity, ranging from simple paradigms to covering far more verb classes than occur in natural languages. Rather than learning all languages equally efficiently, models trained on these languages show strict preferences for processing simpler languages. Furthermore, while some observed behaviors mimic human linguistic priors, we find that they indicate the model memorizes its training data rather than generalizes from it.</abstract>
      <url hash="c4e15055">2025.sigtyp-1.2</url>
      <bibkey>tosolini-blevins-2025-analyzing</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.2</doi>
    </paper>
    <paper id="3">
      <title>Unstable Grounds for Beautiful Trees? Testing the Robustness of Concept Translations in the Compilation of Multilingual Wordlists</title>
      <author><first>David</first><last>Snee</last><affiliation>Universität Passau and Universität Passau</affiliation></author>
      <author><first>Luca</first><last>Ciucci</last><affiliation>Universität Passau</affiliation></author>
      <author><first>Arne</first><last>Rubehn</last><affiliation>Universität Passau</affiliation></author>
      <author><first>Kellen Parker Van</first><last>Dam</last><affiliation>Universität Passau</affiliation></author>
      <author><first>Johann-Mattis</first><last>List</last><affiliation>Universität Passau and Max-Planck Institute</affiliation></author>
      <pages>16-28</pages>
      <abstract>Multilingual wordlists play a crucial role in comparative linguistics. While many studies have been carried out to test the power of computational methods for language subgrouping or divergence time estimation, few studies have put the data upon which these studies are based to a rigorous test. Here, we conduct a first experiment that tests the robustness of concept translation as an integral part of the compilation of multilingual wordlists. Investigating the variation in concept translations in independently compiled wordlists from 10 dataset pairs covering 9 different language families, we find that on average, only 83% of all translations yield the same word form, while identical forms in terms of phonetic transcriptions can only be found in 23% of all cases. Our findings can prove important when trying to assess the uncertainty of phylogenetic studies and the conclusions derived from them.</abstract>
      <url hash="12e0b78d">2025.sigtyp-1.3</url>
      <bibkey>snee-etal-2025-unstable</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.3</doi>
    </paper>
    <paper id="4">
      <title>Annotating and Inferring Compositional Structures in Numeral Systems Across Languages</title>
      <author><first>Arne</first><last>Rubehn</last><affiliation>Universität Passau</affiliation></author>
      <author><first>Christoph</first><last>Rzymski</last><affiliation>Max-Planck Institute</affiliation></author>
      <author><first>Luca</first><last>Ciucci</last><affiliation>Universität Passau</affiliation></author>
      <author><first>Katja</first><last>Bocklage</last><affiliation>Universität Passau</affiliation></author>
      <author><first>Alžběta</first><last>Kučerová</last><affiliation>Universität Passau and Universität Passau</affiliation></author>
      <author><first>David</first><last>Snee</last><affiliation>Universität Passau and Universität Passau</affiliation></author>
      <author><first>Abishek</first><last>Stephen</last></author>
      <author><first>Kellen Parker Van</first><last>Dam</last><affiliation>Universität Passau</affiliation></author>
      <author><first>Johann-Mattis</first><last>List</last><affiliation>Universität Passau and Max-Planck Institute</affiliation></author>
      <pages>29-42</pages>
      <abstract>Numeral systems across the world’s languages vary in fascinating ways, both regarding their synchronic structure and the diachronic processes that determined how they evolved in their current shape. For a proper comparison of numeral systems across different languages, however, it is important to code them in a standardized form that allows for the comparison of basic properties. Here, we present a simple but effective coding scheme for numeral annotation, along with a workflow that helps to code numeral systems in a computer-assisted manner, providing sample data for numerals from 1 to 40 in 25 typologically diverse languages. We perform a thorough analysis of the sample, focusing on the systematic comparison between the underlying and the surface morphological structure. We further experiment with automated models for morpheme segmentation, where we find allomorphy as the major reason for segmentation errors. Finally, we show that subword tokenization algorithms are not viable for discovering morphemes in low-resource scenarios.</abstract>
      <url hash="dc7fbc86">2025.sigtyp-1.4</url>
      <bibkey>rubehn-etal-2025-annotating</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.4</doi>
    </paper>
    <paper id="5">
      <title>Beyond the Data: The Impact of Annotation Inconsistencies in <fixed-case>UD</fixed-case> Treebanks on Typological Universals and Complexity Assessment</title>
      <author><first>Antoni Brosa</first><last>Rodríguez</last><affiliation>Universitat Rovira i Virgili</affiliation></author>
      <author><first>M. Dolores Jiménez</first><last>López</last><affiliation>Universitat Rovira i Virgili</affiliation></author>
      <pages>43-51</pages>
      <abstract>This study explores the impact of annotation inconsistencies in Universal Dependencies (UD) treebanks on typological research in computational linguistics. UD provides a standardized framework for cross-linguistic annotation, facilitating large-scale empirical studies on linguistic diversity and universals. However, despite rigorous guidelines, annotation inconsistencies persist across treebanks. The objective of this paper is to assess how these inconsistencies affect typological universals, linguistic descriptions, and complexity metrics. We analyze systematic annotation errors in multiple UD treebanks, focusing on morphological features. Case studies on Spanish and Dutch demonstrate how differing annotation decisions within the same language create contradictory typological profiles. We classify the errors into two main categories: overgeneration errors (features incorrectly annotated, since do not actually exist in a language) and data omission errors (inconsistent or incomplete annotation of features that do exist). Our results show that these inconsistencies significantly distort typological analyses, leading to false generalizations and miscalculations of linguistic complexity. We propose methodological safeguards for typological research using UD data. Our findings highlight the need for methodological improvements to ensure more reliable cross-linguistic generalizations in computational typology.</abstract>
      <url hash="4110f4a1">2025.sigtyp-1.5</url>
      <bibkey>rodriguez-lopez-2025-beyond</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.5</doi>
    </paper>
    <paper id="6">
      <title>Beyond cognacy</title>
      <author><first>Gerhard</first><last>Jäger</last><affiliation>Eberhard-Karls-Universität Tübingen</affiliation></author>
      <pages>52-60</pages>
      <abstract>Computational phylogenetics has become an established tool in historical linguistics, with many language families now analyzed using likelihood-based inference. However, standard approaches rely on expert-annotated cognate sets, which are sparse, labor-intensive to produce, and limited to individual language families. This paper explores alternatives by comparing the established method to two fully automated methods that extract phylogenetic signal directly from lexical data. One uses automatic cognate clustering with unigram/concept features; the other applies multiple sequence alignment (MSA) derived from a pair-hidden Markov model. Both are evaluated against expert classifications from Glottolog and typological data from Grambank. Also, the intrinsic strengths of the phylogenetic signal in the characters are compared. Results show that MSA-based inference yields trees more consistent with linguistic classifications, better predicts typological variation, and provides a clearer phylogenetic signal, suggesting it as a promising, scalable alternative to traditional cognate-based methods. This opens new avenues for global-scale language phylogenies beyond expert annotation bottlenecks.</abstract>
      <url hash="bfb15f95">2025.sigtyp-1.6</url>
      <bibkey>jager-2025-beyond</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.6</doi>
    </paper>
    <paper id="7">
      <title><fixed-case>S</fixed-case>en<fixed-case>W</fixed-case>i<fixed-case>C</fixed-case>h: Sense-Annotation of Low-Resource Languages for <fixed-case>W</fixed-case>i<fixed-case>C</fixed-case> using Hybrid Methods</title>
      <author><first>Roksana</first><last>Goworek</last></author>
      <author><first>Harpal Singh</first><last>Karlcut</last></author>
      <author><first>Hamza</first><last>Shezad</last><affiliation>University of Engineering Technology</affiliation></author>
      <author><first>Nijaguna</first><last>Darshana</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Abhishek</first><last>Mane</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Syam</first><last>Bondada</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Raghav</first><last>Sikka</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Ulvi</first><last>Mammadov</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Rauf</first><last>Allahverdiyev</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Sriram Satkirti</first><last>Purighella</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Paridhi</first><last>Gupta</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Muhinyia</first><last>Ndegwa</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Bao Khanh</first><last>Tran</last><affiliation>Queen Mary University of London</affiliation></author>
      <author><first>Haim</first><last>Dubossarsky</last><affiliation>Queen Mary University of London</affiliation></author>
      <pages>61-74</pages>
      <abstract>This paper addresses the critical need for high-quality evaluation datasets in low-resource languages to advance cross-lingual transfer. While cross-lingual transfer offers a key strategy for leveraging multilingual pretraining to expand language technologies to understudied and typologically diverse languages, its effectiveness is dependent on quality and suitable benchmarks. We release new sense-annotated datasets of sentences containing polysemous words, spanning nine low-resource languages across diverse language families and scripts. To facilitate dataset creation, the paper presents a demonstrably beneficial semi-automatic annotation method. The utility of the datasets is demonstrated through Word-in-Context (WiC) formatted experiments that evaluate transfer on these low-resource languages. Results highlight the importance of targeted dataset creation and evaluation for effective polysemy disambiguation in low-resource settings and transfer studies. The released datasets and code aim to support further research into fair, robust, and truly multilingual NLP.</abstract>
      <url hash="6325d622">2025.sigtyp-1.7</url>
      <bibkey>goworek-etal-2025-senwich</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.7</doi>
    </paper>
    <paper id="9">
      <title><fixed-case>XCOMPS</fixed-case>: A Multilingual Benchmark of Conceptual Minimal Pairs</title>
      <author><first>Linyang</first><last>He</last></author>
      <author><first>Ercong</first><last>Nie</last></author>
      <author><first>Sukru Samet</first><last>Dindar</last></author>
      <author><first>Arsalan</first><last>Firoozi</last></author>
      <author><first>Van</first><last>Nguyen</last></author>
      <author><first>Corentin</first><last>Puffay</last></author>
      <author><first>Riki</first><last>Shimizu</last></author>
      <author><first>Haotian</first><last>Ye</last><affiliation>Center for Information and Language Processing</affiliation></author>
      <author><first>Jonathan</first><last>Brennan</last><affiliation>University of Michigan - Ann Arbor</affiliation></author>
      <author><first>Helmut</first><last>Schmid</last><affiliation>Center for Information and Language Processing</affiliation></author>
      <author><first>Hinrich</first><last>Schuetze</last></author>
      <author><first>Nima</first><last>Mesgarani</last><affiliation>Columbia University</affiliation></author>
      <pages>75-81</pages>
      <abstract>In this work, we introduce XCOMPS, a multilingual conceptual minimal pair dataset that covers 17 languages.Using this dataset, we evaluate LLMs’ multilingual conceptual understanding through metalinguistic prompting, direct probability measurement, and neurolinguistic probing. We find that: 1) LLMs exhibit weaker conceptual understanding for low-resource languages, and accuracy varies across languages despite being tested on the same concept sets. 2) LLMs excel at distinguishing concept-property pairs that are visibly different but exhibit a marked performance drop when negative pairs share subtle semantic similarities. 3) More morphologically complex languages yield lower concept understanding scores and require deeper layers for conceptual reasoning.</abstract>
      <url hash="eb135904">2025.sigtyp-1.9</url>
      <bibkey>he-etal-2025-xcomps</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.9</doi>
    </paper>
    <paper id="11">
      <title>Tone in Perspective: A Computational Typological Analysis of Tone Function in <fixed-case>ASR</fixed-case></title>
      <author><first>Siyu</first><last>Liang</last></author>
      <author><first>Gina-Anne</first><last>Levow</last><affiliation>University of Washington</affiliation></author>
      <pages>82-92</pages>
      <abstract>This study investigates the impact of pitch flattening on automatic speech recognition (ASR) performance across tonal and non-tonal languages. Using vocoder-based signal processing techniques, we created pitch-flattened versions of speech recordings and compared ASR performance against original recordings. Results reveal that tonal languages experience substantially larger performance degradation than non-tonal languages. Analysis of tone confusion matrices shows systematic patterns of misidentification where contour tones collapse toward level tones when pitch information is removed. Calculation of tone’s functional load at syllable and word levels demonstrates that syllable-level functional load strongly predicts ASR vulnerability to pitch flattening, while word-level patterns reflect each language’s morphological structure. These findings illuminate the differential importance of pitch information across languages and suggest that ASR systems for languages with high syllable-level functional load require more robust pitch modeling.</abstract>
      <url hash="c4c76165">2025.sigtyp-1.11</url>
      <bibkey>liang-levow-2025-tone</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.11</doi>
    </paper>
    <paper id="12">
      <title>A discovery procedure for synlexification patterns in the world’s languages</title>
      <author><first>Hannah S.</first><last>Rognan</last></author>
      <author><first>Barend</first><last>Beekhuizen</last><affiliation>University of Toronto</affiliation></author>
      <pages>93-113</pages>
      <abstract>Synlexification is the pattern of crosslinguistic lexical semantic variation whereby what is expressed in a single word in one language, is expressed in multiple words in another (e.g., French ‘monter’ vs. English ‘go+up’). We introduce a computational method for automatically extracting instances of synlexification from a parallel corpus at a large scale (many languages, many domains). The method involves debiasing the seed language by splitting up synlexifications in the seed language where other languages consistently split them. The method was applied to a massively parallel corpus of 198 Bible translations. We validate it on a broad sample of cases, and demonstrate its potential for typological research.</abstract>
      <url hash="5ab18a52">2025.sigtyp-1.12</url>
      <bibkey>rognan-beekhuizen-2025-discovery</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.12</doi>
    </paper>
    <paper id="13">
      <title>Construction-Based Reduction of Translationese for Low-Resource Languages: A Pilot Study on <fixed-case>B</fixed-case>avarian</title>
      <author><first>Peiqin</first><last>Lin</last></author>
      <author><first>Marion</first><last>Thaler</last></author>
      <author><first>Daniela</first><last>Goschala</last></author>
      <author><first>Amir Hossein</first><last>Kargaran</last></author>
      <author><first>Yihong</first><last>Liu</last></author>
      <author><first>André F. T.</first><last>Martins</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>114-121</pages>
      <abstract>When translating into a low-resource language, a language model can have a tendency to produce translations that are close to the source (e.g., word-by-word translations) due to a lack of rich low-resource training data in pretraining. Thus, the output often is translationese that differs considerably from what native speakers would produce naturally. To remedy this, we synthetically create a training set in which the frequency of a construction unique to the low-resource language is artificially inflated. For the case of Bavarian, we show that, after training, the language model has learned the unique construction and that native speakers judge its output as more natural. Our pilot study suggests that construction-based mitigation of translationese is a promising approach. Code and artifacts are available at <url>https://github.com/cisnlp/BayernGPT</url>.</abstract>
      <url hash="ef5ed912">2025.sigtyp-1.13</url>
      <bibkey>lin-etal-2025-construction</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.13</doi>
    </paper>
    <paper id="14">
      <title>High-Dimensional Interlingual Representations of Large Language Models</title>
      <author><first>Bryan</first><last>Wilie</last></author>
      <author><first>Samuel</first><last>Cahyawijaya</last><affiliation>Cohere</affiliation></author>
      <author><first>Junxian</first><last>He</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Pascale</first><last>Fung</last><affiliation>HKUST</affiliation></author>
      <pages>122-155</pages>
      <abstract>Large language models (LLMs) trained on massive multilingual datasets hint at the formation of interlingual constructs–a shared region in the representation space. However, evidence regarding this phenomenon is mixed, leaving it unclear whether these models truly develop unified interlingual representations, or present a partially aligned constructs. We explore 31 diverse languages varying on their resource-levels, typologies, and geographical regions; and find that multilingual LLMs exhibit inconsistent cross-lingual alignments. To address this, we propose an interlingual representation framework identifying both the shared interlingual semantic region and fragmented components, existed due to representational limitations. We introduce Interlingual Local Overlap (ILO) score to quantify interlingual alignment by comparing the local neighborhood structures of high-dimensional representations. We utilize ILO to investigate the impact of single-language fine-tuning on the interlingual alignment in multilingual LLMs. Our results indicate that training exclusively on a single language disrupts the alignment in early layers, while freezing these layers preserves the alignment of interlingual representations, leading to improved cross-lingual generalization. These results validate our framework and metric for evaluating interlingual representation, and further underscore that interlingual alignment is crucial for scalable multilingual learning.</abstract>
      <url hash="139da2aa">2025.sigtyp-1.14</url>
      <bibkey>wilie-etal-2025-high</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.14</doi>
    </paper>
    <paper id="15">
      <title>Domain Meets Typology: Predicting Verb-Final Order from <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies for Financial and Blockchain <fixed-case>NLP</fixed-case></title>
      <author><first>Zichao</first><last>Li</last></author>
      <author><first>Zong</first><last>Ke</last></author>
      <pages>156-164</pages>
      <abstract>This paper introduces a domain-adapted approach for verb-order prediction across general and specialized texts (financial/blockchain), combining Universal Dependencies syntax with novel features (AVAR, DLV) and dynamic threshold calibration. We evaluate on 53 languages from UD v2.11, 12K financial sentences (FinBench), and 1,845 blockchain whitepapers (CryptoUD), outperforming four baselines by 6-19% F1. Key findings include: (1) 62% SOV prevalence in SEC filings (+51% over general English), (2) 88% technical whitepaper alignment with Solidity’s SOV patterns, and (3) 9% gains from adaptive thresholds. The system processes 1,150 sentences/second - 2.4× faster than XLM-T - while maintaining higher accuracy, demonstrating that lightweight feature-based methods can surpass neural approaches for domain-specific syntactic analysis.</abstract>
      <url hash="a8c3534a">2025.sigtyp-1.15</url>
      <bibkey>li-ke-2025-domain</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.15</doi>
    </paper>
    <paper id="16">
      <title>Token-level semantic typology without a massively parallel corpus</title>
      <author><first>Barend</first><last>Beekhuizen</last><affiliation>University of Toronto</affiliation></author>
      <pages>165-176</pages>
      <abstract>This paper presents a computational method for token-level lexical semantic comparative research in an original text setting, as opposed to the more common massively parallel setting. Given a set of (non-massively parallel) bitexts, the method consists of leveraging pre-trained contextual vectors in a reference language to induce, for a token in one target language, the lexical items that all other target languages would have used, thus simulating a massively parallel set-up. The method is evaluated on its extraction and induction quality, and the use of the method for lexical semantic typological research is demonstrated.</abstract>
      <url hash="89392e05">2025.sigtyp-1.16</url>
      <bibkey>beekhuizen-2025-token</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.16</doi>
    </paper>
    <paper id="17">
      <title>Are Translated Texts Useful for Gradient Word Order Extraction?</title>
      <author><first>Amanda</first><last>Kann</last><affiliation>Stockholm University</affiliation></author>
      <pages>177-182</pages>
      <abstract>Gradient, token-level measures of word order preferences within a language are useful both for cross-linguistic comparison in linguistic typology and for multilingual NLP applications. However, such measures might not be representative of general language use when extracted from translated corpora, due to noise introduced by structural effects of translation. We attempt to quantify this uncertainty in a case study of subject/verb order statistics extracted from a parallel corpus of parliamentary speeches in 21 European languages. We find that word order proportions in translated texts generally resemble those extracted from non-translated texts, but tend to skew somewhat toward the dominant word order of the target language. We also investigate the potential presence of underlying source language-specific effects, but find that they do not sufficiently explain the variation across translations.</abstract>
      <url hash="b21287ef">2025.sigtyp-1.17</url>
      <bibkey>kann-2025-translated</bibkey>
      <doi>10.18653/v1/2025.sigtyp-1.17</doi>
    </paper>
  </volume>
</collection>
