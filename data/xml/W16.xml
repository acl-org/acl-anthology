<?xml version='1.0' encoding='UTF-8'?>
<collection id="W16">
  <volume id="1">
    <meta>
      <booktitle>Proceedings of the Workshop on Human-Computer Question Answering</booktitle>
      <editor><first>Mohit</first><last>Iyyer</last></editor>
      <editor><first>He</first><last>He</last></editor>
      <editor><first>Jordan</first><last>Boyd-Graber</last></editor>
      <editor><first>Hal</first><last>Daumé III</last></editor>
      <doi>10.18653/v1/W16-01</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>San Diego, California</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="3bd9d757">W16-0100</url>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>W</fixed-case>atson Discovery Advisor: Question-answering in an industrial setting</title>
      <author><first>Charley</first> <last>Beller</last></author>
      <author><first>Graham</first> <last>Katz</last></author>
      <author><first>Allen</first> <last>Ginsberg</last></author>
      <author><first>Chris</first> <last>Phipps</last></author>
      <author><first>Sean</first> <last>Bethard</last></author>
      <author><first>Paul</first> <last>Chase</last></author>
      <author><first>Elinna</first> <last>Shek</last></author>
      <author><first>Kristen</first> <last>Summers</last></author>
      <pages>1–7</pages>
      <url hash="22222c57">W16-0101</url>
      <doi>10.18653/v1/W16-0101</doi>
    </paper>
    <paper id="2">
      <title>Crowdsourcing for (almost) Real-time Question Answering</title>
      <author><first>Denis</first> <last>Savenkov</last></author>
      <author><first>Scott</first> <last>Weitzner</last></author>
      <author><first>Eugene</first> <last>Agichtein</last></author>
      <pages>8–14</pages>
      <url hash="68f00bfe">W16-0102</url>
      <doi>10.18653/v1/W16-0102</doi>
    </paper>
    <paper id="3">
      <title>Attention-Based Convolutional Neural Network for Machine Comprehension</title>
      <author><first>Wenpeng</first> <last>Yin</last></author>
      <author><first>Sebastian</first> <last>Ebert</last></author>
      <author><first>Hinrich</first> <last>Schütze</last></author>
      <pages>15–21</pages>
      <url hash="1d025637">W16-0103</url>
      <doi>10.18653/v1/W16-0103</doi>
    </paper>
    <paper id="4">
      <title>Open-domain Factoid Question Answering via Knowledge Graph Search</title>
      <author><first>Ahmad</first> <last>Aghaebrahimian</last></author>
      <author><first>Filip</first> <last>Jurčíček</last></author>
      <pages>22–28</pages>
      <url hash="15d24a1c">W16-0104</url>
      <doi>10.18653/v1/W16-0104</doi>
    </paper>
    <paper id="5">
      <title>Neural Enquirer: Learning to Query Tables in Natural Language</title>
      <author><first>Pengcheng</first> <last>Yin</last></author>
      <author><first>Zhengdong</first> <last>Lu</last></author>
      <author><first>Hang</first> <last>Li</last></author>
      <author><first>Kao</first> <last>Ben</last></author>
      <pages>29–35</pages>
      <url hash="5d066efa">W16-0105</url>
      <doi>10.18653/v1/W16-0105</doi>
    </paper>
    <paper id="6">
      <title>Neural Generative Question Answering</title>
      <author><first>Jun</first> <last>Yin</last></author>
      <author><first>Xin</first> <last>Jiang</last></author>
      <author><first>Zhengdong</first> <last>Lu</last></author>
      <author><first>Lifeng</first> <last>Shang</last></author>
      <author><first>Hang</first> <last>Li</last></author>
      <author><first>Xiaoming</first> <last>Li</last></author>
      <pages>36–42</pages>
      <url hash="d3b66423">W16-0106</url>
      <doi>10.18653/v1/W16-0106</doi>
    </paper>
    <paper id="7">
      <title>“A Distorted Skull Lies in the Bottom Center...” Identifying Paintings from Text Descriptions</title>
      <author><first>Anupam</first> <last>Guha</last></author>
      <author><first>Mohit</first> <last>Iyyer</last></author>
      <author><first>Jordan</first> <last>Boyd-Graber</last></author>
      <pages>43–47</pages>
      <url hash="f517a470">W16-0107</url>
      <doi>10.18653/v1/W16-0107</doi>
    </paper>
    <paper id="8">
      <title>Using Confusion Graphs to Understand Classifier Error</title>
      <author><first>Davis</first> <last>Yoshida</last></author>
      <author><first>Jordan</first> <last>Boyd-Graber</last></author>
      <pages>48–52</pages>
      <url hash="553bb860">W16-0108</url>
      <doi>10.18653/v1/W16-0108</doi>
    </paper>
    <paper id="9">
      <title>Paraphrase for Open Question Answering: New Dataset and Methods</title>
      <author><first>Ying</first> <last>Xu</last></author>
      <author><first>Pascual</first> <last>Martínez-Gómez</last></author>
      <author><first>Yusuke</first> <last>Miyao</last></author>
      <author><first>Randy</first> <last>Goebel</last></author>
      <pages>53–61</pages>
      <url hash="ed4db935">W16-0109</url>
      <doi>10.18653/v1/W16-0109</doi>
    </paper>
  </volume>
  <volume id="2">
    <meta>
      <booktitle>Proceedings of the Fifth Workshop on Computational Linguistics for Literature</booktitle>
      <editor><first>Anna</first><last>Feldman</last></editor>
      <editor><first>Anna</first><last>Kazantseva</last></editor>
      <editor><first>Stan</first><last>Szpakowicz</last></editor>
      <doi>10.18653/v1/W16-02</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>San Diego, California, USA</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="a7c8f094">W16-0200</url>
    </frontmatter>
    <paper id="1">
      <title>Supervised Machine Learning for Hybrid Meter</title>
      <author><first>Alex</first> <last>Estes</last></author>
      <author><first>Christopher</first> <last>Hench</last></author>
      <pages>1–8</pages>
      <url hash="55dd6a59">W16-0201</url>
      <doi>10.18653/v1/W16-0201</doi>
    </paper>
    <paper id="2">
      <title>Automatic Text Generation by Learning from Literary Structures</title>
      <author><first>Angel</first> <last>Daza</last></author>
      <author><first>Hiram</first> <last>Calvo</last></author>
      <author><first>Jesús</first> <last>Figueroa-Nazuno</last></author>
      <pages>9–19</pages>
      <url hash="9cd16e98">W16-0202</url>
      <doi>10.18653/v1/W16-0202</doi>
    </paper>
    <paper id="3">
      <title>Intersecting Word Vectors to Take Figurative Language to New Heights</title>
      <author><first>Andrea</first> <last>Gagliano</last></author>
      <author><first>Emily</first> <last>Paul</last></author>
      <author><first>Kyle</first> <last>Booten</last></author>
      <author><first>Marti A.</first> <last>Hearst</last></author>
      <pages>20–31</pages>
      <url hash="412f8058">W16-0203</url>
      <doi>10.18653/v1/W16-0203</doi>
    </paper>
    <paper id="4">
      <title>Gender-Distinguishing Features in Film Dialogue</title>
      <author><first>Alexandra</first> <last>Schofield</last></author>
      <author><first>Leo</first> <last>Mehr</last></author>
      <pages>32–39</pages>
      <url hash="dafd9eb3">W16-0204</url>
      <doi>10.18653/v1/W16-0204</doi>
      <revision id="1" href="W16-0204v1" hash="613deabe"/>
      <revision id="2" href="W16-0204v2" hash="dafd9eb3" date="2020-08-27">The paper now has a note that describes the systematic problems with the paper's name-based strategy of automatic gender recognition (or any AGR). It provides some references that justify this. No change has been made to the main body of the paper.</revision>
    </paper>
    <paper id="5">
      <title>Reconstructing Ancient Literary Texts from Noisy Manuscripts</title>
      <author><first>Moshe</first> <last>Koppel</last></author>
      <author><first>Moty</first> <last>Michaely</last></author>
      <author><first>Alex</first> <last>Tal</last></author>
      <pages>40–46</pages>
      <url hash="f6686405">W16-0205</url>
      <doi>10.18653/v1/W16-0205</doi>
    </paper>
    <paper id="6">
      <title>Syntax Matters for Rhetorical Structure: The Case of Chiasmus</title>
      <author><first>Marie</first> <last>Dubremetz</last></author>
      <author><first>Joakim</first> <last>Nivre</last></author>
      <pages>47–53</pages>
      <url hash="68eed656">W16-0206</url>
      <doi>10.18653/v1/W16-0206</doi>
    </paper>
    <paper id="7">
      <title>Bilingual Chronological Classification of Hafez’s Poems</title>
      <author><first>Arya</first> <last>Rahgozar</last></author>
      <author><first>Diana</first> <last>Inkpen</last></author>
      <pages>54–62</pages>
      <url hash="83921997">W16-0207</url>
      <doi>10.18653/v1/W16-0207</doi>
    </paper>
  </volume>
  <volume id="3">
    <meta>
      <booktitle>Proceedings of the Third Workshop on Computational Linguistics and Clinical Psychology</booktitle>
      <editor><first>Kristy</first><last>Hollingshead</last></editor>
      <editor><first>Lyle</first><last>Ungar</last></editor>
      <doi>10.18653/v1/W16-03</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>San Diego, CA, USA</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="305ee091">W16-0300</url>
    </frontmatter>
    <paper id="1">
      <title>Detecting late-life depression in <fixed-case>A</fixed-case>lzheimer’s disease through analysis of speech and language</title>
      <author><first>Kathleen C.</first> <last>Fraser</last></author>
      <author><first>Frank</first> <last>Rudzicz</last></author>
      <author><first>Graeme</first> <last>Hirst</last></author>
      <pages>1–11</pages>
      <url hash="91cf2cab">W16-0301</url>
      <doi>10.18653/v1/W16-0301</doi>
    </paper>
    <paper id="2">
      <title>Towards Early Dementia Detection: Fusing Linguistic and Non-Linguistic Clinical Data</title>
      <author><first>Joseph</first> <last>Bullard</last></author>
      <author><first>Cecilia</first> <last>Ovesdotter Alm</last></author>
      <author><first>Xumin</first> <last>Liu</last></author>
      <author><first>Qi</first> <last>Yu</last></author>
      <author><first>Rubén</first> <last>Proaño</last></author>
      <pages>12–22</pages>
      <url hash="70cd17ba">W16-0302</url>
      <doi>10.18653/v1/W16-0302</doi>
    </paper>
    <paper id="3">
      <title>Self-Reflective Sentiment Analysis</title>
      <author><first>Benjamin</first> <last>Shickel</last></author>
      <author><first>Martin</first> <last>Heesacker</last></author>
      <author><first>Sherry</first> <last>Benton</last></author>
      <author><first>Ashkan</first> <last>Ebadi</last></author>
      <author><first>Paul</first> <last>Nickerson</last></author>
      <author><first>Parisa</first> <last>Rashidi</last></author>
      <pages>23–32</pages>
      <url hash="8cfb561e">W16-0303</url>
      <doi>10.18653/v1/W16-0303</doi>
    </paper>
    <paper id="4">
      <title>Is Sentiment in Movies the Same as Sentiment in Psychotherapy? Comparisons Using a New Psychotherapy Sentiment Database</title>
      <author><first>Michael</first> <last>Tanana</last></author>
      <author><first>Aaron</first> <last>Dembe</last></author>
      <author><first>Christina S.</first> <last>Soma</last></author>
      <author><first>Zac</first> <last>Imel</last></author>
      <author><first>David</first> <last>Atkins</last></author>
      <author><first>Vivek</first> <last>Srikumar</last></author>
      <pages>33–41</pages>
      <url hash="a53c8553">W16-0304</url>
      <doi>10.18653/v1/W16-0304</doi>
    </paper>
    <paper id="5">
      <title>Building a Motivational Interviewing Dataset</title>
      <author><first>Verónica</first> <last>Pérez-Rosas</last></author>
      <author><first>Rada</first> <last>Mihalcea</last></author>
      <author><first>Kenneth</first> <last>Resnicow</last></author>
      <author><first>Satinder</first> <last>Singh</last></author>
      <author><first>Lawrence</first> <last>An</last></author>
      <pages>42–51</pages>
      <url hash="284e73ef">W16-0305</url>
      <doi>10.18653/v1/W16-0305</doi>
    </paper>
    <paper id="6">
      <title>Crazy Mad Nutters: The Language of Mental Health</title>
      <author><first>Jena D.</first> <last>Hwang</last></author>
      <author><first>Kristy</first> <last>Hollingshead</last></author>
      <pages>52–62</pages>
      <url hash="b1c668aa">W16-0306</url>
      <doi>10.18653/v1/W16-0306</doi>
    </paper>
    <paper id="7">
      <title>The language of mental health problems in social media</title>
      <author><first>George</first> <last>Gkotsis</last></author>
      <author><first>Anika</first> <last>Oellrich</last></author>
      <author><first>Tim</first> <last>Hubbard</last></author>
      <author><first>Richard</first> <last>Dobson</last></author>
      <author><first>Maria</first> <last>Liakata</last></author>
      <author><first>Sumithra</first> <last>Velupillai</last></author>
      <author><first>Rina</first> <last>Dutta</last></author>
      <pages>63–73</pages>
      <url hash="4184d137">W16-0307</url>
      <doi>10.18653/v1/W16-0307</doi>
    </paper>
    <paper id="8">
      <title>Exploring Autism Spectrum Disorders Using <fixed-case>HLT</fixed-case></title>
      <author><first>Julia</first> <last>Parish-Morris</last></author>
      <author><first>Mark</first> <last>Liberman</last></author>
      <author><first>Neville</first> <last>Ryant</last></author>
      <author><first>Christopher</first> <last>Cieri</last></author>
      <author><first>Leila</first> <last>Bateman</last></author>
      <author><first>Emily</first> <last>Ferguson</last></author>
      <author><first>Robert</first> <last>Schultz</last></author>
      <pages>74–84</pages>
      <url hash="d458602d">W16-0308</url>
      <doi>10.18653/v1/W16-0308</doi>
    </paper>
    <paper id="9">
      <title>Generating Clinically Relevant Texts: A Case Study on Life-Changing Events</title>
      <author><first>Mayuresh</first> <last>Oak</last></author>
      <author><first>Anil</first> <last>Behera</last></author>
      <author><first>Titus</first> <last>Thomas</last></author>
      <author><first>Cecilia</first> <last>Ovesdotter Alm</last></author>
      <author><first>Emily</first> <last>Prud’hommeaux</last></author>
      <author><first>Christopher</first> <last>Homan</last></author>
      <author><first>Raymond</first> <last>Ptucha</last></author>
      <pages>85–94</pages>
      <url hash="a6afaac8">W16-0309</url>
      <doi>10.18653/v1/W16-0309</doi>
    </paper>
    <paper id="10">
      <title>Don’t Let Notes Be Misunderstood: A Negation Detection Method for Assessing Risk of Suicide in Mental Health Records</title>
      <author><first>George</first> <last>Gkotsis</last></author>
      <author><first>Sumithra</first> <last>Velupillai</last></author>
      <author><first>Anika</first> <last>Oellrich</last></author>
      <author><first>Harry</first> <last>Dean</last></author>
      <author><first>Maria</first> <last>Liakata</last></author>
      <author><first>Rina</first> <last>Dutta</last></author>
      <pages>95–105</pages>
      <url hash="a4fdf8e8">W16-0310</url>
      <doi>10.18653/v1/W16-0310</doi>
    </paper>
    <paper id="11">
      <title>Exploratory Analysis of Social Media Prior to a Suicide Attempt</title>
      <author><first>Glen</first> <last>Coppersmith</last></author>
      <author><first>Kim</first> <last>Ngo</last></author>
      <author><first>Ryan</first> <last>Leary</last></author>
      <author><first>Anthony</first> <last>Wood</last></author>
      <pages>106–117</pages>
      <url hash="0defc9c0">W16-0311</url>
      <doi>10.18653/v1/W16-0311</doi>
    </paper>
    <paper id="12">
      <title><fixed-case>CLP</fixed-case>sych 2016 Shared Task: Triaging content in online peer-support forums</title>
      <author><first>David N.</first> <last>Milne</last></author>
      <author><first>Glen</first> <last>Pink</last></author>
      <author><first>Ben</first> <last>Hachey</last></author>
      <author><first>Rafael A.</first> <last>Calvo</last></author>
      <pages>118–127</pages>
      <url hash="3ee113d7">W16-0312</url>
      <doi>10.18653/v1/W16-0312</doi>
    </paper>
    <paper id="13">
      <title><fixed-case>D</fixed-case>ata61-<fixed-case>CSIRO</fixed-case> systems at the <fixed-case>CLP</fixed-case>sych 2016 Shared Task</title>
      <author><first>Sunghwan Mac</first> <last>Kim</last></author>
      <author><first>Yufei</first> <last>Wang</last></author>
      <author><first>Stephen</first> <last>Wan</last></author>
      <author><first>Cécile</first> <last>Paris</last></author>
      <pages>128–132</pages>
      <url hash="91194a9e">W16-0313</url>
      <doi>10.18653/v1/W16-0313</doi>
    </paper>
    <paper id="14">
      <title>Predicting Post Severity in Mental Health Forums</title>
      <author><first>Shervin</first> <last>Malmasi</last></author>
      <author><first>Marcos</first> <last>Zampieri</last></author>
      <author><first>Mark</first> <last>Dras</last></author>
      <pages>133–137</pages>
      <url hash="07639b1a">W16-0314</url>
      <doi>10.18653/v1/W16-0314</doi>
    </paper>
    <paper id="15">
      <title>Classifying <fixed-case>R</fixed-case>each<fixed-case>O</fixed-case>ut posts with a radial basis function <fixed-case>SVM</fixed-case></title>
      <author><first>Chris</first> <last>Brew</last></author>
      <pages>138–142</pages>
      <url hash="cc488e97">W16-0315</url>
      <doi>10.18653/v1/W16-0315</doi>
    </paper>
    <paper id="16">
      <title>Triaging Mental Health Forum Posts</title>
      <author><first>Arman</first> <last>Cohan</last></author>
      <author><first>Sydney</first> <last>Young</last></author>
      <author><first>Nazli</first> <last>Goharian</last></author>
      <pages>143–147</pages>
      <url hash="b1733c19">W16-0316</url>
      <doi>10.18653/v1/W16-0316</doi>
    </paper>
    <paper id="17">
      <title>Mental Distress Detection and Triage in Forum Posts: The <fixed-case>LT</fixed-case>3 <fixed-case>CLP</fixed-case>sych 2016 Shared Task System</title>
      <author><first>Bart</first> <last>Desmet</last></author>
      <author><first>Gilles</first> <last>Jacobs</last></author>
      <author><first>Véronique</first> <last>Hoste</last></author>
      <pages>148–152</pages>
      <url hash="c836252c">W16-0317</url>
      <doi>10.18653/v1/W16-0317</doi>
    </paper>
    <paper id="18">
      <title>Text Analysis and Automatic Triage of Posts in a Mental Health Forum</title>
      <author><first>Ehsaneddin</first> <last>Asgari</last></author>
      <author><first>Soroush</first> <last>Nasiriany</last></author>
      <author><first>Mohammad R.K.</first> <last>Mofrad</last></author>
      <pages>153–157</pages>
      <url hash="131ada2b">W16-0318</url>
      <doi>10.18653/v1/W16-0318</doi>
    </paper>
    <paper id="19">
      <title>The <fixed-case>UMD</fixed-case> <fixed-case>CLP</fixed-case>sych 2016 Shared Task System: Text Representation for Predicting Triage of Forum Posts about Mental Health</title>
      <author><first>Meir</first> <last>Friedenberg</last></author>
      <author><first>Hadi</first> <last>Amiri</last></author>
      <author><first>Hal</first> <last>Daumé III</last></author>
      <author><first>Philip</first> <last>Resnik</last></author>
      <pages>158–161</pages>
      <url hash="a9e075b5">W16-0319</url>
      <doi>10.18653/v1/W16-0319</doi>
    </paper>
    <paper id="20">
      <title>Using Linear Classifiers for the Automatic Triage of Posts in the 2016 <fixed-case>CLP</fixed-case>sych Shared Task</title>
      <author><first>Juri</first> <last>Opitz</last></author>
      <pages>162–165</pages>
      <url hash="cd734d7c">W16-0320</url>
      <doi>10.18653/v1/W16-0320</doi>
    </paper>
    <paper id="21">
      <title>The <fixed-case>GW</fixed-case>/<fixed-case>UMD</fixed-case> <fixed-case>CLP</fixed-case>sych 2016 Shared Task System</title>
      <author><first>Ayah</first> <last>Zirikly</last></author>
      <author><first>Varun</first> <last>Kumar</last></author>
      <author><first>Philip</first> <last>Resnik</last></author>
      <pages>166–170</pages>
      <url hash="6139e346">W16-0321</url>
      <doi>10.18653/v1/W16-0321</doi>
    </paper>
    <paper id="22">
      <title>Semi-supervised <fixed-case>CLP</fixed-case>sych 2016 Shared Task System Submission</title>
      <author><first>Nicolas</first> <last>Rey-Villamizar</last></author>
      <author><first>Prasha</first> <last>Shrestha</last></author>
      <author><first>Thamar</first> <last>Solorio</last></author>
      <author><first>Farig</first> <last>Sadeque</last></author>
      <author><first>Steven</first> <last>Bethard</last></author>
      <author><first>Ted</first> <last>Pedersen</last></author>
      <pages>171–175</pages>
      <url hash="3a4d8e6d">W16-0322</url>
      <doi>10.18653/v1/W16-0322</doi>
    </paper>
    <paper id="23">
      <title>Combining Multiple Classifiers Using Global Ranking for <fixed-case>R</fixed-case>each<fixed-case>O</fixed-case>ut.com Post Triage</title>
      <author><first>Chen-Kai</first> <last>Wang</last></author>
      <author><first>Hong-Jie</first> <last>Dai</last></author>
      <author><first>Chih-Wei</first> <last>Chen</last></author>
      <author><first>Jitendra</first> <last>Jonnagaddala</last></author>
      <author><first>Nai-Wen</first> <last>Chang</last></author>
      <pages>176–179</pages>
      <url hash="829be90a">W16-0323</url>
      <doi>10.18653/v1/W16-0323</doi>
    </paper>
    <paper id="24">
      <title>Classification of mental health forum posts</title>
      <author><first>Glen</first> <last>Pink</last></author>
      <author><first>Will</first> <last>Radford</last></author>
      <author><first>Ben</first> <last>Hachey</last></author>
      <pages>180–182</pages>
      <url hash="301bdf7c">W16-0324</url>
      <doi>10.18653/v1/W16-0324</doi>
    </paper>
    <paper id="25">
      <title>Automatic Triage of Mental Health Online Forum Posts: <fixed-case>CLP</fixed-case>sych 2016 System Description</title>
      <author><first>Hayda</first> <last>Almeida</last></author>
      <author><first>Marc</first> <last>Queudot</last></author>
      <author><first>Marie-Jean</first> <last>Meurs</last></author>
      <pages>183–187</pages>
      <url hash="76907aca">W16-0325</url>
      <doi>10.18653/v1/W16-0325</doi>
    </paper>
    <paper id="26">
      <title>Automatic Triage of Mental Health Forum Posts</title>
      <author><first>Benjamin</first> <last>Shickel</last></author>
      <author><first>Parisa</first> <last>Rashidi</last></author>
      <pages>188–192</pages>
      <url hash="e300fe56">W16-0326</url>
      <doi>10.18653/v1/W16-0326</doi>
    </paper>
    <paper id="27">
      <title>Text-based experiments for Predicting mental health emergencies in online web forum posts</title>
      <author><first>Hector-Hugo</first> <last>Franco-Penya</last></author>
      <author><first>Liliana</first> <last>Mamani Sanchez</last></author>
      <pages>193–197</pages>
      <url hash="d059b5ff">W16-0327</url>
      <doi>10.18653/v1/W16-0327</doi>
    </paper>
  </volume>
  <volume id="4">
    <meta>
      <booktitle>Proceedings of the 7th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis</booktitle>
      <editor><first>Alexandra</first><last>Balahur</last></editor>
      <editor><first>Erik</first><last>van der Goot</last></editor>
      <editor><first>Piek</first><last>Vossen</last></editor>
      <editor><first>Andres</first><last>Montoyo</last></editor>
      <doi>10.18653/v1/W16-04</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>San Diego, California</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="86cbdace">W16-0400</url>
    </frontmatter>
    <paper id="1">
      <title>Sentiment Analysis - What are we talking about?</title>
      <author><first>Alexandra</first> <last>Balahur</last></author>
      <pages>1</pages>
      <url hash="d1e8beec">W16-0401</url>
      <doi>10.18653/v1/W16-0401</doi>
    </paper>
    <paper id="2">
      <title>Sentiment, Subjectivity, and Social Analysis Go <fixed-case>T</fixed-case>o<fixed-case>W</fixed-case>ork: An Industry View - Invited Talk</title>
      <author><first>Seth</first> <last>Grimes</last></author>
      <pages>2</pages>
      <url hash="c4de1b99">W16-0402</url>
      <doi>10.18653/v1/W16-0402</doi>
    </paper>
    <paper id="3">
      <title>Rumor Identification and Belief Investigation on <fixed-case>T</fixed-case>witter</title>
      <author><first>Sardar</first> <last>Hamidian</last></author>
      <author><first>Mona</first> <last>Diab</last></author>
      <pages>3–8</pages>
      <url hash="401fda19">W16-0403</url>
      <doi>10.18653/v1/W16-0403</doi>
    </paper>
    <paper id="4">
      <title>Modelling Valence and Arousal in <fixed-case>F</fixed-case>acebook posts</title>
      <author><first>Daniel</first> <last>Preoţiuc-Pietro</last></author>
      <author><first>H. Andrew</first> <last>Schwartz</last></author>
      <author><first>Gregory</first> <last>Park</last></author>
      <author><first>Johannes</first> <last>Eichstaedt</last></author>
      <author><first>Margaret</first> <last>Kern</last></author>
      <author><first>Lyle</first> <last>Ungar</last></author>
      <author><first>Elisabeth</first> <last>Shulman</last></author>
      <pages>9–15</pages>
      <url hash="68d5b843">W16-0404</url>
      <doi>10.18653/v1/W16-0404</doi>
      <attachment type="presentation" hash="dc69f38f">W16-0404.Presentation.pdf</attachment>
    </paper>
    <paper id="5">
      <title>Purity Homophily in Social Networks - Invited Talk</title>
      <author><first>Morteza</first> <last>Dehghani</last></author>
      <pages>16</pages>
      <url hash="f11ebb8b">W16-0405</url>
      <doi>10.18653/v1/W16-0405</doi>
    </paper>
    <paper id="6">
      <title>Hit Songs’ Sentiments Harness Public Mood &amp; Predict Stock Market</title>
      <author><first>Rachel</first> <last>Harsley</last></author>
      <author><first>Bhavesh</first> <last>Gupta</last></author>
      <author><first>Barbara</first> <last>Di Eugenio</last></author>
      <author><first>Huayi</first> <last>Li</last></author>
      <pages>17–25</pages>
      <url hash="39e249f1">W16-0406</url>
      <doi>10.18653/v1/W16-0406</doi>
    </paper>
    <paper id="7">
      <title>Fashioning Data - A Social Media Perspective on Fast Fashion Brands</title>
      <author><first>Rupak</first> <last>Chakraborty</last></author>
      <author><first>Senjuti</first> <last>Kundu</last></author>
      <author><first>Prakul</first> <last>Agarwal</last></author>
      <pages>26–35</pages>
      <url hash="46beaa98">W16-0407</url>
      <doi>10.18653/v1/W16-0407</doi>
    </paper>
    <paper id="8">
      <title>Deep Learning for Sentiment Analysis - Invited Talk</title>
      <author><first>Richard</first> <last>Socher</last></author>
      <pages>36</pages>
      <url hash="e5a31ac4">W16-0408</url>
      <doi>10.18653/v1/W16-0408</doi>
    </paper>
    <paper id="9">
      <title>Sentiment Lexicon Creation using Continuous Latent Space and Neural Networks</title>
      <author><first>Pedro</first> <last>Dias Cardoso</last></author>
      <author><first>Anindya</first> <last>Roy</last></author>
      <pages>37–42</pages>
      <url hash="6e09cc1c">W16-0409</url>
      <doi>10.18653/v1/W16-0409</doi>
    </paper>
    <paper id="10">
      <title>The Effect of Negators, Modals, and Degree Adverbs on Sentiment Composition</title>
      <author><first>Svetlana</first> <last>Kiritchenko</last></author>
      <author><first>Saif</first> <last>Mohammad</last></author>
      <pages>43–52</pages>
      <url hash="eab693f9">W16-0410</url>
      <doi>10.18653/v1/W16-0410</doi>
    </paper>
    <paper id="11">
      <title>How can <fixed-case>NLP</fixed-case> Tasks Mutually Benefit Sentiment Analysis? A Holistic Approach to Sentiment Analysis</title>
      <author><first>Lingjia</first> <last>Deng</last></author>
      <author><first>Janyce</first> <last>Wiebe</last></author>
      <pages>53–59</pages>
      <url hash="f9973a96">W16-0411</url>
      <doi>10.18653/v1/W16-0411</doi>
    </paper>
    <paper id="12">
      <title>An Unsupervised System for Visual Exploration of <fixed-case>T</fixed-case>witter Conversations</title>
      <author><first>Derrick</first> <last>Higgins</last></author>
      <author><first>Michael</first> <last>Heilman</last></author>
      <author><first>Adrianna</first> <last>Jelesnianska</last></author>
      <author><first>Keith</first> <last>Ingersoll</last></author>
      <pages>60–65</pages>
      <url hash="7bdb8a2f">W16-0412</url>
      <doi>10.18653/v1/W16-0412</doi>
    </paper>
    <paper id="13">
      <title>Threat detection in online discussions</title>
      <author><first>Aksel</first> <last>Wester</last></author>
      <author><first>Lilja</first> <last>Øvrelid</last></author>
      <author><first>Erik</first> <last>Velldal</last></author>
      <author><first>Hugo Lewi</first> <last>Hammer</last></author>
      <pages>66–71</pages>
      <url hash="893d3a24">W16-0413</url>
      <doi>10.18653/v1/W16-0413</doi>
    </paper>
    <paper id="14">
      <title>Classification of comment helpfulness to improve knowledge sharing among medical practitioners.</title>
      <author><first>Pierre André</first> <last>Ménard</last></author>
      <author><first>Caroline</first> <last>Barrière</last></author>
      <pages>72–81</pages>
      <url hash="2fa3ced4">W16-0414</url>
      <doi>10.18653/v1/W16-0414</doi>
    </paper>
    <paper id="15">
      <title>Political Issue Extraction Model: A Novel Hierarchical Topic Model That Uses Tweets By Political And Non-Political Authors</title>
      <author><first>Aditya</first> <last>Joshi</last></author>
      <author><first>Pushpak</first> <last>Bhattacharyya</last></author>
      <author><first>Mark</first> <last>Carman</last></author>
      <pages>82–90</pages>
      <url hash="a8509dab">W16-0415</url>
      <doi>10.18653/v1/W16-0415</doi>
    </paper>
    <paper id="16">
      <title>Early text classification: a Naïve solution</title>
      <author><first>Hugo Jair</first> <last>Escalante</last></author>
      <author><first>Manuel</first> <last>Montes y Gomez</last></author>
      <author><first>Luis</first> <last>Villasenor</last></author>
      <author><first>Marcelo Luis</first> <last>Errecalde</last></author>
      <pages>91–99</pages>
      <url hash="e76d887e">W16-0416</url>
      <doi>10.18653/v1/W16-0416</doi>
    </paper>
    <paper id="17">
      <title>Semi-supervised and unsupervised categorization of posts in Web discussion forums using part-of-speech information and minimal features</title>
      <author><first>Krish</first> <last>Perumal</last></author>
      <author><first>Graeme</first> <last>Hirst</last></author>
      <pages>100–108</pages>
      <url hash="d20389ac">W16-0417</url>
      <doi>10.18653/v1/W16-0417</doi>
    </paper>
    <paper id="18">
      <title>Linguistic Understanding of Complaints and Praises in User Reviews</title>
      <author><first>Guangyu</first> <last>Zhou</last></author>
      <author><first>Kavita</first> <last>Ganesan</last></author>
      <pages>109–114</pages>
      <url hash="29f186fd">W16-0418</url>
      <doi>10.18653/v1/W16-0418</doi>
    </paper>
    <paper id="19">
      <title>Reputation System: Evaluating Reputation among All Good Sellers</title>
      <author><first>Vandana</first> <last>Jha</last></author>
      <author><first>Savitha</first> <last>R</last></author>
      <author><first>P Deepa</first> <last>Shenoy</last></author>
      <author><first>Venugopal</first> <last>K R</last></author>
      <pages>115–121</pages>
      <url hash="c5ee5425">W16-0419</url>
      <doi>10.18653/v1/W16-0419</doi>
    </paper>
    <paper id="20">
      <title>Improve Sentiment Analysis of Citations with Author Modelling</title>
      <author><first>Zheng</first> <last>Ma</last></author>
      <author><first>Jinseok</first> <last>Nam</last></author>
      <author><first>Karsten</first> <last>Weihe</last></author>
      <pages>122–127</pages>
      <url hash="3a8c64d1">W16-0420</url>
      <doi>10.18653/v1/W16-0420</doi>
    </paper>
    <paper id="21">
      <title>Implicit Aspect Detection in Restaurant Reviews using Cooccurence of Words</title>
      <author><first>Rrubaa</first> <last>Panchendrarajan</last></author>
      <author><first>Nazick</first> <last>Ahamed</last></author>
      <author><first>Brunthavan</first> <last>Murugaiah</last></author>
      <author><first>Prakhash</first> <last>Sivakumar</last></author>
      <author><first>Surangika</first> <last>Ranathunga</last></author>
      <author><first>Akila</first> <last>Pemasiri</last></author>
      <pages>128–136</pages>
      <url hash="c05e4dd6">W16-0421</url>
      <doi>10.18653/v1/W16-0421</doi>
    </paper>
    <paper id="22">
      <title>Domain Adaptation of Polarity Lexicon combining Term Frequency and Bootstrapping</title>
      <author><first>Salud María</first> <last>Jiménez-Zafra</last></author>
      <author><first>Maite</first> <last>Martin</last></author>
      <author><first>M. Dolores</first> <last>Molina-Gonzalez</last></author>
      <author><first>L. Alfonso</first> <last>Ureña-López</last></author>
      <pages>137–146</pages>
      <url hash="ca22333b">W16-0422</url>
      <doi>10.18653/v1/W16-0422</doi>
    </paper>
    <paper id="23">
      <title>Do Enterprises Have Emotions?</title>
      <author><first>Sven</first> <last>Buechel</last></author>
      <author><first>Udo</first> <last>Hahn</last></author>
      <author><first>Jan</first> <last>Goldenstein</last></author>
      <author><first>Sebastian G. M.</first> <last>Händschke</last></author>
      <author><first>Peter</first> <last>Walgenbach</last></author>
      <pages>147–153</pages>
      <url hash="5ed60783">W16-0423</url>
      <doi>10.18653/v1/W16-0423</doi>
    </paper>
    <paper id="24">
      <title>A semantic-affective compositional approach for the affective labelling of adjective-noun and noun-noun pairs</title>
      <author><first>Elisavet</first> <last>Palogiannidi</last></author>
      <author><first>Elias</first> <last>Iosif</last></author>
      <author><first>Polychronis</first> <last>Koutsakis</last></author>
      <author><first>Alexandros</first> <last>Potamianos</last></author>
      <pages>154–160</pages>
      <url hash="96352bd3">W16-0424</url>
      <doi>10.18653/v1/W16-0424</doi>
    </paper>
    <paper id="25">
      <title>Fracking Sarcasm using Neural Network</title>
      <author><first>Aniruddha</first> <last>Ghosh</last></author>
      <author><first>Tony</first> <last>Veale</last></author>
      <pages>161–169</pages>
      <url hash="25749269">W16-0425</url>
      <doi>10.18653/v1/W16-0425</doi>
    </paper>
    <paper id="26">
      <title>An Hymn of an even Deeper Sentiment Analysis</title>
      <author><first>Manfred</first> <last>Klenner</last></author>
      <pages>170</pages>
      <url hash="c4ae5925">W16-0426</url>
      <doi>10.18653/v1/W16-0426</doi>
    </paper>
    <paper id="27">
      <title>Sentiment Analysis in <fixed-case>T</fixed-case>witter: A <fixed-case>S</fixed-case>em<fixed-case>E</fixed-case>val Perspective</title>
      <author><first>Preslav</first> <last>Nakov</last></author>
      <pages>171–172</pages>
      <url hash="5ee25c69">W16-0427</url>
      <doi>10.18653/v1/W16-0427</doi>
    </paper>
    <paper id="28">
      <title>The Challenge of Sentiment Quantification</title>
      <author><first>Fabrizio</first> <last>Sebastiani</last></author>
      <pages>173</pages>
      <url hash="ee8844d7">W16-0428</url>
      <doi>10.18653/v1/W16-0428</doi>
    </paper>
    <paper id="29">
      <title>A Practical Guide to Sentiment Annotation: Challenges and Solutions</title>
      <author><first>Saif</first> <last>Mohammad</last></author>
      <pages>174–179</pages>
      <url hash="a2a991ec">W16-0429</url>
      <doi>10.18653/v1/W16-0429</doi>
    </paper>
    <paper id="30">
      <title>Emotions and <fixed-case>NLP</fixed-case>: Future Directions</title>
      <author><first>Carlo</first> <last>Strapparava</last></author>
      <pages>180</pages>
      <url hash="55db6d0d">W16-0430</url>
      <doi>10.18653/v1/W16-0430</doi>
    </paper>
  </volume>
  <volume id="5">
    <meta>
      <booktitle>Proceedings of the 11th Workshop on Innovative Use of <fixed-case>NLP</fixed-case> for Building Educational Applications</booktitle>
      <editor><first>Joel</first> <last>Tetreault</last></editor>
      <editor><first>Jill</first> <last>Burstein</last></editor>
      <editor><first>Claudia</first> <last>Leacock</last></editor>
      <editor><first>Helen</first> <last>Yannakoudakis</last></editor>
      <doi>10.18653/v1/W16-05</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>San Diego, CA</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="039acc36">W16-0500</url>
    </frontmatter>
    <paper id="1">
      <title>The Effect of Multiple Grammatical Errors on Processing Non-Native Writing</title>
      <author><first>Courtney</first> <last>Napoles</last></author>
      <author><first>Aoife</first> <last>Cahill</last></author>
      <author><first>Nitin</first> <last>Madnani</last></author>
      <pages>1–11</pages>
      <url hash="e3142370">W16-0501</url>
      <doi>10.18653/v1/W16-0501</doi>
    </paper>
    <paper id="2">
      <title>Text Readability Assessment for Second Language Learners</title>
      <author><first>Menglin</first> <last>Xia</last></author>
      <author><first>Ekaterina</first> <last>Kochmar</last></author>
      <author><first>Ted</first> <last>Briscoe</last></author>
      <pages>12–22</pages>
      <url hash="308e9d6b">W16-0502</url>
      <doi>10.18653/v1/W16-0502</doi>
    </paper>
    <paper id="3">
      <title>Automatic Generation of Context-Based Fill-in-the-Blank Exercises Using Co-occurrence Likelihoods and <fixed-case>G</fixed-case>oogle n-grams</title>
      <author><first>Jennifer</first> <last>Hill</last></author>
      <author><first>Rahul</first> <last>Simha</last></author>
      <pages>23–30</pages>
      <url hash="6c853ab0">W16-0503</url>
      <doi>10.18653/v1/W16-0503</doi>
    </paper>
    <paper id="4">
      <title>Automated classification of collaborative problem solving interactions in simulated science tasks</title>
      <author><first>Michael</first> <last>Flor</last></author>
      <author><first>Su-Youn</first> <last>Yoon</last></author>
      <author><first>Jiangang</first> <last>Hao</last></author>
      <author><first>Lei</first> <last>Liu</last></author>
      <author><first>Alina</first> <last>von Davier</last></author>
      <pages>31–41</pages>
      <url hash="b3882fca">W16-0504</url>
      <doi>10.18653/v1/W16-0504</doi>
    </paper>
    <paper id="5">
      <title>Computer-assisted stylistic revision with incomplete and noisy feedback. A pilot study</title>
      <author><first>Christian M.</first> <last>Meyer</last></author>
      <author><first>Johann Frerik</first> <last>Koch</last></author>
      <pages>42–52</pages>
      <url hash="99057419">W16-0505</url>
      <doi>10.18653/v1/W16-0505</doi>
    </paper>
    <paper id="6">
      <title>A Report on the Automatic Evaluation of Scientific Writing Shared Task</title>
      <author><first>Vidas</first> <last>Daudaravicius</last></author>
      <author><first>Rafael E.</first> <last>Banchs</last></author>
      <author><first>Elena</first> <last>Volodina</last></author>
      <author><first>Courtney</first> <last>Napoles</last></author>
      <pages>53–62</pages>
      <url hash="cbc0a529">W16-0506</url>
      <doi>10.18653/v1/W16-0506</doi>
    </paper>
    <paper id="7">
      <title>Topicality-Based Indices for Essay Scoring</title>
      <author><first>Beata</first> <last>Beigman Klebanov</last></author>
      <author><first>Michael</first> <last>Flor</last></author>
      <author><first>Binod</first> <last>Gyawali</last></author>
      <pages>63–72</pages>
      <url hash="994b34d9">W16-0507</url>
      <doi>10.18653/v1/W16-0507</doi>
    </paper>
    <paper id="8">
      <title>Predicting the Spelling Difficulty of Words for Language Learners</title>
      <author><first>Lisa</first> <last>Beinborn</last></author>
      <author><first>Torsten</first> <last>Zesch</last></author>
      <author><first>Iryna</first> <last>Gurevych</last></author>
      <pages>73–83</pages>
      <url hash="10d5c3fe">W16-0508</url>
      <doi>10.18653/v1/W16-0508</doi>
    </paper>
    <paper id="9">
      <title>Characterizing Text Difficulty with Word Frequencies</title>
      <author><first>Xiaobin</first> <last>Chen</last></author>
      <author><first>Detmar</first> <last>Meurers</last></author>
      <pages>84–94</pages>
      <url hash="d712ff1d">W16-0509</url>
      <doi>10.18653/v1/W16-0509</doi>
    </paper>
    <paper id="10">
      <title>Unsupervised Modeling of Topical Relevance in <fixed-case>L</fixed-case>2 Learner Text</title>
      <author><first>Ronan</first> <last>Cummins</last></author>
      <author><first>Helen</first> <last>Yannakoudakis</last></author>
      <author><first>Ted</first> <last>Briscoe</last></author>
      <pages>95–104</pages>
      <url hash="1e190a37">W16-0510</url>
      <doi>10.18653/v1/W16-0510</doi>
    </paper>
    <paper id="11">
      <title><fixed-case>UW</fixed-case>-<fixed-case>S</fixed-case>tanford System Description for <fixed-case>AESW</fixed-case> 2016 Shared Task on Grammatical Error Detection</title>
      <author><first>Dan</first> <last>Flickinger</last></author>
      <author><first>Michael</first> <last>Goodman</last></author>
      <author><first>Woodley</first> <last>Packard</last></author>
      <pages>105–111</pages>
      <url hash="3b2396c7">W16-0511</url>
      <doi>10.18653/v1/W16-0511</doi>
    </paper>
    <paper id="12">
      <title>Shallow Semantic Reasoning from an Incomplete Gold Standard for Learner Language</title>
      <author><first>Levi</first> <last>King</last></author>
      <author><first>Markus</first> <last>Dickinson</last></author>
      <pages>112–121</pages>
      <url hash="12e3f330">W16-0512</url>
      <doi>10.18653/v1/W16-0512</doi>
    </paper>
    <paper id="13">
      <title>The <fixed-case>NTNU</fixed-case>-<fixed-case>YZU</fixed-case> System in the <fixed-case>AESW</fixed-case> Shared Task: Automated Evaluation of Scientific Writing Using a Convolutional Neural Network</title>
      <author><first>Lung-Hao</first> <last>Lee</last></author>
      <author><first>Bo-Lin</first> <last>Lin</last></author>
      <author><first>Liang-Chih</first> <last>Yu</last></author>
      <author><first>Yuen-Hsien</first> <last>Tseng</last></author>
      <pages>122–129</pages>
      <url hash="b81f8193">W16-0513</url>
      <doi>10.18653/v1/W16-0513</doi>
    </paper>
    <paper id="14">
      <title>Automated scoring across different modalities</title>
      <author><first>Anastassia</first> <last>Loukina</last></author>
      <author><first>Aoife</first> <last>Cahill</last></author>
      <pages>130–135</pages>
      <url hash="1658a80b">W16-0514</url>
      <doi>10.18653/v1/W16-0514</doi>
    </paper>
    <paper id="15">
      <title>Model Combination for Correcting Preposition Selection Errors</title>
      <author><first>Nitin</first> <last>Madnani</last></author>
      <author><first>Michael</first> <last>Heilman</last></author>
      <author><first>Aoife</first> <last>Cahill</last></author>
      <pages>136–141</pages>
      <url hash="9591c092">W16-0515</url>
      <doi>10.18653/v1/W16-0515</doi>
    </paper>
    <paper id="16">
      <title><fixed-case>P</fixed-case>ictogrammar: an <fixed-case>AAC</fixed-case> device based on a semantic grammar</title>
      <author><first>Fernando</first> <last>Martínez-Santiago</last></author>
      <author><first>Miguel Ángel</first> <last>García-Cumbreras</last></author>
      <author><first>Arturo</first> <last>Montejo-Ráez</last></author>
      <author><first>Manuel Carlos</first> <last>Díaz-Galiano</last></author>
      <pages>142–150</pages>
      <url hash="a75a4b7a">W16-0516</url>
      <doi>10.18653/v1/W16-0516</doi>
    </paper>
    <paper id="17">
      <title>Detecting Context Dependence in Exercise Item Candidates Selected from Corpora</title>
      <author><first>Ildikó</first> <last>Pilán</last></author>
      <pages>151–161</pages>
      <url hash="3ed5ec41">W16-0517</url>
      <doi>10.18653/v1/W16-0517</doi>
    </paper>
    <paper id="18">
      <title>Feature-Rich Error Detection in Scientific Writing Using Logistic Regression</title>
      <author><first>Madeline</first> <last>Remse</last></author>
      <author><first>Mohsen</first> <last>Mesgar</last></author>
      <author><first>Michael</first> <last>Strube</last></author>
      <pages>162–171</pages>
      <url hash="9aa7fcf7">W16-0518</url>
      <doi>10.18653/v1/W16-0518</doi>
    </paper>
    <paper id="19">
      <title>Bundled Gap Filling: A New Paradigm for Unambiguous Cloze Exercises</title>
      <author><first>Michael</first> <last>Wojatzki</last></author>
      <author><first>Oren</first> <last>Melamud</last></author>
      <author><first>Torsten</first> <last>Zesch</last></author>
      <pages>172–181</pages>
      <url hash="cad1bd77">W16-0519</url>
      <doi>10.18653/v1/W16-0519</doi>
    </paper>
    <paper id="20">
      <title>Evaluation Dataset (<fixed-case>DT</fixed-case>-Grade) and Word Weighting Approach towards Constructed Short Answers Assessment in Tutorial Dialogue Context</title>
      <author><first>Rajendra</first> <last>Banjade</last></author>
      <author><first>Nabin</first> <last>Maharjan</last></author>
      <author><first>Nobal Bikram</first> <last>Niraula</last></author>
      <author><first>Dipesh</first> <last>Gautam</last></author>
      <author><first>Borhan</first> <last>Samei</last></author>
      <author><first>Vasile</first> <last>Rus</last></author>
      <pages>182–187</pages>
      <url hash="d9f90a90">W16-0520</url>
      <doi>10.18653/v1/W16-0520</doi>
    </paper>
    <paper id="21">
      <title>Linguistically Aware Information Retrieval: Providing Input Enrichment for Second Language Learners</title>
      <author><first>Maria</first> <last>Chinkina</last></author>
      <author><first>Detmar</first> <last>Meurers</last></author>
      <pages>188–198</pages>
      <url hash="f558af2b">W16-0521</url>
      <doi>10.18653/v1/W16-0521</doi>
    </paper>
    <paper id="22">
      <title>Enhancing <fixed-case>STEM</fixed-case> Motivation through Personal and Communal Values: <fixed-case>NLP</fixed-case> for Assessment of Utility Value in Student Writing</title>
      <author><first>Beata</first> <last>Beigman Klebanov</last></author>
      <author><first>Jill</first> <last>Burstein</last></author>
      <author><first>Judith</first> <last>Harackiewicz</last></author>
      <author><first>Stacy</first> <last>Priniski</last></author>
      <author><first>Matthew</first> <last>Mulholland</last></author>
      <pages>199–205</pages>
      <url hash="c6372be6">W16-0522</url>
      <doi>10.18653/v1/W16-0522</doi>
    </paper>
    <paper id="23">
      <title>Cost-Effectiveness in Building a Low-Resource Morphological Analyzer for Learner Language</title>
      <author><first>Scott</first> <last>Ledbetter</last></author>
      <author><first>Markus</first> <last>Dickinson</last></author>
      <pages>206–216</pages>
      <url hash="1f41c385">W16-0523</url>
      <doi>10.18653/v1/W16-0523</doi>
    </paper>
    <paper id="24">
      <title>Automatically Scoring Tests of Proficiency in Music Instruction</title>
      <author><first>Nitin</first> <last>Madnani</last></author>
      <author><first>Aoife</first> <last>Cahill</last></author>
      <author><first>Brian</first> <last>Riordan</last></author>
      <pages>217–222</pages>
      <url hash="22554673">W16-0524</url>
      <doi>10.18653/v1/W16-0524</doi>
    </paper>
    <paper id="25">
      <title>Combined Tree Kernel-based classifiers for Assessing Quality of Scientific Text</title>
      <author><first>Liliana</first> <last>Mamani Sanchez</last></author>
      <author><first>Hector-Hugo</first> <last>Franco-Penya</last></author>
      <pages>223–228</pages>
      <url hash="c5f2fd86">W16-0525</url>
      <doi>10.18653/v1/W16-0525</doi>
    </paper>
    <paper id="26">
      <title>Augmenting Course Material with Open Access Textbooks</title>
      <author><first>Smitha</first> <last>Milli</last></author>
      <author><first>Marti A.</first> <last>Hearst</last></author>
      <pages>229–234</pages>
      <url hash="86c7284e">W16-0526</url>
      <doi>10.18653/v1/W16-0526</doi>
    </paper>
    <paper id="27">
      <title>Exploring the Intersection of Short Answer Assessment, Authorship Attribution, and Plagiarism Detection</title>
      <author><first>Björn</first> <last>Rudzewitz</last></author>
      <pages>235–241</pages>
      <url hash="f61db8e3">W16-0527</url>
      <doi>10.18653/v1/W16-0527</doi>
    </paper>
    <paper id="28">
      <title>Sentence-Level Grammatical Error Identification as Sequence-to-Sequence Correction</title>
      <author><first>Allen</first> <last>Schmaltz</last></author>
      <author><first>Yoon</first> <last>Kim</last></author>
      <author><first>Alexander M.</first> <last>Rush</last></author>
      <author><first>Stuart</first> <last>Shieber</last></author>
      <pages>242–251</pages>
      <url hash="568c2971">W16-0528</url>
      <doi>10.18653/v1/W16-0528</doi>
    </paper>
    <paper id="29">
      <title>Combining Off-the-shelf Grammar and Spelling Tools for the Automatic Evaluation of Scientific Writing (<fixed-case>AESW</fixed-case>) Shared Task 2016</title>
      <author><first>René</first> <last>Witte</last></author>
      <author><first>Bahar</first> <last>Sateli</last></author>
      <pages>252–255</pages>
      <url hash="2ace0d30">W16-0529</url>
      <doi>10.18653/v1/W16-0529</doi>
    </paper>
    <paper id="30">
      <title>Candidate re-ranking for <fixed-case>SMT</fixed-case>-based grammatical error correction</title>
      <author><first>Zheng</first> <last>Yuan</last></author>
      <author><first>Ted</first> <last>Briscoe</last></author>
      <author><first>Mariano</first> <last>Felice</last></author>
      <pages>256–266</pages>
      <url hash="ff6b8958">W16-0530</url>
      <doi>10.18653/v1/W16-0530</doi>
    </paper>
    <paper id="31">
      <title>Spoken Text Difficulty Estimation Using Linguistic Features</title>
      <author><first>Su-Youn</first> <last>Yoon</last></author>
      <author><first>Yeonsuk</first> <last>Cho</last></author>
      <author><first>Diane</first> <last>Napolitano</last></author>
      <pages>267–276</pages>
      <url hash="fac3ce50">W16-0531</url>
      <doi>10.18653/v1/W16-0531</doi>
    </paper>
    <paper id="32">
      <title>Automatically Extracting Topical Components for a Response-to-Text Writing Assessment</title>
      <author><first>Zahra</first> <last>Rahimi</last></author>
      <author><first>Diane</first> <last>Litman</last></author>
      <pages>277–282</pages>
      <url hash="f88021b8">W16-0532</url>
      <doi>10.18653/v1/W16-0532</doi>
    </paper>
    <paper id="33">
      <title>Sentence Similarity Measures for Fine-Grained Estimation of Topical Relevance in Learner Essays</title>
      <author><first>Marek</first> <last>Rei</last></author>
      <author><first>Ronan</first> <last>Cummins</last></author>
      <pages>283–288</pages>
      <url hash="50a039a4">W16-0533</url>
      <doi>10.18653/v1/W16-0533</doi>
    </paper>
    <paper id="34">
      <title>Insights from <fixed-case>R</fixed-case>ussian second language readability classification: complexity-dependent training requirements, and feature evaluation of multiple categories</title>
      <author><first>Robert</first> <last>Reynolds</last></author>
      <pages>289–300</pages>
      <url hash="1aa387de">W16-0534</url>
      <doi>10.18653/v1/W16-0534</doi>
    </paper>
    <paper id="35">
      <title>Investigating Active Learning for Short-Answer Scoring</title>
      <author><first>Andrea</first> <last>Horbach</last></author>
      <author><first>Alexis</first> <last>Palmer</last></author>
      <pages>301–311</pages>
      <url hash="1b066dd3">W16-0535</url>
      <doi>10.18653/v1/W16-0535</doi>
    </paper>
  </volume>
  <volume id="6">
    <meta>
      <booktitle>Proceedings of the 2nd Workshop on Semantics-Driven Machine Translation (<fixed-case>S</fixed-case>ed<fixed-case>MT</fixed-case> 2016)</booktitle>
      <editor><first>Deyi</first><last>Xiong</last></editor>
      <editor><first>Kevin</first><last>Duh</last></editor>
      <editor><first>Eneko</first><last>Agirre</last></editor>
      <editor><first>Nora</first><last>Aranberri</last></editor>
      <editor><first>Houfeng</first><last>Wang</last></editor>
      <doi>10.18653/v1/W16-06</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>San Diego, California</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="918828fb">W16-0600</url>
    </frontmatter>
    <paper id="1">
      <title>Deterministic natural language generation from meaning representations for machine translation</title>
      <author><first>Alastair</first> <last>Butler</last></author>
      <pages>1–9</pages>
      <url hash="0a4e6318">W16-0601</url>
      <doi>10.18653/v1/W16-0601</doi>
    </paper>
    <paper id="2">
      <title>Extending Phrase-Based Translation with Dependencies by Using Graphs</title>
      <author><first>Liangyou</first> <last>Li</last></author>
      <author><first>Andy</first> <last>Way</last></author>
      <author><first>Qun</first> <last>Liu</last></author>
      <pages>10–12</pages>
      <url hash="f6b5adad">W16-0602</url>
      <doi>10.18653/v1/W16-0602</doi>
    </paper>
    <paper id="3">
      <title>The Naming Sharing Structure and its Cognitive Meaning in <fixed-case>C</fixed-case>hinese and <fixed-case>E</fixed-case>nglish</title>
      <author><first>Shili</first> <last>Ge</last></author>
      <author><first>Rou</first> <last>Song</last></author>
      <pages>13–21</pages>
      <url hash="129a1f8f">W16-0603</url>
      <doi>10.18653/v1/W16-0603</doi>
    </paper>
    <paper id="4">
      <title>Towards Semantic-based Hybrid Machine Translation between <fixed-case>B</fixed-case>ulgarian and <fixed-case>E</fixed-case>nglish</title>
      <author><first>Kiril</first> <last>Simov</last></author>
      <author><first>Petya</first> <last>Osenova</last></author>
      <author><first>Alexander</first> <last>Popov</last></author>
      <pages>22–26</pages>
      <url hash="cc6d3e71">W16-0604</url>
      <doi>10.18653/v1/W16-0604</doi>
    </paper>
  </volume>
  <volume id="7">
    <meta>
      <booktitle>Proceedings of the Workshop on Coreference Resolution Beyond <fixed-case>O</fixed-case>nto<fixed-case>N</fixed-case>otes (<fixed-case>CORBON</fixed-case> 2016)</booktitle>
      <editor><first>Maciej</first><last>Ogrodniczuk</last></editor>
      <editor><first>Vincent</first><last>Ng</last></editor>
      <doi>10.18653/v1/W16-07</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>San Diego, California</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="079de2d2">W16-0700</url>
    </frontmatter>
    <paper id="1">
      <title>Sense Anaphoric Pronouns: Am <fixed-case>I</fixed-case> One?</title>
      <author><first>Marta</first> <last>Recasens</last></author>
      <author><first>Zhichao</first> <last>Hu</last></author>
      <author><first>Olivia</first> <last>Rhinehart</last></author>
      <pages>1–6</pages>
      <url hash="8cb2a6e1">W16-0701</url>
      <doi>10.18653/v1/W16-0701</doi>
    </paper>
    <paper id="2">
      <title>Experiments on bridging across languages and genres</title>
      <author><first>Yulia</first> <last>Grishina</last></author>
      <pages>7–15</pages>
      <url hash="745f2fc8">W16-0702</url>
      <doi>10.18653/v1/W16-0702</doi>
    </paper>
    <paper id="3">
      <title>Bridging Relations in <fixed-case>P</fixed-case>olish: Adaptation of Existing Typologies</title>
      <author><first>Maciej</first> <last>Ogrodniczuk</last></author>
      <author><first>Magdalena</first> <last>Zawisławska</last></author>
      <pages>16–22</pages>
      <url hash="137731d0">W16-0703</url>
      <doi>10.18653/v1/W16-0703</doi>
    </paper>
    <paper id="4">
      <title>Beyond Identity Coreference: Contrasting Indicators of Textual Coherence in <fixed-case>E</fixed-case>nglish and <fixed-case>G</fixed-case>erman</title>
      <author><first>Kerstin</first> <last>Kunz</last></author>
      <author><first>Ekaterina</first> <last>Lapshinova-Koltunski</last></author>
      <author><first>José Manuel</first> <last>Martínez</last></author>
      <pages>23–31</pages>
      <url hash="6bb2d15d">W16-0704</url>
      <doi>10.18653/v1/W16-0704</doi>
    </paper>
    <paper id="5">
      <title>Exploring the steps of Verb Phrase Ellipsis</title>
      <author><first>Zhengzhong</first> <last>Liu</last></author>
      <author><first>Edgar</first> <last>Gonzàlez Pellicer</last></author>
      <author><first>Daniel</first> <last>Gillick</last></author>
      <pages>32–40</pages>
      <url hash="89fce31c">W16-0705</url>
      <doi>10.18653/v1/W16-0705</doi>
    </paper>
    <paper id="6">
      <title>Anaphoricity in Connectives: A Case Study on <fixed-case>G</fixed-case>erman</title>
      <author><first>Manfred</first> <last>Stede</last></author>
      <author><first>Yulia</first> <last>Grishina</last></author>
      <pages>41–46</pages>
      <url hash="41c73a86">W16-0706</url>
      <doi>10.18653/v1/W16-0706</doi>
    </paper>
    <paper id="7">
      <title>Abstract Coreference in a Multilingual Perspective: a View on <fixed-case>C</fixed-case>zech and <fixed-case>G</fixed-case>erman</title>
      <author><first>Anna</first> <last>Nedoluzhko</last></author>
      <author><first>Ekaterina</first> <last>Lapshinova-Koltunski</last></author>
      <pages>47–52</pages>
      <url hash="3dd1eed5">W16-0707</url>
      <doi>10.18653/v1/W16-0707</doi>
    </paper>
    <paper id="8">
      <title>Antecedent Prediction Without a Pipeline</title>
      <author><first>Sam</first> <last>Wiseman</last></author>
      <author><first>Alexander M.</first> <last>Rush</last></author>
      <author><first>Stuart</first> <last>Shieber</last></author>
      <pages>53–58</pages>
      <url hash="8844df61">W16-0708</url>
      <doi>10.18653/v1/W16-0708</doi>
    </paper>
    <paper id="9">
      <title>Bridging Corpus for <fixed-case>R</fixed-case>ussian in comparison with <fixed-case>C</fixed-case>zech</title>
      <author><first>Anna</first> <last>Roitberg</last></author>
      <author><first>Anna</first> <last>Nedoluzhko</last></author>
      <pages>59–66</pages>
      <url hash="d14eb7f6">W16-0709</url>
      <doi>10.18653/v1/W16-0709</doi>
    </paper>
    <paper id="10">
      <title>Coreference Resolution for the <fixed-case>B</fixed-case>asque Language with <fixed-case>BART</fixed-case></title>
      <author><first>Ander</first> <last>Soraluze</last></author>
      <author><first>Olatz</first> <last>Arregi</last></author>
      <author><first>Xabier</first> <last>Arregi</last></author>
      <author><first>Arantza</first> <last>Díaz de Ilarraza</last></author>
      <author><first>Mijail</first> <last>Kabadjov</last></author>
      <author><first>Massimo</first> <last>Poesio</last></author>
      <pages>67–73</pages>
      <url hash="32a732ea">W16-0710</url>
      <doi>10.18653/v1/W16-0710</doi>
    </paper>
    <paper id="11">
      <title>Error analysis for anaphora resolution in <fixed-case>R</fixed-case>ussian: new challenging issues for anaphora resolution task in a morphologically rich language</title>
      <author><first>Svetlana</first> <last>Toldova</last></author>
      <author><first>Ilya</first> <last>Azerkovich</last></author>
      <author><first>Alina</first> <last>Ladygina</last></author>
      <author><first>Anna</first> <last>Roitberg</last></author>
      <author><first>Maria</first> <last>Vasilyeva</last></author>
      <pages>74–83</pages>
      <url hash="9fc495d1">W16-0711</url>
      <doi>10.18653/v1/W16-0711</doi>
    </paper>
    <paper id="12">
      <title>How to Handle Split Antecedents in <fixed-case>T</fixed-case>amil?</title>
      <author><first>Vijay</first> <last>Sundar Ram</last></author>
      <author><first>Sobha</first> <last>Lalitha Devi</last></author>
      <pages>84–91</pages>
      <url hash="acec4f7f">W16-0712</url>
      <doi>10.18653/v1/W16-0712</doi>
    </paper>
    <paper id="13">
      <title>When Annotation Schemes Change Rules Help: A Configurable Approach to Coreference Resolution beyond <fixed-case>O</fixed-case>nto<fixed-case>N</fixed-case>otes</title>
      <author><first>Amir</first> <last>Zeldes</last></author>
      <author><first>Shuo</first> <last>Zhang</last></author>
      <pages>92–101</pages>
      <url hash="33f688fd">W16-0713</url>
      <doi>10.18653/v1/W16-0713</doi>
    </paper>
  </volume>
  <volume id="8">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Computational Approaches to Deception Detection</booktitle>
      <editor><first>Tommaso</first><last>Fornaciari</last></editor>
      <editor><first>Eileen</first><last>Fitzpatrick</last></editor>
      <editor><first>Joan</first><last>Bachenko</last></editor>
      <doi>10.18653/v1/W16-08</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>San Diego, California</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="33003660">W16-0800</url>
    </frontmatter>
    <paper id="1">
      <title>Account Deletion Prediction on <fixed-case>R</fixed-case>u<fixed-case>N</fixed-case>et: A Case Study of Suspicious <fixed-case>T</fixed-case>witter Accounts Active During the <fixed-case>R</fixed-case>ussian-<fixed-case>U</fixed-case>krainian Crisis</title>
      <author><first>Svitlana</first> <last>Volkova</last></author>
      <author><first>Eric</first> <last>Bell</last></author>
      <pages>1–6</pages>
      <url hash="74c399a1">W16-0801</url>
      <doi>10.18653/v1/W16-0801</doi>
    </paper>
    <paper id="2">
      <title>Fake News or Truth? Using Satirical Cues to Detect Potentially Misleading News</title>
      <author><first>Victoria</first> <last>Rubin</last></author>
      <author><first>Niall</first> <last>Conroy</last></author>
      <author><first>Yimin</first> <last>Chen</last></author>
      <author><first>Sarah</first> <last>Cornwell</last></author>
      <pages>7–17</pages>
      <url hash="a4ad3802">W16-0802</url>
      <doi>10.18653/v1/W16-0802</doi>
    </paper>
    <paper id="3">
      <title>Using the verifiability of details as a test of deception: A conceptual framework for the automation of the verifiability approach</title>
      <author><first>Bennett</first> <last>Kleinberg</last></author>
      <author><first>Galit</first> <last>Nahari</last></author>
      <author><first>Bruno</first> <last>Verschuere</last></author>
      <pages>18–25</pages>
      <url hash="277129d7">W16-0803</url>
      <doi>10.18653/v1/W16-0803</doi>
    </paper>
    <paper id="4">
      <title>Estimating the amenibility of new domains for deception detection</title>
      <author><first>Eileen</first> <last>Fitzpatrick</last></author>
      <author><first>Joan</first> <last>Bachenko</last></author>
      <pages>26–31</pages>
      <url hash="7856d68f">W16-0804</url>
      <doi>10.18653/v1/W16-0804</doi>
    </paper>
    <paper id="5">
      <title>The Use of Second Life for Deception Detection Research</title>
      <author><first>Stephen</first> <last>Kunath</last></author>
      <author><first>Kevin</first> <last>McCabe</last></author>
      <pages>32–39</pages>
      <url hash="ffea7b5c">W16-0805</url>
      <doi>10.18653/v1/W16-0805</doi>
    </paper>
    <paper id="6">
      <title>Identifying Individual Differences in Gender, Ethnicity, and Personality from Dialogue for Deception Detection</title>
      <author><first>Sarah Ita</first> <last>Levitan</last></author>
      <author><first>Yocheved</first> <last>Levitan</last></author>
      <author><first>Guozhen</first> <last>An</last></author>
      <author><first>Michelle</first> <last>Levine</last></author>
      <author><first>Rivka</first> <last>Levitan</last></author>
      <author><first>Andrew</first> <last>Rosenberg</last></author>
      <author><first>Julia</first> <last>Hirschberg</last></author>
      <pages>40–44</pages>
      <url hash="efd8dc5b">W16-0806</url>
      <doi>10.18653/v1/W16-0806</doi>
    </paper>
    <paper id="7">
      <title>Individual Differences in Strategic Deception</title>
      <author><first>Scott</first> <last>Appling</last></author>
      <author><first>Erica</first> <last>Briscoe</last></author>
      <pages>45–52</pages>
      <url hash="03bcd413">W16-0807</url>
      <doi>10.18653/v1/W16-0807</doi>
    </paper>
  </volume>
  <volume id="9">
    <meta>
      <booktitle>Proceedings of the Workshop on Discontinuous Structures in Natural Language Processing</booktitle>
      <editor><first>Wolfgang</first><last>Maier</last></editor>
      <editor><first>Sandra</first><last>Kübler</last></editor>
      <editor><first>Constantin</first><last>Orasan</last></editor>
      <doi>10.18653/v1/W16-09</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>San Diego, California</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="8b8e5722">W16-0900</url>
    </frontmatter>
    <paper id="1">
      <title>An <fixed-case>LFG</fixed-case> Account of Discontinuous Nominal Expressions</title>
      <author><first>Liselotte</first> <last>Snijders</last></author>
      <pages>1–11</pages>
      <url hash="bb324340">W16-0901</url>
      <doi>10.18653/v1/W16-0901</doi>
    </paper>
    <paper id="2">
      <title>Non-projectivity and valency</title>
      <author><first>Zdenka</first> <last>Uresova</last></author>
      <author><first>Eva</first> <last>Fucikova</last></author>
      <author><first>Jan</first> <last>Hajic</last></author>
      <pages>12–21</pages>
      <url hash="ef278552">W16-0902</url>
      <doi>10.18653/v1/W16-0902</doi>
    </paper>
    <paper id="3">
      <title>Machine Translation of Non-Contiguous Multiword Units</title>
      <author><first>Anabela</first> <last>Barreiro</last></author>
      <author><first>Fernando</first> <last>Batista</last></author>
      <pages>22–30</pages>
      <url hash="ca19599e">W16-0903</url>
      <doi>10.18653/v1/W16-0903</doi>
    </paper>
    <paper id="4">
      <title>Discontinuous <fixed-case>VP</fixed-case> in <fixed-case>B</fixed-case>ulgarian</title>
      <author><first>Elisaveta</first> <last>Balabanova</last></author>
      <pages>31–36</pages>
      <url hash="16ea0f71">W16-0904</url>
      <doi>10.18653/v1/W16-0904</doi>
    </paper>
    <paper id="5">
      <title>Discontinuous Genitives in <fixed-case>H</fixed-case>indi/<fixed-case>U</fixed-case>rdu</title>
      <author><first>Sebastian</first> <last>Sulger</last></author>
      <pages>37–46</pages>
      <url hash="355cc297">W16-0905</url>
      <doi>10.18653/v1/W16-0905</doi>
    </paper>
    <paper id="6">
      <title>Discontinuous parsing with continuous trees</title>
      <author><first>Wolfgang</first> <last>Maier</last></author>
      <author><first>Timm</first> <last>Lichte</last></author>
      <pages>47–57</pages>
      <url hash="a8218695">W16-0906</url>
      <doi>10.18653/v1/W16-0906</doi>
    </paper>
    <paper id="7">
      <title>Discontinuity (Re)²-visited: A Minimalist Approach to Pseudoprojective Constituent Parsing</title>
      <author><first>Yannick</first> <last>Versley</last></author>
      <pages>58–69</pages>
      <url hash="ea830911">W16-0907</url>
      <doi>10.18653/v1/W16-0907</doi>
    </paper>
  </volume>
  <volume id="10">
    <meta>
      <booktitle>Proceedings of the Fourth Workshop on Events</booktitle>
      <editor><first>Martha</first><last>Palmer</last></editor>
      <editor><first>Ed</first><last>Hovy</last></editor>
      <editor><first>Teruko</first><last>Mitamura</last></editor>
      <editor><first>Tim</first><last>O’Gorman</last></editor>
      <doi>10.18653/v1/W16-10</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>San Diego, California</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="0e3f9268">W16-1000</url>
    </frontmatter>
    <paper id="1">
      <title>“Making the News”: Identifying Noteworthy Events in News Articles</title>
      <author><first>Shyam</first> <last>Upadhyay</last></author>
      <author><first>Christos</first> <last>Christodoulopoulos</last></author>
      <author><first>Dan</first> <last>Roth</last></author>
      <pages>1–7</pages>
      <url hash="f3962f99">W16-1001</url>
      <doi>10.18653/v1/W16-1001</doi>
    </paper>
    <paper id="2">
      <title>Annotation of causal and aspectual structure of events in <fixed-case>RED</fixed-case>: a preliminary report</title>
      <author><first>William</first> <last>Croft</last></author>
      <author><first>Pavlina</first> <last>Pešková</last></author>
      <author><first>Michael</first> <last>Regan</last></author>
      <pages>8–17</pages>
      <url hash="a0fb327d">W16-1002</url>
      <doi>10.18653/v1/W16-1002</doi>
    </paper>
    <paper id="3">
      <title>Multimodal Use of an Upper-Level Event Ontology</title>
      <author><first>Claire</first> <last>Bonial</last></author>
      <author><first>David</first> <last>Tahmoush</last></author>
      <author><first>Susan</first> <last>Windisch Brown</last></author>
      <author><first>Martha</first> <last>Palmer</last></author>
      <pages>18–26</pages>
      <url hash="8941e154">W16-1003</url>
      <doi>10.18653/v1/W16-1003</doi>
    </paper>
    <paper id="4">
      <title>A Comparison of Event Representations in <fixed-case>DEFT</fixed-case></title>
      <author><first>Ann</first> <last>Bies</last></author>
      <author><first>Zhiyi</first> <last>Song</last></author>
      <author><first>Jeremy</first> <last>Getman</last></author>
      <author><first>Joe</first> <last>Ellis</last></author>
      <author><first>Justin</first> <last>Mott</last></author>
      <author><first>Stephanie</first> <last>Strassel</last></author>
      <author><first>Martha</first> <last>Palmer</last></author>
      <author><first>Teruko</first> <last>Mitamura</last></author>
      <author><first>Marjorie</first> <last>Freedman</last></author>
      <author><first>Heng</first> <last>Ji</last></author>
      <author><first>Tim</first> <last>O’Gorman</last></author>
      <pages>27–36</pages>
      <url hash="37ef2687">W16-1004</url>
      <doi>10.18653/v1/W16-1004</doi>
    </paper>
    <paper id="5">
      <title>Event Nugget and Event Coreference Annotation</title>
      <author><first>Zhiyi</first> <last>Song</last></author>
      <author><first>Ann</first> <last>Bies</last></author>
      <author><first>Stephanie</first> <last>Strassel</last></author>
      <author><first>Joe</first> <last>Ellis</last></author>
      <author><first>Teruko</first> <last>Mitamura</last></author>
      <author><first>Hoa Trang</first> <last>Dang</last></author>
      <author><first>Yukari</first> <last>Yamakawa</last></author>
      <author><first>Sue</first> <last>Holm</last></author>
      <pages>37–45</pages>
      <url hash="25c981e2">W16-1005</url>
      <doi>10.18653/v1/W16-1005</doi>
    </paper>
    <paper id="6">
      <title>Constructing a Dictionary Describing Feature Changes of Arguments in Event Sentences</title>
      <author><first>Tetsuaki</first> <last>Nakamura</last></author>
      <author><first>Daisuke</first> <last>Kawahara</last></author>
      <pages>46–50</pages>
      <url hash="a869f049">W16-1006</url>
      <doi>10.18653/v1/W16-1006</doi>
    </paper>
    <paper id="7">
      <title><fixed-case>C</fixed-case>a<fixed-case>T</fixed-case>e<fixed-case>RS</fixed-case>: Causal and Temporal Relation Scheme for Semantic Annotation of Event Structures</title>
      <author><first>Nasrin</first> <last>Mostafazadeh</last></author>
      <author><first>Alyson</first> <last>Grealish</last></author>
      <author><first>Nathanael</first> <last>Chambers</last></author>
      <author><first>James</first> <last>Allen</last></author>
      <author><first>Lucy</first> <last>Vanderwende</last></author>
      <pages>51–61</pages>
      <url hash="5e78df06">W16-1007</url>
      <doi>10.18653/v1/W16-1007</doi>
    </paper>
  </volume>
  <volume id="11">
    <meta>
      <booktitle>Proceedings of the Fourth Workshop on Metaphor in <fixed-case>NLP</fixed-case></booktitle>
      <editor><first>Beata</first><last>Beigman Klebanov</last></editor>
      <editor><first>Ekaterina</first><last>Shutova</last></editor>
      <editor><first>Patricia</first><last>Lichtenstein</last></editor>
      <doi>10.18653/v1/W16-11</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>San Diego, California</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="0111fe9d">W16-1100</url>
    </frontmatter>
    <paper id="1">
      <title>Finding metaphorical triggers through source (not target) domain lexicalization patterns</title>
      <author><first>Jenny</first> <last>Lederer</last></author>
      <pages>1–9</pages>
      <url hash="9c11eac5">W16-1101</url>
      <doi>10.18653/v1/W16-1101</doi>
    </paper>
    <paper id="2">
      <title>Detecting novel metaphor using selectional preference information</title>
      <author><first>Hessel</first> <last>Haagsma</last></author>
      <author><first>Johannes</first> <last>Bjerva</last></author>
      <pages>10–17</pages>
      <url hash="853cd0e8">W16-1102</url>
      <doi>10.18653/v1/W16-1102</doi>
    </paper>
    <paper id="3">
      <title>Supervised Metaphor Detection using Conditional Random Fields</title>
      <author><first>Sunny</first> <last>Rai</last></author>
      <author><first>Shampa</first> <last>Chakraverty</last></author>
      <author><first>Devendra K.</first> <last>Tayal</last></author>
      <pages>18–27</pages>
      <url hash="a81c1a28">W16-1103</url>
      <doi>10.18653/v1/W16-1103</doi>
    </paper>
    <paper id="4">
      <title>Token-Level Metaphor Detection using Neural Networks</title>
      <author><first>Erik-Lân</first> <last>Do Dinh</last></author>
      <author><first>Iryna</first> <last>Gurevych</last></author>
      <pages>28–33</pages>
      <url hash="e116a5c3">W16-1104</url>
      <doi>10.18653/v1/W16-1104</doi>
    </paper>
    <paper id="5">
      <title>Round Up The Usual Suspects: Knowledge-Based Metaphor Generation</title>
      <author><first>Tony</first> <last>Veale</last></author>
      <pages>34–41</pages>
      <url hash="fbff2e71">W16-1105</url>
      <doi>10.18653/v1/W16-1105</doi>
    </paper>
  </volume>
  <volume id="12">
    <meta>
      <booktitle>Proceedings of the Workshop on Multilingual and Cross-lingual Methods in <fixed-case>NLP</fixed-case></booktitle>
      <editor><first>Dipanjan</first><last>Das</last></editor>
      <editor><first>Chris</first><last>Dyer</last></editor>
      <editor><first>Manaal</first><last>Faruqui</last></editor>
      <editor><first>Yulia</first><last>Tsvetkov</last></editor>
      <doi>10.18653/v1/W16-12</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>San Diego, California</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="d037abb0">W16-1200</url>
    </frontmatter>
    <paper id="1">
      <title>Learning Cross-lingual Representations with Matrix Factorization</title>
      <author><first>Hanan</first> <last>Aldarmaki</last></author>
      <author><first>Mona</first> <last>Diab</last></author>
      <pages>1–9</pages>
      <url hash="ae2a0c24">W16-1201</url>
      <doi>10.18653/v1/W16-1201</doi>
    </paper>
    <paper id="2">
      <title>Should Have, Would Have, Could Have. Investigating Verb Group Representations for Parsing with <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies.</title>
      <author><first>Miryam</first> <last>de Lhoneux</last></author>
      <author><first>Joakim</first> <last>Nivre</last></author>
      <pages>10–19</pages>
      <url hash="35f8f4d1">W16-1202</url>
      <doi>10.18653/v1/W16-1202</doi>
      <attachment type="poster" hash="5271b5b8">W16-1202.Poster.pdf</attachment>
    </paper>
    <paper id="3">
      <title>Cross-lingual Dependency Transfer : What Matters? Assessing the Impact of Pre- and Post-processing</title>
      <author><first>Ophélie</first> <last>Lacroix</last></author>
      <author><first>Guillaume</first> <last>Wisniewski</last></author>
      <author><first>François</first> <last>Yvon</last></author>
      <pages>20–29</pages>
      <url hash="a21c646b">W16-1203</url>
      <doi>10.18653/v1/W16-1203</doi>
    </paper>
    <paper id="4">
      <title>Enhancing Automatic <fixed-case>W</fixed-case>ordnet Construction Using Word Embeddings</title>
      <author><first>Feras</first> <last>Al Tarouti</last></author>
      <author><first>Jugal</first> <last>Kalita</last></author>
      <pages>30–34</pages>
      <url hash="a4e20fd3">W16-1204</url>
      <doi>10.18653/v1/W16-1204</doi>
    </paper>
    <paper id="5">
      <title>Cross-lingual alignment transfer: a chicken-and-egg story?</title>
      <author><first>Lauriane</first> <last>Aufrant</last></author>
      <author><first>Guillaume</first> <last>Wisniewski</last></author>
      <author><first>François</first> <last>Yvon</last></author>
      <pages>35–44</pages>
      <url hash="7ce51586">W16-1205</url>
      <doi>10.18653/v1/W16-1205</doi>
    </paper>
    <paper id="6">
      <title>Leveraging Data-Driven Methods in Word-Level Language Identification for a Multilingual Alpine Heritage Corpus</title>
      <author><first>Ada</first> <last>Wan</last></author>
      <pages>45–54</pages>
      <url hash="74985240">W16-1206</url>
      <doi>10.18653/v1/W16-1206</doi>
    </paper>
    <paper id="7">
      <title>Learning Translations for Tagged Words: Extending the Translation Lexicon of an <fixed-case>ITG</fixed-case> for Low Resource Languages</title>
      <author><first>Markus</first> <last>Saers</last></author>
      <author><first>Dekai</first> <last>Wu</last></author>
      <pages>55–64</pages>
      <url hash="142e4c20">W16-1207</url>
      <doi>10.18653/v1/W16-1207</doi>
    </paper>
    <paper id="8">
      <title>Comparing Fifty Natural Languages and Twelve Genetic Languages Using Word Embedding Language Divergence (<fixed-case>WELD</fixed-case>) as a Quantitative Measure of Language Distance</title>
      <author><first>Ehsaneddin</first> <last>Asgari</last></author>
      <author><first>Mohammad R.K.</first> <last>Mofrad</last></author>
      <pages>65–74</pages>
      <url hash="277e0dee">W16-1208</url>
      <doi>10.18653/v1/W16-1208</doi>
    </paper>
  </volume>
  <volume id="13">
    <meta>
      <booktitle>Proceedings of the 5th Workshop on Automated Knowledge Base Construction</booktitle>
      <editor><first>Jay</first><last>Pujara</last></editor>
      <editor><first>Tim</first><last>Rocktaschel</last></editor>
      <editor><first>Danqi</first><last>Chen</last></editor>
      <editor><first>Sameer</first><last>Singh</last></editor>
      <doi>10.18653/v1/W16-13</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>San Diego, CA</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="a4d47249">W16-1300</url>
    </frontmatter>
    <paper id="1">
      <title>Using Graphs of Classifiers to Impose Constraints on Semi-supervised Relation Extraction</title>
      <author><first>Lidong</first> <last>Bing</last></author>
      <author><first>William</first> <last>Cohen</last></author>
      <author><first>Bhuwan</first> <last>Dhingra</last></author>
      <author><first>Richard</first> <last>Wang</last></author>
      <pages>1–6</pages>
      <url hash="d761f9de">W16-1301</url>
      <doi>10.18653/v1/W16-1301</doi>
    </paper>
    <paper id="2">
      <title>Discovering Entity Knowledge Bases on the Web</title>
      <author><first>Andrew</first> <last>Chisholm</last></author>
      <author><first>Will</first> <last>Radford</last></author>
      <author><first>Ben</first> <last>Hachey</last></author>
      <pages>7–11</pages>
      <url hash="8df7c9b0">W16-1302</url>
      <doi>10.18653/v1/W16-1302</doi>
    </paper>
    <paper id="3">
      <title><fixed-case>IKE</fixed-case> - An Interactive Tool for Knowledge Extraction</title>
      <author><first>Bhavana</first> <last>Dalvi</last></author>
      <author><first>Sumithra</first> <last>Bhakthavatsalam</last></author>
      <author><first>Chris</first> <last>Clark</last></author>
      <author><first>Peter</first> <last>Clark</last></author>
      <author><first>Oren</first> <last>Etzioni</last></author>
      <author><first>Anthony</first> <last>Fader</last></author>
      <author><first>Dirk</first> <last>Groeneveld</last></author>
      <pages>12–17</pages>
      <url hash="c464a06a">W16-1303</url>
      <doi>10.18653/v1/W16-1303</doi>
    </paper>
    <paper id="4">
      <title>Incorporating Selectional Preferences in Multi-hop Relation Extraction</title>
      <author><first>Rajarshi</first> <last>Das</last></author>
      <author><first>Arvind</first> <last>Neelakantan</last></author>
      <author><first>David</first> <last>Belanger</last></author>
      <author><first>Andrew</first> <last>McCallum</last></author>
      <pages>18–23</pages>
      <url hash="c3a106d3">W16-1304</url>
      <doi>10.18653/v1/W16-1304</doi>
    </paper>
    <paper id="5">
      <title>Knowledge Base Population for Organization Mentions in Email</title>
      <author><first>Ning</first> <last>Gao</last></author>
      <author><first>Mark</first> <last>Dredze</last></author>
      <author><first>Douglas</first> <last>Oard</last></author>
      <pages>24–28</pages>
      <url hash="c81335e5">W16-1305</url>
      <doi>10.18653/v1/W16-1305</doi>
    </paper>
    <paper id="6">
      <title>Enriching <fixed-case>W</fixed-case>ikidata with Frame Semantics</title>
      <author><first>Hatem</first> <last>Mousselly-Sergieh</last></author>
      <author><first>Iryna</first> <last>Gurevych</last></author>
      <pages>29–34</pages>
      <url hash="90cc7a0a">W16-1306</url>
      <doi>10.18653/v1/W16-1306</doi>
    </paper>
    <paper id="7">
      <title>Demonyms and Compound Relational Nouns in Nominal Open <fixed-case>IE</fixed-case></title>
      <author><first>Harinder</first> <last>Pal</last></author>
      <author><first/><last>Mausam</last></author>
      <pages>35–39</pages>
      <url hash="38fdf3d1">W16-1307</url>
      <doi>10.18653/v1/W16-1307</doi>
    </paper>
    <paper id="8">
      <title>But What Do We Actually Know?</title>
      <author><first>Simon</first> <last>Razniewski</last></author>
      <author><first>Fabian</first> <last>Suchanek</last></author>
      <author><first>Werner</first> <last>Nutt</last></author>
      <pages>40–44</pages>
      <url hash="4f1514e7">W16-1308</url>
      <doi>10.18653/v1/W16-1308</doi>
    </paper>
    <paper id="9">
      <title>Learning Knowledge Base Inference with Neural Theorem Provers</title>
      <author><first>Tim</first> <last>Rocktäschel</last></author>
      <author><first>Sebastian</first> <last>Riedel</last></author>
      <pages>45–50</pages>
      <url hash="bb4030de">W16-1309</url>
      <doi>10.18653/v1/W16-1309</doi>
    </paper>
    <paper id="10">
      <title>The Physics of Text: Ontological Realism in Information Extraction</title>
      <author><first>Stuart</first> <last>Russell</last></author>
      <author><first>Ole Torp</first> <last>Lassen</last></author>
      <author><first>Justin</first> <last>Uang</last></author>
      <author><first>Wei</first> <last>Wang</last></author>
      <pages>51–56</pages>
      <url hash="177f0523">W16-1310</url>
      <doi>10.18653/v1/W16-1310</doi>
    </paper>
    <paper id="11">
      <title><fixed-case>K</fixed-case>now2<fixed-case>L</fixed-case>ook: Commonsense Knowledge for Visual Search</title>
      <author><first>Sreyasi</first> <last>Nag Chowdhury</last></author>
      <author><first>Niket</first> <last>Tandon</last></author>
      <author><first>Gerhard</first> <last>Weikum</last></author>
      <pages>57–62</pages>
      <url hash="45d356aa">W16-1311</url>
      <doi>10.18653/v1/W16-1311</doi>
    </paper>
    <paper id="12">
      <title>Row-less Universal Schema</title>
      <author><first>Patrick</first> <last>Verga</last></author>
      <author><first>Andrew</first> <last>McCallum</last></author>
      <pages>63–68</pages>
      <url hash="ae42dd2a">W16-1312</url>
      <doi>10.18653/v1/W16-1312</doi>
    </paper>
    <paper id="13">
      <title>An Attentive Neural Architecture for Fine-grained Entity Type Classification</title>
      <author><first>Sonse</first> <last>Shimaoka</last></author>
      <author><first>Pontus</first> <last>Stenetorp</last></author>
      <author><first>Kentaro</first> <last>Inui</last></author>
      <author><first>Sebastian</first> <last>Riedel</last></author>
      <pages>69–74</pages>
      <url hash="11a979e6">W16-1313</url>
      <doi>10.18653/v1/W16-1313</doi>
    </paper>
    <paper id="14">
      <title>Regularizing Relation Representations by First-order Implications</title>
      <author><first>Thomas</first> <last>Demeester</last></author>
      <author><first>Tim</first> <last>Rocktäschel</last></author>
      <author><first>Sebastian</first> <last>Riedel</last></author>
      <pages>75–80</pages>
      <url hash="2a3c8946">W16-1314</url>
      <doi>10.18653/v1/W16-1314</doi>
    </paper>
    <paper id="15">
      <title>Applying Universal Schemas for Domain Specific Ontology Expansion</title>
      <author><first>Paul</first> <last>Groth</last></author>
      <author><first>Sujit</first> <last>Pal</last></author>
      <author><first>Darin</first> <last>McBeath</last></author>
      <author><first>Brad</first> <last>Allen</last></author>
      <author><first>Ron</first> <last>Daniel</last></author>
      <pages>81–85</pages>
      <url hash="f702fcf0">W16-1315</url>
      <doi>10.18653/v1/W16-1315</doi>
    </paper>
    <paper id="16">
      <title>Design of Word Association Games using Dialog Systems for Acquisition of Word Association Knowledge</title>
      <author><first>Yuichiro</first> <last>Machida</last></author>
      <author><first>Daisuke</first> <last>Kawahara</last></author>
      <author><first>Sadao</first> <last>Kurohashi</last></author>
      <author><first>Manabu</first> <last>Sassano</last></author>
      <pages>86–91</pages>
      <url hash="57d5e572">W16-1316</url>
      <doi>10.18653/v1/W16-1316</doi>
    </paper>
    <paper id="17">
      <title>Call for Discussion: Building a New Standard Dataset for Relation Extraction Tasks</title>
      <author><first>Teresa</first> <last>Martin</last></author>
      <author><first>Fiete</first> <last>Botschen</last></author>
      <author><first>Ajay</first> <last>Nagesh</last></author>
      <author><first>Andrew</first> <last>McCallum</last></author>
      <pages>92–96</pages>
      <url hash="3118895b">W16-1317</url>
      <doi>10.18653/v1/W16-1317</doi>
    </paper>
    <paper id="18">
      <title>A Comparison of Weak Supervision methods for Knowledge Base Construction</title>
      <author><first>Ameet</first> <last>Soni</last></author>
      <author><first>Dileep</first> <last>Viswanathan</last></author>
      <author><first>Niranjan</first> <last>Pachaiyappan</last></author>
      <author><first>Sriraam</first> <last>Natarajan</last></author>
      <pages>97–102</pages>
      <url hash="035bf412">W16-1318</url>
      <doi>10.18653/v1/W16-1318</doi>
    </paper>
    <paper id="19">
      <title>A Factorization Machine Framework for Testing Bigram Embeddings in Knowledgebase Completion</title>
      <author><first>Johannes</first> <last>Welbl</last></author>
      <author><first>Guillaume</first> <last>Bouchard</last></author>
      <author><first>Sebastian</first> <last>Riedel</last></author>
      <pages>103–107</pages>
      <url hash="df88ab35">W16-1319</url>
      <doi>10.18653/v1/W16-1319</doi>
    </paper>
  </volume>
  <volume id="14">
    <meta>
      <booktitle>Proceedings of <fixed-case>T</fixed-case>ext<fixed-case>G</fixed-case>raphs-10: the Workshop on Graph-based Methods for Natural Language Processing</booktitle>
      <editor><first>Tanmoy</first><last>Chakraborty</last></editor>
      <editor><first>Martin</first><last>Riedl</last></editor>
      <editor><first>V.G.Vinod</first><last>Vydiswaran</last></editor>
      <doi>10.18653/v1/W16-14</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>San Diego, CA, USA</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="67d5ed32">W16-1400</url>
    </frontmatter>
    <paper id="1">
      <title>Embedding Senses for Efficient Graph-based Word Sense Disambiguation</title>
      <author><first>Luis</first> <last>Nieto Piña</last></author>
      <author><first>Richard</first> <last>Johansson</last></author>
      <pages>1–5</pages>
      <url hash="fd2c5584">W16-1401</url>
      <doi>10.18653/v1/W16-1401</doi>
    </paper>
    <paper id="2">
      <title>Context Tailoring for Text Normalization</title>
      <author><first>Seniz</first> <last>Demir</last></author>
      <pages>6–14</pages>
      <url hash="73b299ac">W16-1402</url>
      <doi>10.18653/v1/W16-1402</doi>
    </paper>
    <paper id="3">
      <title>Cross-Lingual Question Answering Using Common Semantic Space</title>
      <author><first>Amir</first> <last>Pouran Ben Veyseh</last></author>
      <pages>15–19</pages>
      <url hash="4fc172c6">W16-1403</url>
      <doi>10.18653/v1/W16-1403</doi>
    </paper>
    <paper id="4">
      <title>Network Motifs May Improve Quality Assessment of Text Documents</title>
      <author><first>Thomas</first> <last>Arnold</last></author>
      <author><first>Karsten</first> <last>Weihe</last></author>
      <pages>20–28</pages>
      <url hash="b23cd9df">W16-1404</url>
      <doi>10.18653/v1/W16-1404</doi>
    </paper>
    <paper id="5">
      <title>Better Together: Combining Language and Social Interactions into a Shared Representation</title>
      <author><first>Yi-Yu</first> <last>Lai</last></author>
      <author><first>Chang</first> <last>Li</last></author>
      <author><first>Dan</first> <last>Goldwasser</last></author>
      <author><first>Jennifer</first> <last>Neville</last></author>
      <pages>29–33</pages>
      <url hash="a167b9f7">W16-1405</url>
      <doi>10.18653/v1/W16-1405</doi>
    </paper>
    <paper id="6">
      <title>Visualization of Dynamic Reference Graphs</title>
      <author><first>Ivan</first> <last>Rodin</last></author>
      <author><first>Ekaterina</first> <last>Chernyak</last></author>
      <author><first>Mikhail</first> <last>Dubov</last></author>
      <author><first>Boris</first> <last>Mirkin</last></author>
      <pages>34–38</pages>
      <url hash="5e415868">W16-1406</url>
      <doi>10.18653/v1/W16-1406</doi>
    </paper>
  </volume>
  <volume id="15">
    <meta>
      <booktitle>Proceedings of the Joint Workshop on Bibliometric-enhanced Information Retrieval and Natural Language Processing for Digital Libraries (<fixed-case>BIRNDL</fixed-case>)</booktitle>
      <editor><first>Guillaume</first> <last>Cabanac</last></editor>
      <editor><first>Muthu Kumar</first> <last>Chandrasekaran</last></editor>
      <editor><first>Ingo</first> <last>Frommholz</last></editor>
      <editor><first>Kokil</first> <last>Jaidka</last></editor>
      <editor><first>Min-Yen</first> <last>Kan</last></editor>
      <editor><first>Philipp</first> <last>Mayr</last></editor>
      <editor><first>Dietmar</first> <last>Wolfram</last></editor>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <pages>1–5</pages>
      <url hash="54283ae6">W16-1500</url>
      <attachment type="presentation" hash="029570d5">W16-1500.Presentation.pdf</attachment>
    </frontmatter>
    <paper id="1">
      <title>Bibliometrics, Information Retrieval and Natural Language Processing: Natural Synergies to Support Digital Library Research</title>
      <author><first>Dietmar</first> <last>Wolfram</last></author>
      <pages>6–13</pages>
      <url hash="1c40fb6a">W16-1501</url>
      <attachment type="presentation" hash="2dac9495">W16-1501.Presentation.pdf</attachment>
    </paper>
    <paper id="2">
      <title>Multiple In-text Reference Aggregation Phenomenon</title>
      <author><first>Marc</first> <last>Bertin</last></author>
      <author><first>Iana</first> <last>Atanassova</last></author>
      <pages>14–22</pages>
      <url hash="f23fb08c">W16-1502</url>
    </paper>
    <paper id="3">
      <title>Post Retraction Citations in Context</title>
      <author><first>Gali</first> <last>Halevi</last></author>
      <author><first>Judit</first> <last>Bar-Ilan</last></author>
      <pages>23–29</pages>
      <url hash="11c7414d">W16-1503</url>
      <attachment type="presentation" hash="a0b810a7">W16-1503.Presentation.pdf</attachment>
    </paper>
    <paper id="4">
      <title>Incorporating Satellite Documents into Co-citation Networks for Scientific Paper Searches</title>
      <author><first>Masaki</first> <last>Eto</last></author>
      <pages>30–35</pages>
      <url hash="05be3774">W16-1504</url>
      <attachment type="presentation" hash="865f4aeb">W16-1504.Presentation.pdf</attachment>
    </paper>
    <paper id="5">
      <title>Making Sense of Massive Amounts of Scientific Publications: the Scientific Knowledge Miner Project</title>
      <author><first>Francesco</first> <last>Ronzano</last></author>
      <author><first>Ana</first> <last>Freire</last></author>
      <author><first>Diego</first> <last>Saez-Trumper</last></author>
      <author><first>Horacio</first> <last>Saggion</last></author>
      <pages>36–41</pages>
      <url hash="3fcf4629">W16-1505</url>
      <attachment type="presentation" hash="9bcf8fc2">W16-1505.Presentation.pdf</attachment>
    </paper>
    <paper id="6">
      <title>Exploring the Leading Authors and Journals in Major Topics by Citation Sentences and Topic Modeling</title>
      <author><first>Ha Jin</first> <last>Kim</last></author>
      <author><first>Juyoung</first> <last>An</last></author>
      <author><first>Yoo Kyung</first> <last>Jeong</last></author>
      <author><first>Min</first> <last>Song</last></author>
      <pages>42–50</pages>
      <url hash="383302df">W16-1506</url>
      <attachment type="presentation" hash="8822f0aa">W16-1506.Presentation.pdf</attachment>
    </paper>
    <paper id="7">
      <title>What Papers Should <fixed-case>I</fixed-case> Cite from my Reading List? User Evaluation of a Manuscript Preparatory Assistive Task</title>
      <author><first>Aravind Sesagiri</first> <last>Raamkumar</last></author>
      <author><first>Schubert</first> <last>Foo</last></author>
      <author><first>Natalie</first> <last>Pang</last></author>
      <pages>51–62</pages>
      <url hash="938fc245">W16-1507</url>
      <attachment type="presentation" hash="baa6ae73">W16-1507.Presentation.pdf</attachment>
    </paper>
    <paper id="8">
      <title>Delineating Fields Using Mathematical Jargon</title>
      <author><first>Jevin</first> <last>West</last></author>
      <author><first>Jason</first> <last>Portenoy</last></author>
      <pages>63–71</pages>
      <url hash="fd677417">W16-1508</url>
    </paper>
    <paper id="9">
      <title>A Study of Reuse and Plagiarism in Speech and Natural Language Processing papers</title>
      <author><first>Joseph</first> <last>Mariani</last></author>
      <author><first>Gil</first> <last>Francopoulo</last></author>
      <author><first>Patrick</first> <last>Paroubek</last></author>
      <pages>72–83</pages>
      <url hash="d84fe0ae">W16-1509</url>
      <attachment type="presentation" hash="10373ec0">W16-1509.Presentation.pdf</attachment>
    </paper>
    <paper id="10">
      <title>How do Practitioners, <fixed-case>P</fixed-case>h<fixed-case>D</fixed-case> Students and Postdocs in the Social Sciences Assess Topic-specific Recommendations?</title>
      <author><first>Philipp</first> <last>Mayr</last></author>
      <pages>84–92</pages>
      <url hash="022b12b5">W16-1510</url>
      <attachment type="presentation" hash="9c2149c2">W16-1510.Presentation.pdf</attachment>
    </paper>
    <paper id="11">
      <title>Overview of the <fixed-case>CL</fixed-case>-<fixed-case>S</fixed-case>ci<fixed-case>S</fixed-case>umm 2016 Shared Task</title>
      <author><first>Kokil</first> <last>Jaidka</last></author>
      <author><first>Muthu</first> <last>Kumar Chandrasekaran</last></author>
      <author><first>Sajal</first> <last>Rustagi</last></author>
      <author><first>Min-Yen</first> <last>Kan</last></author>
      <pages>93–102</pages>
      <url hash="dc5af250">W16-1511</url>
      <attachment type="presentation" hash="3d1d227b">W16-1511.Presentation.pdf</attachment>
    </paper>
    <paper id="12">
      <title>Lexical and Syntactic cues to identify Reference Scope of Citance</title>
      <author><first>Peeyush</first> <last>Aggarwal</last></author>
      <author><first>Richa</first> <last>Sharma</last></author>
      <pages>103–112</pages>
      <url hash="e3c58079">W16-1512</url>
      <attachment type="poster" hash="7e08ca1b">W16-1512.Poster.png</attachment>
    </paper>
    <paper id="13">
      <title><fixed-case>U</fixed-case>niversity of <fixed-case>H</fixed-case>ouston at <fixed-case>CL</fixed-case>-<fixed-case>S</fixed-case>ci<fixed-case>S</fixed-case>umm 2016: <fixed-case>SVM</fixed-case>s with tree kernels and Sentence Similarity</title>
      <author><first>Luis</first> <last>Moraes</last></author>
      <author><first>Shahryar</first> <last>Baki</last></author>
      <author><first>Rakesh</first> <last>Verma</last></author>
      <author><first>Daniel</first> <last>Lee</last></author>
      <pages>113–121</pages>
      <url hash="03d511e5">W16-1513</url>
    </paper>
    <paper id="14">
      <title>Identifying Referenced Text in Scientific Publications by Summarisation and Classification Techniques</title>
      <author><first>Stefan</first> <last>Klampfl</last></author>
      <author><first>Andi</first> <last>Rexha</last></author>
      <author><first>Roman</first> <last>Kern</last></author>
      <pages>122–131</pages>
      <url hash="f2682df5">W16-1514</url>
      <attachment type="poster" hash="97d1189a">W16-1514.Poster.png</attachment>
    </paper>
    <paper id="15">
      <title><fixed-case>P</fixed-case>oly<fixed-case>U</fixed-case> at <fixed-case>CL</fixed-case>-<fixed-case>S</fixed-case>ci<fixed-case>S</fixed-case>umm 2016</title>
      <author><first>Ziqiang</first> <last>Cao</last></author>
      <author><first>Wenjie</first> <last>Li</last></author>
      <author><first>Dapeng</first> <last>Wu</last></author>
      <pages>132–138</pages>
      <url hash="3c1dd1d2">W16-1515</url>
    </paper>
    <paper id="16">
      <title>Recognizing Reference Spans and Classifying their Discourse Facets</title>
      <author><first>Kun</first> <last>Lu</last></author>
      <author><first>Jin</first> <last>Mao</last></author>
      <author><first>Gang</first> <last>Li</last></author>
      <author><first>Jian</first> <last>Xu</last></author>
      <pages>139–145</pages>
      <url hash="e5bbf3cd">W16-1516</url>
      <attachment type="poster" hash="4db5337c">W16-1516.Poster.png</attachment>
    </paper>
    <paper id="17">
      <title><fixed-case>RALI</fixed-case> System Description for <fixed-case>CL</fixed-case>-<fixed-case>S</fixed-case>ci<fixed-case>S</fixed-case>umm 2016 Shared Task</title>
      <author><first>Bruno</first> <last>Malenfant</last></author>
      <author><first>Guy</first> <last>Lapalme</last></author>
      <pages>146–155</pages>
      <url hash="584a8a5e">W16-1517</url>
    </paper>
    <paper id="18">
      <title><fixed-case>CIST</fixed-case> System for <fixed-case>CL</fixed-case>-<fixed-case>S</fixed-case>ci<fixed-case>S</fixed-case>umm 2016 Shared Task</title>
      <author><first>Lei</first> <last>Li</last></author>
      <author><first>Liyuan</first> <last>Mao</last></author>
      <author><first>Yazhao</first> <last>Zhang</last></author>
      <author><first>Junqi</first> <last>Chi</last></author>
      <author><first>Taiwen</first> <last>Huang</last></author>
      <author><first>Xiaoyue</first> <last>Cong</last></author>
      <author><first>Heng</first> <last>Peng</last></author>
      <pages>156–167</pages>
      <url hash="b9c82f9c">W16-1518</url>
    </paper>
    <paper id="19">
      <title><fixed-case>NEAL</fixed-case>: A Neurally Enhanced Approach to Linking Citation and Reference</title>
      <author><first>Tadashi</first> <last>Nomoto</last></author>
      <pages>168–174</pages>
      <url hash="b50e4c60">W16-1519</url>
      <attachment type="poster" hash="6a33eaeb">W16-1519.Poster.png</attachment>
    </paper>
    <paper id="20">
      <title>Trainable Citation-enhanced Summarization of Scientific Articles</title>
      <author><first>Horacio</first> <last>Saggion</last></author>
      <author><first>Ahmed</first> <last>AbuRa’ed</last></author>
      <author><first>Francesco</first> <last>Ronzano</last></author>
      <pages>175–186</pages>
      <url hash="51f6e65c">W16-1520</url>
    </paper>
  </volume>
  <volume id="16">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on Representation Learning for <fixed-case>NLP</fixed-case></booktitle>
      <url hash="f1eff05e">W16-16</url>
      <editor><first>Phil</first><last>Blunsom</last></editor>
      <editor><first>Kyunghyun</first><last>Cho</last></editor>
      <editor><first>Shay</first><last>Cohen</last></editor>
      <editor><first>Edward</first><last>Grefenstette</last></editor>
      <editor><first>Karl Moritz</first><last>Hermann</last></editor>
      <editor><first>Laura</first><last>Rimell</last></editor>
      <editor><first>Jason</first><last>Weston</last></editor>
      <editor><first>Scott Wen-tau</first><last>Yih</last></editor>
      <doi>10.18653/v1/W16-16</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="ea8ba2ef">W16-1600</url>
    </frontmatter>
    <paper id="1">
      <title>Explaining Predictions of Non-Linear Classifiers in <fixed-case>NLP</fixed-case></title>
      <author><first>Leila</first> <last>Arras</last></author>
      <author><first>Franziska</first> <last>Horn</last></author>
      <author><first>Grégoire</first> <last>Montavon</last></author>
      <author><first>Klaus-Robert</first> <last>Müller</last></author>
      <author><first>Wojciech</first> <last>Samek</last></author>
      <pages>1–7</pages>
      <url hash="11947d5f">W16-1601</url>
      <doi>10.18653/v1/W16-1601</doi>
    </paper>
    <paper id="2">
      <title>Joint Learning of Sentence Embeddings for Relevance and Entailment</title>
      <author><first>Petr</first> <last>Baudiš</last></author>
      <author><first>Silvestr</first> <last>Stanko</last></author>
      <author><first>Jan</first> <last>Šedivý</last></author>
      <pages>8–17</pages>
      <url hash="7ccfa19c">W16-1602</url>
      <doi>10.18653/v1/W16-1602</doi>
    </paper>
    <paper id="3">
      <title>A Joint Model for Word Embedding and Word Morphology</title>
      <author><first>Kris</first> <last>Cao</last></author>
      <author><first>Marek</first> <last>Rei</last></author>
      <pages>18–26</pages>
      <url hash="b0d6cd55">W16-1603</url>
      <doi>10.18653/v1/W16-1603</doi>
    </paper>
    <paper id="4">
      <title>On the Compositionality and Semantic Interpretation of <fixed-case>E</fixed-case>nglish Noun Compounds</title>
      <author><first>Corina</first> <last>Dima</last></author>
      <pages>27–39</pages>
      <url hash="430b27c6">W16-1604</url>
      <doi>10.18653/v1/W16-1604</doi>
    </paper>
    <paper id="5">
      <title>Functional Distributional Semantics</title>
      <author><first>Guy</first> <last>Emerson</last></author>
      <author><first>Ann</first> <last>Copestake</last></author>
      <pages>40–52</pages>
      <url hash="94c68efe">W16-1605</url>
      <attachment type="poster" hash="96b919bd">W16-1605.Poster.pdf</attachment>
      <doi>10.18653/v1/W16-1605</doi>
    </paper>
    <paper id="6">
      <title>Assisting Discussion Forum Users using Deep Recurrent Neural Networks</title>
      <author><first>Jacob</first> <last>Hagstedt P Suorra</last></author>
      <author><first>Olof</first> <last>Mogren</last></author>
      <pages>53–61</pages>
      <url hash="fcf7430f">W16-1606</url>
      <doi>10.18653/v1/W16-1606</doi>
    </paper>
    <paper id="7">
      <title>Adjusting Word Embeddings with Semantic Intensity Orders</title>
      <author><first>Joo-Kyung</first> <last>Kim</last></author>
      <author><first>Marie-Catherine</first> <last>de Marneffe</last></author>
      <author><first>Eric</first> <last>Fosler-Lussier</last></author>
      <pages>62–69</pages>
      <url hash="6e22fe3f">W16-1607</url>
      <doi>10.18653/v1/W16-1607</doi>
    </paper>
    <paper id="8">
      <title>Towards Abstraction from Extraction: Multiple Timescale Gated Recurrent Unit for Summarization</title>
      <author><first>Minsoo</first> <last>Kim</last></author>
      <author><first>Dennis Singh</first> <last>Moirangthem</last></author>
      <author><first>Minho</first> <last>Lee</last></author>
      <pages>70–77</pages>
      <url hash="96ddb459">W16-1608</url>
      <doi>10.18653/v1/W16-1608</doi>
    </paper>
    <paper id="9">
      <title>An Empirical Evaluation of doc2vec with Practical Insights into Document Embedding Generation</title>
      <author><first>Jey Han</first> <last>Lau</last></author>
      <author><first>Timothy</first> <last>Baldwin</last></author>
      <pages>78–86</pages>
      <url hash="14461e55">W16-1609</url>
      <doi>10.18653/v1/W16-1609</doi>
    </paper>
    <paper id="10">
      <title>Quantifying the Vanishing Gradient and Long Distance Dependency Problem in Recursive Neural Networks and Recursive <fixed-case>LSTM</fixed-case>s</title>
      <author><first>Phong</first> <last>Le</last></author>
      <author><first>Willem</first> <last>Zuidema</last></author>
      <pages>87–93</pages>
      <url hash="2b9938c4">W16-1610</url>
      <doi>10.18653/v1/W16-1610</doi>
    </paper>
    <paper id="11">
      <title><fixed-case>LSTM</fixed-case>-Based Mixture-of-Experts for Knowledge-Aware Dialogues</title>
      <author><first>Phong</first> <last>Le</last></author>
      <author><first>Marc</first> <last>Dymetman</last></author>
      <author><first>Jean-Michel</first> <last>Renders</last></author>
      <pages>94–99</pages>
      <url hash="972a02ff">W16-1611</url>
      <doi>10.18653/v1/W16-1611</doi>
    </paper>
    <paper id="12">
      <title>Mapping Unseen Words to Task-Trained Embedding Spaces</title>
      <author><first>Pranava Swaroop</first> <last>Madhyastha</last></author>
      <author><first>Mohit</first> <last>Bansal</last></author>
      <author><first>Kevin</first> <last>Gimpel</last></author>
      <author><first>Karen</first> <last>Livescu</last></author>
      <pages>100–110</pages>
      <url hash="6eb1d13c">W16-1612</url>
      <doi>10.18653/v1/W16-1612</doi>
    </paper>
    <paper id="13">
      <title>Multilingual Modal Sense Classification using a Convolutional Neural Network</title>
      <author><first>Ana</first> <last>Marasović</last></author>
      <author><first>Anette</first> <last>Frank</last></author>
      <pages>111–120</pages>
      <url hash="41e8a06e">W16-1613</url>
      <doi>10.18653/v1/W16-1613</doi>
    </paper>
    <paper id="14">
      <title>Towards cross-lingual distributed representations without parallel text trained with adversarial autoencoders</title>
      <author><first>Antonio Valerio</first> <last>Miceli Barone</last></author>
      <pages>121–126</pages>
      <url hash="0f6204b8">W16-1614</url>
      <doi>10.18653/v1/W16-1614</doi>
    </paper>
    <paper id="15">
      <title>Decomposing Bilexical Dependencies into Semantic and Syntactic Vectors</title>
      <author><first>Jeff</first> <last>Mitchell</last></author>
      <pages>127–136</pages>
      <url hash="f6d1b1d2">W16-1615</url>
      <doi>10.18653/v1/W16-1615</doi>
    </paper>
    <paper id="16">
      <title>Learning Semantic Relatedness in Community Question Answering Using Neural Models</title>
      <author><first>Henry</first> <last>Nassif</last></author>
      <author><first>Mitra</first> <last>Mohtarami</last></author>
      <author><first>James</first> <last>Glass</last></author>
      <pages>137–147</pages>
      <url hash="ac4d34d3">W16-1616</url>
      <doi>10.18653/v1/W16-1616</doi>
    </paper>
    <paper id="17">
      <title>Learning Text Similarity with <fixed-case>S</fixed-case>iamese Recurrent Networks</title>
      <author><first>Paul</first> <last>Neculoiu</last></author>
      <author><first>Maarten</first> <last>Versteegh</last></author>
      <author><first>Mihai</first> <last>Rotaru</last></author>
      <pages>148–157</pages>
      <url hash="224072f3">W16-1617</url>
      <doi>10.18653/v1/W16-1617</doi>
    </paper>
    <paper id="18">
      <title>A Two-stage Approach for Extending Event Detection to New Types via Neural Networks</title>
      <author><first>Thien Huu</first> <last>Nguyen</last></author>
      <author><first>Lisheng</first> <last>Fu</last></author>
      <author><first>Kyunghyun</first> <last>Cho</last></author>
      <author><first>Ralph</first> <last>Grishman</last></author>
      <pages>158–165</pages>
      <url hash="fa1f7704">W16-1618</url>
      <doi>10.18653/v1/W16-1618</doi>
    </paper>
    <paper id="19">
      <title>Parameterized context windows in Random Indexing</title>
      <author><first>Tobias</first> <last>Norlund</last></author>
      <author><first>David</first> <last>Nilsson</last></author>
      <author><first>Magnus</first> <last>Sahlgren</last></author>
      <pages>166–173</pages>
      <url hash="79d6f7f1">W16-1619</url>
      <doi>10.18653/v1/W16-1619</doi>
    </paper>
    <paper id="20">
      <title>Making Sense of Word Embeddings</title>
      <author><first>Maria</first> <last>Pelevina</last></author>
      <author><first>Nikolay</first> <last>Arefiev</last></author>
      <author><first>Chris</first> <last>Biemann</last></author>
      <author><first>Alexander</first> <last>Panchenko</last></author>
      <pages>174–183</pages>
      <url hash="ecb9da00">W16-1620</url>
      <doi>10.18653/v1/W16-1620</doi>
    </paper>
    <paper id="21">
      <title>Pair Distance Distribution: A Model of Semantic Representation</title>
      <author><first>Yonatan</first> <last>Ramni</last></author>
      <author><first>Oded</first> <last>Maimon</last></author>
      <author><first>Evgeni</first> <last>Khmelnitsky</last></author>
      <pages>184–192</pages>
      <url hash="13d7b1d9">W16-1621</url>
      <doi>10.18653/v1/W16-1621</doi>
    </paper>
    <paper id="22">
      <title>Measuring Semantic Similarity of Words Using Concept Networks</title>
      <author><first>Gábor</first> <last>Recski</last></author>
      <author><first>Eszter</first> <last>Iklódi</last></author>
      <author><first>Katalin</first> <last>Pajkossy</last></author>
      <author><first>András</first> <last>Kornai</last></author>
      <pages>193–200</pages>
      <url hash="3005cc1c">W16-1622</url>
      <doi>10.18653/v1/W16-1622</doi>
    </paper>
    <paper id="23">
      <title>Using Embedding Masks for Word Categorization</title>
      <author><first>Stefan</first> <last>Ruseti</last></author>
      <author><first>Traian</first> <last>Rebedea</last></author>
      <author><first>Stefan</first> <last>Trausan-Matu</last></author>
      <pages>201–205</pages>
      <url hash="d8190caa">W16-1623</url>
      <doi>10.18653/v1/W16-1623</doi>
    </paper>
    <paper id="24">
      <title>Sparsifying Word Representations for Deep Unordered Sentence Modeling</title>
      <author><first>Prasanna</first> <last>Sattigeri</last></author>
      <author><first>Jayaraman</first> <last>J. Thiagarajan</last></author>
      <pages>206–214</pages>
      <url hash="4e565bf7">W16-1624</url>
      <doi>10.18653/v1/W16-1624</doi>
    </paper>
    <paper id="25">
      <title>Why “Blow Out”? A Structural Analysis of the Movie Dialog Dataset</title>
      <author><first>Richard</first> <last>Searle</last></author>
      <author><first>Megan</first> <last>Bingham-Walker</last></author>
      <pages>215–221</pages>
      <url hash="6e48e38b">W16-1625</url>
      <doi>10.18653/v1/W16-1625</doi>
    </paper>
    <paper id="26">
      <title>Learning Word Importance with the Neural Bag-of-Words Model</title>
      <author><first>Imran</first> <last>Sheikh</last></author>
      <author><first>Irina</first> <last>Illina</last></author>
      <author><first>Dominique</first> <last>Fohr</last></author>
      <author><first>Georges</first> <last>Linarès</last></author>
      <pages>222–229</pages>
      <url hash="312d2390">W16-1626</url>
      <doi>10.18653/v1/W16-1626</doi>
    </paper>
    <paper id="27">
      <title>A Vector Model for Type-Theoretical Semantics</title>
      <author><first>Konstantin</first> <last>Sokolov</last></author>
      <pages>230–238</pages>
      <url hash="a4279ee0">W16-1627</url>
      <doi>10.18653/v1/W16-1627</doi>
    </paper>
    <paper id="28">
      <title>Towards Generalizable Sentence Embeddings</title>
      <author><first>Eleni</first> <last>Triantafillou</last></author>
      <author><first>Jamie Ryan</first> <last>Kiros</last></author>
      <author><first>Raquel</first> <last>Urtasun</last></author>
      <author><first>Richard</first> <last>Zemel</last></author>
      <pages>239–248</pages>
      <url hash="7ff959eb">W16-1628</url>
      <doi>10.18653/v1/W16-1628</doi>
    </paper>
    <paper id="29">
      <title>Domain Adaptation for Neural Networks by Parameter Augmentation</title>
      <author><first>Yusuke</first> <last>Watanabe</last></author>
      <author><first>Kazuma</first> <last>Hashimoto</last></author>
      <author><first>Yoshimasa</first> <last>Tsuruoka</last></author>
      <pages>249–257</pages>
      <url hash="1298e71f">W16-1629</url>
      <doi>10.18653/v1/W16-1629</doi>
    </paper>
    <paper id="30">
      <title>Neural Associative Memory for Dual-Sequence Modeling</title>
      <author><first>Dirk</first> <last>Weissenborn</last></author>
      <pages>258–266</pages>
      <url hash="26e47b14">W16-1630</url>
      <doi>10.18653/v1/W16-1630</doi>
    </paper>
  </volume>
  <volume id="17">
    <meta>
      <booktitle>Proceedings of the 10th Linguistic Annotation Workshop held in conjunction with <fixed-case>ACL</fixed-case> 2016 (<fixed-case>LAW</fixed-case>-X 2016)</booktitle>
      <url hash="f481d324">W16-17</url>
      <editor><first>Annemarie</first><last>Friedrich</last></editor>
      <editor><first>Katrin</first><last>Tomanek</last></editor>
      <doi>10.18653/v1/W16-17</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="dedbc595">W16-1700</url>
    </frontmatter>
    <paper id="1">
      <title>Building a Cross-document Event-Event Relation Corpus</title>
      <author><first>Yu</first> <last>Hong</last></author>
      <author><first>Tongtao</first> <last>Zhang</last></author>
      <author><first>Tim</first> <last>O’Gorman</last></author>
      <author><first>Sharone</first> <last>Horowit-Hendler</last></author>
      <author><first>Heng</first> <last>Ji</last></author>
      <author><first>Martha</first> <last>Palmer</last></author>
      <pages>1–6</pages>
      <url hash="94b92129">W16-1701</url>
      <doi>10.18653/v1/W16-1701</doi>
    </paper>
    <paper id="2">
      <title>Annotating the Little Prince with <fixed-case>C</fixed-case>hinese <fixed-case>AMR</fixed-case>s</title>
      <author><first>Bin</first> <last>Li</last></author>
      <author><first>Yuan</first> <last>Wen</last></author>
      <author><first>Weiguang</first> <last>Qu</last></author>
      <author><first>Lijun</first> <last>Bu</last></author>
      <author><first>Nianwen</first> <last>Xue</last></author>
      <pages>7–15</pages>
      <url hash="8b1c7416">W16-1702</url>
      <doi>10.18653/v1/W16-1702</doi>
    </paper>
    <paper id="3">
      <title>Converting <fixed-case>S</fixed-case>yn<fixed-case>T</fixed-case>ag<fixed-case>R</fixed-case>us Dependency Treebank into <fixed-case>P</fixed-case>enn <fixed-case>T</fixed-case>reebank Style</title>
      <author><first>Alex</first> <last>Luu</last></author>
      <author><first>Sophia A.</first> <last>Malamud</last></author>
      <author><first>Nianwen</first> <last>Xue</last></author>
      <pages>16–21</pages>
      <url hash="db0a1e91">W16-1703</url>
      <doi>10.18653/v1/W16-1703</doi>
    </paper>
    <paper id="4">
      <title>A Discourse-Annotated Corpus of Conjoined <fixed-case>VP</fixed-case>s</title>
      <author><first>Bonnie</first> <last>Webber</last></author>
      <author><first>Rashmi</first> <last>Prasad</last></author>
      <author><first>Alan</first> <last>Lee</last></author>
      <author><first>Aravind</first> <last>Joshi</last></author>
      <pages>22–31</pages>
      <url hash="7e020982">W16-1704</url>
      <doi>10.18653/v1/W16-1704</doi>
    </paper>
    <paper id="5">
      <title>Annotating Spelling Errors in <fixed-case>G</fixed-case>erman Texts Produced by Primary School Children</title>
      <author><first>Ronja</first> <last>Laarmann-Quante</last></author>
      <author><first>Lukas</first> <last>Knichel</last></author>
      <author><first>Stefanie</first> <last>Dipper</last></author>
      <author><first>Carina</first> <last>Betken</last></author>
      <pages>32–42</pages>
      <url hash="cc9efa3d">W16-1705</url>
      <doi>10.18653/v1/W16-1705</doi>
    </paper>
    <paper id="6">
      <title>Supersense tagging with inter-annotator disagreement</title>
      <author><first>Héctor</first> <last>Martínez Alonso</last></author>
      <author><first>Anders</first> <last>Johannsen</last></author>
      <author><first>Barbara</first> <last>Plank</last></author>
      <pages>43–48</pages>
      <url hash="67700dd3">W16-1706</url>
      <doi>10.18653/v1/W16-1706</doi>
    </paper>
    <paper id="7">
      <title>Filling in the Blanks in Understanding Discourse Adverbials: Consistency, Conflict, and Context-Dependence in a Crowdsourced Elicitation Task</title>
      <author><first>Hannah</first> <last>Rohde</last></author>
      <author><first>Anna</first> <last>Dickinson</last></author>
      <author><first>Nathan</first> <last>Schneider</last></author>
      <author><first>Christopher N. L.</first> <last>Clark</last></author>
      <author><first>Annie</first> <last>Louis</last></author>
      <author><first>Bonnie</first> <last>Webber</last></author>
      <pages>49–58</pages>
      <url hash="18317d7b">W16-1707</url>
      <doi>10.18653/v1/W16-1707</doi>
    </paper>
    <paper id="8">
      <title>Comparison of Annotating Methods for Named Entity Corpora</title>
      <author><first>Kanako</first> <last>Komiya</last></author>
      <author><first>Masaya</first> <last>Suzuki</last></author>
      <author><first>Tomoya</first> <last>Iwakura</last></author>
      <author><first>Minoru</first> <last>Sasaki</last></author>
      <author><first>Hiroyuki</first> <last>Shinnou</last></author>
      <pages>59–67</pages>
      <url hash="d0fc2bd3">W16-1708</url>
      <doi>10.18653/v1/W16-1708</doi>
    </paper>
    <paper id="9">
      <title>Different Flavors of <fixed-case>GUM</fixed-case>: Evaluating Genre and Sentence Type Effects on Multilayer Corpus Annotation Quality</title>
      <author><first>Amir</first> <last>Zeldes</last></author>
      <author><first>Dan</first> <last>Simonson</last></author>
      <pages>68–78</pages>
      <url hash="7cf47140">W16-1709</url>
      <doi>10.18653/v1/W16-1709</doi>
    </paper>
    <paper id="10">
      <title>Addressing Annotation Complexity: The Case of Annotating Ideological Perspective in <fixed-case>E</fixed-case>gyptian Social Media</title>
      <author><first>Heba</first> <last>Elfardy</last></author>
      <author><first>Mona</first> <last>Diab</last></author>
      <pages>79–88</pages>
      <url hash="21ae85ee">W16-1710</url>
      <doi>10.18653/v1/W16-1710</doi>
    </paper>
    <paper id="11">
      <title>Evaluating Inter-Annotator Agreement on Historical Spelling Normalization</title>
      <author><first>Marcel</first> <last>Bollmann</last></author>
      <author><first>Stefanie</first> <last>Dipper</last></author>
      <author><first>Florian</first> <last>Petran</last></author>
      <pages>89–98</pages>
      <url hash="5320cefb">W16-1711</url>
      <doi>10.18653/v1/W16-1711</doi>
    </paper>
    <paper id="12">
      <title>A Corpus of Preposition Supersenses</title>
      <author><first>Nathan</first> <last>Schneider</last></author>
      <author><first>Jena D.</first> <last>Hwang</last></author>
      <author><first>Vivek</first> <last>Srikumar</last></author>
      <author><first>Meredith</first> <last>Green</last></author>
      <author><first>Abhijit</first> <last>Suresh</last></author>
      <author><first>Kathryn</first> <last>Conger</last></author>
      <author><first>Tim</first> <last>O’Gorman</last></author>
      <author><first>Martha</first> <last>Palmer</last></author>
      <pages>99–109</pages>
      <url hash="72cc45b5">W16-1712</url>
      <doi>10.18653/v1/W16-1712</doi>
    </paper>
    <paper id="13">
      <title>Focus Annotation of Task-based Data: Establishing the Quality of Crowd Annotation</title>
      <author><first>Kordula</first> <last>De Kuthy</last></author>
      <author><first>Ramon</first> <last>Ziai</last></author>
      <author><first>Detmar</first> <last>Meurers</last></author>
      <pages>110–119</pages>
      <url hash="2eb7764a">W16-1713</url>
      <doi>10.18653/v1/W16-1713</doi>
    </paper>
    <paper id="14">
      <title>Part of Speech Annotation of a <fixed-case>T</fixed-case>urkish-<fixed-case>G</fixed-case>erman Code-Switching Corpus</title>
      <author><first>Özlem</first> <last>Çetinoğlu</last></author>
      <author><first>Çağrı</first> <last>Çöltekin</last></author>
      <pages>120–130</pages>
      <url hash="5838816a">W16-1714</url>
      <doi>10.18653/v1/W16-1714</doi>
    </paper>
    <paper id="15">
      <title>Dependency Annotation Choices: Assessing Theoretical and Practical Issues of <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies</title>
      <author><first>Kim</first> <last>Gerdes</last></author>
      <author><first>Sylvain</first> <last>Kahane</last></author>
      <pages>131–140</pages>
      <url hash="00cbf93f">W16-1715</url>
      <doi>10.18653/v1/W16-1715</doi>
    </paper>
    <paper id="16">
      <title>Conversion from Paninian Karakas to <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies for <fixed-case>H</fixed-case>indi Dependency Treebank</title>
      <author><first>Juhi</first> <last>Tandon</last></author>
      <author><first>Himani</first> <last>Chaudhry</last></author>
      <author><first>Riyaz Ahmad</first> <last>Bhat</last></author>
      <author><first>Dipti</first> <last>Sharma</last></author>
      <pages>141–150</pages>
      <url hash="8b92ac15">W16-1716</url>
      <doi>10.18653/v1/W16-1716</doi>
    </paper>
    <paper id="17">
      <title>Phrase Generalization: a Corpus Study in Multi-Document Abstracts and Original News Alignments</title>
      <author><first>Ariani</first> <last>Di-Felippo</last></author>
      <author><first>Ani</first> <last>Nenkova</last></author>
      <pages>151–159</pages>
      <url hash="e8c14da4">W16-1717</url>
      <doi>10.18653/v1/W16-1717</doi>
    </paper>
    <paper id="18">
      <title>Generating Disambiguating Paraphrases for Structurally Ambiguous Sentences</title>
      <author><first>Manjuan</first> <last>Duan</last></author>
      <author><first>Ethan</first> <last>Hill</last></author>
      <author><first>Michael</first> <last>White</last></author>
      <pages>160–170</pages>
      <url hash="61be5a26">W16-1718</url>
      <doi>10.18653/v1/W16-1718</doi>
    </paper>
    <paper id="19">
      <title>Applying <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependency to the <fixed-case>A</fixed-case>rapaho Language</title>
      <author><first>Irina</first> <last>Wagner</last></author>
      <author><first>Andrew</first> <last>Cowell</last></author>
      <author><first>Jena D.</first> <last>Hwang</last></author>
      <pages>171–179</pages>
      <url hash="7593a550">W16-1719</url>
      <doi>10.18653/v1/W16-1719</doi>
    </paper>
    <paper id="20">
      <title>Annotating the discourse and dialogue structure of <fixed-case>SMS</fixed-case> message conversations</title>
      <author><first>Nianwen</first> <last>Xue</last></author>
      <author><first>Qishen</first> <last>Su</last></author>
      <author><first>Sooyoung</first> <last>Jeong</last></author>
      <pages>180–187</pages>
      <url hash="8d1d7853">W16-1720</url>
      <doi>10.18653/v1/W16-1720</doi>
    </paper>
    <paper id="21">
      <title>Creating a Novel Geolocation Corpus from Historical Texts</title>
      <author><first>Grant</first> <last>DeLozier</last></author>
      <author><first>Ben</first> <last>Wing</last></author>
      <author><first>Jason</first> <last>Baldridge</last></author>
      <author><first>Scott</first> <last>Nesbit</last></author>
      <pages>188–198</pages>
      <url hash="f6a9843a">W16-1721</url>
      <doi>10.18653/v1/W16-1721</doi>
    </paper>
  </volume>
  <volume id="18">
    <meta>
      <booktitle>Proceedings of the 12th Workshop on Multiword Expressions</booktitle>
      <url hash="ef47ae6d">W16-18</url>
      <editor><first>Valia</first><last>Kordoni</last></editor>
      <editor><first>Kostadin</first><last>Cholakov</last></editor>
      <editor><first>Markus</first><last>Egg</last></editor>
      <editor><first>Stella</first><last>Markantonatou</last></editor>
      <editor><first>Preslav</first><last>Nakov</last></editor>
      <doi>10.18653/v1/W16-18</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="f9e87f49">W16-1800</url>
    </frontmatter>
    <paper id="1">
      <title>Learning Paraphrasing for Multiword Expressions</title>
      <author><first>Seid Muhie</first> <last>Yimam</last></author>
      <author><first>Héctor</first> <last>Martínez Alonso</last></author>
      <author><first>Martin</first> <last>Riedl</last></author>
      <author><first>Chris</first> <last>Biemann</last></author>
      <pages>1–10</pages>
      <url hash="05079bf2">W16-1801</url>
      <doi>10.18653/v1/W16-1801</doi>
    </paper>
    <paper id="2">
      <title>Exploring Long-Term Temporal Trends in the Use of Multiword Expressions</title>
      <author><first>Tal</first> <last>Daniel</last></author>
      <author><first>Mark</first> <last>Last</last></author>
      <pages>11–20</pages>
      <url hash="4b202fff">W16-1802</url>
      <doi>10.18653/v1/W16-1802</doi>
    </paper>
    <paper id="3">
      <title>Lexical Variability and Compositionality: Investigating Idiomaticity with Distributional Semantic Models</title>
      <author><first>Marco Silvio Giuseppe</first> <last>Senaldi</last></author>
      <author><first>Gianluca E.</first> <last>Lebani</last></author>
      <author><first>Alessandro</first> <last>Lenci</last></author>
      <pages>21–31</pages>
      <url hash="85b8283b">W16-1803</url>
      <doi>10.18653/v1/W16-1803</doi>
    </paper>
    <paper id="4">
      <title>Filtering and Measuring the Intrinsic Quality of Human Compositionality Judgments</title>
      <author><first>Carlos</first> <last>Ramisch</last></author>
      <author><first>Silvio</first> <last>Cordeiro</last></author>
      <author><first>Aline</first> <last>Villavicencio</last></author>
      <pages>32–37</pages>
      <url hash="dc474799">W16-1804</url>
      <doi>10.18653/v1/W16-1804</doi>
    </paper>
    <paper id="5">
      <title>Graph-based Clustering of Synonym Senses for <fixed-case>G</fixed-case>erman Particle Verbs</title>
      <author><first>Moritz</first> <last>Wittmann</last></author>
      <author><first>Marion</first> <last>Weller-Di Marco</last></author>
      <author><first>Sabine</first> <last>Schulte im Walde</last></author>
      <pages>38–43</pages>
      <url hash="8891d610">W16-1805</url>
      <doi>10.18653/v1/W16-1805</doi>
    </paper>
    <paper id="6">
      <title>Accounting ngrams and multi-word terms can improve topic models</title>
      <author><first>Michael</first> <last>Nokel</last></author>
      <author><first>Natalia</first> <last>Loukachevitch</last></author>
      <pages>44–49</pages>
      <url hash="7985a84b">W16-1806</url>
      <doi>10.18653/v1/W16-1806</doi>
    </paper>
    <paper id="7">
      <title>Top a Splitter: Using Distributional Semantics for Improving Compound Splitting</title>
      <author><first>Patrick</first> <last>Ziering</last></author>
      <author><first>Stefan</first> <last>Müller</last></author>
      <author><first>Lonneke</first> <last>van der Plas</last></author>
      <pages>50–55</pages>
      <url hash="02f1edbc">W16-1807</url>
      <doi>10.18653/v1/W16-1807</doi>
    </paper>
    <paper id="8">
      <title>Using Word Embeddings for Improving Statistical Machine Translation of Phrasal Verbs</title>
      <author><first>Kostadin</first> <last>Cholakov</last></author>
      <author><first>Valia</first> <last>Kordoni</last></author>
      <pages>56–60</pages>
      <url hash="c62c3cef">W16-1808</url>
      <doi>10.18653/v1/W16-1808</doi>
    </paper>
    <paper id="9">
      <title>Modeling the Non-Substitutability of Multiword Expressions with Distributional Semantics and a Log-Linear Model</title>
      <author><first>Meghdad</first> <last>Farahmand</last></author>
      <author><first>James</first> <last>Henderson</last></author>
      <pages>61–66</pages>
      <url hash="a459cd26">W16-1809</url>
      <doi>10.18653/v1/W16-1809</doi>
    </paper>
    <paper id="10">
      <title>Phrase Representations for Multiword Expressions</title>
      <author><first>Joël</first> <last>Legrand</last></author>
      <author><first>Ronan</first> <last>Collobert</last></author>
      <pages>67–71</pages>
      <url hash="78838b19">W16-1810</url>
      <doi>10.18653/v1/W16-1810</doi>
    </paper>
    <paper id="11">
      <title>Representing Support Verbs in <fixed-case>F</fixed-case>rame<fixed-case>N</fixed-case>et</title>
      <author><first>Miriam R. L.</first> <last>Petruck</last></author>
      <author><first>Michael</first> <last>Ellsworth</last></author>
      <pages>72–77</pages>
      <url hash="06e6c753">W16-1811</url>
      <doi>10.18653/v1/W16-1811</doi>
    </paper>
    <paper id="12">
      <title>Inherently Pronominal Verbs in <fixed-case>C</fixed-case>zech: Description and Conversion Based on Treebank Annotation</title>
      <author><first>Zdeňka</first> <last>Urešová</last></author>
      <author><first>Eduard</first> <last>Bejček</last></author>
      <author><first>Jan</first> <last>Hajič</last></author>
      <pages>78–83</pages>
      <url hash="6c14386d">W16-1812</url>
      <doi>10.18653/v1/W16-1812</doi>
    </paper>
    <paper id="13">
      <title>Using collocational features to improve automated scoring of <fixed-case>EFL</fixed-case> texts</title>
      <author><first>Yves</first> <last>Bestgen</last></author>
      <pages>84–90</pages>
      <url hash="57b14b7b">W16-1813</url>
      <doi>10.18653/v1/W16-1813</doi>
    </paper>
    <paper id="14">
      <title>A study on the production of collocations by <fixed-case>E</fixed-case>uropean <fixed-case>P</fixed-case>ortuguese learners</title>
      <author><first>Ângela</first> <last>Costa</last></author>
      <author><first>Luísa</first> <last>Coheur</last></author>
      <author><first>Teresa</first> <last>Lino</last></author>
      <pages>91–95</pages>
      <url hash="3a1a4949">W16-1814</url>
      <doi>10.18653/v1/W16-1814</doi>
    </paper>
    <paper id="15">
      <title>Extraction and Recognition of <fixed-case>P</fixed-case>olish Multiword Expressions using <fixed-case>W</fixed-case>ikipedia and Finite-State Automata</title>
      <author><first>Paweł</first> <last>Chrząszcz</last></author>
      <pages>96–106</pages>
      <url hash="31844027">W16-1815</url>
      <doi>10.18653/v1/W16-1815</doi>
    </paper>
    <paper id="16">
      <title>Impact of <fixed-case>MWE</fixed-case> Resources on Multiword Recognition</title>
      <author><first>Martin</first> <last>Riedl</last></author>
      <author><first>Chris</first> <last>Biemann</last></author>
      <pages>107–111</pages>
      <url hash="a4464d41">W16-1816</url>
      <doi>10.18653/v1/W16-1816</doi>
    </paper>
    <paper id="17">
      <title>A Word Embedding Approach to Identifying Verb-Noun Idiomatic Combinations</title>
      <author><first>Waseem</first> <last>Gharbieh</last></author>
      <author><first>Virendra</first> <last>Bhavsar</last></author>
      <author><first>Paul</first> <last>Cook</last></author>
      <pages>112–118</pages>
      <url hash="1785eda2">W16-1817</url>
      <doi>10.18653/v1/W16-1817</doi>
    </paper>
  </volume>
  <volume id="19">
    <meta>
      <booktitle>Proceedings of the 7th Workshop on Cognitive Aspects of Computational Language Learning</booktitle>
      <url hash="8ba31537">W16-19</url>
      <editor><first>Anna</first><last>Korhonen</last></editor>
      <editor><first>Alessandro</first><last>Lenci</last></editor>
      <editor><first>Brian</first><last>Murphy</last></editor>
      <editor><first>Thierry</first><last>Poibeau</last></editor>
      <editor><first>Aline</first><last>Villavicencio</last></editor>
      <doi>10.18653/v1/W16-19</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="95e4392f">W16-1900</url>
    </frontmatter>
    <paper id="1">
      <title>Automated Discourse Analysis of Narrations by Adolescents with Autistic Spectrum Disorder</title>
      <author><first>Michaela</first> <last>Regneri</last></author>
      <author><first>Diane</first> <last>King</last></author>
      <pages>1–9</pages>
      <url hash="673f3615">W16-1901</url>
      <doi>10.18653/v1/W16-1901</doi>
    </paper>
    <paper id="2">
      <title>Detection of <fixed-case>A</fixed-case>lzheimer’s disease based on automatic analysis of common objects descriptions</title>
      <author><first>Laura</first> <last>Hernández-Domínguez</last></author>
      <author><first>Edgar</first> <last>García-Cano</last></author>
      <author><first>Sylvie</first> <last>Ratté</last></author>
      <author><first>Gerardo</first> <last>Sierra-Martínez</last></author>
      <pages>10–15</pages>
      <url hash="26a778de">W16-1902</url>
      <doi>10.18653/v1/W16-1902</doi>
    </paper>
    <paper id="3">
      <title>Conversing with the elderly in <fixed-case>L</fixed-case>atin <fixed-case>A</fixed-case>merica: a new cohort for multimodal, multilingual longitudinal studies on aging</title>
      <author><first>Laura</first> <last>Hernández-Domínguez</last></author>
      <author><first>Sylvie</first> <last>Ratté</last></author>
      <author><first>Boyd</first> <last>Davis</last></author>
      <author><first>Charlene</first> <last>Pope</last></author>
      <pages>16–21</pages>
      <url hash="aab062f1">W16-1903</url>
      <doi>10.18653/v1/W16-1903</doi>
    </paper>
    <paper id="4">
      <title>Leveraging Annotators’ Gaze Behaviour for Coreference Resolution</title>
      <author><first>Joe</first> <last>Cheri</last></author>
      <author><first>Abhijit</first> <last>Mishra</last></author>
      <author><first>Pushpak</first> <last>Bhattacharyya</last></author>
      <pages>22–26</pages>
      <url hash="f363d235">W16-1904</url>
      <doi>10.18653/v1/W16-1904</doi>
    </paper>
    <paper id="5">
      <title>From alignment of etymological data to phylogenetic inference via population genetics</title>
      <author><first>Javad</first> <last>Nouri</last></author>
      <author><first>Roman</first> <last>Yangarber</last></author>
      <pages>27–37</pages>
      <url hash="ae9ebc0e">W16-1905</url>
      <doi>10.18653/v1/W16-1905</doi>
    </paper>
    <paper id="6">
      <title>An incremental model of syntactic bootstrapping</title>
      <author><first>Christos</first> <last>Christodoulopoulos</last></author>
      <author><first>Dan</first> <last>Roth</last></author>
      <author><first>Cynthia</first> <last>Fisher</last></author>
      <pages>38–43</pages>
      <url hash="dfe19ccb">W16-1906</url>
      <doi>10.18653/v1/W16-1906</doi>
    </paper>
    <paper id="7">
      <title>Longitudinal Studies of Variation Sets in Child-directed Speech</title>
      <author><first>Mats</first> <last>Wirén</last></author>
      <author><first>Kristina</first> <last>Nilsson Björkenstam</last></author>
      <author><first>Gintarė</first> <last>Grigonytė</last></author>
      <author><first>Elisabet Eir</first> <last>Cortes</last></author>
      <pages>44–52</pages>
      <url hash="863fd01b">W16-1907</url>
      <doi>10.18653/v1/W16-1907</doi>
    </paper>
    <paper id="8">
      <title>Learning Phone Embeddings for Word Segmentation of Child-Directed Speech</title>
      <author><first>Jianqiang</first> <last>Ma</last></author>
      <author><first>Çağrı</first> <last>Çöltekin</last></author>
      <author><first>Erhard</first> <last>Hinrichs</last></author>
      <pages>53–63</pages>
      <url hash="ff2240a5">W16-1908</url>
      <doi>10.18653/v1/W16-1908</doi>
    </paper>
    <paper id="9">
      <title>Generalization in Artificial Language Learning: Modelling the Propensity to Generalize</title>
      <author><first>Raquel G.</first> <last>Alhama</last></author>
      <author><first>Willem</first> <last>Zuidema</last></author>
      <pages>64–72</pages>
      <url hash="69e38fa1">W16-1909</url>
      <doi>10.18653/v1/W16-1909</doi>
    </paper>
    <paper id="10">
      <title>Explicit Causal Connections between the Acquisition of Linguistic Tiers: Evidence from Dynamical Systems Modeling</title>
      <author><first>Daniel</first> <last>Spokoyny</last></author>
      <author><first>Jeremy</first> <last>Irvin</last></author>
      <author><first>Fermin</first> <last>Moscoso del Prado Martin</last></author>
      <pages>73–81</pages>
      <url hash="611e671b">W16-1910</url>
      <doi>10.18653/v1/W16-1910</doi>
    </paper>
    <paper id="11">
      <title>Modelling the informativeness and timing of non-verbal cues in parent-child interaction</title>
      <author><first>Kristina</first> <last>Nilsson Björkenstam</last></author>
      <author><first>Mats</first> <last>Wirén</last></author>
      <author><first>Robert</first> <last>Östling</last></author>
      <pages>82–90</pages>
      <url hash="46376351">W16-1911</url>
      <doi>10.18653/v1/W16-1911</doi>
    </paper>
  </volume>
  <volume id="20">
    <meta>
      <booktitle>Proceedings of the 14th <fixed-case>SIGMORPHON</fixed-case> Workshop on Computational Research in Phonetics, Phonology, and Morphology</booktitle>
      <url hash="fc86503d">W16-20</url>
      <editor><first>Micha</first><last>Elsner</last></editor>
      <editor><first>Sandra</first> <last>Kuebler</last></editor>
      <doi>10.18653/v1/W16-20</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="14f25017">W16-2000</url>
    </frontmatter>
    <paper id="1">
      <title>Mining linguistic tone patterns with symbolic representation</title>
      <author><first>Shuo</first> <last>Zhang</last></author>
      <pages>1–9</pages>
      <url hash="7d975a2e">W16-2001</url>
      <doi>10.18653/v1/W16-2001</doi>
    </paper>
    <paper id="2">
      <title>The <fixed-case>SIGMORPHON</fixed-case> 2016 Shared <fixed-case>T</fixed-case>ask—<fixed-case>M</fixed-case>orphological Reinflection</title>
      <author><first>Ryan</first> <last>Cotterell</last></author>
      <author><first>Christo</first> <last>Kirov</last></author>
      <author><first>John</first> <last>Sylak-Glassman</last></author>
      <author><first>David</first> <last>Yarowsky</last></author>
      <author><first>Jason</first> <last>Eisner</last></author>
      <author><first>Mans</first> <last>Hulden</last></author>
      <pages>10–22</pages>
      <url hash="57774fe4">W16-2002</url>
      <doi>10.18653/v1/W16-2002</doi>
    </paper>
    <paper id="3">
      <title>Morphological reinflection with convolutional neural networks</title>
      <author><first>Robert</first> <last>Östling</last></author>
      <pages>23–26</pages>
      <url hash="f6118c0c">W16-2003</url>
      <doi>10.18653/v1/W16-2003</doi>
    </paper>
    <paper id="4">
      <title><fixed-case>EHU</fixed-case> at the <fixed-case>SIGMORPHON</fixed-case> 2016 Shared Task. A Simple Proposal: Grapheme-to-Phoneme for Inflection</title>
      <author><first>Iñaki</first> <last>Alegria</last></author>
      <author><first>Izaskun</first> <last>Etxeberria</last></author>
      <pages>27–30</pages>
      <url hash="f797af1a">W16-2004</url>
      <doi>10.18653/v1/W16-2004</doi>
    </paper>
    <paper id="5">
      <title>Morphological Reinflection via Discriminative String Transduction</title>
      <author><first>Garrett</first> <last>Nicolai</last></author>
      <author><first>Bradley</first> <last>Hauer</last></author>
      <author><first>Adam</first> <last>St Arnaud</last></author>
      <author><first>Grzegorz</first> <last>Kondrak</last></author>
      <pages>31–35</pages>
      <url hash="62a2b6a8">W16-2005</url>
      <doi>10.18653/v1/W16-2005</doi>
    </paper>
    <paper id="6">
      <title>Morphological reinflection with conditional random fields and unsupervised features</title>
      <author><first>Ling</first> <last>Liu</last></author>
      <author><first>Lingshuang Jack</first> <last>Mao</last></author>
      <pages>36–40</pages>
      <url hash="a734fc6d">W16-2006</url>
      <doi>10.18653/v1/W16-2006</doi>
    </paper>
    <paper id="7">
      <title>Improving Sequence to Sequence Learning for Morphological Inflection Generation: The <fixed-case>BIU</fixed-case>-<fixed-case>MIT</fixed-case> Systems for the <fixed-case>SIGMORPHON</fixed-case> 2016 Shared Task for Morphological Reinflection</title>
      <author><first>Roee</first> <last>Aharoni</last></author>
      <author><first>Yoav</first> <last>Goldberg</last></author>
      <author><first>Yonatan</first> <last>Belinkov</last></author>
      <pages>41–48</pages>
      <url hash="ca4fc73c">W16-2007</url>
      <doi>10.18653/v1/W16-2007</doi>
    </paper>
    <paper id="8">
      <title>Evaluating Sequence Alignment for Learning Inflectional Morphology</title>
      <author><first>David</first> <last>King</last></author>
      <pages>49–53</pages>
      <url hash="523af288">W16-2008</url>
      <doi>10.18653/v1/W16-2008</doi>
    </paper>
    <paper id="9">
      <title>Using longest common subsequence and character models to predict word forms</title>
      <author><first>Alexey</first> <last>Sorokin</last></author>
      <pages>54–61</pages>
      <url hash="cda11914">W16-2009</url>
      <doi>10.18653/v1/W16-2009</doi>
    </paper>
    <paper id="10">
      <title><fixed-case>MED</fixed-case>: The <fixed-case>LMU</fixed-case> System for the <fixed-case>SIGMORPHON</fixed-case> 2016 Shared Task on Morphological Reinflection</title>
      <author><first>Katharina</first> <last>Kann</last></author>
      <author><first>Hinrich</first> <last>Schütze</last></author>
      <pages>62–70</pages>
      <url hash="1561ea52">W16-2010</url>
      <doi>10.18653/v1/W16-2010</doi>
    </paper>
    <paper id="11">
      <title>The <fixed-case>C</fixed-case>olumbia <fixed-case>U</fixed-case>niversity - <fixed-case>N</fixed-case>ew <fixed-case>Y</fixed-case>ork <fixed-case>U</fixed-case>niversity <fixed-case>A</fixed-case>bu <fixed-case>D</fixed-case>habi <fixed-case>SIGMORPHON</fixed-case> 2016 Morphological Reinflection Shared Task Submission</title>
      <author><first>Dima</first> <last>Taji</last></author>
      <author><first>Ramy</first> <last>Eskander</last></author>
      <author><first>Nizar</first> <last>Habash</last></author>
      <author><first>Owen</first> <last>Rambow</last></author>
      <pages>71–75</pages>
      <url hash="f2eed862">W16-2011</url>
      <doi>10.18653/v1/W16-2011</doi>
    </paper>
    <paper id="12">
      <title>Letter Sequence Labeling for Compound Splitting</title>
      <author><first>Jianqiang</first> <last>Ma</last></author>
      <author><first>Verena</first> <last>Henrich</last></author>
      <author><first>Erhard</first> <last>Hinrichs</last></author>
      <pages>76–81</pages>
      <url hash="9710383f">W16-2012</url>
      <doi>10.18653/v1/W16-2012</doi>
    </paper>
    <paper id="13">
      <title>Automatic Detection of Intra-Word Code-Switching</title>
      <author><first>Dong</first> <last>Nguyen</last></author>
      <author><first>Leonie</first> <last>Cornips</last></author>
      <pages>82–86</pages>
      <url hash="90ead85b">W16-2013</url>
      <doi>10.18653/v1/W16-2013</doi>
    </paper>
    <paper id="14">
      <title>Read my points: Effect of animation type when speech-reading from <fixed-case>EMA</fixed-case> data</title>
      <author><first>Kristy</first> <last>James</last></author>
      <author><first>Martijn</first> <last>Wieling</last></author>
      <pages>87–92</pages>
      <url hash="c8fe679d">W16-2014</url>
      <doi>10.18653/v1/W16-2014</doi>
    </paper>
    <paper id="15">
      <title>Predicting the Direction of Derivation in <fixed-case>E</fixed-case>nglish Conversion</title>
      <author><first>Max</first> <last>Kisselew</last></author>
      <author><first>Laura</first> <last>Rimell</last></author>
      <author><first>Alexis</first> <last>Palmer</last></author>
      <author><first>Sebastian</first> <last>Padó</last></author>
      <pages>93–98</pages>
      <url hash="616e0cca">W16-2015</url>
      <doi>10.18653/v1/W16-2015</doi>
    </paper>
    <paper id="16">
      <title>Morphological Segmentation Can Improve Syllabification</title>
      <author><first>Garrett</first> <last>Nicolai</last></author>
      <author><first>Lei</first> <last>Yao</last></author>
      <author><first>Grzegorz</first> <last>Kondrak</last></author>
      <pages>99–103</pages>
      <url hash="9258cff6">W16-2016</url>
      <doi>10.18653/v1/W16-2016</doi>
    </paper>
    <paper id="17">
      <title>Towards a Formal Representation of Components of <fixed-case>G</fixed-case>erman Compounds</title>
      <author><first>Thierry</first> <last>Declerck</last></author>
      <author><first>Piroska</first> <last>Lendvai</last></author>
      <pages>104–109</pages>
      <url hash="ee21b965">W16-2017</url>
      <doi>10.18653/v1/W16-2017</doi>
    </paper>
    <paper id="18">
      <title>Towards robust cross-linguistic comparisons of phonological networks</title>
      <author><first>Philippa</first> <last>Shoemark</last></author>
      <author><first>Sharon</first> <last>Goldwater</last></author>
      <author><first>James</first> <last>Kirby</last></author>
      <author><first>Rik</first> <last>Sarkar</last></author>
      <pages>110–120</pages>
      <url hash="0bc5095f">W16-2018</url>
      <doi>10.18653/v1/W16-2018</doi>
    </paper>
    <paper id="19">
      <title>Morphotactics as Tier-Based Strictly Local Dependencies</title>
      <author><first>Alëna</first> <last>Aksënova</last></author>
      <author><first>Thomas</first> <last>Graf</last></author>
      <author><first>Sedigheh</first> <last>Moradi</last></author>
      <pages>121–130</pages>
      <url hash="bfc3ae5a">W16-2019</url>
      <doi>10.18653/v1/W16-2019</doi>
    </paper>
    <paper id="20">
      <title>A Multilinear Approach to the Unsupervised Learning of Morphology</title>
      <author><first>Anthony</first> <last>Meyer</last></author>
      <author><first>Markus</first> <last>Dickinson</last></author>
      <pages>131–140</pages>
      <url hash="38a30ef8">W16-2020</url>
      <doi>10.18653/v1/W16-2020</doi>
    </paper>
    <paper id="21">
      <title>Inferring Morphotactics from Interlinear Glossed Text: Combining Clustering and Precision Grammars</title>
      <author><first>Olga</first> <last>Zamaraeva</last></author>
      <pages>141–150</pages>
      <url hash="43a56991">W16-2021</url>
      <doi>10.18653/v1/W16-2021</doi>
    </paper>
  </volume>
  <volume id="21">
    <meta>
      <booktitle>Proceedings of the 10th <fixed-case>SIGHUM</fixed-case> Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities</booktitle>
      <url hash="c23bb9f6">W16-21</url>
      <editor><first>Nils</first><last>Reiter</last></editor>
      <editor><first>Beatrice</first><last>Alex</last></editor>
      <editor><first>Kalliopi A.</first><last>Zervanou</last></editor>
      <doi>10.18653/v1/W16-21</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="3c2890a3">W16-2100</url>
    </frontmatter>
    <paper id="1">
      <title>Brave New World: Uncovering Topical Dynamics in the <fixed-case>ACL</fixed-case> <fixed-case>A</fixed-case>nthology Reference Corpus Using Term Life Cycle Information</title>
      <author><first>Anne-Kathrin</first> <last>Schumann</last></author>
      <pages>1–11</pages>
      <url hash="7b871225">W16-2101</url>
      <doi>10.18653/v1/W16-2101</doi>
    </paper>
    <paper id="2">
      <title>Analysis of Policy Agendas: Lessons Learned from Automatic Topic Classification of <fixed-case>C</fixed-case>roatian Political Texts</title>
      <author><first>Mladen</first> <last>Karan</last></author>
      <author><first>Jan</first> <last>Šnajder</last></author>
      <author><first>Daniela</first> <last>Širinić</last></author>
      <author><first>Goran</first> <last>Glavaš</last></author>
      <pages>12–21</pages>
      <url hash="5de624d7">W16-2102</url>
      <doi>10.18653/v1/W16-2102</doi>
    </paper>
    <paper id="3">
      <title>Searching Four-Millenia-Old Digitized Documents: A Text Retrieval System for Egyptologists</title>
      <author><first>Estíbaliz</first> <last>Iglesias-Franjo</last></author>
      <author><first>Jesús</first> <last>Vilares</last></author>
      <pages>22–31</pages>
      <url hash="9b6162e2">W16-2103</url>
      <doi>10.18653/v1/W16-2103</doi>
    </paper>
    <paper id="4">
      <title>Old <fixed-case>S</fixed-case>wedish Part-of-Speech Tagging between Variation and External Knowledge</title>
      <author><first>Yvonne</first> <last>Adesam</last></author>
      <author><first>Gerlof</first> <last>Bouma</last></author>
      <pages>32–42</pages>
      <url hash="981e7969">W16-2104</url>
      <doi>10.18653/v1/W16-2104</doi>
    </paper>
    <paper id="5">
      <title>Code-Switching Ubique Est - Language Identification and Part-of-Speech Tagging for Historical Mixed Text</title>
      <author><first>Sarah</first> <last>Schulz</last></author>
      <author><first>Mareike</first> <last>Keller</last></author>
      <pages>43–51</pages>
      <url hash="e03d4261">W16-2105</url>
      <doi>10.18653/v1/W16-2105</doi>
    </paper>
    <paper id="6">
      <title>Dealing with word-internal modification and spelling variation in data-driven lemmatization</title>
      <author><first>Fabian</first> <last>Barteld</last></author>
      <author><first>Ingrid</first> <last>Schröder</last></author>
      <author><first>Heike</first> <last>Zinsmeister</last></author>
      <pages>52–62</pages>
      <url hash="283f6a22">W16-2106</url>
      <doi>10.18653/v1/W16-2106</doi>
    </paper>
    <paper id="7">
      <title>You Shall Know People by the Company They Keep: Person Name Disambiguation for Social Network Construction</title>
      <author><first>Mariona</first> <last>Coll Ardanuy</last></author>
      <author><first>Maarten</first> <last>van den Bos</last></author>
      <author><first>Caroline</first> <last>Sporleder</last></author>
      <pages>63–73</pages>
      <url hash="c9f73436">W16-2107</url>
      <doi>10.18653/v1/W16-2107</doi>
    </paper>
    <paper id="8">
      <title>Deriving Players &amp; Themes in the <fixed-case>R</fixed-case>egesta <fixed-case>I</fixed-case>mperii using <fixed-case>SVM</fixed-case>s and Neural Networks</title>
      <author><first>Juri</first> <last>Opitz</last></author>
      <author><first>Anette</first> <last>Frank</last></author>
      <pages>74–83</pages>
      <url hash="e24d870f">W16-2108</url>
      <doi>10.18653/v1/W16-2108</doi>
    </paper>
    <paper id="9">
      <title>Semi-automated annotation of page-based documents within the Genre and Multimodality framework</title>
      <author><first>Tuomo</first> <last>Hiippala</last></author>
      <pages>84–89</pages>
      <url hash="37c3f2cb">W16-2109</url>
      <doi>10.18653/v1/W16-2109</doi>
    </paper>
    <paper id="10">
      <title>Nomen Omen. Enhancing the <fixed-case>L</fixed-case>atin Morphological Analyser Lemlat with an Onomasticon</title>
      <author><first>Marco</first> <last>Budassi</last></author>
      <author><first>Marco</first> <last>Passarotti</last></author>
      <pages>90–94</pages>
      <url hash="8456a0f7">W16-2110</url>
      <doi>10.18653/v1/W16-2110</doi>
    </paper>
    <paper id="11">
      <title>How Do Cultural Differences Impact the Quality of Sarcasm Annotation?: A Case Study of <fixed-case>I</fixed-case>ndian Annotators and <fixed-case>A</fixed-case>merican Text</title>
      <author><first>Aditya</first> <last>Joshi</last></author>
      <author><first>Pushpak</first> <last>Bhattacharyya</last></author>
      <author><first>Mark</first> <last>Carman</last></author>
      <author><first>Jaya</first> <last>Saraswati</last></author>
      <author><first>Rajita</first> <last>Shukla</last></author>
      <pages>95–99</pages>
      <url hash="b7f9ae82">W16-2111</url>
      <doi>10.18653/v1/W16-2111</doi>
    </paper>
    <paper id="12">
      <title>Combining Phonology and Morphology for the Normalization of Historical Texts</title>
      <author><first>Izaskun</first> <last>Etxeberria</last></author>
      <author><first>Iñaki</first> <last>Alegria</last></author>
      <author><first>Larraitz</first> <last>Uria</last></author>
      <author><first>Mans</first> <last>Hulden</last></author>
      <pages>100–105</pages>
      <url hash="a658e825">W16-2112</url>
      <doi>10.18653/v1/W16-2112</doi>
    </paper>
    <paper id="13">
      <title>Towards Building a Political Protest Database to Explain Changes in the Welfare State</title>
      <author><first>Çağıl</first> <last>Sönmez</last></author>
      <author><first>Arzucan</first> <last>Özgür</last></author>
      <author><first>Erdem</first> <last>Yörük</last></author>
      <pages>106–110</pages>
      <url hash="3c2ea8f2">W16-2113</url>
      <doi>10.18653/v1/W16-2113</doi>
    </paper>
    <paper id="14">
      <title>An Assessment of Experimental Protocols for Tracing Changes in Word Semantics Relative to Accuracy and Reliability</title>
      <author><first>Johannes</first> <last>Hellrich</last></author>
      <author><first>Udo</first> <last>Hahn</last></author>
      <pages>111–117</pages>
      <url hash="cb7c6fc7">W16-2114</url>
      <doi>10.18653/v1/W16-2114</doi>
    </paper>
    <paper id="15">
      <title><fixed-case>U</fixed-case>niversal <fixed-case>M</fixed-case>orphology for <fixed-case>O</fixed-case>ld <fixed-case>H</fixed-case>ungarian</title>
      <author><first>Eszter</first> <last>Simon</last></author>
      <author><first>Veronika</first> <last>Vincze</last></author>
      <pages>118–127</pages>
      <url hash="3d0cd300">W16-2115</url>
      <doi>10.18653/v1/W16-2115</doi>
    </paper>
    <paper id="16">
      <title>Automatic Identification of Suicide Notes from Linguistic and Sentiment Features</title>
      <author><first>Annika Marie</first> <last>Schoene</last></author>
      <author><first>Nina</first> <last>Dethlefs</last></author>
      <pages>128–133</pages>
      <url hash="09907634">W16-2116</url>
      <doi>10.18653/v1/W16-2116</doi>
    </paper>
    <paper id="17">
      <title>Towards a text analysis system for political debates</title>
      <author><first>Dieu-Thu</first> <last>Le</last></author>
      <author><first>Ngoc Thang</first> <last>Vu</last></author>
      <author><first>Andre</first> <last>Blessing</last></author>
      <pages>134–139</pages>
      <url hash="f5071594">W16-2117</url>
      <doi>10.18653/v1/W16-2117</doi>
    </paper>
    <paper id="18">
      <title>Whodunit... and to Whom? Subjects, Objects, and Actions in Research Articles on <fixed-case>A</fixed-case>merican Labor Unions</title>
      <author><first>Vilja</first> <last>Hulden</last></author>
      <pages>140–145</pages>
      <url hash="8939021f">W16-2118</url>
      <doi>10.18653/v1/W16-2118</doi>
    </paper>
    <paper id="19">
      <title>An <fixed-case>NLP</fixed-case> Pipeline for <fixed-case>C</fixed-case>optic</title>
      <author><first>Amir</first> <last>Zeldes</last></author>
      <author><first>Caroline T.</first> <last>Schroeder</last></author>
      <pages>146–155</pages>
      <url hash="4a620923">W16-2119</url>
      <doi>10.18653/v1/W16-2119</doi>
    </paper>
    <paper id="20">
      <title>Automatic discovery of <fixed-case>L</fixed-case>atin syntactic changes</title>
      <author><first>Micha</first> <last>Elsner</last></author>
      <author><first>Emily</first> <last>Lane</last></author>
      <pages>156–164</pages>
      <url hash="ffeb4ffe">W16-2120</url>
      <doi>10.18653/v1/W16-2120</doi>
    </paper>
    <paper id="21">
      <title>Information-based Modeling of Diachronic Linguistic Change: from Typicality to Productivity</title>
      <author><first>Stefania</first> <last>Degaetano-Ortlieb</last></author>
      <author><first>Elke</first> <last>Teich</last></author>
      <pages>165–173</pages>
      <url hash="66b0f60d">W16-2121</url>
      <doi>10.18653/v1/W16-2121</doi>
    </paper>
  </volume>
  <volume id="22">
    <meta>
      <booktitle>Proceedings of the First Conference on Machine Translation: Volume 1, Research Papers</booktitle>
      <editor><first>Ondřej</first><last>Bojar</last></editor>
      <editor><first>Christian</first><last>Buck</last></editor>
      <editor><first>Rajen</first><last>Chatterjee</last></editor>
      <editor><first>Christian</first><last>Federmann</last></editor>
      <editor><first>Liane</first><last>Guillou</last></editor>
      <editor><first>Barry</first><last>Haddow</last></editor>
      <editor><first>Matthias</first><last>Huck</last></editor>
      <editor><first>Antonio Jimeno</first><last>Yepes</last></editor>
      <editor><first>Aurélie</first><last>Névéol</last></editor>
      <editor><first>Mariana</first><last>Neves</last></editor>
      <editor><first>Pavel</first><last>Pecina</last></editor>
      <editor><first>Martin</first><last>Popel</last></editor>
      <editor><first>Philipp</first><last>Koehn</last></editor>
      <editor><first>Christof</first><last>Monz</last></editor>
      <editor><first>Matteo</first><last>Negri</last></editor>
      <editor><first>Matt</first><last>Post</last></editor>
      <editor><first>Lucia</first><last>Specia</last></editor>
      <editor><first>Karin</first><last>Verspoor</last></editor>
      <editor><first>Jörg</first><last>Tiedemann</last></editor>
      <editor><first>Marco</first><last>Turchi</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="7561d136">W16-2200</url>
      <doi>10.18653/v1/W16-2200</doi>
    </frontmatter>
    <paper id="1">
      <title>Cross-language Projection of Dependency Trees with Constrained Partial Parsing for Tree-to-Tree Machine Translation</title>
      <author><first>Yu</first> <last>Shen</last></author>
      <author><first>Chenhui</first> <last>Chu</last></author>
      <author><first>Fabien</first> <last>Cromieres</last></author>
      <author><first>Sadao</first> <last>Kurohashi</last></author>
      <pages>1–11</pages>
      <url hash="cf35b0fe">W16-2201</url>
      <doi>10.18653/v1/W16-2201</doi>
    </paper>
    <paper id="2">
      <title>Improving Pronoun Translation by Modeling Coreference Uncertainty</title>
      <author><first>Ngoc Quang</first> <last>Luong</last></author>
      <author><first>Andrei</first> <last>Popescu-Belis</last></author>
      <pages>12–20</pages>
      <url hash="c7098c03">W16-2202</url>
      <doi>10.18653/v1/W16-2202</doi>
    </paper>
    <paper id="3">
      <title>Modeling verbal inflection for <fixed-case>E</fixed-case>nglish to <fixed-case>G</fixed-case>erman <fixed-case>SMT</fixed-case></title>
      <author><first>Anita</first> <last>Ramm</last></author>
      <author><first>Alexander</first> <last>Fraser</last></author>
      <pages>21–31</pages>
      <url hash="f84ee4fa">W16-2203</url>
      <doi>10.18653/v1/W16-2203</doi>
    </paper>
    <paper id="4">
      <title>Modeling Selectional Preferences of Verbs and Nouns in String-to-Tree Machine Translation</title>
      <author><first>Maria</first> <last>Nădejde</last></author>
      <author><first>Alexandra</first> <last>Birch</last></author>
      <author><first>Philipp</first> <last>Koehn</last></author>
      <pages>32–42</pages>
      <url hash="973e8309">W16-2204</url>
      <doi>10.18653/v1/W16-2204</doi>
    </paper>
    <paper id="5">
      <title>Modeling Complement Types in Phrase-Based <fixed-case>SMT</fixed-case></title>
      <author><first>Marion</first> <last>Weller-Di Marco</last></author>
      <author><first>Alexander</first> <last>Fraser</last></author>
      <author><first>Sabine</first> <last>Schulte im Walde</last></author>
      <pages>43–53</pages>
      <url hash="a5f0f442">W16-2205</url>
      <doi>10.18653/v1/W16-2205</doi>
    </paper>
    <paper id="6">
      <title>Alignment-Based Neural Machine Translation</title>
      <author><first>Tamer</first> <last>Alkhouli</last></author>
      <author><first>Gabriel</first> <last>Bretschner</last></author>
      <author><first>Jan-Thorsten</first> <last>Peter</last></author>
      <author><first>Mohammed</first> <last>Hethnawi</last></author>
      <author><first>Andreas</first> <last>Guta</last></author>
      <author><first>Hermann</first> <last>Ney</last></author>
      <pages>54–65</pages>
      <url hash="bc06e8dc">W16-2206</url>
      <doi>10.18653/v1/W16-2206</doi>
    </paper>
    <paper id="7">
      <title>Neural Network-based Word Alignment through Score Aggregation</title>
      <author><first>Joël</first> <last>Legrand</last></author>
      <author><first>Michael</first> <last>Auli</last></author>
      <author><first>Ronan</first> <last>Collobert</last></author>
      <pages>66–73</pages>
      <url hash="709a27cd">W16-2207</url>
      <doi>10.18653/v1/W16-2207</doi>
    </paper>
    <paper id="8">
      <title>Using Factored Word Representation in Neural Network Language Models</title>
      <author><first>Jan</first> <last>Niehues</last></author>
      <author><first>Thanh-Le</first> <last>Ha</last></author>
      <author><first>Eunah</first> <last>Cho</last></author>
      <author><first>Alex</first> <last>Waibel</last></author>
      <pages>74–82</pages>
      <url hash="026c1137">W16-2208</url>
      <doi>10.18653/v1/W16-2208</doi>
    </paper>
    <paper id="9">
      <title>Linguistic Input Features Improve Neural Machine Translation</title>
      <author><first>Rico</first> <last>Sennrich</last></author>
      <author><first>Barry</first> <last>Haddow</last></author>
      <pages>83–91</pages>
      <url hash="7f1c3491">W16-2209</url>
      <doi>10.18653/v1/W16-2209</doi>
    </paper>
    <paper id="10">
      <title>A Framework for Discriminative Rule Selection in Hierarchical <fixed-case>M</fixed-case>oses</title>
      <author><first>Fabienne</first> <last>Braune</last></author>
      <author><first>Alexander</first> <last>Fraser</last></author>
      <author><first>Hal</first> <last>Daumé III</last></author>
      <author><first>Aleš</first> <last>Tamchyna</last></author>
      <pages>92–101</pages>
      <url hash="8c627042">W16-2210</url>
      <doi>10.18653/v1/W16-2210</doi>
    </paper>
    <paper id="11">
      <title>Fast and highly parallelizable phrase table for statistical machine translation</title>
      <author><first>Nikolay</first> <last>Bogoychev</last></author>
      <author><first>Hieu</first> <last>Hoang</last></author>
      <pages>102–109</pages>
      <url hash="aaa8f61f">W16-2211</url>
      <doi>10.18653/v1/W16-2211</doi>
    </paper>
    <paper id="12">
      <title>A Comparative Study on Vocabulary Reduction for Phrase Table Smoothing</title>
      <author><first>Yunsu</first> <last>Kim</last></author>
      <author><first>Andreas</first> <last>Guta</last></author>
      <author><first>Joern</first> <last>Wuebker</last></author>
      <author><first>Hermann</first> <last>Ney</last></author>
      <pages>110–117</pages>
      <url hash="7dc7bcf1">W16-2212</url>
      <doi>10.18653/v1/W16-2212</doi>
    </paper>
    <paper id="13">
      <title>Examining the Relationship between Preordering and Word Order Freedom in Machine Translation</title>
      <author><first>Joachim</first> <last>Daiber</last></author>
      <author><first>Miloš</first> <last>Stanojević</last></author>
      <author><first>Wilker</first> <last>Aziz</last></author>
      <author><first>Khalil</first> <last>Sima’an</last></author>
      <pages>118–130</pages>
      <url hash="38959903">W16-2213</url>
      <doi>10.18653/v1/W16-2213</doi>
    </paper>
  </volume>
  <volume id="23">
    <meta>
      <booktitle>Proceedings of the First Conference on Machine Translation: Volume 2, Shared Task Papers</booktitle>
      <editor><first>Ondřej</first><last>Bojar</last></editor>
      <editor><first>Christian</first><last>Buck</last></editor>
      <editor><first>Rajen</first><last>Chatterjee</last></editor>
      <editor><first>Christian</first><last>Federmann</last></editor>
      <editor><first>Liane</first><last>Guillou</last></editor>
      <editor><first>Barry</first><last>Haddow</last></editor>
      <editor><first>Matthias</first><last>Huck</last></editor>
      <editor><first>Antonio Jimeno</first><last>Yepes</last></editor>
      <editor><first>Aurélie</first><last>Névéol</last></editor>
      <editor><first>Mariana</first><last>Neves</last></editor>
      <editor><first>Pavel</first><last>Pecina</last></editor>
      <editor><first>Martin</first><last>Popel</last></editor>
      <editor><first>Philipp</first><last>Koehn</last></editor>
      <editor><first>Christof</first><last>Monz</last></editor>
      <editor><first>Matteo</first><last>Negri</last></editor>
      <editor><first>Matt</first><last>Post</last></editor>
      <editor><first>Lucia</first><last>Specia</last></editor>
      <editor><first>Karin</first><last>Verspoor</last></editor>
      <editor><first>Jörg</first><last>Tiedemann</last></editor>
      <editor><first>Marco</first><last>Turchi</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <doi>10.18653/v1/W16-2300</doi>
    </frontmatter>
    <paper id="1">
      <title>Findings of the 2016 Conference on Machine Translation</title>
      <author><first>Ondřej</first> <last>Bojar</last></author>
      <author><first>Rajen</first> <last>Chatterjee</last></author>
      <author><first>Christian</first> <last>Federmann</last></author>
      <author><first>Yvette</first> <last>Graham</last></author>
      <author><first>Barry</first> <last>Haddow</last></author>
      <author><first>Matthias</first> <last>Huck</last></author>
      <author><first>Antonio</first> <last>Jimeno Yepes</last></author>
      <author><first>Philipp</first> <last>Koehn</last></author>
      <author><first>Varvara</first> <last>Logacheva</last></author>
      <author><first>Christof</first> <last>Monz</last></author>
      <author><first>Matteo</first> <last>Negri</last></author>
      <author><first>Aurélie</first> <last>Névéol</last></author>
      <author><first>Mariana</first> <last>Neves</last></author>
      <author><first>Martin</first> <last>Popel</last></author>
      <author><first>Matt</first> <last>Post</last></author>
      <author><first>Raphael</first> <last>Rubino</last></author>
      <author><first>Carolina</first> <last>Scarton</last></author>
      <author><first>Lucia</first> <last>Specia</last></author>
      <author><first>Marco</first> <last>Turchi</last></author>
      <author><first>Karin</first> <last>Verspoor</last></author>
      <author><first>Marcos</first> <last>Zampieri</last></author>
      <pages>131–198</pages>
      <url hash="05f4159e">W16-2301</url>
      <doi>10.18653/v1/W16-2301</doi>
    </paper>
    <paper id="2">
      <title>Results of the <fixed-case>WMT</fixed-case>16 Metrics Shared Task</title>
      <author><first>Ondřej</first> <last>Bojar</last></author>
      <author><first>Yvette</first> <last>Graham</last></author>
      <author><first>Amir</first> <last>Kamran</last></author>
      <author><first>Miloš</first> <last>Stanojević</last></author>
      <pages>199–231</pages>
      <url hash="b1a8befa">W16-2302</url>
      <doi>10.18653/v1/W16-2302</doi>
    </paper>
    <paper id="3">
      <title>Results of the <fixed-case>WMT</fixed-case>16 Tuning Shared Task</title>
      <author><first>Bushra</first> <last>Jawaid</last></author>
      <author><first>Amir</first> <last>Kamran</last></author>
      <author><first>Miloš</first> <last>Stanojević</last></author>
      <author><first>Ondřej</first> <last>Bojar</last></author>
      <pages>232–238</pages>
      <url hash="d37b13e8">W16-2303</url>
      <doi>10.18653/v1/W16-2303</doi>
    </paper>
    <paper id="4">
      <title><fixed-case>LIMSI</fixed-case>@<fixed-case>WMT</fixed-case>’16: Machine Translation of News</title>
      <author><first>Alexandre</first> <last>Allauzen</last></author>
      <author><first>Lauriane</first> <last>Aufrant</last></author>
      <author><first>Franck</first> <last>Burlot</last></author>
      <author><first>Ophélie</first> <last>Lacroix</last></author>
      <author><first>Elena</first> <last>Knyazeva</last></author>
      <author><first>Thomas</first> <last>Lavergne</last></author>
      <author><first>Guillaume</first> <last>Wisniewski</last></author>
      <author><first>François</first> <last>Yvon</last></author>
      <pages>239–245</pages>
      <url hash="4134921d">W16-2304</url>
      <doi>10.18653/v1/W16-2304</doi>
    </paper>
    <paper id="5">
      <title><fixed-case>TÜBİTAK</fixed-case> <fixed-case>SMT</fixed-case> System Submission for <fixed-case>WMT</fixed-case>2016</title>
      <author><first>Emre</first> <last>Bektaş</last></author>
      <author><first>Ertuğrul</first> <last>Yilmaz</last></author>
      <author><first>Coşkun</first> <last>Mermer</last></author>
      <author><first>İlknur</first> <last>Durgar El-Kahlout</last></author>
      <pages>246–251</pages>
      <url hash="b5c16eb1">W16-2305</url>
      <doi>10.18653/v1/W16-2305</doi>
    </paper>
    <paper id="6">
      <title><fixed-case>P</fixed-case>ar<fixed-case>FDA</fixed-case> for Instance Selection for Statistical Machine Translation</title>
      <author><first>Ergun</first> <last>Biçici</last></author>
      <pages>252–258</pages>
      <url hash="a780ae7a">W16-2306</url>
      <doi>10.18653/v1/W16-2306</doi>
      <revision id="1" href="W16-2306v1" hash="6b7718cb"/>
      <revision id="2" href="W16-2306v2" hash="a780ae7a">No description of the changes were recorded.</revision>
    </paper>
    <paper id="7">
      <title><fixed-case>S</fixed-case>heffield Systems for the <fixed-case>E</fixed-case>nglish-<fixed-case>R</fixed-case>omanian <fixed-case>WMT</fixed-case> Translation Task</title>
      <author><first>Frédéric</first> <last>Blain</last></author>
      <author><first>Xingyi</first> <last>Song</last></author>
      <author><first>Lucia</first> <last>Specia</last></author>
      <pages>259–263</pages>
      <url hash="fb1a10ee">W16-2307</url>
      <doi>10.18653/v1/W16-2307</doi>
    </paper>
    <paper id="8">
      <title><fixed-case>M</fixed-case>eta<fixed-case>M</fixed-case>ind Neural Machine Translation System for <fixed-case>WMT</fixed-case> 2016</title>
      <author><first>James</first> <last>Bradbury</last></author>
      <author><first>Richard</first> <last>Socher</last></author>
      <pages>264–267</pages>
      <url hash="e4111dbc">W16-2308</url>
      <doi>10.18653/v1/W16-2308</doi>
    </paper>
    <paper id="9">
      <title><fixed-case>NYU</fixed-case>-<fixed-case>MILA</fixed-case> Neural Machine Translation Systems for <fixed-case>WMT</fixed-case>’16</title>
      <author><first>Junyoung</first> <last>Chung</last></author>
      <author><first>Kyunghyun</first> <last>Cho</last></author>
      <author><first>Yoshua</first> <last>Bengio</last></author>
      <pages>268–271</pages>
      <url hash="6c92ce14">W16-2309</url>
      <doi>10.18653/v1/W16-2309</doi>
    </paper>
    <paper id="10">
      <title>The <fixed-case>JHU</fixed-case> Machine Translation Systems for <fixed-case>WMT</fixed-case> 2016</title>
      <author><first>Shuoyang</first> <last>Ding</last></author>
      <author><first>Kevin</first> <last>Duh</last></author>
      <author><first>Huda</first> <last>Khayrallah</last></author>
      <author><first>Philipp</first> <last>Koehn</last></author>
      <author><first>Matt</first> <last>Post</last></author>
      <pages>272–280</pages>
      <url hash="14a0116d">W16-2310</url>
      <doi>10.18653/v1/W16-2310</doi>
    </paper>
    <paper id="11">
      <title>Yandex School of Data Analysis approach to <fixed-case>E</fixed-case>nglish-<fixed-case>T</fixed-case>urkish translation at <fixed-case>WMT</fixed-case>16 News Translation Task</title>
      <author><first>Anton</first> <last>Dvorkovich</last></author>
      <author><first>Sergey</first> <last>Gubanov</last></author>
      <author><first>Irina</first> <last>Galinskaya</last></author>
      <pages>281–288</pages>
      <url hash="9b0a09d3">W16-2311</url>
      <doi>10.18653/v1/W16-2311</doi>
    </paper>
    <paper id="12">
      <title>Hybrid Morphological Segmentation for Phrase-Based Machine Translation</title>
      <author><first>Stig-Arne</first> <last>Grönroos</last></author>
      <author><first>Sami</first> <last>Virpioja</last></author>
      <author><first>Mikko</first> <last>Kurimo</last></author>
      <pages>289–295</pages>
      <url hash="523509ec">W16-2312</url>
      <doi>10.18653/v1/W16-2312</doi>
    </paper>
    <paper id="13">
      <title>The <fixed-case>AFRL</fixed-case>-<fixed-case>MITLL</fixed-case> <fixed-case>WMT</fixed-case>16 News-Translation Task Systems</title>
      <author><first>Jeremy</first> <last>Gwinnup</last></author>
      <author><first>Tim</first> <last>Anderson</last></author>
      <author><first>Grant</first> <last>Erdmann</last></author>
      <author><first>Katherine</first> <last>Young</last></author>
      <author><first>Michaeel</first> <last>Kazi</last></author>
      <author><first>Elizabeth</first> <last>Salesky</last></author>
      <author><first>Brian</first> <last>Thompson</last></author>
      <pages>296–302</pages>
      <url hash="102afba1">W16-2313</url>
      <doi>10.18653/v1/W16-2313</doi>
    </paper>
    <paper id="14">
      <title>The Karlsruhe Institute of Technology Systems for the News Translation Task in <fixed-case>WMT</fixed-case> 2016</title>
      <author><first>Thanh-Le</first> <last>Ha</last></author>
      <author><first>Eunah</first> <last>Cho</last></author>
      <author><first>Jan</first> <last>Niehues</last></author>
      <author><first>Mohammed</first> <last>Mediani</last></author>
      <author><first>Matthias</first> <last>Sperber</last></author>
      <author><first>Alexandre</first> <last>Allauzen</last></author>
      <author><first>Alexander</first> <last>Waibel</last></author>
      <pages>303–310</pages>
      <url hash="c3c6c57e">W16-2314</url>
      <doi>10.18653/v1/W16-2314</doi>
    </paper>
    <paper id="15">
      <title>The <fixed-case>E</fixed-case>dinburgh/<fixed-case>LMU</fixed-case> Hierarchical Machine Translation System for <fixed-case>WMT</fixed-case> 2016</title>
      <author><first>Matthias</first> <last>Huck</last></author>
      <author><first>Alexander</first> <last>Fraser</last></author>
      <author><first>Barry</first> <last>Haddow</last></author>
      <pages>311–318</pages>
      <url hash="46c67c9f">W16-2315</url>
      <doi>10.18653/v1/W16-2315</doi>
    </paper>
    <paper id="16">
      <title>The <fixed-case>AMU</fixed-case>-<fixed-case>UEDIN</fixed-case> Submission to the <fixed-case>WMT</fixed-case>16 News Translation Task: Attention-based <fixed-case>NMT</fixed-case> Models as Feature Functions in Phrase-based <fixed-case>SMT</fixed-case></title>
      <author><first>Marcin</first> <last>Junczys-Dowmunt</last></author>
      <author><first>Tomasz</first> <last>Dwojak</last></author>
      <author><first>Rico</first> <last>Sennrich</last></author>
      <pages>319–325</pages>
      <url hash="18103c7b">W16-2316</url>
      <doi>10.18653/v1/W16-2316</doi>
    </paper>
    <paper id="17">
      <title><fixed-case>NRC</fixed-case> <fixed-case>R</fixed-case>ussian-<fixed-case>E</fixed-case>nglish Machine Translation System for <fixed-case>WMT</fixed-case> 2016</title>
      <author><first>Chi-kiu</first> <last>Lo</last></author>
      <author><first>Colin</first> <last>Cherry</last></author>
      <author><first>George</first> <last>Foster</last></author>
      <author><first>Darlene</first> <last>Stewart</last></author>
      <author><first>Rabib</first> <last>Islam</last></author>
      <author><first>Anna</first> <last>Kazantseva</last></author>
      <author><first>Roland</first> <last>Kuhn</last></author>
      <pages>326–332</pages>
      <url hash="0c6db599">W16-2317</url>
      <doi>10.18653/v1/W16-2317</doi>
    </paper>
    <paper id="18">
      <title>Merged bilingual trees based on <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies in Machine Translation</title>
      <author><first>David</first> <last>Mareček</last></author>
      <pages>333–338</pages>
      <url hash="d82f1efc">W16-2318</url>
      <doi>10.18653/v1/W16-2318</doi>
    </paper>
    <paper id="19">
      <title><fixed-case>PROMT</fixed-case> Translation Systems for <fixed-case>WMT</fixed-case> 2016 Translation Tasks</title>
      <author><first>Alexander</first> <last>Molchanov</last></author>
      <author><first>Fedor</first> <last>Bykov</last></author>
      <pages>339–343</pages>
      <url hash="e7e1a5a1">W16-2319</url>
      <doi>10.18653/v1/W16-2319</doi>
    </paper>
    <paper id="20">
      <title>The <fixed-case>QT</fixed-case>21/<fixed-case>H</fixed-case>im<fixed-case>L</fixed-case> Combined Machine Translation System</title>
      <author><first>Jan-Thorsten</first> <last>Peter</last></author>
      <author><first>Tamer</first> <last>Alkhouli</last></author>
      <author><first>Hermann</first> <last>Ney</last></author>
      <author><first>Matthias</first> <last>Huck</last></author>
      <author><first>Fabienne</first> <last>Braune</last></author>
      <author><first>Alexander</first> <last>Fraser</last></author>
      <author><first>Aleš</first> <last>Tamchyna</last></author>
      <author><first>Ondřej</first> <last>Bojar</last></author>
      <author><first>Barry</first> <last>Haddow</last></author>
      <author><first>Rico</first> <last>Sennrich</last></author>
      <author><first>Frédéric</first> <last>Blain</last></author>
      <author><first>Lucia</first> <last>Specia</last></author>
      <author><first>Jan</first> <last>Niehues</last></author>
      <author><first>Alex</first> <last>Waibel</last></author>
      <author><first>Alexandre</first> <last>Allauzen</last></author>
      <author><first>Lauriane</first> <last>Aufrant</last></author>
      <author><first>Franck</first> <last>Burlot</last></author>
      <author><first>Elena</first> <last>Knyazeva</last></author>
      <author><first>Thomas</first> <last>Lavergne</last></author>
      <author><first>François</first> <last>Yvon</last></author>
      <author><first>Mārcis</first> <last>Pinnis</last></author>
      <author><first>Stella</first> <last>Frank</last></author>
      <pages>344–355</pages>
      <url hash="01402526">W16-2320</url>
      <doi>10.18653/v1/W16-2320</doi>
    </paper>
    <paper id="21">
      <title>The <fixed-case>RWTH</fixed-case> <fixed-case>A</fixed-case>achen <fixed-case>U</fixed-case>niversity <fixed-case>E</fixed-case>nglish-<fixed-case>R</fixed-case>omanian Machine Translation System for <fixed-case>WMT</fixed-case> 2016</title>
      <author><first>Jan-Thorsten</first> <last>Peter</last></author>
      <author><first>Tamer</first> <last>Alkhouli</last></author>
      <author><first>Andreas</first> <last>Guta</last></author>
      <author><first>Hermann</first> <last>Ney</last></author>
      <pages>356–361</pages>
      <url hash="6ce7c40d">W16-2321</url>
      <doi>10.18653/v1/W16-2321</doi>
    </paper>
    <paper id="22">
      <title><fixed-case>A</fixed-case>bu-<fixed-case>M</fixed-case>a<fixed-case>T</fixed-case>ran at <fixed-case>WMT</fixed-case> 2016 Translation Task: Deep Learning, Morphological Segmentation and Tuning on Character Sequences</title>
      <author><first>Víctor M.</first> <last>Sánchez-Cartagena</last></author>
      <author><first>Antonio</first> <last>Toral</last></author>
      <pages>362–370</pages>
      <url hash="c415e119">W16-2322</url>
      <doi>10.18653/v1/W16-2322</doi>
    </paper>
    <paper id="23">
      <title><fixed-case>E</fixed-case>dinburgh Neural Machine Translation Systems for <fixed-case>WMT</fixed-case> 16</title>
      <author><first>Rico</first> <last>Sennrich</last></author>
      <author><first>Barry</first> <last>Haddow</last></author>
      <author><first>Alexandra</first> <last>Birch</last></author>
      <pages>371–376</pages>
      <url hash="d70f2ecf">W16-2323</url>
      <doi>10.18653/v1/W16-2323</doi>
    </paper>
    <paper id="24">
      <title>The Edit Distance Transducer in Action: The <fixed-case>U</fixed-case>niversity of <fixed-case>C</fixed-case>ambridge <fixed-case>E</fixed-case>nglish-<fixed-case>G</fixed-case>erman System at <fixed-case>WMT</fixed-case>16</title>
      <author><first>Felix</first> <last>Stahlberg</last></author>
      <author><first>Eva</first> <last>Hasler</last></author>
      <author><first>Bill</first> <last>Byrne</last></author>
      <pages>377–384</pages>
      <url hash="ef888899">W16-2324</url>
      <doi>10.18653/v1/W16-2324</doi>
    </paper>
    <paper id="25">
      <title><fixed-case>CUNI</fixed-case>-<fixed-case>LMU</fixed-case> Submissions in <fixed-case>WMT</fixed-case>2016: Chimera Constrained and Beaten</title>
      <author><first>Aleš</first> <last>Tamchyna</last></author>
      <author><first>Roman</first> <last>Sudarikov</last></author>
      <author><first>Ondřej</first> <last>Bojar</last></author>
      <author><first>Alexander</first> <last>Fraser</last></author>
      <pages>385–390</pages>
      <url hash="c8676507">W16-2325</url>
      <doi>10.18653/v1/W16-2325</doi>
    </paper>
    <paper id="26">
      <title>Phrase-Based <fixed-case>SMT</fixed-case> for <fixed-case>F</fixed-case>innish with More Data, Better Models and Alternative Alignment and Translation Tools</title>
      <author><first>Jörg</first> <last>Tiedemann</last></author>
      <author><first>Fabienne</first> <last>Cap</last></author>
      <author><first>Jenna</first> <last>Kanerva</last></author>
      <author><first>Filip</first> <last>Ginter</last></author>
      <author><first>Sara</first> <last>Stymne</last></author>
      <author><first>Robert</first> <last>Östling</last></author>
      <author><first>Marion</first> <last>Weller-Di Marco</last></author>
      <pages>391–398</pages>
      <url hash="ddd63531">W16-2326</url>
      <doi>10.18653/v1/W16-2326</doi>
    </paper>
    <paper id="27">
      <title><fixed-case>E</fixed-case>dinburgh’s Statistical Machine Translation Systems for <fixed-case>WMT</fixed-case>16</title>
      <author><first>Philip</first> <last>Williams</last></author>
      <author><first>Rico</first> <last>Sennrich</last></author>
      <author><first>Maria</first> <last>Nădejde</last></author>
      <author><first>Matthias</first> <last>Huck</last></author>
      <author><first>Barry</first> <last>Haddow</last></author>
      <author><first>Ondřej</first> <last>Bojar</last></author>
      <pages>399–410</pages>
      <url hash="bcbbd0d3">W16-2327</url>
      <doi>10.18653/v1/W16-2327</doi>
    </paper>
    <paper id="28">
      <title><fixed-case>PJAIT</fixed-case> Systems for the <fixed-case>WMT</fixed-case> 2016</title>
      <author><first>Krzysztof</first> <last>Wolk</last></author>
      <author><first>Krzysztof</first> <last>Marasek</last></author>
      <pages>411–414</pages>
      <url hash="51cc9f35">W16-2328</url>
      <doi>10.18653/v1/W16-2328</doi>
    </paper>
    <paper id="29">
      <title><fixed-case>DFKI</fixed-case>’s system for <fixed-case>WMT</fixed-case>16 <fixed-case>IT</fixed-case>-domain task, including analysis of systematic errors</title>
      <author><first>Eleftherios</first> <last>Avramidis</last></author>
      <author><first>Aljoscha</first> <last>Burchardt</last></author>
      <author><first>Vivien</first> <last>Macketanz</last></author>
      <author><first>Ankit</first> <last>Srivastava</last></author>
      <pages>415–422</pages>
      <url hash="cc43eb34">W16-2329</url>
      <doi>10.18653/v1/W16-2329</doi>
    </paper>
    <paper id="30">
      <title><fixed-case>ILLC</fixed-case>-<fixed-case>U</fixed-case>v<fixed-case>A</fixed-case> Adaptation System (Scorpio) at <fixed-case>WMT</fixed-case>’16 <fixed-case>IT</fixed-case>-<fixed-case>DOMAIN</fixed-case> Task</title>
      <author><first>Hoang</first> <last>Cuong</last></author>
      <author><first>Stella</first> <last>Frank</last></author>
      <author><first>Khalil</first> <last>Sima’an</last></author>
      <pages>423–427</pages>
      <url hash="29e90868">W16-2330</url>
      <doi>10.18653/v1/W16-2330</doi>
    </paper>
    <paper id="31">
      <title>Data Selection for <fixed-case>IT</fixed-case> Texts using Paragraph Vector</title>
      <author><first>Mirela-Stefania</first> <last>Duma</last></author>
      <author><first>Wolfgang</first> <last>Menzel</last></author>
      <pages>428–434</pages>
      <url hash="5765a27b">W16-2331</url>
      <doi>10.18653/v1/W16-2331</doi>
    </paper>
    <paper id="32">
      <title><fixed-case>SMT</fixed-case> and Hybrid systems of the <fixed-case>QTL</fixed-case>eap project in the <fixed-case>WMT</fixed-case>16 <fixed-case>IT</fixed-case>-task</title>
      <author><first>Rosa</first> <last>Gaudio</last></author>
      <author><first>Gorka</first> <last>Labaka</last></author>
      <author><first>Eneko</first> <last>Agirre</last></author>
      <author><first>Petya</first> <last>Osenova</last></author>
      <author><first>Kiril</first> <last>Simov</last></author>
      <author><first>Martin</first> <last>Popel</last></author>
      <author><first>Dieke</first> <last>Oele</last></author>
      <author><first>Gertjan</first> <last>van Noord</last></author>
      <author><first>Luís</first> <last>Gomes</last></author>
      <author><first>João</first> <last>António Rodrigues</last></author>
      <author><first>Steven</first> <last>Neale</last></author>
      <author><first>João</first> <last>Silva</last></author>
      <author><first>Andreia</first> <last>Querido</last></author>
      <author><first>Nuno</first> <last>Rendeiro</last></author>
      <author><first>António</first> <last>Branco</last></author>
      <pages>435–441</pages>
      <url hash="c9289d8a">W16-2332</url>
      <doi>10.18653/v1/W16-2332</doi>
    </paper>
    <paper id="33">
      <title><fixed-case>JU-USAAR</fixed-case>: A Domain Adaptive <fixed-case>MT</fixed-case> System</title>
      <author><first>Koushik</first> <last>Pahari</last></author>
      <author><first>Alapan</first> <last>Kuila</last></author>
      <author><first>Santanu</first> <last>Pal</last></author>
      <author><first>Sudip Kumar</first> <last>Naskar</last></author>
      <author><first>Sivaji</first> <last>Bandyopadhyay</last></author>
      <author><first>Josef</first> <last>van Genabith</last></author>
      <pages>442–448</pages>
      <url hash="464deeb7">W16-2333</url>
      <doi>10.18653/v1/W16-2333</doi>
    </paper>
    <paper id="34">
      <title>Dictionary-based Domain Adaptation of <fixed-case>MT</fixed-case> Systems without Retraining</title>
      <author><first>Rudolf</first> <last>Rosa</last></author>
      <author><first>Roman</first> <last>Sudarikov</last></author>
      <author><first>Michal</first> <last>Novák</last></author>
      <author><first>Martin</first> <last>Popel</last></author>
      <author><first>Ondřej</first> <last>Bojar</last></author>
      <pages>449–455</pages>
      <url hash="3edb30d8">W16-2334</url>
      <doi>10.18653/v1/W16-2334</doi>
    </paper>
    <paper id="35">
      <title><fixed-case>E</fixed-case>nglish-<fixed-case>P</fixed-case>ortuguese Biomedical Translation Task Using a Genuine Phrase-Based Statistical Machine Translation Approach</title>
      <author><first>José</first> <last>Aires</last></author>
      <author><first>Gabriel</first> <last>Lopes</last></author>
      <author><first>Luís</first> <last>Gomes</last></author>
      <pages>456–462</pages>
      <url hash="dd56352f">W16-2335</url>
      <doi>10.18653/v1/W16-2335</doi>
    </paper>
    <paper id="36">
      <title>The <fixed-case>TALP</fixed-case>–<fixed-case>UPC</fixed-case> <fixed-case>S</fixed-case>panish–<fixed-case>E</fixed-case>nglish <fixed-case>WMT</fixed-case> Biomedical Task: Bilingual Embeddings and Char-based Neural Language Model Rescoring in a Phrase-based System</title>
      <author><first>Marta R.</first> <last>Costa-jussà</last></author>
      <author><first>Cristina</first> <last>España-Bonet</last></author>
      <author><first>Pranava</first> <last>Madhyastha</last></author>
      <author><first>Carlos</first> <last>Escolano</last></author>
      <author><first>José A. R.</first> <last>Fonollosa</last></author>
      <pages>463–468</pages>
      <url hash="804ca6e2">W16-2336</url>
      <doi>10.18653/v1/W16-2336</doi>
    </paper>
    <paper id="37">
      <title><fixed-case>LIMSI</fixed-case>’s Contribution to the <fixed-case>WMT</fixed-case>’16 Biomedical Translation Task</title>
      <author><first>Julia</first> <last>Ive</last></author>
      <author><first>Aurélien</first> <last>Max</last></author>
      <author><first>François</first> <last>Yvon</last></author>
      <pages>469–476</pages>
      <url hash="370ace60">W16-2337</url>
      <doi>10.18653/v1/W16-2337</doi>
    </paper>
    <paper id="38">
      <title><fixed-case>IXA</fixed-case> Biomedical Translation System at <fixed-case>WMT</fixed-case>16 Biomedical Translation Task</title>
      <author><first>Olatz</first> <last>Perez-de-Viñaspre</last></author>
      <author><first>Gorka</first> <last>Labaka</last></author>
      <pages>477–482</pages>
      <url hash="4699e644">W16-2338</url>
      <doi>10.18653/v1/W16-2338</doi>
    </paper>
    <paper id="39">
      <title><fixed-case>C</fixed-case>obalt<fixed-case>F</fixed-case>: A Fluent Metric for <fixed-case>MT</fixed-case> Evaluation</title>
      <author><first>Marina</first> <last>Fomicheva</last></author>
      <author><first>Núria</first> <last>Bel</last></author>
      <author><first>Lucia</first> <last>Specia</last></author>
      <author><first>Iria</first> <last>da Cunha</last></author>
      <author><first>Anton</first> <last>Malinovskiy</last></author>
      <pages>483–490</pages>
      <url hash="e7d47af8">W16-2339</url>
      <doi>10.18653/v1/W16-2339</doi>
    </paper>
    <paper id="40">
      <title><fixed-case>DTED</fixed-case>: Evaluation of Machine Translation Structure Using Dependency Parsing and Tree Edit Distance</title>
      <author><first>Martin</first> <last>McCaffery</last></author>
      <author><first>Mark-Jan</first> <last>Nederhof</last></author>
      <pages>491–498</pages>
      <url hash="6a509409">W16-2340</url>
      <doi>10.18653/v1/W16-2340</doi>
    </paper>
    <paper id="41">
      <title>chr<fixed-case>F</fixed-case> deconstructed: beta parameters and n-gram weights</title>
      <author><first>Maja</first> <last>Popović</last></author>
      <pages>499–504</pages>
      <url hash="9527a9c4">W16-2341</url>
      <doi>10.18653/v1/W16-2341</doi>
    </paper>
    <paper id="42">
      <title><fixed-case>C</fixed-case>harac<fixed-case>T</fixed-case>er: Translation Edit Rate on Character Level</title>
      <author><first>Weiyue</first> <last>Wang</last></author>
      <author><first>Jan-Thorsten</first> <last>Peter</last></author>
      <author><first>Hendrik</first> <last>Rosendahl</last></author>
      <author><first>Hermann</first> <last>Ney</last></author>
      <pages>505–510</pages>
      <url hash="cb1563c4">W16-2342</url>
      <doi>10.18653/v1/W16-2342</doi>
    </paper>
    <paper id="43">
      <title>Extract Domain-specific Paraphrase from Monolingual Corpus for Automatic Evaluation of Machine Translation</title>
      <author><first>Lilin</first> <last>Zhang</last></author>
      <author><first>Zhen</first> <last>Weng</last></author>
      <author><first>Wenyan</first> <last>Xiao</last></author>
      <author><first>Jianyi</first> <last>Wan</last></author>
      <author><first>Zhiming</first> <last>Chen</last></author>
      <author><first>Yiming</first> <last>Tan</last></author>
      <author><first>Maoxi</first> <last>Li</last></author>
      <author><first>Mingwen</first> <last>Wang</last></author>
      <pages>511–517</pages>
      <url hash="9f75b4e7">W16-2343</url>
      <doi>10.18653/v1/W16-2343</doi>
    </paper>
    <paper id="44">
      <title>Particle Swarm Optimization Submission for <fixed-case>WMT</fixed-case>16 Tuning Task</title>
      <author><first>Viktor</first> <last>Kocur</last></author>
      <author><first>Ondřej</first> <last>Bojar</last></author>
      <pages>518–524</pages>
      <url hash="ff532308">W16-2344</url>
      <doi>10.18653/v1/W16-2344</doi>
    </paper>
    <paper id="45">
      <title>Findings of the 2016 <fixed-case>WMT</fixed-case> Shared Task on Cross-lingual Pronoun Prediction</title>
      <author><first>Liane</first> <last>Guillou</last></author>
      <author><first>Christian</first> <last>Hardmeier</last></author>
      <author><first>Preslav</first> <last>Nakov</last></author>
      <author><first>Sara</first> <last>Stymne</last></author>
      <author><first>Jörg</first> <last>Tiedemann</last></author>
      <author><first>Yannick</first> <last>Versley</last></author>
      <author><first>Mauro</first> <last>Cettolo</last></author>
      <author><first>Bonnie</first> <last>Webber</last></author>
      <author><first>Andrei</first> <last>Popescu-Belis</last></author>
      <pages>525–542</pages>
      <url hash="a2e6e680">W16-2345</url>
      <doi>10.18653/v1/W16-2345</doi>
    </paper>
    <paper id="46">
      <title>A Shared Task on Multimodal Machine Translation and Crosslingual Image Description</title>
      <author><first>Lucia</first> <last>Specia</last></author>
      <author><first>Stella</first> <last>Frank</last></author>
      <author><first>Khalil</first> <last>Sima’an</last></author>
      <author><first>Desmond</first> <last>Elliott</last></author>
      <pages>543–553</pages>
      <url hash="32e923e2">W16-2346</url>
      <doi>10.18653/v1/W16-2346</doi>
    </paper>
    <paper id="47">
      <title>Findings of the <fixed-case>WMT</fixed-case> 2016 Bilingual Document Alignment Shared Task</title>
      <author><first>Christian</first> <last>Buck</last></author>
      <author><first>Philipp</first> <last>Koehn</last></author>
      <pages>554–563</pages>
      <url hash="643eff18">W16-2347</url>
      <doi>10.18653/v1/W16-2347</doi>
    </paper>
    <paper id="48">
      <title>Cross-lingual Pronoun Prediction with Linguistically Informed Features</title>
      <author><first>Rachel</first> <last>Bawden</last></author>
      <pages>564–570</pages>
      <url hash="5f52ad46">W16-2348</url>
      <doi>10.18653/v1/W16-2348</doi>
    </paper>
    <paper id="49">
      <title>The <fixed-case>K</fixed-case>yoto <fixed-case>U</fixed-case>niversity Cross-Lingual Pronoun Translation System</title>
      <author><first>Raj</first> <last>Dabre</last></author>
      <author><first>Yevgeniy</first> <last>Puzikov</last></author>
      <author><first>Fabien</first> <last>Cromieres</last></author>
      <author><first>Sadao</first> <last>Kurohashi</last></author>
      <pages>571–575</pages>
      <url hash="951e9661">W16-2349</url>
      <doi>10.18653/v1/W16-2349</doi>
    </paper>
    <paper id="50">
      <title>Pronoun Prediction with Latent Anaphora Resolution</title>
      <author><first>Christian</first> <last>Hardmeier</last></author>
      <pages>576–580</pages>
      <url hash="b27aac11">W16-2350</url>
      <doi>10.18653/v1/W16-2350</doi>
    </paper>
    <paper id="51">
      <title>It-disambiguation and source-aware language models for cross-lingual pronoun prediction</title>
      <author><first>Sharid</first> <last>Loáiciga</last></author>
      <author><first>Liane</first> <last>Guillou</last></author>
      <author><first>Christian</first> <last>Hardmeier</last></author>
      <pages>581–588</pages>
      <url hash="d347621b">W16-2351</url>
      <doi>10.18653/v1/W16-2351</doi>
    </paper>
    <paper id="52">
      <title>Pronoun Language Model and Grammatical Heuristics for Aiding Pronoun Prediction</title>
      <author><first>Ngoc Quang</first> <last>Luong</last></author>
      <author><first>Andrei</first> <last>Popescu-Belis</last></author>
      <pages>589–595</pages>
      <url hash="ee11b73d">W16-2352</url>
      <doi>10.18653/v1/W16-2352</doi>
    </paper>
    <paper id="53">
      <title>Cross-Lingual Pronoun Prediction with Deep Recurrent Neural Networks</title>
      <author><first>Juhani</first> <last>Luotolahti</last></author>
      <author><first>Jenna</first> <last>Kanerva</last></author>
      <author><first>Filip</first> <last>Ginter</last></author>
      <pages>596–601</pages>
      <url hash="fd7b12d2">W16-2353</url>
      <doi>10.18653/v1/W16-2353</doi>
    </paper>
    <paper id="54">
      <title>Pronoun Prediction with Linguistic Features and Example Weighing</title>
      <author><first>Michal</first> <last>Novák</last></author>
      <pages>602–608</pages>
      <url hash="e6cd5de6">W16-2354</url>
      <doi>10.18653/v1/W16-2354</doi>
    </paper>
    <paper id="55">
      <title>Feature Exploration for Cross-Lingual Pronoun Prediction</title>
      <author><first>Sara</first> <last>Stymne</last></author>
      <pages>609–615</pages>
      <url hash="9cec52a5">W16-2355</url>
      <doi>10.18653/v1/W16-2355</doi>
    </paper>
    <paper id="56">
      <title>A Linear Baseline Classifier for Cross-Lingual Pronoun Prediction</title>
      <author><first>Jörg</first> <last>Tiedemann</last></author>
      <pages>616–619</pages>
      <url hash="87cbf746">W16-2356</url>
      <doi>10.18653/v1/W16-2356</doi>
    </paper>
    <paper id="57">
      <title>Cross-lingual Pronoun Prediction for <fixed-case>E</fixed-case>nglish, <fixed-case>F</fixed-case>rench and <fixed-case>G</fixed-case>erman with Maximum Entropy Classification</title>
      <author><first>Dominikus</first> <last>Wetzel</last></author>
      <pages>620–626</pages>
      <url hash="c6b6eb9b">W16-2357</url>
      <doi>10.18653/v1/W16-2357</doi>
    </paper>
    <paper id="58">
      <title>Does Multimodality Help Human and Machine for Translation and Image Captioning?</title>
      <author><first>Ozan</first> <last>Caglayan</last></author>
      <author><first>Walid</first> <last>Aransa</last></author>
      <author><first>Yaxing</first> <last>Wang</last></author>
      <author><first>Marc</first> <last>Masana</last></author>
      <author><first>Mercedes</first> <last>García-Martínez</last></author>
      <author><first>Fethi</first> <last>Bougares</last></author>
      <author><first>Loïc</first> <last>Barrault</last></author>
      <author><first>Joost</first> <last>van de Weijer</last></author>
      <pages>627–633</pages>
      <url hash="6e985082">W16-2358</url>
      <doi>10.18653/v1/W16-2358</doi>
    </paper>
    <paper id="59">
      <title><fixed-case>DCU</fixed-case>-<fixed-case>U</fixed-case>v<fixed-case>A</fixed-case> Multimodal <fixed-case>MT</fixed-case> System Report</title>
      <author><first>Iacer</first> <last>Calixto</last></author>
      <author><first>Desmond</first> <last>Elliott</last></author>
      <author><first>Stella</first> <last>Frank</last></author>
      <pages>634–638</pages>
      <url hash="b5b9ea84">W16-2359</url>
      <doi>10.18653/v1/W16-2359</doi>
    </paper>
    <paper id="60">
      <title>Attention-based Multimodal Neural Machine Translation</title>
      <author><first>Po-Yao</first> <last>Huang</last></author>
      <author><first>Frederick</first> <last>Liu</last></author>
      <author><first>Sz-Rung</first> <last>Shiang</last></author>
      <author><first>Jean</first> <last>Oh</last></author>
      <author><first>Chris</first> <last>Dyer</last></author>
      <pages>639–645</pages>
      <url hash="057d7722">W16-2360</url>
      <doi>10.18653/v1/W16-2360</doi>
    </paper>
    <paper id="61">
      <title><fixed-case>CUNI</fixed-case> System for <fixed-case>WMT</fixed-case>16 Automatic Post-Editing and Multimodal Translation Tasks</title>
      <author><first>Jindřich</first> <last>Libovický</last></author>
      <author><first>Jindřich</first> <last>Helcl</last></author>
      <author><first>Marek</first> <last>Tlustý</last></author>
      <author><first>Ondřej</first> <last>Bojar</last></author>
      <author><first>Pavel</first> <last>Pecina</last></author>
      <pages>646–654</pages>
      <url hash="da848c43">W16-2361</url>
      <doi>10.18653/v1/W16-2361</doi>
    </paper>
    <paper id="62">
      <title><fixed-case>WMT</fixed-case> 2016 Multimodal Translation System Description based on Bidirectional Recurrent Neural Networks with Double-Embeddings</title>
      <author><first>Sergio</first> <last>Rodríguez Guasch</last></author>
      <author><first>Marta R.</first> <last>Costa-jussà</last></author>
      <pages>655–659</pages>
      <url hash="1f1722cd">W16-2362</url>
      <doi>10.18653/v1/W16-2362</doi>
    </paper>
    <paper id="63">
      <title><fixed-case>SHEF</fixed-case>-Multimodal: Grounding Machine Translation on Images</title>
      <author><first>Kashif</first> <last>Shah</last></author>
      <author><first>Josiah</first> <last>Wang</last></author>
      <author><first>Lucia</first> <last>Specia</last></author>
      <pages>660–665</pages>
      <url hash="4d7b922d">W16-2363</url>
      <doi>10.18653/v1/W16-2363</doi>
    </paper>
    <paper id="64">
      <title><fixed-case>DOCAL</fixed-case> - Vicomtech’s Participation in the <fixed-case>WMT</fixed-case>16 Shared Task on Bilingual Document Alignment</title>
      <author><first>Andoni</first> <last>Azpeitia</last></author>
      <author><first>Thierry</first> <last>Etchegoyhen</last></author>
      <pages>666–671</pages>
      <url hash="8a437172">W16-2364</url>
      <doi>10.18653/v1/W16-2364</doi>
    </paper>
    <paper id="65">
      <title>Quick and Reliable Document Alignment via <fixed-case>TF</fixed-case>/<fixed-case>IDF</fixed-case>-weighted Cosine Distance</title>
      <author><first>Christian</first> <last>Buck</last></author>
      <author><first>Philipp</first> <last>Koehn</last></author>
      <pages>672–678</pages>
      <url hash="6b8dba41">W16-2365</url>
      <doi>10.18653/v1/W16-2365</doi>
    </paper>
    <paper id="66">
      <title><fixed-case>YODA</fixed-case> System for <fixed-case>WMT</fixed-case>16 Shared Task: Bilingual Document Alignment</title>
      <author><first>Aswarth Abhilash</first> <last>Dara</last></author>
      <author><first>Yiu-Chang</first> <last>Lin</last></author>
      <pages>679–684</pages>
      <url hash="65dfeb43">W16-2366</url>
      <doi>10.18653/v1/W16-2366</doi>
    </paper>
    <paper id="67">
      <title>Bitextor’s participation in <fixed-case>WMT</fixed-case>’16: shared task on document alignment</title>
      <author><first>Miquel</first> <last>Esplà-Gomis</last></author>
      <author><first>Mikel</first> <last>Forcada</last></author>
      <author><first>Sergio</first> <last>Ortiz-Rojas</last></author>
      <author><first>Jorge</first> <last>Ferrández-Tordera</last></author>
      <pages>685–691</pages>
      <url hash="921d12a3">W16-2367</url>
      <doi>10.18653/v1/W16-2367</doi>
    </paper>
    <paper id="68">
      <title>Bilingual Document Alignment with Latent Semantic Indexing</title>
      <author><first>Ulrich</first> <last>Germann</last></author>
      <pages>692–696</pages>
      <url hash="781cac52">W16-2368</url>
      <doi>10.18653/v1/W16-2368</doi>
    </paper>
    <paper id="69">
      <title>First Steps Towards Coverage-Based Document Alignment</title>
      <author><first>Luís</first> <last>Gomes</last></author>
      <author><first>Gabriel</first> <last>Pereira Lopes</last></author>
      <pages>697–702</pages>
      <url hash="1c37937e">W16-2369</url>
      <doi>10.18653/v1/W16-2369</doi>
    </paper>
    <paper id="70">
      <title><fixed-case>BAD</fixed-case> <fixed-case>LUC</fixed-case>@<fixed-case>WMT</fixed-case> 2016: a Bilingual Document Alignment Platform Based on Lucene</title>
      <author><first>Laurent</first> <last>Jakubina</last></author>
      <author><first>Phillippe</first> <last>Langlais</last></author>
      <pages>703–709</pages>
      <url hash="5345b92d">W16-2370</url>
      <doi>10.18653/v1/W16-2370</doi>
    </paper>
    <paper id="71">
      <title>Using Term Position Similarity and Language Modeling for Bilingual Document Alignment</title>
      <author><first>Thanh C.</first> <last>Le</last></author>
      <author><first>Hoa Trong</first> <last>Vu</last></author>
      <author><first>Jonathan</first> <last>Oberländer</last></author>
      <author><first>Ondřej</first> <last>Bojar</last></author>
      <pages>710–716</pages>
      <url hash="0963b148">W16-2371</url>
      <doi>10.18653/v1/W16-2371</doi>
    </paper>
    <paper id="72">
      <title>The <fixed-case>ADAPT</fixed-case> Bilingual Document Alignment system at <fixed-case>WMT</fixed-case>16</title>
      <author><first>Pintu</first> <last>Lohar</last></author>
      <author><first>Haithem</first> <last>Afli</last></author>
      <author><first>Chao-Hong</first> <last>Liu</last></author>
      <author><first>Andy</first> <last>Way</last></author>
      <pages>717–723</pages>
      <url hash="abe8fc9c">W16-2372</url>
      <doi>10.18653/v1/W16-2372</doi>
    </paper>
    <paper id="73">
      <title><fixed-case>WMT</fixed-case>2016: A Hybrid Approach to Bilingual Document Alignment</title>
      <author><first>Sainik</first> <last>Mahata</last></author>
      <author><first>Dipankar</first> <last>Das</last></author>
      <author><first>Santanu</first> <last>Pal</last></author>
      <pages>724–727</pages>
      <url hash="316d756c">W16-2373</url>
      <doi>10.18653/v1/W16-2373</doi>
    </paper>
    <paper id="74">
      <title><fixed-case>E</fixed-case>nglish-<fixed-case>F</fixed-case>rench Document Alignment Based on Keywords and Statistical Translation</title>
      <author><first>Marek</first> <last>Medveď</last></author>
      <author><first>Miloš</first> <last>Jakubíček</last></author>
      <author><first>Vojtech</first> <last>Kovář</last></author>
      <pages>728–732</pages>
      <url hash="5d7d3a87">W16-2374</url>
      <doi>10.18653/v1/W16-2374</doi>
    </paper>
    <paper id="75">
      <title>The <fixed-case>ILSP</fixed-case>/<fixed-case>ARC</fixed-case> submission to the <fixed-case>WMT</fixed-case> 2016 Bilingual Document Alignment Shared Task</title>
      <author><first>Vassilis</first> <last>Papavassiliou</last></author>
      <author><first>Prokopis</first> <last>Prokopidis</last></author>
      <author><first>Stelios</first> <last>Piperidis</last></author>
      <pages>733–739</pages>
      <url hash="a1a0d7eb">W16-2375</url>
      <doi>10.18653/v1/W16-2375</doi>
    </paper>
    <paper id="76">
      <title>Word Clustering Approach to Bilingual Document Alignment (<fixed-case>WMT</fixed-case> 2016 Shared Task)</title>
      <author><first>Vadim</first> <last>Shchukin</last></author>
      <author><first>Dmitry</first> <last>Khristich</last></author>
      <author><first>Irina</first> <last>Galinskaya</last></author>
      <pages>740–744</pages>
      <url hash="1a912d70">W16-2376</url>
      <doi>10.18653/v1/W16-2376</doi>
    </paper>
    <paper id="77">
      <title>The <fixed-case>FBK</fixed-case> Participation in the <fixed-case>WMT</fixed-case> 2016 Automatic Post-editing Shared Task</title>
      <author><first>Rajen</first> <last>Chatterjee</last></author>
      <author><first>José G.</first> <last>C. de Souza</last></author>
      <author><first>Matteo</first> <last>Negri</last></author>
      <author><first>Marco</first> <last>Turchi</last></author>
      <pages>745–750</pages>
      <url hash="f10ed0eb">W16-2377</url>
      <doi>10.18653/v1/W16-2377</doi>
    </paper>
    <paper id="78">
      <title>Log-linear Combinations of Monolingual and Bilingual Neural Machine Translation Models for Automatic Post-Editing</title>
      <author><first>Marcin</first> <last>Junczys-Dowmunt</last></author>
      <author><first>Roman</first> <last>Grundkiewicz</last></author>
      <pages>751–758</pages>
      <url hash="0e322ab5">W16-2378</url>
      <doi>10.18653/v1/W16-2378</doi>
    </paper>
    <paper id="79">
      <title><fixed-case>USAAR</fixed-case>: An Operation Sequential Model for Automatic Statistical Post-Editing</title>
      <author><first>Santanu</first> <last>Pal</last></author>
      <author><first>Marcos</first> <last>Zampieri</last></author>
      <author><first>Josef</first> <last>van Genabith</last></author>
      <pages>759–763</pages>
      <url hash="1b172b97">W16-2379</url>
      <doi>10.18653/v1/W16-2379</doi>
    </paper>
    <paper id="80">
      <title>Bilingual Embeddings and Word Alignments for Translation Quality Estimation</title>
      <author><first>Amal</first> <last>Abdelsalam</last></author>
      <author><first>Ondřej</first> <last>Bojar</last></author>
      <author><first>Samhaa</first> <last>El-Beltagy</last></author>
      <pages>764–771</pages>
      <url hash="ff635db3">W16-2380</url>
      <doi>10.18653/v1/W16-2380</doi>
    </paper>
    <paper id="81">
      <title><fixed-case>SHEF</fixed-case>-<fixed-case>MIME</fixed-case>: Word-level Quality Estimation Using Imitation Learning</title>
      <author><first>Daniel</first> <last>Beck</last></author>
      <author><first>Andreas</first> <last>Vlachos</last></author>
      <author><first>Gustavo</first> <last>Paetzold</last></author>
      <author><first>Lucia</first> <last>Specia</last></author>
      <pages>772–776</pages>
      <url hash="c1aab797">W16-2381</url>
      <doi>10.18653/v1/W16-2381</doi>
    </paper>
    <paper id="82">
      <title>Referential Translation Machines for Predicting Translation Performance</title>
      <author><first>Ergun</first> <last>Biçici</last></author>
      <pages>777–781</pages>
      <url hash="14dc0235">W16-2382</url>
      <doi>10.18653/v1/W16-2382</doi>
    </paper>
    <paper id="83">
      <title><fixed-case>UA</fixed-case>lacant word-level and phrase-level machine translation quality estimation systems at <fixed-case>WMT</fixed-case> 2016</title>
      <author><first>Miquel</first> <last>Esplà-Gomis</last></author>
      <author><first>Felipe</first> <last>Sánchez-Martínez</last></author>
      <author><first>Mikel</first> <last>Forcada</last></author>
      <pages>782–786</pages>
      <url hash="c3ddfda0">W16-2383</url>
      <doi>10.18653/v1/W16-2383</doi>
    </paper>
    <paper id="84">
      <title>Recurrent Neural Network based Translation Quality Estimation</title>
      <author><first>Hyun</first> <last>Kim</last></author>
      <author><first>Jong-Hyeok</first> <last>Lee</last></author>
      <pages>787–792</pages>
      <url hash="fd0645ff">W16-2384</url>
      <doi>10.18653/v1/W16-2384</doi>
    </paper>
    <paper id="85">
      <title><fixed-case>YSDA</fixed-case> Participation in the <fixed-case>WMT</fixed-case>’16 Quality Estimation Shared Task</title>
      <author><first>Anna</first> <last>Kozlova</last></author>
      <author><first>Mariya</first> <last>Shmatova</last></author>
      <author><first>Anton</first> <last>Frolov</last></author>
      <pages>793–799</pages>
      <url hash="7d0724f1">W16-2385</url>
      <doi>10.18653/v1/W16-2385</doi>
    </paper>
    <paper id="86">
      <title><fixed-case>USFD</fixed-case>’s Phrase-level Quality Estimation Systems</title>
      <author><first>Varvara</first> <last>Logacheva</last></author>
      <author><first>Frédéric</first> <last>Blain</last></author>
      <author><first>Lucia</first> <last>Specia</last></author>
      <pages>800–805</pages>
      <url hash="49fece9a">W16-2386</url>
      <doi>10.18653/v1/W16-2386</doi>
    </paper>
    <paper id="87">
      <title>Unbabel’s Participation in the <fixed-case>WMT</fixed-case>16 Word-Level Translation Quality Estimation Shared Task</title>
      <author><first>André F. T.</first> <last>Martins</last></author>
      <author><first>Ramón</first> <last>Astudillo</last></author>
      <author><first>Chris</first> <last>Hokamp</last></author>
      <author><first>Fabio</first> <last>Kepler</last></author>
      <pages>806–811</pages>
      <url hash="372cd4a7">W16-2387</url>
      <doi>10.18653/v1/W16-2387</doi>
    </paper>
    <paper id="88">
      <title><fixed-case>S</fixed-case>imple<fixed-case>N</fixed-case>ets: Quality Estimation with Resource-Light Neural Networks</title>
      <author><first>Gustavo</first> <last>Paetzold</last></author>
      <author><first>Lucia</first> <last>Specia</last></author>
      <pages>812–818</pages>
      <url hash="fa7a860e">W16-2388</url>
      <doi>10.18653/v1/W16-2388</doi>
    </paper>
    <paper id="89">
      <title>Translation Quality Estimation using Recurrent Neural Network</title>
      <author><first>Raj Nath</first> <last>Patel</last></author>
      <author><first>Sasikumar</first> <last>M</last></author>
      <pages>819–824</pages>
      <url hash="1f8162a4">W16-2389</url>
      <doi>10.18653/v1/W16-2389</doi>
    </paper>
    <paper id="90">
      <title>The <fixed-case>UU</fixed-case> Submission to the Machine Translation Quality Estimation Task</title>
      <author><first>Oscar</first> <last>Sagemo</last></author>
      <author><first>Sara</first> <last>Stymne</last></author>
      <pages>825–830</pages>
      <url hash="62c99b33">W16-2390</url>
      <doi>10.18653/v1/W16-2390</doi>
    </paper>
    <paper id="91">
      <title>Word embeddings and discourse information for Quality Estimation</title>
      <author><first>Carolina</first> <last>Scarton</last></author>
      <author><first>Daniel</first> <last>Beck</last></author>
      <author><first>Kashif</first> <last>Shah</last></author>
      <author><first>Karin</first> <last>Sim Smith</last></author>
      <author><first>Lucia</first> <last>Specia</last></author>
      <pages>831–837</pages>
      <url hash="6cf9d1a5">W16-2391</url>
      <doi>10.18653/v1/W16-2391</doi>
    </paper>
    <paper id="92">
      <title><fixed-case>SHEF</fixed-case>-<fixed-case>LIUM</fixed-case>-<fixed-case>NN</fixed-case>: Sentence level Quality Estimation with Neural Network Features</title>
      <author><first>Kashif</first> <last>Shah</last></author>
      <author><first>Fethi</first> <last>Bougares</last></author>
      <author><first>Loïc</first> <last>Barrault</last></author>
      <author><first>Lucia</first> <last>Specia</last></author>
      <pages>838–842</pages>
      <url hash="ba89d3c0">W16-2392</url>
      <doi>10.18653/v1/W16-2392</doi>
    </paper>
    <paper id="93">
      <title><fixed-case>UGENT</fixed-case>-<fixed-case>LT</fixed-case>3 <fixed-case>SCATE</fixed-case> Submission for <fixed-case>WMT</fixed-case>16 Shared Task on Quality Estimation</title>
      <author><first>Arda</first> <last>Tezcan</last></author>
      <author><first>Véronique</first> <last>Hoste</last></author>
      <author><first>Lieve</first> <last>Macken</last></author>
      <pages>843–850</pages>
      <url hash="2e962b80">W16-2393</url>
      <doi>10.18653/v1/W16-2393</doi>
    </paper>
  </volume>
  <volume id="24">
    <meta>
      <booktitle>Proceedings of the <fixed-case>SIGFSM</fixed-case> Workshop on Statistical <fixed-case>NLP</fixed-case> and Weighted Automata</booktitle>
      <url hash="610bf0b7">W16-24</url>
      <editor><first>Bryan</first><last>Jurish</last></editor>
      <editor><first>Andreas</first><last>Maletti</last></editor>
      <editor><first>Kay-Michael</first><last>Würzner</last></editor>
      <editor><first>Uwe</first><last>Springmann</last></editor>
      <doi>10.18653/v1/W16-24</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="bf60daf6">W16-2400</url>
    </frontmatter>
    <paper id="1">
      <title>Equivalences between Ranked and Unranked Weighted Tree Automata via Binarization</title>
      <author><first>Toni</first> <last>Dietze</last></author>
      <pages>1–10</pages>
      <url hash="56a32bfd">W16-2401</url>
      <doi>10.18653/v1/W16-2401</doi>
    </paper>
    <paper id="2">
      <title>Adaptive Importance Sampling from Finite State Automata</title>
      <author><first>Christoph</first> <last>Teichmann</last></author>
      <author><first>Kasimir</first> <last>Wansing</last></author>
      <author><first>Alexander</first> <last>Koller</last></author>
      <pages>11–20</pages>
      <url hash="d8379f9d">W16-2402</url>
      <doi>10.18653/v1/W16-2402</doi>
    </paper>
    <paper id="3">
      <title>Transition-based dependency parsing as latent-variable constituent parsing</title>
      <author><first>Mark-Jan</first> <last>Nederhof</last></author>
      <pages>21–31</pages>
      <url hash="1e13946e">W16-2403</url>
      <doi>10.18653/v1/W16-2403</doi>
    </paper>
    <paper id="4">
      <title>Distributed representation and estimation of <fixed-case>WFST</fixed-case>-based n-gram models</title>
      <author><first>Cyril</first> <last>Allauzen</last></author>
      <author><first>Michael</first> <last>Riley</last></author>
      <author><first>Brian</first> <last>Roark</last></author>
      <pages>32–41</pages>
      <url hash="2b015162">W16-2404</url>
      <doi>10.18653/v1/W16-2404</doi>
    </paper>
    <paper id="5">
      <title>Learning Transducer Models for Morphological Analysis from Example Inflections</title>
      <author><first>Markus</first> <last>Forsberg</last></author>
      <author><first>Mans</first> <last>Hulden</last></author>
      <pages>42–50</pages>
      <url hash="2c780278">W16-2405</url>
      <doi>10.18653/v1/W16-2405</doi>
    </paper>
    <paper id="6">
      <title>Data-Driven Spelling Correction using Weighted Finite-State Methods</title>
      <author><first>Miikka</first> <last>Silfverberg</last></author>
      <author><first>Pekka</first> <last>Kauppinen</last></author>
      <author><first>Krister</first> <last>Lindén</last></author>
      <pages>51–59</pages>
      <url hash="c33a8b89">W16-2406</url>
      <doi>10.18653/v1/W16-2406</doi>
    </paper>
    <paper id="7">
      <title><fixed-case>EM</fixed-case>-Training for Weighted Aligned Hypergraph Bimorphisms</title>
      <author><first>Frank</first> <last>Drewes</last></author>
      <author><first>Kilian</first> <last>Gebhardt</last></author>
      <author><first>Heiko</first> <last>Vogler</last></author>
      <pages>60–69</pages>
      <url hash="0e1f76a2">W16-2407</url>
      <doi>10.18653/v1/W16-2407</doi>
    </paper>
    <paper id="8">
      <title>On the Correspondence between Compositional Matrix-Space Models of Language and Weighted Automata</title>
      <author><first>Shima</first> <last>Asaadi</last></author>
      <author><first>Sebastian</first> <last>Rudolph</last></author>
      <pages>70–74</pages>
      <url hash="1ff98885">W16-2408</url>
      <doi>10.18653/v1/W16-2408</doi>
    </paper>
    <paper id="9">
      <title><fixed-case>P</fixed-case>ynini: A Python library for weighted finite-state grammar compilation</title>
      <author><first>Kyle</first> <last>Gorman</last></author>
      <pages>75–80</pages>
      <url hash="9bf9b1f6">W16-2409</url>
      <doi>10.18653/v1/W16-2409</doi>
    </paper>
  </volume>
  <volume id="25">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for <fixed-case>NLP</fixed-case></booktitle>
      <url hash="c3dabc06">W16-25</url>
      <doi>10.18653/v1/W16-25</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="4662c1ec">W16-2500</url>
    </frontmatter>
    <paper id="1">
      <title>Intrinsic Evaluation of Word Vectors Fails to Predict Extrinsic Performance</title>
      <author><first>Billy</first> <last>Chiu</last></author>
      <author><first>Anna</first> <last>Korhonen</last></author>
      <author><first>Sampo</first> <last>Pyysalo</last></author>
      <pages>1–6</pages>
      <url hash="7bcbc117">W16-2501</url>
      <doi>10.18653/v1/W16-2501</doi>
    </paper>
    <paper id="2">
      <title>A critique of word similarity as a method for evaluating distributional semantic models</title>
      <author><first>Miroslav</first> <last>Batchkarov</last></author>
      <author><first>Thomas</first> <last>Kober</last></author>
      <author><first>Jeremy</first> <last>Reffin</last></author>
      <author><first>Julie</first> <last>Weeds</last></author>
      <author><first>David</first> <last>Weir</last></author>
      <pages>7–12</pages>
      <url hash="1e4213ab">W16-2502</url>
      <doi>10.18653/v1/W16-2502</doi>
    </paper>
    <paper id="3">
      <title>Issues in evaluating semantic spaces using word analogies</title>
      <author><first>Tal</first> <last>Linzen</last></author>
      <pages>13–18</pages>
      <url hash="3271dc0e">W16-2503</url>
      <doi>10.18653/v1/W16-2503</doi>
    </paper>
    <paper id="4">
      <title>Evaluating Word Embeddings Using a Representative Suite of Practical Tasks</title>
      <author><first>Neha</first> <last>Nayak</last></author>
      <author><first>Gabor</first> <last>Angeli</last></author>
      <author><first>Christopher D.</first> <last>Manning</last></author>
      <pages>19–23</pages>
      <url hash="45313556">W16-2504</url>
      <doi>10.18653/v1/W16-2504</doi>
    </paper>
    <paper id="5">
      <title>Story Cloze Evaluator: Vector Space Representation Evaluation by Predicting What Happens Next</title>
      <author><first>Nasrin</first> <last>Mostafazadeh</last></author>
      <author><first>Lucy</first> <last>Vanderwende</last></author>
      <author><first>Wen-tau</first> <last>Yih</last></author>
      <author><first>Pushmeet</first> <last>Kohli</last></author>
      <author><first>James</first> <last>Allen</last></author>
      <pages>24–29</pages>
      <url hash="bbaf62d6">W16-2505</url>
      <doi>10.18653/v1/W16-2505</doi>
    </paper>
    <paper id="6">
      <title>Problems With Evaluation of Word Embeddings Using Word Similarity Tasks</title>
      <author><first>Manaal</first> <last>Faruqui</last></author>
      <author><first>Yulia</first> <last>Tsvetkov</last></author>
      <author><first>Pushpendre</first> <last>Rastogi</last></author>
      <author><first>Chris</first> <last>Dyer</last></author>
      <pages>30–35</pages>
      <url hash="303468d0">W16-2506</url>
      <doi>10.18653/v1/W16-2506</doi>
    </paper>
    <paper id="7">
      <title>Intrinsic Evaluations of Word Embeddings: What Can We Do Better?</title>
      <author><first>Anna</first> <last>Gladkova</last></author>
      <author><first>Aleksandr</first> <last>Drozd</last></author>
      <pages>36–42</pages>
      <url hash="2874987d">W16-2507</url>
      <doi>10.18653/v1/W16-2507</doi>
    </paper>
    <paper id="8">
      <title>Find the word that does not belong: A Framework for an Intrinsic Evaluation of Word Vector Representations</title>
      <author><first>José</first> <last>Camacho-Collados</last></author>
      <author><first>Roberto</first> <last>Navigli</last></author>
      <pages>43–50</pages>
      <url hash="0c640b8f">W16-2508</url>
      <doi>10.18653/v1/W16-2508</doi>
    </paper>
    <paper id="9">
      <title>Capturing Discriminative Attributes in a Distributional Space: Task Proposal</title>
      <author><first>Alicia</first> <last>Krebs</last></author>
      <author><first>Denis</first> <last>Paperno</last></author>
      <pages>51–54</pages>
      <url hash="f3782850">W16-2509</url>
      <doi>10.18653/v1/W16-2509</doi>
    </paper>
    <paper id="10">
      <title>An Improved Crowdsourcing Based Evaluation Technique for Word Embedding Methods</title>
      <author><first>Farhana Ferdousi</first> <last>Liza</last></author>
      <author><first>Marek</first> <last>Grześ</last></author>
      <pages>55–61</pages>
      <url hash="1a3cad4a">W16-2510</url>
      <doi>10.18653/v1/W16-2510</doi>
    </paper>
    <paper id="11">
      <title>Evaluation of acoustic word embeddings</title>
      <author><first>Sahar</first> <last>Ghannay</last></author>
      <author><first>Yannick</first> <last>Estève</last></author>
      <author><first>Nathalie</first> <last>Camelin</last></author>
      <author><first>Paul</first> <last>Deleglise</last></author>
      <pages>62–66</pages>
      <url hash="4dfb636e">W16-2511</url>
      <doi>10.18653/v1/W16-2511</doi>
    </paper>
    <paper id="12">
      <title>Evaluating Embeddings using Syntax-based Classification Tasks as a Proxy for Parser Performance</title>
      <author><first>Arne</first> <last>Köhn</last></author>
      <pages>67–71</pages>
      <url hash="b4044d0d">W16-2512</url>
      <doi>10.18653/v1/W16-2512</doi>
    </paper>
    <paper id="13">
      <title>Evaluating vector space models using human semantic priming results</title>
      <author><first>Allyson</first> <last>Ettinger</last></author>
      <author><first>Tal</first> <last>Linzen</last></author>
      <pages>72–77</pages>
      <url hash="34c479dd">W16-2513</url>
      <doi>10.18653/v1/W16-2513</doi>
    </paper>
    <paper id="14">
      <title>Evaluating embeddings on dictionary-based similarity</title>
      <author><first>Judit</first> <last>Ács</last></author>
      <author><first>András</first> <last>Kornai</last></author>
      <pages>78–82</pages>
      <url hash="f42ae45d">W16-2514</url>
      <doi>10.18653/v1/W16-2514</doi>
    </paper>
    <paper id="15">
      <title>Evaluating multi-sense embeddings for semantic resolution monolingually and in word translation</title>
      <author><first>Gábor</first> <last>Borbély</last></author>
      <author><first>Márton</first> <last>Makrai</last></author>
      <author><first>Dávid Márk</first> <last>Nemeskey</last></author>
      <author><first>András</first> <last>Kornai</last></author>
      <pages>83–89</pages>
      <url hash="8e5ec9f4">W16-2515</url>
      <doi>10.18653/v1/W16-2515</doi>
    </paper>
    <paper id="16">
      <title>Subsumption Preservation as a Comparative Measure for Evaluating Sense-Directed Embeddings</title>
      <author><first>Ali</first> <last>Seyed</last></author>
      <pages>90–93</pages>
      <url hash="d74e5cdf">W16-2516</url>
      <doi>10.18653/v1/W16-2516</doi>
    </paper>
    <paper id="17">
      <title>Evaluating Informal-Domain Word Representations With <fixed-case>U</fixed-case>rban<fixed-case>D</fixed-case>ictionary</title>
      <author><first>Naomi</first> <last>Saphra</last></author>
      <author><first>Adam</first> <last>Lopez</last></author>
      <pages>94–98</pages>
      <url hash="3e192e04">W16-2517</url>
      <doi>10.18653/v1/W16-2517</doi>
    </paper>
    <paper id="18">
      <title>Thematic fit evaluation: an aspect of selectional preferences</title>
      <author><first>Asad</first> <last>Sayeed</last></author>
      <author><first>Clayton</first> <last>Greenberg</last></author>
      <author><first>Vera</first> <last>Demberg</last></author>
      <pages>99–105</pages>
      <url hash="e753e839">W16-2518</url>
      <doi>10.18653/v1/W16-2518</doi>
    </paper>
    <paper id="19">
      <title>Improving Reliability of Word Similarity Evaluation by Redesigning Annotation Task and Performance Measure</title>
      <author><first>Oded</first> <last>Avraham</last></author>
      <author><first>Yoav</first> <last>Goldberg</last></author>
      <pages>106–110</pages>
      <url hash="10e10d7c">W16-2519</url>
      <doi>10.18653/v1/W16-2519</doi>
    </paper>
    <paper id="20">
      <title>Correlation-based Intrinsic Evaluation of Word Vector Representations</title>
      <author><first>Yulia</first> <last>Tsvetkov</last></author>
      <author><first>Manaal</first> <last>Faruqui</last></author>
      <author><first>Chris</first> <last>Dyer</last></author>
      <pages>111–115</pages>
      <url hash="fe42e8ce">W16-2520</url>
      <doi>10.18653/v1/W16-2520</doi>
    </paper>
    <paper id="21">
      <title>Evaluating word embeddings with f<fixed-case>MRI</fixed-case> and eye-tracking</title>
      <author><first>Anders</first> <last>Søgaard</last></author>
      <pages>116–121</pages>
      <url hash="3633db57">W16-2521</url>
      <doi>10.18653/v1/W16-2521</doi>
    </paper>
    <paper id="22">
      <title>Defining Words with Words: Beyond the Distributional Hypothesis</title>
      <author><first>Iuliana-Elena</first> <last>Parasca</last></author>
      <author><first>Andreas Lukas</first> <last>Rauter</last></author>
      <author><first>Jack</first> <last>Roper</last></author>
      <author><first>Aleksandar</first> <last>Rusinov</last></author>
      <author><first>Guillaume</first> <last>Bouchard</last></author>
      <author><first>Sebastian</first> <last>Riedel</last></author>
      <author><first>Pontus</first> <last>Stenetorp</last></author>
      <pages>122–126</pages>
      <url hash="1b2df14a">W16-2522</url>
      <doi>10.18653/v1/W16-2522</doi>
    </paper>
    <paper id="23">
      <title>A Proposal for Linguistic Similarity Datasets Based on Commonality Lists</title>
      <author><first>Dmitrijs</first> <last>Milajevs</last></author>
      <author><first>Sascha</first> <last>Griffiths</last></author>
      <pages>127–133</pages>
      <url hash="07f661ab">W16-2523</url>
      <doi>10.18653/v1/W16-2523</doi>
    </paper>
    <paper id="24">
      <title>Probing for semantic evidence of composition by means of simple classification tasks</title>
      <author><first>Allyson</first> <last>Ettinger</last></author>
      <author><first>Ahmed</first> <last>Elgohary</last></author>
      <author><first>Philip</first> <last>Resnik</last></author>
      <pages>134–139</pages>
      <url hash="95d3c4ce">W16-2524</url>
      <doi>10.18653/v1/W16-2524</doi>
    </paper>
    <paper id="25">
      <title><fixed-case>SLEDDED</fixed-case>: A Proposed Dataset of Event Descriptions for Evaluating Phrase Representations</title>
      <author><first>Laura</first> <last>Rimell</last></author>
      <author><first>Eva Maria</first> <last>Vecchi</last></author>
      <pages>140–144</pages>
      <url hash="08688e10">W16-2525</url>
      <doi>10.18653/v1/W16-2525</doi>
    </paper>
    <paper id="26">
      <title>Sentence Embedding Evaluation Using Pyramid Annotation</title>
      <author><first>Tal</first> <last>Baumel</last></author>
      <author><first>Raphael</first> <last>Cohen</last></author>
      <author><first>Michael</first> <last>Elhadad</last></author>
      <pages>145–149</pages>
      <url hash="2b570781">W16-2526</url>
      <doi>10.18653/v1/W16-2526</doi>
    </paper>
  </volume>
  <volume id="26">
    <meta>
      <booktitle>Proceedings of the 10th Web as Corpus Workshop</booktitle>
      <url hash="5c1d58cf">W16-26</url>
      <editor><first>Paul</first><last>Cook</last></editor>
      <editor><first>Stefan</first><last>Evert</last></editor>
      <editor><first>Roland</first><last>Schäfer</last></editor>
      <editor><first>Egon</first><last>Stemle</last></editor>
      <doi>10.18653/v1/W16-26</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="9d4db0ae">W16-2600</url>
    </frontmatter>
    <paper id="1">
      <title>Automatic Classification by Topic Domain for Meta Data Generation, Web Corpus Evaluation, and Corpus Comparison</title>
      <author><first>Roland</first> <last>Schäfer</last></author>
      <author><first>Felix</first> <last>Bildhauer</last></author>
      <pages>1–6</pages>
      <url hash="67158d3d">W16-2601</url>
      <doi>10.18653/v1/W16-2601</doi>
    </paper>
    <paper id="2">
      <title>Efficient construction of metadata-enhanced web corpora</title>
      <author><first>Adrien</first> <last>Barbaresi</last></author>
      <pages>7–16</pages>
      <url hash="45d2ab6c">W16-2602</url>
      <doi>10.18653/v1/W16-2602</doi>
    </paper>
    <paper id="3">
      <title>Topically-focused Blog Corpora for Multiple Languages</title>
      <author><first>Andrew</first> <last>Salway</last></author>
      <author><first>Dag</first> <last>Elgesem</last></author>
      <author><first>Knut</first> <last>Hofland</last></author>
      <author><first>Øystein</first> <last>Reigem</last></author>
      <author><first>Lubos</first> <last>Steskal</last></author>
      <pages>17–26</pages>
      <url hash="e930eba9">W16-2603</url>
      <doi>10.18653/v1/W16-2603</doi>
    </paper>
    <paper id="4">
      <title>The Challenges and Joys of Analysing Ongoing Language Change in Web-based Corpora: a Case Study</title>
      <author><first>Anne</first> <last>Krause</last></author>
      <pages>27–34</pages>
      <url hash="3d678eed">W16-2604</url>
      <doi>10.18653/v1/W16-2604</doi>
    </paper>
    <paper id="5">
      <title>Using the Web and Social Media as Corpora for Monitoring the Spread of Neologisms. The case of ‘rapefugee’, ‘rapeugee’, and ‘rapugee’.</title>
      <author><first>Quirin</first> <last>Würschinger</last></author>
      <author><first>Mohammad Fazleh</first> <last>Elahi</last></author>
      <author><first>Desislava</first> <last>Zhekova</last></author>
      <author><first>Hans-Jörg</first> <last>Schmid</last></author>
      <pages>35–43</pages>
      <url hash="4eee78d8">W16-2605</url>
      <doi>10.18653/v1/W16-2605</doi>
    </paper>
    <paper id="6">
      <title><fixed-case>E</fixed-case>mpiri<fixed-case>ST</fixed-case> 2015: A Shared Task on the Automatic Linguistic Annotation of Computer-Mediated Communication and Web Corpora</title>
      <author><first>Michael</first> <last>Beißwenger</last></author>
      <author><first>Sabine</first> <last>Bartsch</last></author>
      <author><first>Stefan</first> <last>Evert</last></author>
      <author><first>Kay-Michael</first> <last>Würzner</last></author>
      <pages>44–56</pages>
      <url hash="ab9e6969">W16-2606</url>
      <doi>10.18653/v1/W16-2606</doi>
    </paper>
    <paper id="7">
      <title><fixed-case>S</fixed-case>o<fixed-case>M</fixed-case>a<fixed-case>J</fixed-case>o: State-of-the-art tokenization for <fixed-case>G</fixed-case>erman web and social media texts</title>
      <author><first>Thomas</first> <last>Proisl</last></author>
      <author><first>Peter</first> <last>Uhrig</last></author>
      <pages>57–62</pages>
      <url hash="a4d87dc9">W16-2607</url>
      <doi>10.18653/v1/W16-2607</doi>
    </paper>
    <paper id="8">
      <title><fixed-case>U</fixed-case>d<fixed-case>S</fixed-case>-(retrain|distributional|surface): Improving <fixed-case>POS</fixed-case> Tagging for <fixed-case>OOV</fixed-case> Words in <fixed-case>G</fixed-case>erman <fixed-case>CMC</fixed-case> and Web Data</title>
      <author><first>Jakob</first> <last>Prange</last></author>
      <author><first>Andrea</first> <last>Horbach</last></author>
      <author><first>Stefan</first> <last>Thater</last></author>
      <pages>63–71</pages>
      <url hash="f9cdc838">W16-2608</url>
      <doi>10.18653/v1/W16-2608</doi>
    </paper>
    <paper id="9">
      <title>Babler - Data Collection from the Web to Support Speech Recognition and Keyword Search</title>
      <author><first>Gideon</first> <last>Mendels</last></author>
      <author><first>Erica</first> <last>Cooper</last></author>
      <author><first>Julia</first> <last>Hirschberg</last></author>
      <pages>72–81</pages>
      <url hash="c349f8a0">W16-2609</url>
      <doi>10.18653/v1/W16-2609</doi>
    </paper>
    <paper id="10">
      <title>A Global Analysis of Emoji Usage</title>
      <author><first>Nikola</first> <last>Ljubešić</last></author>
      <author><first>Darja</first> <last>Fišer</last></author>
      <pages>82–89</pages>
      <url hash="8db9baf2">W16-2610</url>
      <doi>10.18653/v1/W16-2610</doi>
    </paper>
    <paper id="11">
      <title>Genre classification for a corpus of academic webpages</title>
      <author><first>Erika</first> <last>Dalan</last></author>
      <author><first>Serge</first> <last>Sharoff</last></author>
      <pages>90–98</pages>
      <url hash="07725fa0">W16-2611</url>
      <doi>10.18653/v1/W16-2611</doi>
    </paper>
    <paper id="12">
      <title>On Bias-free Crawling and Representative Web Corpora</title>
      <author><first>Roland</first> <last>Schäfer</last></author>
      <pages>99–105</pages>
      <url hash="14e7f64e">W16-2612</url>
      <doi>10.18653/v1/W16-2612</doi>
    </paper>
    <paper id="13">
      <title><fixed-case>E</fixed-case>mpiri<fixed-case>ST</fixed-case>: <fixed-case>AIPHES</fixed-case> - Robust Tokenization and <fixed-case>POS</fixed-case>-Tagging for Different Genres</title>
      <author><first>Steffen</first> <last>Remus</last></author>
      <author><first>Gerold</first> <last>Hintz</last></author>
      <author><first>Chris</first> <last>Biemann</last></author>
      <author><first>Christian M.</first> <last>Meyer</last></author>
      <author><first>Darina</first> <last>Benikova</last></author>
      <author><first>Judith</first> <last>Eckle-Kohler</last></author>
      <author><first>Margot</first> <last>Mieskes</last></author>
      <author><first>Thomas</first> <last>Arnold</last></author>
      <pages>106–114</pages>
      <url hash="acfd3ff6">W16-2613</url>
      <doi>10.18653/v1/W16-2613</doi>
    </paper>
    <paper id="14">
      <title>bot.zen @ <fixed-case>E</fixed-case>mpiri<fixed-case>ST</fixed-case> 2015 - A minimally-deep learning <fixed-case>P</fixed-case>o<fixed-case>S</fixed-case>-tagger (trained for <fixed-case>G</fixed-case>erman <fixed-case>CMC</fixed-case> and Web data)</title>
      <author><first>Egon</first> <last>Stemle</last></author>
      <pages>115–119</pages>
      <url hash="5fb2bc48">W16-2614</url>
      <doi>10.18653/v1/W16-2614</doi>
    </paper>
    <paper id="15">
      <title><fixed-case>LTL</fixed-case>-<fixed-case>UDE</fixed-case> @ <fixed-case>E</fixed-case>mpiri<fixed-case>ST</fixed-case> 2015: Tokenization and <fixed-case>P</fixed-case>o<fixed-case>S</fixed-case> Tagging of Social Media Text</title>
      <author><first>Tobias</first> <last>Horsmann</last></author>
      <author><first>Torsten</first> <last>Zesch</last></author>
      <pages>120–126</pages>
      <url hash="e280800f">W16-2615</url>
      <doi>10.18653/v1/W16-2615</doi>
    </paper>
  </volume>
  <volume id="27">
    <meta>
      <booktitle>Proceedings of the Sixth Named Entity Workshop</booktitle>
      <url hash="88ff6055">W16-27</url>
      <editor><first>Xiangyu</first> <last>Duan</last></editor>
      <editor><first>Rafael E.</first> <last>Banchs</last></editor>
      <editor><first>Min</first> <last>Zhang</last></editor>
      <editor><first>Haizhou</first> <last>Li</last></editor>
      <editor><first>A</first> <last>Kumaran</last></editor>
      <doi>10.18653/v1/W16-27</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="695d4178">W16-2700</url>
    </frontmatter>
    <paper id="1">
      <title>Leveraging Entity Linking and Related Language Projection to Improve Name Transliteration</title>
      <author><first>Ying</first> <last>Lin</last></author>
      <author><first>Xiaoman</first> <last>Pan</last></author>
      <author><first>Aliya</first> <last>Deri</last></author>
      <author><first>Heng</first> <last>Ji</last></author>
      <author><first>Kevin</first> <last>Knight</last></author>
      <pages>1–10</pages>
      <url hash="a02f8c53">W16-2701</url>
      <doi>10.18653/v1/W16-2701</doi>
      <revision id="1" href="W16-2701v1" hash="9fc0603d"/>
      <revision id="2" href="W16-2701v2" hash="a02f8c53">No description of the changes were recorded.</revision>
    </paper>
    <paper id="2">
      <title>Multi-source named entity typing for social media</title>
      <author><first>Reuth</first> <last>Vexler</last></author>
      <author><first>Einat</first> <last>Minkov</last></author>
      <pages>11–20</pages>
      <url hash="7abec999">W16-2702</url>
      <doi>10.18653/v1/W16-2702</doi>
    </paper>
    <paper id="3">
      <title>Evaluating and Combining Name Entity Recognition Systems</title>
      <author><first>Ridong</first> <last>Jiang</last></author>
      <author><first>Rafael E.</first> <last>Banchs</last></author>
      <author><first>Haizhou</first> <last>Li</last></author>
      <pages>21–27</pages>
      <url hash="97875bb5">W16-2703</url>
      <doi>10.18653/v1/W16-2703</doi>
    </paper>
    <paper id="4">
      <title><fixed-case>G</fixed-case>erman <fixed-case>NER</fixed-case> with a Multilingual Rule Based Information Extraction System: Analysis and Issues</title>
      <author><first>Anna</first> <last>Druzhkina</last></author>
      <author><first>Alexey</first> <last>Leontyev</last></author>
      <author><first>Maria</first> <last>Stepanova</last></author>
      <pages>28–33</pages>
      <url hash="8293aabe">W16-2704</url>
      <doi>10.18653/v1/W16-2704</doi>
    </paper>
    <paper id="5">
      <title><fixed-case>S</fixed-case>panish <fixed-case>NER</fixed-case> with Word Representations and Conditional Random Fields</title>
      <author><first>Jenny Linet</first> <last>Copara Zea</last></author>
      <author><first>Jose Eduardo</first> <last>Ochoa Luna</last></author>
      <author><first>Camilo</first> <last>Thorne</last></author>
      <author><first>Goran</first> <last>Glavaš</last></author>
      <pages>34–40</pages>
      <url hash="a638f291">W16-2705</url>
      <doi>10.18653/v1/W16-2705</doi>
    </paper>
    <paper id="6">
      <title>Constructing a <fixed-case>J</fixed-case>apanese Basic Named Entity Corpus of Various Genres</title>
      <author><first>Tomoya</first> <last>Iwakura</last></author>
      <author><first>Kanako</first> <last>Komiya</last></author>
      <author><first>Ryuichi</first> <last>Tachibana</last></author>
      <pages>41–46</pages>
      <url hash="f10d62d5">W16-2706</url>
      <doi>10.18653/v1/W16-2706</doi>
    </paper>
    <paper id="7">
      <title>Linguistic Issues in the Machine Transliteration of <fixed-case>C</fixed-case>hinese, <fixed-case>J</fixed-case>apanese and <fixed-case>A</fixed-case>rabic Names</title>
      <author><first>Jack</first> <last>Halpern</last></author>
      <pages>47–48</pages>
      <url hash="d66b7c43">W16-2707</url>
      <doi>10.18653/v1/W16-2707</doi>
    </paper>
    <paper id="8">
      <title>Whitepaper of <fixed-case>NEWS</fixed-case> 2016 Shared Task on Machine Transliteration</title>
      <author><first>Xiangyu</first> <last>Duan</last></author>
      <author><first>Min</first> <last>Zhang</last></author>
      <author><first>Haizhou</first> <last>Li</last></author>
      <author><first>Rafael</first> <last>Banchs</last></author>
      <author><first>A</first> <last>Kumaran</last></author>
      <pages>49–57</pages>
      <url hash="abdf54bf">W16-2708</url>
      <doi>10.18653/v1/W16-2708</doi>
    </paper>
    <paper id="9">
      <title>Report of <fixed-case>NEWS</fixed-case> 2016 Machine Transliteration Shared Task</title>
      <author><first>Xiangyu</first> <last>Duan</last></author>
      <author><first>Rafael</first> <last>Banchs</last></author>
      <author><first>Min</first> <last>Zhang</last></author>
      <author><first>Haizhou</first> <last>Li</last></author>
      <author><first>A.</first> <last>Kumaran</last></author>
      <pages>58–72</pages>
      <url hash="626827e6">W16-2709</url>
      <doi>10.18653/v1/W16-2709</doi>
    </paper>
    <paper id="10">
      <title>Applying Neural Networks to <fixed-case>E</fixed-case>nglish-<fixed-case>C</fixed-case>hinese Named Entity Transliteration</title>
      <author><first>Yan</first> <last>Shao</last></author>
      <author><first>Joakim</first> <last>Nivre</last></author>
      <pages>73–77</pages>
      <url hash="cc82210b">W16-2710</url>
      <doi>10.18653/v1/W16-2710</doi>
    </paper>
    <paper id="11">
      <title>Target-Bidirectional Neural Models for Machine Transliteration</title>
      <author><first>Andrew</first> <last>Finch</last></author>
      <author><first>Lemao</first> <last>Liu</last></author>
      <author><first>Xiaolin</first> <last>Wang</last></author>
      <author><first>Eiichiro</first> <last>Sumita</last></author>
      <pages>78–82</pages>
      <url hash="d197b9e3">W16-2711</url>
      <doi>10.18653/v1/W16-2711</doi>
    </paper>
    <paper id="12">
      <title>Regulating Orthography-Phonology Relationship for <fixed-case>E</fixed-case>nglish to <fixed-case>T</fixed-case>hai Transliteration</title>
      <author><first>Binh Minh</first> <last>Nguyen</last></author>
      <author><first>Hoang Gia</first> <last>Ngo</last></author>
      <author><first>Nancy F.</first> <last>Chen</last></author>
      <pages>83–87</pages>
      <url hash="f4ba4070">W16-2712</url>
      <doi>10.18653/v1/W16-2712</doi>
    </paper>
    <paper id="13">
      <title><fixed-case>M</fixed-case>oses-based official baseline for <fixed-case>NEWS</fixed-case> 2016</title>
      <author><first>Marta R.</first> <last>Costa-jussà</last></author>
      <pages>88–90</pages>
      <url hash="1e1c1f7a">W16-2713</url>
      <doi>10.18653/v1/W16-2713</doi>
    </paper>
  </volume>
  <volume id="28">
    <meta>
      <booktitle>Proceedings of the Third Workshop on Argument Mining (<fixed-case>A</fixed-case>rg<fixed-case>M</fixed-case>ining2016)</booktitle>
      <url hash="0656cfa4">W16-28</url>
      <editor><first>Chris</first><last>Reed</last></editor>
      <doi>10.18653/v1/W16-28</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="62f28624">W16-2800</url>
    </frontmatter>
    <paper id="1">
      <title>“What Is Your Evidence?” A Study of Controversial Topics on Social Media</title>
      <author><first>Aseel</first> <last>Addawood</last></author>
      <author><first>Masooda</first> <last>Bashir</last></author>
      <pages>1–11</pages>
      <url hash="3fe101c6">W16-2801</url>
      <doi>10.18653/v1/W16-2801</doi>
    </paper>
    <paper id="2">
      <title>Summarizing Multi-Party Argumentative Conversations in Reader Comment on News</title>
      <author><first>Emma</first> <last>Barker</last></author>
      <author><first>Robert</first> <last>Gaizauskas</last></author>
      <pages>12–20</pages>
      <url hash="4ba4cb41">W16-2802</url>
      <doi>10.18653/v1/W16-2802</doi>
    </paper>
    <paper id="3">
      <title>Argumentative texts and clause types</title>
      <author><first>Maria</first> <last>Becker</last></author>
      <author><first>Alexis</first> <last>Palmer</last></author>
      <author><first>Anette</first> <last>Frank</last></author>
      <pages>21–30</pages>
      <url hash="f1cd7df3">W16-2803</url>
      <doi>10.18653/v1/W16-2803</doi>
    </paper>
    <paper id="4">
      <title>Contextual stance classification of opinions: A step towards enthymeme reconstruction in online reviews</title>
      <author><first>Pavithra</first> <last>Rajendran</last></author>
      <author><first>Danushka</first> <last>Bollegala</last></author>
      <author><first>Simon</first> <last>Parsons</last></author>
      <pages>31–39</pages>
      <url hash="936efa81">W16-2804</url>
      <doi>10.18653/v1/W16-2804</doi>
    </paper>
    <paper id="5">
      <title>The <fixed-case>CASS</fixed-case> Technique for Evaluating the Performance of Argument Mining</title>
      <author><first>Rory</first> <last>Duthie</last></author>
      <author><first>John</first> <last>Lawrence</last></author>
      <author><first>Katarzyna</first> <last>Budzynska</last></author>
      <author><first>Chris</first> <last>Reed</last></author>
      <pages>40–49</pages>
      <url hash="e7cb6d05">W16-2805</url>
      <doi>10.18653/v1/W16-2805</doi>
    </paper>
    <paper id="6">
      <title>Extracting Case Law Sentences for Argumentation about the Meaning of Statutory Terms</title>
      <author><first>Jaromír</first> <last>Šavelka</last></author>
      <author><first>Kevin D.</first> <last>Ashley</last></author>
      <pages>50–59</pages>
      <url hash="6c855ea4">W16-2806</url>
      <doi>10.18653/v1/W16-2806</doi>
    </paper>
    <paper id="7">
      <title>Scrutable Feature Sets for Stance Classification</title>
      <author><first>Angrosh</first> <last>Mandya</last></author>
      <author><first>Advaith</first> <last>Siddharthan</last></author>
      <author><first>Adam</first> <last>Wyner</last></author>
      <pages>60–69</pages>
      <url hash="8b0687aa">W16-2807</url>
      <doi>10.18653/v1/W16-2807</doi>
    </paper>
    <paper id="8">
      <title><fixed-case>A</fixed-case>rgumentation: Content, Structure, and Relationship with Essay Quality</title>
      <author><first>Beata</first> <last>Beigman Klebanov</last></author>
      <author><first>Christian</first> <last>Stab</last></author>
      <author><first>Jill</first> <last>Burstein</last></author>
      <author><first>Yi</first> <last>Song</last></author>
      <author><first>Binod</first> <last>Gyawali</last></author>
      <author><first>Iryna</first> <last>Gurevych</last></author>
      <pages>70–75</pages>
      <url hash="46ec0f90">W16-2808</url>
      <doi>10.18653/v1/W16-2808</doi>
    </paper>
    <paper id="9">
      <title>Neural Attention Model for Classification of Sentences that Support Promoting/Suppressing Relationship</title>
      <author><first>Yuta</first> <last>Koreeda</last></author>
      <author><first>Toshihiko</first> <last>Yanase</last></author>
      <author><first>Kohsuke</first> <last>Yanai</last></author>
      <author><first>Misa</first> <last>Sato</last></author>
      <author><first>Yoshiki</first> <last>Niwa</last></author>
      <pages>76–81</pages>
      <url hash="0b3d196b">W16-2809</url>
      <doi>10.18653/v1/W16-2809</doi>
    </paper>
    <paper id="10">
      <title>Towards Feasible Guidelines for the Annotation of Argument Schemes</title>
      <author><first>Elena</first> <last>Musi</last></author>
      <author><first>Debanjan</first> <last>Ghosh</last></author>
      <author><first>Smaranda</first> <last>Muresan</last></author>
      <pages>82–93</pages>
      <url hash="cdcfbe3d">W16-2810</url>
      <doi>10.18653/v1/W16-2810</doi>
    </paper>
    <paper id="11">
      <title>Identifying Argument Components through <fixed-case>T</fixed-case>ext<fixed-case>R</fixed-case>ank</title>
      <author><first>Georgios</first> <last>Petasis</last></author>
      <author><first>Vangelis</first> <last>Karkaletsis</last></author>
      <pages>94–102</pages>
      <url hash="8308a589">W16-2811</url>
      <doi>10.18653/v1/W16-2811</doi>
    </paper>
    <paper id="12">
      <title>Rhetorical structure and argumentation structure in monologue text</title>
      <author><first>Andreas</first> <last>Peldszus</last></author>
      <author><first>Manfred</first> <last>Stede</last></author>
      <pages>103–112</pages>
      <url hash="a0fec8a7">W16-2812</url>
      <doi>10.18653/v1/W16-2812</doi>
    </paper>
    <paper id="13">
      <title>Recognizing the Absence of Opposing Arguments in Persuasive Essays</title>
      <author><first>Christian</first> <last>Stab</last></author>
      <author><first>Iryna</first> <last>Gurevych</last></author>
      <pages>113–118</pages>
      <url hash="b934406c">W16-2813</url>
      <doi>10.18653/v1/W16-2813</doi>
    </paper>
    <paper id="14">
      <title>Expert Stance Graphs for Computational Argumentation</title>
      <author><first>Orith</first> <last>Toledo-Ronen</last></author>
      <author><first>Roy</first> <last>Bar-Haim</last></author>
      <author><first>Noam</first> <last>Slonim</last></author>
      <pages>119–123</pages>
      <url hash="c6368db5">W16-2814</url>
      <doi>10.18653/v1/W16-2814</doi>
    </paper>
    <paper id="15">
      <title>Fill the Gap! Analyzing Implicit Premises between Claims from Online Debates</title>
      <author><first>Filip</first> <last>Boltužić</last></author>
      <author><first>Jan</first> <last>Šnajder</last></author>
      <pages>124–133</pages>
      <url hash="0e71d0fd">W16-2815</url>
      <doi>10.18653/v1/W16-2815</doi>
    </paper>
    <paper id="16">
      <title>Summarising the points made in online political debates</title>
      <author><first>Charlie</first> <last>Egan</last></author>
      <author><first>Advaith</first> <last>Siddharthan</last></author>
      <author><first>Adam</first> <last>Wyner</last></author>
      <pages>134–143</pages>
      <url hash="0dc9ea8b">W16-2816</url>
      <doi>10.18653/v1/W16-2816</doi>
    </paper>
    <paper id="17">
      <title>What to Do with an Airport? Mining Arguments in the <fixed-case>G</fixed-case>erman Online Participation Project Tempelhofer Feld</title>
      <author><first>Matthias</first> <last>Liebeck</last></author>
      <author><first>Katharina</first> <last>Esau</last></author>
      <author><first>Stefan</first> <last>Conrad</last></author>
      <pages>144–153</pages>
      <url hash="361740bb">W16-2817</url>
      <doi>10.18653/v1/W16-2817</doi>
    </paper>
    <paper id="18">
      <title>Unshared task: (Dis)agreement in online debates</title>
      <author><first>Maria</first> <last>Skeppstedt</last></author>
      <author><first>Magnus</first> <last>Sahlgren</last></author>
      <author><first>Carita</first> <last>Paradis</last></author>
      <author><first>Andreas</first> <last>Kerren</last></author>
      <pages>154–159</pages>
      <url hash="589e66f3">W16-2818</url>
      <doi>10.18653/v1/W16-2818</doi>
    </paper>
    <paper id="19">
      <title>Unshared Task at the 3rd Workshop on Argument Mining: Perspective Based Local Agreement and Disagreement in Online Debate</title>
      <author><first>Chantal</first> <last>van Son</last></author>
      <author><first>Tommaso</first> <last>Caselli</last></author>
      <author><first>Antske</first> <last>Fokkens</last></author>
      <author><first>Isa</first> <last>Maks</last></author>
      <author><first>Roser</first> <last>Morante</last></author>
      <author><first>Lora</first> <last>Aroyo</last></author>
      <author><first>Piek</first> <last>Vossen</last></author>
      <pages>160–165</pages>
      <url hash="a052791f">W16-2819</url>
      <doi>10.18653/v1/W16-2819</doi>
    </paper>
    <paper id="20">
      <title>A Preliminary Study of Disputation Behavior in Online Debating Forum</title>
      <author><first>Zhongyu</first> <last>Wei</last></author>
      <author><first>Yandi</first> <last>Xia</last></author>
      <author><first>Chen</first> <last>Li</last></author>
      <author id="yang-liu-icsi"><first>Yang</first> <last>Liu</last></author>
      <author><first>Zachary</first> <last>Stallbohm</last></author>
      <author><first>Yi</first> <last>Li</last></author>
      <author><first>Yang</first> <last>Jin</last></author>
      <pages>166–171</pages>
      <url hash="3902087f">W16-2820</url>
      <doi>10.18653/v1/W16-2820</doi>
    </paper>
  </volume>
  <volume id="29">
    <meta>
      <booktitle>Proceedings of the 15th Workshop on Biomedical Natural Language Processing</booktitle>
      <url hash="ae240577">W16-29</url>
      <editor><first>Kevin Bretonnel</first> <last>Cohen</last></editor>
      <editor><first>Dina</first> <last>Demner-Fushman</last></editor>
      <editor><first>Sophia</first> <last>Ananiadou</last></editor>
      <editor><first>Jun-ichi</first> <last>Tsujii</last></editor>
      <doi>10.18653/v1/W16-29</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="492716fc">W16-2900</url>
    </frontmatter>
    <paper id="1">
      <title>A Machine Learning Approach to Clinical Terms Normalization</title>
      <author><first>José</first> <last>Castaño</last></author>
      <author><first>María Laura</first> <last>Gambarte</last></author>
      <author><first>Hee Joon</first> <last>Park</last></author>
      <author><first>Maria</first><last>del Pilar Avila Williams</last></author>
      <author><first>David</first> <last>Pérez</last></author>
      <author><first>Fernando</first> <last>Campos</last></author>
      <author><first>Daniel</first> <last>Luna</last></author>
      <author><first>Sonia</first> <last>Benítez</last></author>
      <author><first>Hernán</first> <last>Berinsky</last></author>
      <author><first>Sofía</first> <last>Zanetti</last></author>
      <pages>1–11</pages>
      <url hash="8e8c1e03">W16-2901</url>
      <doi>10.18653/v1/W16-2901</doi>
    </paper>
    <paper id="2">
      <title>Improved Semantic Representation for Domain-Specific Entities</title>
      <author><first>Mohammad Taher</first> <last>Pilehvar</last></author>
      <author><first>Nigel</first> <last>Collier</last></author>
      <pages>12–16</pages>
      <url hash="cb362fd2">W16-2902</url>
      <doi>10.18653/v1/W16-2902</doi>
    </paper>
    <paper id="3">
      <title>Identification, characterization, and grounding of gradable terms in clinical text</title>
      <author><first>Chaitanya</first> <last>Shivade</last></author>
      <author><first>Marie-Catherine</first> <last>de Marneffe</last></author>
      <author><first>Eric</first> <last>Fosler-Lussier</last></author>
      <author><first>Albert M.</first> <last>Lai</last></author>
      <pages>17–26</pages>
      <url hash="951a8511">W16-2903</url>
      <doi>10.18653/v1/W16-2903</doi>
    </paper>
    <paper id="4">
      <title>Graph-based Semi-supervised Gene Mention Tagging</title>
      <author><first>Golnar</first> <last>Sheikhshab</last></author>
      <author><first>Elizabeth</first> <last>Starks</last></author>
      <author><first>Aly</first> <last>Karsan</last></author>
      <author><first>Anoop</first> <last>Sarkar</last></author>
      <author><first>Inanc</first> <last>Birol</last></author>
      <pages>27–35</pages>
      <url hash="f18c11f5">W16-2904</url>
      <doi>10.18653/v1/W16-2904</doi>
    </paper>
    <paper id="5">
      <title>Feature Derivation for Exploitation of Distant Annotation via Pattern Induction against Dependency Parses</title>
      <author><first>Dayne</first> <last>Freitag</last></author>
      <author><first>John</first> <last>Niekrasz</last></author>
      <pages>36–45</pages>
      <url hash="461cc835">W16-2905</url>
      <doi>10.18653/v1/W16-2905</doi>
    </paper>
    <paper id="6">
      <title>Inferring Implicit Causal Relationships in Biomedical Literature</title>
      <author><first>Halil</first> <last>Kilicoglu</last></author>
      <pages>46–55</pages>
      <url hash="3cb107bf">W16-2906</url>
      <doi>10.18653/v1/W16-2906</doi>
    </paper>
    <paper id="7">
      <title><fixed-case>S</fixed-case>nap<fixed-case>T</fixed-case>o<fixed-case>G</fixed-case>rid: From Statistical to Interpretable Models for Biomedical Information Extraction</title>
      <author><first>Marco A.</first> <last>Valenzuela-Escárcega</last></author>
      <author><first>Gus</first> <last>Hahn-Powell</last></author>
      <author><first>Dane</first> <last>Bell</last></author>
      <author><first>Mihai</first> <last>Surdeanu</last></author>
      <pages>56–65</pages>
      <url hash="a0cf97ca">W16-2907</url>
      <doi>10.18653/v1/W16-2907</doi>
    </paper>
    <paper id="8">
      <title>Character based String Kernels for Bio-Entity Relation Detection</title>
      <author><first>Ritambhara</first> <last>Singh</last></author>
      <author><first>Yanjun</first> <last>Qi</last></author>
      <pages>66–71</pages>
      <url hash="dc2b2f53">W16-2908</url>
      <doi>10.18653/v1/W16-2908</doi>
    </paper>
    <paper id="9">
      <title>Disambiguation of entities in <fixed-case>MEDLINE</fixed-case> abstracts by combining <fixed-case>M</fixed-case>e<fixed-case>SH</fixed-case> terms with knowledge</title>
      <author><first>Amy</first> <last>Siu</last></author>
      <author><first>Patrick</first> <last>Ernst</last></author>
      <author><first>Gerhard</first> <last>Weikum</last></author>
      <pages>72–76</pages>
      <url hash="bc8c4e74">W16-2909</url>
      <doi>10.18653/v1/W16-2909</doi>
    </paper>
    <paper id="10">
      <title>Using Distributed Representations to Disambiguate Biomedical and Clinical Concepts</title>
      <author><first>Stéphan</first> <last>Tulkens</last></author>
      <author><first>Simon</first> <last>Suster</last></author>
      <author><first>Walter</first> <last>Daelemans</last></author>
      <pages>77–82</pages>
      <url hash="19b2bf91">W16-2910</url>
      <doi>10.18653/v1/W16-2910</doi>
    </paper>
    <paper id="11">
      <title>Unsupervised Document Classification with Informed Topic Models</title>
      <author><first>Timothy</first> <last>Miller</last></author>
      <author><first>Dmitriy</first> <last>Dligach</last></author>
      <author><first>Guergana</first> <last>Savova</last></author>
      <pages>83–91</pages>
      <url hash="d5bd4528">W16-2911</url>
      <doi>10.18653/v1/W16-2911</doi>
    </paper>
    <paper id="12">
      <title>Vocabulary Development To Support Information Extraction of Substance Abuse from Psychiatry Notes</title>
      <author><first>Sumithra</first> <last>Velupillai</last></author>
      <author><first>Danielle L.</first> <last>Mowery</last></author>
      <author><first>Mike</first> <last>Conway</last></author>
      <author><first>John</first> <last>Hurdle</last></author>
      <author><first>Brent</first> <last>Kious</last></author>
      <pages>92–101</pages>
      <url hash="5ef2e12b">W16-2912</url>
      <doi>10.18653/v1/W16-2912</doi>
    </paper>
    <paper id="13">
      <title>Syntactic analyses and named entity recognition for <fixed-case>P</fixed-case>ub<fixed-case>M</fixed-case>ed and <fixed-case>P</fixed-case>ub<fixed-case>M</fixed-case>ed Central — up-to-the-minute</title>
      <author><first>Kai</first> <last>Hakala</last></author>
      <author><first>Suwisa</first> <last>Kaewphan</last></author>
      <author><first>Tapio</first> <last>Salakoski</last></author>
      <author><first>Filip</first> <last>Ginter</last></author>
      <pages>102–107</pages>
      <url hash="d7376c0c">W16-2913</url>
      <doi>10.18653/v1/W16-2913</doi>
    </paper>
    <paper id="14">
      <title>Improving Temporal Relation Extraction with Training Instance Augmentation</title>
      <author><first>Chen</first> <last>Lin</last></author>
      <author><first>Timothy</first> <last>Miller</last></author>
      <author><first>Dmitriy</first> <last>Dligach</last></author>
      <author><first>Steven</first> <last>Bethard</last></author>
      <author><first>Guergana</first> <last>Savova</last></author>
      <pages>108–113</pages>
      <url hash="bc5ca89f">W16-2914</url>
      <doi>10.18653/v1/W16-2914</doi>
    </paper>
    <paper id="15">
      <title>Using Centroids of Word Embeddings and Word Mover’s Distance for Biomedical Document Retrieval in Question Answering</title>
      <author><first>Georgios-Ioannis</first> <last>Brokos</last></author>
      <author><first>Prodromos</first> <last>Malakasiotis</last></author>
      <author><first>Ion</first> <last>Androutsopoulos</last></author>
      <pages>114–118</pages>
      <url hash="0b9b0779">W16-2915</url>
      <doi>10.18653/v1/W16-2915</doi>
    </paper>
    <paper id="16">
      <title>Measuring the State of the Art of Automated Pathway Curation Using Graph Algorithms - A Case Study of the m<fixed-case>TOR</fixed-case> Pathway</title>
      <author><first>Michael</first> <last>Spranger</last></author>
      <author><first>Sucheendra</first> <last>Palaniappan</last></author>
      <author><first>Samik</first> <last>Gosh</last></author>
      <pages>119–127</pages>
      <url hash="8d54181a">W16-2916</url>
      <doi>10.18653/v1/W16-2916</doi>
    </paper>
    <paper id="17">
      <title>Construction of a Personal Experience Tweet Corpus for Health Surveillance</title>
      <author><first>Keyuan</first> <last>Jiang</last></author>
      <author><first>Ricardo</first> <last>Calix</last></author>
      <author><first>Matrika</first> <last>Gupta</last></author>
      <pages>128–135</pages>
      <url hash="1a69d666">W16-2917</url>
      <doi>10.18653/v1/W16-2917</doi>
    </paper>
    <paper id="18">
      <title>Modelling the Combination of Generic and Target Domain Embeddings in a Convolutional Neural Network for Sentence Classification</title>
      <author><first>Nut</first> <last>Limsopatham</last></author>
      <author><first>Nigel</first> <last>Collier</last></author>
      <pages>136–140</pages>
      <url hash="3e35cfa8">W16-2918</url>
      <doi>10.18653/v1/W16-2918</doi>
    </paper>
    <paper id="19">
      <title><fixed-case>P</fixed-case>ub<fixed-case>T</fixed-case>erm<fixed-case>V</fixed-case>ariants: biomedical term variants and their use for <fixed-case>P</fixed-case>ub<fixed-case>M</fixed-case>ed search</title>
      <author><first>Lana</first> <last>Yeganova</last></author>
      <author><first>Won</first> <last>Kim</last></author>
      <author><first>Sun</first> <last>Kim</last></author>
      <author><first>Rezarta</first> <last>Islamaj Doğan</last></author>
      <author><first>Wanli</first> <last>Liu</last></author>
      <author><first>Donald C</first> <last>Comeau</last></author>
      <author><first>Zhiyong</first> <last>Lu</last></author>
      <author><first>W John</first> <last>Wilbur</last></author>
      <pages>141–145</pages>
      <url hash="3e3febf1">W16-2919</url>
      <doi>10.18653/v1/W16-2919</doi>
    </paper>
    <paper id="20">
      <title>This before That: Causal Precedence in the Biomedical Domain</title>
      <author><first>Gus</first> <last>Hahn-Powell</last></author>
      <author><first>Dane</first> <last>Bell</last></author>
      <author><first>Marco A.</first> <last>Valenzuela-Escárcega</last></author>
      <author><first>Mihai</first> <last>Surdeanu</last></author>
      <pages>146–155</pages>
      <url hash="3fb05536">W16-2920</url>
      <doi>10.18653/v1/W16-2920</doi>
    </paper>
    <paper id="21">
      <title>Syntactic methods for negation detection in radiology reports in <fixed-case>S</fixed-case>panish</title>
      <author><first>Viviana</first> <last>Cotik</last></author>
      <author><first>Vanesa</first> <last>Stricker</last></author>
      <author><first>Jorge</first> <last>Vivaldi</last></author>
      <author><first>Horacio</first> <last>Rodriguez</last></author>
      <pages>156–165</pages>
      <url hash="37e61fc8">W16-2921</url>
      <doi>10.18653/v1/W16-2921</doi>
    </paper>
    <paper id="22">
      <title>How to Train good Word Embeddings for Biomedical <fixed-case>NLP</fixed-case></title>
      <author><first>Billy</first> <last>Chiu</last></author>
      <author><first>Gamal</first> <last>Crichton</last></author>
      <author><first>Anna</first> <last>Korhonen</last></author>
      <author><first>Sampo</first> <last>Pyysalo</last></author>
      <pages>166–174</pages>
      <url hash="31e8a29a">W16-2922</url>
      <doi>10.18653/v1/W16-2922</doi>
    </paper>
    <paper id="23">
      <title>An Information Foraging Approach to Determining the Number of Relevant Features</title>
      <author><first>Brian</first> <last>Connolly</last></author>
      <author><first>Benjamin</first> <last>Glass</last></author>
      <author><first>John</first> <last>Pestian</last></author>
      <pages>175–180</pages>
      <url hash="3149b51b">W16-2923</url>
      <doi>10.18653/v1/W16-2923</doi>
    </paper>
    <paper id="24">
      <title>Assessing the Feasibility of an Automated Suggestion System for Communicating Critical Findings from Chest Radiology Reports to Referring Physicians</title>
      <author><first>Brian E.</first> <last>Chapman</last></author>
      <author><first>Danielle L.</first> <last>Mowery</last></author>
      <author><first>Evan</first> <last>Narasimhan</last></author>
      <author><first>Neel</first> <last>Patel</last></author>
      <author><first>Wendy</first> <last>Chapman</last></author>
      <author><first>Marta</first> <last>Heilbrun</last></author>
      <pages>181–185</pages>
      <url hash="0312ee26">W16-2924</url>
      <doi>10.18653/v1/W16-2924</doi>
    </paper>
    <paper id="25">
      <title>Building a dictionary of lexical variants for phenotype descriptors</title>
      <author><first>Simon</first> <last>Kocbek</last></author>
      <author><first>Tudor</first> <last>Groza</last></author>
      <pages>186–190</pages>
      <url hash="dd9e8be4">W16-2925</url>
      <doi>10.18653/v1/W16-2925</doi>
    </paper>
    <paper id="26">
      <title>Applying deep learning on electronic health records in <fixed-case>S</fixed-case>wedish to predict healthcare-associated infections</title>
      <author><first>Olof</first> <last>Jacobson</last></author>
      <author><first>Hercules</first> <last>Dalianis</last></author>
      <pages>191–195</pages>
      <url hash="3e2bbce6">W16-2926</url>
      <doi>10.18653/v1/W16-2926</doi>
    </paper>
    <paper id="27">
      <title>Identifying First Episodes of Psychosis in Psychiatric Patient Records using Machine Learning</title>
      <author><first>Genevieve</first> <last>Gorrell</last></author>
      <author><first>Sherifat</first> <last>Oduola</last></author>
      <author><first>Angus</first> <last>Roberts</last></author>
      <author><first>Tom</first> <last>Craig</last></author>
      <author><first>Craig</first> <last>Morgan</last></author>
      <author><first>Rob</first> <last>Stewart</last></author>
      <pages>196–205</pages>
      <url hash="5494f034">W16-2927</url>
      <doi>10.18653/v1/W16-2927</doi>
    </paper>
    <paper id="28">
      <title>Relation extraction from clinical texts using domain invariant convolutional neural network</title>
      <author><first>Sunil</first> <last>Sahu</last></author>
      <author><first>Ashish</first> <last>Anand</last></author>
      <author><first>Krishnadev</first> <last>Oruganty</last></author>
      <author><first>Mahanandeeshwar</first> <last>Gattu</last></author>
      <pages>206–215</pages>
      <url hash="741d7bd9">W16-2928</url>
      <doi>10.18653/v1/W16-2928</doi>
    </paper>
  </volume>
  <volume id="30">
    <meta>
      <booktitle>Proceedings of the 4th <fixed-case>B</fixed-case>io<fixed-case>NLP</fixed-case> Shared Task Workshop</booktitle>
      <url hash="d6351653">W16-30</url>
      <editor><first>Claire</first><last>Nėdellec</last></editor>
      <editor><first>Robert</first><last>Bossy</last></editor>
      <editor><first>Jin-Dong</first><last>Kim</last></editor>
      <doi>10.18653/v1/W16-30</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="a5deb057">W16-3000</url>
    </frontmatter>
    <paper id="1">
      <title>Overview of the Regulatory Network of Plant Seed Development (<fixed-case>S</fixed-case>ee<fixed-case>D</fixed-case>ev) Task at the <fixed-case>B</fixed-case>io<fixed-case>NLP</fixed-case> Shared Task 2016.</title>
      <author><first>Estelle</first> <last>Chaix</last></author>
      <author><first>Bertrand</first> <last>Dubreucq</last></author>
      <author><first>Abdelhak</first> <last>Fatihi</last></author>
      <author><first>Dialekti</first> <last>Valsamou</last></author>
      <author><first>Robert</first> <last>Bossy</last></author>
      <author><first>Mouhamadou</first> <last>Ba</last></author>
      <author><first>Louise</first> <last>Deléger</last></author>
      <author><first>Pierre</first> <last>Zweigenbaum</last></author>
      <author><first>Philippe</first> <last>Bessières</last></author>
      <author><first>Loic</first> <last>Lepiniec</last></author>
      <author><first>Claire</first> <last>Nédellec</last></author>
      <pages>1–11</pages>
      <url hash="203b84fa">W16-3001</url>
      <doi>10.18653/v1/W16-3001</doi>
    </paper>
    <paper id="2">
      <title>Overview of the Bacteria Biotope Task at <fixed-case>B</fixed-case>io<fixed-case>NLP</fixed-case> Shared Task 2016</title>
      <author><first>Louise</first> <last>Deléger</last></author>
      <author><first>Robert</first> <last>Bossy</last></author>
      <author><first>Estelle</first> <last>Chaix</last></author>
      <author><first>Mouhamadou</first> <last>Ba</last></author>
      <author><first>Arnaud</first> <last>Ferré</last></author>
      <author><first>Philippe</first> <last>Bessières</last></author>
      <author><first>Claire</first> <last>Nédellec</last></author>
      <pages>12–22</pages>
      <url hash="cdf9ee6c">W16-3002</url>
      <doi>10.18653/v1/W16-3002</doi>
    </paper>
    <paper id="3">
      <title>Refactoring the <fixed-case>G</fixed-case>enia Event Extraction Shared Task Toward a General Framework for <fixed-case>IE</fixed-case>-Driven <fixed-case>KB</fixed-case> Development</title>
      <author><first>Jin-Dong</first> <last>Kim</last></author>
      <author><first>Yue</first> <last>Wang</last></author>
      <author><first>Nicola</first> <last>Colic</last></author>
      <author><first>Seung Han</first> <last>Beak</last></author>
      <author><first>Yong Hwan</first> <last>Kim</last></author>
      <author><first>Min</first> <last>Song</last></author>
      <pages>23–31</pages>
      <url hash="84aa1fc6">W16-3003</url>
      <doi>10.18653/v1/W16-3003</doi>
    </paper>
    <paper id="4">
      <title><fixed-case>L</fixed-case>it<fixed-case>W</fixed-case>ay, Discriminative Extraction for Different Bio-Events</title>
      <author><first>Chen</first> <last>Li</last></author>
      <author><first>Zhiqiang</first> <last>Rao</last></author>
      <author><first>Xiangrong</first> <last>Zhang</last></author>
      <pages>32–41</pages>
      <url hash="f08d2ee3">W16-3004</url>
      <doi>10.18653/v1/W16-3004</doi>
    </paper>
    <paper id="5">
      <title><fixed-case>VERSE</fixed-case>: Event and Relation Extraction in the <fixed-case>B</fixed-case>io<fixed-case>NLP</fixed-case> 2016 Shared Task</title>
      <author><first>Jake</first> <last>Lever</last></author>
      <author><first>Steven JM</first> <last>Jones</last></author>
      <pages>42–49</pages>
      <url hash="bfc6cc03">W16-3005</url>
      <doi>10.18653/v1/W16-3005</doi>
    </paper>
    <paper id="6">
      <title>A dictionary- and rule-based system for identification of bacteria and habitats in text</title>
      <author><first>Helen V</first> <last>Cook</last></author>
      <author><first>Evangelos</first> <last>Pafilis</last></author>
      <author><first>Lars Juhl</first> <last>Jensen</last></author>
      <pages>50–55</pages>
      <url hash="a321929f">W16-3006</url>
      <doi>10.18653/v1/W16-3006</doi>
    </paper>
    <paper id="7">
      <title>Ontology-Based Categorization of Bacteria and Habitat Entities using Information Retrieval Techniques</title>
      <author><first>Mert</first> <last>Tiftikci</last></author>
      <author><first>Hakan</first> <last>Şahin</last></author>
      <author><first>Berfu</first> <last>Büyüköz</last></author>
      <author><first>Alper</first> <last>Yayıkçı</last></author>
      <author><first>Arzucan</first> <last>Özgür</last></author>
      <pages>56–63</pages>
      <url hash="2796b774">W16-3007</url>
      <doi>10.18653/v1/W16-3007</doi>
    </paper>
    <paper id="8">
      <title>Identification of Mentions and Relations between Bacteria and Biotope from <fixed-case>P</fixed-case>ub<fixed-case>M</fixed-case>ed Abstracts</title>
      <author><first>Cyril</first> <last>Grouin</last></author>
      <pages>64–72</pages>
      <url hash="49bb2bee">W16-3008</url>
      <doi>10.18653/v1/W16-3008</doi>
    </paper>
    <paper id="9">
      <title>Deep Learning with Minimal Training Data: <fixed-case>T</fixed-case>urku<fixed-case>NLP</fixed-case> Entry in the <fixed-case>B</fixed-case>io<fixed-case>NLP</fixed-case> Shared Task 2016</title>
      <author><first>Farrokh</first> <last>Mehryary</last></author>
      <author><first>Jari</first> <last>Björne</last></author>
      <author><first>Sampo</first> <last>Pyysalo</last></author>
      <author><first>Tapio</first> <last>Salakoski</last></author>
      <author><first>Filip</first> <last>Ginter</last></author>
      <pages>73–81</pages>
      <url hash="981e596a">W16-3009</url>
      <doi>10.18653/v1/W16-3009</doi>
    </paper>
    <paper id="10">
      <title><fixed-case>S</fixed-case>ee<fixed-case>D</fixed-case>ev Binary Event Extraction using <fixed-case>SVM</fixed-case>s and a Rich Feature Set</title>
      <author><first>Nagesh</first> <last>C. Panyam</last></author>
      <author><first>Gitansh</first> <last>Khirbat</last></author>
      <author><first>Karin</first> <last>Verspoor</last></author>
      <author><first>Trevor</first> <last>Cohn</last></author>
      <author><first>Kotagiri</first> <last>Ramamohanarao</last></author>
      <pages>82–87</pages>
      <url hash="a7eef606">W16-3010</url>
      <doi>10.18653/v1/W16-3010</doi>
    </paper>
    <paper id="11">
      <title>Extraction of Regulatory Events using Kernel-based Classifiers and Distant Supervision</title>
      <author><first>Andre</first> <last>Lamurias</last></author>
      <author><first>Miguel J.</first> <last>Rodrigues</last></author>
      <author><first>Luka A.</first> <last>Clarke</last></author>
      <author><first>Francisco M.</first> <last>Couto</last></author>
      <pages>88–92</pages>
      <url hash="c8e2c059">W16-3011</url>
      <doi>10.18653/v1/W16-3011</doi>
    </paper>
    <paper id="12">
      <title><fixed-case>DUTIR</fixed-case> in <fixed-case>B</fixed-case>io<fixed-case>NLP</fixed-case>-<fixed-case>ST</fixed-case> 2016: Utilizing Convolutional Network and Distributed Representation to Extract Complicate Relations</title>
      <author><first>Honglei</first> <last>Li</last></author>
      <author><first>Jianhai</first> <last>Zhang</last></author>
      <author><first>Jian</first> <last>Wang</last></author>
      <author><first>Hongfei</first> <last>Lin</last></author>
      <author><first>Zhihao</first> <last>Yang</last></author>
      <pages>93–100</pages>
      <url hash="251668f5">W16-3012</url>
      <doi>10.18653/v1/W16-3012</doi>
    </paper>
    <paper id="13">
      <title>Extracting Biomedical Event Using Feature Selection and Word Representation</title>
      <author><first>Xinyu</first> <last>He</last></author>
      <author><first>Lishuang</first> <last>Li</last></author>
      <author><first>Jieqiong</first> <last>Zheng</last></author>
      <author><first>Meiyue</first> <last>Qin</last></author>
      <pages>101</pages>
      <url hash="ececbf10">W16-3013</url>
      <doi>10.18653/v1/W16-3013</doi>
    </paper>
  </volume>
  <volume id="31">
    <meta>
      <booktitle>Proceedings of the Fourth <fixed-case>B</fixed-case>io<fixed-case>ASQ</fixed-case> workshop</booktitle>
      <url hash="e6e6c182">W16-31</url>
      <editor><first>Ioannis A.</first><last>Kakadiaris</last></editor>
      <editor><first>George</first><last>Paliouras</last></editor>
      <editor><first>Anastasia</first><last>Krithara</last></editor>
      <doi>10.18653/v1/W16-31</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="1efea395">W16-3100</url>
    </frontmatter>
    <paper id="1">
      <title>Results of the 4th edition of <fixed-case>B</fixed-case>io<fixed-case>ASQ</fixed-case> Challenge</title>
      <author><first>Anastasia</first> <last>Krithara</last></author>
      <author><first>Anastasios</first> <last>Nentidis</last></author>
      <author><first>Georgios</first> <last>Paliouras</last></author>
      <author><first>Ioannis</first> <last>Kakadiaris</last></author>
      <pages>1–7</pages>
      <url hash="29638aeb">W16-3101</url>
      <doi>10.18653/v1/W16-3101</doi>
    </paper>
    <paper id="2">
      <title>Using Learning-To-Rank to Enhance <fixed-case>NLM</fixed-case> Medical Text Indexer Results</title>
      <author><first>Ilya</first> <last>Zavorin</last></author>
      <author><first>James</first> <last>Mork</last></author>
      <author><first>Dina</first> <last>Demner-Fushman</last></author>
      <pages>8–15</pages>
      <url hash="766f84fc">W16-3102</url>
      <doi>10.18653/v1/W16-3102</doi>
    </paper>
    <paper id="3">
      <title><fixed-case>LABDA</fixed-case> at the 2016 <fixed-case>B</fixed-case>io<fixed-case>ASQ</fixed-case> challenge task 4a: Semantic Indexing by using <fixed-case>E</fixed-case>lastic<fixed-case>S</fixed-case>earch</title>
      <author><first>Isabel</first> <last>Segura-Bedmar</last></author>
      <author><first>Adrián</first> <last>Carruana</last></author>
      <author><first>Paloma</first> <last>Martínez</last></author>
      <pages>16–22</pages>
      <url hash="4bf25ab9">W16-3103</url>
      <doi>10.18653/v1/W16-3103</doi>
    </paper>
    <paper id="4">
      <title>Learning to Answer Biomedical Questions: <fixed-case>OAQA</fixed-case> at <fixed-case>B</fixed-case>io<fixed-case>ASQ</fixed-case> 4<fixed-case>B</fixed-case></title>
      <author><first>Zi</first> <last>Yang</last></author>
      <author><first>Yue</first> <last>Zhou</last></author>
      <author><first>Eric</first> <last>Nyberg</last></author>
      <pages>23–37</pages>
      <url hash="5d8d47bc">W16-3104</url>
      <doi>10.18653/v1/W16-3104</doi>
    </paper>
    <paper id="5">
      <title><fixed-case>HPI</fixed-case> Question Answering System in <fixed-case>B</fixed-case>io<fixed-case>ASQ</fixed-case> 2016</title>
      <author><first>Frederik</first> <last>Schulze</last></author>
      <author><first>Ricarda</first> <last>Schüler</last></author>
      <author><first>Tim</first> <last>Draeger</last></author>
      <author><first>Daniel</first> <last>Dummer</last></author>
      <author><first>Alexander</first> <last>Ernst</last></author>
      <author><first>Pedro</first> <last>Flemming</last></author>
      <author><first>Cindy</first> <last>Perscheid</last></author>
      <author><first>Mariana</first> <last>Neves</last></author>
      <pages>38–44</pages>
      <url hash="0008ff35">W16-3105</url>
      <doi>10.18653/v1/W16-3105</doi>
    </paper>
    <paper id="6">
      <title><fixed-case>KSA</fixed-case>nswer: Question-answering System of Kangwon National University and Sogang University in the 2016 <fixed-case>B</fixed-case>io<fixed-case>ASQ</fixed-case> Challenge</title>
      <author><first>Hyeon-gu</first> <last>Lee</last></author>
      <author><first>Minkyoung</first> <last>Kim</last></author>
      <author><first>Harksoo</first> <last>Kim</last></author>
      <author><first>Juae</first> <last>Kim</last></author>
      <author><first>Sunjae</first> <last>Kwon</last></author>
      <author><first>Jungyun</first> <last>Seo</last></author>
      <author><first>Yi-reun</first> <last>Kim</last></author>
      <author><first>Jung-Kyu</first> <last>Choi</last></author>
      <pages>45–49</pages>
      <url hash="adde376c">W16-3106</url>
      <doi>10.18653/v1/W16-3106</doi>
    </paper>
    <paper id="7">
      <title>Large-Scale Semantic Indexing and Question Answering in Biomedicine</title>
      <author><first>Eirini</first> <last>Papagiannopoulou</last></author>
      <author><first>Yiannis</first> <last>Papanikolaou</last></author>
      <author><first>Dimitris</first> <last>Dimitriadis</last></author>
      <author><first>Sakis</first> <last>Lagopoulos</last></author>
      <author><first>Grigorios</first> <last>Tsoumakas</last></author>
      <author><first>Manos</first> <last>Laliotis</last></author>
      <author><first>Nikos</first> <last>Markantonatos</last></author>
      <author><first>Ioannis</first> <last>Vlahavas</last></author>
      <pages>50–54</pages>
      <url hash="f31a6d11">W16-3107</url>
      <doi>10.18653/v1/W16-3107</doi>
    </paper>
  </volume>
  <volume id="32">
    <meta>
      <booktitle>Proceedings of the 5th Workshop on Vision and Language</booktitle>
      <url hash="0218f4d3">W16-32</url>
      <editor><first>Anya</first><last>Belz</last></editor>
      <editor><first>Erkut</first><last>Erdem</last></editor>
      <editor><first>Krystian</first><last>Mikolajczyk</last></editor>
      <editor><first>Katerina</first><last>Pastra</last></editor>
      <doi>10.18653/v1/W16-32</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Berlin, Germany</address>
      <month>August</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="3b0e3159">W16-3200</url>
    </frontmatter>
    <paper id="1">
      <title>Automatic Annotation of Structured Facts in Images</title>
      <author><first>Mohamed</first> <last>Elhoseiny</last></author>
      <author><first>Scott</first> <last>Cohen</last></author>
      <author><first>Walter</first> <last>Chang</last></author>
      <author><first>Brian</first> <last>Price</last></author>
      <author><first>Ahmed</first> <last>Elgammal</last></author>
      <pages>1–9</pages>
      <url hash="5f6a0307">W16-3201</url>
      <doi>10.18653/v1/W16-3201</doi>
    </paper>
    <paper id="2">
      <title>Combining Lexical and Spatial Knowledge to Predict Spatial Relations between Objects in Images</title>
      <author><first>Manuela</first> <last>Hürlimann</last></author>
      <author><first>Johan</first> <last>Bos</last></author>
      <pages>10–18</pages>
      <url hash="857278a9">W16-3202</url>
      <doi>10.18653/v1/W16-3202</doi>
    </paper>
    <paper id="3">
      <title>Focused Evaluation for Image Description with Binary Forced-Choice Tasks</title>
      <author><first>Micah</first> <last>Hodosh</last></author>
      <author><first>Julia</first> <last>Hockenmaier</last></author>
      <pages>19–28</pages>
      <url hash="732868c0">W16-3203</url>
      <doi>10.18653/v1/W16-3203</doi>
    </paper>
    <paper id="4">
      <title>Leveraging Captions in the Wild to Improve Object Detection</title>
      <author><first>Mert</first> <last>Kilickaya</last></author>
      <author><first>Nazli</first> <last>Ikizler-Cinbis</last></author>
      <author><first>Erkut</first> <last>Erdem</last></author>
      <author><first>Aykut</first> <last>Erdem</last></author>
      <pages>29–38</pages>
      <url hash="d4c12677">W16-3204</url>
      <doi>10.18653/v1/W16-3204</doi>
    </paper>
    <paper id="5">
      <title>Natural Language Descriptions of Human Activities Scenes: Corpus Generation and Analysis</title>
      <author><first>Nouf</first> <last>Alharbi</last></author>
      <author><first>Yoshihiko</first> <last>Gotoh</last></author>
      <pages>39–47</pages>
      <url hash="eaf9c37c">W16-3205</url>
      <doi>10.18653/v1/W16-3205</doi>
    </paper>
    <paper id="6">
      <title>Interactively Learning Visually Grounded Word Meanings from a Human Tutor</title>
      <author><first>Yanchao</first> <last>Yu</last></author>
      <author><first>Arash</first> <last>Eshghi</last></author>
      <author><first>Oliver</first> <last>Lemon</last></author>
      <pages>48–53</pages>
      <url hash="c9f53b45">W16-3206</url>
      <doi>10.18653/v1/W16-3206</doi>
    </paper>
    <paper id="7">
      <title>Pragmatic Factors in Image Description: The Case of Negations</title>
      <author><first>Emiel</first> <last>van Miltenburg</last></author>
      <author><first>Roser</first> <last>Morante</last></author>
      <author><first>Desmond</first> <last>Elliott</last></author>
      <pages>54–59</pages>
      <url hash="18eab334">W16-3207</url>
      <doi>10.18653/v1/W16-3207</doi>
    </paper>
    <paper id="8">
      <title>Building a Bagpipe with a Bag and a Pipe: Exploring Conceptual Combination in Vision</title>
      <author><first>Sandro</first> <last>Pezzelle</last></author>
      <author><first>Ravi</first> <last>Shekhar</last></author>
      <author><first>Raffaella</first> <last>Bernardi</last></author>
      <pages>60–64</pages>
      <url hash="b8cabc17">W16-3208</url>
      <doi>10.18653/v1/W16-3208</doi>
    </paper>
    <paper id="9">
      <title>Exploring Different Preposition Sets, Models and Feature Sets in Automatic Generation of Spatial Image Descriptions</title>
      <author><first>Anja</first> <last>Belz</last></author>
      <author><first>Adrian</first> <last>Muscat</last></author>
      <author><first>Brandon</first> <last>Birmingham</last></author>
      <pages>65–69</pages>
      <url hash="6ff2b50f">W16-3209</url>
      <doi>10.18653/v1/W16-3209</doi>
    </paper>
    <paper id="10">
      <title><fixed-case>M</fixed-case>ulti30<fixed-case>K</fixed-case>: Multilingual <fixed-case>E</fixed-case>nglish-<fixed-case>G</fixed-case>erman Image Descriptions</title>
      <author><first>Desmond</first> <last>Elliott</last></author>
      <author><first>Stella</first> <last>Frank</last></author>
      <author><first>Khalil</first> <last>Sima’an</last></author>
      <author><first>Lucia</first> <last>Specia</last></author>
      <pages>70–74</pages>
      <url hash="db735aa0">W16-3210</url>
      <doi>10.18653/v1/W16-3210</doi>
    </paper>
    <paper id="11">
      <title>“Look, some Green Circles!”: Learning to Quantify from Images</title>
      <author><first>Ionut</first> <last>Sorodoc</last></author>
      <author><first>Angeliki</first> <last>Lazaridou</last></author>
      <author><first>Gemma</first> <last>Boleda</last></author>
      <author><first>Aurélie</first> <last>Herbelot</last></author>
      <author><first>Sandro</first> <last>Pezzelle</last></author>
      <author><first>Raffaella</first> <last>Bernardi</last></author>
      <pages>75–79</pages>
      <url hash="c844381c">W16-3211</url>
      <doi>10.18653/v1/W16-3211</doi>
    </paper>
    <paper id="12">
      <title><fixed-case>T</fixed-case>ext2voronoi: An Image-driven Approach to Differential Diagnosis</title>
      <author><first>Alexander</first> <last>Mehler</last></author>
      <author><first>Tolga</first> <last>Uslu</last></author>
      <author><first>Wahed</first> <last>Hemati</last></author>
      <pages>80–85</pages>
      <url hash="853c184f">W16-3212</url>
      <doi>10.18653/v1/W16-3212</doi>
    </paper>
    <paper id="13">
      <title>Detecting Visually Relevant Sentences for Fine-Grained Classification</title>
      <author><first>Olivia</first> <last>Winn</last></author>
      <author><first>Madhavan Kavanur</first> <last>Kidambi</last></author>
      <author><first>Smaranda</first> <last>Muresan</last></author>
      <pages>86–91</pages>
      <url hash="41be7b7d">W16-3213</url>
      <doi>10.18653/v1/W16-3213</doi>
    </paper>
  </volume>
  <volume id="33">
    <meta>
      <booktitle>Proceedings of the 12th International Workshop on Tree Adjoining Grammars and Related Formalisms (<fixed-case>TAG</fixed-case>+12)</booktitle>
      <url hash="aee408f9">W16-33</url>
      <editor><first>David</first> <last>Chiang</last></editor>
      <editor><first>Alexander</first> <last>Koller</last></editor>
      <address>Düsseldorf, Germany</address>
      <month>June</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="ed1b3274">W16-3300</url>
    </frontmatter>
    <paper id="1">
      <title>Coordination in <fixed-case>M</fixed-case>inimalist <fixed-case>G</fixed-case>rammars: Excorporation and Across the Board (Head) Movement</title>
      <author><first>John</first> <last>Torr</last></author>
      <author><first>Edward P.</first> <last>Stabler</last></author>
      <pages>1–17</pages>
      <url hash="0964c3a3">W16-3301</url>
    </paper>
    <paper id="2">
      <title><fixed-case>A</fixed-case>rab<fixed-case>TAG</fixed-case>: from a Handcrafted to a Semi-automatically Generated <fixed-case>TAG</fixed-case></title>
      <author><first>Chérifa</first> <last>Ben Khelil</last></author>
      <author><first>Denys</first> <last>Duchier</last></author>
      <author><first>Yannick</first> <last>Parmentier</last></author>
      <author><first>Chiraz</first> <last>Zribi</last></author>
      <author><first>Fériel</first> <last>Ben Fraj</last></author>
      <pages>18–26</pages>
      <url hash="f29df071">W16-3302</url>
    </paper>
    <paper id="3">
      <title>Interfacing Sentential and Discourse <fixed-case>TAG</fixed-case>-based Grammars</title>
      <author><first>Laurence</first> <last>Danlos</last></author>
      <author><first>Aleksandre</first> <last>Maskharashvili</last></author>
      <author><first>Sylvain</first> <last>Pogodalla</last></author>
      <pages>27–37</pages>
      <url hash="697b018f">W16-3303</url>
    </paper>
    <paper id="4">
      <title>Modelling Discourse in <fixed-case>STAG</fixed-case>: Subordinate Conjunctions and Attributing Phrases</title>
      <author><first>Timothée</first> <last>Bernard</last></author>
      <author><first>Laurence</first> <last>Danlos</last></author>
      <pages>38–47</pages>
      <url hash="44fc659d">W16-3304</url>
    </paper>
    <paper id="5">
      <title>Argument linking in <fixed-case>LTAG</fixed-case>: A constraint-based implementation with <fixed-case>XMG</fixed-case></title>
      <author><first>Laura</first> <last>Kallmeyer</last></author>
      <author><first>Timm</first> <last>Lichte</last></author>
      <author><first>Rainer</first> <last>Osswald</last></author>
      <author><first>Simon</first> <last>Petitjean</last></author>
      <pages>48–57</pages>
      <url hash="1affe68e">W16-3305</url>
    </paper>
    <paper id="6">
      <title>Verbal fields in <fixed-case>H</fixed-case>ungarian simple sentences and infinitival clausal complements</title>
      <author><first>Kata</first> <last>Balogh</last></author>
      <pages>58–66</pages>
      <url hash="2f40a0f0">W16-3306</url>
    </paper>
    <paper id="7">
      <title>Modelling the ziji Blocking Effect and Constraining Bound Variable Derivations in <fixed-case>MC</fixed-case>-<fixed-case>TAG</fixed-case> with Delayed Locality</title>
      <author><first>Dennis Ryan</first> <last>Storoshenko</last></author>
      <pages>67–76</pages>
      <url hash="cc711ac7">W16-3307</url>
    </paper>
    <paper id="8">
      <title>Node-based Induction of Tree-Substitution Grammars</title>
      <author><first>Rose</first> <last>Sloan</last></author>
      <pages>77–84</pages>
      <url hash="8c2e06af">W16-3308</url>
    </paper>
    <paper id="9">
      <title>Revisiting Supertagging and Parsing: How to Use Supertags in Transition-Based Parsing</title>
      <author><first>Wonchang</first> <last>Chung</last></author>
      <author><first>Suhas Siddhesh</first> <last>Mhatre</last></author>
      <author><first>Alexis</first> <last>Nasr</last></author>
      <author><first>Owen</first> <last>Rambow</last></author>
      <author><first>Srinivas</first> <last>Bangalore</last></author>
      <pages>85–92</pages>
      <url hash="98de0fc9">W16-3309</url>
    </paper>
    <paper id="10">
      <title>An Alternate View on Strong Lexicalization in <fixed-case>TAG</fixed-case></title>
      <author><first>Aniello</first> <last>De Santo</last></author>
      <author><first>Alëna</first> <last>Aksënova</last></author>
      <author><first>Thomas</first> <last>Graf</last></author>
      <pages>93–102</pages>
      <url hash="0a6dba49">W16-3310</url>
    </paper>
    <paper id="11">
      <title>Hyperedge Replacement and Nonprojective Dependency Structures</title>
      <author><first>Daniel</first> <last>Bauer</last></author>
      <author><first>Owen</first> <last>Rambow</last></author>
      <pages>103–111</pages>
      <url hash="242e0a8e">W16-3311</url>
    </paper>
    <paper id="12">
      <title>Parasitic Gaps and the Heterogeneity of Dependency Formation in <fixed-case>STAG</fixed-case></title>
      <author><first>Dennis Ryan</first> <last>Storoshenko</last></author>
      <author><first>Robert</first> <last>Frank</last></author>
      <pages>112–120</pages>
      <url hash="5c1f0268">W16-3312</url>
    </paper>
  </volume>
  <volume id="34">
    <meta>
      <booktitle>Proceedings of the 19th Annual Conference of the <fixed-case>E</fixed-case>uropean Association for Machine Translation</booktitle>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="c1df18f2">W16-3400</url>
    </frontmatter>
    <paper id="1">
      <title>Patterns of Terminological Variation in Post-editing and of Cognate Use in Machine Translation in Contrast to Human Translation</title>
      <author><first>Oliver</first><last>Čulo</last></author>
      <author><first>Jean</first><last>Nitzke</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>106-114</pages>
      <url hash="ec276228">W16-3401</url>
    </paper>
    <paper id="2">
      <title>Graphonological <fixed-case>L</fixed-case>evenshtein Edit Distance: Application for Automated Cognate Identification</title>
      <author><first>Bogdan</first><last>Babych</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>115-128</pages>
      <url hash="af0cd04d">W16-3402</url>
    </paper>
    <paper id="3">
      <title>Improving Phrase-Based <fixed-case>SMT</fixed-case> Using Cross-Granularity Embedding Similarity</title>
      <author><first>Peyman</first><last>Passban</last></author>
      <author><first>Chris</first><last>Hokamp</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>129-140</pages>
      <url hash="9ef3dc00">W16-3403</url>
    </paper>
    <paper id="4">
      <title>Comparing Translator Acceptability of <fixed-case>TM</fixed-case> and <fixed-case>SMT</fixed-case> Outputs</title>
      <author><first>Joss</first><last>Moorkens</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>141-151</pages>
      <url hash="8c10ef6f">W16-3404</url>
    </paper>
    <paper id="5">
      <title>Stand-off Annotation of Web Content as a Legally Safer Alternative to Crawling for Distribution</title>
      <author><first>Mikel L.</first><last>Forcada</last></author>
      <author><first>Miquel</first><last>Esplà-Gomis</last></author>
      <author><first>Juan Antonio</first><last>Pérez-Ortiz</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>152-164</pages>
      <url hash="f5525e19">W16-3405</url>
    </paper>
    <paper id="6">
      <title>Combining Translation Memories and Syntax-Based <fixed-case>SMT</fixed-case>: Experiments with Real Industrial Data</title>
      <author><first>Liangyou</first><last>Li</last></author>
      <author><first>Carla Parra</first><last>Escartin</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>165-177</pages>
      <url hash="21185583">W16-3406</url>
    </paper>
    <paper id="7">
      <title>The Trouble with Machine Translation Coherence</title>
      <author><first>Karin Sim</first><last>Smith</last></author>
      <author><first>Wilker</first><last>Aziz</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>178-189</pages>
      <url hash="a492357f">W16-3407</url>
    </paper>
    <paper id="8">
      <title>Pivoting Methods and Data for <fixed-case>C</fixed-case>zech-<fixed-case>V</fixed-case>ietnamese Translation via <fixed-case>E</fixed-case>nglish</title>
      <author><first>Duc Tam</first><last>Hoang</last></author>
      <author><first>Ondrej</first><last>Bojar</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>190-202</pages>
      <url hash="35ee6398">W16-3408</url>
    </paper>
    <paper id="9">
      <title>Detecting Grammatical Errors in Machine Translation Output Using Dependency Parsing and Treebank Querying</title>
      <author><first>Arda</first><last>Tezcan</last></author>
      <author><first>Veronique</first><last>Hoste</last></author>
      <author><first>Lieve</first><last>Macken</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>203-217</pages>
      <url hash="45a2b2c0">W16-3409</url>
    </paper>
    <paper id="10">
      <title>Potential and Limits of Using Post-edits as Reference Translations for <fixed-case>MT</fixed-case> Evaluation</title>
      <author><first>Maja</first><last>Popovic</last></author>
      <author><first>Mihael</first><last>Arčan</last></author>
      <author><first>Arle</first><last>Lommel</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>218-229</pages>
      <url hash="c00fffab">W16-3410</url>
    </paper>
    <paper id="11">
      <title>Can Text Simplification Help Machine Translation?</title>
      <author><first>Sanja</first><last>Štajner</last></author>
      <author><first>Maja</first><last>Popovic</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>230-242</pages>
      <url hash="1a5a0fd3">W16-3411</url>
    </paper>
    <paper id="12">
      <title>A Portable Method for Parallel and Comparable Document Alignment</title>
      <author><first>Thierry</first><last>Etchegoyhen</last></author>
      <author><first>Andoni</first><last>Azpeitia</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>243-255</pages>
      <url hash="865d1827">W16-3412</url>
    </paper>
    <paper id="13">
      <title>Semantic Textual Similarity in Quality Estimation</title>
      <author><first>Hanna</first><last>Bechara</last></author>
      <author><first>Carla Parra</first><last>Escartin</last></author>
      <author><first>Constantin</first><last>Orasan</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>256-268</pages>
      <url hash="3e909cc1">W16-3413</url>
    </paper>
    <paper id="14">
      <title>Climbing Mont <fixed-case>BLEU</fixed-case>: The Strange World of Reachable High-<fixed-case>BLEU</fixed-case> Translations</title>
      <author><first>Aaron</first><last>Smith</last></author>
      <author><first>Christian</first><last>Hardmeier</last></author>
      <author><first>Joerg</first><last>Tiedemann</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>269-281</pages>
      <url hash="58d64522">W16-3414</url>
    </paper>
    <paper id="15">
      <title>Interactive-Predictive Translation Based on Multiple Word-Segments</title>
      <author><first>Miguel</first><last>Domingo</last></author>
      <author><first>Alvaro</first><last>Peris</last></author>
      <author><first>Francisco</first><last>Casacuberta</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>282-291</pages>
      <url hash="98d4018c">W16-3415</url>
    </paper>
    <paper id="16">
      <title>A Contextual Language Model to Improve Machine Translation of Pronouns by Re-ranking Translation Hypotheses</title>
      <author><first>Ngoc Quang</first><last>Luong</last></author>
      <author><first>Andrei</first><last>Popescu-Belis</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>292-304</pages>
      <url hash="351d0f76">W16-3416</url>
    </paper>
    <paper id="17">
      <title>Predicting and Using Implicit Discourse Elements in <fixed-case>C</fixed-case>hinese-<fixed-case>E</fixed-case>nglish Translation</title>
      <author><first>David</first><last>Steele</last></author>
      <author><first>Lucia</first><last>Specia</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>305-317</pages>
      <url hash="beb0656c">W16-3417</url>
    </paper>
    <paper id="18">
      <title>A Graphical Pronoun Analysis Tool for the <fixed-case>PROTEST</fixed-case> Pronoun Evaluation Test Suite</title>
      <author><first>Christian</first><last>Hardmeier</last></author>
      <author><first>Liane</first><last>Guillou</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>318-330</pages>
      <url hash="7ffe1de9">W16-3418</url>
    </paper>
    <paper id="19">
      <title>Measuring Cognitive Translation Effort with Activity Units</title>
      <author><first>Moritz Jonas</first><last>Schaeffer</last></author>
      <author><first>Michael</first><last>Carl</last></author>
      <author><first>Isabel</first><last>Lacruz</last></author>
      <author><first>Akiko</first><last>Aizawa</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>331-34195</pages>
      <url hash="9625dfab">W16-3419</url>
    </paper>
    <paper id="20">
      <title>A Comparative Study of Post-editing Guidelines</title>
      <author><first>Ke</first><last>Hu</last></author>
      <author><first>Patrick</first><last>Cadwell</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>34206-353</pages>
      <url hash="0c8a572d">W16-3420</url>
    </paper>
    <paper id="21">
      <title>Dealing with Data Sparseness in <fixed-case>SMT</fixed-case> with Factured Models and Morphological Expansion: a Case Study on <fixed-case>C</fixed-case>roatian</title>
      <author><first>Victor M.</first><last>Sánchez-Cartagena</last></author>
      <author><first>Nikola</first><last>Ljubešić</last></author>
      <author><first>Filip</first><last>Klubička</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>354-360</pages>
      <url hash="035e4957">W16-3421</url>
    </paper>
    <paper id="22">
      <title>Collaborative Development of a Rule-Based Machine Translator between <fixed-case>C</fixed-case>roatian and <fixed-case>S</fixed-case>erbian</title>
      <author><first>Filip</first><last>Klubička</last></author>
      <author><first>Gema</first><last>Ramírez-Sánchez</last></author>
      <author><first>Nikola</first><last>Ljubešić</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>361-367</pages>
      <url hash="128e8778">W16-3422</url>
    </paper>
    <paper id="23">
      <title>Re-assessing the Impact of <fixed-case>SMT</fixed-case> Techniques with Human Evaluation: a Case Study on <fixed-case>E</fixed-case>nglish—<fixed-case>C</fixed-case>roatian</title>
      <author><first>Antonio</first><last>Toral</last></author>
      <author><first>Raphael</first><last>Rubino</last></author>
      <author><first>Gema</first><last>Ramírez-Sánchez</last></author>
      <journal>Baltic Journal of Modern Computing</journal>
      <issue>2</issue>
      <pages>368-375</pages>
      <url hash="8f6ff62c">W16-3423</url>
    </paper>
  </volume>
  <volume id="35">
    <meta>
      <booktitle>Proceedings of the 2nd International Workshop on Natural Language Generation and the Semantic Web (<fixed-case>W</fixed-case>eb<fixed-case>NLG</fixed-case> 2016)</booktitle>
      <url hash="7f9a9504">W16-35</url>
      <editor><first>Claire</first><last>Gardent</last></editor>
      <editor><first>Aldo</first><last>Gangemi</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Edinburgh, Scotland</address>
      <month>September</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="efe4feac">W16-3500</url>
    </frontmatter>
    <paper id="1">
      <title>Generating sets of related sentences from input seed features</title>
      <author><first>Cristina</first><last>Barros</last></author>
      <author><first>Elena</first><last>Lloret</last></author>
      <pages>1–4</pages>
      <url hash="4bfa8d9c">W16-3501</url>
    </paper>
    <paper id="2">
      <title>A Repository of Frame Instance Lexicalizations for Generation</title>
      <author><first>Valerio</first><last>Basile</last></author>
      <pages>5–12</pages>
      <url hash="585cbd15">W16-3502</url>
      <attachment type="dataset" hash="7dc24798">W16-3502.Datasets.zip</attachment>
    </paper>
    <paper id="3">
      <title>Processing Document Collections to Automatically Extract Linked Data: Semantic Storytelling Technologies for Smart Curation Workflows</title>
      <author><first>Peter</first><last>Bourgonje</last></author>
      <author><first>Julian</first><last>Moreno Schneider</last></author>
      <author><first>Georg</first><last>Rehm</last></author>
      <author><first>Felix</first><last>Sasaki</last></author>
      <pages>13–16</pages>
      <url hash="08b6ac96">W16-3503</url>
    </paper>
    <paper id="4">
      <title>On the Robustness of Standalone Referring Expression Generation Algorithms Using <fixed-case>RDF</fixed-case> Data</title>
      <author><first>Pablo</first><last>Duboue</last></author>
      <author><first>Martin Ariel</first><last>Domínguez</last></author>
      <author><first>Paula</first><last>Estrella</last></author>
      <pages>17–24</pages>
      <url hash="649f1047">W16-3504</url>
      <attachment type="dataset" hash="37da4270">W16-3504.Datasets.zip</attachment>
    </paper>
    <paper id="5">
      <title>Content Selection through Paraphrase Detection: Capturing different Semantic Realisations of the Same Idea</title>
      <author><first>Elena</first><last>Lloret</last></author>
      <author><first>Claire</first><last>Gardent</last></author>
      <pages>25–28</pages>
      <url hash="dcab4f20">W16-3505</url>
    </paper>
    <paper id="6">
      <title>Aligning Texts and Knowledge Bases with Semantic Sentence Simplification</title>
      <author><first>Yassine</first><last>Mrabet</last></author>
      <author><first>Pavlos</first><last>Vougiouklis</last></author>
      <author><first>Halil</first><last>Kilicoglu</last></author>
      <author><first>Claire</first><last>Gardent</last></author>
      <author><first>Dina</first><last>Demner-Fushman</last></author>
      <author><first>Jonathon</first><last>Hare</last></author>
      <author><first>Elena</first><last>Simperl</last></author>
      <pages>29–36</pages>
      <url hash="8a2caca2">W16-3506</url>
      <attachment type="dataset" hash="a0d0ae02">W16-3506.Datasets.zip</attachment>
    </paper>
    <paper id="7">
      <title>Building a System for Stock News Generation in <fixed-case>R</fixed-case>ussian</title>
      <author><first>Liubov</first><last>Nesterenko</last></author>
      <pages>37–40</pages>
      <url hash="7ecae007">W16-3507</url>
    </paper>
    <paper id="8">
      <title>Content selection as semantic-based ontology exploration</title>
      <author><first>Laura</first><last>Perez-Beltrachini</last></author>
      <author><first>Claire</first><last>Gardent</last></author>
      <author><first>Anselme</first><last>Revuz</last></author>
      <author><first>Saptarashmi</first><last>Bandyopadhyay</last></author>
      <pages>41–45</pages>
      <url hash="482ba079">W16-3508</url>
    </paper>
    <paper id="9">
      <title><fixed-case>R</fixed-case>ead<fixed-case>ME</fixed-case> generation from an <fixed-case>OWL</fixed-case> ontology describing <fixed-case>NLP</fixed-case> tools</title>
      <author><first>Driss</first><last>Sadoun</last></author>
      <author><first>Satenik</first><last>Mkhitaryan</last></author>
      <author><first>Damien</first><last>Nouvel</last></author>
      <author><first>Mathieu</first><last>Valette</last></author>
      <pages>46–49</pages>
      <url hash="4ba8c721">W16-3509</url>
    </paper>
    <paper id="10">
      <title>Comparing the Template-Based Approach to <fixed-case>GF</fixed-case>: the case of <fixed-case>A</fixed-case>frikaans</title>
      <author><first>Lauren</first><last>Sanby</last></author>
      <author><first>Ion</first><last>Todd</last></author>
      <author><first>Maria C.</first><last>Keet</last></author>
      <pages>50–53</pages>
      <url hash="d8bd26e1">W16-3510</url>
    </paper>
    <paper id="11">
      <title>Generating Paraphrases from <fixed-case>DBP</fixed-case>edia using Deep Learning</title>
      <author><first>Amin</first><last>Sleimi</last></author>
      <author><first>Claire</first><last>Gardent</last></author>
      <pages>54–57</pages>
      <url hash="8760c7cf">W16-3511</url>
    </paper>
    <paper id="12">
      <title>Automatic Tweet Generation From Traffic Incident Data</title>
      <author><first>Khoa</first><last>Tran</last></author>
      <author><first>Fred</first><last>Popowich</last></author>
      <pages>59–66</pages>
      <url hash="61a196c8">W16-3512</url>
    </paper>
    <paper id="13">
      <title>Analysing the Integration of Semantic Web Features for Document Planning across Genres</title>
      <author><first>Marta</first><last>Vicente</last></author>
      <author><first>Elena</first><last>Lloret</last></author>
      <pages>67–70</pages>
      <url hash="c6b6b1ca">W16-3513</url>
    </paper>
  </volume>
  <volume id="36">
    <meta>
      <booktitle>Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue</booktitle>
      <url hash="9e9eb5b8">W16-36</url>
      <editor><first>Raquel</first><last>Fernandez</last></editor>
      <editor><first>Wolfgang</first><last>Minker</last></editor>
      <editor><first>Giuseppe</first><last>Carenini</last></editor>
      <editor><first>Ryuichiro</first><last>Higashinaka</last></editor>
      <editor><first>Ron</first><last>Artstein</last></editor>
      <editor><first>Alesia</first><last>Gainer</last></editor>
      <doi>10.18653/v1/W16-36</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Los Angeles</address>
      <month>September</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="62fcdc64">W16-3600</url>
    </frontmatter>
    <paper id="1">
      <title>Towards End-to-End Learning for Dialog State Tracking and Management using Deep Reinforcement Learning</title>
      <author><first>Tiancheng</first> <last>Zhao</last></author>
      <author><first>Maxine</first> <last>Eskenazi</last></author>
      <pages>1–10</pages>
      <url hash="3f792b74">W16-3601</url>
      <doi>10.18653/v1/W16-3601</doi>
    </paper>
    <paper id="2">
      <title>Task Lineages: Dialog State Tracking for Flexible Interaction</title>
      <author><first>Sungjin</first> <last>Lee</last></author>
      <author><first>Amanda</first> <last>Stent</last></author>
      <pages>11–21</pages>
      <url hash="9e1a136a">W16-3602</url>
      <doi>10.18653/v1/W16-3602</doi>
    </paper>
    <paper id="3">
      <title>Joint Online Spoken Language Understanding and Language Modeling With Recurrent Neural Networks</title>
      <author><first>Bing</first> <last>Liu</last></author>
      <author><first>Ian</first> <last>Lane</last></author>
      <pages>22–30</pages>
      <url hash="60bc31ee">W16-3603</url>
      <doi>10.18653/v1/W16-3603</doi>
    </paper>
    <paper id="4">
      <title>Creating and Characterizing a Diverse Corpus of Sarcasm in Dialogue</title>
      <author><first>Shereen</first> <last>Oraby</last></author>
      <author><first>Vrindavan</first> <last>Harrison</last></author>
      <author><first>Lena</first> <last>Reed</last></author>
      <author><first>Ernesto</first> <last>Hernandez</last></author>
      <author><first>Ellen</first> <last>Riloff</last></author>
      <author><first>Marilyn</first> <last>Walker</last></author>
      <pages>31–41</pages>
      <url hash="eae71aea">W16-3604</url>
      <doi>10.18653/v1/W16-3604</doi>
    </paper>
    <paper id="5">
      <title>The <fixed-case>SENSEI</fixed-case> Annotated Corpus: Human Summaries of Reader Comment Conversations in On-line News</title>
      <author><first>Emma</first> <last>Barker</last></author>
      <author><first>Monica Lestari</first> <last>Paramita</last></author>
      <author><first>Ahmet</first> <last>Aker</last></author>
      <author><first>Emina</first> <last>Kurtic</last></author>
      <author><first>Mark</first> <last>Hepple</last></author>
      <author><first>Robert</first> <last>Gaizauskas</last></author>
      <pages>42–52</pages>
      <url hash="7f6b62df">W16-3605</url>
      <doi>10.18653/v1/W16-3605</doi>
    </paper>
    <paper id="6">
      <title>Special Session - The Future Directions of Dialogue-Based Intelligent Personal Assistants</title>
      <author><first>Yoichi</first> <last>Matsuyama</last></author>
      <author><first>Alexandros</first> <last>Papangelis</last></author>
      <pages>53</pages>
      <url hash="74cd85f5">W16-3606</url>
      <doi>10.18653/v1/W16-3606</doi>
    </paper>
    <paper id="7">
      <title>Keynote - More than meets the ear: Processes that shape dialogue</title>
      <author><first>Susan</first> <last>Brennan</last></author>
      <pages>54</pages>
      <url hash="0fb28a43">W16-3607</url>
      <doi>10.18653/v1/W16-3607</doi>
    </paper>
    <paper id="8">
      <title>A <fixed-case>W</fixed-case>izard-of-<fixed-case>O</fixed-case>z Study on A Non-Task-Oriented Dialog Systems That Reacts to User Engagement</title>
      <author><first>Zhou</first> <last>Yu</last></author>
      <author><first>Leah</first> <last>Nicolich-Henkin</last></author>
      <author><first>Alan W</first> <last>Black</last></author>
      <author><first>Alexander</first> <last>Rudnicky</last></author>
      <pages>55–63</pages>
      <url hash="5aa2cb60">W16-3608</url>
      <doi>10.18653/v1/W16-3608</doi>
    </paper>
    <paper id="9">
      <title>Classifying Emotions in Customer Support Dialogues in Social Media</title>
      <author><first>Jonathan</first> <last>Herzig</last></author>
      <author><first>Guy</first> <last>Feigenblat</last></author>
      <author><first>Michal</first> <last>Shmueli-Scheuer</last></author>
      <author><first>David</first> <last>Konopnicki</last></author>
      <author><first>Anat</first> <last>Rafaeli</last></author>
      <author><first>Daniel</first> <last>Altman</last></author>
      <author><first>David</first> <last>Spivak</last></author>
      <pages>64–73</pages>
      <url hash="058956a3">W16-3609</url>
      <doi>10.18653/v1/W16-3609</doi>
    </paper>
    <paper id="10">
      <title>Cultural Communication Idiosyncrasies in Human-Computer Interaction</title>
      <author><first>Juliana</first> <last>Miehle</last></author>
      <author><first>Koichiro</first> <last>Yoshino</last></author>
      <author><first>Louisa</first> <last>Pragst</last></author>
      <author><first>Stefan</first> <last>Ultes</last></author>
      <author><first>Satoshi</first> <last>Nakamura</last></author>
      <author><first>Wolfgang</first> <last>Minker</last></author>
      <pages>74–79</pages>
      <url hash="2cfd19ae">W16-3610</url>
      <doi>10.18653/v1/W16-3610</doi>
    </paper>
    <paper id="11">
      <title>Using phone features to improve dialogue state tracking generalisation to unseen states</title>
      <author><first>Iñigo</first> <last>Casanueva</last></author>
      <author><first>Thomas</first> <last>Hain</last></author>
      <author><first>Mauro</first> <last>Nicolao</last></author>
      <author><first>Phil</first> <last>Green</last></author>
      <pages>80–89</pages>
      <url hash="92f3ff03">W16-3611</url>
      <doi>10.18653/v1/W16-3611</doi>
    </paper>
    <paper id="12">
      <title>Character Identification on Multiparty Conversation: Identifying Mentions of Characters in <fixed-case>TV</fixed-case> Shows</title>
      <author><first>Yu-Hsin</first> <last>Chen</last></author>
      <author><first>Jinho D.</first> <last>Choi</last></author>
      <pages>90–100</pages>
      <url hash="b0b0de8a">W16-3612</url>
      <doi>10.18653/v1/W16-3612</doi>
    </paper>
    <paper id="13">
      <title>Policy Networks with Two-Stage Training for Dialogue Systems</title>
      <author><first>Mehdi</first> <last>Fatemi</last></author>
      <author><first>Layla</first> <last>El Asri</last></author>
      <author><first>Hannes</first> <last>Schulz</last></author>
      <author><first>Jing</first> <last>He</last></author>
      <author><first>Kaheer</first> <last>Suleman</last></author>
      <pages>101–110</pages>
      <url hash="a6e194d7">W16-3613</url>
      <doi>10.18653/v1/W16-3613</doi>
    </paper>
    <paper id="14">
      <title>Language Portability for Dialogue Systems: Translating a Question-Answering System from <fixed-case>E</fixed-case>nglish into <fixed-case>T</fixed-case>amil</title>
      <author><first>Satheesh</first> <last>Ravi</last></author>
      <author><first>Ron</first> <last>Artstein</last></author>
      <pages>111–116</pages>
      <url hash="ab4d9d2f">W16-3614</url>
      <doi>10.18653/v1/W16-3614</doi>
    </paper>
    <paper id="15">
      <title>Extracting <fixed-case>PDTB</fixed-case> Discourse Relations from Student Essays</title>
      <author><first>Kate</first> <last>Forbes-Riley</last></author>
      <author><first>Fan</first> <last>Zhang</last></author>
      <author><first>Diane</first> <last>Litman</last></author>
      <pages>117–127</pages>
      <url hash="26aaf3d6">W16-3615</url>
      <doi>10.18653/v1/W16-3615</doi>
    </paper>
    <paper id="16">
      <title>Empirical comparison of dependency conversions for <fixed-case>RST</fixed-case> discourse trees</title>
      <author><first>Katsuhiko</first> <last>Hayashi</last></author>
      <author><first>Tsutomu</first> <last>Hirao</last></author>
      <author><first>Masaaki</first> <last>Nagata</last></author>
      <pages>128–136</pages>
      <url hash="370bea80">W16-3616</url>
      <doi>10.18653/v1/W16-3616</doi>
    </paper>
    <paper id="17">
      <title>The Role of Discourse Units in Near-Extractive Summarization</title>
      <author><first>Junyi Jessy</first> <last>Li</last></author>
      <author><first>Kapil</first> <last>Thadani</last></author>
      <author><first>Amanda</first> <last>Stent</last></author>
      <pages>137–147</pages>
      <url hash="c7bbfacb">W16-3617</url>
      <doi>10.18653/v1/W16-3617</doi>
    </paper>
    <paper id="18">
      <title>Initiations and Interruptions in a Spoken Dialog System</title>
      <author><first>Leah</first> <last>Nicolich-Henkin</last></author>
      <author><first>Carolyn</first> <last>Rosé</last></author>
      <author><first>Alan W</first> <last>Black</last></author>
      <pages>148–156</pages>
      <url hash="1179dabf">W16-3618</url>
      <doi>10.18653/v1/W16-3618</doi>
    </paper>
    <paper id="19">
      <title>Analyzing Post-dialogue Comments by Speakers – How Do Humans Personalize Their Utterances in Dialogue? –</title>
      <author><first>Toru</first> <last>Hirano</last></author>
      <author><first>Ryuichiro</first> <last>Higashinaka</last></author>
      <author><first>Yoshihiro</first> <last>Matsuo</last></author>
      <pages>157–165</pages>
      <url hash="1366666a">W16-3619</url>
      <doi>10.18653/v1/W16-3619</doi>
    </paper>
    <paper id="20">
      <title>On the Contribution of Discourse Structure on Text Complexity Assessment</title>
      <author><first>Elnaz</first> <last>Davoodi</last></author>
      <author><first>Leila</first> <last>Kosseim</last></author>
      <pages>166–174</pages>
      <url hash="6050d5d5">W16-3620</url>
      <doi>10.18653/v1/W16-3620</doi>
    </paper>
    <paper id="21">
      <title>Syntactic parsing of chat language in contact center conversation corpus</title>
      <author><first>Alexis</first> <last>Nasr</last></author>
      <author><first>Geraldine</first> <last>Damnati</last></author>
      <author><first>Aleksandra</first> <last>Guerraz</last></author>
      <author><first>Frederic</first> <last>Bechet</last></author>
      <pages>175–184</pages>
      <url hash="57f279be">W16-3621</url>
      <doi>10.18653/v1/W16-3621</doi>
    </paper>
    <paper id="22">
      <title>A Context-aware Natural Language Generator for Dialogue Systems</title>
      <author><first>Ondřej</first> <last>Dušek</last></author>
      <author><first>Filip</first> <last>Jurčíček</last></author>
      <pages>185–190</pages>
      <url hash="7ca5bb18">W16-3622</url>
      <doi>10.18653/v1/W16-3622</doi>
    </paper>
    <paper id="23">
      <title>Identifying Teacher Questions Using Automatic Speech Recognition in Classrooms</title>
      <author><first>Nathaniel</first> <last>Blanchard</last></author>
      <author><first>Patrick</first> <last>Donnelly</last></author>
      <author><first>Andrew M.</first> <last>Olney</last></author>
      <author><first>Borhan</first> <last>Samei</last></author>
      <author><first>Brooke</first> <last>Ward</last></author>
      <author><first>Xiaoyi</first> <last>Sun</last></author>
      <author><first>Sean</first> <last>Kelly</last></author>
      <author><first>Martin</first> <last>Nystrand</last></author>
      <author><first>Sidney K.</first> <last>D’Mello</last></author>
      <pages>191–201</pages>
      <url hash="12b5a092">W16-3623</url>
      <doi>10.18653/v1/W16-3623</doi>
    </paper>
    <paper id="24">
      <title>A framework for the automatic inference of stochastic turn-taking styles</title>
      <author><first>Kornel</first> <last>Laskowski</last></author>
      <pages>202–211</pages>
      <url hash="b2578aac">W16-3624</url>
      <doi>10.18653/v1/W16-3624</doi>
    </paper>
    <paper id="25">
      <title>Talking with <fixed-case>ERICA</fixed-case>, an autonomous android</title>
      <author><first>Koji</first> <last>Inoue</last></author>
      <author><first>Pierrick</first> <last>Milhorat</last></author>
      <author><first>Divesh</first> <last>Lala</last></author>
      <author><first>Tianyu</first> <last>Zhao</last></author>
      <author><first>Tatsuya</first> <last>Kawahara</last></author>
      <pages>212–215</pages>
      <url hash="9aedb670">W16-3625</url>
      <doi>10.18653/v1/W16-3625</doi>
    </paper>
    <paper id="26">
      <title>Rapid Prototyping of Form-driven Dialogue Systems Using an Open-source Framework</title>
      <author><first>Svetlana</first> <last>Stoyanchev</last></author>
      <author><first>Pierre</first> <last>Lison</last></author>
      <author><first>Srinivas</first> <last>Bangalore</last></author>
      <pages>216–219</pages>
      <url hash="44a1d0c9">W16-3626</url>
      <doi>10.18653/v1/W16-3626</doi>
    </paper>
    <paper id="27">
      <title><fixed-case>LVCSR</fixed-case> System on a Hybrid <fixed-case>GPU</fixed-case>-<fixed-case>CPU</fixed-case> Embedded Platform for Real-Time Dialog Applications</title>
      <author><first>Alexei V.</first> <last>Ivanov</last></author>
      <author><first>Patrick L.</first> <last>Lange</last></author>
      <author><first>David</first> <last>Suendermann-Oeft</last></author>
      <pages>220–223</pages>
      <url hash="b746593d">W16-3627</url>
      <doi>10.18653/v1/W16-3627</doi>
    </paper>
    <paper id="28">
      <title>Socially-Aware Animated Intelligent Personal Assistant Agent</title>
      <author><first>Yoichi</first> <last>Matsuyama</last></author>
      <author><first>Arjun</first> <last>Bhardwaj</last></author>
      <author><first>Ran</first> <last>Zhao</last></author>
      <author><first>Oscar</first> <last>Romeo</last></author>
      <author><first>Sushma</first> <last>Akoju</last></author>
      <author><first>Justine</first> <last>Cassell</last></author>
      <pages>224–227</pages>
      <url hash="d50a7d0d">W16-3628</url>
      <doi>10.18653/v1/W16-3628</doi>
    </paper>
    <paper id="29">
      <title>Selection method of an appropriate response in chat-oriented dialogue systems</title>
      <author><first>Hideaki</first> <last>Mori</last></author>
      <author><first>Masahiro</first> <last>Araki</last></author>
      <pages>228–231</pages>
      <url hash="ffebb615">W16-3629</url>
      <doi>10.18653/v1/W16-3629</doi>
    </paper>
    <paper id="30">
      <title>Real-Time Understanding of Complex Discriminative Scene Descriptions</title>
      <author><first>Ramesh</first> <last>Manuvinakurike</last></author>
      <author><first>Casey</first> <last>Kennington</last></author>
      <author><first>David</first> <last>DeVault</last></author>
      <author><first>David</first> <last>Schlangen</last></author>
      <pages>232–241</pages>
      <url hash="3a20b8db">W16-3630</url>
      <doi>10.18653/v1/W16-3630</doi>
    </paper>
    <paper id="31">
      <title>Supporting Spoken Assistant Systems with a Graphical User Interface that Signals Incremental Understanding and Prediction State</title>
      <author><first>Casey</first> <last>Kennington</last></author>
      <author><first>David</first> <last>Schlangen</last></author>
      <pages>242–251</pages>
      <url hash="3fe41ddf">W16-3631</url>
      <doi>10.18653/v1/W16-3631</doi>
    </paper>
    <paper id="32">
      <title>Toward incremental dialogue act segmentation in fast-paced interactive dialogue systems</title>
      <author><first>Ramesh</first> <last>Manuvinakurike</last></author>
      <author><first>Maike</first> <last>Paetzel</last></author>
      <author><first>Cheng</first> <last>Qu</last></author>
      <author><first>David</first> <last>Schlangen</last></author>
      <author><first>David</first> <last>DeVault</last></author>
      <pages>252–262</pages>
      <url hash="04897cb3">W16-3632</url>
      <doi>10.18653/v1/W16-3632</doi>
    </paper>
    <paper id="33">
      <title>Keynote - Modeling Human Communication Dynamics</title>
      <author><first>Louis-Philippe</first> <last>Morency</last></author>
      <pages>263</pages>
      <url hash="afbdc369">W16-3633</url>
      <doi>10.18653/v1/W16-3633</doi>
    </paper>
    <paper id="34">
      <title>On the Evaluation of Dialogue Systems with Next Utterance Classification</title>
      <author><first>Ryan</first> <last>Lowe</last></author>
      <author><first>Iulian Vlad</first> <last>Serban</last></author>
      <author><first>Michael</first> <last>Noseworthy</last></author>
      <author><first>Laurent</first> <last>Charlin</last></author>
      <author><first>Joelle</first> <last>Pineau</last></author>
      <pages>264–269</pages>
      <url hash="6e894484">W16-3634</url>
      <doi>10.18653/v1/W16-3634</doi>
    </paper>
    <paper id="35">
      <title>Towards Using Conversations with Spoken Dialogue Systems in the Automated Assessment of Non-Native Speakers of <fixed-case>E</fixed-case>nglish</title>
      <author><first>Diane</first> <last>Litman</last></author>
      <author><first>Steve</first> <last>Young</last></author>
      <author><first>Mark</first> <last>Gales</last></author>
      <author><first>Kate</first> <last>Knill</last></author>
      <author><first>Karen</first> <last>Ottewell</last></author>
      <author><first>Rogier</first> <last>van Dalen</last></author>
      <author><first>David</first> <last>Vandyke</last></author>
      <pages>270–275</pages>
      <url hash="c6e297f4">W16-3635</url>
      <doi>10.18653/v1/W16-3635</doi>
    </paper>
    <paper id="36">
      <title>Measuring the Similarity of Sentential Arguments in Dialogue</title>
      <author><first>Amita</first> <last>Misra</last></author>
      <author><first>Brian</first> <last>Ecker</last></author>
      <author><first>Marilyn</first> <last>Walker</last></author>
      <pages>276–287</pages>
      <url hash="87197a7c">W16-3636</url>
      <doi>10.18653/v1/W16-3636</doi>
    </paper>
    <paper id="37">
      <title>Investigating Fluidity for Human-Robot Interaction with Real-time, Real-world Grounding Strategies</title>
      <author><first>Julian</first> <last>Hough</last></author>
      <author><first>David</first> <last>Schlangen</last></author>
      <pages>288–298</pages>
      <url hash="ae73f5d1">W16-3637</url>
      <doi>10.18653/v1/W16-3637</doi>
    </paper>
    <paper id="38">
      <title>Do Characters Abuse More Than Words?</title>
      <author><first>Yashar</first> <last>Mehdad</last></author>
      <author><first>Joel</first> <last>Tetreault</last></author>
      <pages>299–303</pages>
      <url hash="3ae34259">W16-3638</url>
      <doi>10.18653/v1/W16-3638</doi>
    </paper>
    <paper id="39">
      <title>Towards a dialogue system that supports rich visualizations of data</title>
      <author><first>Abhinav</first> <last>Kumar</last></author>
      <author><first>Jillian</first> <last>Aurisano</last></author>
      <author><first>Barbara</first> <last>Di Eugenio</last></author>
      <author><first>Andrew</first> <last>Johnson</last></author>
      <author><first>Alberto</first> <last>Gonzalez</last></author>
      <author><first>Jason</first> <last>Leigh</last></author>
      <pages>304–309</pages>
      <url hash="216cf017">W16-3639</url>
      <doi>10.18653/v1/W16-3639</doi>
    </paper>
    <paper id="40">
      <title>Analyzing the Effect of Entrainment on Dialogue Acts</title>
      <author><first>Masahiro</first> <last>Mizukami</last></author>
      <author><first>Koichiro</first> <last>Yoshino</last></author>
      <author><first>Graham</first> <last>Neubig</last></author>
      <author><first>David</first> <last>Traum</last></author>
      <author><first>Satoshi</first> <last>Nakamura</last></author>
      <pages>310–318</pages>
      <url hash="11862f96">W16-3640</url>
      <doi>10.18653/v1/W16-3640</doi>
    </paper>
    <paper id="41">
      <title>Towards an Entertaining Natural Language Generation System: Linguistic Peculiarities of <fixed-case>J</fixed-case>apanese Fictional Characters</title>
      <author><first>Chiaki</first> <last>Miyazaki</last></author>
      <author><first>Toru</first> <last>Hirano</last></author>
      <author><first>Ryuichiro</first> <last>Higashinaka</last></author>
      <author><first>Yoshihiro</first> <last>Matsuo</last></author>
      <pages>319–328</pages>
      <url hash="167dd70c">W16-3641</url>
      <doi>10.18653/v1/W16-3641</doi>
    </paper>
    <paper id="42">
      <title>Reference Resolution in Situated Dialogue with Learned Semantics</title>
      <author><first>Xiaolong</first> <last>Li</last></author>
      <author><first>Kristy</first> <last>Boyer</last></author>
      <pages>329–338</pages>
      <url hash="a129bd0c">W16-3642</url>
      <doi>10.18653/v1/W16-3642</doi>
    </paper>
    <paper id="43">
      <title>Training an adaptive dialogue policy for interactive learning of visually grounded word meanings</title>
      <author><first>Yanchao</first> <last>Yu</last></author>
      <author><first>Arash</first> <last>Eshghi</last></author>
      <author><first>Oliver</first> <last>Lemon</last></author>
      <pages>339–349</pages>
      <url hash="83294f6b">W16-3643</url>
      <doi>10.18653/v1/W16-3643</doi>
    </paper>
    <paper id="44">
      <title>Learning Fine-Grained Knowledge about Contingent Relations between Everyday Events</title>
      <author><first>Elahe</first> <last>Rahimtoroghi</last></author>
      <author><first>Ernesto</first> <last>Hernandez</last></author>
      <author><first>Marilyn</first> <last>Walker</last></author>
      <pages>350–359</pages>
      <url hash="c2b34dba">W16-3644</url>
      <doi>10.18653/v1/W16-3644</doi>
      <attachment type="presentation" hash="9964bae0">W16-3644.Presentation.pdf</attachment>
    </paper>
    <paper id="45">
      <title>When do we laugh?</title>
      <author><first>Ye</first> <last>Tian</last></author>
      <author><first>Chiara</first> <last>Mazzocconi</last></author>
      <author><first>Jonathan</first> <last>Ginzburg</last></author>
      <pages>360–369</pages>
      <url hash="534373e7">W16-3645</url>
      <doi>10.18653/v1/W16-3645</doi>
    </paper>
    <paper id="46">
      <title>Small Talk Improves User Impressions of Interview Dialogue Systems</title>
      <author><first>Takahiro</first> <last>Kobori</last></author>
      <author><first>Mikio</first> <last>Nakano</last></author>
      <author><first>Tomoaki</first> <last>Nakamura</last></author>
      <pages>370–380</pages>
      <url hash="14db1acb">W16-3646</url>
      <doi>10.18653/v1/W16-3646</doi>
    </paper>
    <paper id="47">
      <title>Automatic Recognition of Conversational Strategies in the Service of a Socially-Aware Dialog System</title>
      <author><first>Ran</first> <last>Zhao</last></author>
      <author><first>Tanmay</first> <last>Sinha</last></author>
      <author><first>Alan</first> <last>Black</last></author>
      <author><first>Justine</first> <last>Cassell</last></author>
      <pages>381–392</pages>
      <url hash="4bd36566">W16-3647</url>
      <doi>10.18653/v1/W16-3647</doi>
    </paper>
    <paper id="48">
      <title>Neural Utterance Ranking Model for Conversational Dialogue Systems</title>
      <author><first>Michimasa</first> <last>Inaba</last></author>
      <author><first>Kenichi</first> <last>Takahashi</last></author>
      <pages>393–403</pages>
      <url hash="c76a3ecd">W16-3648</url>
      <doi>10.18653/v1/W16-3648</doi>
    </paper>
    <paper id="49">
      <title>Strategy and Policy Learning for Non-Task-Oriented Conversational Systems</title>
      <author><first>Zhou</first> <last>Yu</last></author>
      <author><first>Ziyu</first> <last>Xu</last></author>
      <author><first>Alan W</first> <last>Black</last></author>
      <author><first>Alexander</first> <last>Rudnicky</last></author>
      <pages>404–412</pages>
      <url hash="7782eede">W16-3649</url>
      <doi>10.18653/v1/W16-3649</doi>
    </paper>
  </volume>
  <volume id="37">
    <meta>
      <booktitle>Proceedings of the 6th Workshop on South and Southeast <fixed-case>A</fixed-case>sian Natural Language Processing (<fixed-case>WSSANLP</fixed-case>2016)</booktitle>
      <url hash="39688d71">W16-37</url>
      <editor><first>Dekai</first><last>Wu</last></editor>
      <editor><first>Pushpak</first><last>Bhattacharyya</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="4d1add27">W16-3700</url>
    </frontmatter>
    <paper id="1">
      <title>Compound Type Identification in <fixed-case>S</fixed-case>anskrit: What Roles do the Corpus and Grammar Play?</title>
      <author><first>Amrith</first> <last>Krishna</last></author>
      <author><first>Pavankumar</first> <last>Satuluri</last></author>
      <author><first>Shubham</first> <last>Sharma</last></author>
      <author><first>Apurv</first> <last>Kumar</last></author>
      <author><first>Pawan</first> <last>Goyal</last></author>
      <pages>1–10</pages>
      <url hash="82681c15">W16-3701</url>
      <abstract>We propose a classification framework for semantic type identification of compounds in Sanskrit. We broadly classify the compounds into four different classes namely, <i>Avyayībhāva</i>, <i>Tatpuruṣa</i>, <i>Bahuvrīhi</i> and <i>Dvandva</i>. Our
      classification is based on the traditional classification system followed
      by the ancient grammar treatise <i>Adṣṭādhyāyī</i>, proposed by Pāṇini 25
      centuries back. We construct an elaborate features space for our system by
      combining conditional rules from the grammar <i>Adṣṭādhyāyī</i>, semantic relations
      between the compound components from a lexical database <i>Amarakoṣa</i> and
      linguistic structures from the data using Adaptor Grammars. Our in-depth
      analysis of the feature space highlight inadequacy of <i>Adṣṭādhyāyī</i>, a generative
      grammar, in classifying the data samples. Our experimental results
      validate the effectiveness of using lexical databases as suggested by Amba
      Kulkarni and Anil Kumar, and put forward a new research direction by
      introducing linguistic patterns obtained from Adaptor grammars for
      effective identification of compound type. We utilise an ensemble based
      approach, specifically designed for handling skewed datasets and we %and
      Experimenting with various classification methods, we achieve an overall
      accuracy of 0.77 using random forest classifiers.
    </abstract>
    </paper>
    <paper id="2">
      <title>Comparison of Grapheme-to-Phoneme Conversion Methods on a <fixed-case>M</fixed-case>yanmar Pronunciation Dictionary</title>
      <author><first>Ye</first> <last>Kyaw Thu</last></author>
      <author><first>Win</first> <last>Pa Pa</last></author>
      <author><first>Yoshinori</first> <last>Sagisaka</last></author>
      <author><first>Naoto</first> <last>Iwahashi</last></author>
      <pages>11–22</pages>
      <url hash="d61e01a5">W16-3702</url>
      <abstract>Grapheme-to-Phoneme (G2P) conversion is the task of predicting the pronunciation of a word given its graphemic or written form. It is a highly important part of both automatic speech recognition (ASR) and text-to-speech (TTS) systems. In this paper, we evaluate seven G2P conversion approaches: Adaptive Regularization of Weight Vectors (AROW) based structured learning (S-AROW), Conditional Random Field (CRF), Joint-sequence models (JSM), phrase-based statistical machine translation (PBSMT), Recurrent Neural Network (RNN), Support Vector Machine (SVM) based point-wise classification, Weighted Finite-state Transducers (WFST) on a manually tagged Myanmar phoneme dictionary. The G2P bootstrapping experimental results were measured with both automatic phoneme error rate (PER) calculation and also manual checking in terms of voiced/unvoiced, tones, consonant and vowel errors. The result shows that CRF, PBSMT and WFST approaches are the best performing methods for G2P conversion on Myanmar language.</abstract>
    </paper>
    <paper id="3">
      <title>Character-Aware Neural Networks for <fixed-case>A</fixed-case>rabic Named Entity Recognition for Social Media</title>
      <author><first>Mourad</first> <last>Gridach</last></author>
      <pages>23–32</pages>
      <url hash="0d054d83">W16-3703</url>
      <abstract>Named Entity Recognition (NER) is the task of classifying or labelling atomic elements in the text into categories such as Person, Location or Organisation. For Arabic language, recognizing named entities is a challenging task because of the complexity and the unique characteristics of this language. In addition, most of the previous work focuses on Modern Standard Arabic (MSA), however, recognizing named entities in social media is becoming more interesting these days. Dialectal Arabic (DA) and MSA are both used in social media, which is deemed as another challenging task. Most state-of-the-art Arabic NER systems count heavily on handcrafted engineering features and lexicons which is time consuming. In this paper, we introduce a novel neural network architecture which benefits both from character- and word-level representations automatically, by using combination of bidirectional LSTM and Conditional Random Field (CRF), eliminating the need for most feature engineering. Moreover, our model relies on unsupervised word representations learned from unannotated corpora. Experimental results demonstrate that our model achieves state-of-the-art performance on publicly available benchmark for Arabic NER for social media and surpassing the previous system by a large margin.</abstract>
    </paper>
    <paper id="4">
      <title>Development of a <fixed-case>B</fixed-case>engali parser by cross-lingual transfer from <fixed-case>H</fixed-case>indi</title>
      <author><first>Ayan</first> <last>Das</last></author>
      <author><first>Agnivo</first> <last>Saha</last></author>
      <author><first>Sudeshna</first> <last>Sarkar</last></author>
      <pages>33–43</pages>
      <url hash="fa8b79a7">W16-3704</url>
      <abstract>In recent years there has been a lot of interest in cross-lingual parsing for developing treebanks for languages with small or no annotated treebanks. In this paper, we explore the development of a cross-lingual transfer parser from Hindi to Bengali using a Hindi parser and a Hindi-Bengali parallel corpus. A parser is trained and applied to the Hindi sentences of the parallel corpus and the parse trees are projected to construct probable parse trees of the corresponding Bengali sentences. Only about 14% of these trees are complete (transferred trees contain all the target sentence words) and they are used to construct a Bengali parser. We relax the criteria of completeness to consider well-formed trees (43% of the trees) leading to an improvement. We note that the words often do not have a one-to-one mapping in the two languages but considering sentences at the chunk-level results in better correspondence between the two languages. Based on this we present a method to use chunking as a preprocessing step and do the transfer on the chunk trees. We find that about 72% of the projected parse trees of Bengali are now well-formed. The resultant parser achieves significant improvement in both Unlabeled Attachment Score (UAS) as well as Labeled Attachment Score (LAS) over the baseline word-level transferred parser.</abstract>
    </paper>
    <paper id="5">
      <title><fixed-case>S</fixed-case>inhala Short Sentence Similarity Calculation using Corpus-Based and Knowledge-Based Similarity Measures</title>
      <author><first>Jcs</first> <last>Kadupitiya</last></author>
      <author><first>Surangika</first> <last>Ranathunga</last></author>
      <author><first>Gihan</first> <last>Dias</last></author>
      <pages>44–53</pages>
      <url hash="3aef193e">W16-3705</url>
      <abstract>Currently, corpus based-similarity, string-based similarity, and knowledge-based similarity techniques are used to compare short phrases. However, no work has been conducted on the similarity of phrases in Sinhala language. In this paper, we present a hybrid methodology to compute the similarity between two Sinhala sentences using a Semantic Similarity Measurement technique (corpus-based similarity measurement plus knowledge-based similarity measurement) that makes use of word order information. Since Sinhala WordNet is still under construction, we used lexical resources in performing this semantic similarity calculation. Evaluation using 4000 sentence pairs yielded an average MSE of 0.145 and a Pearson correla-tion factor of 0.832.</abstract>
    </paper>
    <paper id="6">
      <title>Enriching Source for <fixed-case>E</fixed-case>nglish-to-<fixed-case>U</fixed-case>rdu Machine Translation</title>
      <author><first>Bushra</first> <last>Jawaid</last></author>
      <author><first>Amir</first> <last>Kamran</last></author>
      <author><first>Ondřej</first> <last>Bojar</last></author>
      <pages>54–63</pages>
      <url hash="882de253">W16-3706</url>
      <abstract>This paper focuses on the generation of case markers for free word order languages that use case markers as phrasal clitics for marking the relationship between the dependent-noun and its head. The generation of such clitics becomes essential task especially when translating from fixed word order languages where syntactic relations are identified by the positions of the dependent-nouns. To address the problem of missing markers on source-side, artificial markers are added in source to improve alignments with its target counterparts. Up to 1 BLEU point increase is observed over the baseline on different test sets for English-to-Urdu.</abstract>
    </paper>
    <paper id="7">
      <title>The <fixed-case>IMAGACT</fixed-case>4<fixed-case>ALL</fixed-case> Ontology of Animated Images: Implications for Theoretical and Machine Translation of Action Verbs from <fixed-case>E</fixed-case>nglish-<fixed-case>I</fixed-case>ndian Languages</title>
      <author><first>Pitambar</first> <last>Behera</last></author>
      <author><first>Sharmin</first> <last>Muzaffar</last></author>
      <author><first>Atul Ku.</first> <last>Ojha</last></author>
      <author><first>Girish</first> <last>Jha</last></author>
      <pages>64–73</pages>
      <url hash="cabe047c">W16-3707</url>
      <abstract>Action verbs are one of the frequently occurring linguistic elements in any given natural language as the speakers use them during every linguistic intercourse. However, each language expresses action verbs in its own inherently unique manner by categorization. One verb can refer to several interpretations of actions and one action can be expressed by more than one verb. The inter-language and intra-language variations create ambiguity for the translation of languages from the source language to target language with respect to action verbs. IMAGACT is a corpus-based ontological platform of action verbs translated from prototypic animated images explained in English and Italian as meta-languages. In this paper, we are presenting the issues and challenges in translating action verbs of Indian languages as target and English as source language by observing the animated images. Among the ten Indian languages which have been annotated so far on the platform are Sanskrit, Hindi, Urdu, Odia (Oriya), Bengali, Manipuri, Tamil, Assamese, Magahi and Marathi. Out of them, Manipuri belongs to the Sino-Tibetan, Tamil comes off the Dravidian and the rest owe their genesis to the Indo-Aryan language family. One of the issues is that the one-word morphological English verbs are translated into most of the Indian languages as verbs having more than one-word form; for instance as in the case of conjunct, compound, serial verbs and so on. We are further presenting a cross-lingual comparison of action verbs among Indian languages. In addition, we are also dealing with the issues in disambiguating animated images by the L1 native speakers using competence-based judgements and the theoretical and machine translation implications they bear.</abstract>
    </paper>
    <paper id="8">
      <title>Crowdsourcing-based Annotation of Emotions in <fixed-case>F</fixed-case>ilipino and <fixed-case>E</fixed-case>nglish Tweets</title>
      <author><first>Fermin Roberto</first> <last>Lapitan</last></author>
      <author><first>Riza Theresa</first> <last>Batista-Navarro</last></author>
      <author><first>Eliezer</first> <last>Albacea</last></author>
      <pages>74–82</pages>
      <url hash="49057879">W16-3708</url>
      <abstract>The automatic analysis of emotions conveyed in social media content, e.g., tweets, has many beneficial applications. In the Philippines, one of the most disaster-prone countries in the world, such methods could potentially enable first responders to make timely decisions despite the risk of data deluge. However, recognising emotions expressed in Philippine-generated tweets, which are mostly written in Filipino, English or a mix of both, is a non-trivial task. In order to facilitate the development of natural language processing (NLP) methods that will automate such type of analysis, we have built a corpus of tweets whose predominant emotions have been manually annotated by means of crowdsourcing. Defining measures ensuring that only high-quality annotations were retained, we have produced a gold standard corpus of 1,146 emotion-labelled Filipino and English tweets. We validate the value of this manually produced resource by demonstrating that an automatic emotion-prediction method based on the use of a publicly available word-emotion association lexicon was unable to reproduce the labels assigned via crowdsourcing. While we are planning to make a few extensions to the corpus in the near future, its current version has been made publicly available in order to foster the development of emotion analysis methods based on advanced Filipino and English NLP.</abstract>
    </paper>
    <paper id="10">
      <title>Sentiment Analysis of Tweets in Three <fixed-case>I</fixed-case>ndian Languages</title>
      <author><first>Shanta</first> <last>Phani</last></author>
      <author><first>Shibamouli</first> <last>Lahiri</last></author>
      <author><first>Arindam</first> <last>Biswas</last></author>
      <pages>93–102</pages>
      <url hash="4cd15cbf">W16-3710</url>
      <abstract>In this paper, we describe the results of sentiment analysis on tweets in three Indian languages – Bengali, Hindi, and Tamil. We used the recently released SAIL dataset (Patra et al., 2015), and obtained state-of-the-art results in all three languages. Our features are simple, robust, scalable, and language-independent. Further, we show that these simple features provide better results than more complex and language-specific features, in two separate classification tasks. Detailed feature analysis and error analysis have been reported, along with learning curves for Hindi and Bengali.</abstract>
    </paper>
    <paper id="11">
      <title>Dealing with Linguistic Divergences in <fixed-case>E</fixed-case>nglish-<fixed-case>B</fixed-case>hojpuri Machine Translation</title>
      <author><first>Pitambar</first> <last>Behera</last></author>
      <author><first>Neha</first> <last>Mourya</last></author>
      <author><first>Vandana</first> <last>Pandey</last></author>
      <pages>103–113</pages>
      <url hash="2d15ad8d">W16-3711</url>
      <abstract>In Machine Translation, divergence is one of the major barriers which plays a deciding role in determining the efficiency of the system at hand. Translation divergences originate when there is structural discrepancies between the input and the output languages. It can be of various types based on the issues we are addressing to such as linguistic, cultural, communicative and so on. Owing to the fact that two languages owe their origin to different language families, linguistic divergences emerge. The present study attempts at categorizing different types of linguistic divergences: the lexical-semantic and syntactic. In addition, it also helps identify and resolve the divergent linguistic features between English as source language and Bhojpuri as target language pair. Dorr’s theoretical framework (1994, 1994a) has been followed in the classification and resolution procedure. Furthermore, so far as the methodology is concerned, we have adhered to the Dorr’s Lexical Conceptual Structure for the resolution of divergences. This research will prove to be beneficial for developing efficient MT systems if the mentioned factors are incorporated considering the inherent structural constraints between source and target languages.ated considering the inherent structural constraints between SL and TL pairs.</abstract>
    </paper>
    <paper id="12">
      <title>The development of a web corpus of <fixed-case>H</fixed-case>indi language and corpus-based comparative studies to <fixed-case>J</fixed-case>apanese</title>
      <author><first>Miki</first> <last>Nishioka</last></author>
      <author><first>Shiro</first> <last>Akasegawa</last></author>
      <pages>114–123</pages>
      <url hash="63c5ded3">W16-3712</url>
      <abstract>In this paper, we discuss our creation of a web corpus of spoken Hindi (COSH), one of the Indo-Aryan languages spoken mainly in the Indian subcontinent. We also point out notable problems we’ve encountered in the web corpus and the special concordancer. After observing the kind of technical problems we encountered, especially regarding annotation tagged by Shiva Reddy’s tagger, we argue how they can be solved when using COSH for linguistic studies. Finally, we mention the kinds of linguistic research that we non-native speakers of Hindi can do using the corpus, especially in pragmatics and semantics, and from a comparative viewpoint to Japanese.</abstract>
    </paper>
    <paper id="13">
      <title>Automatic Creation of a Sentence Aligned <fixed-case>S</fixed-case>inhala-<fixed-case>T</fixed-case>amil Parallel Corpus</title>
      <author><first>Riyafa</first> <last>Abdul Hameed</last></author>
      <author><first>Nadeeshani</first> <last>Pathirennehelage</last></author>
      <author><first>Anusha</first> <last>Ihalapathirana</last></author>
      <author><first>Maryam</first> <last>Ziyad Mohamed</last></author>
      <author><first>Surangika</first> <last>Ranathunga</last></author>
      <author><first>Sanath</first> <last>Jayasena</last></author>
      <author><first>Gihan</first> <last>Dias</last></author>
      <author><first>Sandareka</first> <last>Fernando</last></author>
      <pages>124–132</pages>
      <url hash="61c9dde3">W16-3713</url>
      <abstract>A sentence aligned parallel corpus is an important prerequisite in statistical machine translation. However, manual creation of such a parallel corpus is time consuming, and requires experts fluent in both languages. Automatic creation of a sentence aligned parallel corpus using parallel text is the solution to this problem. In this paper, we present the first ever empirical evaluation carried out to identify the best method to automatically create a sentence aligned Sinhala-Tamil parallel corpus. Annual reports from Sri Lankan government institutions were used as the parallel text for aligning. Despite both Sinhala and Tamil being under-resourced languages, we were able to achieve an F-score value of 0.791 using a hybrid approach that makes use of a bilingual dictionary.</abstract>
    </paper>
    <paper id="14">
      <title>Clustering-based Phonetic Projection in Mismatched Crowdsourcing Channels for Low-resourced <fixed-case>ASR</fixed-case></title>
      <author><first>Wenda</first> <last>Chen</last></author>
      <author><first>Mark</first> <last>Hasegawa-Johnson</last></author>
      <author><first>Nancy</first> <last>Chen</last></author>
      <author><first>Preethi</first> <last>Jyothi</last></author>
      <author><first>Lav</first> <last>Varshney</last></author>
      <pages>133–141</pages>
      <url hash="47114570">W16-3714</url>
      <abstract>Acquiring labeled speech for low-resource languages is a difficult task in the absence of native speakers of the language. One solution to this problem involves collecting speech transcriptions from crowd workers who are foreign or non-native speakers of a given target language. From these mismatched transcriptions, one can derive probabilistic phone transcriptions that are defined over the set of all target language phones using a noisy channel model. This paper extends prior work on deriving probabilistic transcriptions (PTs) from mismatched transcriptions by 1) modelling multilingual channels and 2) introducing a clustering-based phonetic mapping technique to improve the quality of PTs. Mismatched crowdsourcing for multilingual channels has certain properties of projection mapping, e.g., it can be interpreted as a clustering based on singular value decomposition of the segment alignments. To this end, we explore the use of distinctive feature weights, lexical tone confusions, and a two-step clustering algorithm to learn projections of phoneme segments from mismatched multilingual transcriber languages to the target language. We evaluate our techniques using mismatched transcriptions for Cantonese speech acquired from native English and Mandarin speakers. We observe a 5-9% relative reduction in phone error rate for the predicted Cantonese phone transcriptions using our proposed techniques compared with the previous PT method.</abstract>
    </paper>
    <paper id="15">
      <title>Improving the Morphological Analysis of Classical <fixed-case>S</fixed-case>anskrit</title>
      <author><first>Oliver</first> <last>Hellwig</last></author>
      <pages>142–151</pages>
      <url hash="e3f861af">W16-3715</url>
      <abstract>The paper describes a new tagset for the morphological disambiguation of Sanskrit, and compares the accuracy of two machine learning methods (Conditional Random Fields, deep recurrent neural networks) for this task, with a special focus on how to model the lexicographic information. It reports a significant improvement over previously published results.</abstract>
    </paper>
    <paper id="16">
      <title>Query Translation for Cross-Language Information Retrieval using Multilingual Word Clusters</title>
      <author><first>Paheli</first> <last>Bhattacharya</last></author>
      <author><first>Pawan</first> <last>Goyal</last></author>
      <author><first>Sudeshna</first> <last>Sarkar</last></author>
      <pages>152–162</pages>
      <url hash="cacfc036">W16-3716</url>
      <abstract>In Cross-Language Information Retrieval, finding the appropriate translation of the source language query has always been a difficult problem to solve. We propose a technique towards solving this problem with the help of multilingual word clusters obtained from multilingual word embeddings. We use word embeddings of the languages projected to a common vector space on which a community-detection algorithm is applied to find clusters such that words that represent the same concept from different languages fall in the same group. We utilize these multilingual word clusters to perform query translation for Cross-Language Information Retrieval for three languages - English, Hindi and Bengali. We have experimented with the FIRE 2012 and Wikipedia datasets and have shown improvements over several standard methods like dictionary-based method, a transliteration-based model and Google Translate.</abstract>
    </paper>
    <paper id="17">
      <title>A study of attention-based neural machine translation model on <fixed-case>I</fixed-case>ndian languages</title>
      <author><first>Ayan</first> <last>Das</last></author>
      <author><first>Pranay</first> <last>Yerra</last></author>
      <author><first>Ken</first> <last>Kumar</last></author>
      <author><first>Sudeshna</first> <last>Sarkar</last></author>
      <pages>163–172</pages>
      <url hash="62517e39">W16-3717</url>
      <abstract>Neural machine translation (NMT) models have recently been shown to be very successful in machine translation (MT). The use of LSTMs in machine translation has significantly improved the translation performance for longer sentences by being able to capture the context and long range correlations of the sentences in their hidden layers. The attention model based NMT system (Bahdanau et al., 2014) has become the state-of-the-art, performing equal or better than other statistical MT approaches. In this paper, we wish to study the performance of the attention-model based NMT system (Bahdanau et al., 2014) on the Indian language pair, Hindi and Bengali, and do an analysis on the types or errors that occur in case when the languages are morphologically rich and there is a scarcity of large parallel training corpus. We then carry out certain post-processing heuristic steps to improve the quality of the translated statements and suggest further measures that can be carried out.</abstract>
    </paper>
    <paper id="18">
      <title>Comprehensive Part-Of-Speech Tag Set and <fixed-case>SVM</fixed-case> based <fixed-case>POS</fixed-case> Tagger for <fixed-case>S</fixed-case>inhala</title>
      <author><first>Sandareka</first> <last>Fernando</last></author>
      <author><first>Surangika</first> <last>Ranathunga</last></author>
      <author><first>Sanath</first> <last>Jayasena</last></author>
      <author><first>Gihan</first> <last>Dias</last></author>
      <pages>173–182</pages>
      <url hash="777ca8f5">W16-3718</url>
      <abstract>This paper presents a new comprehensive multi-level Part-Of-Speech tag set and a Support Vector Machine based Part-Of-Speech tagger for the Sinhala language. The currently available tag set for Sinhala has two limitations: the unavailability of tags to represent some word classes and the lack of tags to capture inflection based grammatical variations of words. The new tag set, presented in this paper overcomes both of these limitations. The accuracy of available Sinhala Part-Of-Speech taggers, which are based on Hidden Markov Models, still falls far behind state of the art. Our Support Vector Machine based tagger achieved an overall accuracy of 84.68% with 59.86% accuracy for unknown words and 87.12% for known words, when the test set contains 10% of unknown words.</abstract>
    </paper>
    <paper id="19">
      <title>Align Me: A framework to generate Parallel Corpus Using <fixed-case>OCR</fixed-case>s and Bilingual Dictionaries</title>
      <author><first>Priyam</first> <last>Bakliwal</last></author>
      <author><first>Devadath</first> <last>V V</last></author>
      <author><first>C V</first> <last>Jawahar</last></author>
      <pages>183–187</pages>
      <url hash="bf6c0bf7">W16-3719</url>
      <abstract>Multilingual language processing tasks like statistical machine translation and cross language information retrieval rely mainly on availability of accurate parallel corpora. Manual construction of such corpus can be extremely expensive and time consuming. In this paper we present a simple yet efficient method to generate huge amount of reasonably accurate parallel corpus with minimal user efforts. We utilize the availability of large number of English books and their corresponding translations in other languages to build parallel corpus. Optical Character Recognizing systems are used to digitize such books. We propose a robust dictionary based parallel corpus generation system for alignment of multilingual text at different levels of granularity (sentence, paragraphs, etc). We show the performance of our proposed method on a manually aligned dataset of 300 Hindi-English sentences and 100 English-Malayalam sentences.</abstract>
    </paper>
    <paper id="20">
      <title>Learning <fixed-case>I</fixed-case>ndonesian-<fixed-case>C</fixed-case>hinese Lexicon with Bilingual Word Embedding Models and Monolingual Signals</title>
      <author><first>Xinying</first> <last>Qiu</last></author>
      <author><first>Gangqin</first> <last>Zhu</last></author>
      <pages>188–193</pages>
      <url hash="afdd4337">W16-3720</url>
      <abstract>We present a research on learning Indonesian-Chinese bilingual lexicon using monolingual word embedding and bilingual seed lexicons to build shared bilingual word embedding space. We take the first attempt to examine the impact of different monolingual signals for the choice of seed lexicons on the model performance. We found that although monolingual signals alone do not seem to outperform signals coverings all words, the significant improvement for learning word translation of the same signal types may suggest that linguistic features possess value for further study in distinguishing the semantic margins of the shared word embedding space.</abstract>
    </paper>
    <paper id="21">
      <title>Creating rich online dictionaries for the <fixed-case>L</fixed-case>ao–<fixed-case>F</fixed-case>rench language pair, reusable for Machine Translation</title>
      <author><first>Vincent</first> <last>Berment</last></author>
      <pages>194–197</pages>
      <url hash="00c32f98">W16-3721</url>
      <abstract>In this paper, we present how we generated two rich online bilingual dictionaries — Lao-French and French-Lao — from unstructured dictionaries in Microsoft Word files. Then we shortly discuss the possible reuse of the lexical data for Machine Translation projects.</abstract>
    </paper>
  </volume>
  <volume id="38">
    <meta>
      <booktitle>Proceedings of the Workshop on Grammar and Lexicon: interactions and interfaces (<fixed-case>G</fixed-case>ram<fixed-case>L</fixed-case>ex)</booktitle>
      <url hash="b6039f7b">W16-38</url>
      <editor><first>Eva</first><last>Hajičová</last></editor>
      <editor><first>Igor</first><last>Boguslavsky</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="880ab67f">W16-3800</url>
    </frontmatter>
    <paper id="1">
      <title>Information structure, syntax, and pragmatics and other factors in resolving scope ambiguity</title>
      <author><first>Valentina</first> <last>Apresjan</last></author>
      <pages>1–6</pages>
      <url hash="d130fcfd">W16-3801</url>
      <abstract>The paper is a corpus study of the factors involved in disambiguating potential scope ambiguity in sentences with negation and universal quantifier, such as “I don’t want talk to all these people”, which can alternatively mean ‘I don’t want to talk to any of these people’ and ‘I don’t want to talk to some of these people’. The relevant factors are demonstrated to be largely different from those involved in disambiguating lexical polysemy. They include the syntactic function of the constituent containing “all” quantifier (subject, direct complement, adjunct), as well as the deepness of its embedding; the status of the main predicate and “all” constituent with respect to the information structure of the 6utterance (topic vs. focus, given vs. new information); pragmatic implicatures pertaining to the situations described in the utterances.</abstract>
    </paper>
    <paper id="2">
      <title>Multiword Expressions at the Grammar-Lexicon Interface</title>
      <author><first>Timothy</first> <last>Baldwin</last></author>
      <pages>7</pages>
      <url hash="119ce7e7">W16-3802</url>
      <abstract>In this talk, I will outline a range of challenges presented by multiword expressions in terms of (lexicalist) precision grammar engineering, and different strategies for accommodating those challenges, in an attempt to strike the right balance in terms of generalisation and over- and under-generation.</abstract>
    </paper>
    <paper id="3">
      <title>Microsyntactic Phenomena as a Computational Linguistics Issue</title>
      <author><first>Leonid</first> <last>Iomdin</last></author>
      <pages>8–17</pages>
      <url hash="dbe3666a">W16-3803</url>
      <abstract>Microsyntactic linguistic units, such as syntactic idioms and non-standard syntactic constructions, are poorly represented in linguistic resources, mostly because the former are elements occupying an intermediate position between the lexicon and the grammar and the latter are too specific to be routinely tackled by general grammars. Consequently, many such units produce substantial gaps in systems intended to solve sophisticated computational linguistics tasks, such as parsing, deep semantic analysis, question answering, machine translation, or text generation. They also present obstacles for applying advanced techniques to these tasks, such as machine learning. The paper discusses an approach aimed at bridging such gaps, focusing on the development of monolingual and multilingual corpora where microsyntactic units are to be tagged.</abstract>
    </paper>
    <paper id="4">
      <title><fixed-case>A</fixed-case>lternations: From Lexicon to Grammar And Back Again</title>
      <author><first>Markéta</first> <last>Lopatková</last></author>
      <author><first>Václava</first> <last>Kettnerová</last></author>
      <pages>18–27</pages>
      <url hash="210c59be">W16-3804</url>
      <abstract>An excellent example of a phenomenon bridging a lexicon and a grammar is provided by grammaticalized alternations (e.g., passivization, reflexivity, and reciprocity): these alternations represent productive grammatical processes which are, however, lexically determined. While grammaticalized alternations keep lexical meaning of verbs unchanged, they are usually characterized by various changes in their morphosyntactic structure. In this contribution, we demonstrate on the example of reciprocity and its representation in the valency lexicon of Czech verbs, VALLEX how a linguistic description of complex (and still systemic) changes characteristic of grammaticalized alternations can benefit from an integration of grammatical rules into a valency lexicon. In contrast to other types of grammaticalized alternations, reciprocity in Czech has received relatively little attention although it closely interacts with various linguistic phenomena (e.g., with light verbs, diatheses, and reflexivity).</abstract>
    </paper>
    <paper id="5">
      <title>Extra-Specific Multiword Expressions for Language-Endowed Intelligent Agents</title>
      <author><first>Marjorie</first> <last>McShane</last></author>
      <author><first>Sergei</first> <last>Nirenburg</last></author>
      <pages>28–37</pages>
      <url hash="7d97ec39">W16-3805</url>
      <abstract>Language-endowed intelligent agents benefit from leveraging lexical knowledge falling at different points along a spectrum of compositionality. This means that robust computational lexicons should include not only the compositional expectations of argument-taking words, but also non-compositional collocations (idioms), semi-compositional collocations that might be difficult for an agent to interpret (e.g., standard metaphors), and even collocations that could be compositionally analyzed but are so frequently encountered that recording their meaning increases the efficiency of interpretation. In this paper we argue that yet another type of string-to-meaning mapping can also be useful to intelligent agents: remembered semantic analyses of actual text inputs. These can be viewed as super-specific multi-word expressions whose recorded interpretations mimic a person’s memories of knowledge previously learned from language input. These differ from typical annotated corpora in two ways. First, they provide a full, context-sensitive semantic interpretation rather than select features. Second, they are are formulated in the ontologically-grounded metalanguage used in a particular agent environment, meaning that the interpretations contribute to the dynamically evolving cognitive capabilites of agents configured in that environment.</abstract>
    </paper>
    <paper id="6">
      <title><fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies: A Cross-Linguistic Perspective on Grammar and Lexicon</title>
      <author><first>Joakim</first> <last>Nivre</last></author>
      <pages>38–40</pages>
      <url hash="cbd1cdf8">W16-3806</url>
      <abstract>Universal Dependencies is an initiative to develop cross-linguistically consistent grammatical annotation for many languages, with the goal of facilitating multilingual parser development, cross-lingual learning and parsing research from a language typology perspective. It assumes a dependency-based approach to syntax and a lexicalist approach to morphology, which together entail that the fundamental units of grammatical annotation are words. Words have properties captured by morphological annotation and enter into relations captured by syntactic annotation. Moreover, priority is given to relations between lexical content words, as opposed to grammatical function words. In this position paper, I discuss how this approach allows us to capture similarities and differences across typologically diverse languages.</abstract>
    </paper>
    <paper id="7">
      <title>The Development of Multimodal Lexical Resources</title>
      <author><first>James</first> <last>Pustejovsky</last></author>
      <author><first>Tuan</first> <last>Do</last></author>
      <author><first>Gitit</first> <last>Kehat</last></author>
      <author><first>Nikhil</first> <last>Krishnaswamy</last></author>
      <pages>41–47</pages>
      <url hash="241d79b8">W16-3807</url>
      <abstract>Human communication is a multimodal activity, involving not only speech and written expressions, but intonation, images, gestures, visual clues, and the interpretation of actions through perception. In this paper, we describe the design of a multimodal lexicon that is able to accommodate the diverse modalities that present themselves in NLP applications. We have been developing a multimodal semantic representation, VoxML, that integrates the encoding of semantic, visual, gestural, and action-based features associated with linguistic expressions.</abstract>
    </paper>
    <paper id="8">
      <title>On the Non-canonical Valency Filling</title>
      <author><first>Igor</first> <last>Boguslavsky</last></author>
      <pages>51–60</pages>
      <url hash="90f6cbfe">W16-3808</url>
      <abstract>Valency slot filling is a semantic glue, which brings together the meanings of words. As regards the position of an argument in the dependency structure with respect to its predicate, there exist three types of valency filling: active (canonical), passive, and discontinuous. Of these, the first type is studied much better than the other two. As a rule, canonical actants are unambiguously marked in the syntactic structure, and each actant corresponds to a unique syntactic position. Linguistic information on which syntactic function an actant might have (subject, direct or indirect object), what its morphological form should be and which prepositions or conjunctions it requires, can be given in the lexicon in the form of government patterns, subcategorization frames, or similar data structures. We concentrate on non-canonical cases of valency filling in Russian, which are characteristic of non-verbal parts of speech, such as adverbs, adjectives, and particles, in the first place. They are more difficult to handle than canonical ones, because the position of the actant in the tree is governed by more complicated rules. A valency may be filled by expressions occupying different syntactic positions, and a syntactic position may accept expressions filling different valencies of the same word. We show how these phenomena can be processed in a semantic analyzer.</abstract>
    </paper>
    <paper id="9">
      <title>Improvement of <fixed-case>V</fixed-case>erb<fixed-case>N</fixed-case>et-like resources by frame typing</title>
      <author><first>Laurence</first> <last>Danlos</last></author>
      <author><first>Matthieu</first> <last>Constant</last></author>
      <author><first>Lucie</first> <last>Barque</last></author>
      <pages>61–70</pages>
      <url hash="240f92cb">W16-3809</url>
      <abstract>Verbenet is a French lexicon developed by “translation” of its English counterpart — VerbNet (Kipper-Schuler, 2005)—and treatment of the specificities of French syntax (Pradet et al., 2014; Danlos et al., 2016). One difficulty encountered in its development springs from the fact that the list of (potentially numerous) frames has no internal organization. This paper proposes a type system for frames that shows whether two frames are variants of a given alternation. Frame typing facilitates coherence checking of the resource in a “virtuous circle”. We present the principles underlying a program we developed and used to automatically type frames in VerbeNet. We also show that our system is portable to other languages.</abstract>
    </paper>
    <paper id="10">
      <title>Enriching a Valency Lexicon by Deverbative Nouns</title>
      <author><first>Eva</first> <last>Fučíková</last></author>
      <author><first>Jan</first> <last>Hajič</last></author>
      <author><first>Zdeňka</first> <last>Urešová</last></author>
      <pages>71–80</pages>
      <url hash="1c103335">W16-3810</url>
      <abstract>We present an attempt to automatically identify Czech deverbative nouns using several methods that use large corpora as well as existing lexical resources. The motivation for the task is to extend a verbal valency (i.e., predicate-argument) lexicon by adding nouns that share the valency properties with the base verb, assuming their properties can be derived (even if not trivially) from the underlying verb by deterministic grammatical rules. At the same time, even in inflective languages, not all deverbatives are simply created from their underlying base verb by regular lexical derivation processes. We have thus developed hybrid techniques that use both large parallel corpora and several standard lexical resources. Thanks to the use of parallel corpora, the resulting sets contain also synonyms, which the lexical derivation rules cannot get. For evaluation, we have manually created a small, 100-verb gold data since no such dataset was initially available for Czech.</abstract>
    </paper>
    <paper id="11">
      <title>The Grammar of <fixed-case>E</fixed-case>nglish Deverbal Compounds and their Meaning</title>
      <author><first>Gianina</first> <last>Iordăchioaia</last></author>
      <author><first>Lonneke</first> <last>van der Plas</last></author>
      <author><first>Glorianna</first> <last>Jagfeld</last></author>
      <pages>81–91</pages>
      <url hash="4ccbdd8b">W16-3811</url>
      <abstract>We present an interdisciplinary study on the interaction between the interpretation of noun-noun deverbal compounds (DCs; e.g., task assignment) and the morphosyntactic properties of their deverbal heads in English. Underlying hypotheses from theoretical linguistics are tested with tools and resources from computational linguistics. We start with Grimshaw’s (1990) insight that deverbal nouns are ambiguous between argument-supporting nominal (ASN) readings, which inherit verbal arguments (e.g., the assignment of the tasks), and the less verbal and more lexicalized Result Nominal and Simple Event readings (e.g., a two-page assignment). Following Grimshaw, our hypothesis is that the former will realize object arguments in DCs, while the latter will receive a wider range of interpretations like root compounds headed by non-derived nouns (e.g., chocolate box). Evidence from a large corpus assisted by machine learning techniques confirms this hypothesis, by showing that, besides other features, the realization of internal arguments by deverbal heads outside compounds (i.e., the most distinctive ASN-property in Grimshaw 1990) is a good predictor for an object interpretation of non-heads in DCs.</abstract>
    </paper>
    <paper id="12">
      <title>Encoding a syntactic dictionary into a super granular unification grammar</title>
      <author><first>Sylvain</first> <last>Kahane</last></author>
      <author><first>François</first> <last>Lareau</last></author>
      <pages>92–101</pages>
      <url hash="dae31c48">W16-3812</url>
      <abstract>We show how to turn a large-scale syntactic dictionary into a dependency-based unification grammar where each piece of lexical information calls a separate rule, yielding a super granular grammar. Subcategorization, raising and control verbs, auxiliaries and copula, passivization, and tough-movement are discussed. We focus on the semantics-syntax interface and offer a new perspective on syntactic structure.</abstract>
    </paper>
    <paper id="13">
      <title>Identification of Flexible Multiword Expressions with the Help of Dependency Structure Annotation</title>
      <author><first>Ayaka</first> <last>Morimoto</last></author>
      <author><first>Akifumi</first> <last>Yoshimoto</last></author>
      <author><first>Akihiko</first> <last>Kato</last></author>
      <author><first>Hiroyuki</first> <last>Shindo</last></author>
      <author><first>Yuji</first> <last>Matsumoto</last></author>
      <pages>102–109</pages>
      <url hash="907ccbf0">W16-3813</url>
      <abstract>This paper presents our ongoing work on compilation of English multi-word expression (MWE) lexicon. We are especially interested in collecting flexible MWEs, in which some other components can intervene the expression such as “a number of” vs “a large number of” where a modifier of “number” can be placed in the expression and inherit the original meaning. We fiest collect possible candidates of flexible English MWEs from the web, and annotate all of their occurrences in the Wall Street Journal portion of Ontonotes corpus. We make use of word dependency strcuture information of the sentences converted from the phrase structure annotation. This process enables semi-automatic annotation of MWEs in the corpus and simultanaously produces the internal and external dependency representation of flexible MWEs.</abstract>
    </paper>
    <paper id="14">
      <title>A new look at possessive reflexivization: A comparative study between <fixed-case>C</fixed-case>zech and <fixed-case>R</fixed-case>ussian</title>
      <author><first>Anna</first> <last>Nedoluzhko</last></author>
      <pages>110–119</pages>
      <url hash="93b076b2">W16-3814</url>
      <abstract>The paper presents a contrastive description of reflexive possessive pronouns “svůj” in Czech and “svoj” in Russian. The research concerns syntactic, semantic and pragmatic aspects. With our analysis, we shed a new light on the already investigated issue, which comes from a detailed comparison of the phenomenon of possessive reflexivization in two typologically and genetically similar languages. We show that whereas in Czech, the possessive reflexivization is mostly limited to syntactic functions and does not go beyond the grammar, in Russian it gets additional semantic meanings and moves substan-tially towards the lexicon. The obtained knowledge allows us to explain heretofore unclear marginal uses of reflexives in each language.</abstract>
    </paper>
    <paper id="15">
      <title>Modeling non-standard language</title>
      <author><first>Alexandr</first> <last>Rosen</last></author>
      <pages>120–131</pages>
      <url hash="62f67c74">W16-3815</url>
      <abstract>A specific language as used by different speakers and in different situations has a number of more or less distant varieties. Extending the notion of non-standard language to varieties that do not fit an explicitly or implicitly assumed norm or pattern, we look for methods and tools that could be applied to this domain. The needs start from the theoretical side: categories usable for the analysis of non-standard language are not readily available, and continue to methods and tools required for its detection and diagnostics. A general discussion of issues related to non-standard language is followed by two case studies. The first study presents a taxonomy of morphosyntactic categories as an attempt to analyse non-standard forms produced by non-native learners of Czech. The second study focusses on the role of a rule-based grammar and lexicon in the process of building and using a parsebank.</abstract>
    </paper>
  </volume>
  <volume id="39">
    <meta>
      <booktitle>Proceedings of the 2nd Workshop on Noisy User-generated Text (<fixed-case>WNUT</fixed-case>)</booktitle>
      <url hash="6aa5caec">W16-39</url>
      <editor><first>Bo</first><last>Han</last></editor>
      <editor><first>Alan</first><last>Ritter</last></editor>
      <editor><first>Leon</first><last>Derczynski</last></editor>
      <editor><first>Wei</first><last>Xu</last></editor>
      <editor><first>Tim</first><last>Baldwin</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="759bfa84">W16-3900</url>
    </frontmatter>
    <paper id="1">
      <title>Processing non-canonical or noisy text: fortuitous data to the rescue</title>
      <author><first>Barbara</first> <last>Plank</last></author>
      <pages>1</pages>
      <url hash="7f56f0b3">W16-3901</url>
      <abstract>Real world data differs radically from the benchmark corpora we use in NLP, resulting in large performance drops. The reason for this problem is obvious: NLP models are trained on limited samples from canonical varieties considered standard. However, there are many dimensions, e.g., sociodemographic, language, genre, sentence type, etc. on which texts can differ from the standard. The solution is not obvious: we cannot control for all factors, and it is not clear how to best go beyond the current practice of training on homogeneous data from a single domain and language. In this talk, I review the notion of canonicity, and how it shapes our community’s approach to language. I argue for the use of fortuitous data. Fortuitous data is data out there that just waits to be harvested. It includes data which is in plain sight, but is often neglected, and more distant sources like behavioral data, which first need to be refined. They provide additional contexts and a myriad of opportunities to build more adaptive language technology, some of which I will explore in this talk.</abstract>
    </paper>
    <paper id="2">
      <title>From Entity Linking to Question Answering – Recent Progress on Semantic Grounding Tasks</title>
      <author><first>Ming-Wei</first> <last>Chang</last></author>
      <pages>2</pages>
      <url hash="94158619">W16-3902</url>
      <abstract>Entity linking and semantic parsing have been shown to be crucial to important applications such as question answering and document understanding. These tasks often require structured learning models, which make predictions on multiple interdependent variables. In this talk, I argue that carefully designed structured learning algorithms play a central role in entity linking and semantic parsing tasks. In particular, I will present several new structured learning models for entity linking, which jointly detect mentions and disambiguate entities as well as capture non-textual information. I will then show how to use a staged search procedure to building a state-of-the-art knowledge base question answering system. Finally, if time permits, I will discuss different supervision protocols for training semantic parsers and the value of labeling semantic parses.</abstract>
    </paper>
    <paper id="3">
      <title><fixed-case>DISAANA</fixed-case> and <fixed-case>D</fixed-case>-<fixed-case>SUMM</fixed-case>: Large-scale Real Time <fixed-case>NLP</fixed-case> Systems for Analyzing Disaster Related Reports in Tweets</title>
      <author><first>Kentaro</first> <last>Torisawa</last></author>
      <pages>3</pages>
      <url hash="5f63c164">W16-3903</url>
      <abstract>This talk presents two NLP systems that were developed for helping disaster victims and rescue workers in the aftermath of large-scale disasters. DISAANA provides answers to questions such as “What is in short supply in Tokyo?” and displays locations related to each answer on a map. D-SUMM automatically summarizes a large number of disaster related reports concerning a specified area and helps rescue workers to understand disaster situations from a macro perspective. Both systems are publicly available as Web services. In the aftermath of the 2016 Kumamoto Earthquake (M7.0), the Japanese government actually used DISAANA to analyze the situation.</abstract>
    </paper>
    <paper id="4">
      <title>Private or Corporate? Predicting User Types on <fixed-case>T</fixed-case>witter</title>
      <author><first>Nikola</first> <last>Ljubešić</last></author>
      <author><first>Darja</first> <last>Fišer</last></author>
      <pages>4–12</pages>
      <url hash="6c407c61">W16-3904</url>
      <abstract>In this paper we present a series of experiments on discriminating between private and corporate accounts on Twitter. We define features based on Twitter metadata, morphosyntactic tags and surface forms, showing that the simple bag-of-words model achieves single best results that can, however, be improved by building a weighted soft ensemble of classifiers based on each feature type. Investigating the time and language dependence of each feature type delivers quite unexpecting results showing that features based on metadata are neither time- nor language-insensitive as the way the two user groups use the social network varies heavily through time and space.</abstract>
    </paper>
    <paper id="5">
      <title>From Noisy Questions to <fixed-case>M</fixed-case>inecraft Texts: Annotation Challenges in Extreme Syntax Scenario</title>
      <author><first>Héctor</first> <last>Martínez Alonso</last></author>
      <author><first>Djamé</first> <last>Seddah</last></author>
      <author><first>Benoît</first> <last>Sagot</last></author>
      <pages>13–23</pages>
      <url hash="c12fe1d0">W16-3905</url>
      <abstract>User-generated content presents many challenges for its automatic processing. While many of them do come from out-of-vocabulary effects, others spawn from different linguistic phenomena such as unusual syntax. In this work we present a French three-domain data set made up of question headlines from a cooking forum, game chat logs and associated forums from two popular online games (MINECRAFT &amp; LEAGUE OF LEGENDS). We chose these domains because they encompass different degrees of lexical and syntactic compliance with canonical language. We conduct an automatic and manual evaluation of the difficulties of processing these domains for part-of-speech prediction, and introduce a pilot study to determine whether dependency analysis lends itself well to annotate these data. We also discuss the development cost of our data set.</abstract>
    </paper>
    <paper id="6">
      <title>Disaster Analysis using User-Generated Weather Report</title>
      <author><first>Yasunobu</first> <last>Asakura</last></author>
      <author><first>Masatsugu</first> <last>Hangyo</last></author>
      <author><first>Mamoru</first> <last>Komachi</last></author>
      <pages>24–32</pages>
      <url hash="fb0c4b59">W16-3906</url>
      <abstract>Information extraction from user-generated text has gained much attention with the growth of the Web.Disaster analysis using information from social media provides valuable, real-time, geolocation information for helping people caught up these in disasters. However, it is not convenient to analyze texts posted on social media because disaster keywords match any texts that contain words. For collecting posts about a disaster from social media, we need to develop a classifier to filter posts irrelevant to disasters. Moreover, because of the nature of social media, we can take advantage of posts that come with GPS information. However, a post does not always refer to an event occurring at the place where it has been posted. Therefore, we propose a new task of classifying whether a flood disaster occurred, in addition to predicting the geolocation of events from user-generated text. We report the annotation of the flood disaster corpus and develop a classifier to demonstrate the use of this corpus for disaster analysis.</abstract>
    </paper>
    <paper id="7">
      <title>Veracity Computing from Lexical Cues and Perceived Certainty Trends</title>
      <author><first>Uwe</first> <last>Reichel</last></author>
      <author><first>Piroska</first> <last>Lendvai</last></author>
      <pages>33–42</pages>
      <url hash="6fd6850b">W16-3907</url>
      <abstract>We present a data-driven method for determining the veracity of a set of rumorous claims on social media data. Tweets from different sources pertaining to a rumor are processed on three levels: first, factuality values are assigned to each tweet based on four textual cue categories relevant for our journalism use case; these amalgamate speaker support in terms of polarity and commitment in terms of certainty and speculation. Next, the proportions of these lexical cues are utilized as predictors for tweet certainty in a generalized linear regression model. Subsequently, lexical cue proportions, predicted certainty, as well as their time course characteristics are used to compute veracity for each rumor in terms of the identity of the rumor-resolving tweet and its binary resolution value judgment. The system operates without access to extralinguistic resources. Evaluated on the data portion for which hand-labeled examples were available, it achieves .74 F1-score on identifying rumor resolving tweets and .76 F1-score on predicting if a rumor is resolved as true or false.</abstract>
    </paper>
    <paper id="8">
      <title>A Simple but Effective Approach to Improve <fixed-case>A</fixed-case>rabizi-to-<fixed-case>E</fixed-case>nglish Statistical Machine Translation</title>
      <author><first>Marlies</first> <last>van der Wees</last></author>
      <author><first>Arianna</first> <last>Bisazza</last></author>
      <author><first>Christof</first> <last>Monz</last></author>
      <pages>43–50</pages>
      <url hash="1a9f4fb4">W16-3908</url>
      <abstract>A major challenge for statistical machine translation (SMT) of Arabic-to-English user-generated text is the prevalence of text written in Arabizi, or Romanized Arabic. When facing such texts, a translation system trained on conventional Arabic-English data will suffer from extremely low model coverage. In addition, Arabizi is not regulated by any official standardization and therefore highly ambiguous, which prevents rule-based approaches from achieving good translation results. In this paper, we improve Arabizi-to-English machine translation by presenting a simple but effective Arabizi-to-Arabic transliteration pipeline that does not require knowledge by experts or native Arabic speakers. We incorporate this pipeline into a phrase-based SMT system, and show that translation quality after automatically transliterating Arabizi to Arabic yields results that are comparable to those achieved after human transliteration.</abstract>
    </paper>
    <paper id="9">
      <title>Name Variation in Community Question Answering Systems</title>
      <author><first>Anietie</first> <last>Andy</last></author>
      <author><first>Satoshi</first> <last>Sekine</last></author>
      <author><first>Mugizi</first> <last>Rwebangira</last></author>
      <author><first>Mark</first> <last>Dredze</last></author>
      <pages>51–60</pages>
      <url hash="17fa975c">W16-3909</url>
      <abstract>Name Variation in Community Question Answering Systems Abstract Community question answering systems are forums where users can ask and answer questions in various categories. Examples are Yahoo! Answers, Quora, and Stack Overflow. A common challenge with such systems is that a significant percentage of asked questions are left unanswered. In this paper, we propose an algorithm to reduce the number of unanswered questions in Yahoo! Answers by reusing the answer to the most similar past resolved question to the unanswered question, from the site. Semantically similar questions could be worded differently, thereby making it difficult to find questions that have shared needs. For example, “Who is the best player for the Reds?” and “Who is currently the biggest star at Manchester United?” have a shared need but are worded differently; also, “Reds” and “Manchester United” are used to refer to the soccer team Manchester United football club. In this research, we focus on question categories that contain a large number of named entities and entity name variations. We show that in these categories, entity linking can be used to identify relevant past resolved questions with shared needs as a given question by disambiguating named entities and matching these questions based on the disambiguated entities, identified entities, and knowledge base information related to these entities. We evaluated our algorithm on a new dataset constructed from Yahoo! Answers. The dataset contains annotated question pairs, (Qgiven, [Qpast, Answer]). We carried out experiments on several question categories and show that an entity-based approach gives good performance when searching for similar questions in entity rich categories.</abstract>
    </paper>
    <paper id="10">
      <title>Whose Nickname is This? Recognizing Politicians from Their Aliases</title>
      <author><first>Wei-Chung</first> <last>Wang</last></author>
      <author><first>Hung-Chen</first> <last>Chen</last></author>
      <author><first>Zhi-Kai</first> <last>Ji</last></author>
      <author><first>Hui-I</first> <last>Hsiao</last></author>
      <author><first>Yu-Shian</first> <last>Chiu</last></author>
      <author><first>Lun-Wei</first> <last>Ku</last></author>
      <pages>61–69</pages>
      <url hash="b3ad71d1">W16-3910</url>
      <abstract>Using aliases to refer to public figures is one way to make fun of people, to express sarcasm, or even to sidestep legal issues when expressing opinions on social media. However, linking an alias back to the real name is difficult, as it entails phonemic, graphemic, and semantic challenges. In this paper, we propose a phonemic-based approach and inject semantic information to align aliases with politicians’ Chinese formal names. The proposed approach creates an HMM model for each name to model its phonemes and takes into account document-level pairwise mutual information to capture the semantic relations to the alias. In this work we also introduce two new datasets consisting of 167 phonemic pairs and 279 mixed pairs of aliases and formal names. Experimental results show that the proposed approach models both phonemic and semantic information and outperforms previous work on both the phonemic and mixed datasets with the best top-1 accuracies of 0.78 and 0.59 respectively.</abstract>
    </paper>
    <paper id="11">
      <title>Towards Accurate Event Detection in Social Media: A Weakly Supervised Approach for Learning Implicit Event Indicators</title>
      <author><first>Ajit</first> <last>Jain</last></author>
      <author><first>Girish</first> <last>Kasiviswanathan</last></author>
      <author><first>Ruihong</first> <last>Huang</last></author>
      <pages>70–77</pages>
      <url hash="20d11bad">W16-3911</url>
      <abstract>Accurate event detection in social media is very challenging because user generated contents are extremely noisy and sparse in content. Event indicators are generally words or phrases that act as a trigger that help us understand the semantics of the context they occur in. We present a weakly supervised approach that relies on using a single strong event indicator phrase as a seed to acquire a variety of additional event cues. We propose to leverage various types of implicit event indicators, such as props, actors and precursor events, to achieve precise event detection. We experimented with civil unrest events and show that the automatically learnt event indicators are effective in identifying specific types of events.</abstract>
    </paper>
    <paper id="12">
      <title>Unsupervised Stemmer for <fixed-case>A</fixed-case>rabic Tweets</title>
      <author><first>Fahad</first> <last>Albogamy</last></author>
      <author><first>Allan</first> <last>Ramsay</last></author>
      <pages>78–84</pages>
      <url hash="a7890888">W16-3912</url>
      <abstract>Stemming is an essential processing step in a wide range of high level text processing applications such as information extraction, machine translation and sentiment analysis. It is used to reduce words to their stems. Many stemming algorithms have been developed for Modern Standard Arabic (MSA). Although Arabic tweets and MSA are closely related and share many characteristics, there are substantial differences between them in lexicon and syntax. In this paper, we introduce a light Arabic stemmer for Arabic tweets. Our results show improvements over the performance of a number of well-known stemmers for Arabic.</abstract>
    </paper>
    <paper id="13">
      <title>Topic Stability over Noisy Sources</title>
      <author><first>Jing</first> <last>Su</last></author>
      <author><first>Derek</first> <last>Greene</last></author>
      <author><first>Oisín</first> <last>Boydell</last></author>
      <pages>85–93</pages>
      <url hash="4fd8e974">W16-3913</url>
      <abstract>Topic modelling techniques such as LDA have recently been applied to speech transcripts and OCR output. These corpora may contain noisy or erroneous texts which may undermine topic stability. Therefore, it is important to know how well a topic modelling algorithm will perform when applied to noisy data. In this paper we show that different types of textual noise can have diverse effects on the stability of topic models. On the other hand, topic model stability is not consistent with the same type but different levels of noise. We introduce a dictionary filtering approach to address this challenge, with the result that a topic model with the correct number of topics is always identified across different levels of noise.</abstract>
    </paper>
    <paper id="14">
      <title>Analysis of <fixed-case>T</fixed-case>witter Data for Postmarketing Surveillance in Pharmacovigilance</title>
      <author><first>Julie</first> <last>Pain</last></author>
      <author><first>Jessie</first> <last>Levacher</last></author>
      <author><first>Adam</first> <last>Quinquenel</last></author>
      <author><first>Anja</first> <last>Belz</last></author>
      <pages>94–101</pages>
      <url hash="e20030d4">W16-3914</url>
      <abstract>Postmarketing surveillance (PMS) has the vital aim to monitor effects of drugs after release for use by the general population, but suffers from under-reporting and limited coverage. Automatic methods for detecting drug effect reports, especially for social media, could vastly increase the scope of PMS. Very few automatic PMS methods are currently available, in particular for the messy text types encountered on Twitter. In this paper we describe first results for developing PMS methods specifically for tweets. We describe the corpus of 125,669 tweets we have created and annotated to train and test the tools. We find that generic tools perform well for tweet-level language identification and tweet-level sentiment analysis (both 0.94 F1-Score). For detection of effect mentions we are able to achieve 0.87 F1-Score, while effect-level adverse-vs.-beneficial analysis proves harder with an F1-Score of 0.64. Among other things, our results indicate that MetaMap semantic types provide a very promising basis for identifying drug effect mentions in tweets.</abstract>
    </paper>
    <paper id="15">
      <title>Named Entity Recognition and Hashtag Decomposition to Improve the Classification of Tweets</title>
      <author><first>Billal</first> <last>Belainine</last></author>
      <author><first>Alexsandro</first> <last>Fonseca</last></author>
      <author><first>Fatiha</first> <last>Sadat</last></author>
      <pages>102–111</pages>
      <url hash="a2bfa60e">W16-3915</url>
      <abstract>In social networks services like Twitter, users are overwhelmed with huge amount of social data, most of which are short, unstructured and highly noisy. Identifying accurate information from this huge amount of data is indeed a hard task. Classification of tweets into organized form will help the user to easily access these required information. Our first contribution relates to filtering parts of speech and preprocessing this kind of highly noisy and short data. Our second contribution concerns the named entity recognition (NER) in tweets. Thus, the adaptation of existing language tools for natural languages, noisy and not accurate language tweets, is necessary. Our third contribution involves segmentation of hashtags and a semantic enrichment using a combination of relations from WordNet, which helps the performance of our classification system, including disambiguation of named entities, abbreviations and acronyms. Graph theory is used to cluster the words extracted from WordNet and tweets, based on the idea of connected components. We test our automatic classification system with four categories: politics, economy, sports and the medical field. We evaluate and compare several automatic classification systems using part or all of the items described in our contributions and found that filtering by part of speech and named entity recognition dramatically increase the classification precision to 77.3 %. Moreover, a classification system incorporating segmentation of hashtags and semantic enrichment by two relations from WordNet, synonymy and hyperonymy, increase classification precision up to 83.4 %.</abstract>
    </paper>
    <paper id="16">
      <title>Exploring Word Embeddings for Unsupervised Textual User-Generated Content Normalization</title>
      <author><first>Thales Felipe</first> <last>Costa Bertaglia</last></author>
      <author><first>Maria das Graças</first> <last>Volpe Nunes</last></author>
      <pages>112–120</pages>
      <url hash="3867f38e">W16-3916</url>
      <abstract>Text normalization techniques based on rules, lexicons or supervised training requiring large corpora are not scalable nor domain interchangeable, and this makes them unsuitable for normalizing user-generated content (UGC). Current tools available for Brazilian Portuguese make use of such techniques. In this work we propose a technique based on distributed representation of words (or word embeddings). It generates continuous numeric vectors of high-dimensionality to represent words. The vectors explicitly encode many linguistic regularities and patterns, as well as syntactic and semantic word relationships. Words that share semantic similarity are represented by similar vectors. Based on these features, we present a totally unsupervised, expandable and language and domain independent method for learning normalization lexicons from word embeddings. Our approach obtains high correction rate of orthographic errors and internet slang in product reviews, outperforming the current available tools for Brazilian Portuguese.</abstract>
    </paper>
    <paper id="17">
      <title>How Document Pre-processing affects Keyphrase Extraction Performance</title>
      <author><first>Florian</first> <last>Boudin</last></author>
      <author><first>Hugo</first> <last>Mougard</last></author>
      <author><first>Damien</first> <last>Cram</last></author>
      <pages>121–128</pages>
      <url hash="bd8e0218">W16-3917</url>
      <abstract>The SemEval-2010 benchmark dataset has brought renewed attention to the task of automatic keyphrase extraction. This dataset is made up of scientific articles that were automatically converted from PDF format to plain text and thus require careful preprocessing so that irrevelant spans of text do not negatively affect keyphrase extraction performance. In previous work, a wide range of document preprocessing techniques were described but their impact on the overall performance of keyphrase extraction models is still unexplored. Here, we re-assess the performance of several keyphrase extraction models and measure their robustness against increasingly sophisticated levels of document preprocessing.</abstract>
    </paper>
    <paper id="18">
      <title><fixed-case>J</fixed-case>apanese Text Normalization with Encoder-Decoder Model</title>
      <author><first>Taishi</first> <last>Ikeda</last></author>
      <author><first>Hiroyuki</first> <last>Shindo</last></author>
      <author><first>Yuji</first> <last>Matsumoto</last></author>
      <pages>129–137</pages>
      <url hash="d2482776">W16-3918</url>
      <abstract>Text normalization is the task of transforming lexical variants to their canonical forms. We model the problem of text normalization as a character-level sequence to sequence learning problem and present a neural encoder-decoder model for solving it. To train the encoder-decoder model, many sentences pairs are generally required. However, Japanese non-standard canonical pairs are scarce in the form of parallel corpora. To address this issue, we propose a method of data augmentation to increase data size by converting existing resources into synthesized non-standard forms using handcrafted rules. We conducted an experiment to demonstrate that the synthesized corpus contributes to stably train an encoder-decoder model and improve the performance of Japanese text normalization.</abstract>
    </paper>
    <paper id="19">
      <title>Results of the <fixed-case>WNUT</fixed-case>16 Named Entity Recognition Shared Task</title>
      <author><first>Benjamin</first> <last>Strauss</last></author>
      <author><first>Bethany</first> <last>Toma</last></author>
      <author><first>Alan</first> <last>Ritter</last></author>
      <author><first>Marie-Catherine</first> <last>de Marneffe</last></author>
      <author><first>Wei</first> <last>Xu</last></author>
      <pages>138–144</pages>
      <url hash="0119d2e1">W16-3919</url>
      <abstract>This paper presents the results of the Twitter Named Entity Recognition shared task associated with W-NUT 2016: a named entity tagging task with 10 teams participating. We outline the shared task, annotation process and dataset statistics, and provide a high-level overview of the participating systems for each shared task.</abstract>
    </paper>
    <paper id="20">
      <title>Bidirectional <fixed-case>LSTM</fixed-case> for Named Entity Recognition in <fixed-case>T</fixed-case>witter Messages</title>
      <author><first>Nut</first> <last>Limsopatham</last></author>
      <author><first>Nigel</first> <last>Collier</last></author>
      <pages>145–152</pages>
      <url hash="cc3e2f33">W16-3920</url>
      <abstract>In this paper, we present our approach for named entity recognition in Twitter messages that we used in our participation in the Named Entity Recognition in Twitter shared task at the COLING 2016 Workshop on Noisy User-generated text (WNUT). The main challenge that we aim to tackle in our participation is the short, noisy and colloquial nature of tweets, which makes named entity recognition in Twitter message a challenging task. In particular, we investigate an approach for dealing with this problem by enabling bidirectional long short-term memory (LSTM) to automatically learn orthographic features without requiring feature engineering. In comparison with other systems participating in the shared task, our system achieved the most effective performance on both the ‘segmentation and categorisation’ and the ‘segmentation only’ sub-tasks.</abstract>
    </paper>
    <paper id="21">
      <title>Learning to recognise named entities in tweets by exploiting weakly labelled data</title>
      <author><first>Kurt Junshean</first> <last>Espinosa</last></author>
      <author><first>Riza Theresa</first> <last>Batista-Navarro</last></author>
      <author><first>Sophia</first> <last>Ananiadou</last></author>
      <pages>153–163</pages>
      <url hash="39fd6b92">W16-3921</url>
      <abstract>Named entity recognition (NER) in social media (e.g., Twitter) is a challenging task due to the noisy nature of text. As part of our participation in the W-NUT 2016 Named Entity Recognition Shared Task, we proposed an unsupervised learning approach using deep neural networks and leverage a knowledge base (i.e., DBpedia) to bootstrap sparse entity types with weakly labelled data. To further boost the performance, we employed a more sophisticated tagging scheme and applied dropout as a regularisation technique in order to reduce overfitting. Even without hand-crafting linguistic features nor leveraging any of the W-NUT-provided gazetteers, we obtained robust performance with our approach, which ranked third amongst all shared task participants according to the official evaluation on a gold standard named entity-annotated corpus of 3,856 tweets.</abstract>
    </paper>
    <paper id="22">
      <title>Feature-Rich <fixed-case>T</fixed-case>witter Named Entity Recognition and Classification</title>
      <author><first>Utpal Kumar</first> <last>Sikdar</last></author>
      <author><first>Björn</first> <last>Gambäck</last></author>
      <pages>164–170</pages>
      <url hash="611f16cb">W16-3922</url>
      <abstract>Twitter named entity recognition is the process of identifying proper names and classifying them into some predefined labels/categories. The paper introduces a Twitter named entity system using a supervised machine learning approach, namely Conditional Random Fields. A large set of different features was developed and the system was trained using these. The Twitter named entity task can be divided into two parts: i) Named entity extraction from tweets and ii) Twitter name classification into ten different types. For Twitter named entity recognition on unseen test data, our system obtained the second highest F1 score in the shared task: 63.22%. The system performance on the classification task was worse, with an F1 measure of 40.06% on unseen test data, which was the fourth best of the ten systems participating in the shared task.</abstract>
    </paper>
    <paper id="23">
      <title>Learning to Search for Recognizing Named Entities in <fixed-case>T</fixed-case>witter</title>
      <author><first>Ioannis</first> <last>Partalas</last></author>
      <author><first>Cédric</first> <last>Lopez</last></author>
      <author><first>Nadia</first> <last>Derbas</last></author>
      <author><first>Ruslan</first> <last>Kalitvianski</last></author>
      <pages>171–177</pages>
      <url hash="39881933">W16-3923</url>
      <abstract>We presented in this work our participation in the 2nd Named Entity Recognition for Twitter shared task. The task has been cast as a sequence labeling one and we employed a learning to search approach in order to tackle it. We also leveraged LOD for extracting rich contextual features for the named-entities. Our submission achieved F-scores of 46.16 and 60.24 for the classification and the segmentation tasks and ranked 2nd and 3rd respectively. The post-analysis showed that LOD features improved substantially the performance of our system as they counter-balance the lack of context in tweets. The shared task gave us the opportunity to test the performance of NER systems in short and noisy textual data. The results of the participated systems shows that the task is far to be considered as a solved one and methods with stellar performance in normal texts need to be revised.</abstract>
    </paper>
    <paper id="24">
      <title><fixed-case>D</fixed-case>eep<fixed-case>NNNER</fixed-case>: Applying <fixed-case>BLSTM</fixed-case>-<fixed-case>CNN</fixed-case>s and Extended Lexicons to Named Entity Recognition in Tweets</title>
      <author><first>Fabrice</first> <last>Dugas</last></author>
      <author><first>Eric</first> <last>Nichols</last></author>
      <pages>178–187</pages>
      <url hash="1dabcef3">W16-3924</url>
      <abstract>In this paper, we describe the DeepNNNER entry to The 2nd Workshop on Noisy User-generated Text (WNUT) Shared Task #2: Named Entity Recognition in Twitter. Our shared task submission adopts the bidirectional LSTM-CNN model of Chiu and Nichols (2016), as it has been shown to perform well on both newswire and Web texts. It uses word embeddings trained on large-scale Web text collections together with text normalization to cope with the diversity in Web texts, and lexicons for target named entity classes constructed from publicly-available sources. Extended evaluation comparing the effectiveness of various word embeddings, text normalization, and lexicon settings shows that our system achieves a maximum F1-score of 47.24, performance surpassing that of the shared task’s second-ranked system.</abstract>
    </paper>
    <paper id="25">
      <title><fixed-case>ASU</fixed-case>: An Experimental Study on Applying Deep Learning in <fixed-case>T</fixed-case>witter Named Entity Recognition.</title>
      <author><first>Michel Naim</first> <last>Gerguis</last></author>
      <author><first>Cherif</first> <last>Salama</last></author>
      <author><first>M. Watheq</first> <last>El-Kharashi</last></author>
      <pages>188–196</pages>
      <url hash="edbcbeda">W16-3925</url>
      <abstract>This paper describes the ASU system submitted in the COLING W-NUT 2016 Twitter Named Entity Recognition (NER) task. We present an experimental study on applying deep learning to extracting named entities (NEs) from tweets. We built two Long Short-Term Memory (LSTM) models for the task. The first model was built to extract named entities without types while the second model was built to extract and then classify them into 10 fine-grained entity classes. In this effort, we show detailed experimentation results on the effectiveness of word embeddings, brown clusters, part-of-speech (POS) tags, shape features, gazetteers, and local context for the tweet input vector representation to the LSTM model. Also, we present a set of experiments, to better design the network parameters for the Twitter NER task. Our system was ranked the fifth out of ten participants with a final f1-score for the typed classes of 39% and 55% for the non typed ones.</abstract>
    </paper>
    <paper id="26">
      <title><fixed-case>UQAM</fixed-case>-<fixed-case>NTL</fixed-case>: Named entity recognition in <fixed-case>T</fixed-case>witter messages</title>
      <author><first>Ngoc Tan</first> <last>Le</last></author>
      <author><first>Fatma</first> <last>Mallek</last></author>
      <author><first>Fatiha</first> <last>Sadat</last></author>
      <pages>197–202</pages>
      <url hash="8845ed95">W16-3926</url>
      <abstract>This paper describes our system used in the 2nd Workshop on Noisy User-generated Text (WNUT) shared task for Named Entity Recognition (NER) in Twitter, in conjunction with Coling 2016. Our system is based on supervised machine learning by applying Conditional Random Fields (CRF) to train two classifiers for two evaluations. The first evaluation aims at predicting the 10 fine-grained types of named entities; while the second evaluation aims at predicting no type of named entities. The experimental results show that our method has significantly improved Twitter NER performance.</abstract>
    </paper>
    <paper id="27">
      <title>Semi-supervised Named Entity Recognition in noisy-text</title>
      <author><first>Shubhanshu</first> <last>Mishra</last></author>
      <author><first>Jana</first> <last>Diesner</last></author>
      <pages>203–212</pages>
      <url hash="cb4276bc">W16-3927</url>
      <abstract>Many of the existing Named Entity Recognition (NER) solutions are built based on news corpus data with proper syntax. These solutions might not lead to highly accurate results when being applied to noisy, user generated data, e.g., tweets, which can feature sloppy spelling, concept drift, and limited contextualization of terms and concepts due to length constraints. The models described in this paper are based on linear chain conditional random fields (CRFs), use the BIEOU encoding scheme, and leverage random feature dropout for up-sampling the training data. The considered features include word clusters and pre-trained distributed word representations, updated gazetteer features, and global context predictions. The latter feature allows for ingesting the meaning of new or rare tokens into the system via unsupervised learning and for alleviating the need to learn lexicon based features, which usually tend to be high dimensional. In this paper, we report on the solution [ST] we submitted to the WNUT 2016 NER shared task. We also present an improvement over our original submission [SI], which we built by using semi-supervised learning on labelled training data and pre-trained resourced constructed from unlabelled tweet data. Our ST solution achieved an F1 score of 1.2% higher than the baseline (35.1% F1) for the task of extracting 10 entity types. The SI resulted in an increase of 8.2% in F1 score over the base-line (7.08% over ST). Finally, the SI model’s evaluation on the test data achieved a F1 score of 47.3% (~1.15% increase over the 2nd best submitted solution). Our experimental setup and results are available as a standalone twitter NER tool at <url>https://github.com/napsternxg/TwitterNER</url>.
    </abstract>
    </paper>
    <paper id="28">
      <title><fixed-case>T</fixed-case>witter Geolocation Prediction Shared Task of the 2016 Workshop on Noisy User-generated Text</title>
      <author><first>Bo</first> <last>Han</last></author>
      <author><first>Afshin</first> <last>Rahimi</last></author>
      <author><first>Leon</first> <last>Derczynski</last></author>
      <author><first>Timothy</first> <last>Baldwin</last></author>
      <pages>213–217</pages>
      <url hash="7d824871">W16-3928</url>
      <abstract>This paper presents the shared task for English Twitter geolocation prediction in WNUT 2016. We discuss details of task settings, data preparations and participant systems. The derived dataset and performance figures from each system provide baselines for future research in this realm.</abstract>
    </paper>
    <paper id="29">
      <title><fixed-case>CSIRO</fixed-case> <fixed-case>D</fixed-case>ata61 at the <fixed-case>WNUT</fixed-case> Geo Shared Task</title>
      <author><first>Gaya</first> <last>Jayasinghe</last></author>
      <author><first>Brian</first> <last>Jin</last></author>
      <author><first>James</first> <last>Mchugh</last></author>
      <author><first>Bella</first> <last>Robinson</last></author>
      <author><first>Stephen</first> <last>Wan</last></author>
      <pages>218–226</pages>
      <url hash="0a3e069b">W16-3929</url>
      <abstract>In this paper, we describe CSIRO Data61’s participation in the Geolocation shared task at the Workshop for Noisy User-generated Text. Our approach was to use ensemble methods to capitalise on four component methods: heuristics based on metadata, a label propagation method, timezone text classifiers, and an information retrieval approach. The ensembles we explored focused on examining the role of language technologies in geolocation prediction and also in examining the use of hard voting and cascading ensemble methods. Based on the accuracy of city-level predictions, our systems were the best performing submissions at this year’s shared task. Furthermore, when estimating the latitude and longitude of a user, our median error distance was accurate to within 30 kilometers.</abstract>
    </paper>
    <paper id="30">
      <title>Geolocation Prediction in <fixed-case>T</fixed-case>witter Using Location Indicative Words and Textual Features</title>
      <author><first>Lianhua</first> <last>Chi</last></author>
      <author><first>Kwan Hui</first> <last>Lim</last></author>
      <author><first>Nebula</first> <last>Alam</last></author>
      <author><first>Christopher J.</first> <last>Butler</last></author>
      <pages>227–234</pages>
      <url hash="e5d6f742">W16-3930</url>
      <abstract>Knowing the location of a social media user and their posts is important for various purposes, such as the recommendation of location-based items/services, and locality detection of crisis/disasters. This paper describes our submission to the shared task “Geolocation Prediction in Twitter” of the 2nd Workshop on Noisy User-generated Text. In this shared task, we propose an algorithm to predict the location of Twitter users and tweets using a multinomial Naive Bayes classifier trained on Location Indicative Words and various textual features (such as city/country names, #hashtags and @mentions). We compared our approach against various baselines based on Location Indicative Words, city/country names, #hashtags and @mentions as individual feature sets, and experimental results show that our approach outperforms these baselines in terms of classification accuracy, mean and median error distance.</abstract>
    </paper>
    <paper id="31">
      <title>A Simple Scalable Neural Networks based Model for Geolocation Prediction in <fixed-case>T</fixed-case>witter</title>
      <author><first>Yasuhide</first> <last>Miura</last></author>
      <author><first>Motoki</first> <last>Taniguchi</last></author>
      <author><first>Tomoki</first> <last>Taniguchi</last></author>
      <author><first>Tomoko</first> <last>Ohkuma</last></author>
      <pages>235–239</pages>
      <url hash="245d9fdc">W16-3931</url>
      <abstract>This paper describes a model that we submitted to W-NUT 2016 Shared task #1: Geolocation Prediction in Twitter. Our model classifies a tweet or a user to a city using a simple neural networks structure with fully-connected layers and average pooling processes. From the findings of previous geolocation prediction approaches, we integrated various user metadata along with message texts and trained the model with them. In the test run of the task, the model achieved the accuracy of 40.91% and the median distance error of 69.50 km in message-level prediction and the accuracy of 47.55% and the median distance error of 16.13 km in user-level prediction. These results are moderate performances in terms of accuracy and best performances in terms of distance. The results show a promising extension of neural networks based models for geolocation prediction where recent advances in neural networks can be added to enhance our current simple model.</abstract>
    </paper>
  </volume>
  <volume id="40">
    <meta>
      <booktitle>Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (<fixed-case>LT</fixed-case>4<fixed-case>DH</fixed-case>)</booktitle>
      <url hash="2a879f05">W16-40</url>
      <editor><first>Erhard</first><last>Hinrichs</last></editor>
      <editor><first>Marie</first><last>Hinrichs</last></editor>
      <editor><first>Thorsten</first><last>Trippel</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="1a78077e">W16-4000</url>
    </frontmatter>
    <paper id="1">
      <title>Flexible and Reliable Text Analytics in the Digital Humanities – Some Methodological Considerations</title>
      <author><first>Jonas</first> <last>Kuhn</last></author>
      <pages>1</pages>
      <url hash="b2117c83">W16-4001</url>
      <abstract>The availability of Language Technology Resources and Tools generates a considerable methodological potential in the Digital Humanities: aspects of research questions from the Humanities and Social Sciences can be addressed on text collections in ways that were unavailable to traditional approaches. I start this talk by sketching some sample scenarios of Digital Humanities projects which involve various Humanities and Social Science disciplines, noting that the potential for a meaningful contribution to higher-level questions is highest when the employed language technological models are carefully tailored both (a) to characteristics of the given target corpus, and (b) to relevant analytical subtasks feeding the discipline-specific research questions. Keeping up a multidisciplinary perspective, I then point out a recurrent dilemma in Digital Humanities projects that follow the conventional set-up of collaboration: to build high-quality computational models for the data, fixed analytical targets should be specified as early as possible – but to be able to respond to Humanities questions as they evolve over the course of analysis, the analytical machinery should be kept maximally flexible. To reach both, I argue for a novel collaborative culture that rests on a more interleaved, continuous dialogue. (Re-)Specification of analytical targets should be an ongoing process in which the Humanities Scholars and Social Scientists play a role that is as important as the Computational Scientists’ role. A promising approach lies in the identification of re-occurring types of analytical subtasks, beyond linguistic standard tasks, which can form building blocks for text analysis across disciplines, and for which corpus-based characterizations (viz. annotations) can be collected, compared and revised. On such grounds, computational modeling is more directly tied to the evolving research questions, and hence the seemingly opposing needs of reliable target specifications vs. “malleable” frameworks of analysis can be reconciled. Experimental work following this approach is under way in the Center for Reflected Text Analytics (CRETA) in Stuttgart.</abstract>
    </paper>
    <paper id="2">
      <title>Finding Rising and Falling Words</title>
      <author><first>Erik</first> <last>Tjong Kim Sang</last></author>
      <pages>2–9</pages>
      <url hash="307a279b">W16-4002</url>
      <abstract>We examine two different methods for finding rising words (among which neologisms) and falling words (among which archaisms) in decades of magazine texts (millions of words) and in years of tweets (billions of words): one based on correlation coefficients of relative frequencies and time, and one based on comparing initial and final word frequencies of time intervals. We find that smoothing frequency scores improves the precision scores of both methods and that the correlation coefficients perform better on magazine text but worse on tweets. Since the two ranking methods find different words they can be used in side-by-side to study the behavior of words over time.</abstract>
    </paper>
    <paper id="3">
      <title>A Dataset for Multimodal Question Answering in the Cultural Heritage Domain</title>
      <author><first>Shurong</first> <last>Sheng</last></author>
      <author><first>Luc</first> <last>Van Gool</last></author>
      <author><first>Marie-Francine</first> <last>Moens</last></author>
      <pages>10–17</pages>
      <url hash="ff914652">W16-4003</url>
      <abstract>Multimodal question answering in the cultural heritage domain allows visitors to ask questions in a more natural way and thus provides better user experiences with cultural objects while visiting a museum, landmark or any other historical site. In this paper, we introduce the construction of a golden standard dataset that will aid research of multimodal question answering in the cultural heritage domain. The dataset, which will be soon released to the public, contains multimodal content including images of typical artworks from the fascinating old-Egyptian Amarna period, related image-containing documents of the artworks and over 800 multimodal queries integrating visual and textual questions. The multimodal questions and related documents are all in English. The multimodal questions are linked to relevant paragraphs in the related documents that contain the answer to the multimodal query.</abstract>
    </paper>
    <paper id="4">
      <title>Extracting Social Networks from Literary Text with Word Embedding Tools</title>
      <author><first>Gerhard</first> <last>Wohlgenannt</last></author>
      <author><first>Ekaterina</first> <last>Chernyak</last></author>
      <author><first>Dmitry</first> <last>Ilvovsky</last></author>
      <pages>18–25</pages>
      <url hash="ac3fec15">W16-4004</url>
      <abstract>In this paper a social network is extracted from a literary text. The social network shows, how frequent the characters interact and how similar their social behavior is. Two types of similarity measures are used: the first applies co-occurrence statistics, while the second exploits cosine similarity on different types of word embedding vectors. The results are evaluated by a paid micro-task crowdsourcing survey. The experiments suggest that specific types of word embeddings like word2vec are well-suited for the task at hand and the specific circumstances of literary fiction text.</abstract>
    </paper>
    <paper id="5">
      <title>Exploration of register-dependent lexical semantics using word embeddings</title>
      <author><first>Andrey</first> <last>Kutuzov</last></author>
      <author><first>Elizaveta</first> <last>Kuzmenko</last></author>
      <author><first>Anna</first> <last>Marakasova</last></author>
      <pages>26–34</pages>
      <url hash="934f200f">W16-4005</url>
      <abstract>We present an approach to detect differences in lexical semantics across English language registers, using word embedding models from distributional semantics paradigm. Models trained on register-specific subcorpora of the BNC corpus are employed to compare lists of nearest associates for particular words and draw conclusions about their semantic shifts depending on register in which they are used. The models are evaluated on the task of register classification with the help of the deep inverse regression approach. Additionally, we present a demo web service featuring most of the described models and allowing to explore word meanings in different English registers and to detect register affiliation for arbitrary texts. The code for the service can be easily adapted to any set of underlying models.</abstract>
    </paper>
    <paper id="6">
      <title>Original-Transcribed Text Alignment for <fixed-case>M</fixed-case>anyosyu Written by <fixed-case>O</fixed-case>ld <fixed-case>J</fixed-case>apanese Language</title>
      <author><first>Teruaki</first> <last>Oka</last></author>
      <author><first>Tomoaki</first> <last>Kono</last></author>
      <pages>35–44</pages>
      <url hash="08e2d651">W16-4006</url>
      <abstract>We are constructing an annotated diachronic corpora of the Japanese language. In part of thiswork, we construct a corpus of Manyosyu, which is an old Japanese poetry anthology. In thispaper, we describe how to align the transcribed text and its original text semiautomatically to beable to cross-reference them in our Manyosyu corpus. Although we align the original charactersto the transcribed words manually, we preliminarily align the transcribed and original charactersby using an unsupervised automatic alignment technique of statistical machine translation toalleviate the work. We found that automatic alignment achieves an F1-measure of 0.83; thus, each poem has 1–2 alignment errors. However, finding these errors and modifying them are less workintensiveand more efficient than fully manual annotation. The alignment probabilities can beutilized in this modification. Moreover, we found that we can locate the uncertain transcriptionsin our corpus and compare them to other transcriptions, by using the alignment probabilities.</abstract>
    </paper>
    <paper id="7">
      <title><fixed-case>S</fixed-case>hamela: A Large-Scale Historical <fixed-case>A</fixed-case>rabic Corpus</title>
      <author><first>Yonatan</first> <last>Belinkov</last></author>
      <author><first>Alexander</first> <last>Magidow</last></author>
      <author><first>Maxim</first> <last>Romanov</last></author>
      <author><first>Avi</first> <last>Shmidman</last></author>
      <author><first>Moshe</first> <last>Koppel</last></author>
      <pages>45–53</pages>
      <url hash="d38498e8">W16-4007</url>
      <abstract>Arabic is a widely-spoken language with a rich and long history spanning more than fourteen centuries. Yet existing Arabic corpora largely focus on the modern period or lack sufficient diachronic information. We develop a large-scale, historical corpus of Arabic of about 1 billion words from diverse periods of time. We clean this corpus, process it with a morphological analyzer, and enhance it by detecting parallel passages and automatically dating undated texts. We demonstrate its utility with selected case-studies in which we show its application to the digital humanities.</abstract>
    </paper>
    <paper id="8">
      <title>Feelings from the <fixed-case>P</fixed-case>ast—<fixed-case>A</fixed-case>dapting Affective Lexicons for Historical Emotion Analysis</title>
      <author><first>Sven</first> <last>Buechel</last></author>
      <author><first>Johannes</first> <last>Hellrich</last></author>
      <author><first>Udo</first> <last>Hahn</last></author>
      <pages>54–61</pages>
      <url hash="935bbe17">W16-4008</url>
      <abstract>We here describe a novel methodology for measuring affective language in historical text by expanding an affective lexicon and jointly adapting it to prior language stages. We automatically construct a lexicon for word-emotion association of 18th and 19th century German which is then validated against expert ratings. Subsequently, this resource is used to identify distinct emotional patterns and trace long-term emotional trends in different genres of writing spanning several centuries.</abstract>
    </paper>
    <paper id="9">
      <title>Automatic parsing as an efficient pre-annotation tool for historical texts</title>
      <author><first>Hanne Martine</first> <last>Eckhoff</last></author>
      <author><first>Aleksandrs</first> <last>Berdičevskis</last></author>
      <pages>62–70</pages>
      <url hash="9367a82e">W16-4009</url>
      <abstract>Historical treebanks tend to be manually annotated, which is not surprising, since state-of-the-art parsers are not accurate enough to ensure high-quality annotation for historical texts. We test whether automatic parsing can be an efficient pre-annotation tool for Old East Slavic texts. We use the TOROT treebank from the PROIEL treebank family. We convert the PROIEL format to the CONLL format and use MaltParser to create syntactic pre-annotation. Using the most conservative evaluation method, which takes into account PROIEL-specific features, MaltParser by itself yields 0.845 unlabelled attachment score, 0.779 labelled attachment score and 0.741 secondary dependency accuracy (note, though, that the test set comes from a relatively simple genre and contains rather short sentences). Experiments with human annotators show that preparsing, if limited to sentences where no changes to word or sentence boundaries are required, increases their annotation rate. For experienced annotators, the speed gain varies from 5.80% to 16.57%, for inexperienced annotators from 14.61% to 32.17% (using conservative estimates). There are no strong reliable differences in the annotation accuracy, which means that there is no reason to suspect that using preparsing might lower the final annotation quality.</abstract>
    </paper>
    <paper id="10">
      <title>A Visual Representation of <fixed-case>W</fixed-case>ittgenstein’s <fixed-case>T</fixed-case>ractatus Logico-Philosophicus</title>
      <author><first>Anca</first> <last>Bucur</last></author>
      <author><first>Sergiu</first> <last>Nisioi</last></author>
      <pages>71–75</pages>
      <url hash="04646b6c">W16-4010</url>
      <abstract>In this paper we will discuss a method for data visualization together with its potential usefulness in digital humanities and philosophy of language. We compiled a multilingual parallel corpus from different versions of <i>Wittgenstein’s Tractatus Logico-philosophicus</i>, including the original in German and translations into English, Spanish, French, and Russian. Using this corpus, we compute a similarity measure between propositions and render a visual network of relations for different languages. </abstract>
    </paper>
    <paper id="11">
      <title>A Web-based Tool for the Integrated Annotation of Semantic and Syntactic Structures</title>
      <author><first>Richard</first> <last>Eckart de Castilho</last></author>
      <author><first>Éva</first> <last>Mújdricza-Maydt</last></author>
      <author><first>Seid Muhie</first> <last>Yimam</last></author>
      <author><first>Silvana</first> <last>Hartmann</last></author>
      <author><first>Iryna</first> <last>Gurevych</last></author>
      <author><first>Anette</first> <last>Frank</last></author>
      <author><first>Chris</first> <last>Biemann</last></author>
      <pages>76–84</pages>
      <url hash="5c204154">W16-4011</url>
      <abstract>We introduce the third major release of WebAnno, a generic web-based annotation tool for distributed teams. New features in this release focus on semantic annotation tasks (e.g. semantic role labelling or event annotation) and allow the tight integration of semantic annotations with syntactic annotations. In particular, we introduce the concept of slot features, a novel constraint mechanism that allows modelling the interaction between semantic and syntactic annotations, as well as a new annotation user interface. The new features were developed and used in an annotation project for semantic roles on German texts. The paper briefly introduces this project and reports on experiences performing annotations with the new tool. On a comparative evaluation, our tool reaches significant speedups over WebAnno 2 for a semantic annotation task.</abstract>
    </paper>
    <paper id="12">
      <title>Challenges and Solutions for <fixed-case>L</fixed-case>atin Named Entity Recognition</title>
      <author><first>Alexander</first> <last>Erdmann</last></author>
      <author><first>Christopher</first> <last>Brown</last></author>
      <author><first>Brian</first> <last>Joseph</last></author>
      <author><first>Mark</first> <last>Janse</last></author>
      <author><first>Petra</first> <last>Ajaka</last></author>
      <author><first>Micha</first> <last>Elsner</last></author>
      <author><first>Marie-Catherine</first> <last>de Marneffe</last></author>
      <pages>85–93</pages>
      <url hash="fe450160">W16-4012</url>
      <abstract>Although spanning thousands of years and genres as diverse as liturgy, historiography, lyric and other forms of prose and poetry, the body of Latin texts is still relatively sparse compared to English. Data sparsity in Latin presents a number of challenges for traditional Named Entity Recognition techniques. Solving such challenges and enabling reliable Named Entity Recognition in Latin texts can facilitate many down-stream applications, from machine translation to digital historiography, enabling Classicists, historians, and archaeologists for instance, to track the relationships of historical persons, places, and groups on a large scale. This paper presents the first annotated corpus for evaluating Named Entity Recognition in Latin, as well as a fully supervised model that achieves over 90% F-score on a held-out test set, significantly outperforming a competitive baseline. We also present a novel active learning strategy that predicts how many and which sentences need to be annotated for named entities in order to attain a specified degree of accuracy when recognizing named entities automatically in a given text. This maximizes the productivity of annotators while simultaneously controlling quality.</abstract>
    </paper>
    <paper id="13">
      <title>Geographical Visualization of Search Results in Historical Corpora</title>
      <author><first>Florian</first> <last>Petran</last></author>
      <pages>94–100</pages>
      <url hash="4b47d980">W16-4013</url>
      <abstract>We present ANNISVis, a webapp for comparative visualization of geographical distribution of linguistic data, as well as a sample deployment for a corpus of Middle High German texts. Unlike existing geographical visualization solutions, which work with pre-existing data sets, or are bound to specific corpora, ANNISVis allows the user to formulate multiple ad-hoc queries and visualizes them on a map, and it can be configured for any corpus that can be imported into ANNIS. This enables explorative queries of the quantitative aspects of a corpus with geographical features. The tool will be made available to download in open source.</abstract>
    </paper>
    <paper id="14">
      <title>Implementation of a Workflow Management System for Non-Expert Users</title>
      <author><first>Bart</first> <last>Jongejan</last></author>
      <pages>101–108</pages>
      <url hash="8bd36c62">W16-4014</url>
      <abstract>In the Danish CLARIN-DK infrastructure, chaining language technology (LT) tools into a workflow is easy even for a non-expert user, because she only needs to specify the input and the desired output of the workflow. With this information and the registered input and output profiles of the available tools, the CLARIN-DK workflow management system (WMS) computes combinations of tools that will give the desired result. This advanced functionality was originally not envisaged, but came within reach by writing the WMS partly in Java and partly in a programming language for symbolic computation, Bracmat. Handling LT tool profiles, including the computation of workflows, is easier with Bracmat’s language constructs for tree pattern matching and tree construction than with the language constructs offered by mainstream programming languages.</abstract>
    </paper>
    <paper id="15">
      <title>Integrating Optical Character Recognition and Machine Translation of Historical Documents</title>
      <author><first>Haithem</first> <last>Afli</last></author>
      <author><first>Andy</first> <last>Way</last></author>
      <pages>109–116</pages>
      <url hash="cd3ebc50">W16-4015</url>
      <abstract>Machine Translation (MT) plays a critical role in expanding capacity in the translation industry. However, many valuable documents, including digital documents, are encoded in non-accessible formats for machine processing (e.g., Historical or Legal documents). Such documents must be passed through a process of Optical Character Recognition (OCR) to render the text suitable for MT. No matter how good the OCR is, this process introduces recognition errors, which often renders MT ineffective. In this paper, we propose a new OCR to MT framework based on adding a new OCR error correction module to enhance the overall quality of translation. Experimentation shows that our new system correction based on the combination of Language Modeling and Translation methods outperforms the baseline system by nearly 30% relative improvement.</abstract>
    </paper>
    <paper id="16">
      <title>Language technology tools and resources for the analysis of multimodal communication</title>
      <author><first>László</first> <last>Hunyadi</last></author>
      <author><first>Tamás</first> <last>Váradi</last></author>
      <author><first>István</first> <last>Szekrényes</last></author>
      <pages>117–124</pages>
      <url hash="c93697d0">W16-4016</url>
      <abstract>In this paper we describe how the complexity of human communication can be analysed with the help of language technology. We present the HuComTech corpus, a multimodal corpus containing 50 hours of videotaped interviews containing a rich annotation of about 2 million items annotated on 33 levels. The corpus serves as a general resource for a wide range of re-search addressing natural conversation between humans in their full complexity. It can benefit particularly digital humanities researchers working in the field of pragmatics, conversational analysis and discourse analysis. We will present a number of tools and automated methods that can help such enquiries. In particular, we will highlight the tool Theme, which is designed to uncover hidden temporal patterns (called T-patterns) in human interaction, and will show how it can applied to the study of multimodal communication.</abstract>
    </paper>
    <paper id="17">
      <title>Large-scale Analysis of Spoken Free-verse Poetry</title>
      <author><first>Timo</first> <last>Baumann</last></author>
      <author><first>Burkhard</first> <last>Meyer-Sickendiek</last></author>
      <pages>125–130</pages>
      <url hash="6fed2d9a">W16-4017</url>
      <abstract>Most modern and post-modern poems have developed a post-metrical idea of lyrical prosody that employs rhythmical features of everyday language and prose instead of a strict adherence to rhyme and metrical schemes. This development is subsumed under the term free verse prosody. We present our methodology for the large-scale analysis of modern and post-modern poetry in both their written form and as spoken aloud by the author. We employ language processing tools to align text and speech, to generate a null-model of how the poem would be spoken by a naïve reader, and to extract contrastive prosodic features used by the poet. On these, we intend to build our model of free verse prosody, which will help to understand, differentiate and relate the different styles of free verse poetry. We plan to use our processing scheme on large amounts of data to iteratively build models of styles, to validate and guide manual style annotation, to identify further rhythmical categories, and ultimately to broaden our understanding of free verse poetry. In this paper, we report on a proof-of-concept of our methodology using smaller amounts of poems and a limited set of features. We find that our methodology helps to extract differentiating features in the authors’ speech that can be explained by philological insight. Thus, our automatic method helps to guide the literary analysis and this in turn helps to improve our computational models.</abstract>
    </paper>
    <paper id="18">
      <title><fixed-case>PAT</fixed-case> workbench: Annotation and Evaluation of Text and Pictures in Multimodal Instructions</title>
      <author><first>Ielka</first> <last>van der Sluis</last></author>
      <author><first>Lennart</first> <last>Kloppenburg</last></author>
      <author><first>Gisela</first> <last>Redeker</last></author>
      <pages>131–139</pages>
      <url hash="6fe7c24f">W16-4018</url>
      <abstract>This paper presents a tool to investigate the design of multimodal instructions (MIs), i.e., instructions that contain both text and pictures. The benefit of including pictures in information presentation has been established, but the characteristics of those pictures and of their textual counterparts and the rela-tion(s) between them have not been researched in a systematic manner. We present the PAT Work-bench, a tool to store, annotate and retrieve MIs based on a validated coding scheme with currently 42 categories that describe instructions in terms of textual features, pictorial elements, and relations be-tween text and pictures. We describe how the PAT Workbench facilitates collaborative annotation and inter-annotator agreement calculation. Future work on the tool includes expanding its functionality and usability by (i) making the MI annotation scheme dynamic for adding relevant features based on empirical evaluations of the MIs, (ii) implementing algorithms for automatic tagging of MI features, and (iii) implementing automatic MI evaluation algorithms based on results obtained via e.g. crowdsourced assessments of MIs.</abstract>
    </paper>
    <paper id="19">
      <title>Semantic Indexing of Multilingual Corpora and its Application on the History Domain</title>
      <author><first>Alessandro</first> <last>Raganato</last></author>
      <author><first>Jose</first> <last>Camacho-Collados</last></author>
      <author><first>Antonio</first> <last>Raganato</last></author>
      <author><first>Yunseo</first> <last>Joung</last></author>
      <pages>140–147</pages>
      <url hash="7d6b4a3f">W16-4019</url>
      <abstract>The increasing amount of multilingual text collections available in different domains makes its automatic processing essential for the development of a given field. However, standard processing techniques based on statistical clues and keyword searches have clear limitations. Instead, we propose a knowledge-based processing pipeline which overcomes most of the limitations of these techniques. This, in turn, enables direct comparison across texts in different languages without the need of translation. In this paper we show the potential of this approach for semantically indexing multilingual text collections in the history domain. In our experiments we used a version of the Bible translated in four different languages, evaluating the precision of our semantic indexing pipeline and showing its reliability on the cross-lingual text retrieval task.</abstract>
    </paper>
    <paper id="20">
      <title>Tagging <fixed-case>I</fixed-case>ngush - Language Technology For Low-Resource Languages Using Resources From Linguistic Field Work</title>
      <author><first>Jörg</first> <last>Tiedemann</last></author>
      <author><first>Johanna</first> <last>Nichols</last></author>
      <author><first>Ronald</first> <last>Sprouse</last></author>
      <pages>148–155</pages>
      <url hash="cad46122">W16-4020</url>
      <abstract>This paper presents on-going work on creating NLP tools for under-resourced languages from very sparse training data coming from linguistic field work. In this work, we focus on Ingush, a Nakh-Daghestanian language spoken by about 300,000 people in the Russian republics Ingushetia and Chechnya. We present work on morphosyntactic taggers trained on transcribed and linguistically analyzed recordings and dependency parsers using English glosses to project annotation for creating synthetic treebanks. Our preliminary results are promising, supporting the goal of bootstrapping efficient NLP tools with limited or no task-specific annotated data resources available.</abstract>
    </paper>
    <paper id="21">
      <title>The <fixed-case>M</fixed-case>ulti<fixed-case>T</fixed-case>al <fixed-case>NLP</fixed-case> tool infrastructure</title>
      <author><first>Driss</first> <last>Sadoun</last></author>
      <author><first>Satenik</first> <last>Mkhitaryan</last></author>
      <author><first>Damien</first> <last>Nouvel</last></author>
      <author><first>Mathieu</first> <last>Valette</last></author>
      <pages>156–163</pages>
      <url hash="92cc199b">W16-4021</url>
      <abstract>This paper gives an overview of the MultiTal project, which aims to create a research infrastructure that ensures long-term distribution of NLP tools descriptions. The goal is to make NLP tools more accessible and usable to end-users of different disciplines. The infrastructure is built on a meta-data scheme modelling and standardising multilingual NLP tools documentation. The model is conceptualised using an OWL ontology. The formal representation of the ontology allows us to automatically generate organised and structured documentation in different languages for each represented tool.</abstract>
    </paper>
    <paper id="22">
      <title>Tools and Instruments for Building and Querying Diachronic Computational Lexica</title>
      <author><first>Fahad</first> <last>Khan</last></author>
      <author><first>Andrea</first> <last>Bellandi</last></author>
      <author><first>Monica</first> <last>Monachini</last></author>
      <pages>164–171</pages>
      <url hash="157e8f70">W16-4022</url>
      <abstract>This article describes work on enabling the addition of temporal information to senses of words in linguistic linked open data lexica based on the lemonDia model. Our contribution in this article is twofold. On the one hand, we demonstrate how lemonDia enables the querying of diachronic lexical datasets using OWL-oriented Semantic Web based technologies. On the other hand, we present a preliminary version of an interactive interface intended to help users in creating lexical datasets that model meaning change over time.</abstract>
    </paper>
    <paper id="23">
      <title>Tracking Words in <fixed-case>C</fixed-case>hinese Poetry of <fixed-case>T</fixed-case>ang and <fixed-case>S</fixed-case>ong Dynasties with the <fixed-case>C</fixed-case>hina <fixed-case>B</fixed-case>iographical <fixed-case>D</fixed-case>atabase</title>
      <author><first>Chao-Lin</first> <last>Liu</last></author>
      <author><first>Kuo-Feng</first> <last>Luo</last></author>
      <pages>172–180</pages>
      <url hash="a6003c94">W16-4023</url>
      <abstract>(This is the abstract for the submission.) Large-scale comparisons between the poetry of Tang and Song dynasties shed light on how words and expressions were used and shared among the poets. That some words were used only in the Tang poetry and some only in the Song poetry could lead to interesting research in linguistics. That the most frequent colors are different in the Tang and Song poetry provides a trace of the changing social circumstances in the dynasties. Results of the current work link to research topics of lexicography, semantics, and social transitions. We discuss our findings and present our algorithms for efficient comparisons among the poems, which are crucial for completing billion times of comparisons within acceptable time.</abstract>
    </paper>
    <paper id="24">
      <title>Using <fixed-case>TEI</fixed-case> for textbook research</title>
      <author><first>Lena-Luise</first> <last>Stahn</last></author>
      <author><first>Steffen</first> <last>Hennicke</last></author>
      <author><first>Ernesto William</first> <last>De Luca</last></author>
      <pages>181–186</pages>
      <url hash="5d6d6a79">W16-4024</url>
      <abstract>The following paper describes the first steps in the development of an ontology for the textbook research discipline. The aim of the project WorldViews is to establish a digital edition focussing on views of the world depicted in textbooks. For this purpose an initial TEI profile has been formalised and tested as a use case to enable the semantical encoding of the resource ‘textbook’. This profile shall provide a basic data model describing major facets of the textbook’s structure relevant to historians.</abstract>
    </paper>
    <paper id="25">
      <title>Web services and data mining: combining linguistic tools for <fixed-case>P</fixed-case>olish with an analytical platform</title>
      <author><first>Maciej</first> <last>Ogrodniczuk</last></author>
      <pages>187–195</pages>
      <url hash="7f57a99c">W16-4025</url>
      <abstract>In this paper we present a new combination of existing language tools for Polish with a popular data mining platform intended to help researchers from digital humanities perform computational analyses without any programming. The toolset includes RapidMiner Studio, a software solution offering graphical setup of integrated analytical processes and Multiservice, a Web service offering access to several state-of-the-art linguistic tools for Polish. The setting is verified in a simple task of counting frequencies of unknown words in a small corpus.</abstract>
    </paper>
  </volume>
  <volume id="41">
    <meta>
      <booktitle>Proceedings of the Workshop on Computational Linguistics for Linguistic Complexity (<fixed-case>CL</fixed-case>4<fixed-case>LC</fixed-case>)</booktitle>
      <url hash="c33e59d9">W16-41</url>
      <editor><first>Dominique</first><last>Brunato</last></editor>
      <editor><first>Felice</first><last>Dell’Orletta</last></editor>
      <editor><first>Giulia</first><last>Venturi</last></editor>
      <editor><first>Thomas</first><last>François</last></editor>
      <editor><first>Philippe</first><last>Blache</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="e98ba154">W16-4100</url>
    </frontmatter>
    <paper id="1">
      <title>Could Machine Learning Shed Light on Natural Language Complexity?</title>
      <author><first>Maria Dolores</first> <last>Jiménez-López</last></author>
      <author><first>Leonor</first> <last>Becerra-Bonache</last></author>
      <pages>1–11</pages>
      <url hash="b8358efc">W16-4101</url>
      <abstract>In this paper, we propose to use a subfield of machine learning –grammatical inference– to measure linguistic complexity from a developmental point of view. We focus on relative complexity by considering a child learner in the process of first language acquisition. The relevance of grammatical inference models for measuring linguistic complexity from a developmental point of view is based on the fact that algorithms proposed in this area can be considered computational models for studying first language acquisition. Even though it will be possible to use different techniques from the field of machine learning as computational models for dealing with linguistic complexity -since in any model we have algorithms that can learn from data-, we claim that grammatical inference models offer some advantages over other tools.</abstract>
    </paper>
    <paper id="2">
      <title>Towards a Distributional Model of Semantic Complexity</title>
      <author><first>Emmanuele</first> <last>Chersoni</last></author>
      <author><first>Philippe</first> <last>Blache</last></author>
      <author><first>Alessandro</first> <last>Lenci</last></author>
      <pages>12–22</pages>
      <url hash="6138ef53">W16-4102</url>
      <abstract>In this paper, we introduce for the first time a Distributional Model for computing semantic complexity, inspired by the general principles of the Memory, Unification and Control framework(Hagoort, 2013; Hagoort, 2016). We argue that sentence comprehension is an incremental process driven by the goal of constructing a coherent representation of the event represented by the sentence. The composition cost of a sentence depends on the semantic coherence of the event being constructed and on the activation degree of the linguistic constructions. We also report the results of a first evaluation of the model on the Bicknell dataset (Bicknell et al., 2010).</abstract>
    </paper>
    <paper id="3">
      <title><fixed-case>C</fixed-case>o<fixed-case>C</fixed-case>o<fixed-case>G</fixed-case>en - Complexity Contour Generator: Automatic Assessment of Linguistic Complexity Using a Sliding-Window Technique</title>
      <author><first>Ströbel</first> <last>Marcus</last></author>
      <author><first>Elma</first> <last>Kerz</last></author>
      <author><first>Daniel</first> <last>Wiechmann</last></author>
      <author><first>Stella</first> <last>Neumann</last></author>
      <pages>23–31</pages>
      <url hash="409ed0e9">W16-4103</url>
      <abstract>We present a novel approach to the automatic assessment of text complexity based on a sliding-window technique that tracks the distribution of complexity within a text. Such distribution is captured by what we term “complexity contours” derived from a series of measurements for a given linguistic complexity measure. This approach is implemented in an automatic computational tool, CoCoGen – Complexity Contour Generator, which in its current version supports 32 indices of linguistic complexity. The goal of the paper is twofold: (1) to introduce the design of our computational tool based on a sliding-window technique and (2) to showcase this approach in the area of second language (L2) learning, i.e. more specifically, in the area of L2 writing.</abstract>
    </paper>
    <paper id="4">
      <title>Addressing surprisal deficiencies in reading time models</title>
      <author><first>Marten</first> <last>van Schijndel</last></author>
      <author><first>William</first> <last>Schuler</last></author>
      <pages>32–37</pages>
      <url hash="c6e995fa">W16-4104</url>
      <abstract>This study demonstrates a weakness in how n-gram and PCFG surprisal are used to predict reading times in eye-tracking data. In particular, the information conveyed by words skipped during saccades is not usually included in the surprisal measures. This study shows that correcting the surprisal calculation improves n-gram surprisal and that upcoming n-grams affect reading times, replicating previous findings of how lexical frequencies affect reading times. In contrast, the predictivity of PCFG surprisal does not benefit from the surprisal correction despite the fact that lexical sequences skipped by saccades are processed by readers, as demonstrated by the corrected n-gram measure. These results raise questions about the formulation of information-theoretic measures of syntactic processing such as PCFG surprisal and entropy reduction when applied to reading times.</abstract>
    </paper>
    <paper id="5">
      <title>Towards grounding computational linguistic approaches to readability: Modeling reader-text interaction for easy and difficult texts</title>
      <author><first>Sowmya</first> <last>Vajjala</last></author>
      <author><first>Detmar</first> <last>Meurers</last></author>
      <author><first>Alexander</first> <last>Eitel</last></author>
      <author><first>Katharina</first> <last>Scheiter</last></author>
      <pages>38–48</pages>
      <url hash="59b88aab">W16-4105</url>
      <abstract>Computational approaches to readability assessment are generally built and evaluated using gold standard corpora labeled by publishers or teachers rather than being grounded in observations about human performance. Considering that both the reading process and the outcome can be observed, there is an empirical wealth that could be used to ground computational analysis of text readability. This will also support explicit readability models connecting text complexity and the reader’s language proficiency to the reading process and outcomes. This paper takes a step in this direction by reporting on an experiment to study how the relation between text complexity and reader’s language proficiency affects the reading process and performance outcomes of readers after reading We modeled the reading process using three eye tracking variables: fixation count, average fixation count, and second pass reading duration. Our models for these variables explained 78.9%, 74% and 67.4% variance, respectively. Performance outcome was modeled through recall and comprehension questions, and these models explained 58.9% and 27.6% of the variance, respectively. While the online models give us a better understanding of the cognitive correlates of reading with text complexity and language proficiency, modeling of the offline measures can be particularly relevant for incorporating user aspects into readability models.</abstract>
    </paper>
    <paper id="6">
      <title>Memory access during incremental sentence processing causes reading time latency</title>
      <author><first>Cory</first> <last>Shain</last></author>
      <author><first>Marten</first> <last>van Schijndel</last></author>
      <author><first>Richard</first> <last>Futrell</last></author>
      <author><first>Edward</first> <last>Gibson</last></author>
      <author><first>William</first> <last>Schuler</last></author>
      <pages>49–58</pages>
      <url hash="7694c1ca">W16-4106</url>
      <abstract>Studies on the role of memory as a predictor of reading time latencies (1) differ in their predictions about when memory effects should occur in processing and (2) have had mixed results, with strong positive effects emerging from isolated constructed stimuli and weak or even negative effects emerging from naturally-occurring stimuli. Our study addresses these concerns by comparing several implementations of prominent sentence processing theories on an exploratory corpus and evaluating the most successful of these on a confirmatory corpus, using a new self-paced reading corpus of seemingly natural narratives constructed to contain an unusually high proportion of memory-intensive constructions. We show highly significant and complementary broad-coverage latency effects both for predictors based on the Dependency Locality Theory and for predictors based on a left-corner parsing model of sentence processing. Our results indicate that memory access during sentence processing does take time, but suggest that stimuli requiring many memory access events may be necessary in order to observe the effect.</abstract>
    </paper>
    <paper id="7">
      <title>Reducing lexical complexity as a tool to increase text accessibility for children with dyslexia</title>
      <author><first>Núria</first> <last>Gala</last></author>
      <author><first>Johannes</first> <last>Ziegler</last></author>
      <pages>59–66</pages>
      <url hash="d87b23e6">W16-4107</url>
      <abstract>Lexical complexity plays a central role in readability, particularly for dyslexic children and poor readers because of their slow and laborious decoding and word recognition skills. Although some features to aid readability may be common to most languages (e.g., the majority of ‘easy’ words are of low frequency), we believe that lexical complexity is mainly language-specific. In this paper, we define lexical complexity for French and we present a pilot study on the effects of text simplification in dyslexic children. The participants were asked to read out loud original and manually simplified versions of a standardized French text corpus and to answer comprehension questions after reading each text. The analysis of the results shows that the simplifications performed were beneficial in terms of reading speed and they reduced the number of reading errors (mainly lexical ones) without a loss in comprehension. Although the number of participants in this study was rather small (N=10), the results are promising and contribute to the development of applications in computational linguistics.</abstract>
    </paper>
    <paper id="8">
      <title>Syntactic and Lexical Complexity in <fixed-case>I</fixed-case>talian Noncanonical Structures</title>
      <author><first>Rodolfo</first> <last>Delmonte</last></author>
      <pages>67–78</pages>
      <url hash="5ebb9cab">W16-4108</url>
      <abstract>In this paper we will be dealing with different levels of complexity in the processing of Italian, a Romance language inheriting many properties from Latin which make it an almost free word order language . The paper is concerned with syntactic complexity as measurable on the basis of the cognitive parser that incrementally builds up a syntactic representation to be used by the semantic component. The theory behind will be LFG and parsing preferences will be used to justify one choice both from a principled and a processing point of view. LFG is a transformationless theory in which there is no deep structure separate from surface syntactic structure. This is partially in accordance with constructional theories in which noncanonical structures containing non-argument functions FOCUS/TOPIC are treated as multifunctional constituents. Complexity is computed on a processing basis following suggestions made by Blache and demonstrated by Kluender and Chesi</abstract>
    </paper>
    <paper id="9">
      <title>Real Multi-Sense or Pseudo Multi-Sense: An Approach to Improve Word Representation</title>
      <author><first>Haoyue</first> <last>Shi</last></author>
      <author><first>Caihua</first> <last>Li</last></author>
      <author><first>Junfeng</first> <last>Hu</last></author>
      <pages>79–88</pages>
      <url hash="2cb2c587">W16-4109</url>
      <abstract>Previous researches have shown that learning multiple representations for polysemous words can improve the performance of word embeddings on many tasks. However, this leads to another problem. Several vectors of a word may actually point to the same meaning, namely pseudo multi-sense. In this paper, we introduce the concept of pseudo multi-sense, and then propose an algorithm to detect such cases. With the consideration of the detected pseudo multi-sense cases, we try to refine the existing word embeddings to eliminate the influence of pseudo multi-sense. Moreover, we apply our algorithm on previous released multi-sense word embeddings and tested it on artificial word similarity tasks and the analogy task. The result of the experiments shows that diminishing pseudo multi-sense can improve the quality of word representations. Thus, our method is actually an efficient way to reduce linguistic complexity.</abstract>
    </paper>
    <paper id="10">
      <title>A Preliminary Study of Statistically Predictive Syntactic Complexity Features and Manual Simplifications in <fixed-case>B</fixed-case>asque</title>
      <author><first>Itziar</first> <last>Gonzalez-Dios</last></author>
      <author><first>María Jesús</first> <last>Aranzabe</last></author>
      <author><first>Arantza</first> <last>Díaz de Ilarraza</last></author>
      <pages>89–97</pages>
      <url hash="d7549b89">W16-4110</url>
      <abstract>In this paper, we present a comparative analysis of statistically predictive syntactic features of complexity and the treatment of these features by humans when simplifying texts. To that end, we have used a list of the most five statistically predictive features obtained automatically and the Corpus of Basque Simplified Texts (CBST) to analyse how the syntactic phenomena in these features have been manually simplified. Our aim is to go beyond the descriptions of operations found in the corpus and relate the multidisciplinary findings to understand text complexity from different points of view. We also present some issues that can be important when analysing linguistic complexity.</abstract>
    </paper>
    <paper id="11">
      <title>Dynamic pause assessment of keystroke logged data for the detection of complexity in translation and monolingual text production</title>
      <author><first>Arndt</first> <last>Heilmann</last></author>
      <author><first>Stella</first> <last>Neumann</last></author>
      <pages>98–103</pages>
      <url hash="b8b655eb">W16-4111</url>
      <abstract>Pause analysis of key-stroke logged translations is a hallmark of process based translation studies. However, an exact definition of what a cognitively effortful pause during the translation process is has not been found yet (Saldanha and O’Brien, 2013). This paper investigates the design of a key-stroke and subject dependent identification system of cognitive effort to track complexity in translation with keystroke logging (cf. also (Dragsted, 2005) (Couto-Vale, in preparation)). It is an elastic measure that takes into account idiosyncratic pause duration of translators as well as further confounds such as bi-gram frequency, letter frequency and some motor tasks involved in writing. The method is compared to a common static threshold of 1000 ms in an analysis of cognitive effort during the translation of grammatical functions from English to German. Additionally, the results are triangulated with eye tracking data for further validation. The findings show that at least for smaller sets of data a dynamic pause assessment may lead to more accurate results than a generic static pause threshold of similar duration.</abstract>
    </paper>
    <paper id="12">
      <title>Implicit readability ranking using the latent variable of a <fixed-case>B</fixed-case>ayesian Probit model</title>
      <author><first>Johan</first> <last>Falkenjack</last></author>
      <author><first>Arne</first> <last>Jönsson</last></author>
      <pages>104–112</pages>
      <url hash="f85a4447">W16-4112</url>
      <abstract>Data driven approaches to readability analysis for languages other than English has been plagued by a scarcity of suitable corpora. Often, relevant corpora consist only of easy-to-read texts with no rank information or empirical readability scores, making only binary approaches, such as classification, applicable. We propose a Bayesian, latent variable, approach to get the most out of these kinds of corpora. In this paper we present results on using such a model for readability ranking. The model is evaluated on a preliminary corpus of ranked student texts with encouraging results. We also assess the model by showing that it performs readability classification on par with a state of the art classifier while at the same being transparent enough to allow more sophisticated interpretations.</abstract>
    </paper>
    <paper id="13">
      <title><fixed-case>CTAP</fixed-case>: A Web-Based Tool Supporting Automatic Complexity Analysis</title>
      <author><first>Xiaobin</first> <last>Chen</last></author>
      <author><first>Detmar</first> <last>Meurers</last></author>
      <pages>113–119</pages>
      <url hash="917cfb97">W16-4113</url>
      <abstract>Informed by research on readability and language acquisition, computational linguists have developed sophisticated tools for the analysis of linguistic complexity. While some tools are starting to become accessible on the web, there still is a disconnect between the features that can in principle be identified based on state-of-the-art computational linguistic analysis, and the analyses a second language acquisition researcher, teacher, or textbook writer can readily obtain and visualize for their own collection of texts. This short paper presents a web-based tool development that aims to meet this challenge. The Common Text Analysis Platform (CTAP) is designed to support fully configurable linguistic feature extraction for a wide range of complexity analyses. It features a user-friendly interface, modularized and reusable analysis component integration, and flexible corpus and feature management. Building on the Unstructured Information Management framework (UIMA), CTAP readily supports integration of state-of-the-art NLP and complexity feature extraction maintaining modularization and reusability. CTAP thereby aims at providing a common platform for complexity analysis, encouraging research collaboration and sharing of feature extraction components—to jointly advance the state-of-the-art in complexity analysis in a form that readily supports real-life use by ordinary users.</abstract>
    </paper>
    <paper id="14">
      <title>Coursebook Texts as a Helping Hand for Classifying Linguistic Complexity in Language Learners’ Writings</title>
      <author><first>Ildikó</first> <last>Pilán</last></author>
      <author><first>David</first> <last>Alfter</last></author>
      <author><first>Elena</first> <last>Volodina</last></author>
      <pages>120–126</pages>
      <url hash="c49c2775">W16-4114</url>
      <abstract>We bring together knowledge from two different types of language learning data, texts learners read and texts they write, to improve linguistic complexity classification in the latter. Linguistic complexity in the foreign and second language learning context can be expressed in terms of proficiency levels. We show that incorporating features capturing lexical complexity information from reading passages can boost significantly the machine learning based classification of learner-written texts into proficiency levels. With an F1 score of .8 our system rivals state-of-the-art results reported for other languages for this task. Finally, we present a freely available web-based tool for proficiency level classification and lexical complexity visualization for both learner writings and reading texts.</abstract>
    </paper>
    <paper id="15">
      <title>Using Ambiguity Detection to Streamline Linguistic Annotation</title>
      <author><first>Wajdi</first> <last>Zaghouani</last></author>
      <author><first>Abdelati</first> <last>Hawwari</last></author>
      <author><first>Sawsan</first> <last>Alqahtani</last></author>
      <author><first>Houda</first> <last>Bouamor</last></author>
      <author><first>Mahmoud</first> <last>Ghoneim</last></author>
      <author><first>Mona</first> <last>Diab</last></author>
      <author><first>Kemal</first> <last>Oflazer</last></author>
      <pages>127–136</pages>
      <url hash="fe6f7de0">W16-4115</url>
      <abstract>Arabic writing is typically underspecified for short vowels and other markups, referred to as diacritics. In addition to the lexical ambiguity exhibited in most languages, the lack of diacritics in written Arabic adds another layer of ambiguity which is an artifact of the orthography. In this paper, we present the details of three annotation experimental conditions designed to study the impact of automatic ambiguity detection, on annotation speed and quality in a large scale annotation project.</abstract>
    </paper>
    <paper id="16">
      <title>Morphological Complexity Influences Verb-Object Order in <fixed-case>S</fixed-case>wedish <fixed-case>S</fixed-case>ign <fixed-case>L</fixed-case>anguage</title>
      <author><first>Johannes</first> <last>Bjerva</last></author>
      <author><first>Carl</first> <last>Börstell</last></author>
      <pages>137–141</pages>
      <url hash="cd57413d">W16-4116</url>
      <abstract>Computational linguistic approaches to sign languages could benefit from investigating how complexity influences structure. We investigate whether morphological complexity has an effect on the order of Verb (V) and Object (O) in Swedish Sign Language (SSL), on the basis of elicited data from five Deaf signers. We find a significant difference in the distribution of the orderings OV vs. VO, based on an analysis of morphological weight. While morphologically heavy verbs exhibit a general preference for OV, humanness seems to affect the ordering in the opposite direction, with [+human] Objects pushing towards a preference for VO.</abstract>
    </paper>
    <paper id="17">
      <title>A Comparison Between Morphological Complexity Measures: Typological Data vs. Language Corpora</title>
      <author><first>Christian</first> <last>Bentz</last></author>
      <author><first>Tatyana</first> <last>Ruzsics</last></author>
      <author><first>Alexander</first> <last>Koplenig</last></author>
      <author><first>Tanja</first> <last>Samardžić</last></author>
      <pages>142–153</pages>
      <url hash="1b1f1404">W16-4117</url>
      <abstract>Language complexity is an intriguing phenomenon argued to play an important role in both language learning and processing. The need to compare languages with regard to their complexity resulted in a multitude of approaches and methods, ranging from accounts targeting specific structural features to global quantification of variation more generally. In this paper, we investigate the degree to which morphological complexity measures are mutually correlated in a sample of more than 500 languages of 101 language families. We use human expert judgements from the World Atlas of Language Structures (WALS), and compare them to four quantitative measures automatically calculated from language corpora. These consist of three previously defined corpus-derived measures, which are all monolingual, and one new measure based on automatic word-alignment across pairs of languages. We find strong correlations between all the measures, illustrating that both expert judgements and automated approaches converge to similar complexity ratings, and can be used interchangeably.</abstract>
    </paper>
    <paper id="18">
      <title>Similarity-Based Alignment of Monolingual Corpora for Text Simplification Purposes</title>
      <author><first>Sarah</first> <last>Albertsson</last></author>
      <author><first>Evelina</first> <last>Rennes</last></author>
      <author><first>Arne</first> <last>Jönsson</last></author>
      <pages>154–163</pages>
      <url hash="41260c1e">W16-4118</url>
      <abstract>Comparable or parallel corpora are beneficial for many NLP tasks. The automatic collection of corpora enables large-scale resources, even for less-resourced languages, which in turn can be useful for deducing rules and patterns for text rewriting algorithms, a subtask of automatic text simplification. We present two methods for the alignment of Swedish easy-to-read text segments to text segments from a reference corpus. The first method (M1) was originally developed for the task of text reuse detection, measuring sentence similarity by a modified version of a TF-IDF vector space model. A second method (M2), also accounting for part-of-speech tags, was developed, and the methods were compared. For evaluation, a crowdsourcing platform was built for human judgement data collection, and preliminary results showed that cosine similarity relates better to human ranks than the Dice coefficient. We also saw a tendency that including syntactic context to the TF-IDF vector space model is beneficial for this kind of paraphrase alignment task.</abstract>
    </paper>
    <paper id="19">
      <title>Automatic Construction of Large Readability Corpora</title>
      <author><first>Jorge Alberto</first> <last>Wagner Filho</last></author>
      <author><first>Rodrigo</first> <last>Wilkens</last></author>
      <author><first>Aline</first> <last>Villavicencio</last></author>
      <pages>164–173</pages>
      <url hash="d5d927af">W16-4119</url>
      <abstract>This work presents a framework for the automatic construction of large Web corpora classified by readability level. We compare different Machine Learning classifiers for the task of readability assessment focusing on Portuguese and English texts, analysing the impact of variables like the feature inventory used in the resulting corpus. In a comparison between shallow and deeper features, the former already produce F-measures of over 0.75 for Portuguese texts, but the use of additional features results in even better results, in most cases. For English, shallow features also perform well as do classic readability formulas. Comparing different classifiers for the task, logistic regression obtained, in general, the best results, but with considerable differences between the results for two and those for three-classes, especially regarding the intermediary class. Given the large scale of the resulting corpus, for evaluation we adopt the agreement between different classifiers as an indication of readability assessment certainty. As a result of this work, a large corpus for Brazilian Portuguese was built, including 1.7 million documents and about 1.6 billion tokens, already parsed and annotated with 134 different textual attributes, along with the agreement among the various classifiers.</abstract>
    </paper>
    <paper id="20">
      <title>Testing the Processing Hypothesis of word order variation using a probabilistic language model</title>
      <author><first>Jelke</first> <last>Bloem</last></author>
      <pages>174–185</pages>
      <url hash="658ff78c">W16-4120</url>
      <abstract>This work investigates the application of a measure of surprisal to modeling a grammatical variation phenomenon between near-synonymous constructions. We investigate a particular variation phenomenon, word order variation in Dutch two-verb clusters, where it has been established that word order choice is affected by processing cost. Several multifactorial corpus studies of Dutch verb clusters have used other measures of processing complexity to show that this factor affects word order choice. This previous work allows us to compare the surprisal measure, which is based on constraint satisfaction theories of language modeling, to those previously used measures, which are more directly linked to empirical observations of processing complexity. Our results show that surprisal does not predict the word order choice by itself, but is a significant predictor when used in a measure of uniform information density (UID). This lends support to the view that human language processing is facilitated not so much by predictable sequences of words but more by sequences of words in which information is spread evenly.</abstract>
    </paper>
    <paper id="21">
      <title>Temporal Lobes as Combinatory Engines for both Form and Meaning</title>
      <author><first>Jixing</first> <last>Li</last></author>
      <author><first>Jonathan</first> <last>Brennan</last></author>
      <author><first>Adam</first> <last>Mahar</last></author>
      <author><first>John</first> <last>Hale</last></author>
      <pages>186–191</pages>
      <url hash="97e26c1c">W16-4121</url>
      <abstract>The relative contributions of meaning and form to sentence processing remains an outstanding issue across the language sciences. We examine this issue by formalizing four incremental complexity metrics and comparing them against freely-available ROI timecourses. Syntax-related metrics based on top-down parsing and structural dependency-distance turn out to significantly improve a regression model, compared to a simpler model that formalizes only conceptual combination using a distributional vector-space model. This confirms the view of the anterior temporal lobes as combinatory engines that deal in both form (see e.g. Brennan et al., 2012; Mazoyer, 1993) and meaning (see e.g., Patterson et al., 2007). This same characterization applies to a posterior temporal region in roughly “Wernicke’s Area.”</abstract>
    </paper>
    <paper id="22">
      <title>Automatic Speech Recognition Errors as a Predictor of <fixed-case>L</fixed-case>2 Listening Difficulties</title>
      <author><first>Maryam Sadat</first> <last>Mirzaei</last></author>
      <author><first>Kourosh</first> <last>Meshgi</last></author>
      <author><first>Tatsuya</first> <last>Kawahara</last></author>
      <pages>192–201</pages>
      <url hash="53b9a7cd">W16-4122</url>
      <abstract>This paper investigates the use of automatic speech recognition (ASR) errors as indicators of the second language (L2) learners’ listening difficulties and in doing so strives to overcome the shortcomings of Partial and Synchronized Caption (PSC) system. PSC is a system that generates a partial caption including difficult words detected based on high speech rate, low frequency, and specificity. To improve the choice of words in this system, and explore a better method to detect speech challenges, ASR errors were investigated as a model of the L2 listener, hypothesizing that some of these errors are similar to those of language learners’ when transcribing the videos. To investigate this hypothesis, ASR errors in transcription of several TED talks were analyzed and compared with PSC’s selected words. Both the overlapping and mismatching cases were analyzed to investigate possible improvement for the PSC system. Those ASR errors that were not detected by PSC as cases of learners’ difficulties were further analyzed and classified into four categories: homophones, minimal pairs, breached boundaries and negatives. These errors were embedded into the baseline PSC to make the enhanced version and were evaluated in an experiment with L2 learners. The results indicated that the enhanced version, which encompasses the ASR errors addresses most of the L2 learners’ difficulties and better assists them in comprehending challenging video segments as compared with the baseline.</abstract>
    </paper>
    <paper id="23">
      <title>Quantifying sentence complexity based on eye-tracking measures</title>
      <author><first>Abhinav Deep</first> <last>Singh</last></author>
      <author><first>Poojan</first> <last>Mehta</last></author>
      <author><first>Samar</first> <last>Husain</last></author>
      <author><first>Rajkumar</first> <last>Rajakrishnan</last></author>
      <pages>202–212</pages>
      <url hash="3576ca5b">W16-4123</url>
      <abstract>Eye-tracking reading times have been attested to reflect cognitive processes underlying sentence comprehension. However, the use of reading times in NLP applications is an underexplored area of research. In this initial work we build an automatic system to assess sentence complexity using automatically predicted eye-tracking reading time measures and demonstrate the efficacy of these reading times for a well known NLP task, namely, readability assessment. We use a machine learning model and a set of features known to be significant predictors of reading times in order to learn per-word reading times from a corpus of English text having reading times of human readers. Subsequently, we use the model to predict reading times for novel text in the context of the aforementioned task. A model based only on reading times gave competitive results compared to the systems that use extensive syntactic features to compute linguistic complexity. Our work, to the best of our knowledge, is the first study to show that automatically predicted reading times can successfully model the difficulty of a text and can be deployed in practical text processing applications.</abstract>
    </paper>
    <paper id="24">
      <title>Upper Bound of Entropy Rate Revisited —<fixed-case>A</fixed-case> New Extrapolation of Compressed Large-Scale Corpora—</title>
      <author><first>Ryosuke</first> <last>Takahira</last></author>
      <author><first>Kumiko</first> <last>Tanaka-Ishii</last></author>
      <author><first>Łukasz</first> <last>Dębowski</last></author>
      <pages>213–221</pages>
      <url hash="e687183d">W16-4124</url>
      <abstract>The article presents results of entropy rate estimation for human languages across six languages by using large, state-of-the-art corpora of up to 7.8 gigabytes. To obtain the estimates for data length tending to infinity, we use an extrapolation function given by an ansatz. Whereas some ansatzes of this kind were proposed in previous research papers, here we introduce a stretched exponential extrapolation function that has a smaller error of fit. In this way, we uncover a possibility that the entropy rates of human languages are positive but 20% smaller than previously reported.</abstract>
    </paper>
    <paper id="25">
      <title>Learning pressures reduce morphological complexity: Linking corpus, computational and experimental evidence</title>
      <author><first>Christian</first> <last>Bentz</last></author>
      <author><first>Aleksandrs</first> <last>Berdicevskis</last></author>
      <pages>222–232</pages>
      <url hash="9ec56e04">W16-4125</url>
      <abstract>The morphological complexity of languages differs widely and changes over time. Pathways of change are often driven by the interplay of multiple competing factors, and are hard to disentangle. We here focus on a paradigmatic scenario of language change: the reduction of morphological complexity from Latin towards the Romance languages. To establish a causal explanation for this phenomenon, we employ three lines of evidence: 1) analyses of parallel corpora to measure the complexity of words in actual language production, 2) applications of NLP tools to further tease apart the contribution of inflectional morphology to word complexity, and 3) experimental data from artificial language learning, which illustrate the learning pressures at play when morphology simplifies. These three lines of evidence converge to show that pressures associated with imperfect language learning are good candidates to causally explain the reduction in morphological complexity in the Latin-to-Romance scenario. More generally, we argue that combining corpus, computational and experimental evidence is the way forward in historical linguistics and linguistic typology.</abstract>
    </paper>
  </volume>
  <volume id="42">
    <meta>
      <booktitle>Proceedings of the Clinical Natural Language Processing Workshop (<fixed-case>C</fixed-case>linical<fixed-case>NLP</fixed-case>)</booktitle>
      <url hash="932f6c83">W16-42</url>
      <editor><first>Anna</first><last>Rumshisky</last></editor>
      <editor><first>Kirk</first><last>Roberts</last></editor>
      <editor><first>Steven</first><last>Bethard</last></editor>
      <editor><first>Tristan</first><last>Naumann</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="841915e5">W16-4200</url>
    </frontmatter>
    <paper id="1">
      <title>The impact of simple feature engineering in multilingual medical <fixed-case>NER</fixed-case></title>
      <author><first>Rebecka</first> <last>Weegar</last></author>
      <author><first>Arantza</first> <last>Casillas</last></author>
      <author><first>Arantza</first> <last>Diaz de Ilarraza</last></author>
      <author><first>Maite</first> <last>Oronoz</last></author>
      <author><first>Alicia</first> <last>Pérez</last></author>
      <author><first>Koldo</first> <last>Gojenola</last></author>
      <pages>1–6</pages>
      <url hash="43cdd82a">W16-4201</url>
      <abstract>The goal of this paper is to examine the impact of simple feature engineering mechanisms before applying more sophisticated techniques to the task of medical NER. Sometimes papers using scientifically sound techniques present raw baselines that could be improved adding simple and cheap features. This work focuses on entity recognition for the clinical domain for three languages: English, Swedish and Spanish. The task is tackled using simple features, starting from the window size, capitalization, prefixes, and moving to POS and semantic tags. This work demonstrates that a simple initial step of feature engineering can improve the baseline results significantly. Hence, the contributions of this paper are: first, a short list of guidelines well supported with experimental results on three languages and, second, a detailed description of the relevance of these features for medical NER.</abstract>
    </paper>
    <paper id="2">
      <title>Bidirectional <fixed-case>LSTM</fixed-case>-<fixed-case>CRF</fixed-case> for Clinical Concept Extraction</title>
      <author><first>Raghavendra</first> <last>Chalapathy</last></author>
      <author><first>Ehsan</first> <last>Zare Borzeshi</last></author>
      <author><first>Massimo</first> <last>Piccardi</last></author>
      <pages>7–12</pages>
      <url hash="715d03e0">W16-4202</url>
      <abstract>Automated extraction of concepts from patient clinical records is an essential facilitator of clinical research. For this reason, the 2010 i2b2/VA Natural Language Processing Challenges for Clinical Records introduced a concept extraction task aimed at identifying and classifying concepts into predefined categories (i.e., treatments, tests and problems). State-of-the-art concept extraction approaches heavily rely on handcrafted features and domain-specific resources which are hard to collect and define. For this reason, this paper proposes an alternative, streamlined approach: a recurrent neural network (the bidirectional LSTM with CRF decoding) initialized with general-purpose, off-the-shelf word embeddings. The experimental results achieved on the 2010 i2b2/VA reference corpora using the proposed framework outperform all recent methods and ranks closely to the best submission from the original 2010 i2b2/VA challenge.</abstract>
    </paper>
    <paper id="3">
      <title><fixed-case>M</fixed-case>ed<fixed-case>NLPD</fixed-case>oc: <fixed-case>J</fixed-case>apanese Shared Task for Clinical <fixed-case>NLP</fixed-case></title>
      <author><first>Eiji</first> <last>Aramaki</last></author>
      <author><first>Yoshinobu</first> <last>Kano</last></author>
      <author><first>Tomoko</first> <last>Ohkuma</last></author>
      <author><first>Mizuki</first> <last>Morita</last></author>
      <pages>13–16</pages>
      <url hash="d54d7f82">W16-4203</url>
      <abstract>Due to the recent replacements of physical documents with electronic medical records (EMR), the importance of information processing in medical fields has been increased. We have been organizing the MedNLP task series in NTCIR-10 and 11. These workshops were the first shared tasks which attempt to evaluate technologies that retrieve important information from medical reports written in Japanese. In this report, we describe the NTCIR-12 MedNLPDoc task which is designed for more advanced and practical use for the medical fields. This task is considered as a multi-labeling task to a patient record. This report presents results of the shared task, discusses and illustrates remained issues in the medical natural language processing field.</abstract>
    </paper>
    <paper id="4">
      <title>Feature-Augmented Neural Networks for Patient Note De-identification</title>
      <author><first>Ji Young</first> <last>Lee</last></author>
      <author><first>Franck</first> <last>Dernoncourt</last></author>
      <author><first>Özlem</first> <last>Uzuner</last></author>
      <author><first>Peter</first> <last>Szolovits</last></author>
      <pages>17–22</pages>
      <url hash="1b2f81b6">W16-4204</url>
      <abstract>Patient notes contain a wealth of information of potentially great interest to medical investigators. However, to protect patients’ privacy, Protected Health Information (PHI) must be removed from the patient notes before they can be legally released, a process known as patient note de-identification. The main objective for a de-identification system is to have the highest possible recall. Recently, the first neural-network-based de-identification system has been proposed, yielding state-of-the-art results. Unlike other systems, it does not rely on human-engineered features, which allows it to be quickly deployed, but does not leverage knowledge from human experts or from electronic health records (EHRs). In this work, we explore a method to incorporate human-engineered features as well as features derived from EHRs to a neural-network-based de-identification system. Our results show that the addition of features, especially the EHR-derived features, further improves the state-of-the-art in patient note de-identification, including for some of the most sensitive PHI types such as patient names. Since in a real-life setting patient notes typically come with EHRs, we recommend developers of de-identification systems to leverage the information EHRs contain.</abstract>
    </paper>
    <paper id="5">
      <title>Semi-supervised Clustering of Medical Text</title>
      <author><first>Pracheta</first> <last>Sahoo</last></author>
      <author><first>Asif</first> <last>Ekbal</last></author>
      <author><first>Sriparna</first> <last>Saha</last></author>
      <author><first>Diego</first> <last>Mollá</last></author>
      <author><first>Kaushik</first> <last>Nandan</last></author>
      <pages>23–31</pages>
      <url hash="3f8aa572">W16-4205</url>
      <abstract>Semi-supervised clustering is an attractive alternative for traditional (unsupervised) clustering in targeted applications. By using the information of a small annotated dataset, semi-supervised clustering can produce clusters that are customized to the application domain. In this paper, we present a semi-supervised clustering technique based on a multi-objective evolutionary algorithm (NSGA-II-clus). We apply this technique to the task of clustering medical publications for Evidence Based Medicine (EBM) and observe an improvement of the results against unsupervised and other semi-supervised clustering techniques.</abstract>
    </paper>
    <paper id="6">
      <title>Deep Learning Architecture for Patient Data De-identification in Clinical Records</title>
      <author><first>Shweta</first> <last>Yadav</last></author>
      <author><first>Asif</first> <last>Ekbal</last></author>
      <author><first>Sriparna</first> <last>Saha</last></author>
      <author><first>Pushpak</first> <last>Bhattacharyya</last></author>
      <pages>32–41</pages>
      <url hash="d556281d">W16-4206</url>
      <abstract>Rapid growth in Electronic Medical Records (EMR) has emerged to an expansion of data in the clinical domain. The majority of the available health care information is sealed in the form of narrative documents which form the rich source of clinical information. Text mining of such clinical records has gained huge attention in various medical applications like treatment and decision making. However, medical records enclose patient Private Health Information (PHI) which can reveal the identities of the patients. In order to retain the privacy of patients, it is mandatory to remove all the PHI information prior to making it publicly available. The aim is to de-identify or encrypt the PHI from the patient medical records. In this paper, we propose an algorithm based on deep learning architecture to solve this problem. We perform de-identification of seven PHI terms from the clinical records. Experiments on benchmark datasets show that our proposed approach achieves encouraging performance, which is better than the baseline model developed with Conditional Random Field.</abstract>
    </paper>
    <paper id="7">
      <title>Neural Clinical Paraphrase Generation with Attention</title>
      <author><first>Sadid A.</first> <last>Hasan</last></author>
      <author><first>Bo</first> <last>Liu</last></author>
      <author><first>Joey</first> <last>Liu</last></author>
      <author><first>Ashequl</first> <last>Qadir</last></author>
      <author><first>Kathy</first> <last>Lee</last></author>
      <author><first>Vivek</first> <last>Datla</last></author>
      <author><first>Aaditya</first> <last>Prakash</last></author>
      <author><first>Oladimeji</first> <last>Farri</last></author>
      <pages>42–53</pages>
      <url hash="d927b47b">W16-4207</url>
      <abstract>Paraphrase generation is important in various applications such as search, summarization, and question answering due to its ability to generate textual alternatives while keeping the overall meaning intact. Clinical paraphrase generation is especially vital in building patient-centric clinical decision support (CDS) applications where users are able to understand complex clinical jargons via easily comprehensible alternative paraphrases. This paper presents Neural Clinical Paraphrase Generation (NCPG), a novel approach that casts the task as a monolingual neural machine translation (NMT) problem. We propose an end-to-end neural network built on an attention-based bidirectional Recurrent Neural Network (RNN) architecture with an encoder-decoder framework to perform the task. Conventional bilingual NMT models mostly rely on word-level modeling and are often limited by out-of-vocabulary (OOV) issues. In contrast, we represent the source and target paraphrase pairs as character sequences to address this limitation. To the best of our knowledge, this is the first work that uses attention-based RNNs for clinical paraphrase generation and also proposes an end-to-end character-level modeling for this task. Extensive experiments on a large curated clinical paraphrase corpus show that the attention-based NCPG models achieve improvements of up to 5.2 BLEU points and 0.5 METEOR points over a non-attention based strong baseline for word-level modeling, whereas further gains of up to 6.1 BLEU points and 1.3 METEOR points are obtained by the character-level NCPG models over their word-level counterparts. Overall, our models demonstrate comparable performance relative to the state-of-the-art phrase-based non-neural models.</abstract>
    </paper>
    <paper id="8">
      <title>Assessing the Corpus Size vs. Similarity Trade-off for Word Embeddings in Clinical <fixed-case>NLP</fixed-case></title>
      <author><first>Kirk</first> <last>Roberts</last></author>
      <pages>54–63</pages>
      <url hash="66cdc8bb">W16-4208</url>
      <abstract>The proliferation of deep learning methods in natural language processing (NLP) and the large amounts of data they often require stands in stark contrast to the relatively data-poor clinical NLP domain. In particular, large text corpora are necessary to build high-quality word embeddings, yet often large corpora that are suitably representative of the target clinical data are unavailable. This forces a choice between building embeddings from small clinical corpora and less representative, larger corpora. This paper explores this trade-off, as well as intermediate compromise solutions. Two standard clinical NLP tasks (the i2b2 2010 concept and assertion tasks) are evaluated with commonly used deep learning models (recurrent neural networks and convolutional neural networks) using a set of six corpora ranging from the target i2b2 data to large open-domain datasets. While combinations of corpora are generally found to work best, the single-best corpus is generally task-dependent.</abstract>
    </paper>
    <paper id="9">
      <title>Inference of <fixed-case>ICD</fixed-case> Codes from <fixed-case>J</fixed-case>apanese Medical Records by Searching Disease Names</title>
      <author><first>Masahito</first> <last>Sakishita</last></author>
      <author><first>Yoshinobu</first> <last>Kano</last></author>
      <pages>64–68</pages>
      <url hash="bac83201">W16-4209</url>
      <abstract>Importance of utilizing medical information is getting increased as electronic health records (EHRs) are widely used nowadays. We aim to assign international standardized disease codes, ICD-10, to Japanese textual information in EHRs for users to reuse the information accurately. In this paper, we propose methods to automatically extract diagnosis and to assign ICD codes to Japanese medical records. Due to the lack of available training data, we dare employed rule-based methods rather than machine learning. We observed characteristics of medical records carefully, writing rules to make effective methods by hand. We applied our system to the NTCIR-12 MedNLPDoc shared task data where participants are required to assign ICD-10 codes of possible diagnosis in given EHRs. In this shared task, our system achieved the highest F-measure score among all participants in the most severe evaluation criteria. Through comparison with other approaches, we show that our approach could be a useful milestone for the future development of Japanese medical record processing.</abstract>
    </paper>
    <paper id="10">
      <title>A fine-grained corpus annotation schema of <fixed-case>G</fixed-case>erman nephrology records</title>
      <author><first>Roland</first> <last>Roller</last></author>
      <author><first>Hans</first> <last>Uszkoreit</last></author>
      <author><first>Feiyu</first> <last>Xu</last></author>
      <author><first>Laura</first> <last>Seiffe</last></author>
      <author><first>Michael</first> <last>Mikhailov</last></author>
      <author><first>Oliver</first> <last>Staeck</last></author>
      <author><first>Klemens</first> <last>Budde</last></author>
      <author><first>Fabian</first> <last>Halleck</last></author>
      <author><first>Danilo</first> <last>Schmidt</last></author>
      <pages>69–77</pages>
      <url hash="406474fd">W16-4210</url>
      <abstract>In this work we present a fine-grained annotation schema to detect named entities in German clinical data of chronically ill patients with kidney diseases. The annotation schema is driven by the needs of our clinical partners and the linguistic aspects of German language. In order to generate annotations within a short period, the work also presents a semi-automatic annotation which uses additional sources of knowledge such as UMLS, to pre-annotate concepts in advance. The presented schema will be used to apply novel techniques from natural language processing and machine learning to support doctors treating their patients by improved information access from unstructured German texts.</abstract>
    </paper>
    <paper id="11">
      <title>Detecting <fixed-case>J</fixed-case>apanese Patients with <fixed-case>A</fixed-case>lzheimer’s Disease based on Word Category Frequencies</title>
      <author><first>Daisaku</first> <last>Shibata</last></author>
      <author><first>Shoko</first> <last>Wakamiya</last></author>
      <author><first>Ayae</first> <last>Kinoshita</last></author>
      <author><first>Eiji</first> <last>Aramaki</last></author>
      <pages>78–85</pages>
      <url hash="893a816f">W16-4211</url>
      <abstract>In recent years, detecting Alzheimer disease (AD) in early stages based on natural language processing (NLP) has drawn much attention. To date, vocabulary size, grammatical complexity, and fluency have been studied using NLP metrics. However, the content analysis of AD narratives is still unreachable for NLP. This study investigates features of the words that AD patients use in their spoken language. After recruiting 18 examinees of 53–90 years old (mean: 76.89), they were divided into two groups based on MMSE scores. The AD group comprised 9 examinees with scores of 21 or lower. The healthy control group comprised 9 examinees with a score of 22 or higher. Linguistic Inquiry and Word Count (LIWC) classified words were used to categorize the words that the examinees used. The word frequency was found from observation. Significant differences were confirmed for the usage of impersonal pronouns in the AD group. This result demonstrated the basic feasibility of the proposed NLP-based detection approach.</abstract>
    </paper>
    <paper id="12">
      <title>Prediction of Key Patient Outcome from Sentence and Word of Medical Text Records</title>
      <author><first>Takanori</first> <last>Yamashita</last></author>
      <author><first>Yoshifumi</first> <last>Wakata</last></author>
      <author><first>Hidehisa</first> <last>Soejima</last></author>
      <author><first>Naoki</first> <last>Nakashima</last></author>
      <author><first>Sachio</first> <last>Hirokawa</last></author>
      <pages>86–90</pages>
      <url hash="0d888b8f">W16-4212</url>
      <abstract>The number of unstructured medical records kept in hospital information systems is increasing. The conditions of patients are formulated as outcomes in clinical pathway. A variance of an outcome describes deviations from standards of care like a patient’s bad condition. The present paper applied text mining to extract feature words and phrases of the variance from admission records. We report the cases the variances of “pain control” and “no neuropathy worsening” in cerebral infarction.</abstract>
    </paper>
    <paper id="13">
      <title>Unsupervised Abbreviation Detection in Clinical Narratives</title>
      <author><first>Markus</first> <last>Kreuzthaler</last></author>
      <author><first>Michel</first> <last>Oleynik</last></author>
      <author><first>Alexander</first> <last>Avian</last></author>
      <author><first>Stefan</first> <last>Schulz</last></author>
      <pages>91–98</pages>
      <url hash="4169dc4e">W16-4213</url>
      <abstract>Clinical narratives in electronic health record systems are a rich resource of patient-based information. They constitute an ongoing challenge for natural language processing, due to their high compactness and abundance of short forms. German medical texts exhibit numerous ad-hoc abbreviations that terminate with a period character. The disambiguation of period characters is therefore an important task for sentence and abbreviation detection. This task is addressed by a combination of co-occurrence information of word types with trailing period characters, a large domain dictionary, and a simple rule engine, thus merging statistical and dictionary-based disambiguation strategies. An F-measure of 0.95 could be reached by using the unsupervised approach presented in this paper. The results are promising for a domain-independent abbreviation detection strategy, because our approach avoids retraining of models or use case specific feature engineering efforts required for supervised machine learning approaches.</abstract>
    </paper>
    <paper id="14">
      <title>Automated Anonymization as Spelling Variant Detection</title>
      <author><first>Steven Kester</first> <last>Yuwono</last></author>
      <author><first>Hwee Tou</first> <last>Ng</last></author>
      <author><first>Kee Yuan</first> <last>Ngiam</last></author>
      <pages>99–103</pages>
      <url hash="db0e7551">W16-4214</url>
      <abstract>The issue of privacy has always been a concern when clinical texts are used for research purposes. Personal health information (PHI) (such as name and identification number) needs to be removed so that patients cannot be identified. Manual anonymization is not feasible due to the large number of clinical texts to be anonymized. In this paper, we tackle the task of anonymizing clinical texts written in sentence fragments and which frequently contain symbols, abbreviations, and misspelled words. Our clinical texts therefore differ from those in the i2b2 shared tasks which are in prose form with complete sentences. Our clinical texts are also part of a structured database which contains patient name and identification number in structured fields. As such, we formulate our anonymization task as spelling variant detection, exploiting patients’ personal information in the structured fields to detect their spelling variants in clinical texts. We successfully anonymized clinical texts consisting of more than 200 million words, using minimum edit distance and regular expression patterns.</abstract>
    </paper>
  </volume>
  <volume id="43">
    <meta>
      <booktitle>Proceedings of the Workshop on Computational Modeling of People’s Opinions, Personality, and Emotions in Social Media (<fixed-case>PEOPLES</fixed-case>)</booktitle>
      <url hash="ee0d3b04">W16-43</url>
      <editor><first>Malvina</first><last>Nissim</last></editor>
      <editor><first>Viviana</first><last>Patti</last></editor>
      <editor><first>Barbara</first><last>Plank</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="6edf6880">W16-4300</url>
    </frontmatter>
    <paper id="1">
      <title>Zooming in on Gender Differences in Social Media</title>
      <author><first>Aparna</first> <last>Garimella</last></author>
      <author><first>Rada</first> <last>Mihalcea</last></author>
      <pages>1–10</pages>
      <url hash="37291a0f">W16-4301</url>
      <abstract>Men are from Mars and women are from Venus - or so the genre of relationship literature would have us believe. But there is some truth in this idea, and researchers in fields as diverse as psychology, sociology, and linguistics have explored ways to better understand the differences between genders. In this paper, we take another look at the problem of gender discrimination and attempt to move beyond the typical surface-level text classification approach, by (1) identifying semantic and psycholinguistic word classes that reflect systematic differences between men and women and (2) finding differences between genders in the ways they use the same words. We describe several experiments and report results on a large collection of blogs authored by men and women.</abstract>
    </paper>
    <paper id="2">
      <title>The Effect of Gender and Age Differences on the Recognition of Emotions from Facial Expressions</title>
      <author><first>Daniela</first> <last>Schneevogt</last></author>
      <author><first>Patrizia</first> <last>Paggio</last></author>
      <pages>11–19</pages>
      <url hash="ecd38df7">W16-4302</url>
      <abstract>Recent studies have demonstrated gender and cultural differences in the recognition of emotions in facial expressions. However, most studies were conducted on American subjects. In this paper, we explore the generalizability of several findings to a non-American culture in the form of Danish subjects. We conduct an emotion recognition task followed by two stereotype questionnaires with different genders and age groups. While recent findings (Krems et al., 2015) suggest that women are biased to see anger in neutral facial expressions posed by females, in our sample both genders assign higher ratings of anger to all emotions expressed by females. Furthermore, we demonstrate an effect of gender on the fear-surprise-confusion observed by Tomkins and McCarter (1964); females overpredict fear, while males overpredict surprise.</abstract>
    </paper>
    <paper id="3">
      <title>A Recurrent and Compositional Model for Personality Trait Recognition from Short Texts</title>
      <author id="fei-liu-unimelb"><first>Fei</first> <last>Liu</last></author>
      <author><first>Julien</first> <last>Perez</last></author>
      <author><first>Scott</first> <last>Nowson</last></author>
      <pages>20–29</pages>
      <url hash="2d89ea4b">W16-4303</url>
      <abstract>Many methods have been used to recognise author personality traits from text, typically combining linguistic feature engineering with shallow learning models, e.g. linear regression or Support Vector Machines. This work uses deep-learning-based models and atomic features of text, the characters, to build hierarchical, vectorial word and sentence representations for trait inference. This method, applied to a corpus of tweets, shows state-of-the-art performance across five traits compared with prior work. The results, supported by preliminary visualisation work, are encouraging for the ability to detect complex human traits.</abstract>
    </paper>
    <paper id="4">
      <title>Distant supervision for emotion detection using <fixed-case>F</fixed-case>acebook reactions</title>
      <author><first>Chris</first> <last>Pool</last></author>
      <author><first>Malvina</first> <last>Nissim</last></author>
      <pages>30–39</pages>
      <url hash="7bd30aec">W16-4304</url>
      <abstract>We exploit the Facebook reaction feature in a distant supervised fashion to train a support vector machine classifier for emotion detection, using several feature combinations and combining different Facebook pages. We test our models on existing benchmarks for emotion detection and show that employing only information that is derived completely automatically, thus without relying on any handcrafted lexicon as it’s usually done, we can achieve competitive results. The results also show that there is large room for improvement, especially by gearing the collection of Facebook pages, with a view to the target domain.</abstract>
    </paper>
    <paper id="5">
      <title>A graphical framework to detect and categorize diverse opinions from online news</title>
      <author><first>Ankan</first> <last>Mullick</last></author>
      <author><first>Pawan</first> <last>Goyal</last></author>
      <author><first>Niloy</first> <last>Ganguly</last></author>
      <pages>40–49</pages>
      <url hash="d95b4ed9">W16-4305</url>
      <abstract>This paper proposes a graphical framework to extract opinionated sentences which highlight different contexts within a given news article by introducing the concept of diversity in a graphical model for opinion detection.We conduct extensive evaluations and find that the proposed modification leads to impressive improvement in performance and makes the final results of the model much more usable. The proposed method (OP-D) not only performs much better than the other techniques used for opinion detection as well as introducing diversity, but is also able to select opinions from different categories (Asher et al. 2009). By developing a classification model which categorizes the identified sentences into various opinion categories, we find that OP-D is able to push opinions from different categories uniformly among the top opinions.</abstract>
    </paper>
    <paper id="6">
      <title>Active learning for detection of stance components</title>
      <author><first>Maria</first> <last>Skeppstedt</last></author>
      <author><first>Magnus</first> <last>Sahlgren</last></author>
      <author><first>Carita</first> <last>Paradis</last></author>
      <author><first>Andreas</first> <last>Kerren</last></author>
      <pages>50–59</pages>
      <url hash="9d492f7f">W16-4306</url>
      <abstract>Automatic detection of five language components, which are all relevant for expressing opinions and for stance taking, was studied: positive sentiment, negative sentiment, speculation, contrast and condition. A resource-aware approach was taken, which included manual annotation of 500 training samples and the use of limited lexical resources. Active learning was compared to random selection of training data, as well as to a lexicon-based method. Active learning was successful for the categories speculation, contrast and condition, but not for the two sentiment categories, for which results achieved when using active learning were similar to those achieved when applying a random selection of training data. This difference is likely due to a larger variation in how sentiment is expressed than in how speakers express the other three categories. This larger variation was also shown by the lower recall results achieved by the lexicon-based approach for sentiment than for the categories speculation, contrast and condition.</abstract>
    </paper>
    <paper id="7">
      <title>Detecting Opinion Polarities using Kernel Methods</title>
      <author><first>Rasoul</first> <last>Kaljahi</last></author>
      <author><first>Jennifer</first> <last>Foster</last></author>
      <pages>60–69</pages>
      <url hash="49293f8d">W16-4307</url>
      <abstract>We investigate the application of kernel methods to representing both structural and lexical knowledge for predicting polarity of opinions in consumer product review. We introduce any-gram kernels which model lexical information in a significantly faster way than the traditional n-gram features, while capturing all possible orders of n-grams n in a sequence without the need to explicitly present a pre-specified set of such orders. We also present an effective format to represent constituency and dependency structure together with aspect terms and sentiment polarity scores. Furthermore, we modify the traditional tree kernel function to compute the similarity based on word embedding vectors instead of exact string match and present experiments using the new models.</abstract>
    </paper>
    <paper id="8">
      <title>Effects of Semantic Relatedness between Setups and Punchlines in <fixed-case>T</fixed-case>witter Hashtag Games</title>
      <author><first>Andrew</first> <last>Cattle</last></author>
      <author><first>Xiaojuan</first> <last>Ma</last></author>
      <pages>70–79</pages>
      <url hash="7f99420e">W16-4308</url>
      <abstract>This paper explores humour recognition for Twitter-based hashtag games. Given their popularity, frequency, and relatively formulaic nature, these games make a good target for computational humour research and can leverage Twitter likes and retweets as humour judgments. In this work, we use pair-wise relative humour judgments to examine several measures of semantic relatedness between setups and punchlines on a hashtag game corpus we collected and annotated. Results show that perplexity, Normalized Google Distance, and free-word association-based features are all useful in identifying “funnier” hashtag game responses. In fact, we provide empirical evidence that funnier punchlines tend to be more obscure, although more obscure punchlines are not necessarily rated funnier. Furthermore, the asymmetric nature of free-word association features allows us to see that while punchlines should be harder to predict given a setup, they should also be relatively easy to understand in context.</abstract>
    </paper>
    <paper id="9">
      <title>Generating Sentiment Lexicons for <fixed-case>G</fixed-case>erman <fixed-case>T</fixed-case>witter</title>
      <author><first>Uladzimir</first> <last>Sidarenka</last></author>
      <author><first>Manfred</first> <last>Stede</last></author>
      <pages>80–90</pages>
      <url hash="6ee1ce08">W16-4309</url>
      <abstract>Despite a substantial progress made in developing new sentiment lexicon generation (SLG) methods for English, the task of transferring these approaches to other languages and domains in a sound way still remains open. In this paper, we contribute to the solution of this problem by systematically comparing semi-automatic translations of common English polarity lists with the results of the original automatic SLG algorithms, which were applied directly to German data. We evaluate these lexicons on a corpus of 7,992 manually annotated tweets. In addition to that, we also collate the results of dictionary- and corpus-based SLG methods in order to find out which of these paradigms is better suited for the inherently noisy domain of social media. Our experiments show that semi-automatic translations notably outperform automatic systems (reaching a macro-averaged F1-score of 0.589), and that dictionary-based techniques produce much better polarity lists as compared to corpus-based approaches (whose best F1-scores run up to 0.479 and 0.419 respectively) even for the non-standard Twitter genre.</abstract>
    </paper>
    <paper id="10">
      <title>Innovative Semi-Automatic Methodology to Annotate Emotional Corpora</title>
      <author><first>Lea</first> <last>Canales</last></author>
      <author><first>Carlo</first> <last>Strapparava</last></author>
      <author><first>Ester</first> <last>Boldrini</last></author>
      <author><first>Patricio</first> <last>Martínez-Barco</last></author>
      <pages>91–100</pages>
      <url hash="3659128f">W16-4310</url>
      <abstract>Detecting depression or personality traits, tutoring and student behaviour systems, or identifying cases of cyber-bulling are a few of the wide range of the applications, in which the automatic detection of emotion is a crucial element. Emotion detection has the potential of high impact by contributing the benefit of business, society, politics or education. Given this context, the main objective of our research is to contribute to the resolution of one of the most important challenges in textual emotion detection task: the problems of emotional corpora annotation. This will be tackled by proposing of a new semi-automatic methodology. Our innovative methodology consists in two main phases: (1) an automatic process to pre-annotate the unlabelled sentences with a reduced number of emotional categories; and (2) a refinement manual process where human annotators will determine which is the predominant emotion between the emotional categories selected in the phase 1. Our proposal in this paper is to show and evaluate the pre-annotation process to analyse the feasibility and the benefits by the methodology proposed. The results obtained are promising and allow obtaining a substantial improvement of annotation time and cost and confirm the usefulness of our pre-annotation process to improve the annotation task.</abstract>
    </paper>
    <paper id="11">
      <title>Personality Estimation from <fixed-case>J</fixed-case>apanese Text</title>
      <author><first>Koichi</first> <last>Kamijo</last></author>
      <author><first>Tetsuya</first> <last>Nasukawa</last></author>
      <author><first>Hideya</first> <last>Kitamura</last></author>
      <pages>101–109</pages>
      <url hash="c4f14007">W16-4311</url>
      <abstract>We created a model to estimate personality trait from authors’ text written in Japanese and measured its performance by conducting surveys and analyzing the Twitter data of 1,630 users. We used the Big Five personality traits for personality trait estimation. Our approach is a combination of category- and Word2Vec-based approaches. For the category-based element, we added several unique Japanese categories along with the ones regularly used in the English model, and for the Word2Vec-based element, we used a model called GloVe. We found that some of the newly added categories have a stronger correlation with personality traits than other categories do and that the combination of the category- and Word2Vec-based approaches improves the accuracy of the personality trait estimation compared with the case of using just one of them.</abstract>
    </paper>
    <paper id="12">
      <title>Predicting <fixed-case>B</fixed-case>rexit: Classifying Agreement is Better than Sentiment and Pollsters</title>
      <author><first>Fabio</first> <last>Celli</last></author>
      <author><first>Evgeny</first> <last>Stepanov</last></author>
      <author><first>Massimo</first> <last>Poesio</last></author>
      <author><first>Giuseppe</first> <last>Riccardi</last></author>
      <pages>110–118</pages>
      <url hash="21ecf61c">W16-4312</url>
      <abstract>On June 23rd 2016, UK held the referendum which ratified the exit from the EU. While most of the traditional pollsters failed to forecast the final vote, there were online systems that hit the result with high accuracy using opinion mining techniques and big data. Starting one month before, we collected and monitored millions of posts about the referendum from social media conversations, and exploited Natural Language Processing techniques to predict the referendum outcome. In this paper we discuss the methods used by traditional pollsters and compare it to the predictions based on different opinion mining techniques. We find that opinion mining based on agreement/disagreement classification works better than opinion mining based on polarity classification in the forecast of the referendum outcome.</abstract>
    </paper>
    <paper id="13">
      <title>Sarcasm Detection : Building a Contextual Hierarchy</title>
      <author><first>Taradheesh</first> <last>Bali</last></author>
      <author><first>Navjyoti</first> <last>Singh</last></author>
      <pages>119–127</pages>
      <url hash="dc20839b">W16-4313</url>
      <abstract>The conundrum of understanding and classifying sarcasm has been dealt with by the traditional theorists as an analysis of a sarcastic utterance and the ironic situation that surrounds it. The problem with such an approach is that it is too narrow, as it is unable to sufficiently utilize the two indispensable agents in making such an utterance, viz. the speaker and the listener. It undermines the necessary context required to comprehend a sarcastic utterance. In this paper, we propose a novel approach towards understanding sarcasm in terms of the existing knowledge hierarchy between the two participants, which forms the basis of the context that both agents share. The difference in relationship of the speaker of the sarcastic utterance and the disparate audience found on social media, such as Twitter, is also captured. We then apply our model on a corpus of tweets to achieve significant results and consequently, shed light on subjective nature of context, which is contingent on the relation between the speaker and the listener.</abstract>
    </paper>
    <paper id="14">
      <title>Social and linguistic behavior and its correlation to trait empathy</title>
      <author><first>Marina</first> <last>Litvak</last></author>
      <author><first>Jahna</first> <last>Otterbacher</last></author>
      <author><first>Chee Siang</first> <last>Ang</last></author>
      <author><first>David</first> <last>Atkins</last></author>
      <pages>128–137</pages>
      <url hash="730ffd1a">W16-4314</url>
      <abstract>A growing body of research exploits social media behaviors to gauge psychological character-istics, though trait empathy has received little attention. Because of its intimate link to the abil-ity to relate to others, our research aims to predict participants’ levels of empathy, given their textual and friending behaviors on Facebook. Using Poisson regression, we compared the vari-ance explained in Davis’ Interpersonal Reactivity Index (IRI) scores on four constructs (em-pathic concern, personal distress, fantasy, perspective taking), by two classes of variables: 1) post content and 2) linguistic style. Our study lays the groundwork for a greater understanding of empathy’s role in facilitating interactions on social media.</abstract>
    </paper>
    <paper id="15">
      <title>The Challenges of Multi-dimensional Sentiment Analysis Across Languages</title>
      <author><first>Emily</first> <last>Öhman</last></author>
      <author><first>Timo</first> <last>Honkela</last></author>
      <author><first>Jörg</first> <last>Tiedemann</last></author>
      <pages>138–142</pages>
      <url hash="4e3f9f05">W16-4315</url>
      <abstract>This paper outlines a pilot study on multi-dimensional and multilingual sentiment analysis of social media content. We use parallel corpora of movie subtitles as a proxy for colloquial language in social media channels and a multilingual emotion lexicon for fine-grained sentiment analyses. Parallel data sets make it possible to study the preservation of sentiments and emotions in translation and our assessment reveals that the lexical approach shows great inter-language agreement. However, our manual evaluation also suggests that the use of purely lexical methods is limited and further studies are necessary to pinpoint the cross-lingual differences and to develop better sentiment classifiers.</abstract>
    </paper>
    <paper id="16">
      <title>The Social Mood of News: Self-reported Annotations to Design Automatic Mood Detection Systems</title>
      <author><first>Firoj</first> <last>Alam</last></author>
      <author><first>Fabio</first> <last>Celli</last></author>
      <author><first>Evgeny A.</first> <last>Stepanov</last></author>
      <author><first>Arindam</first> <last>Ghosh</last></author>
      <author><first>Giuseppe</first> <last>Riccardi</last></author>
      <pages>143–152</pages>
      <url hash="91d3ae3a">W16-4316</url>
      <abstract>In this paper, we address the issue of automatic prediction of readers’ mood from newspaper articles and comments. As online newspapers are becoming more and more similar to social media platforms, users can provide affective feedback, such as mood and emotion. We have exploited the self-reported annotation of mood categories obtained from the metadata of the Italian online newspaper corriere.it to design and evaluate a system for predicting five different mood categories from news articles and comments: indignation, disappointment, worry, satisfaction, and amusement. The outcome of our experiments shows that overall, bag-of-word-ngrams perform better compared to all other feature sets; however, stylometric features perform better for the mood score prediction of articles. Our study shows that self-reported annotations can be used to design automatic mood prediction systems.</abstract>
    </paper>
    <paper id="17">
      <title>Microblog Emotion Classification by Computing Similarity in Text, Time, and Space</title>
      <author><first>Anja</first> <last>Summa</last></author>
      <author><first>Bernd</first> <last>Resch</last></author>
      <author><first>Michael</first> <last>Strube</last></author>
      <pages>153–162</pages>
      <url hash="077c9a16">W16-4317</url>
      <abstract>Most work in NLP analysing microblogs focuses on textual content thus neglecting temporal and spatial information. We present a new interdisciplinary method for emotion classification that combines linguistic, temporal, and spatial information into a single metric. We create a graph of labeled and unlabeled tweets that encodes the relations between neighboring tweets with respect to their emotion labels. Graph-based semi-supervised learning labels all tweets with an emotion.</abstract>
    </paper>
    <paper id="18">
      <title>A domain-agnostic approach for opinion prediction on speech</title>
      <author><first>Pedro Bispo</first> <last>Santos</last></author>
      <author><first>Lisa</first> <last>Beinborn</last></author>
      <author><first>Iryna</first> <last>Gurevych</last></author>
      <pages>163–172</pages>
      <url hash="1ed81d9d">W16-4318</url>
      <abstract>We explore a domain-agnostic approach for analyzing speech with the goal of opinion prediction. We represent the speech signal by mel-frequency cepstral coefficients and apply long short-term memory neural networks to automatically learn temporal regularities in speech. In contrast to previous work, our approach does not require complex feature engineering and works without textual transcripts. As a consequence, it can easily be applied on various speech analysis tasks for different languages and the results show that it can nevertheless be competitive to the state-of-the-art in opinion prediction. In a detailed error analysis for opinion mining we find that our approach performs well in identifying speaker-specific characteristics, but should be combined with additional information if subtle differences in the linguistic content need to be identified.</abstract>
    </paper>
    <paper id="19">
      <title>Can We Make Computers Laugh at Talks?</title>
      <author><first>Chong Min</first> <last>Lee</last></author>
      <author><first>Su-Youn</first> <last>Yoon</last></author>
      <author><first>Lei</first> <last>Chen</last></author>
      <pages>173–181</pages>
      <url hash="aa5635bb">W16-4319</url>
      <abstract>Considering the importance of public speech skills, a system which makes a prediction on where audiences laugh in a talk can be helpful to a person who prepares for a talk. We investigated a possibility that a state-of-the-art humor recognition system can be used in detecting sentences inducing laughters in talks. In this study, we used TED talks and laughters in the talks as data. Our results showed that the state-of-the-art system needs to be improved in order to be used in a practical application. In addition, our analysis showed that classifying humorous sentences in talks is very challenging due to close distance between humorous and non-humorous sentences.</abstract>
    </paper>
    <paper id="20">
      <title>Towards Automatically Classifying Depressive Symptoms from <fixed-case>T</fixed-case>witter Data for Population Health</title>
      <author><first>Danielle L.</first> <last>Mowery</last></author>
      <author><first>Albert</first> <last>Park</last></author>
      <author><first>Craig</first> <last>Bryan</last></author>
      <author><first>Mike</first> <last>Conway</last></author>
      <pages>182–191</pages>
      <url hash="82b698bf">W16-4320</url>
      <abstract>Major depressive disorder, a debilitating and burdensome disease experienced by individuals worldwide, can be defined by several depressive symptoms (e.g., anhedonia (inability to feel pleasure), depressed mood, difficulty concentrating, etc.). Individuals often discuss their experiences with depression symptoms on public social media platforms like Twitter, providing a potentially useful data source for monitoring population-level mental health risk factors. In a step towards developing an automated method to estimate the prevalence of symptoms associated with major depressive disorder over time in the United States using Twitter, we developed classifiers for discerning whether a Twitter tweet represents no evidence of depression or evidence of depression. If there was evidence of depression, we then classified whether the tweet contained a depressive symptom and if so, which of three subtypes: depressed mood, disturbed sleep, or fatigue or loss of energy. We observed that the most accurate classifiers could predict classes with high-to-moderate F1-score performances for no evidence of depression (85), evidence of depression (52), and depressive symptoms (49). We report moderate F1-scores for depressive symptoms ranging from 75 (fatigue or loss of energy) to 43 (disturbed sleep) to 35 (depressed mood). Our work demonstrates baseline approaches for automatically encoding Twitter data with granular depressive symptoms associated with major depressive disorder.</abstract>
    </paper>
  </volume>
  <volume id="44">
    <meta>
      <booktitle>Proceedings of the Open Knowledge Base and Question Answering Workshop (<fixed-case>OKBQA</fixed-case> 2016)</booktitle>
      <url hash="dedd8037">W16-44</url>
      <editor><first>Key-Sun</first><last>Choi</last></editor>
      <editor><first>Christina</first><last>Unger</last></editor>
      <editor><first>Piek</first><last>Vossen</last></editor>
      <editor><first>Jin-Dong</first><last>Kim</last></editor>
      <editor><first>Noriko</first><last>Kando</last></editor>
      <editor><first>Axel-Cyrille</first><last>Ngonga Ngomo</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="083b8473">W16-4400</url>
    </frontmatter>
    <paper id="1">
      <title>Using <fixed-case>W</fixed-case>ikipedia and Semantic Resources to Find Answer Types and Appropriate Answer Candidate Sets in Question Answering</title>
      <author><first>Po-Chun</first> <last>Chen</last></author>
      <author><first>Meng-Jie</first> <last>Zhuang</last></author>
      <author><first>Chuan-Jie</first> <last>Lin</last></author>
      <pages>1–10</pages>
      <url hash="ebe0e016">W16-4401</url>
      <abstract>This paper proposes a new idea that uses Wikipedia categories as answer types and defines candidate sets inside Wikipedia. The focus of a given question is searched in the hierarchy of Wikipedia main pages. Our searching strategy combines head-noun matching and synonym matching provided in semantic resources. The set of answer candidates is determined by the entry hierarchy in Wikipedia and the hyponymy hierarchy in WordNet. The experimental results show that the approach can find candidate sets in a smaller size but achieve better performance especially for ARTIFACT and ORGANIZATION types, where the performance is better than state-of-the-art Chinese factoid QA systems.</abstract>
    </paper>
    <paper id="2">
      <title>Large-Scale Acquisition of Commonsense Knowledge via a Quiz Game on a Dialogue System</title>
      <author><first>Naoki</first> <last>Otani</last></author>
      <author><first>Daisuke</first> <last>Kawahara</last></author>
      <author><first>Sadao</first> <last>Kurohashi</last></author>
      <author><first>Nobuhiro</first> <last>Kaji</last></author>
      <author><first>Manabu</first> <last>Sassano</last></author>
      <pages>11–20</pages>
      <url hash="af61d4a8">W16-4402</url>
      <abstract>Commonsense knowledge is essential for fully understanding language in many situations. We acquire large-scale commonsense knowledge from humans using a game with a purpose (GWAP) developed on a smartphone spoken dialogue system. We transform the manual knowledge acquisition process into an enjoyable quiz game and have collected over 150,000 unique commonsense facts by gathering the data of more than 70,000 players over eight months. In this paper, we present a simple method for maintaining the quality of acquired knowledge and an empirical analysis of the knowledge acquisition process. To the best of our knowledge, this is the first work to collect large-scale knowledge via a GWAP on a widely-used spoken dialogue system.</abstract>
    </paper>
    <paper id="3">
      <title>A Hierarchical Neural Network for Information Extraction of Product Attribute and Condition Sentences</title>
      <author><first>Yukinori</first> <last>Homma</last></author>
      <author><first>Kugatsu</first> <last>Sadamitsu</last></author>
      <author><first>Kyosuke</first> <last>Nishida</last></author>
      <author><first>Ryuichiro</first> <last>Higashinaka</last></author>
      <author><first>Hisako</first> <last>Asano</last></author>
      <author><first>Yoshihiro</first> <last>Matsuo</last></author>
      <pages>21–29</pages>
      <url hash="ba5265a7">W16-4403</url>
      <abstract>This paper describes a hierarchical neural network we propose for sentence classification to extract product information from product documents. The network classifies each sentence in a document into attribute and condition classes on the basis of word sequences and sentence sequences in the document. Experimental results showed the method using the proposed network significantly outperformed baseline methods by taking semantic representation of word and sentence sequential data into account. We also evaluated the network with two different product domains (insurance and tourism domains) and found that it was effective for both the domains.</abstract>
    </paper>
    <paper id="4">
      <title>Combining Lexical and Semantic-based Features for Answer Sentence Selection</title>
      <author><first>Jing</first> <last>Shi</last></author>
      <author><first>Jiaming</first> <last>Xu</last></author>
      <author><first>Yiqun</first> <last>Yao</last></author>
      <author><first>Suncong</first> <last>Zheng</last></author>
      <author><first>Bo</first> <last>Xu</last></author>
      <pages>30–38</pages>
      <url hash="afdd08f2">W16-4404</url>
      <abstract>Question answering is always an attractive and challenging task in natural language processing area. There are some open domain question answering systems, such as IBM Waston, which take the unstructured text data as input, in some ways of humanlike thinking process and a mode of artificial intelligence. At the conference on Natural Language Processing and Chinese Computing (NLPCC) 2016, China Computer Federation hosted a shared task evaluation about Open Domain Question Answering. We achieve the 2nd place at the document-based subtask. In this paper, we present our solution, which consists of feature engineering in lexical and semantic aspects and model training methods. As the result of the evaluation shows, our solution provides a valuable and brief model which could be used in modelling question answering or sentence semantic relevance. We hope our solution would contribute to this vast and significant task with some heuristic thinking.</abstract>
    </paper>
    <paper id="5">
      <title>An Entity-Based approach to Answering Recurrent and Non-Recurrent Questions with Past Answers</title>
      <author><first>Anietie</first> <last>Andy</last></author>
      <author><first>Mugizi</first> <last>Rwebangira</last></author>
      <author><first>Satoshi</first> <last>Sekine</last></author>
      <pages>39–43</pages>
      <url hash="f0c2ce07">W16-4405</url>
      <abstract>An Entity-based approach to Answering recurrent and non-recurrent questions with Past Answers Abstract Community question answering (CQA) systems such as Yahoo! Answers allow registered-users to ask and answer questions in various question categories. However, a significant percentage of asked questions in Yahoo! Answers are unanswered. In this paper, we propose to reduce this percentage by reusing answers to past resolved questions from the site. Specifically, we propose to satisfy unanswered questions in entity rich categories by searching for and reusing the best answers to past resolved questions with shared needs. For unanswered questions that do not have a past resolved question with a shared need, we propose to use the best answer to a past resolved question with similar needs. Our experiments on a Yahoo! Answers dataset shows that our approach retrieves most of the past resolved questions that have shared and similar needs to unanswered questions.</abstract>
    </paper>
    <paper id="6">
      <title>Answer Presentation in Question Answering over Linked Data using Typed Dependency Subtree Patterns</title>
      <author><first>Rivindu</first> <last>Perera</last></author>
      <author><first>Parma</first> <last>Nand</last></author>
      <pages>44–48</pages>
      <url hash="3ecc34ec">W16-4406</url>
      <abstract>In an era where highly accurate Question Answering (QA) systems are being built using complex Natural Language Processing (NLP) and Information Retrieval (IR) algorithms, presenting the acquired answer to the user akin to a human answer is also crucial. In this paper we present an answer presentation strategy by embedding the answer in a sentence which is developed by incorporating the linguistic structure of the source question extracted through typed dependency parsing. The evaluation using human participants proved that the methodology is human-competitive and can result in linguistically correct sentences for more that 70% of the test dataset acquired from QALD question dataset.</abstract>
    </paper>
    <paper id="7">
      <title><fixed-case>B</fixed-case>io<fixed-case>M</fixed-case>ed<fixed-case>LAT</fixed-case> Corpus: Annotation of the Lexical Answer Type for Biomedical Questions</title>
      <author><first>Mariana</first> <last>Neves</last></author>
      <author><first>Milena</first> <last>Kraus</last></author>
      <pages>49–58</pages>
      <url hash="76ad5d53">W16-4407</url>
      <abstract>Question answering (QA) systems need to provide exact answers for the questions that are posed to the system. However, this can only be achieved through a precise processing of the question. During this procedure, one important step is the detection of the expected type of answer that the system should provide by extracting the headword of the questions and identifying its semantic type. We have annotated the headword and assigned UMLS semantic types to 643 factoid/list questions from the BioASQ training data. We present statistics on the corpus and a preliminary evaluation in baseline experiments. We also discuss the challenges on both the manual annotation and the automatic detection of the headwords and the semantic types. We believe that this is a valuable resource for both training and evaluation of biomedical QA systems. The corpus is available at: <url>https://github.com/mariananeves/BioMedLAT</url>.
    </abstract>
    </paper>
    <paper id="8">
      <title>Double Topic Shifts in Open Domain Conversations: Natural Language Interface for a <fixed-case>W</fixed-case>ikipedia-based Robot Application</title>
      <author><first>Kristiina</first> <last>Jokinen</last></author>
      <author><first>Graham</first> <last>Wilcock</last></author>
      <pages>59–66</pages>
      <url hash="8edb41c1">W16-4408</url>
      <abstract>The paper describes topic shifting in dialogues with a robot that provides information from Wiki-pedia. The work focuses on a double topical construction of dialogue coherence which refers to discourse coherence on two levels: the evolution of dialogue topics via the interaction between the user and the robot system, and the creation of discourse topics via the content of the Wiki-pedia article itself. The user selects topics that are of interest to her, and the system builds a list of potential topics, anticipated to be the next topic, by the links in the article and by the keywords extracted from the article. The described system deals with Wikipedia articles, but could easily be adapted to other digital information providing systems.</abstract>
    </paper>
    <paper id="9">
      <title>Filling a Knowledge Graph with a Crowd</title>
      <author><first>GyuHyeon</first> <last>Choi</last></author>
      <author><first>Sangha</first> <last>Nam</last></author>
      <author><first>Dongho</first> <last>Choi</last></author>
      <author><first>Key-Sun</first> <last>Choi</last></author>
      <pages>67–71</pages>
      <url hash="53bb3064">W16-4409</url>
      <abstract/>
    </paper>
    <paper id="10">
      <title>Pairing <fixed-case>W</fixed-case>ikipedia Articles Across Languages</title>
      <author><first>Marcus</first> <last>Klang</last></author>
      <author><first>Pierre</first> <last>Nugues</last></author>
      <pages>72–76</pages>
      <url hash="3334ae26">W16-4410</url>
      <abstract>Wikipedia has become a reference knowledge source for scores of NLP applications. One of its invaluable features lies in its multilingual nature, where articles on a same entity or concept can have from one to more than 200 different versions. The interlinking of language versions in Wikipedia has undergone a major renewal with the advent of Wikidata, a unified scheme to identify entities and their properties using unique numbers. However, as the interlinking is still manually carried out by thousands of editors across the globe, errors may creep in the assignment of entities. In this paper, we describe an optimization technique to match automatically language versions of articles, and hence entities, that is only based on bags of words and anchors. We created a dataset of all the articles on persons we extracted from Wikipedia in six languages: English, French, German, Russian, Spanish, and Swedish. We report a correct match of at least 94.3% on each pair.</abstract>
    </paper>
    <paper id="11">
      <title><fixed-case>SRDF</fixed-case>: Extracting Lexical Knowledge Graph for Preserving Sentence Meaning</title>
      <author><first>Sangha</first> <last>Nam</last></author>
      <author><first>GyuHyeon</first> <last>Choi</last></author>
      <author><first>Younggyun</first> <last>Hahm</last></author>
      <author><first>Key-Sun</first> <last>Choi</last></author>
      <pages>77–81</pages>
      <url hash="8c1e9a97">W16-4411</url>
      <abstract>In this paper, we present an open information extraction system so-called SRDF that generates lexical knowledge graphs from unstructured texts. In semantic web, knowledge is expressed in the RDF triple form but the natural language text consist of multiple relations between arguments. For this reason, we combine open information extraction with the reification for the full text extraction to preserve meaning of sentence in our knowledge graph. And also our knowledge graph is designed to adapt for many existing semantic web applications. At the end of this paper, we introduce the result of the experiment and a Korean template generation module developed using SRDF.</abstract>
    </paper>
    <paper id="12">
      <title><fixed-case>QAF</fixed-case>: Frame Semantics-based Question Interpretation</title>
      <author><first>Younggyun</first> <last>Hahm</last></author>
      <author><first>Sangha</first> <last>Nam</last></author>
      <author><first>Key-Sun</first> <last>Choi</last></author>
      <pages>82–90</pages>
      <url hash="928ccf1a">W16-4412</url>
      <abstract>Natural language questions are interpreted to a sequence of patterns to be matched with instances of patterns in a knowledge base (KB) for answering. A natural language (NL) question answering (QA) system utilizes meaningful patterns matching the syntac-tic/lexical features between the NL questions and KB. In the most of KBs, there are only binary relations in triple form to represent relation between two entities or entity and a value using the domain specific ontology. However, the binary relation representation is not enough to cover complex information in questions, and the ontology vocabulary sometimes does not cover the lexical meaning in questions. Complex meaning needs a knowledge representation to link the binary relation-type triples in KB. In this paper, we propose a frame semantics-based semantic parsing approach as KB-independent question pre-processing. We will propose requirements of question interpretation in the KBQA perspective, and a query form representation based on our proposed format QAF (Ques-tion Answering with the Frame Semantics), which is supposed to cover the requirements. In QAF, frame semantics roles as a model to represent complex information in questions and to disambiguate the lexical meaning in questions to match with the ontology vocabu-lary. Our system takes a question as an input and outputs QAF-query by the process which assigns semantic information in the question to its corresponding frame semantic structure using the semantic parsing rules.</abstract>
    </paper>
    <paper id="13">
      <title>Answering Yes-No Questions by Penalty Scoring in History Subjects of University Entrance Examinations</title>
      <author><first>Yoshinobu</first> <last>Kano</last></author>
      <pages>91–96</pages>
      <url hash="03704c38">W16-4413</url>
      <abstract>Answering yes–no questions is more difficult than simply retrieving ranked search results. To answer yes–no questions, especially when the correct answer is no, one must find an objectionable keyword that makes the question’s answer no. Existing systems, such as factoid-based ones, cannot answer yes–no questions very well because of insufficient handling of such objectionable keywords. We suggest an algorithm that answers yes–no questions by assigning an importance to objectionable keywords. Concretely speaking, we suggest a penalized scoring method that finds and makes lower score for parts of documents that include such objectionable keywords. We check a keyword distribution for each part of a document such as a paragraph, calculating the keyword density as a basic score. Then we use an objectionable keyword penalty when a keyword does not appear in a target part but appears in other parts of the document. Our algorithm is robust for open domain problems because it requires no training. We achieved 4.45 point better results in F1 scores than the best score of the NTCIR-10 RITE2 shared task, also obtained the best score in 2014 mock university examination challenge of the Todai Robot project.</abstract>
    </paper>
    <paper id="14">
      <title>Dedicated Workflow Management for <fixed-case>OKBQA</fixed-case> Framework</title>
      <author><first>Jiseong</first> <last>Kim</last></author>
      <author><first>GyuHyeon</first> <last>Choi</last></author>
      <author><first>Key-Sun</first> <last>Choi</last></author>
      <pages>97–101</pages>
      <url hash="da87a841">W16-4414</url>
      <abstract>Nowadays, a question answering (QA) system is used in various areas such a quiz show, personal assistant, home device, and so on. The OKBQA framework supports developing a QA system in an intuitive and collaborative ways. To support collaborative development, the framework should be equipped with some functions, e.g., flexible system configuration, debugging supports, intuitive user interface, and so on while considering different developing groups of different domains. This paper presents OKBQA controller, a dedicated workflow manager for OKBQA framework, to boost collaborative development of a QA system.</abstract>
    </paper>
  </volume>
  <volume id="45">
    <meta>
      <booktitle>Proceedings of the Sixth Workshop on Hybrid Approaches to Translation (<fixed-case>H</fixed-case>y<fixed-case>T</fixed-case>ra6)</booktitle>
      <url hash="5d1ba745">W16-45</url>
      <editor><first>Patrik</first><last>Lambert</last></editor>
      <editor><first>Bogdan</first><last>Babych</last></editor>
      <editor><first>Kurt</first><last>Eberle</last></editor>
      <editor><first>Rafael E.</first><last>Banchs</last></editor>
      <editor><first>Reinhard</first><last>Rapp</last></editor>
      <editor><first>Marta R.</first><last>Costa-jussà</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="d03fd2cc">W16-4500</url>
    </frontmatter>
    <paper id="1">
      <title>Combining fast_align with Hierarchical Sub-sentential Alignment for Better Word Alignments</title>
      <author><first>Hao</first> <last>Wang</last></author>
      <author><first>Yves</first> <last>Lepage</last></author>
      <pages>1–7</pages>
      <url hash="cbdaeedb">W16-4501</url>
      <abstract>fast align is a simple and fast word alignment tool which is widely used in state-of-the-art machine translation systems. It yields comparable results in the end-to-end translation experiments of various language pairs. However, fast align does not perform as well as GIZA++ when applied to language pairs with distinct word orders, like English and Japanese. In this paper, given the lexical translation table output by fast align, we propose to realign words using the hierarchical sub-sentential alignment approach. Experimental results show that simple additional processing improves the performance of word alignment, which is measured by counting alignment matches in comparison with fast align. We also report the result of final machine translation in both English-Japanese and Japanese-English. We show our best system provided significant improvements over the baseline as measured by BLEU and RIBES.</abstract>
    </paper>
    <paper id="2">
      <title>Neural Network Language Models for Candidate Scoring in Hybrid Multi-System Machine Translation</title>
      <author><first>Matīss</first> <last>Rikters</last></author>
      <pages>8–15</pages>
      <url hash="acda1b5f">W16-4502</url>
      <abstract>This paper presents the comparison of how using different neural network based language modeling tools for selecting the best candidate fragments affects the final output translation quality in a hybrid multi-system machine translation setup. Experiments were conducted by comparing perplexity and BLEU scores on common test cases using the same training data set. A 12-gram statistical language model was selected as a baseline to oppose three neural network based models of different characteristics. The models were integrated in a hybrid system that depends on the perplexity score of a sentence fragment to produce the best fitting translations. The results show a correlation between language model perplexity and BLEU scores as well as overall improvements in BLEU.</abstract>
    </paper>
    <paper id="3">
      <title>Image-Image Search for Comparable Corpora Construction</title>
      <author><first>Yu</first> <last>Hong</last></author>
      <author><first>Liang</first> <last>Yao</last></author>
      <author><first>Mengyi</first> <last>Liu</last></author>
      <author><first>Tongtao</first> <last>Zhang</last></author>
      <author><first>Wenxuan</first> <last>Zhou</last></author>
      <author><first>Jianmin</first> <last>Yao</last></author>
      <author><first>Heng</first> <last>Ji</last></author>
      <pages>16–25</pages>
      <url hash="416aff29">W16-4503</url>
      <abstract>We present a novel method of comparable corpora construction. Unlike the traditional methods which heavily rely on linguistic features, our method only takes image similarity into consid-eration. We use an image-image search engine to obtain similar images, together with the cap-tions in source language and target language. On the basis, we utilize captions of similar imag-es to construct sentence-level bilingual corpora. Experiments on 10,371 target captions show that our method achieves a precision of 0.85 in the top search results.</abstract>
    </paper>
    <paper id="4">
      <title>Predicting Translation Equivalents in Linked <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>ets</title>
      <author><first>Krasimir</first> <last>Angelov</last></author>
      <author><first>Gleb</first> <last>Lobanov</last></author>
      <pages>26–32</pages>
      <url hash="b32b8716">W16-4504</url>
      <abstract>We present an algorithm for predicting translation equivalents between two languages, based on the corresponding WordNets. The assumption is that all synsets of one of the languages are linked to the corresponding synsets in the other language. In theory, given the exact sense of a word in a context it must be possible to translate it as any of the words in the linked synset. In practice, however, this does not work well since automatic and accurate sense disambiguation is difficult. Instead it is possible to define a more robust translation relation between the lexemes of the two languages. As far as we know the Finnish WordNet is the only one that includes that relation. Our algorithm can be used to predict the relation for other languages as well. This is useful for instance in hybrid machine translation systems which are usually more dependent on high-quality translation dictionaries.</abstract>
    </paper>
    <paper id="5">
      <title>Modifications of Machine Translation Evaluation Metrics by Using Word Embeddings</title>
      <author><first>Haozhou</first> <last>Wang</last></author>
      <author><first>Paola</first> <last>Merlo</last></author>
      <pages>33–41</pages>
      <url hash="64898a1b">W16-4505</url>
      <abstract>Traditional machine translation evaluation metrics such as BLEU and WER have been widely used, but these metrics have poor correlations with human judgements because they badly represent word similarity and impose strict identity matching. In this paper, we propose some modifications to the traditional measures based on word embeddings for these two metrics. The evaluation results show that our modifications significantly improve their correlation with human judgements.</abstract>
    </paper>
    <paper id="6">
      <title>Verb sense disambiguation in Machine Translation</title>
      <author><first>Roman</first> <last>Sudarikov</last></author>
      <author><first>Ondřej</first> <last>Dušek</last></author>
      <author><first>Martin</first> <last>Holub</last></author>
      <author><first>Ondřej</first> <last>Bojar</last></author>
      <author><first>Vincent</first> <last>Kríž</last></author>
      <pages>42–50</pages>
      <url hash="80887ada">W16-4506</url>
      <abstract>We describe experiments in Machine Translation using word sense disambiguation (WSD) information. This work focuses on WSD in verbs, based on two different approaches – verbal patterns based on corpus pattern analysis and verbal word senses from valency frames. We evaluate several options of using verb senses in the source-language sentences as an additional factor for the Moses statistical machine translation system. Our results show a statistically significant translation quality improvement in terms of the BLEU metric for the valency frames approach, but in manual evaluation, both WSD methods bring improvements.</abstract>
    </paper>
    <paper id="7">
      <title>Improving word alignment for low resource languages using <fixed-case>E</fixed-case>nglish monolingual <fixed-case>SRL</fixed-case></title>
      <author><first>Meriem</first> <last>Beloucif</last></author>
      <author><first>Markus</first> <last>Saers</last></author>
      <author><first>Dekai</first> <last>Wu</last></author>
      <pages>51–60</pages>
      <url hash="e38ba765">W16-4507</url>
      <abstract>We introduce a new statistical machine translation approach specifically geared to learning translation from low resource languages, that exploits monolingual English semantic parsing to bias inversion transduction grammar (ITG) induction. We show that in contrast to conventional statistical machine translation (SMT) training methods, which rely heavily on phrase memorization, our approach focuses on learning bilingual correlations that help translating low resource languages, by using the output language semantic structure to further narrow down ITG constraints. This approach is motivated by previous research which has shown that injecting a semantic frame based objective function while training SMT models improves the translation quality. We show that including a monolingual semantic objective function during the learning of the translation model leads towards a semantically driven alignment which is more efficient than simply tuning loglinear mixture weights against a semantic frame based evaluation metric in the final stage of statistical machine translation training. We test our approach with three different language pairs and demonstrate that our model biases the learning towards more semantically correct alignments. Both GIZA++ and ITG based techniques fail to capture meaningful bilingual constituents, which is required when trying to learn translation models for low resource languages. In contrast, our proposed model not only improve translation by injecting a monolingual objective function to learn bilingual correlations during early training of the translation model, but also helps to learn more meaningful correlations with a relatively small data set, leading to a better alignment compared to either conventional ITG or traditional GIZA++ based approaches.</abstract>
    </paper>
    <paper id="8">
      <title>Using Bilingual Segments in Generating Word-to-word Translations</title>
      <author><first>Kavitha</first> <last>Mahesh</last></author>
      <author><first>Gabriel</first> <last>Pereira Lopes</last></author>
      <author><first>Luís</first> <last>Gomes</last></author>
      <pages>61–71</pages>
      <url hash="a93a23c1">W16-4508</url>
      <abstract>We defend that bilingual lexicons automatically extracted from parallel corpora, whose entries have been meanwhile validated by linguists and classified as correct or incorrect, should constitute a specific parallel corpora. And, in this paper, we propose to use word-to-word translations to learn morph-units (comprising of bilingual stems and suffixes) from those bilingual lexicons for two language pairs L1-L2 and L1-L3 to induce a bilingual lexicon for the language pair L2-L3, apart from also learning morph-units for this other language pair. The applicability of bilingual morph-units in L1-L2 and L1-L3 is examined from the perspective of pivot-based lexicon induction for language pair L2-L3 with L1 as bridge. While the lexicon is derived by transitivity, the correspondences are identified based on previously learnt bilingual stems and suffixes rather than surface translation forms. The induced pairs are validated using a binary classifier trained on morphological and similarity-based features using an existing, automatically acquired, manually validated bilingual translation lexicon for language pair L2-L3. In this paper, we discuss the use of English (EN)-French (FR) and English (EN)-Portuguese (PT) lexicon of word-to-word translations in generating word-to-word translations for the language pair FR-PT with EN as pivot language. Generated translations are filtered out first using an SVM-based FR-PT classifier and then are manually validated.</abstract>
    </paper>
  </volume>
  <volume id="46">
    <meta>
      <booktitle>Proceedings of the 3rd Workshop on <fixed-case>A</fixed-case>sian Translation (<fixed-case>WAT</fixed-case>2016)</booktitle>
      <url hash="a000cbcf">W16-46</url>
      <editor><first>Toshiaki</first><last>Nakazawa</last></editor>
      <editor><first>Hideya</first><last>Mino</last></editor>
      <editor><first>Chenchen</first><last>Ding</last></editor>
      <editor><first>Isao</first><last>Goto</last></editor>
      <editor><first>Graham</first><last>Neubig</last></editor>
      <editor><first>Sadao</first><last>Kurohashi</last></editor>
      <editor><first>Ir. Hammam</first><last>Riza</last></editor>
      <editor><first>Pushpak</first><last>Bhattacharyya</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="9343760c">W16-4600</url>
    </frontmatter>
    <paper id="1">
      <title>Overview of the 3rd Workshop on <fixed-case>A</fixed-case>sian Translation</title>
      <author><first>Toshiaki</first> <last>Nakazawa</last></author>
      <author><first>Chenchen</first> <last>Ding</last></author>
      <author><first>Hideya</first> <last>Mino</last></author>
      <author><first>Isao</first> <last>Goto</last></author>
      <author><first>Graham</first> <last>Neubig</last></author>
      <author><first>Sadao</first> <last>Kurohashi</last></author>
      <pages>1–46</pages>
      <url hash="2a8fd4b4">W16-4601</url>
      <abstract>This paper presents the results of the shared tasks from the 3rd workshop on Asian translation (WAT2016) including J ↔ E, J ↔ C scientific paper translation subtasks, C ↔ J, K ↔ J, E ↔ J patent translation subtasks, I ↔ E newswire subtasks and H ↔ E, H ↔ J mixed domain subtasks. For the WAT2016, 15 institutions participated in the shared tasks. About 500 translation results have been submitted to the automatic evaluation server, and selected submissions were manually evaluated.</abstract>
    </paper>
    <paper id="2">
      <title>Translation of Patent Sentences with a Large Vocabulary of Technical Terms Using Neural Machine Translation</title>
      <author><first>Zi</first> <last>Long</last></author>
      <author><first>Takehito</first> <last>Utsuro</last></author>
      <author><first>Tomoharu</first> <last>Mitsuhashi</last></author>
      <author><first>Mikio</first> <last>Yamamoto</last></author>
      <pages>47–57</pages>
      <url hash="41fb3b56">W16-4602</url>
      <abstract>Neural machine translation (NMT), a new approach to machine translation, has achieved promising results comparable to those of traditional approaches such as statistical machine translation (SMT). Despite its recent success, NMT cannot handle a larger vocabulary because training complexity and decoding complexity proportionally increase with the number of target words. This problem becomes even more serious when translating patent documents, which contain many technical terms that are observed infrequently. In NMTs, words that are out of vocabulary are represented by a single unknown token. In this paper, we propose a method that enables NMT to translate patent sentences comprising a large vocabulary of technical terms. We train an NMT system on bilingual data wherein technical terms are replaced with technical term tokens; this allows it to translate most of the source sentences except technical terms. Further, we use it as a decoder to translate source sentences with technical term tokens and replace the tokens with technical term translations using SMT. We also use it to rerank the 1,000-best SMT translations on the basis of the average of the SMT score and that of the NMT rescoring of the translated sentences with technical term tokens. Our experiments on Japanese-Chinese patent sentences show that the proposed NMT system achieves a substantial improvement of up to 3.1 BLEU points and 2.3 RIBES points over traditional SMT systems and an improvement of approximately 0.6 BLEU points and 0.8 RIBES points over an equivalent NMT system without our proposed technique.</abstract>
    </paper>
    <paper id="3">
      <title><fixed-case>J</fixed-case>apanese-<fixed-case>E</fixed-case>nglish Machine Translation of Recipe Texts</title>
      <author><first>Takayuki</first> <last>Sato</last></author>
      <author><first>Jun</first> <last>Harashima</last></author>
      <author><first>Mamoru</first> <last>Komachi</last></author>
      <pages>58–67</pages>
      <url hash="46737803">W16-4603</url>
      <abstract>Concomitant with the globalization of food culture, demand for the recipes of specialty dishes has been increasing. The recent growth in recipe sharing websites and food blogs has resulted in numerous recipe texts being available for diverse foods in various languages. However, little work has been done on machine translation of recipe texts. In this paper, we address the task of translating recipes and investigate the advantages and disadvantages of traditional phrase-based statistical machine translation and more recent neural machine translation. Specifically, we translate Japanese recipes into English, analyze errors in the translated recipes, and discuss available room for improvements.</abstract>
    </paper>
    <paper id="4">
      <title><fixed-case>IIT</fixed-case> <fixed-case>B</fixed-case>ombay’s <fixed-case>E</fixed-case>nglish-<fixed-case>I</fixed-case>ndonesian submission at <fixed-case>WAT</fixed-case>: Integrating Neural Language Models with <fixed-case>SMT</fixed-case></title>
      <author><first>Sandhya</first> <last>Singh</last></author>
      <author><first>Anoop</first> <last>Kunchukuttan</last></author>
      <author><first>Pushpak</first> <last>Bhattacharyya</last></author>
      <pages>68–74</pages>
      <url hash="2c3ee4b9">W16-4604</url>
      <abstract>This paper describes the IIT Bombay’s submission as a part of the shared task in WAT 2016 for English–Indonesian language pair. The results reported here are for both the direction of the language pair. Among the various approaches experimented, Operation Sequence Model (OSM) and Neural Language Model have been submitted for WAT. The OSM approach integrates translation and reordering process resulting in relatively improved translation. Similarly the neural experiment integrates Neural Language Model with Statistical Machine Translation (SMT) as a feature for translation. The Neural Probabilistic Language Model (NPLM) gave relatively high BLEU points for Indonesian to English translation system while the Neural Network Joint Model (NNJM) performed better for English to Indonesian direction of translation system. The results indicate improvement over the baseline Phrase-based SMT by 0.61 BLEU points for English-Indonesian system and 0.55 BLEU points for Indonesian-English translation system.</abstract>
    </paper>
    <paper id="5">
      <title>Domain Adaptation and Attention-Based Unknown Word Replacement in <fixed-case>C</fixed-case>hinese-to-<fixed-case>J</fixed-case>apanese Neural Machine Translation</title>
      <author><first>Kazuma</first> <last>Hashimoto</last></author>
      <author><first>Akiko</first> <last>Eriguchi</last></author>
      <author><first>Yoshimasa</first> <last>Tsuruoka</last></author>
      <pages>75–83</pages>
      <url hash="beb56148">W16-4605</url>
      <abstract>This paper describes our UT-KAY system that participated in the Workshop on Asian Translation 2016. Based on an Attention-based Neural Machine Translation (ANMT) model, we build our system by incorporating a domain adaptation method for multiple domains and an attention-based unknown word replacement method. In experiments, we verify that the attention-based unknown word replacement method is effective in improving translation scores in Chinese-to-Japanese machine translation. We further show results of manual analysis on the replaced unknown words.</abstract>
    </paper>
    <paper id="6">
      <title>Global Pre-ordering for Improving Sublanguage Translation</title>
      <author><first>Masaru</first> <last>Fuji</last></author>
      <author><first>Masao</first> <last>Utiyama</last></author>
      <author><first>Eiichiro</first> <last>Sumita</last></author>
      <author><first>Yuji</first> <last>Matsumoto</last></author>
      <pages>84–93</pages>
      <url hash="6c893243">W16-4606</url>
      <abstract>When translating formal documents, capturing the sentence structure specific to the sublanguage is extremely necessary to obtain high-quality translations. This paper proposes a novel global reordering method with particular focus on long-distance reordering for capturing the global sentence structure of a sublanguage. The proposed method learns global reordering models from a non-annotated parallel corpus and works in conjunction with conventional syntactic reordering. Experimental results on the patent abstract sublanguage show substantial gains of more than 25 points in the RIBES metric and comparable BLEU scores both for Japanese-to-English and English-to-Japanese translations.</abstract>
    </paper>
    <paper id="7">
      <title>Neural Reordering Model Considering Phrase Translation and Word Alignment for Phrase-based Translation</title>
      <author><first>Shin</first> <last>Kanouchi</last></author>
      <author><first>Katsuhito</first> <last>Sudoh</last></author>
      <author><first>Mamoru</first> <last>Komachi</last></author>
      <pages>94–103</pages>
      <url hash="aa305b42">W16-4607</url>
      <abstract>This paper presents an improved lexicalized reordering model for phrase-based statistical machine translation using a deep neural network. Lexicalized reordering suffers from reordering ambiguity, data sparseness and noises in a phrase table. Previous neural reordering model is successful to solve the first and second problems but fails to address the third one. Therefore, we propose new features using phrase translation and word alignment to construct phrase vectors to handle inherently noisy phrase translation pairs. The experimental results show that our proposed method improves the accuracy of phrase reordering. We confirm that the proposed method works well with phrase pairs including NULL alignments.</abstract>
    </paper>
    <paper id="8">
      <title>System Description of bjtu_nlp Neural Machine Translation System</title>
      <author><first>Shaotong</first> <last>Li</last></author>
      <author><first>JinAn</first> <last>Xu</last></author>
      <author><first>Yufeng</first> <last>Chen</last></author>
      <author><first>Yujie</first> <last>Zhang</last></author>
      <pages>104–110</pages>
      <url hash="762d4aeb">W16-4608</url>
      <abstract>This paper presents our machine translation system that developed for the WAT2016 evalua-tion tasks of ja-en, ja-zh, en-ja, zh-ja, JPCja-en, JPCja-zh, JPCen-ja, JPCzh-ja. We build our system based on encoder–decoder framework by integrating recurrent neural network (RNN) and gate recurrent unit (GRU), and we also adopt an attention mechanism for solving the problem of information loss. Additionally, we propose a simple translation-specific approach to resolve the unknown word translation problem. Experimental results show that our system performs better than the baseline statistical machine translation (SMT) systems in each task. Moreover, it shows that our proposed approach of unknown word translation performs effec-tively improvement of translation results.</abstract>
    </paper>
    <paper id="9">
      <title>Translation systems and experimental results of the <fixed-case>EHR</fixed-case> group for <fixed-case>WAT</fixed-case>2016 tasks</title>
      <author><first>Terumasa</first> <last>Ehara</last></author>
      <pages>111–118</pages>
      <url hash="6252a1cd">W16-4609</url>
      <abstract>System architecture, experimental settings and experimental results of the group for the WAT2016 tasks are described. We participate in six tasks: en-ja, zh-ja, JPCzh-ja, JPCko-ja, HINDENen-hi and HINDENhi-ja. Although the basic architecture of our sys-tems is PBSMT with reordering, several techniques are conducted. Especially, the system for the HINDENhi-ja task with pivoting by English uses the reordering technique. Be-cause Hindi and Japanese are both OV type languages and English is a VO type language, we can use reordering technique to the pivot language. We can improve BLEU score from 7.47 to 7.66 by the reordering technique for the sentence level pivoting of this task.</abstract>
    </paper>
    <paper id="10">
      <title>Lexicons and Minimum Risk Training for Neural Machine Translation: <fixed-case>NAIST</fixed-case>-<fixed-case>CMU</fixed-case> at <fixed-case>WAT</fixed-case>2016</title>
      <author><first>Graham</first> <last>Neubig</last></author>
      <pages>119–125</pages>
      <url hash="d15e58f3">W16-4610</url>
      <abstract>This year, the Nara Institute of Science and Technology (NAIST)/Carnegie Mellon University (CMU) submission to the Japanese-English translation track of the 2016 Workshop on Asian Translation was based on attentional neural machine translation (NMT) models. In addition to the standard NMT model, we make a number of improvements, most notably the use of discrete translation lexicons to improve probability estimates, and the use of minimum risk training to optimize the MT system for BLEU score. As a result, our system achieved the highest translation evaluation scores for the task.</abstract>
    </paper>
    <paper id="11">
      <title><fixed-case>NICT</fixed-case>-2 Translation System for <fixed-case>WAT</fixed-case>2016: Applying Domain Adaptation to Phrase-based Statistical Machine Translation</title>
      <author><first>Kenji</first> <last>Imamura</last></author>
      <author><first>Eiichiro</first> <last>Sumita</last></author>
      <pages>126–132</pages>
      <url hash="fe375777">W16-4611</url>
      <abstract>This paper describes the NICT-2 translation system for the 3rd Workshop on Asian Translation. The proposed system employs a domain adaptation method based on feature augmentation. We regarded the Japan Patent Office Corpus as a mixture of four domain corpora and improved the translation quality of each domain. In addition, we incorporated language models constructed from Google n-grams as external knowledge. Our domain adaptation method can naturally incorporate such external knowledge that contributes to translation quality.</abstract>
    </paper>
    <paper id="12">
      <title>Translation Using <fixed-case>JAPIO</fixed-case> Patent Corpora: <fixed-case>JAPIO</fixed-case> at <fixed-case>WAT</fixed-case>2016</title>
      <author><first>Satoshi</first> <last>Kinoshita</last></author>
      <author><first>Tadaaki</first> <last>Oshio</last></author>
      <author><first>Tomoharu</first> <last>Mitsuhashi</last></author>
      <author><first>Terumasa</first> <last>Ehara</last></author>
      <pages>133–138</pages>
      <url hash="3dabd3f8">W16-4612</url>
      <abstract>We participate in scientific paper subtask (ASPEC-EJ/CJ) and patent subtask (JPC-EJ/CJ/KJ) with phrase-based SMT systems which are trained with its own patent corpora. Using larger corpora than those prepared by the workshop organizer, we achieved higher BLEU scores than most participants in EJ and CJ translations of patent subtask, but in crowdsourcing evaluation, our EJ translation, which is best in all automatic evaluations, received a very poor score. In scientific paper subtask, our translations are given lower scores than most translations that are produced by translation engines trained with the in-domain corpora. But our scores are higher than those of general-purpose RBMTs and online services. Considering the result of crowdsourcing evaluation, it shows a possibility that CJ SMT system trained with a large patent corpus translates non-patent technical documents at a practical level.</abstract>
    </paper>
    <paper id="13">
      <title>An Efficient and Effective Online Sentence Segmenter for Simultaneous Interpretation</title>
      <author><first>Xiaolin</first> <last>Wang</last></author>
      <author><first>Andrew</first> <last>Finch</last></author>
      <author><first>Masao</first> <last>Utiyama</last></author>
      <author><first>Eiichiro</first> <last>Sumita</last></author>
      <pages>139–148</pages>
      <url hash="bebbd0db">W16-4613</url>
      <abstract>Simultaneous interpretation is a very challenging application of machine translation in which the input is a stream of words from a speech recognition engine. The key problem is how to segment the stream in an online manner into units suitable for translation. The segmentation process proceeds by calculating a confidence score for each word that indicates the soundness of placing a sentence boundary after it, and then heuristics are employed to determine the position of the boundaries. Multiple variants of the confidence scoring method and segmentation heuristics were studied. Experimental results show that the best performing strategy is not only efficient in terms of average latency per word, but also achieved end-to-end translation quality close to an offline baseline, and close to oracle segmentation.</abstract>
    </paper>
    <paper id="14">
      <title>Similar <fixed-case>S</fixed-case>outheast <fixed-case>A</fixed-case>sian Languages: Corpus-Based Case Study on <fixed-case>T</fixed-case>hai-<fixed-case>L</fixed-case>aotian and <fixed-case>M</fixed-case>alay-<fixed-case>I</fixed-case>ndonesian</title>
      <author><first>Chenchen</first> <last>Ding</last></author>
      <author><first>Masao</first> <last>Utiyama</last></author>
      <author><first>Eiichiro</first> <last>Sumita</last></author>
      <pages>149–156</pages>
      <url hash="19e33b36">W16-4614</url>
      <abstract>This paper illustrates the similarity between Thai and Laotian, and between Malay and Indonesian, based on an investigation on raw parallel data from Asian Language Treebank. The cross-lingual similarity is investigated and demonstrated on metrics of correspondence and order of tokens, based on several standard statistical machine translation techniques. The similarity shown in this study suggests a possibility on harmonious annotation and processing of the language pairs in future development.</abstract>
    </paper>
    <paper id="15">
      <title>Integrating empty category detection into preordering Machine Translation</title>
      <author><first>Shunsuke</first> <last>Takeno</last></author>
      <author><first>Masaaki</first> <last>Nagata</last></author>
      <author><first>Kazuhide</first> <last>Yamamoto</last></author>
      <pages>157–165</pages>
      <url hash="83e9b2c0">W16-4615</url>
      <abstract>We propose a method for integrating Japanese empty category detection into the preordering process of Japanese-to-English statistical machine translation. First, we apply machine-learning-based empty category detection to estimate the position and the type of empty categories in the constituent tree of the source sentence. Then, we apply discriminative preordering to the augmented constituent tree in which empty categories are treated as if they are normal lexical symbols. We find that it is effective to filter empty categories based on the confidence of estimation. Our experiments show that, for the IWSLT dataset consisting of short travel conversations, the insertion of empty categories alone improves the BLEU score from 33.2 to 34.3 and the RIBES score from 76.3 to 78.7, which imply that reordering has improved For the KFTT dataset consisting of Wikipedia sentences, the proposed preordering method considering empty categories improves the BLEU score from 19.9 to 20.2 and the RIBES score from 66.2 to 66.3, which shows both translation and reordering have improved slightly.</abstract>
    </paper>
    <paper id="16">
      <title><fixed-case>K</fixed-case>yoto <fixed-case>U</fixed-case>niversity Participation to <fixed-case>WAT</fixed-case> 2016</title>
      <author><first>Fabien</first> <last>Cromieres</last></author>
      <author><first>Chenhui</first> <last>Chu</last></author>
      <author><first>Toshiaki</first> <last>Nakazawa</last></author>
      <author><first>Sadao</first> <last>Kurohashi</last></author>
      <pages>166–174</pages>
      <url hash="b3129e2c">W16-4616</url>
      <abstract>We describe here our approaches and results on the WAT 2016 shared translation tasks. We tried to use both an example-based machine translation (MT) system and a neural MT system. We report very good translation results, especially when using neural MT for Chinese-to-Japanese translation.</abstract>
    </paper>
    <paper id="17">
      <title>Character-based Decoding in Tree-to-Sequence Attention-based Neural Machine Translation</title>
      <author><first>Akiko</first> <last>Eriguchi</last></author>
      <author><first>Kazuma</first> <last>Hashimoto</last></author>
      <author><first>Yoshimasa</first> <last>Tsuruoka</last></author>
      <pages>175–183</pages>
      <url hash="48cb90f2">W16-4617</url>
      <abstract>This paper reports our systems (UT-AKY) submitted in the 3rd Workshop of Asian Translation 2016 (WAT’16) and their results in the English-to-Japanese translation task. Our model is based on the tree-to-sequence Attention-based NMT (ANMT) model proposed by Eriguchi et al. (2016). We submitted two ANMT systems: one with a word-based decoder and the other with a character-based decoder. Experimenting on the English-to-Japanese translation task, we have confirmed that the character-based decoder can cover almost the full vocabulary in the target language and generate translations much faster than the word-based model.</abstract>
    </paper>
    <paper id="18">
      <title>Faster and Lighter Phrase-based Machine Translation Baseline</title>
      <author><first>Liling</first> <last>Tan</last></author>
      <pages>184–193</pages>
      <url hash="8ca33067">W16-4618</url>
      <abstract>This paper describes the SENSE machine translation system participation in the Third Workshop for Asian Translation (WAT2016). We share our best practices to build a fast and light phrase-based machine translation (PBMT) models that have comparable results to the baseline systems provided by the organizers. As Neural Machine Translation (NMT) overtakes PBMT as the state-of-the-art, deep learning and new MT practitioners might not be familiar with the PBMT paradigm and we hope that this paper will help them build a PBMT baseline system quickly and easily.</abstract>
    </paper>
    <paper id="19">
      <title>Improving Patent Translation using Bilingual Term Extraction and Re-tokenization for <fixed-case>C</fixed-case>hinese–<fixed-case>J</fixed-case>apanese</title>
      <author><first>Wei</first> <last>Yang</last></author>
      <author><first>Yves</first> <last>Lepage</last></author>
      <pages>194–202</pages>
      <url hash="d89e6552">W16-4619</url>
      <abstract>Unlike European languages, many Asian languages like Chinese and Japanese do not have typographic boundaries in written system. Word segmentation (tokenization) that break sentences down into individual words (tokens) is normally treated as the first step for machine translation (MT). For Chinese and Japanese, different rules and segmentation tools lead different segmentation results in different level of granularity between Chinese and Japanese. To improve the translation accuracy, we adjust and balance the granularity of segmentation results around terms for Chinese–Japanese patent corpus for training translation model. In this paper, we describe a statistical machine translation (SMT) system which is built on re-tokenized Chinese-Japanese patent training corpus using extracted bilingual multi-word terms.</abstract>
    </paper>
    <paper id="20">
      <title>Controlling the Voice of a Sentence in <fixed-case>J</fixed-case>apanese-to-<fixed-case>E</fixed-case>nglish Neural Machine Translation</title>
      <author><first>Hayahide</first> <last>Yamagishi</last></author>
      <author><first>Shin</first> <last>Kanouchi</last></author>
      <author><first>Takayuki</first> <last>Sato</last></author>
      <author><first>Mamoru</first> <last>Komachi</last></author>
      <pages>203–210</pages>
      <url hash="8227bf7e">W16-4620</url>
      <abstract>In machine translation, we must consider the difference in expression between languages. For example, the active/passive voice may change in Japanese-English translation. The same verb in Japanese may be translated into different voices at each translation because the voice of a generated sentence cannot be determined using only the information of the Japanese sentence. Machine translation systems should consider the information structure to improve the coherence of the output by using several topicalization techniques such as passivization. Therefore, this paper reports on our attempt to control the voice of the sentence generated by an encoder-decoder model. To control the voice of the generated sentence, we added the voice information of the target sentence to the source sentence during the training. We then generated sentences with a specified voice by appending the voice information to the source sentence. We observed experimentally whether the voice could be controlled. The results showed that, we could control the voice of the generated sentence with 85.0% accuracy on average. In the evaluation of Japanese-English translation, we obtained a 0.73-point improvement in BLEU score by using gold voice labels.</abstract>
    </paper>
    <paper id="21">
      <title><fixed-case>C</fixed-case>hinese-to-<fixed-case>J</fixed-case>apanese Patent Machine Translation based on Syntactic Pre-ordering for <fixed-case>WAT</fixed-case> 2016</title>
      <author><first>Katsuhito</first> <last>Sudoh</last></author>
      <author><first>Masaaki</first> <last>Nagata</last></author>
      <pages>211–215</pages>
      <url hash="9b315f30">W16-4621</url>
      <abstract>This paper presents our Chinese-to-Japanese patent machine translation system for WAT 2016 (Group ID: ntt) that uses syntactic pre-ordering over Chinese dependency structures. Chinese words are reordered by a learning-to-rank model based on pairwise classification to obtain word order close to Japanese. In this year’s system, two different machine translation methods are compared: traditional phrase-based statistical machine translation and recent sequence-to-sequence neural machine translation with an attention mechanism. Our pre-ordering showed a significant improvement over the phrase-based baseline, but, in contrast, it degraded the neural machine translation baseline.</abstract>
    </paper>
    <paper id="22">
      <title><fixed-case>IITP</fixed-case> <fixed-case>E</fixed-case>nglish-<fixed-case>H</fixed-case>indi Machine Translation System at <fixed-case>WAT</fixed-case> 2016</title>
      <author><first>Sukanta</first> <last>Sen</last></author>
      <author><first>Debajyoty</first> <last>Banik</last></author>
      <author><first>Asif</first> <last>Ekbal</last></author>
      <author><first>Pushpak</first> <last>Bhattacharyya</last></author>
      <pages>216–222</pages>
      <url hash="d0b1ec5b">W16-4622</url>
      <abstract>In this paper we describe the system that we develop as part of our participation in WAT 2016. We develop a system based on hierarchical phrase-based SMT for English to Hindi language pair. We perform re-ordering and augment bilingual dictionary to improve the performance. As a baseline we use a phrase-based SMT model. The MT models are fine-tuned on the development set, and the best configurations are used to report the evaluation on the test set. Experiments show the BLEU of 13.71 on the benchmark test data. This is better compared to the official baseline BLEU score of 10.79.</abstract>
    </paper>
    <paper id="23">
      <title>Residual Stacking of <fixed-case>RNN</fixed-case>s for Neural Machine Translation</title>
      <author><first>Raphael</first> <last>Shu</last></author>
      <author><first>Akiva</first> <last>Miura</last></author>
      <pages>223–229</pages>
      <url hash="658d1913">W16-4623</url>
      <abstract>To enhance Neural Machine Translation models, several obvious ways such as enlarging the hidden size of recurrent layers and stacking multiple layers of RNN can be considered. Surprisingly, we observe that using naively stacked RNNs in the decoder slows down the training and leads to degradation in performance. In this paper, We demonstrate that applying residual connections in the depth of stacked RNNs can help the optimization, which is referred to as residual stacking. In empirical evaluation, residual stacking of decoder RNNs gives superior results compared to other methods of enhancing the model with a fixed parameter budget. Our submitted systems in WAT2016 are based on a NMT model ensemble with residual stacking in the decoder. To further improve the performance, we also attempt various methods of system combination in our experiments.</abstract>
    </paper>
  </volume>
  <volume id="47">
    <meta>
      <booktitle>Proceedings of the 5th International Workshop on Computational Terminology (Computerm2016)</booktitle>
      <url hash="36ac847e">W16-47</url>
      <editor><first>Patrick</first><last>Drouin</last></editor>
      <editor><first>Natalia</first><last>Grabar</last></editor>
      <editor><first>Thierry</first><last>Hamon</last></editor>
      <editor><first>Kyo</first><last>Kageura</last></editor>
      <editor><first>Koichi</first><last>Takeuchi</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="eea653a3">W16-4700</url>
    </frontmatter>
    <paper id="1">
      <title>Analyzing Impact, Trend, and Diffusion of Knowledge associated with Neoplasms Research</title>
      <author><first>Min</first> <last>Song</last></author>
      <pages>1</pages>
      <url hash="ac89c777">W16-4701</url>
      <abstract>Cancer (a.k.a neoplasms in a broader sense) is one of the leading causes of death worldwide and its incidence is expected to exacerbate. To respond to the critical need from the society, there have been rigorous attempts for the cancer research community to develop treatment for cancer. Accordingly, we observe a surge in the sheer volume of research products and outcomes in relation to neoplasms. In this talk, we introduce the notion of entitymetrics to provide a new lens for understanding the impact, trend, and diffusion of knowledge associated with neoplasms research. To this end, we collected over two million records from PubMed, the most popular search engine in the medical domain. Coupled with text mining techniques including named entity recognition, sentence boundary detection, string approximate matching, entitymetrics enables us to analyze knowledge diffusion, impact, and trend at various knowledge entity units, such as bio-entity, organization, and country. At the end of the talk, the future applications and possible directions of entitymetrics will be discussed.</abstract>
    </paper>
    <paper id="2">
      <title>Local-Global Vectors to Improve Unigram Terminology Extraction</title>
      <author><first>Ehsan</first> <last>Amjadian</last></author>
      <author><first>Diana</first> <last>Inkpen</last></author>
      <author><first>Tahereh</first> <last>Paribakht</last></author>
      <author><first>Farahnaz</first> <last>Faez</last></author>
      <pages>2–11</pages>
      <url hash="48e86f28">W16-4702</url>
      <abstract>The present paper explores a novel method that integrates efficient distributed representations with terminology extraction. We show that the information from a small number of observed instances can be combined with local and global word embeddings to remarkably improve the term extraction results on unigram terms. To do so we pass the terms extracted by other tools to a filter made of the local-global embeddings and a classifier which in turn decides whether or not a term candidate is a term. The filter can also be used as a hub to merge different term extraction tools into a single higher-performing system. We compare filters that use the skip-gram architecture and filters that employ the CBOW architecture for the task at hand.</abstract>
    </paper>
    <paper id="3">
      <title>Recognition of non-domain phrases in automatically extracted lists of terms</title>
      <author><first>Agnieszka</first> <last>Mykowiecka</last></author>
      <author><first>Malgorzata</first> <last>Marciniak</last></author>
      <author><first>Piotr</first> <last>Rychlik</last></author>
      <pages>12–20</pages>
      <url hash="a043d397">W16-4703</url>
      <abstract>In the paper, we address the problem of recognition of non-domain phrases in terminology lists obtained with an automatic term extraction tool. We focus on identification of multi-word phrases that are general terms and discourse function expressions. We tested several methods based on domain corpora comparison and a method based on contexts of phrases identified in a large corpus of general language. We compared the results of the methods to manual annotation. The results show that the task is quite hard as the inter-annotator agreement is low. Several tested methods achieved similar overall results, although the phrase ordering varied between methods. The most successful method with the precision about 0.75 at the half of the tested list was the context based method using a modified contextual diversity coefficient.</abstract>
    </paper>
    <paper id="4">
      <title>Contextual term equivalent search using domain-driven disambiguation</title>
      <author><first>Caroline</first> <last>Barrière</last></author>
      <author><first>Pierre André</first> <last>Ménard</last></author>
      <author><first>Daphnée</first> <last>Azoulay</last></author>
      <pages>21–29</pages>
      <url hash="7c48e55c">W16-4704</url>
      <abstract>This article presents a domain-driven algorithm for the task of term sense disambiguation (TSD). TSD aims at automatically choosing which term record from a term bank best represents the meaning of a term occurring in a particular context. In a translation environment, finding the contextually appropriate term record is necessary to access the proper equivalent to be used in the target language text. The term bank TERMIUM Plus, recently published as an open access repository, is chosen as a domain-rich resource for testing our TSD algorithm, using English and French as source and target languages. We devise an experiment using over 1300 English terms found in scientific articles, and show that our domain-driven TSD algorithm is able to bring the best term record, and therefore the best French equivalent, at the average rank of 1.69 compared to a baseline random rank of 3.51.</abstract>
    </paper>
    <paper id="5">
      <title>A Method of Augmenting Bilingual Terminology by Taking Advantage of the Conceptual Systematicity of Terminologies</title>
      <author><first>Miki</first> <last>Iwai</last></author>
      <author><first>Koichi</first> <last>Takeuchi</last></author>
      <author><first>Kyo</first> <last>Kageura</last></author>
      <author><first>Kazuya</first> <last>Ishibashi</last></author>
      <pages>30–40</pages>
      <url hash="40462eed">W16-4705</url>
      <abstract>In this paper, we propose a method of augmenting existing bilingual terminologies. Our method belongs to a “generate and validate” framework rather than extraction from corpora. Although many studies have proposed methods to find term translations or to augment terminology within a “generate and validate” framework, few has taken full advantage of the systematic nature of terminologies. A terminology of a domain represents the conceptual system of the domain fairly systematically, and we contend that making use of the systematicity fully will greatly contribute to the effective augmentation of terminologies. This paper proposes and evaluates a novel method to generate bilingual term candidates by using existing terminologies and delving into their systematicity. Experiments have shown that our method can generate much better term candidate pairs than the existing method and give improved performance for terminology augmentation.</abstract>
    </paper>
    <paper id="6">
      <title>Acquisition of semantic relations between terms: how far can we get with standard <fixed-case>NLP</fixed-case> tools?</title>
      <author><first>Ina</first> <last>Roesiger</last></author>
      <author><first>Julia</first> <last>Bettinger</last></author>
      <author><first>Johannes</first> <last>Schäfer</last></author>
      <author><first>Michael</first> <last>Dorna</last></author>
      <author><first>Ulrich</first> <last>Heid</last></author>
      <pages>41–51</pages>
      <url hash="f53a5642">W16-4706</url>
      <abstract>The extraction of data exemplifying relations between terms can make use, at least to a large extent, of techniques that are similar to those used in standard hybrid term candidate extraction, namely basic corpus analysis tools (e.g. tagging, lemmatization, parsing), as well as morphological analysis of complex words (compounds and derived items). In this article, we discuss the use of such techniques for the extraction of raw material for a description of relations between terms, and we provide internal evaluation data for the devices developed. We claim that user-generated content is a rich source of term variation through paraphrasing and reformulation, and that these provide relational data at the same time as term variants. Germanic languages with their rich word formation morphology may be particularly good candidates for the approach advocated here.</abstract>
    </paper>
    <paper id="7">
      <title>Evaluation of distributional semantic models: a holistic approach</title>
      <author><first>Gabriel</first> <last>Bernier-Colborne</last></author>
      <author><first>Patrick</first> <last>Drouin</last></author>
      <pages>52–61</pages>
      <url hash="f231b1df">W16-4707</url>
      <abstract>We investigate how both model-related factors and application-related factors affect the accuracy of distributional semantic models (DSMs) in the context of specialized lexicography, and how these factors interact. This holistic approach to the evaluation of DSMs provides valuable guidelines for the use of these models and insight into the kind of semantic information they capture.</abstract>
    </paper>
    <paper id="8">
      <title>A Study on the Interplay Between the Corpus Size and Parameters of a Distributional Model for Term Classification</title>
      <author><first>Behrang</first> <last>QasemiZadeh</last></author>
      <pages>62–72</pages>
      <url hash="5eeb0946">W16-4708</url>
      <abstract>We propose and evaluate a method for identifying co-hyponym lexical units in a terminological resource. The principles of term recognition and distributional semantics are combined to extract terms from a similar category of concept. Given a set of candidate terms, random projections are employed to represent them as low-dimensional vectors. These vectors are derived automatically from the frequency of the co-occurrences of the candidate terms and words that appear within windows of text in their proximity (context-windows). In a <tex-math>k</tex-math>-nearest neighbours framework, these vectors are classified using a small set of manually annotated terms which exemplify concept categories. We then investigate the interplay between the size of the corpus that is used for collecting the co-occurrences and a number of factors that play roles in the performance of the proposed method: the configuration of context-windows for collecting co-occurrences, the selection of neighbourhood size (<tex-math>k</tex-math>), and the choice of similarity metric. </abstract>
    </paper>
    <paper id="9">
      <title>Pattern-based Word Sketches for the Extraction of Semantic Relations</title>
      <author><first>Pilar</first> <last>León-Araúz</last></author>
      <author><first>Antonio</first> <last>San Martín</last></author>
      <author><first>Pamela</first> <last>Faber</last></author>
      <pages>73–82</pages>
      <url hash="bb7b85ae">W16-4709</url>
      <abstract>Despite advances in computer technology, terminologists still tend to rely on manual work to extract all the semantic information that they need for the description of specialized concepts. In this paper we propose the creation of new word sketches in Sketch Engine for the extraction of semantic relations. Following a pattern-based approach, new sketch grammars are devel-oped in order to extract some of the most common semantic relations used in the field of ter-minology: generic-specific, part-whole, location, cause and function.</abstract>
    </paper>
    <paper id="10">
      <title>Constructing and Evaluating Controlled Bilingual Terminologies</title>
      <author><first>Rei</first> <last>Miyata</last></author>
      <author><first>Kyo</first> <last>Kageura</last></author>
      <pages>83–93</pages>
      <url hash="b3405ed8">W16-4710</url>
      <abstract>This paper presents the construction and evaluation of Japanese and English controlled bilingual terminologies that are particularly intended for controlled authoring and machine translation with special reference to the Japanese municipal domain. Our terminologies are constructed by extracting terms from municipal website texts, and the term variations are controlled by defining preferred and proscribed terms for both the source Japanese and the target English. To assess the coverage of the terms/concepts in the municipal domain and validate the quality of the control, we employ a quantitative extrapolation method that estimates the potential vocabulary size. Using Large-Number-of-Rare-Event (LNRE) modelling, we compare two parameters: (1) uncontrolled and controlled and (2) Japanese and English. The results show that our terminologies currently cover about 45–65% of the terms and 50–65% of the concepts in the municipal domain, and are well controlled. The detailed analysis of growth patterns of terminologies also provides insight into the extent to which we can enlarge the terminologies within the realistic range.</abstract>
    </paper>
    <paper id="11">
      <title>Providing and Analyzing <fixed-case>NLP</fixed-case> Terms for our Community</title>
      <author><first>Gil</first> <last>Francopoulo</last></author>
      <author><first>Joseph</first> <last>Mariani</last></author>
      <author><first>Patrick</first> <last>Paroubek</last></author>
      <author><first>Frédéric</first> <last>Vernier</last></author>
      <pages>94–103</pages>
      <url hash="449faa23">W16-4711</url>
      <abstract>By its own nature, the Natural Language Processing (NLP) community is a priori the best equipped to study the evolution of its own publications, but works in this direction are rare and only recently have we seen a few attempts at charting the field. In this paper, we use the algorithms, resources, standards, tools and common practices of the NLP field to build a list of terms characteristic of ongoing research, by mining a large corpus of scientific publications, aiming at the largest possible exhaustivity and covering the largest possible time span. Study of the evolution of this term list through time reveals interesting insights on the dynamics of field and the availability of the term database and of the corpus (for a large part) make possible many further comparative studies in addition to providing a test field for a new graphic interface designed to perform visual time analytics of large sized thesauri.</abstract>
    </paper>
    <paper id="12">
      <title>Evaluating a dictionary of human phenotype terms focusing on rare diseases</title>
      <author><first>Simon</first> <last>Kocbek</last></author>
      <author><first>Toyofumi</first> <last>Fujiwara</last></author>
      <author><first>Jin-Dong</first> <last>Kim</last></author>
      <author><first>Toshihisa</first> <last>Takagi</last></author>
      <author><first>Tudor</first> <last>Groza</last></author>
      <pages>104–109</pages>
      <url hash="b15aa9d1">W16-4712</url>
      <abstract>Annotating medical text such as clinical notes with human phenotype descriptors is an important task that can, for example, assist in building patient profiles. To automatically annotate text one usually needs a dictionary of predefined terms. However, do to the variety of human expressiveness, current state-of-the art phenotype concept recognizers and automatic annotators struggle with specific domain issues and challenges. In this paper we present results of an-notating gold standard corpus with a dictionary containing lexical variants for the Human Phenotype Ontology terms. The main purpose of the dictionary is to improve the recall of phenotype concept recognition systems. We compare the method with four other approaches and present results.</abstract>
    </paper>
    <paper id="13">
      <title>A semi automatic annotation approach for ontological and terminological knowledge acquisition</title>
      <author><first>Driss</first> <last>Sadoun</last></author>
      <pages>110–120</pages>
      <url hash="541cf280">W16-4713</url>
      <abstract>We propose a semi-automatic method for the acquisition of specialised ontological and terminological knowledge. An ontology and a terminology are automatically built from domain experts’ annotations. The ontology formalizes the common and shared conceptual vocabulary of those experts. Its associated terminology defines a glossary linking annotated terms to their semantic categories. These two resources evolve incrementally and are used for an automatic annotation of a new corpus at each iteration. The annotated corpus concerns the evaluation of French higher education and science institutions.</abstract>
    </paper>
    <paper id="14">
      <title>Understanding Medical free text: A Terminology driven approach</title>
      <author><first>Santosh Sai</first> <last>Krishna</last></author>
      <author><first>Manoj</first> <last>Hans</last></author>
      <pages>121–125</pages>
      <url hash="4aacb12a">W16-4714</url>
      <abstract>With many hospitals digitalizing clinical records it has opened opportunities for researchers in NLP, Machine Learning to apply techniques for extracting meaning and make actionable insights. There has been previous attempts in mapping free text to medical nomenclature like UMLS, SNOMED. However, in this paper, we had analyzed diagnosis in clinical reports using ICD10 to achieve a lightweight, real-time predictions by introducing concepts like WordInfo, root word identification. We were able to achieve 68.3% accuracy over clinical records collected from qualified clinicians. Our study would further help the healthcare institutes in organizing their clinical reports based on ICD10 mappings and derive numerous insights to achieve operational efficiency and better medical care.</abstract>
    </paper>
  </volume>
  <volume id="48">
    <meta>
      <booktitle>Proceedings of the Third Workshop on <fixed-case>NLP</fixed-case> for Similar Languages, Varieties and Dialects (<fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial3)</booktitle>
      <url hash="911e20c4">W16-48</url>
      <editor><first>Preslav</first><last>Nakov</last></editor>
      <editor><first>Marcos</first><last>Zampieri</last></editor>
      <editor><first>Liling</first><last>Tan</last></editor>
      <editor><first>Nikola</first><last>Ljubešić</last></editor>
      <editor><first>Jörg</first><last>Tiedemann</last></editor>
      <editor><first>Shervin</first><last>Malmasi</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="977a36fb">W16-4800</url>
    </frontmatter>
    <paper id="1">
      <title>Discriminating between Similar Languages and <fixed-case>A</fixed-case>rabic Dialect Identification: A Report on the Third <fixed-case>DSL</fixed-case> Shared Task</title>
      <author><first>Shervin</first> <last>Malmasi</last></author>
      <author><first>Marcos</first> <last>Zampieri</last></author>
      <author><first>Nikola</first> <last>Ljubešić</last></author>
      <author><first>Preslav</first> <last>Nakov</last></author>
      <author><first>Ahmed</first> <last>Ali</last></author>
      <author><first>Jörg</first> <last>Tiedemann</last></author>
      <pages>1–14</pages>
      <url hash="497e364e">W16-4801</url>
      <abstract>We present the results of the third edition of the Discriminating between Similar Languages (DSL) shared task, which was organized as part of the VarDial’2016 workshop at COLING’2016. The challenge offered two subtasks: subtask 1 focused on the identification of very similar languages and language varieties in newswire texts, whereas subtask 2 dealt with Arabic dialect identification in speech transcripts. A total of 37 teams registered to participate in the task, 24 teams submitted test results, and 20 teams also wrote system description papers. High-order character n-grams were the most successful feature, and the best classification approaches included traditional supervised learning methods such as SVM, logistic regression, and language models, while deep learning approaches did not perform very well.</abstract>
    </paper>
    <paper id="2">
      <title>Discriminating Similar Languages with Linear <fixed-case>SVM</fixed-case>s and Neural Networks</title>
      <author><first>Çağrı</first> <last>Çöltekin</last></author>
      <author><first>Taraka</first> <last>Rama</last></author>
      <pages>15–24</pages>
      <url hash="83cb4c40">W16-4802</url>
      <abstract>This paper describes the systems we experimented with for participating in the discriminating between similar languages (DSL) shared task 2016. We submitted results of a single system based on support vector machines (SVM) with linear kernel and using character ngram features, which obtained the first rank at the closed training track for test set A. Besides the linear SVM, we also report additional experiments with a number of deep learning architectures. Despite our intuition that non-linear deep learning methods should be advantageous, linear models seems to fare better in this task, at least with the amount of data and the amount of effort we spent on tuning these models.</abstract>
    </paper>
    <paper id="3">
      <title><fixed-case>LSTM</fixed-case> Autoencoders for Dialect Analysis</title>
      <author><first>Taraka</first> <last>Rama</last></author>
      <author><first>Çağrı</first> <last>Çöltekin</last></author>
      <pages>25–32</pages>
      <url hash="6f03351f">W16-4803</url>
      <abstract>Computational approaches for dialectometry employed Levenshtein distance to compute an aggregate similarity between two dialects belonging to a single language group. In this paper, we apply a sequence-to-sequence autoencoder to learn a deep representation for words that can be used for meaningful comparison across dialects. In contrast to the alignment-based methods, our method does not require explicit alignments. We apply our architectures to three different datasets and show that the learned representations indicate highly similar results with the analyses based on Levenshtein distance and capture the traditional dialectal differences shown by dialectologists.</abstract>
    </paper>
    <paper id="4">
      <title>The <fixed-case>GW</fixed-case>/<fixed-case>LT</fixed-case>3 <fixed-case>V</fixed-case>ar<fixed-case>D</fixed-case>ial 2016 Shared Task System for Dialects and Similar Languages Detection</title>
      <author><first>Ayah</first> <last>Zirikly</last></author>
      <author><first>Bart</first> <last>Desmet</last></author>
      <author><first>Mona</first> <last>Diab</last></author>
      <pages>33–41</pages>
      <url hash="5f4aa206">W16-4804</url>
      <abstract>This paper describes the GW/LT3 contribution to the 2016 VarDial shared task on the identification of similar languages (task 1) and Arabic dialects (task 2). For both tasks, we experimented with Logistic Regression and Neural Network classifiers in isolation. Additionally, we implemented a cascaded classifier that consists of coarse and fine-grained classifiers (task 1) and a classifier ensemble with majority voting for task 2. The submitted systems obtained state-of-the art performance and ranked first for the evaluation on social media data (test sets B1 and B2 for task 1), with a maximum weighted F1 score of 91.94%.</abstract>
    </paper>
    <paper id="5">
      <title>Processing Dialectal <fixed-case>A</fixed-case>rabic: Exploiting Variability and Similarity to Overcome Challenges and Discover Opportunities</title>
      <author><first>Mona</first> <last>Diab</last></author>
      <pages>42</pages>
      <url hash="921d95bb">W16-4805</url>
      <abstract>We recently witnessed an exponential growth in dialectal Arabic usage in both textual data and speech recordings especially in social media. Processing such media is of great utility for all kinds of applications ranging from information extraction to social media analytics for political and commercial purposes to building decision support systems. Compared to other languages, Arabic, especially the informal variety, poses a significant challenge to natural language processing algorithms since it comprises multiple dialects, linguistic code switching, and a lack of standardized orthographies, to top its relatively complex morphology. Inherently, the problem of processing Arabic in the context of social media is the problem of how to handle resource poor languages. In this talk I will go over some of our insights to some of these problems and show how there is a silver lining where we can generalize some of our solutions to other low resource language contexts.</abstract>
    </paper>
    <paper id="6">
      <title>Language Related Issues for Machine Translation between Closely Related <fixed-case>S</fixed-case>outh <fixed-case>S</fixed-case>lavic Languages</title>
      <author><first>Maja</first> <last>Popović</last></author>
      <author><first>Mihael</first> <last>Arčan</last></author>
      <author><first>Filip</first> <last>Klubička</last></author>
      <pages>43–52</pages>
      <url hash="0d412f70">W16-4806</url>
      <abstract>Machine translation between closely related languages is less challenging and exibits a smaller number of translation errors than translation between distant languages, but there are still obstacles which should be addressed in order to improve such systems. This work explores the obstacles for machine translation systems between closely related South Slavic languages, namely Croatian, Serbian and Slovenian. Statistical systems for all language pairs and translation directions are trained using parallel texts from different domains, however mainly on spoken language i.e. subtitles. For translation between Serbian and Croatian, a rule-based system is also explored. It is shown that for all language pairs and translation systems, the main obstacles are differences between structural properties.</abstract>
    </paper>
    <paper id="7">
      <title><fixed-case>R</fixed-case>omanized <fixed-case>B</fixed-case>erber and <fixed-case>R</fixed-case>omanized <fixed-case>A</fixed-case>rabic Automatic Language Identification Using Machine Learning</title>
      <author><first>Wafia</first> <last>Adouane</last></author>
      <author><first>Nasredine</first> <last>Semmar</last></author>
      <author><first>Richard</first> <last>Johansson</last></author>
      <pages>53–61</pages>
      <url hash="ee01f21c">W16-4807</url>
      <abstract>The identification of the language of text/speech input is the first step to be able to properly do any language-dependent natural language processing. The task is called Automatic Language Identification (ALI). Being a well-studied field since early 1960’s, various methods have been applied to many standard languages. The ALI standard methods require datasets for training and use character/word-based n-gram models. However, social media and new technologies have contributed to the rise of informal and minority languages on the Web. The state-of-the-art automatic language identifiers fail to properly identify many of them. Romanized Arabic (RA) and Romanized Berber (RB) are cases of these informal languages which are under-resourced. The goal of this paper is twofold: detect RA and RB, at a document level, as separate languages and distinguish between them as they coexist in North Africa. We consider the task as a classification problem and use supervised machine learning to solve it. For both languages, character-based 5-grams combined with additional lexicons score the best, F-score of 99.75% and 97.77% for RB and RA respectively.</abstract>
    </paper>
    <paper id="8">
      <title>How Many Languages Can a Language Model Model?</title>
      <author><first>Robert</first> <last>Östling</last></author>
      <pages>62</pages>
      <url hash="c1b56fd2">W16-4808</url>
      <abstract>One of the purposes of the VarDial workshop series is to encourage research into NLP methods that treat human languages as a continuum, by designing models that exploit the similarities between languages and variants. In my work, I am using a continuous vector representation of languages that allows modeling and exploring the language continuum in a very direct way. The basic tool for this is a character-based recurrent neural network language model conditioned on language vectors whose values are learned during training. By feeding the model Bible translations in a thousand languages, not only does the learned vector space capture language similarity, but by interpolating between the learned vectors it is possible to generate text in unattested intermediate forms between the training languages.</abstract>
    </paper>
    <paper id="9">
      <title>Automatic Detection of <fixed-case>A</fixed-case>rabicized <fixed-case>B</fixed-case>erber and <fixed-case>A</fixed-case>rabic Varieties</title>
      <author><first>Wafia</first> <last>Adouane</last></author>
      <author><first>Nasredine</first> <last>Semmar</last></author>
      <author><first>Richard</first> <last>Johansson</last></author>
      <author><first>Victoria</first> <last>Bobicev</last></author>
      <pages>63–72</pages>
      <url hash="111ad823">W16-4809</url>
      <abstract>Automatic Language Identification (ALI) is the detection of the natural language of an input text by a machine. It is the first necessary step to do any language-dependent natural language processing task. Various methods have been successfully applied to a wide range of languages, and the state-of-the-art automatic language identifiers are mainly based on character n-gram models trained on huge corpora. However, there are many languages which are not yet automatically processed, for instance minority and informal languages. Many of these languages are only spoken and do not exist in a written format. Social media platforms and new technologies have facilitated the emergence of written format for these spoken languages based on pronunciation. The latter are not well represented on the Web, commonly referred to as under-resourced languages, and the current available ALI tools fail to properly recognize them. In this paper, we revisit the problem of ALI with the focus on Arabicized Berber and dialectal Arabic short texts. We introduce new resources and evaluate the existing methods. The results show that machine learning models combined with lexicons are well suited for detecting Arabicized Berber and different Arabic varieties and distinguishing between them, giving a macro-average F-score of 92.94%.</abstract>
    </paper>
    <paper id="10">
      <title>Automatic Verification and Augmentation of Multilingual Lexicons</title>
      <author><first>Maryam</first> <last>Aminian</last></author>
      <author><first>Mohamed</first> <last>Al-Badrashiny</last></author>
      <author><first>Mona</first> <last>Diab</last></author>
      <pages>73–81</pages>
      <url hash="49fa1414">W16-4810</url>
      <abstract>We present an approach for automatic verification and augmentation of multilingual lexica. We exploit existing parallel and monolingual corpora to extract multilingual correspondents via tri-angulation. We demonstrate the efficacy of our approach on two publicly available resources: Tharwa, a three-way lexicon comprising Dialectal Arabic, Modern Standard Arabic and English lemmas among other information (Diab et al., 2014); and BabelNet, a multilingual thesaurus comprising over 276 languages including Arabic variant entries (Navigli and Ponzetto, 2012). Our automated approach yields an F1-score of 71.71% in generating correct multilingual correspondents against gold Tharwa, and 54.46% against gold BabelNet without any human intervention.</abstract>
    </paper>
    <paper id="11">
      <title>Faster Decoding for Subword Level Phrase-based <fixed-case>SMT</fixed-case> between Related Languages</title>
      <author><first>Anoop</first> <last>Kunchukuttan</last></author>
      <author><first>Pushpak</first> <last>Bhattacharyya</last></author>
      <pages>82–88</pages>
      <url hash="ca1bd892">W16-4811</url>
      <abstract>A common and effective way to train translation systems between related languages is to consider sub-word level basic units. However, this increases the length of the sentences resulting in increased decoding time. The increase in length is also impacted by the specific choice of data format for representing the sentences as subwords. In a phrase-based SMT framework, we investigate different choices of decoder parameters as well as data format and their impact on decoding time and translation accuracy. We suggest best options for these settings that significantly improve decoding time with little impact on the translation accuracy.</abstract>
    </paper>
    <paper id="12">
      <title>Subdialectal Differences in <fixed-case>S</fixed-case>orani <fixed-case>K</fixed-case>urdish</title>
      <author><first>Shervin</first> <last>Malmasi</last></author>
      <pages>89–96</pages>
      <url hash="48c57c6b">W16-4812</url>
      <abstract>In this study we apply classification methods for detecting subdialectal differences in Sorani Kurdish texts produced in different regions, namely Iran and Iraq. As Sorani is a low-resource language, no corpus including texts from different regions was readily available. To this end, we identified data sources that could be leveraged for this task to create a dataset of 200,000 sentences. Using surface features, we attempted to classify Sorani subdialects, showing that sentences from news sources in Iraq and Iran are distinguishable with 96% accuracy. This is the first preliminary study for a dialect that has not been widely studied in computational linguistics, evidencing the possible existence of distinct subdialects.</abstract>
    </paper>
    <paper id="13">
      <title>Enlarging Scarce In-domain <fixed-case>E</fixed-case>nglish-<fixed-case>C</fixed-case>roatian Corpus for <fixed-case>SMT</fixed-case> of <fixed-case>MOOC</fixed-case>s Using <fixed-case>S</fixed-case>erbian</title>
      <author><first>Maja</first> <last>Popović</last></author>
      <author><first>Kostadin</first> <last>Cholakov</last></author>
      <author><first>Valia</first> <last>Kordoni</last></author>
      <author><first>Nikola</first> <last>Ljubešić</last></author>
      <pages>97–105</pages>
      <url hash="2a7d8109">W16-4813</url>
      <abstract>Massive Open Online Courses have been growing rapidly in size and impact. Yet the language barrier constitutes a major growth impediment in reaching out all people and educating all citizens. A vast majority of educational material is available only in English, and state-of-the-art machine translation systems still have not been tailored for this peculiar genre. In addition, a mere collection of appropriate in-domain training material is a challenging task. In this work, we investigate statistical machine translation of lecture subtitles from English into Croatian, which is morphologically rich and generally weakly supported, especially for the educational domain. We show that results comparable with publicly available systems trained on much larger data can be achieved if a small in-domain training set is used in combination with additional in-domain corpus originating from the closely related Serbian language.</abstract>
    </paper>
    <paper id="14">
      <title><fixed-case>A</fixed-case>rabic Dialect Identification in Speech Transcripts</title>
      <author><first>Shervin</first> <last>Malmasi</last></author>
      <author><first>Marcos</first> <last>Zampieri</last></author>
      <pages>106–113</pages>
      <url hash="a131d41a">W16-4814</url>
      <abstract>In this paper we describe a system developed to identify a set of four regional Arabic dialects (Egyptian, Gulf, Levantine, North African) and Modern Standard Arabic (MSA) in a transcribed speech corpus. We competed under the team name MAZA in the Arabic Dialect Identification sub-task of the 2016 Discriminating between Similar Languages (DSL) shared task. Our system achieved an F1-score of 0.51 in the closed training track, ranking first among the 18 teams that participated in the sub-task. Our system utilizes a classifier ensemble with a set of linear models as base classifiers. We experimented with three different ensemble fusion strategies, with the mean probability approach providing the best performance.</abstract>
    </paper>
    <paper id="15">
      <title><fixed-case>DSL</fixed-case> Shared Task 2016: Perfect Is The Enemy of Good Language Discrimination Through Expectation–Maximization and Chunk-based Language Model</title>
      <author><first>Ondřej</first> <last>Herman</last></author>
      <author><first>Vít</first> <last>Suchomel</last></author>
      <author><first>Vít</first> <last>Baisa</last></author>
      <author><first>Pavel</first> <last>Rychlý</last></author>
      <pages>114–118</pages>
      <url hash="893bf5f7">W16-4815</url>
      <abstract>In this paper we investigate two approaches to discrimination of similar languages: Expectation–maximization algorithm for estimating conditional probability P(word|language) and byte level language models similar to compression-based language modelling methods. The accuracy of these methods reached respectively 86.6% and 88.3% on set A of the DSL Shared task 2016 competition.</abstract>
    </paper>
    <paper id="16">
      <title>Byte-based Language Identification with Deep Convolutional Networks</title>
      <author><first>Johannes</first> <last>Bjerva</last></author>
      <pages>119–125</pages>
      <url hash="6a1d99dc">W16-4816</url>
      <abstract>We report on our system for the shared task on discriminating between similar languages (DSL 2016). The system uses only byte representations in a deep residual network (ResNet). The system, named ResIdent, is trained only on the data released with the task (closed training). We obtain 84.88% accuracy on subtask A, 68.80% accuracy on subtask B1, and 69.80% accuracy on subtask B2. A large difference in accuracy on development data can be observed with relatively minor changes in our network’s architecture and hyperparameters. We therefore expect fine-tuning of these parameters to yield higher accuracies.</abstract>
    </paper>
    <paper id="17">
      <title>Classifying <fixed-case>ASR</fixed-case> Transcriptions According to <fixed-case>A</fixed-case>rabic Dialect</title>
      <author><first>Abualsoud</first> <last>Hanani</last></author>
      <author><first>Aziz</first> <last>Qaroush</last></author>
      <author><first>Stephen</first> <last>Taylor</last></author>
      <pages>126–134</pages>
      <url hash="7657f63f">W16-4817</url>
      <abstract>We describe several systems for identifying short samples of Arabic dialects. The systems were prepared for the shared task of the 2016 DSL Workshop. Our best system, an SVM using character tri-gram features, achieved an accuracy on the test data for the task of 0.4279, compared to a baseline of 0.20 for chance guesses or 0.2279 if we had always chosen the same most frequent class in the test set. This compares with the results of the team with the best weighted F1 score, which was an accuracy of 0.5117. The team entries seem to fall into cohorts, with all the teams in a cohort within a standard-deviation of each other, and our three entries are in the third cohort, which is about seven standard deviations from the top.</abstract>
    </paper>
    <paper id="18">
      <title><fixed-case>U</fixed-case>nibuc<fixed-case>K</fixed-case>ernel: An Approach for <fixed-case>A</fixed-case>rabic Dialect Identification Based on Multiple String Kernels</title>
      <author><first>Radu Tudor</first> <last>Ionescu</last></author>
      <author><first>Marius</first> <last>Popescu</last></author>
      <pages>135–144</pages>
      <url hash="f7c295f8">W16-4818</url>
      <abstract>The most common approach in text mining classification tasks is to rely on features like words, part-of-speech tags, stems, or some other high-level linguistic features. Unlike the common approach, we present a method that uses only character p-grams (also known as n-grams) as features for the Arabic Dialect Identification (ADI) Closed Shared Task of the DSL 2016 Challenge. The proposed approach combines several string kernels using multiple kernel learning. In the learning stage, we try both Kernel Discriminant Analysis (KDA) and Kernel Ridge Regression (KRR), and we choose KDA as it gives better results in a 10-fold cross-validation carried out on the training set. Our approach is shallow and simple, but the empirical results obtained in the ADI Shared Task prove that it achieves very good results. Indeed, we ranked on the second place with an accuracy of 50.91% and a weighted F1 score of 51.31%. We also present improved results in this paper, which we obtained after the competition ended. Simply by adding more regularization into our model to make it more suitable for test data that comes from a different distribution than training data, we obtain an accuracy of 51.82% and a weighted F1 score of 52.18%. Furthermore, the proposed approach has an important advantage in that it is language independent and linguistic theory neutral, as it does not require any NLP tools.</abstract>
    </paper>
    <paper id="19">
      <title>A Character-level Convolutional Neural Network for Distinguishing Similar Languages and Dialects</title>
      <author><first>Yonatan</first> <last>Belinkov</last></author>
      <author><first>James</first> <last>Glass</last></author>
      <pages>145–152</pages>
      <url hash="d2606bfa">W16-4819</url>
      <abstract>Discriminating between closely-related language varieties is considered a challenging and important task. This paper describes our submission to the DSL 2016 shared-task, which included two sub-tasks: one on discriminating similar languages and one on identifying Arabic dialects. We developed a character-level neural network for this task. Given a sequence of characters, our model embeds each character in vector space, runs the sequence through multiple convolutions with different filter widths, and pools the convolutional representations to obtain a hidden vector representation of the text that is used for predicting the language or dialect. We primarily focused on the Arabic dialect identification task and obtained an F1 score of 0.4834, ranking 6th out of 18 participants. We also analyze errors made by our system on the Arabic data in some detail, and point to challenges such an approach is faced with.</abstract>
    </paper>
    <paper id="20">
      <title><fixed-case>H</fixed-case>e<fixed-case>LI</fixed-case>, a Word-Based Backoff Method for Language Identification</title>
      <author><first>Tommi</first> <last>Jauhiainen</last></author>
      <author><first>Krister</first> <last>Lindén</last></author>
      <author><first>Heidi</first> <last>Jauhiainen</last></author>
      <pages>153–162</pages>
      <url hash="b31717b1">W16-4820</url>
      <abstract>In this paper we describe the Helsinki language identification method, HeLI, and the resources we created for and used in the 3rd edition of the Discriminating between Similar Languages (DSL) shared task, which was organized as part of the VarDial 2016 workshop. The shared task comprised of a total of 8 tracks, of which we participated in 7. The shared task had a record number of participants, with 17 teams providing results for the closed track of the test set A. Our system reached the 2nd position in 4 tracks (A closed and open, B1 open and B2 open) and in this paper we are focusing on the methods and data used for those tracks. We describe our word-based backoff method in mathematical notation. We also describe how we selected the corpus we used in the open tracks.</abstract>
    </paper>
    <paper id="21">
      <title><fixed-case>ASIREM</fixed-case> Participation at the Discriminating Similar Languages Shared Task 2016</title>
      <author><first>Wafia</first> <last>Adouane</last></author>
      <author><first>Nasredine</first> <last>Semmar</last></author>
      <author><first>Richard</first> <last>Johansson</last></author>
      <pages>163–169</pages>
      <url hash="4ec7414e">W16-4821</url>
      <abstract>This paper presents the system built by ASIREM team for the Discriminating between Similar Languages (DSL) Shared task 2016. It describes the system which uses character-based and word-based n-grams separately. ASIREM participated in both sub-tasks (sub-task 1 and sub-task 2) and in both open and closed tracks. For the sub-task 1 which deals with Discriminating between similar languages and national language varieties, the system achieved an accuracy of 87.79% on the closed track, ending up ninth (the best results being 89.38%). In sub-task 2, which deals with Arabic dialect identification, the system achieved its best performance using character-based n-grams (49.67% accuracy), ranking fourth in the closed track (the best result being 51.16%), and an accuracy of 53.18%, ranking first in the open track.</abstract>
    </paper>
    <paper id="22">
      <title>Comparing Two Basic Methods for Discriminating Between Similar Languages and Varieties</title>
      <author><first>Pablo</first> <last>Gamallo</last></author>
      <author><first>Iñaki</first> <last>Alegria</last></author>
      <author><first>José Ramom</first> <last>Pichel</last></author>
      <author><first>Manex</first> <last>Agirrezabal</last></author>
      <pages>170–177</pages>
      <url hash="dbb4e869">W16-4822</url>
      <abstract>This article describes the systems submitted by the Citius_Ixa_Imaxin team to the Discriminating Similar Languages Shared Task 2016. The systems are based on two different strategies: classification with ranked dictionaries and Naive Bayes classifiers. The results of the evaluation show that ranking dictionaries are more sound and stable across different domains while basic bayesian models perform reasonably well on in-domain datasets, but their performance drops when they are applied on out-of-domain texts.</abstract>
    </paper>
    <paper id="23">
      <title>Advances in Ngram-based Discrimination of Similar Languages</title>
      <author><first>Cyril</first> <last>Goutte</last></author>
      <author><first>Serge</first> <last>Léger</last></author>
      <pages>178–184</pages>
      <url hash="38475e22">W16-4823</url>
      <abstract>We describe the systems entered by the National Research Council in the 2016 shared task on discriminating similar languages. Like previous years, we relied on character ngram features, and a mixture of discriminative and generative statistical classifiers. We mostly investigated the influence of the amount of data on the performance, in the open task, and compared the two-stage approach (predicting language/group, then variant) to a flat approach. Results suggest that ngrams are still state-of-the-art for language and variant identification, and that additional data has a small but decisive impact.</abstract>
    </paper>
    <paper id="24">
      <title>Discrimination between Similar Languages, Varieties and Dialects using <fixed-case>CNN</fixed-case>- and <fixed-case>LSTM</fixed-case>-based Deep Neural Networks</title>
      <author><first>Chinnappa</first> <last>Guggilla</last></author>
      <pages>185–194</pages>
      <url hash="3e7862b0">W16-4824</url>
      <abstract>In this paper, we describe a system (CGLI) for discriminating similar languages, varieties and dialects using convolutional neural networks (CNNs) and long short-term memory (LSTM) neural networks. We have participated in the Arabic dialect identification sub-task of DSL 2016 shared task for distinguishing different Arabic language texts under closed submission track. Our proposed approach is language independent and works for discriminating any given set of languages, varieties, and dialects. We have obtained 43.29% weighted-F1 accuracy in this sub-task using CNN approach using default network parameters.</abstract>
    </paper>
    <paper id="25">
      <title>Language and Dialect Discrimination Using Compression-Inspired Language Models</title>
      <author><first>Paul</first> <last>McNamee</last></author>
      <pages>195–203</pages>
      <url hash="00d18809">W16-4825</url>
      <abstract>The DSL 2016 shared task continued previous evaluations from 2014 and 2015 that facilitated the study of automated language and dialect identification. This paper describes results for this year’s shared task and from several related experiments conducted at the Johns Hopkins University Human Language Technology Center of Excellence (JHU HLTCOE). Previously the HLTCOE has explored the use of compression-inspired language modeling for language and dialect identification, using news, Wikipedia, blog post, and Twitter corpora. The technique we have relied upon is based on prediction by partial matching (PPM), a state of the art text compression technique. Due to the close relationship between adaptive compression and language modeling, such compression techniques can also be applied to multi-way text classification problems, and previous studies have examined tasks such as authorship attribution, email spam detection, and topical classification. We applied our approach to the multi-class decision that considered each dialect or language as a possibility for the given shared task input line. Results for test-set A were in accord with our expectations, however results for test-sets B and C appear to be markedly worse. We had not anticipated the inclusion of multiple communications in differing languages in test-set B (social media) input lines, and had not expected the test-set C (dialectal Arabic) data to be represented phonetically instead of in native orthography.</abstract>
    </paper>
    <paper id="26">
      <title><fixed-case>A</fixed-case>rabic Language <fixed-case>WEKA</fixed-case>-Based Dialect Classifier for <fixed-case>A</fixed-case>rabic Automatic Speech Recognition Transcripts</title>
      <author><first>Areej</first> <last>Alshutayri</last></author>
      <author><first>Eric</first> <last>Atwell</last></author>
      <author><first>Abdulrahman</first> <last>Alosaimy</last></author>
      <author><first>James</first> <last>Dickins</last></author>
      <author><first>Michael</first> <last>Ingleby</last></author>
      <author><first>Janet</first> <last>Watson</last></author>
      <pages>204–211</pages>
      <url hash="3c016097">W16-4826</url>
      <abstract>This paper describes an Arabic dialect identification system which we developed for the Discriminating Similar Languages (DSL) 2016 shared task. We classified Arabic dialects by using Waikato Environment for Knowledge Analysis (WEKA) data analytic tool which contains many alternative filters and classifiers for machine learning. We experimented with several classifiers and the best accuracy was achieved using the Sequential Minimal Optimization (SMO) algorithm for training and testing process set to three different feature-sets for each testing process. Our approach achieved an accuracy equal to 42.85% which is considerably worse in comparison to the evaluation scores on the training set of 80-90% and with training set “60:40” percentage split which achieved accuracy around 50%. We observed that Buckwalter transcripts from the Saarland Automatic Speech Recognition (ASR) system are given without short vowels, though the Buckwalter system has notation for these. We elaborate such observations, describe our methods and analyse the training dataset.</abstract>
    </paper>
    <paper id="27">
      <title>An Unsupervised Morphological Criterion for Discriminating Similar Languages</title>
      <author><first>Adrien</first> <last>Barbaresi</last></author>
      <pages>212–220</pages>
      <url hash="7d260a80">W16-4827</url>
      <abstract>In this study conducted on the occasion of the Discriminating between Similar Languages shared task, I introduce an additional decision factor focusing on the token and subtoken level. The motivation behind this submission is to test whether a morphologically-informed criterion can add linguistically relevant information to global categorization and thus improve performance. The contributions of this paper are (1) a description of the unsupervised, low-resource method; (2) an evaluation and analysis of its raw performance; and (3) an assessment of its impact within a model comprising common indicators used in language identification. I present and discuss the systems used in the task A, a 12-way language identification task comprising varieties of five main language groups. Additionally I introduce a new off-the-shelf Naive Bayes classifier using a contrastive word and subword n-gram model (“Bayesline”) which outperforms the best submissions.</abstract>
    </paper>
    <paper id="28">
      <title><fixed-case>QCRI</fixed-case> @ <fixed-case>DSL</fixed-case> 2016: Spoken <fixed-case>A</fixed-case>rabic Dialect Identification Using Textual Features</title>
      <author><first>Mohamed</first> <last>Eldesouki</last></author>
      <author><first>Fahim</first> <last>Dalvi</last></author>
      <author><first>Hassan</first> <last>Sajjad</last></author>
      <author><first>Kareem</first> <last>Darwish</last></author>
      <pages>221–226</pages>
      <url hash="545c12ef">W16-4828</url>
      <abstract>The paper describes the QCRI submissions to the task of automatic Arabic dialect classification into 5 Arabic variants, namely Egyptian, Gulf, Levantine, North-African, and Modern Standard Arabic (MSA). The training data is relatively small and is automatically generated from an ASR system. To avoid over-fitting on such small data, we carefully selected and designed the features to capture the morphological essence of the different dialects. We submitted four runs to the Arabic sub-task. For all runs, we used a combined feature vector of character bi-grams, tri-grams, 4-grams, and 5-grams. We tried several machine-learning algorithms, namely Logistic Regression, Naive Bayes, Neural Networks, and Support Vector Machines (SVM) with linear and string kernels. However, our submitted runs used SVM with a linear kernel. In the closed submission, we got the best accuracy of 0.5136 and the third best weighted F1 score, with a difference less than 0.002 from the highest score.</abstract>
    </paper>
    <paper id="29">
      <title>Tuning <fixed-case>B</fixed-case>ayes Baseline for Dialect Detection</title>
      <author><first>Hector-Hugo</first> <last>Franco-Penya</last></author>
      <author><first>Liliana</first> <last>Mamani Sanchez</last></author>
      <pages>227–234</pages>
      <url hash="c3de7107">W16-4829</url>
      <abstract>This paper describes an analysis of our submissions to the Dialect Detection Shared Task 2016. We proposed three different systems that involved simplistic features, to name: a Naive-bayes system, a Support Vector Machines-based system and a Tree Kernel-based system. These systems underperform when compared to other submissions in this shared task, since the best one achieved an accuracy of ~0.834.</abstract>
    </paper>
    <paper id="30">
      <title>Vanilla Classifiers for Distinguishing between Similar Languages</title>
      <author><first>Sergiu</first> <last>Nisioi</last></author>
      <author><first>Alina Maria</first> <last>Ciobanu</last></author>
      <author><first>Liviu P.</first> <last>Dinu</last></author>
      <pages>235–242</pages>
      <url hash="d1bd2550">W16-4830</url>
      <abstract>In this paper we describe the submission of the UniBuc-NLP team for the Discriminating between Similar Languages Shared Task, DSL 2016. We present and analyze the results we obtained in the closed track of sub-task 1 (Similar languages and language varieties) and sub-task 2 (Arabic dialects). For sub-task 1 we used a logistic regression classifier with tf-idf feature weighting and for sub-task 2 a character-based string kernel with an SVM classifier. Our results show that good accuracy scores can be obtained with limited feature and model engineering. While certain limitations are to be acknowledged, our approach worked surprisingly well for out-of-domain, social media data, with 0.898 accuracy (3rd place) for dataset B1 and 0.838 accuracy (4th place) for dataset B2.</abstract>
    </paper>
    <paper id="31">
      <title>N-gram and Neural Language Models for Discriminating Similar Languages</title>
      <author><first>Andre</first> <last>Cianflone</last></author>
      <author><first>Leila</first> <last>Kosseim</last></author>
      <pages>243–250</pages>
      <url hash="20ea5454">W16-4831</url>
      <abstract>This paper describes our submission to the 2016 Discriminating Similar Languages (DSL) Shared Task. We participated in the closed Sub-task 1 with two separate machine learning techniques. The first approach is a character based Convolution Neural Network with an LSTM layer (CLSTM), which achieved an accuracy of 78.45% with minimal tuning. The second approach is a character-based n-gram model of size 7. It achieved an accuracy of 88.45% which is close to the accuracy of 89.38% achieved by the best submission.</abstract>
    </paper>
  </volume>
  <volume id="49">
    <meta>
      <booktitle>Proceedings of the 3rd Workshop on Natural Language Processing Techniques for Educational Applications (<fixed-case>NLPTEA</fixed-case>2016)</booktitle>
      <url hash="48222020">W16-49</url>
      <editor><first>Hsin-Hsi</first><last>Chen</last></editor>
      <editor><first>Yuen-Hsien</first><last>Tseng</last></editor>
      <editor><first>Vincent</first><last>Ng</last></editor>
      <editor><first>Xiaofei</first><last>Lu</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="e4faeb8a">W16-4900</url>
    </frontmatter>
    <paper id="1">
      <title>Simplification of Example Sentences for Learners of <fixed-case>J</fixed-case>apanese Functional Expressions</title>
      <author><first>Jun</first> <last>Liu</last></author>
      <author><first>Yuji</first> <last>Matsumoto</last></author>
      <pages>1–5</pages>
      <url hash="8a6165a6">W16-4901</url>
      <abstract>Learning functional expressions is one of the difficulties for language learners, since functional expressions tend to have multiple meanings and complicated usages in various situations. In this paper, we report an experiment of simplifying example sentences of Japanese functional expressions especially for Chinese-speaking learners. For this purpose, we developed “Japanese Functional Expressions List” and “Simple Japanese Replacement List”. To evaluate the method, we conduct a small-scale experiment with Chinese-speaking learners on the effectiveness of the simplified example sentences. The experimental results indicate that simplified sentences are helpful in learning Japanese functional expressions.</abstract>
    </paper>
    <paper id="2">
      <title>Effectiveness of Linguistic and Learner Features to Listenability Measurement Using a Decision Tree Classifier</title>
      <author><first>Katsunori</first> <last>Kotani</last></author>
      <author><first>Takehiko</first> <last>Yoshimi</last></author>
      <pages>6–10</pages>
      <url hash="d32fc194">W16-4902</url>
      <abstract>In learning Asian languages, learners encounter the problem of character types that are different from those in their first language, for instance, between Chinese characters and the Latin alphabet. This problem also affects listening because learners reconstruct letters from speech sounds. Hence, special attention should be paid to listening practice for learners of Asian languages. However, to our knowledge, few studies have evaluated the ease of listening comprehension (listenability) in Asian languages. Therefore, as a pilot study of listenability in Asian languages, we developed a measurement method for learners of English in order to examine the discriminability of linguistic and learner features. The results showed that the accuracy of our method outperformed a simple majority vote, which suggests that a combination of linguistic and learner features should be used to measure listenability in Asian languages as well as in English.</abstract>
    </paper>
    <paper id="3">
      <title>A Two-Phase Approach Towards Identifying Argument Structure in Natural Language</title>
      <author><first>Arkanath</first> <last>Pathak</last></author>
      <author><first>Pawan</first> <last>Goyal</last></author>
      <author><first>Plaban</first> <last>Bhowmick</last></author>
      <pages>11–19</pages>
      <url hash="50a032db">W16-4903</url>
      <abstract>We propose a new approach for extracting argument structure from natural language texts that contain an underlying argument. Our approach comprises of two phases: Score Assignment and Structure Prediction. The Score Assignment phase trains models to classify relations between argument units (Support, Attack or Neutral). To that end, different training strategies have been explored. We identify different linguistic and lexical features for training the classifiers. Through ablation study, we observe that our novel use of word-embedding features is most effective for this task. The Structure Prediction phase makes use of the scores from the Score Assignment phase to arrive at the optimal structure. We perform experiments on three argumentation datasets, namely, AraucariaDB, Debatepedia and Wikipedia. We also propose two baselines and observe that the proposed approach outperforms baseline systems for the final task of Structure Prediction.</abstract>
    </paper>
    <paper id="4">
      <title>Distributed Vector Representations for Unsupervised Automatic Short Answer Grading</title>
      <author><first>Oliver</first> <last>Adams</last></author>
      <author><first>Shourya</first> <last>Roy</last></author>
      <author><first>Raghuram</first> <last>Krishnapuram</last></author>
      <pages>20–29</pages>
      <url hash="0d6295f6">W16-4904</url>
      <abstract>We address the problem of automatic short answer grading, evaluating a collection of approaches inspired by recent advances in distributional text representations. In addition, we propose an unsupervised approach for determining text similarity using one-to-many alignment of word vectors. We evaluate the proposed technique across two datasets from different domains, namely, computer science and English reading comprehension, that additionally vary between highschool level and undergraduate students. Experiments demonstrate that the proposed technique often outperforms other compositional distributional semantics approaches as well as vector space methods such as latent semantic analysis. When combined with a scoring scheme, the proposed technique provides a powerful tool for tackling the complex problem of short answer grading. We also discuss a number of other key points worthy of consideration in preparing viable, easy-to-deploy automatic short-answer grading systems for the real-world.</abstract>
    </paper>
    <paper id="5">
      <title>A Comparison of Word Embeddings for <fixed-case>E</fixed-case>nglish and Cross-Lingual <fixed-case>C</fixed-case>hinese Word Sense Disambiguation</title>
      <author><first>Hong Jin</first> <last>Kang</last></author>
      <author><first>Tao</first> <last>Chen</last></author>
      <author><first>Muthu Kumar</first> <last>Chandrasekaran</last></author>
      <author><first>Min-Yen</first> <last>Kan</last></author>
      <pages>30–39</pages>
      <url hash="ce0ed74c">W16-4905</url>
      <abstract>Word embeddings are now ubiquitous forms of word representation in natural language processing. There have been applications of word embeddings for monolingual word sense disambiguation (WSD) in English, but few comparisons have been done. This paper attempts to bridge that gap by examining popular embeddings for the task of monolingual English WSD. Our simplified method leads to comparable state-of-the-art performance without expensive retraining. Cross-Lingual WSD – where the word senses of a word in a source language come from a separate target translation language – can also assist in language learning; for example, when providing translations of target vocabulary for learners. Thus we have also applied word embeddings to the novel task of cross-lingual WSD for Chinese and provide a public dataset for further benchmarking. We have also experimented with using word embeddings for LSTM networks and found surprisingly that a basic LSTM network does not work well. We discuss the ramifications of this outcome.</abstract>
    </paper>
    <paper id="6">
      <title>Overview of <fixed-case>NLP</fixed-case>-<fixed-case>TEA</fixed-case> 2016 Shared Task for <fixed-case>C</fixed-case>hinese Grammatical Error Diagnosis</title>
      <author><first>Lung-Hao</first> <last>Lee</last></author>
      <author><first>Gaoqi</first> <last>Rao</last></author>
      <author><first>Liang-Chih</first> <last>Yu</last></author>
      <author><first>Endong</first> <last>Xun</last></author>
      <author><first>Baolin</first> <last>Zhang</last></author>
      <author><first>Li-Ping</first> <last>Chang</last></author>
      <pages>40–48</pages>
      <url hash="b997a0ac">W16-4906</url>
      <abstract>This paper presents the NLP-TEA 2016 shared task for Chinese grammatical error diagnosis which seeks to identify grammatical error types and their range of occurrence within sentences written by learners of Chinese as foreign language. We describe the task definition, data preparation, performance metrics, and evaluation results. Of the 15 teams registered for this shared task, 9 teams developed the system and submitted a total of 36 runs. We expected this evaluation campaign could lead to the development of more advanced NLP techniques for educational applications, especially for Chinese error detection. All data sets with gold standards and scoring scripts are made publicly available to researchers.</abstract>
    </paper>
    <paper id="7">
      <title><fixed-case>C</fixed-case>hinese Grammatical Error Diagnosis with Long Short-Term Memory Networks</title>
      <author><first>Bo</first> <last>Zheng</last></author>
      <author><first>Wanxiang</first> <last>Che</last></author>
      <author><first>Jiang</first> <last>Guo</last></author>
      <author><first>Ting</first> <last>Liu</last></author>
      <pages>49–56</pages>
      <url hash="3bca82da">W16-4907</url>
      <abstract>Grammatical error diagnosis is an important task in natural language processing. This paper introduces our Chinese Grammatical Error Diagnosis (CGED) system in the NLP-TEA-3 shared task for CGED. The CGED system can diagnose four types of grammatical errors which are redundant words (R), missing words (M), bad word selection (S) and disordered words (W). We treat the CGED task as a sequence labeling task and describe three models, including a CRF-based model, an LSTM-based model and an ensemble model using stacking. We also show in details how we build and train the models. Evaluation includes three levels, which are detection level, identification level and position level. On the CGED-HSK dataset of NLP-TEA-3 shared task, our system presents the best F1-scores in all the three levels and also the best recall in the last two levels.</abstract>
    </paper>
    <paper id="8">
      <title>Automatic Grammatical Error Detection for <fixed-case>C</fixed-case>hinese based on Conditional Random Field</title>
      <author><first>Yajun</first> <last>Liu</last></author>
      <author><first>Yingjie</first> <last>Han</last></author>
      <author><first>Liyan</first> <last>Zhuo</last></author>
      <author><first>Hongying</first> <last>Zan</last></author>
      <pages>57–62</pages>
      <url hash="a269b4c8">W16-4908</url>
      <abstract>In the process of learning and using Chinese, foreigners may have grammatical errors due to negative migration of their native languages. Currently, the computer-oriented automatic detection method of grammatical errors is not mature enough. Based on the evaluating task — CGED2016, we select and analyze the classification model and design feature extraction method to obtain grammatical errors including Mission(M), Disorder(W), Selection (S) and Redundant (R) automatically. The experiment results based on the dynamic corpus of HSK show that the Chinese grammatical error automatic detection method, which uses CRF as classification model and n-gram as feature extraction method. It is simple and efficient which play a positive effect on the research of Chinese grammatical error automatic detection and also a supporting and guiding role in the teaching of Chinese as a foreign language.</abstract>
    </paper>
    <paper id="9">
      <title><fixed-case>CYUT</fixed-case>-<fixed-case>III</fixed-case> System at <fixed-case>C</fixed-case>hinese Grammatical Error Diagnosis Task</title>
      <author><first>Po-Lin</first> <last>Chen</last></author>
      <author><first>Shih-Hung</first> <last>Wu</last></author>
      <author><first>Liang-Pu</first> <last>Chen</last></author>
      <author><first>Ping-Che</first> <last>Yang</last></author>
      <pages>63–72</pages>
      <url hash="5882fa13">W16-4909</url>
      <abstract>This paper describe the CYUT-III system on grammar error detection in the 2016 NLP-TEA Chinese Grammar Error Detection shared task CGED. In this task a system has to detect four types of errors, in-cluding redundant word error, missing word error, word selection error and word ordering error. Based on the conditional random fields (CRF) model, our system is a linear tagger that can detect the errors in learners’ essays. Since the system performance depends on the features heavily, in this paper, we are going to report how to integrate the collocation feature into the CRF model. Our system presents the best detection accuracy and Identification accuracy on the TOCFL dataset, which is in traditional Chi-nese. The same system also works well on the simplified Chinese HSK dataset.</abstract>
    </paper>
    <paper id="10">
      <title>Word Order Sensitive Embedding Features/Conditional Random Field-based <fixed-case>C</fixed-case>hinese Grammatical Error Detection</title>
      <author><first>Wei-Chieh</first> <last>Chou</last></author>
      <author><first>Chin-Kui</first> <last>Lin</last></author>
      <author><first>Yuan-Fu</first> <last>Liao</last></author>
      <author><first>Yih-Ru</first> <last>Wang</last></author>
      <pages>73–81</pages>
      <url hash="b924daf4">W16-4910</url>
      <abstract>This paper discusses how to adapt two new word embedding features to build a more efficient Chinese Grammatical Error Diagnosis (CGED) systems to assist Chinese foreign learners (CFLs) in improving their written essays. The major idea is to apply word order sensitive Word2Vec approaches including (1) structured skip-gram and (2) continuous window (CWindow) models, because they are more suitable for solving syntax-based problems. The proposed new features were evaluated on the Test of Chinese as a Foreign Language (TOCFL) learner database provided by NLP-TEA-3&amp;CGED shared task. Experimental results showed that the new features did work better than the traditional word order insensitive Word2Vec approaches. Moreover, according to the official evaluation results, our system achieved the lowest (0.1362) false positive (FA) and the highest precision rates in all three measurements.</abstract>
    </paper>
    <paper id="11">
      <title>A Fluctuation Smoothing Approach for Unsupervised Automatic Short Answer Grading</title>
      <author><first>Shourya</first> <last>Roy</last></author>
      <author><first>Sandipan</first> <last>Dandapat</last></author>
      <author><first>Y.</first> <last>Narahari</last></author>
      <pages>82–91</pages>
      <url hash="c375667d">W16-4911</url>
      <abstract>We offer a fluctuation smoothing computational approach for unsupervised automatic short answer grading (ASAG) techniques in the educational ecosystem. A major drawback of the existing techniques is the significant effect that variations in model answers could have on their performances. The proposed fluctuation smoothing approach, based on classical sequential pattern mining, exploits lexical overlap in students’ answers to any typical question. We empirically demonstrate using multiple datasets that the proposed approach improves the overall performance and significantly reduces (up to 63%) variation in performance (standard deviation) of unsupervised ASAG techniques. We bring in additional benchmarks such as (a) paraphrasing of model answers and (b) using answers by k top performing students as model answers, to amplify the benefits of the proposed approach.</abstract>
    </paper>
    <paper id="12">
      <title><fixed-case>J</fixed-case>apanese Lexical Simplification for Non-Native Speakers</title>
      <author><first>Muhaimin</first> <last>Hading</last></author>
      <author><first>Yuji</first> <last>Matsumoto</last></author>
      <author><first>Maki</first> <last>Sakamoto</last></author>
      <pages>92–96</pages>
      <url hash="5c8961c7">W16-4912</url>
      <abstract>This paper introduces Japanese lexical simplification. Japanese lexical simplification is the task of replacing difficult words in a given sentence to produce a new sentence with simple words without changing the original meaning of the sentence. We purpose a method of supervised regression learning to estimate difficulty ordering of words with statistical features obtained from two types of Japanese corpora. For the similarity of words, we use a Japanese thesaurus and dependency-based word embeddings. Evaluation of the proposed method is performed by comparing the difficulty ordering of the words.</abstract>
    </paper>
    <paper id="13">
      <title>A Corpus-based Approach for <fixed-case>S</fixed-case>panish-<fixed-case>C</fixed-case>hinese Language Learning</title>
      <author><first>Shuyuan</first> <last>Cao</last></author>
      <author><first>Iria</first> <last>da Cunha</last></author>
      <author><first>Mikel</first> <last>Iruskieta</last></author>
      <pages>97–106</pages>
      <url hash="9a34ab99">W16-4913</url>
      <abstract>Due to the huge population that speaks Spanish and Chinese, these languages occupy an important position in the language learning studies. Although there are some automatic translation systems that benefit the learning of both languages, there is enough space to create resources in order to help language learners. As a quick and effective resource that can give large amount language information, corpus-based learning is becoming more and more popular. In this paper we enrich a Spanish-Chinese parallel corpus automatically with part of-speech (POS) information and manually with discourse segmentation (following the Rhetorical Structure Theory (RST) (Mann and Thompson, 1988)). Two search tools allow the Spanish-Chinese language learners to carry out different queries based on tokens and lemmas. The parallel corpus and the research tools are available to the academic community. We propose some examples to illustrate how learners can use the corpus to learn Spanish and Chinese.</abstract>
    </paper>
    <paper id="14">
      <title>Syntactic Well-Formedness Diagnosis and Error-Based Coaching in Computer Assisted Language Learning using Machine Translation</title>
      <author><first>Luis</first> <last>Morgado da Costa</last></author>
      <author><first>Francis</first> <last>Bond</last></author>
      <author><first>Xiaoling</first> <last>He</last></author>
      <pages>107–116</pages>
      <url hash="ffbd0e94">W16-4914</url>
      <abstract>We present a novel approach to Computer Assisted Language Learning (CALL), using deep syntactic parsers and semantic based machine translation (MT) in diagnosing and providing explicit feedback on language learners’ errors. We are currently developing a proof of concept system showing how semantic-based machine translation can, in conjunction with robust computational grammars, be used to interact with students, better understand their language errors, and help students correct their grammar through a series of useful feedback messages and guided language drills. Ultimately, we aim to prove the viability of a new integrated rule-based MT approach to disambiguate students’ intended meaning in a CALL system. This is a necessary step to provide accurate coaching on how to correct ungrammatical input, and it will allow us to overcome a current bottleneck in the field — an exponential burst of ambiguity caused by ambiguous lexical items (Flickinger, 2010). From the users’ interaction with the system, we will also produce a richly annotated Learner Corpus, annotated automatically with both syntactic and semantic information.</abstract>
    </paper>
    <paper id="15">
      <title>An Aligned <fixed-case>F</fixed-case>rench-<fixed-case>C</fixed-case>hinese corpus of 10<fixed-case>K</fixed-case> segments from university educational material</title>
      <author><first>Ruslan</first> <last>Kalitvianski</last></author>
      <author><first>Lingxiao</first> <last>Wang</last></author>
      <author><first>Valérie</first> <last>Bellynck</last></author>
      <author><first>Christian</first> <last>Boitet</last></author>
      <pages>117–121</pages>
      <url hash="3dea8738">W16-4915</url>
      <abstract>This paper describes a corpus of nearly 10K French-Chinese aligned segments, produced by post-editing machine translated computer science courseware. This corpus was built from 2013 to 2016 within the PROJECT_NAME project, by native Chinese students. The quality, as judged by native speakers, is ad-equate for understanding (far better than by reading only the original French) and for getting better marks. This corpus is annotated at segment-level by a self-assessed quality score. It has been directly used as supplemental training data to build a statistical machine translation system dedicated to that sublanguage, and can be used to extract the specific bilingual terminology. To our knowledge, it is the first corpus of this kind to be released.</abstract>
    </paper>
    <paper id="16">
      <title>Analysis of Foreign Language Teaching Methods: An Automatic Readability Approach</title>
      <author><first>Nasser</first> <last>Zalmout</last></author>
      <author><first>Hind</first> <last>Saddiki</last></author>
      <author><first>Nizar</first> <last>Habash</last></author>
      <pages>122–130</pages>
      <url hash="01650106">W16-4916</url>
      <abstract>Much research in education has been done on the study of different language teaching methods. However, there has been little investigation using computational analysis to compare such methods in terms of readability or complexity progression. In this paper, we make use of existing readability scoring techniques and our own classifiers to analyze the textbooks used in two very different teaching methods for English as a Second Language – the grammar-based and the communicative methods. Our analysis indicates that the grammar-based curriculum shows a more coherent readability progression compared to the communicative curriculum. This finding corroborates with the expectations about the differences between these two methods and validates our approach’s value in comparing different teaching methods quantitatively.</abstract>
    </paper>
    <paper id="17">
      <title>Generating and Scoring Correction Candidates in <fixed-case>C</fixed-case>hinese Grammatical Error Diagnosis</title>
      <author><first>Shao-Heng</first> <last>Chen</last></author>
      <author><first>Yu-Lin</first> <last>Tsai</last></author>
      <author><first>Chuan-Jie</first> <last>Lin</last></author>
      <pages>131–139</pages>
      <url hash="ab699d08">W16-4917</url>
      <abstract>Grammatical error diagnosis is an essential part in a language-learning tutoring system. Based on the data sets of Chinese grammar error detection tasks, we proposed a system which measures the likelihood of correction candidates generated by deleting or inserting characters or words, moving substrings to different positions, substituting prepositions with other prepositions, or substituting words with their synonyms or similar strings. Sentence likelihood is measured based on the frequencies of substrings from the space-removed version of Google n-grams. The evaluation on the training set shows that Missing-related and Selection-related candidate generation methods have promising performance. Our final system achieved a precision of 30.28% and a recall of 62.85% in the identification level evaluated on the test set.</abstract>
    </paper>
    <paper id="18">
      <title>Grammatical Error Detection Based on Machine Learning for <fixed-case>M</fixed-case>andarin as Second Language Learning</title>
      <author><first>Jui-Feng</first> <last>Yeh</last></author>
      <author><first>Tsung-Wei</first> <last>Hsu</last></author>
      <author><first>Chan-Kun</first> <last>Yeh</last></author>
      <pages>140–147</pages>
      <url hash="59a6edf9">W16-4918</url>
      <abstract>Mandarin is not simple language for foreigner. Even using Mandarin as the mother tongue, they have to spend more time to learn when they were child. The following issues are the reason why causes learning problem. First, the word is envolved by Hieroglyphic. So a character can express meanings independently, but become a word has another semantic. Second, the Mandarin’s grammars have flexible rule and special usage. Therefore, the common grammatical errors can classify to missing, redundant, selection and disorder. In this paper, we proposed the structure of the Recurrent Neural Networks using Long Short-term memory (RNN-LSTM). It can detect the error type from the foreign learner writing. The features based on the word vector and part-of-speech vector. In the test data found that our method in the detection level of recall better than the others, even as high as 0.9755. That is because we give the possibility of greater choice in detecting errors.</abstract>
    </paper>
    <paper id="19">
      <title><fixed-case>B</fixed-case>i-<fixed-case>LSTM</fixed-case> Neural Networks for <fixed-case>C</fixed-case>hinese Grammatical Error Diagnosis</title>
      <author><first>Shen</first> <last>Huang</last></author>
      <author><first>Houfeng</first> <last>Wang</last></author>
      <pages>148–154</pages>
      <url hash="a69afad5">W16-4919</url>
      <abstract>Grammatical Error Diagnosis for Chinese has always been a challenge for both foreign learners and NLP researchers, for the variousity of grammar and the flexibility of expression. In this paper, we present a model based on Bidirectional Long Short-Term Memory(Bi-LSTM) neural networks, which treats the task as a sequence labeling problem, so as to detect Chinese grammatical errors, to identify the error types and to locate the error positions. In the corpora of this year’s shared task, there can be multiple errors in a single offset of a sentence, to address which, we simutaneously train three Bi-LSTM models sharing word embeddings which label Missing, Redundant and Selection errors respectively. We regard word ordering error as a special kind of word selection error which is longer during training phase, and then separate them by length during testing phase. In NLP-TEA 3 shared task for Chinese Grammatical Error Diagnosis(CGED), Our system achieved relatively high F1 for all the three levels in the traditional Chinese track and for the detection level in the Simpified Chinese track.</abstract>
    </paper>
    <paper id="20">
      <title><fixed-case>C</fixed-case>hinese Grammatical Error Diagnosis Using Single Word Embedding</title>
      <author><first>Jinnan</first> <last>Yang</last></author>
      <author><first>Bo</first> <last>Peng</last></author>
      <author><first>Jin</first> <last>Wang</last></author>
      <author><first>Jixian</first> <last>Zhang</last></author>
      <author><first>Xuejie</first> <last>Zhang</last></author>
      <pages>155–161</pages>
      <url hash="7eedbf76">W16-4920</url>
      <abstract>Abstract Automatic grammatical error detection for Chinese has been a big challenge for NLP researchers. Due to the formal and strict grammar rules in Chinese, it is hard for foreign students to master Chinese. A computer-assisted learning tool which can automatically detect and correct Chinese grammatical errors is necessary for those foreign students. Some of the previous works have sought to identify Chinese grammatical errors using template- and learning-based methods. In contrast, this study introduced convolutional neural network (CNN) and long-short term memory (LSTM) for the shared task of Chinese Grammatical Error Diagnosis (CGED). Different from traditional word-based embedding, single word embedding was used as input of CNN and LSTM. The proposed single word embedding can capture both semantic and syntactic information to detect those four type grammatical error. In experimental evaluation, the recall and f1-score of our submitted results Run1 of the TOCFL testing data ranked the fourth place in all submissions in detection-level.</abstract>
    </paper>
  </volume>
  <volume id="50">
    <meta>
      <booktitle>Proceedings of the Workshop on Extra-Propositional Aspects of Meaning in Computational Linguistics (<fixed-case>E</fixed-case>x<fixed-case>P</fixed-case>ro<fixed-case>M</fixed-case>)</booktitle>
      <url hash="af98d295">W16-50</url>
      <editor><first>Eduardo</first><last>Blanco</last></editor>
      <editor><first>Roser</first><last>Morante</last></editor>
      <editor><first>Roser</first><last>Saurí</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="523f407a">W16-5000</url>
    </frontmatter>
    <paper id="1">
      <title>‘Who would have thought of that!’: A Hierarchical Topic Model for Extraction of Sarcasm-prevalent Topics and Sarcasm Detection</title>
      <author><first>Aditya</first> <last>Joshi</last></author>
      <author><first>Prayas</first> <last>Jain</last></author>
      <author><first>Pushpak</first> <last>Bhattacharyya</last></author>
      <author><first>Mark</first> <last>Carman</last></author>
      <pages>1–10</pages>
      <url hash="14a32262">W16-5001</url>
      <abstract>Topic Models have been reported to be beneficial for aspect-based sentiment analysis. This paper reports the first topic model for sarcasm detection, to the best of our knowledge. Designed on the basis of the intuition that sarcastic tweets are likely to have a mixture of words of both sentiments as against tweets with literal sentiment (either positive or negative), our hierarchical topic model discovers sarcasm-prevalent topics and topic-level sentiment. Using a dataset of tweets labeled using hashtags, the model estimates topic-level, and sentiment-level distributions. Our evaluation shows that topics such as ‘work’, ‘gun laws’, ‘weather’ are sarcasm-prevalent topics. Our model is also able to discover the mixture of sentiment-bearing words that exist in a text of a given sentiment-related label. Finally, we apply our model to predict sarcasm in tweets. We outperform two prior work based on statistical classifiers with specific features, by around 25%.</abstract>
    </paper>
    <paper id="2">
      <title>Detecting Uncertainty Cues in <fixed-case>H</fixed-case>ungarian Social Media Texts</title>
      <author><first>Veronika</first> <last>Vincze</last></author>
      <pages>11–21</pages>
      <url hash="2e0d4c3d">W16-5002</url>
      <abstract>In this paper, we aim at identifying uncertainty cues in Hungarian social media texts. We present our machine learning based uncertainty detector which is based on a rich features set including lexical, morphological, syntactic, semantic and discourse-based features, and we evaluate our system on a small set of manually annotated social media texts. We also carry out cross-domain and domain adaptation experiments using an annotated corpus of standard Hungarian texts and show that domain differences significantly affect machine learning. Furthermore, we argue that differences among uncertainty cue types may also affect the efficiency of uncertainty detection.</abstract>
    </paper>
    <paper id="3">
      <title>Detecting Level of Belief in <fixed-case>C</fixed-case>hinese and <fixed-case>S</fixed-case>panish</title>
      <author><first>Juan Pablo</first> <last>Colomer</last></author>
      <author><first>Keyu</first> <last>Lai</last></author>
      <author><first>Owen</first> <last>Rambow</last></author>
      <pages>22–30</pages>
      <url hash="fc4a0406">W16-5003</url>
      <abstract>There has been extensive work on detecting the level of committed belief (also known as “factuality”) that an author is expressing towards the propositions in his or her utterances. Previous work on English has revealed that this can be done as a sequence tagging task. In this paper, we investigate the same task for Chinese and Spanish, two very different languages from English and from each other.</abstract>
    </paper>
    <paper id="4">
      <title>Contradiction Detection for Rumorous Claims</title>
      <author><first>Piroska</first> <last>Lendvai</last></author>
      <author><first>Uwe</first> <last>Reichel</last></author>
      <pages>31–40</pages>
      <url hash="bc2f7dd2">W16-5004</url>
      <abstract>The utilization of social media material in journalistic workflows is increasing, demanding automated methods for the identification of mis- and disinformation. Since textual contradiction across social media posts can be a signal of rumorousness, we seek to model how claims in Twitter posts are being textually contradicted. We identify two different contexts in which contradiction emerges: its broader form can be observed across independently posted tweets and its more specific form in threaded conversations. We define how the two scenarios differ in terms of central elements of argumentation: claims and conversation structure. We design and evaluate models for the two scenarios uniformly as 3-way Recognizing Textual Entailment tasks in order to represent claims and conversation structure implicitly in a generic inference model, while previous studies used explicit or no representation of these properties. To address noisy text, our classifiers use simple similarity features derived from the string and part-of-speech level. Corpus statistics reveal distribution differences for these features in contradictory as opposed to non-contradictory tweet relations, and the classifiers yield state of the art performance.</abstract>
    </paper>
    <paper id="5">
      <title>Negation and Modality in Machine Translation</title>
      <author><first>Preslav</first> <last>Nakov</last></author>
      <pages>41</pages>
      <url hash="0d4af2e9">W16-5005</url>
      <abstract>Negation and modality are two important grammatical phenomena that have attracted recent research attention as they can contribute to extra-propositional meaning aspects, among with factuality, attribution, irony and sarcasm. These aspects go beyond analysis such as semantic role labeling, and modeling them is important as a step towards a higher level of language understanding, which is needed for practical applications such as sentiment analysis. In this talk, I will go beyond English, and I will discuss how negation and modality are expressed in other languages. I will also go beyond sentiment analysis and I will present some challenges that the two phenomena pose for machine translation (MT). In particular, I will demonstrate how contemporary MT systems fail on them, and I will discuss some possible solutions.</abstract>
    </paper>
    <paper id="6">
      <title>Problematic Cases in the Annotation of Negation in <fixed-case>S</fixed-case>panish</title>
      <author><first>Salud María</first> <last>Jiménez-Zafra</last></author>
      <author><first>Maite</first> <last>Martin</last></author>
      <author><first>L. Alfonso</first> <last>Ureña-López</last></author>
      <author><first>Toni</first> <last>Martí</last></author>
      <author><first>Mariona</first> <last>Taulé</last></author>
      <pages>42–48</pages>
      <url hash="7cd6c025">W16-5006</url>
      <abstract>This paper presents the main sources of disagreement found during the annotation of the Spanish SFU Review Corpus with negation (SFU ReviewSP -NEG). Negation detection is a challenge in most of the task related to NLP, so the availability of corpora annotated with this phenomenon is essential in order to advance in tasks related to this area. A thorough analysis of the problems found during the annotation could help in the study of this phenomenon.</abstract>
    </paper>
    <paper id="7">
      <title>Building a Dictionary of Affixal Negations</title>
      <author><first>Chantal</first> <last>van Son</last></author>
      <author><first>Emiel</first> <last>van Miltenburg</last></author>
      <author><first>Roser</first> <last>Morante</last></author>
      <pages>49–56</pages>
      <url hash="bae2a058">W16-5007</url>
      <abstract>This paper discusses the need for a dictionary of affixal negations and regular antonyms to facilitate their automatic detection in text. Without such a dictionary, affixal negations are very difficult to detect. In addition, we show that the set of affixal negations is not homogeneous, and that different NLP tasks may require different subsets. A dictionary can store the subtypes of affixal negations, making it possible to select a certain subset or to make inferences on the basis of these subtypes. We take a first step towards creating a negation dictionary by annotating all direct antonym pairs inWordNet using an existing typology of affixal negations. By highlighting some of the issues that were encountered in this annotation experiment, we hope to provide some insights into the necessary steps of building a negation dictionary.</abstract>
    </paper>
  </volume>
  <volume id="51">
    <meta>
      <booktitle>Proceedings of the Fifth Workshop on Building and Evaluating Resources for Biomedical Text Mining (<fixed-case>B</fixed-case>io<fixed-case>T</fixed-case>xt<fixed-case>M</fixed-case>2016)</booktitle>
      <url hash="dc9a51f6">W16-51</url>
      <editor><first>Sophia</first><last>Ananiadou</last></editor>
      <editor><first>Riza</first><last>Batista-Navarro</last></editor>
      <editor><first>Kevin Bretonnel</first><last>Cohen</last></editor>
      <editor><first>Dina</first><last>Demner-Fushman</last></editor>
      <editor><first>Paul</first><last>Thompson</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="2d62041e">W16-5100</url>
    </frontmatter>
    <paper id="1">
      <title>Cancer Hallmark Text Classification Using Convolutional Neural Networks</title>
      <author><first>Simon</first> <last>Baker</last></author>
      <author><first>Anna</first> <last>Korhonen</last></author>
      <author><first>Sampo</first> <last>Pyysalo</last></author>
      <pages>1–9</pages>
      <url hash="3fd50a45">W16-5101</url>
      <abstract>Methods based on deep learning approaches have recently achieved state-of-the-art performance in a range of machine learning tasks and are increasingly applied to natural language processing (NLP). Despite strong results in various established NLP tasks involving general domain texts, there is only limited work applying these models to biomedical NLP. In this paper, we consider a Convolutional Neural Network (CNN) approach to biomedical text classification. Evaluation using a recently introduced cancer domain dataset involving the categorization of documents according to the well-established hallmarks of cancer shows that a basic CNN model can achieve a level of performance competitive with a Support Vector Machine (SVM) trained using complex manually engineered features optimized to the task. We further show that simple modifications to the CNN hyperparameters, initialization, and training process allow the model to notably outperform the SVM, establishing a new state of the art result at this task. We make all of the resources and tools introduced in this study available under open licenses from <url>https://cambridgeltl.github.io/cancer-hallmark-cnn/</url>.
    </abstract>
    </paper>
    <paper id="2">
      <title>Learning Orthographic Features in Bi-directional <fixed-case>LSTM</fixed-case> for Biomedical Named Entity Recognition</title>
      <author><first>Nut</first> <last>Limsopatham</last></author>
      <author><first>Nigel</first> <last>Collier</last></author>
      <pages>10–19</pages>
      <url hash="004130f1">W16-5102</url>
      <abstract>End-to-end neural network models for named entity recognition (NER) have shown to achieve effective performances on general domain datasets (e.g. newswire), without requiring additional hand-crafted features. However, in biomedical domain, recent studies have shown that hand-engineered features (e.g. orthographic features) should be used to attain effective performance, due to the complexity of biomedical terminology (e.g. the use of acronyms and complex gene names). In this work, we propose a novel approach that allows a neural network model based on a long short-term memory (LSTM) to automatically learn orthographic features and incorporate them into a model for biomedical NER. Importantly, our bi-directional LSTM model learns and leverages orthographic features on an end-to-end basis. We evaluate our approach by comparing against existing neural network models for NER using three well-established biomedical datasets. Our experimental results show that the proposed approach consistently outperforms these strong baselines across all of the three datasets.</abstract>
    </paper>
    <paper id="3">
      <title>Building Content-driven Entity Networks for Scarce Scientific Literature using Content Information</title>
      <author><first>Reinald Kim</first> <last>Amplayo</last></author>
      <author><first>Min</first> <last>Song</last></author>
      <pages>20–29</pages>
      <url hash="0d79efb8">W16-5103</url>
      <abstract>This paper proposes several network construction methods for collections of scarce scientific literature data. We define scarcity as lacking in value and in volume. Instead of using the paper’s metadata to construct several kinds of scientific networks, we use the full texts of the articles and automatically extract the entities needed to construct the networks. Specifically, we present seven kinds of networks using the proposed construction methods: co-occurrence networks for author, keyword, and biological entities, and citation networks for author, keyword, biological, and topic entities. We show two case studies that applies our proposed methods: CADASIL, a rare yet the most common form of hereditary stroke disorder, and Metformin, the first-line medication to the type 2 diabetes treatment. We apply our proposed method to four different applications for evaluation: finding prolific authors, finding important bio-entities, finding meaningful keywords, and discovering influential topics. The results show that the co-occurrence and citation networks constructed using the proposed method outperforms the traditional-based networks. We also compare our proposed networks to traditional citation networks constructed using enough data and infer that even with the same amount of enough data, our methods perform comparably or better than the traditional methods.</abstract>
    </paper>
    <paper id="4">
      <title>Named Entity Recognition in <fixed-case>S</fixed-case>wedish Health Records with Character-Based Deep Bidirectional <fixed-case>LSTM</fixed-case>s</title>
      <author><first>Simon</first> <last>Almgren</last></author>
      <author><first>Sean</first> <last>Pavlov</last></author>
      <author><first>Olof</first> <last>Mogren</last></author>
      <pages>30–39</pages>
      <url hash="c2d53ea3">W16-5104</url>
      <abstract>We propose an approach for named entity recognition in medical data, using a character-based deep bidirectional recurrent neural network. Such models can learn features and patterns based on the character sequence, and are not limited to a fixed vocabulary. This makes them very well suited for the NER task in the medical domain. Our experimental evaluation shows promising results, with a 60% improvement in F 1 score over the baseline, and our system generalizes well between different datasets.</abstract>
    </paper>
    <paper id="5">
      <title>Entity-Supported Summarization of Biomedical Abstracts</title>
      <author><first>Frederik</first> <last>Schulze</last></author>
      <author><first>Mariana</first> <last>Neves</last></author>
      <pages>40–49</pages>
      <url hash="4285686f">W16-5105</url>
      <abstract>The increasing amount of biomedical information that is available for researchers and clinicians makes it harder to quickly find the right information. Automatic summarization of multiple texts can provide summaries specific to the user’s information needs. In this paper we look into the use named-entity recognition for graph-based summarization. We extend the LexRank algorithm with information about named entities and present EntityRank, a multi-document graph-based summarization algorithm that is solely based on named entities. We evaluate our system on a datasets of 1009 human written summaries provided by BioASQ and on 1974 gene summaries, fetched from the Entrez Gene database. The results show that the addition of named-entity information increases the performance of graph-based summarizers and that the EntityRank significantly outperforms the other methods with regard to the ROUGE measures.</abstract>
    </paper>
    <paper id="6">
      <title>Fully unsupervised low-dimensional representation of adverse drug reaction events through distributional semantics</title>
      <author><first>Alicia</first> <last>Pérez</last></author>
      <author><first>Arantza</first> <last>Casillas</last></author>
      <author><first>Koldo</first> <last>Gojenola</last></author>
      <pages>50–59</pages>
      <url hash="557dfa12">W16-5106</url>
      <abstract>Electronic health records show great variability since the same concept is often expressed with different terms, either scientific latin forms, common or lay variants and even vernacular naming. Deep learning enables distributional representation of terms in a vector-space, and therefore, related terms tend to be close in the vector space. Accordingly, embedding words through these vectors opens the way towards accounting for semantic relatedness through classical algebraic operations. In this work we propose a simple though efficient unsupervised characterization of Adverse Drug Reactions (ADRs). This approach exploits the embedding representation of the terms involved in candidate ADR events, that is, drug-disease entity pairs. In brief, the ADRs are represented as vectors that link the drug with the disease in their context through a recursive additive model. We discovered that a low-dimensional representation that makes use of the modulus and argument of the embedded representation of the ADR event shows correlation with the manually annotated class. Thus, it can be derived that this characterization results in to be beneficial for further classification tasks as predictive features.</abstract>
    </paper>
    <paper id="7">
      <title>A Dataset for <fixed-case>ICD</fixed-case>-10 Coding of Death Certificates: Creation and Usage</title>
      <author><first>Thomas</first> <last>Lavergne</last></author>
      <author><first>Aurélie</first> <last>Névéol</last></author>
      <author><first>Aude</first> <last>Robert</last></author>
      <author><first>Cyril</first> <last>Grouin</last></author>
      <author><first>Grégoire</first> <last>Rey</last></author>
      <author><first>Pierre</first> <last>Zweigenbaum</last></author>
      <pages>60–69</pages>
      <url hash="03f920b1">W16-5107</url>
      <abstract>Very few datasets have been released for the evaluation of diagnosis coding with the International Classification of Diseases, and only one so far in a language other than English. This paper describes a large-scale dataset prepared from French death certificates, and the problems which needed to be solved to turn it into a dataset suitable for the application of machine learning and natural language processing methods of ICD-10 coding. The dataset includes the free-text statements written by medical doctors, the associated meta-data, the human coder-assigned codes for each statement, as well as the statement segments which supported the coder’s decision for each code. The dataset comprises 93,694 death certificates totalling 276,103 statements and 377,677 ICD-10 code assignments (3,457 unique codes). It was made available for an international automated coding shared task, which attracted five participating teams. An extended version of the dataset will be used in a new edition of the shared task.</abstract>
    </paper>
    <paper id="8">
      <title>A Corpus of Tables in Full-Text Biomedical Research Publications</title>
      <author><first>Tatyana</first> <last>Shmanina</last></author>
      <author><first>Ingrid</first> <last>Zukerman</last></author>
      <author><first>Ai Lee</first> <last>Cheam</last></author>
      <author><first>Thomas</first> <last>Bochynek</last></author>
      <author><first>Lawrence</first> <last>Cavedon</last></author>
      <pages>70–79</pages>
      <url hash="d72a645c">W16-5108</url>
      <abstract>The development of text mining techniques for biomedical research literature has received increased attention in recent times. However, most of these techniques focus on prose, while much important biomedical data reside in tables. In this paper, we present a corpus created to serve as a gold standard for the development and evaluation of techniques for the automatic extraction of information from biomedical tables. We describe the guidelines used for corpus annotation and the manner in which they were developed. The high inter-annotator agreement achieved on the corpus, and the generic nature of our annotation approach, suggest that the developed guidelines can serve as a general framework for table annotation in biomedical and other scientific domains. The annotated corpus and the guidelines are available at <url>http://www.csse.monash.edu.au/research/umnl/data/index.shtml</url>.
    </abstract>
    </paper>
    <paper id="9">
      <title>Supervised classification of end-of-lines in clinical text with no manual annotation</title>
      <author><first>Pierre</first> <last>Zweigenbaum</last></author>
      <author><first>Cyril</first> <last>Grouin</last></author>
      <author><first>Thomas</first> <last>Lavergne</last></author>
      <pages>80–88</pages>
      <url hash="1443c210">W16-5109</url>
      <abstract>In some plain text documents, end-of-line marks may or may not mark the boundary of a text unit (e.g., of a paragraph). This vexing problem is likely to impact subsequent natural language processing components, but is seldom addressed in the literature. We propose a method which uses no manual annotation to classify whether end-of-lines must actually be seen as simple spaces (soft line breaks) or as true text unit boundaries. This method, which includes self-training and co-training steps based on token and line length features, achieves 0.943 F-measure on a corpus of short e-books with controlled format, F=0.904 on a random sample of 24 clinical texts with soft line breaks, and F=0.898 on a larger set of mixed clinical texts which may or may not contain soft line breaks, a fairly high value for a method with no manual annotation.</abstract>
    </paper>
    <paper id="10">
      <title><fixed-case>B</fixed-case>io<fixed-case>DCA</fixed-case> Identifier: A System for Automatic Identification of Discourse Connective and Arguments from Biomedical Text</title>
      <author><first>Sindhuja</first> <last>Gopalan</last></author>
      <author><first>Sobha</first> <last>Lalitha Devi</last></author>
      <pages>89–98</pages>
      <url hash="19956da3">W16-5110</url>
      <abstract>This paper describes a Natural language processing system developed for automatic identification of explicit connectives, its sense and arguments. Prior work has shown that the difference in usage of connectives across corpora affects the cross domain connective identification task negatively. Hence the development of domain specific discourse parser has become indispensable. Here, we present a corpus annotated with discourse relations on Medline abstracts. Kappa score is calculated to check the annotation quality of our corpus. The previous works on discourse analysis in bio-medical data have concentrated only on the identification of connectives and hence we have developed an end-end parser for connective and argument identification using Conditional Random Fields algorithm. The type and sub-type of the connective sense is also identified. The results obtained are encouraging.</abstract>
    </paper>
    <paper id="11">
      <title>Data, tools and resources for mining social media drug chatter</title>
      <author><first>Abeed</first> <last>Sarker</last></author>
      <author><first>Graciela</first> <last>Gonzalez</last></author>
      <pages>99–107</pages>
      <url hash="159f2c9e">W16-5111</url>
      <abstract>Social media has emerged into a crucial resource for obtaining population-based signals for various public health monitoring and surveillance tasks, such as pharmacovigilance. There is an abundance of knowledge hidden within social media data, and the volume is growing. Drug-related chatter on social media can include user-generated information that can provide insights into public health problems such as abuse, adverse reactions, long-term effects, and multi-drug interactions. Our objective in this paper is to present to the biomedical natural language processing, data science, and public health communities data sets (annotated and unannotated), tools and resources that we have collected and created from social media. The data we present was collected from Twitter using the generic and brand names of drugs as keywords, along with their common misspellings. Following the collection of the data, annotation guidelines were created over several iterations, which detail important aspects of social media data annotation and can be used by future researchers for developing similar data sets. The annotation guidelines were followed to prepare data sets for text classification, information extraction and normalization. In this paper, we discuss the preparation of these guidelines, outline the data sets prepared, and present an overview of our state-of-the-art systems for data collection, supervised classification, and information extraction. In addition to the development of supervised systems for classification and extraction, we developed and released unlabeled data and language models. We discuss the potential uses of these language models in data mining and the large volumes of unlabeled data from which they were generated. We believe that the summaries and repositories we present here of our data, annotation guidelines, models, and tools will be beneficial to the research community as a single-point entry for all these resources, and will promote further research in this area.</abstract>
    </paper>
    <paper id="12">
      <title>Detection of Text Reuse in <fixed-case>F</fixed-case>rench Medical Corpora</title>
      <author><first>Eva</first> <last>D’hondt</last></author>
      <author><first>Cyril</first> <last>Grouin</last></author>
      <author><first>Aurélie</first> <last>Névéol</last></author>
      <author><first>Efstathios</first> <last>Stamatatos</last></author>
      <author><first>Pierre</first> <last>Zweigenbaum</last></author>
      <pages>108–114</pages>
      <url hash="32dde83c">W16-5112</url>
      <abstract>Electronic Health Records (EHRs) are increasingly available in modern health care institutions either through the direct creation of electronic documents in hospitals’ health information systems, or through the digitization of historical paper records. Each EHR creation method yields the need for sophisticated text reuse detection tools in order to prepare the EHR collections for efficient secondary use relying on Natural Language Processing methods. Herein, we address the detection of two types of text reuse in French EHRs: 1) the detection of updated versions of the same document and 2) the detection of document duplicates that still bear surface differences due to OCR or de-identification processing. We present a robust text reuse detection method to automatically identify redundant document pairs in two French EHR corpora that achieves an overall macro F-measure of 0.68 and 0.60, respectively and correctly identifies all redundant document pairs of interest.</abstract>
    </paper>
    <paper id="13">
      <title>Negation Detection in Clinical Reports Written in <fixed-case>G</fixed-case>erman</title>
      <author><first>Viviana</first> <last>Cotik</last></author>
      <author><first>Roland</first> <last>Roller</last></author>
      <author><first>Feiyu</first> <last>Xu</last></author>
      <author><first>Hans</first> <last>Uszkoreit</last></author>
      <author><first>Klemens</first> <last>Budde</last></author>
      <author><first>Danilo</first> <last>Schmidt</last></author>
      <pages>115–124</pages>
      <url hash="2282e870">W16-5113</url>
      <abstract>An important subtask in clinical text mining tries to identify whether a clinical finding is expressed as present, absent or unsure in a text. This work presents a system for detecting mentions of clinical findings that are negated or just speculated. The system has been applied to two different types of German clinical texts: clinical notes and discharge summaries. Our approach is built on top of NegEx, a well known algorithm for identifying non-factive mentions of medical findings. In this work, we adjust a previous adaptation of NegEx to German and evaluate the system on our data to detect negation and speculation. The results are compared to a baseline algorithm and are analyzed for both types of clinical documents. Our system achieves an F1-Score above 0.9 on both types of reports.</abstract>
    </paper>
    <paper id="14">
      <title>Scoring Disease-Medication Associations using Advanced <fixed-case>NLP</fixed-case>, Machine Learning, and Multiple Content Sources</title>
      <author><first>Bharath</first> <last>Dandala</last></author>
      <author><first>Murthy</first> <last>Devarakonda</last></author>
      <author><first>Mihaela</first> <last>Bornea</last></author>
      <author><first>Christopher</first> <last>Nielson</last></author>
      <pages>125–133</pages>
      <url hash="7d409771">W16-5114</url>
      <abstract>Effective knowledge resources are critical for developing successful clinical decision support systems that alleviate the cognitive load on physicians in patient care. In this paper, we describe two new methods for building a knowledge resource of disease to medication associations. These methods use fundamentally different content and are based on advanced natural language processing and machine learning techniques. One method uses distributional semantics on large medical text, and the other uses data mining on a large number of patient records. The methods are evaluated using 25,379 unique disease-medication pairs extracted from 100 de-identified longitudinal patient records of a large multi-provider hospital system. We measured recall (R), precision (P), and F scores for positive and negative association prediction, along with coverage and accuracy. While individual methods performed well, a combined stacked classifier achieved the best performance, indicating the limitations and unique value of each resource and method. In predicting positive associations, the stacked combination significantly outperformed the baseline (a distant semi-supervised method on large medical text), achieving F scores of 0.75 versus 0.55 on the pairs seen in the patient records, and F scores of 0.69 and 0.35 on unique pairs.</abstract>
    </paper>
    <paper id="15">
      <title>Author Name Disambiguation in <fixed-case>MEDLINE</fixed-case> Based on Journal Descriptors and Semantic Types</title>
      <author><first>Dina</first> <last>Vishnyakova</last></author>
      <author><first>Raul</first> <last>Rodriguez-Esteban</last></author>
      <author><first>Khan</first> <last>Ozol</last></author>
      <author><first>Fabio</first> <last>Rinaldi</last></author>
      <pages>134–142</pages>
      <url hash="6e0c59ad">W16-5115</url>
      <abstract>Author name disambiguation (AND) in publication and citation resources is a well-known problem. Often, information about email address and other details in the affiliation is missing. In cases where such information is not available, identifying the authorship of publications becomes very challenging. Consequently, there have been attempts to resolve such cases by utilizing external resources as references. However, such external resources are heterogeneous and are not always reliable regarding the correctness of information. To solve the AND task, especially when information about an author is not complete we suggest the use of new features such as journal descriptors (JD) and semantic types (ST). The evaluation of different feature models shows that their inclusion has an impact equivalent to that of other important features such as email address. Using such features we show that our system outperforms the state of the art.</abstract>
    </paper>
  </volume>
  <volume id="52">
    <meta>
      <booktitle>Proceedings of the Third International Workshop on Worldwide Language Service Infrastructure and Second Workshop on Open Infrastructures and Analysis Frameworks for Human Language Technologies (<fixed-case>WLSI</fixed-case>/<fixed-case>OIAF</fixed-case>4<fixed-case>HLT</fixed-case>2016)</booktitle>
      <url hash="c36a257c">W16-52</url>
      <editor><first>Yohei</first><last>Murakami</last></editor>
      <editor><first>Donghui</first><last>Lin</last></editor>
      <editor><first>Nancy</first><last>Ide</last></editor>
      <editor><first>James</first><last>Pustejovsky</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="c1e3c6c2">W16-5200</url>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>K</fixed-case>athaa : <fixed-case>NLP</fixed-case> Systems as Edge-Labeled Directed Acyclic <fixed-case>M</fixed-case>ulti<fixed-case>G</fixed-case>raphs</title>
      <author><first>Sharada</first> <last>Mohanty</last></author>
      <author><first>Nehal J</first> <last>Wani</last></author>
      <author><first>Manish</first> <last>Srivastava</last></author>
      <author><first>Dipti</first> <last>Sharma</last></author>
      <pages>1–10</pages>
      <url hash="01b6cf7b">W16-5201</url>
      <abstract>We present Kathaa, an Open Source web-based Visual Programming Framework for Natural Language Processing (NLP) Systems. Kathaa supports the design, execution and analysis of complex NLP systems by visually connecting NLP components from an easily extensible Module Library. It models NLP systems an edge-labeled Directed Acyclic MultiGraph, and lets the user use publicly co-created modules in their own NLP applications irrespective of their technical proficiency in Natural Language Processing. Kathaa exposes an intuitive web based Interface for the users to interact with and modify complex NLP Systems; and a precise Module definition API to allow easy integration of new state of the art NLP components. Kathaa enables researchers to publish their services in a standardized format to enable the masses to use their services out of the box. The vision of this work is to pave the way for a system like Kathaa, to be the Lego blocks of NLP Research and Applications. As a practical use case we use Kathaa to visually implement the Sampark Hindi-Panjabi Machine Translation Pipeline and the Sampark Hindi-Urdu Machine Translation Pipeline, to demonstrate the fact that Kathaa can handle really complex NLP systems while still being intuitive for the end user.</abstract>
    </paper>
    <paper id="2">
      <title><fixed-case>LAPPS</fixed-case>/Galaxy: Current State and Next Steps</title>
      <author><first>Nancy</first> <last>Ide</last></author>
      <author><first>Keith</first> <last>Suderman</last></author>
      <author><first>Eric</first> <last>Nyberg</last></author>
      <author><first>James</first> <last>Pustejovsky</last></author>
      <author><first>Marc</first> <last>Verhagen</last></author>
      <pages>11–18</pages>
      <url hash="dfd18706">W16-5202</url>
      <abstract>The US National Science Foundation (NSF) SI2-funded LAPPS/Galaxy project has developed an open-source platform for enabling complex analyses while hiding complexities associated with underlying infrastructure, that can be accessed through a web interface, deployed on any Unix system, or run from the cloud. It provides sophisticated tool integration and history capabilities, a workflow system for building automated multi-step analyses, state-of-the-art evaluation capabilities, and facilities for sharing and publishing analyses. This paper describes the current facilities available in LAPPS/Galaxy and outlines the project’s ongoing activities to enhance the framework.</abstract>
    </paper>
    <paper id="3">
      <title>Automatic Analysis of Flaws in Pre-Trained <fixed-case>NLP</fixed-case> Models</title>
      <author><first>Richard</first> <last>Eckart de Castilho</last></author>
      <pages>19–27</pages>
      <url hash="d9e93056">W16-5203</url>
      <abstract>Most tools for natural language processing today are based on machine learning and come with pre-trained models. In addition, third-parties provide pre-trained models for popular NLP tools. The predictive power and accuracy of these tools depends on the quality of these models. Downstream researchers often base their results on pre-trained models instead of training their own. Consequently, pre-trained models are an essential resource to our community. However, to be best of our knowledge, no systematic study of pre-trained models has been conducted so far. This paper reports on the analysis of 274 pre-models for six NLP tools and four potential causes of problems: encoding, tokenization, normalization and change over time. The analysis is implemented in the open source tool Model Investigator. Our work 1) allows model consumers to better assess whether a model is suitable for their task, 2) enables tool and model creators to sanity-check their models before distributing them, and 3) enables improvements in tool interoperability by performing automatic adjustments of normalization or other pre-processing based on the models used.</abstract>
    </paper>
    <paper id="4">
      <title>Combining Human Inputters and Language Services to provide Multi-language support system for International Symposiums</title>
      <author><first>Takao</first> <last>Nakaguchi</last></author>
      <author><first>Masayuki</first> <last>Otani</last></author>
      <author><first>Toshiyuki</first> <last>Takasaki</last></author>
      <author><first>Toru</first> <last>Ishida</last></author>
      <pages>28–35</pages>
      <url hash="88ea5a04">W16-5204</url>
      <abstract>In this research, we introduce and implement a method that combines human inputters and machine translators. When the languages of the participants vary widely, the cost of simultaneous translation becomes very high. However, the results of simply applying machine translation to speech text do not have the quality that is needed for real use. Thus, we propose a method that people who understand the language of the speaker cooperate with a machine translation service in support of multilingualization by the co-creation of value. We implement a system with this method and apply it to actual presentations. While the quality of direct machine translations is 1.84 (fluency) and 2.89 (adequacy), the system has corresponding values of 3.76 and 3.85.</abstract>
    </paper>
    <paper id="5">
      <title>Recurrent Neural Network with Word Embedding for Complaint Classification</title>
      <author><first>Panuwat</first> <last>Assawinjaipetch</last></author>
      <author><first>Kiyoaki</first> <last>Shirai</last></author>
      <author><first>Virach</first> <last>Sornlertlamvanich</last></author>
      <author><first>Sanparith</first> <last>Marukata</last></author>
      <pages>36–43</pages>
      <url hash="f75f5383">W16-5205</url>
      <abstract>Complaint classification aims at using information to deliver greater insights to enhance user experience after purchasing the products or services. Categorized information can help us quickly collect emerging problems in order to provide a support needed. Indeed, the response to the complaint without the delay will grant users highest satisfaction. In this paper, we aim to deliver a novel approach which can clarify the complaints precisely with the aim to classify each complaint into nine predefined classes i.e. acces-sibility, company brand, competitors, facilities, process, product feature, staff quality, timing respec-tively and others. Given the idea that one word usually conveys ambiguity and it has to be interpreted by its context, the word embedding technique is used to provide word features while applying deep learning techniques for classifying a type of complaints. The dataset we use contains 8,439 complaints of one company.</abstract>
    </paper>
    <paper id="6">
      <title>Universal dependencies for <fixed-case>U</fixed-case>yghur</title>
      <author><first>Marhaba</first> <last>Eli</last></author>
      <author><first>Weinila</first> <last>Mushajiang</last></author>
      <author><first>Tuergen</first> <last>Yibulayin</last></author>
      <author><first>Kahaerjiang</first> <last>Abiderexiti</last></author>
      <author><first>Yan</first> <last>Liu</last></author>
      <pages>44–50</pages>
      <url hash="8de1e18d">W16-5206</url>
      <abstract>The Universal Dependencies (UD) Project seeks to build a cross-lingual studies of treebanks, linguistic structures and parsing. Its goal is to create a set of multilingual harmonized treebanks that are designed according to a universal annotation scheme. In this paper, we report on the conversion of the Uyghur dependency treebank to a UD version of the treebank which we term the Uyghur Universal Dependency Treebank (UyDT). We present the mapping of the Uyghur dependency treebank’s labelling scheme to the UD scheme, along with a clear description of the structural changes required in this conversion.</abstract>
    </paper>
    <paper id="7">
      <title>A non-expert <fixed-case>K</fixed-case>aldi recipe for <fixed-case>V</fixed-case>ietnamese Speech Recognition System</title>
      <author><first>Hieu-Thi</first> <last>Luong</last></author>
      <author><first>Hai-Quan</first> <last>Vu</last></author>
      <pages>51–55</pages>
      <url hash="f2b1353d">W16-5207</url>
      <abstract>In this paper we describe a non-expert setup for Vietnamese speech recognition system using Kaldi toolkit. We collected a speech corpus over fifteen hours from about fifty Vietnamese native speakers and using it to test the feasibility of our setup. The essential linguistic components for the Automatic Speech Recognition (ASR) system was prepared basing on the written form of the language instead of expertise knowledge on linguistic and phonology as commonly seen in rich resource languages like English. The modeling of tones by integrating them into the phoneme and using the phonetic decision tree is also discussed. Experimental results showed this setup for ASR systems does yield competitive results while still have potentials for further improvements.</abstract>
    </paper>
    <paper id="8">
      <title>Evaluating Ensemble Based Pre-annotation on Named Entity Corpus Construction in <fixed-case>E</fixed-case>nglish and <fixed-case>C</fixed-case>hinese</title>
      <author><first>Tingming</first> <last>Lu</last></author>
      <author><first>Man</first> <last>Zhu</last></author>
      <author><first>Zhiqiang</first> <last>Gao</last></author>
      <author><first>Yaocheng</first> <last>Gui</last></author>
      <pages>56–60</pages>
      <url hash="9927dcfb">W16-5208</url>
      <abstract>Annotated corpora are crucial language resources, and pre-annotation is an usual way to reduce the cost of corpus construction. Ensemble based pre-annotation approach combines multiple existing named entity taggers and categorizes annotations into normal annotations with high confidence and candidate annotations with low confidence, to reduce the human annotation time. In this paper, we manually annotate three English datasets under various pre-annotation conditions, report the effects of ensemble based pre-annotation, and analyze the experimental results. In order to verify the effectiveness of ensemble based pre-annotation in other languages, such as Chinese, three Chinese datasets are also tested. The experimental results show that the ensemble based pre-annotation approach significantly reduces the number of annotations which human annotators have to add, and outperforms the baseline approaches in reduction of human annotation time without loss in annotation performance (in terms of F1-measure), on both English and Chinese datasets.</abstract>
    </paper>
    <paper id="9">
      <title>An Ontology for Language Service Composability</title>
      <author><first>Yohei</first> <last>Murakami</last></author>
      <author><first>Takao</first> <last>Nakaguchi</last></author>
      <author><first>Donghui</first> <last>Lin</last></author>
      <author><first>Toru</first> <last>Ishida</last></author>
      <pages>61–69</pages>
      <url hash="dcc1af4d">W16-5209</url>
      <abstract>Fragmentation and recombination is a key to create customized language environments for supporting various intercultural activities. Fragmentation provides various language resource components for the customized language environments and recombination builds each language environment according to user’s request by combining these components. To realize this fragmentation and recombination process, existing language resources (both data and programs) should be shared as language services and combined beyond mismatch of their service interfaces. To address this issue, standardization is inevitable: standardized interfaces are necessary for language services as well as data format required for language resources. Therefore, we have constructed a hierarchy of language services based on inheritance of service interfaces, which is called language service ontology. This ontology allows users to create a new customized language service that is compatible with existing ones. Moreover, we have developed a dynamic service binding technology that instantiates various executable customized services from an abstract workflow according to user’s request. By using the ontology and service binding together, users can bind the instantiated language service to another abstract workflow for a new customized one.</abstract>
    </paper>
    <paper id="10">
      <title>Between Platform and <fixed-case>API</fixed-case>s: <fixed-case>K</fixed-case>achako <fixed-case>API</fixed-case> for Developers</title>
      <author><first>Yoshinobu</first> <last>Kano</last></author>
      <pages>70–75</pages>
      <url hash="44b63b7c">W16-5210</url>
      <abstract>Different types of users require different functions in NLP software. It is difficult for a single platform to cover all types of users. When a framework aims to provide more interoperability, users are required to learn more concepts; users’ application designs are restricted to be compliant with the framework. While an interoperability framework is useful in certain cases, some types of users will not select the framework due to the learning cost and design restrictions. We suggest a rather simple framework for the interoperability aiming at developers. Reusing an existing NLP platform Kachako, we created an API oriented NLP system. This system loosely couples rich high-end functions, including annotation visualizations, statistical evaluations, an-notation searching, etc. This API do not require users much learning cost, providing customization ability for power users while also allowing easy users to employ many GUI functions.</abstract>
    </paper>
  </volume>
  <volume id="53">
    <meta>
      <booktitle>Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (<fixed-case>C</fixed-case>og<fixed-case>AL</fixed-case>ex - V)</booktitle>
      <url hash="015cecca">W16-53</url>
      <editor><first>Michael</first><last>Zock</last></editor>
      <editor><first>Alessandro</first><last>Lenci</last></editor>
      <editor><first>Stefan</first><last>Evert</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="701d6b67">W16-5300</url>
    </frontmatter>
    <paper id="1">
      <title>Vectors or Graphs? On Differences of Representations for Distributional Semantic Models</title>
      <author><first>Chris</first> <last>Biemann</last></author>
      <pages>1–7</pages>
      <url hash="900780d5">W16-5301</url>
      <abstract>Distributional Semantic Models (DSMs) have recently received increased attention, together with the rise of neural architectures for scalable training of dense vector embeddings. While some of the literature even includes terms like ‘vectors’ and ‘dimensionality’ in the definition of DSMs, there are some good reasons why we should consider alternative formulations of distributional models. As an instance, I present a scalable graph-based solution to distributional semantics. The model belongs to the family of ‘count-based’ DSMs, keeps its representation sparse and explicit, and thus fully interpretable. I will highlight some important differences between sparse graph-based and dense vector approaches to DSMs: while dense vector-based models are computationally easier to handle and provide a nice uniform representation that can be compared and combined in many ways, they lack interpretability, provenance and robustness. On the other hand, graph-based sparse models have a more straightforward interpretation, handle sense distinctions more naturally and can straightforwardly be linked to knowledge bases, while lacking the ability to compare arbitrary lexical units and a compositionality operation. Since both representations have their merits, I opt for exploring their combination in the outlook.</abstract>
    </paper>
    <paper id="2">
      <title>“Beware the Jabberwock, dear reader!” Testing the distributional reality of construction semantics</title>
      <author><first>Gianluca</first> <last>Lebani</last></author>
      <author><first>Alessandro</first> <last>Lenci</last></author>
      <pages>8–18</pages>
      <url hash="68e7434c">W16-5302</url>
      <abstract>Notwithstanding the success of the notion of construction, the computational tradition still lacks a way to represent the semantic content of these linguistic entities. Here we present a simple corpus-based model implementing the idea that the meaning of a syntactic construction is intimately related to the semantics of its typical verbs. It is a two-step process, that starts by identifying the typical verbs occurring with a given syntactic construction and building their distributional vectors. We then calculated the weighted centroid of these vectors in order to derive the distributional signature of a construction. In order to assess the goodness of our approach, we replicated the priming effect described by Johnson and Golberg (2013) as a function of the semantic distance between a construction and its prototypical verbs. Additional support for our view comes from a regression analysis showing that our distributional information can be used to model behavioral data collected with a crowdsourced elicitation experiment.</abstract>
    </paper>
    <paper id="3">
      <title>Regular polysemy: from sense vectors to sense patterns</title>
      <author><first>Anastasiya</first> <last>Lopukhina</last></author>
      <author><first>Konstantin</first> <last>Lopukhin</last></author>
      <pages>19–23</pages>
      <url hash="0f69f5be">W16-5303</url>
      <abstract>Regular polysemy was extensively investigated in lexical semantics, but this phenomenon has been very little studied in distributional semantics. We propose a model for regular polysemy detection that is based on sense vectors and allows to work directly with senses in semantic vector space. Our method is able to detect polysemous words that have the same regular sense alternation as in a given example (a word with two automatically induced senses that represent one polysemy pattern, such as ANIMAL / FOOD). The method works equally well for nouns, verbs and adjectives and achieves average recall of 0.55 and average precision of 0.59 for ten different polysemy patterns.</abstract>
    </paper>
    <paper id="4">
      <title>Path-based vs. Distributional Information in Recognizing Lexical Semantic Relations</title>
      <author><first>Vered</first> <last>Shwartz</last></author>
      <author><first>Ido</first> <last>Dagan</last></author>
      <pages>24–29</pages>
      <url hash="1b85aff4">W16-5304</url>
      <abstract>Recognizing various semantic relations between terms is beneficial for many NLP tasks. While path-based and distributional information sources are considered complementary for this task, the superior results the latter showed recently suggested that the former’s contribution might have become obsolete. We follow the recent success of an integrated neural method for hypernymy detection (Shwartz et al., 2016) and extend it to recognize multiple relations. The empirical results show that this method is effective in the multiclass setting as well. We further show that the path-based information source always contributes to the classification, and analyze the cases in which it mostly complements the distributional information.</abstract>
    </paper>
    <paper id="5">
      <title>Semantic Relation Classification: Task Formalisation and Refinement</title>
      <author><first>Vivian</first> <last>Santos</last></author>
      <author><first>Manuela</first> <last>Huerliman</last></author>
      <author><first>Brian</first> <last>Davis</last></author>
      <author><first>Siegfried</first> <last>Handschuh</last></author>
      <author><first>André</first> <last>Freitas</last></author>
      <pages>30–39</pages>
      <url hash="72f932c8">W16-5305</url>
      <abstract>The identification of semantic relations between terms within texts is a fundamental task in Natural Language Processing which can support applications requiring a lightweight semantic interpretation model. Currently, semantic relation classification concentrates on relations which are evaluated over open-domain data. This work provides a critique on the set of abstract relations used for semantic relation classification with regard to their ability to express relationships between terms which are found in a domain-specific corpora. Based on this analysis, this work proposes an alternative semantic relation model based on reusing and extending the set of abstract relations present in the DOLCE ontology. The resulting set of relations is well grounded, allows to capture a wide range of relations and could thus be used as a foundation for automatic classification of semantic relations.</abstract>
    </paper>
    <paper id="6">
      <title>The Power of Language Music: <fixed-case>A</fixed-case>rabic Lemmatization through Patterns</title>
      <author><first>Mohammed</first> <last>Attia</last></author>
      <author><first>Ayah</first> <last>Zirikly</last></author>
      <author><first>Mona</first> <last>Diab</last></author>
      <pages>40–50</pages>
      <url hash="f50305ee">W16-5306</url>
      <abstract>The interaction between roots and patterns in Arabic has intrigued lexicographers and morphologists for centuries. While roots provide the consonantal building blocks, patterns provide the syllabic vocalic moulds. While roots provide abstract semantic classes, patterns realize these classes in specific instances. In this way both roots and patterns are indispensable for understanding the derivational, morphological and, to some extent, the cognitive aspects of the Arabic language. In this paper we perform lemmatization (a high-level lexical processing) without relying on a lookup dictionary. We use a hybrid approach that consists of a machine learning classifier to predict the lemma pattern for a given stem, and mapping rules to convert stems to their respective lemmas with the vocalization defined by the pattern.</abstract>
    </paper>
    <paper id="7">
      <title>Word Sense Disambiguation using a Bidirectional <fixed-case>LSTM</fixed-case></title>
      <author><first>Mikael</first> <last>Kågebäck</last></author>
      <author><first>Hans</first> <last>Salomonsson</last></author>
      <pages>51–56</pages>
      <url hash="1a625c5b">W16-5307</url>
      <abstract>In this paper we present a clean, yet effective, model for word sense disambiguation. Our approach leverage a bidirectional long short-term memory network which is shared between all words. This enables the model to share statistical strength and to scale well with vocabulary size. The model is trained end-to-end, directly from the raw text to sense labels, and makes effective use of word order. We evaluate our approach on two standard datasets, using identical hyperparameter settings, which are in turn tuned on a third set of held out data. We employ no external resources (e.g. knowledge graphs, part-of-speech tagging, etc), language specific features, or hand crafted rules, but still achieve statistically equivalent results to the best state-of-the-art systems, that employ no such limitations.</abstract>
    </paper>
    <paper id="8">
      <title>Towards a resource based on users’ knowledge to overcome the Tip of the Tongue problem.</title>
      <author><first>Michael</first> <last>Zock</last></author>
      <author><first>Chris</first> <last>Biemann</last></author>
      <pages>57–68</pages>
      <url hash="8f06cce1">W16-5308</url>
      <abstract>Language production is largely a matter of words which, in the case of access problems, can be searched for in an external resource (lexicon, thesaurus). In this kind of dialogue the user provides the momentarily available knowledge concerning the target and the system responds with the best guess(es) it can make given this input. As tip-of-the-tongue (ToT)-studies have shown, people always have some knowledge concerning the target (meaning fragments, number of syllables, ...) even if its complete form is eluding them. We will show here how to tap on this knowledge to build a resource likely to help authors (speakers/writers) to overcome the ToT-problem. Yet, before doing so we need a better understanding of the various kinds of knowledge people have when looking for a word. To this end, we asked crowdworkers to provide some cues to describe a given target and to specify then how each one of them relates to the target, in the hope that this could help others to find the elusive word. Next, we checked how well a given search strategy worked when being applied to differently built lexical networks. The results showed quite dramatic differences, which is not really surprising. After all, different networks are built for different purposes; hence each one of them is more or less suited for a given task. What was more surprising though is the fact that the relational information given by the users did not allow us to find the elusive word in WordNet better than without it.</abstract>
    </paper>
    <paper id="9">
      <title>The <fixed-case>C</fixed-case>og<fixed-case>AL</fixed-case>ex-<fixed-case>V</fixed-case> Shared Task on the Corpus-Based Identification of Semantic Relations</title>
      <author><first>Enrico</first> <last>Santus</last></author>
      <author><first>Anna</first> <last>Gladkova</last></author>
      <author><first>Stefan</first> <last>Evert</last></author>
      <author><first>Alessandro</first> <last>Lenci</last></author>
      <pages>69–79</pages>
      <url hash="1fc4a9a2">W16-5309</url>
      <abstract>The shared task of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex-V) aims at providing a common benchmark for testing current corpus-based methods for the identification of lexical semantic relations (synonymy, antonymy, hypernymy, part-whole meronymy) and at gaining a better understanding of their respective strengths and weaknesses. The shared task uses a challenging dataset extracted from EVALution 1.0, which contains word pairs holding the above-mentioned relations as well as semantically unrelated control items (random). The task is split into two subtasks: (i) identification of related word pairs vs. unrelated ones; (ii) classification of the word pairs according to their semantic relation. This paper describes the subtasks, the dataset, the evaluation metrics, the seven participating systems and their results. The best performing system in subtask 1 is GHHH (F1 = 0.790), while the best system in subtask 2 is LexNet (F1 = 0.445). The dataset and the task description are available at <url>https://sites.google.com/site/cogalex2016/home/shared-task</url>.
    </abstract>
    </paper>
    <paper id="10">
      <title><fixed-case>C</fixed-case>og<fixed-case>AL</fixed-case>ex-<fixed-case>V</fixed-case> Shared Task: <fixed-case>L</fixed-case>ex<fixed-case>NET</fixed-case> - Integrated Path-based and Distributional Method for the Identification of Semantic Relations</title>
      <author><first>Vered</first> <last>Shwartz</last></author>
      <author><first>Ido</first> <last>Dagan</last></author>
      <pages>80–85</pages>
      <url hash="59ae2ea7">W16-5310</url>
      <abstract>We present a submission to the CogALex 2016 shared task on the corpus-based identification of semantic relations, using LexNET (Shwartz and Dagan, 2016), an integrated path-based and distributional method for semantic relation classification. The reported results in the shared task bring this submission to the third place on subtask 1 (word relatedness), and the first place on subtask 2 (semantic relation classification), demonstrating the utility of integrating the complementary path-based and distributional information sources in recognizing concrete semantic relations. Combined with a common similarity measure, LexNET performs fairly good on the word relatedness task (subtask 1). The relatively low performance of LexNET and all other systems on subtask 2, however, confirms the difficulty of the semantic relation classification task, and stresses the need to develop additional methods for this task.</abstract>
    </paper>
    <paper id="11">
      <title><fixed-case>C</fixed-case>og<fixed-case>AL</fixed-case>ex-<fixed-case>V</fixed-case> Shared Task: <fixed-case>GHHH</fixed-case> - Detecting Semantic Relations via Word Embeddings</title>
      <author><first>Mohammed</first> <last>Attia</last></author>
      <author><first>Suraj</first> <last>Maharjan</last></author>
      <author><first>Younes</first> <last>Samih</last></author>
      <author><first>Laura</first> <last>Kallmeyer</last></author>
      <author><first>Thamar</first> <last>Solorio</last></author>
      <pages>86–91</pages>
      <url hash="2d110fe1">W16-5311</url>
      <abstract>This paper describes our system submission to the CogALex-2016 Shared Task on Corpus-Based Identification of Semantic Relations. Our system won first place for Task-1 and second place for Task-2. The evaluation results of our system on the test set is 88.1% (79.0% for TRUE only) f-measure for Task-1 on detecting semantic similarity, and 76.0% (42.3% when excluding RANDOM) for Task-2 on identifying finer-grained semantic relations. In our experiments, we try word analogy, linear regression, and multi-task Convolutional Neural Networks (CNNs) with word embeddings from publicly available word vectors. We found that linear regression performs better in the binary classification (Task-1), while CNNs have better performance in the multi-class semantic classification (Task-2). We assume that word analogy is more suited for deterministic answers rather than handling the ambiguity of one-to-many and many-to-many relationships. We also show that classifier performance could benefit from balancing the distribution of labels in the training data.</abstract>
    </paper>
    <paper id="12">
      <title><fixed-case>C</fixed-case>og<fixed-case>AL</fixed-case>ex-<fixed-case>V</fixed-case> Shared Task: Mach5 – A traditional <fixed-case>DSM</fixed-case> approach to semantic relatedness</title>
      <author><first>Stefan</first> <last>Evert</last></author>
      <pages>92–97</pages>
      <url hash="aea9716e">W16-5312</url>
      <abstract>This contribution provides a strong baseline result for the CogALex-V shared task using a traditional “count”-type DSM (placed in rank 2 out of 7 in subtask 1 and rank 3 out of 6 in subtask 2). Parameter tuning experiments reveal some surprising effects and suggest that the use of random word pairs as negative examples may be problematic, guiding the parameter optimization in an undesirable direction.</abstract>
    </paper>
    <paper id="13">
      <title><fixed-case>C</fixed-case>og<fixed-case>AL</fixed-case>ex-<fixed-case>V</fixed-case> Shared Task: <fixed-case>ROOT</fixed-case>18</title>
      <author><first>Emmanuele</first> <last>Chersoni</last></author>
      <author><first>Giulia</first> <last>Rambelli</last></author>
      <author><first>Enrico</first> <last>Santus</last></author>
      <pages>98–103</pages>
      <url hash="2cf791ce">W16-5313</url>
      <abstract>In this paper, we describe ROOT 18, a classifier using the scores of several unsupervised distributional measures as features to discriminate between semantically related and unrelated words, and then to classify the related pairs according to their semantic relation (i.e. synonymy, antonymy, hypernymy, part-whole meronymy). Our classifier participated in the CogALex-V Shared Task, showing a solid performance on the first subtask, but a poor performance on the second subtask. The low scores reported on the second subtask suggest that distributional measures are not sufficient to discriminate between multiple semantic relations at once.</abstract>
    </paper>
    <paper id="14">
      <title><fixed-case>C</fixed-case>og<fixed-case>AL</fixed-case>ex-<fixed-case>V</fixed-case> Shared Task: <fixed-case>CGSRC</fixed-case> - Classifying Semantic Relations using Convolutional Neural Networks</title>
      <author><first>Chinnappa</first> <last>Guggilla</last></author>
      <pages>104–109</pages>
      <url hash="43eee833">W16-5314</url>
      <abstract>In this paper, we describe a system (CGSRC) for classifying four semantic relations: synonym, hypernym, antonym and meronym using convolutional neural networks (CNN). We have participated in CogALex-V semantic shared task of corpus-based identification of semantic relations. Proposed approach using CNN-based deep neural networks leveraging pre-compiled word2vec distributional neural embeddings achieved 43.15% weighted-F1 accuracy on subtask-1 (checking existence of a relation between two terms) and 25.24% weighted-F1 accuracy on subtask-2 (classifying relation types).</abstract>
    </paper>
    <paper id="15">
      <title><fixed-case>C</fixed-case>og<fixed-case>AL</fixed-case>ex-<fixed-case>V</fixed-case> Shared Task: <fixed-case>LOPE</fixed-case></title>
      <author><first>Kanan</first> <last>Luce</last></author>
      <author><first>Jiaxing</first> <last>Yu</last></author>
      <author><first>Shu-Kai</first> <last>Hsieh</last></author>
      <pages>110–113</pages>
      <url hash="08d2d4db">W16-5315</url>
      <abstract>Automatic discovery of semantically-related words is one of the most important NLP tasks, and has great impact on the theoretical psycholinguistic modeling of the mental lexicon. In this shared task, we employ the word embeddings model to testify two thoughts explicitly or implicitly assumed by the NLP community: (1). Word embedding models can reflect syntagmatic similarities in usage between words to distances in projected vector space. (2). Word embedding models can reflect paradigmatic relationships between words.</abstract>
    </paper>
    <paper id="16">
      <title><fixed-case>C</fixed-case>og<fixed-case>AL</fixed-case>ex-<fixed-case>V</fixed-case> Shared Task: <fixed-case>H</fixed-case>s<fixed-case>H</fixed-case>-Supervised – Supervised similarity learning using entry wise product of context vectors</title>
      <author><first>Christian</first> <last>Wartena</last></author>
      <author><first>Rosa Tsegaye</first> <last>Aga</last></author>
      <pages>114–118</pages>
      <url hash="5e43ce6f">W16-5316</url>
      <abstract>The CogALex-V Shared Task provides two datasets that consists of pairs of words along with a classification of their semantic relation. The dataset for the first task distinguishes only between related and unrelated, while the second data set distinguishes several types of semantic relations. A number of recent papers propose to construct a feature vector that represents a pair of words by applying a pairwise simple operation to all elements of the feature vector. Subsequently, the pairs can be classified by training any classification algorithm on these vectors. In the present paper we apply this method to the provided datasets. We see that the results are not better than from the given simple baseline. We conclude that the results of the investigated method are strongly depended on the type of data to which it is applied.</abstract>
    </paper>
    <paper id="17">
      <title>A Study of the Bump Alternation in <fixed-case>J</fixed-case>apanese from the Perspective of Extended/Onset Causation</title>
      <author><first>Natsuno</first> <last>Aoki</last></author>
      <author><first>Kentaro</first> <last>Nakatani</last></author>
      <pages>119–124</pages>
      <url hash="9a17859f">W16-5317</url>
      <abstract>This paper deals with a seldom studied object/oblique alternation phenomenon in Japanese, which. We call this the bump alternation. This phenomenon, first discussed by Sadanobu (1990), is similar to the English with/against alternation. For example, compare hit the wall with the bat [=immobile-as-direct-object frame] to hit the bat against the wall [=mobile-as-direct-object frame]). However, in the Japanese version, the case frame remains constant. Although we fundamentally question Sadanobu’s acceptability judgment, we also claim that the causation type (i.e., whether the event is an instance of onset or extended causation; Talmy, 1988; 2000) could make an improvement. An extended causative interpretation could improve the acceptability of the otherwise awkward immobile-as-direct-object frame. We examined this claim through a rating study, and the results showed an interaction between the Causation type (extended/onset) and the Object type (mobile/immobile) in the direction we predicted. We propose that a perspective shift on what is moving causes the “extended causation” advantage.</abstract>
    </paper>
    <paper id="18">
      <title><fixed-case>G</fixed-case>ho<fixed-case>S</fixed-case>t-<fixed-case>PV</fixed-case>: A Representative Gold Standard of <fixed-case>G</fixed-case>erman Particle Verbs</title>
      <author><first>Stefan</first> <last>Bott</last></author>
      <author><first>Nana</first> <last>Khvtisavrishvili</last></author>
      <author><first>Max</first> <last>Kisselew</last></author>
      <author><first>Sabine</first> <last>Schulte im Walde</last></author>
      <pages>125–133</pages>
      <url hash="38ba26f9">W16-5318</url>
      <abstract>German particle verbs represent a frequent type of multi-word-expression that forms a highly productive paradigm in the lexicon. Similarly to other multi-word expressions, particle verbs exhibit various levels of compositionality. One of the major obstacles for the study of compositionality is the lack of representative gold standards of human ratings. In order to address this bottleneck, this paper presents such a gold standard data set containing 400 randomly selected German particle verbs. It is balanced across several particle types and three frequency bands, and accomplished by human ratings on the degree of semantic compositionality.</abstract>
    </paper>
    <paper id="19">
      <title>Discovering Potential Terminological Relationships from <fixed-case>T</fixed-case>witter’s Timed Content</title>
      <author><first>Mohammad</first> <last>Daoud</last></author>
      <author><first>Daoud</first> <last>Daoud</last></author>
      <pages>134–144</pages>
      <url hash="e8b04df9">W16-5319</url>
      <abstract>This paper presents a method to discover possible terminological relationships from tweets. We match the histories of terms (frequency patterns). Similar history indicates a possible relationship between terms. For example, if two terms (t1, t2) appeared frequently in Twitter at particular days, and there is a ‘similarity’ in the frequencies over a period of time, then t1 and t2 can be related. Maintaining standard terminological repository with updated relationships can be difficult; especially in a dynamic domain such as social media where thousands of new terms (neology) are coined every day. So we propose to construct a raw repository of lexical units with unconfirmed relationships. We have experimented our method on time-sensitive Arabic terms used by the online Arabic community of Twitter. We draw relationships between these terms by matching their similar frequency patterns (timelines). We use dynamic time warping as a similarity measure. For evaluation, we have selected 630 possible terms (we call them preterms) and we matched the similarity of these terms over a period of 30 days. Around 270 correct relationships were discovered with a precision of 0.61. These relationships were extracted without considering the textual context of the term.</abstract>
    </paper>
    <paper id="20">
      <title><fixed-case>L</fixed-case>exfom: a lexical functions ontology model</title>
      <author><first>Alexsandro</first> <last>Fonseca</last></author>
      <author><first>Fatiha</first> <last>Sadat</last></author>
      <author><first>François</first> <last>Lareau</last></author>
      <pages>145–155</pages>
      <url hash="f5fd2a85">W16-5320</url>
      <abstract>A lexical function represents a type of relation that exists between lexical units (words or expressions) in any language. For example, the antonymy is a type of relation that is represented by the lexical function Anti: Anti(big) = small. Those relations include both paradigmatic relations, i.e. vertical relations, such as synonymy, antonymy and meronymy and syntagmatic relations, i.e. horizontal relations, such as objective qualification (legitimate demand), subjective qualification (fruitful analysis), positive evaluation (good review) and support verbs (pay a visit, subject to an interrogation). In this paper, we present the Lexical Functions Ontology Model (lexfom) to represent lexical functions and the relation among lexical units. Lexfom is divided in four modules: lexical function representation (lfrep), lexical function family (lffam), lexical function semantic perspective (lfsem) and lexical function relations (lfrel). Moreover, we show how it combines to Lexical Model for Ontologies (lemon), for the transformation of lexical networks into the semantic web formats. So far, we have implemented 100 simple and 500 complex lexical functions, and encoded about 8,000 syntagmatic and 46,000 paradigmatic relations, for the French language.</abstract>
    </paper>
    <paper id="21">
      <title>A Proposal for combining “general” and specialized frames</title>
      <author><first>Marie-Claude</first> <last>L’ Homme</last></author>
      <author><first>Carlos</first> <last>Subirats</last></author>
      <author><first>Benoît</first> <last>Robichaud</last></author>
      <pages>156–165</pages>
      <url hash="2367d2f2">W16-5321</url>
      <abstract>The objectives of the work described in this paper are: 1. To list the differences between a general language resource (namely FrameNet) and a domain-specific resource; 2. To devise solutions to merge their contents in order to increase the coverage of the general resource. Both resources are based on Frame Semantics (Fillmore 1985; Fillmore and Baker 2010) and this raises specific challenges since the theoretical framework and the methodology derived from it provide for both a lexical description and a conceptual representation. We propose a series of strategies that handle both lexical and conceptual (frame) differences and implemented them in the specialized resource. We also show that most differences can be handled in a straightforward manner. However, some more domain specific differences (such as frames defined exclusively for the specialized domain or relations between these frames) are likely to be much more difficult to take into account since some are domain-specific.</abstract>
    </paper>
    <paper id="22">
      <title>Antonymy and Canonicity: Experimental and Distributional Evidence</title>
      <author><first>Andreana</first> <last>Pastena</last></author>
      <author><first>Alessandro</first> <last>Lenci</last></author>
      <pages>166–175</pages>
      <url hash="cc9e9b6d">W16-5322</url>
      <abstract>The present paper investigates the phenomenon of antonym canonicity by providing new behavioural and distributional evidence on Italian adjectives. Previous studies have showed that some pairs of antonyms are perceived to be better examples of opposition than others, and are so considered representative of the whole category (e.g., Deese, 1964; Murphy, 2003; Paradis et al., 2009). Our goal is to further investigate why such canonical pairs (Murphy, 2003) exist and how they come to be associated. In the literature, two different approaches have dealt with this issue. The lexical-categorical approach (Charles and Miller, 1989; Justeson and Katz, 1991) finds the cause of canonicity in the high co-occurrence frequency of the two adjectives. The cognitive-prototype approach (Paradis et al., 2009; Jones et al., 2012) instead claims that two adjectives form a canonical pair because they are aligned along a simple and salient dimension. Our empirical evidence, while supporting the latter view, shows that the paradigmatic distributional properties of adjectives can also contribute to explain the phenomenon of canonicity, providing a corpus-based correlate of the cognitive notion of salience.</abstract>
    </paper>
    <paper id="23">
      <title>Categorization of Semantic Roles for Dictionary Definitions</title>
      <author><first>Vivian</first> <last>Silva</last></author>
      <author><first>Siegfried</first> <last>Handschuh</last></author>
      <author><first>André</first> <last>Freitas</last></author>
      <pages>176–184</pages>
      <url hash="6fb596ee">W16-5323</url>
      <abstract>Understanding the semantic relationships between terms is a fundamental task in natural language processing applications. While structured resources that can express those relationships in a formal way, such as ontologies, are still scarce, a large number of linguistic resources gathering dictionary definitions is becoming available, but understanding the semantic structure of natural language definitions is fundamental to make them useful in semantic interpretation tasks. Based on an analysis of a subset of WordNet’s glosses, we propose a set of semantic roles that compose the semantic structure of a dictionary definition, and show how they are related to the definition’s syntactic configuration, identifying patterns that can be used in the development of information extraction frameworks and semantic models.</abstract>
    </paper>
    <paper id="24">
      <title>Corpus and dictionary development for classifiers/quantifiers towards a <fixed-case>F</fixed-case>rench-<fixed-case>J</fixed-case>apanese machine translation</title>
      <author><first>Mutsuko</first> <last>Tomokiyo</last></author>
      <author><first>Christian</first> <last>Boitet</last></author>
      <pages>185–192</pages>
      <url hash="a1a2f5e6">W16-5324</url>
      <abstract>Although quantifiers/classifiers expressions occur frequently in everyday communications or written documents, there is no description for them in classical bilingual paper dictionaries, nor in machine-readable dictionaries. The paper describes a corpus and dictionary development for quantifiers/classifiers, and their usage in the framework of French-Japanese machine translation (MT). They often cause problems of lexical ambiguity and of set phrase recognition during analysis, in particular for a long-distance language pair like French and Japanese. For the development of a dictionary aiming at ambiguity resolution for expressions including quantifiers and classifiers which may be ambiguous with common nouns, we have annotated our corpus with UWs (interlingual lexemes) of UNL (Universal Networking Language) found on the UNL-jp dictionary. The extraction of potential classifiers/quantifiers from corpus is made by UNLexplorer web service. Keywords : classifiers, quantifiers, phraseology study, corpus annotation, UNL (Universal Networking Language), UWs dictionary, Tori Bank, French-Japanese machine translation (MT).</abstract>
    </paper>
  </volume>
  <volume id="54">
    <meta>
      <booktitle>Proceedings of the 12th Workshop on <fixed-case>A</fixed-case>sian Language Resources (<fixed-case>ALR</fixed-case>12)</booktitle>
      <url hash="017ef3a9">W16-54</url>
      <editor><first>Koiti</first><last>Hasida</last></editor>
      <editor><first>Kam-Fai</first><last>Wong</last></editor>
      <editor><first>Nicoletta</first><last>Calzorari</last></editor>
      <editor><first>Key-Sun</first><last>Choi</last></editor>
      <publisher>The COLING 2016 Organizing Committee</publisher>
      <address>Osaka, Japan</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="7f856dd0">W16-5400</url>
    </frontmatter>
    <paper id="1">
      <title>An extension of <fixed-case>ISO</fixed-case>-Space for annotating object direction</title>
      <author><first>Daiki</first> <last>Gotou</last></author>
      <author><first>Hitoshi</first> <last>Nishikawa</last></author>
      <author><first>Takenobu</first> <last>Tokunaga</last></author>
      <pages>1–9</pages>
      <url hash="2bc873a8">W16-5401</url>
      <abstract>In this paper, we extend an existing annotation scheme ISO-Space for annotating necessary spatial information for the task placing an specified object at a specified location with a specified direction according to a natural language instruction. We call such task the spatial placement problem. Our extension particularly focuses on describing the object direction, when the object is placed on the 2D plane. We conducted an annotation experiment in which a corpus of 20 situated dialogues were annotated. The annotation result showed the number of newly introduced tags by our proposal is not negligible. We also implemented an analyser that automatically assigns the proposed tags to the corpus and evaluated its performance. The result showed that the performance for entity tag was quite high ranging from 0.68 to 0.99 in F-measure, but not the case for relation tags, i.e. less than 0.4 in F-measure.</abstract>
    </paper>
    <paper id="2">
      <title>Annotation and Analysis of Discourse Relations, Temporal Relations and Multi-Layered Situational Relations in <fixed-case>J</fixed-case>apanese Texts</title>
      <author><first>Kimi</first> <last>Kaneko</last></author>
      <author><first>Saku</first> <last>Sugawara</last></author>
      <author><first>Koji</first> <last>Mineshima</last></author>
      <author><first>Daisuke</first> <last>Bekki</last></author>
      <pages>10–19</pages>
      <url hash="04b5d3f7">W16-5402</url>
      <abstract>This paper proposes a methodology for building a specialized Japanese data set for recognizing temporal relations and discourse relations. In addition to temporal and discourse relations, multi-layered situational relations that distinguish generic and specific states belonging to different layers in a discourse are annotated. Our methodology has been applied to 170 text fragments taken from Wikinews articles in Japanese. The validity of our methodology is evaluated and analyzed in terms of degree of annotator agreement and frequency of errors.</abstract>
    </paper>
    <paper id="3">
      <title>Developing <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies for <fixed-case>M</fixed-case>andarin <fixed-case>C</fixed-case>hinese</title>
      <author><first>Herman</first> <last>Leung</last></author>
      <author><first>Rafaël</first> <last>Poiret</last></author>
      <author><first>Tak-sum</first> <last>Wong</last></author>
      <author><first>Xinying</first> <last>Chen</last></author>
      <author><first>Kim</first> <last>Gerdes</last></author>
      <author><first>John</first> <last>Lee</last></author>
      <pages>20–29</pages>
      <url hash="99df3fb5">W16-5403</url>
      <abstract>This article proposes a Universal Dependency Annotation Scheme for Mandarin Chinese, including POS tags and dependency analysis. We identify cases of idiosyncrasy of Mandarin Chinese that are difficult to fit into the current schema which has mainly been based on the descriptions of various Indo-European languages. We discuss differences between our scheme and those of the Stanford Chinese Dependencies and the Chinese Dependency Treebank.</abstract>
    </paper>
    <paper id="4">
      <title>Developing Corpus of Lecture Utterances Aligned to Slide Components</title>
      <author><first>Ryo</first> <last>Minamiguchi</last></author>
      <author><first>Masatoshi</first> <last>Tsuchiya</last></author>
      <pages>30–37</pages>
      <url hash="f35b7aac">W16-5404</url>
      <abstract>The approach which formulates the automatic text summarization as a maximum coverage problem with knapsack constraint over a set of textual units and a set of weighted conceptual units is promising. However, it is quite important and difficult to determine the appropriate granularity of conceptual units for this formulation. In order to resolve this problem, we are examining to use components of presentation slides as conceptual units to generate a summary of lecture utterances, instead of other possible conceptual units like base noun phrases or important nouns. This paper explains our developing corpus designed to evaluate our proposing approach, which consists of presentation slides and lecture utterances aligned to presentation slide components.</abstract>
    </paper>
    <paper id="5">
      <title><fixed-case>VS</fixed-case>o<fixed-case>LSCS</fixed-case>um: Building a <fixed-case>V</fixed-case>ietnamese Sentence-Comment Dataset for Social Context Summarization</title>
      <author><first>Minh-Tien</first> <last>Nguyen</last></author>
      <author><first>Dac Viet</first> <last>Lai</last></author>
      <author><first>Phong-Khac</first> <last>Do</last></author>
      <author><first>Duc-Vu</first> <last>Tran</last></author>
      <author><first>Minh-Le</first> <last>Nguyen</last></author>
      <pages>38–48</pages>
      <url hash="0bdbd6d5">W16-5405</url>
      <abstract>This paper presents VSoLSCSum, a Vietnamese linked sentence-comment dataset, which was manually created to treat the lack of standard corpora for social context summarization in Vietnamese. The dataset was collected through the keywords of 141 Web documents in 12 special events, which were mentioned on Vietnamese Web pages. Social users were asked to involve in creating standard summaries and the label of each sentence or comment. The inter-agreement calculated by Cohen’s Kappa among raters after validating is 0.685. To illustrate the potential use of our dataset, a learning to rank method was trained by using a set of local and social features. Experimental results indicate that the summary model trained on our dataset outperforms state-of-the-art baselines in both ROUGE-1 and ROUGE-2 in social context summarization.</abstract>
    </paper>
    <paper id="6">
      <title><fixed-case>BCCWJ</fixed-case>-<fixed-case>D</fixed-case>ep<fixed-case>P</fixed-case>ara: A Syntactic Annotation Treebank on the ‘<fixed-case>B</fixed-case>alanced <fixed-case>C</fixed-case>orpus of <fixed-case>C</fixed-case>ontemporary <fixed-case>W</fixed-case>ritten <fixed-case>J</fixed-case>apanese’</title>
      <author><first>Masayuki</first> <last>Asahara</last></author>
      <author><first>Yuji</first> <last>Matsumoto</last></author>
      <pages>49–58</pages>
      <url hash="9471213a">W16-5406</url>
      <abstract>Paratactic syntactic structures are difficult to represent in syntactic dependency tree structures. As such, we propose an annotation schema for syntactic dependency annotation of Japanese, in which coordinate structures are split from and overlaid on bunsetsu-based (base phrase unit) dependency. The schema represents nested coordinate structures, non-constituent conjuncts, and forward sharing as the set of regions. The annotation was performed on the core data of ‘Balanced Corpus of Contemporary Written Japanese’, which comprised about one million words and 1980 samples from six registers, such as newspapers, books, magazines, and web texts.</abstract>
    </paper>
    <paper id="7">
      <title><fixed-case>SCTB</fixed-case>: A <fixed-case>C</fixed-case>hinese Treebank in Scientific Domain</title>
      <author><first>Chenhui</first> <last>Chu</last></author>
      <author><first>Toshiaki</first> <last>Nakazawa</last></author>
      <author><first>Daisuke</first> <last>Kawahara</last></author>
      <author><first>Sadao</first> <last>Kurohashi</last></author>
      <pages>59–67</pages>
      <url hash="9331a1c7">W16-5407</url>
      <abstract>Treebanks are curial for natural language processing (NLP). In this paper, we present our work for annotating a Chinese treebank in scientific domain (SCTB), to address the problem of the lack of Chinese treebanks in this domain. Chinese analysis and machine translation experiments conducted using this treebank indicate that the annotated treebank can significantly improve the performance on both tasks. This treebank is released to promote Chinese NLP research in scientific domain.</abstract>
    </paper>
    <paper id="8">
      <title>Big Community Data before World Wide Web Era</title>
      <author><first>Tomoya</first> <last>Iwakura</last></author>
      <author><first>Tetsuro</first> <last>Takahashi</last></author>
      <author><first>Akihiro</first> <last>Ohtani</last></author>
      <author><first>Kunio</first> <last>Matsui</last></author>
      <pages>68–72</pages>
      <url hash="c354511c">W16-5408</url>
      <abstract>This paper introduces the NIFTY-Serve corpus, a large data archive collected from Japanese discussion forums that operated via a Bulletin Board System (BBS) between 1987 and 2006. This corpus can be used in Artificial Intelligence researches such as Natural Language Processing, Community Analysis, and so on. The NIFTY-Serve corpus differs from data on WWW in three ways; (1) essentially spam- and duplication-free because of strict data collection procedures, (2) historic user-generated data before WWW, and (3) a complete data set because the service now shut down. We also introduce some examples of use of the corpus.</abstract>
    </paper>
    <paper id="9">
      <title>An Overview of <fixed-case>BPPT</fixed-case>’s <fixed-case>I</fixed-case>ndonesian Language Resources</title>
      <author><first>Gunarso</first> <last>Gunarso</last></author>
      <author><first>Hammam</first> <last>Riza</last></author>
      <pages>73–77</pages>
      <url hash="deb5ef67">W16-5409</url>
      <abstract>This paper describes various Indonesian language resources that Agency for the Assessment and Application of Technology (BPPT) has developed and collected since mid 80’s when we joined MMTS (Multilingual Machine Translation System), an international project coordinated by CICC-Japan to develop a machine translation system for five Asian languages (Bahasa Indonesia, Malay, Thai, Japanese, and Chinese). Since then, we have been actively doing many types of research in the field of statistical machine translation, speech recognition, and speech synthesis which requires many text and speech corpus. Most recent cooperation within ASEAN-IVO is the development of Indonesian ALT (Asian Language Treebank) has added new NLP tools.</abstract>
    </paper>
    <paper id="10">
      <title>Creating <fixed-case>J</fixed-case>apanese Political Corpus from Local Assembly Minutes of 47 prefectures</title>
      <author><first>Yasutomo</first> <last>Kimura</last></author>
      <author><first>Keiichi</first> <last>Takamaru</last></author>
      <author><first>Takuma</first> <last>Tanaka</last></author>
      <author><first>Akio</first> <last>Kobayashi</last></author>
      <author><first>Hiroki</first> <last>Sakaji</last></author>
      <author><first>Yuzu</first> <last>Uchida</last></author>
      <author><first>Hokuto</first> <last>Ototake</last></author>
      <author><first>Shigeru</first> <last>Masuyama</last></author>
      <pages>78–85</pages>
      <url hash="10703e02">W16-5410</url>
      <abstract>This paper describes a Japanese political corpus created for interdisciplinary political research. The corpus contains the local assembly minutes of 47 prefectures from April 2011 to March 2015. This four-year period coincides with the term of office for assembly members in most autonomies. We analyze statistical data, such as the number of speakers, characters, and words, to clarify the characteristics of local assembly minutes. In addition, we identify problems associated with the different web services used by the autonomies to make the minutes available to the public.</abstract>
    </paper>
    <paper id="11">
      <title>Selective Annotation of Sentence Parts: Identification of Relevant Sub-sentential Units</title>
      <author><first>Ge</first> <last>Xu</last></author>
      <author><first>Xiaoyan</first> <last>Yang</last></author>
      <author><first>Chu-Ren</first> <last>Huang</last></author>
      <pages>86–94</pages>
      <url hash="485d9b9f">W16-5411</url>
      <abstract>Many NLP tasks involve sentence-level annotation yet the relevant information is not encoded at sentence level but at some relevant parts of the sentence. Such tasks include but are not limited to: sentiment expression annotation, product feature annotation, and template annotation for Q&amp;A systems. However, annotation of the full corpus sentence by sentence is resource intensive. In this paper, we propose an approach that iteratively extracts frequent parts of sentences for annotating, and compresses the set of sentences after each round of annotation. Our approach can also be used in preparing training sentences for binary classification (domain-related vs. noise, subjectivity vs. objectivity, etc.), assuming that sentence-type annotation can be predicted by annotation of the most relevant sub-sentences. Two experiments are performed to test our proposal and evaluated in terms of time saved and agreement of annotation.</abstract>
    </paper>
    <paper id="12">
      <title>The <fixed-case>K</fixed-case>yutech corpus and topic segmentation using a combined method</title>
      <author><first>Takashi</first> <last>Yamamura</last></author>
      <author><first>Kazutaka</first> <last>Shimada</last></author>
      <author><first>Shintaro</first> <last>Kawahara</last></author>
      <pages>95–104</pages>
      <url hash="d7427ecc">W16-5412</url>
      <abstract>Summarization of multi-party conversation is one of the important tasks in natural language processing. In this paper, we explain a Japanese corpus and a topic segmentation task. To the best of our knowledge, the corpus is the first Japanese corpus annotated for summarization tasks and freely available to anyone. We call it “the Kyutech corpus.” The task of the corpus is a decision-making task with four participants and it contains utterances with time information, topic segmentation and reference summaries. As a case study for the corpus, we describe a method combined with LCSeg and TopicTiling for a topic segmentation task. We discuss the effectiveness and the problems of the combined method through the experiment with the Kyutech corpus.</abstract>
    </paper>
    <paper id="13">
      <title>Automatic Evaluation of Commonsense Knowledge for Refining <fixed-case>J</fixed-case>apanese <fixed-case>C</fixed-case>oncept<fixed-case>N</fixed-case>et</title>
      <author><first>Seiya</first> <last>Shudo</last></author>
      <author><first>Rafal</first> <last>Rzepka</last></author>
      <author><first>Kenji</first> <last>Araki</last></author>
      <pages>105–112</pages>
      <url hash="4604fbfe">W16-5413</url>
      <abstract>In this paper we present two methods for automatic common sense knowledge evaluation for Japanese entries in ConceptNet ontology. Our proposed methods utilize text-mining approach: one with relation clue words and WordNet synonyms, and one without. Both methods were tested with a blog corpus. The system based on our proposed methods reached relatively high precision score for three relations (MadeOf, UsedFor, AtLocation), which is comparable with previous research using commercial search engines and simpler input. We analyze errors and discuss problems of common sense evaluation, both manual and automatic and propose ideas for further improvements.</abstract>
    </paper>
    <paper id="14">
      <title><fixed-case>SAMER</fixed-case>: A Semi-Automatically Created Lexical Resource for <fixed-case>A</fixed-case>rabic Verbal Multiword Expressions Tokens Paradigm and their Morphosyntactic Features</title>
      <author><first>Mohamed</first> <last>Al-Badrashiny</last></author>
      <author><first>Abdelati</first> <last>Hawwari</last></author>
      <author><first>Mahmoud</first> <last>Ghoneim</last></author>
      <author><first>Mona</first> <last>Diab</last></author>
      <pages>113–122</pages>
      <url hash="a2f6beee">W16-5414</url>
      <abstract>Although MWE are relatively morphologically and syntactically fixed expressions, several types of flexibility can be observed in MWE, verbal MWE in particular. Identifying the degree of morphological and syntactic flexibility of MWE is very important for many Lexicographic and NLP tasks. Adding MWE variants/tokens to a dictionary resource requires characterizing the flexibility among other morphosyntactic features. Carrying out the task manually faces several challenges since it is a very laborious task time and effort wise, as well as it will suffer from coverage limitation. The problem is exacerbated in rich morphological languages where the average word in Arabic could have 12 possible inflection forms. Accordingly, in this paper we introduce a semi-automatic Arabic multiwords expressions resource (SAMER). We propose an automated method that identifies the morphological and syntactic flexibility of Arabic Verbal Multiword Expressions (AVMWE). All observed morphological variants and syntactic pattern alternations of an AVMWE are automatically acquired using large scale corpora. We look for three morphosyntactic aspects of AVMWE types investigating derivational and inflectional variations and syntactic templates, namely: 1) inflectional variation (inflectional paradigm) and calculating degree of flexibility; 2) derivational productivity; and 3) identifying and classifying the different syntactic types. We build a comprehensive list of AVMWE. Every token in the AVMWE list is lemmatized and tagged with POS information. We then search Arabic Gigaword and All ATBs for all possible flexible matches. For each AVMWE type we generate: a) a statistically ranked list of MWE-lexeme inflections and syntactic pattern alternations; b) An abstract syntactic template; and c) The most frequent form. Our technique is validated using a Golden MWE annotated list. The results shows that the quality of the generated resource is 80.04%.</abstract>
    </paper>
    <paper id="15">
      <title>Sentiment Analysis for Low Resource Languages: A Study on Informal <fixed-case>I</fixed-case>ndonesian Tweets</title>
      <author><first>Tuan Anh</first> <last>Le</last></author>
      <author><first>David</first> <last>Moeljadi</last></author>
      <author><first>Yasuhide</first> <last>Miura</last></author>
      <author><first>Tomoko</first> <last>Ohkuma</last></author>
      <pages>123–131</pages>
      <url hash="74114cc1">W16-5415</url>
      <abstract>This paper describes our attempt to build a sentiment analysis system for Indonesian tweets. With this system, we can study and identify sentiments and opinions in a text or document computationally. We used four thousand manually labeled tweets collected in February and March 2016 to build the model. Because of the variety of content in tweets, we analyze tweets into eight groups in total, including pos(itive), neg(ative), and neu(tral). Finally, we obtained 73.2% accuracy with Long Short Term Memory (LSTM) without normalizer.</abstract>
    </paper>
  </volume>
  <volume id="55">
    <meta>
      <booktitle>Proceedings of the <fixed-case>INLG</fixed-case> 2016 Workshop on Computational Creativity in Natural Language Generation</booktitle>
      <url hash="a35e75a4">W16-55</url>
      <editor><first>Matthew</first><last>Purver</last></editor>
      <editor><first>Pablo</first><last>Gervás</last></editor>
      <editor><first>Sascha</first><last>Griffiths</last></editor>
      <doi>10.18653/v1/W16-55</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Edinburgh, UK</address>
      <month>September</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="64546267">W16-5500</url>
    </frontmatter>
    <paper id="1">
      <title>Assembling Narratives with Associative Threads</title>
      <author><first>Pierre-Luc</first> <last>Vaudry</last></author>
      <author><first>Guy</first> <last>Lapalme</last></author>
      <pages>1–10</pages>
      <url hash="dadf60d3">W16-5501</url>
      <doi>10.18653/v1/W16-5501</doi>
    </paper>
    <paper id="2">
      <title>Human-like Natural Language Generation Using <fixed-case>M</fixed-case>onte <fixed-case>C</fixed-case>arlo Tree Search</title>
      <author><first>Kaori</first> <last>Kumagai</last></author>
      <author><first>Ichiro</first> <last>Kobayashi</last></author>
      <author><first>Daichi</first> <last>Mochihashi</last></author>
      <author><first>Hideki</first> <last>Asoh</last></author>
      <author><first>Tomoaki</first> <last>Nakamura</last></author>
      <author><first>Takayuki</first> <last>Nagai</last></author>
      <pages>11–18</pages>
      <url hash="13974c6d">W16-5502</url>
      <doi>10.18653/v1/W16-5502</doi>
    </paper>
    <paper id="3">
      <title>Empirical Determination of Basic Heuristics for Narrative Content Planning</title>
      <author><first>Pablo</first> <last>Gervás</last></author>
      <pages>19–26</pages>
      <url hash="7d24eee3">W16-5503</url>
      <doi>10.18653/v1/W16-5503</doi>
    </paper>
    <paper id="4">
      <title><fixed-case>X</fixed-case>575: Writing rengas with web services</title>
      <author><first>Daniel</first> <last>Winterstein</last></author>
      <author><first>Joseph</first> <last>Corneli</last></author>
      <pages>27–30</pages>
      <url hash="417e47e0">W16-5504</url>
      <doi>10.18653/v1/W16-5504</doi>
    </paper>
    <paper id="5">
      <title>A Challenge to the Third Hoshi Shinichi Award</title>
      <author><first>Satoshi</first> <last>Sato</last></author>
      <pages>31–35</pages>
      <url hash="0b4d119b">W16-5505</url>
      <doi>10.18653/v1/W16-5505</doi>
    </paper>
    <paper id="6">
      <title>Automatic Modification of Communication Style in Dialogue Management</title>
      <author><first>Louisa</first> <last>Pragst</last></author>
      <author><first>Juliana</first> <last>Miehle</last></author>
      <author><first>Stefan</first> <last>Ultes</last></author>
      <author><first>Wolfgang</first> <last>Minker</last></author>
      <pages>36–40</pages>
      <url hash="7f1249fd">W16-5506</url>
      <doi>10.18653/v1/W16-5506</doi>
    </paper>
    <paper id="7">
      <title>Mining Knowledge in Storytelling Systems for Narrative Generation</title>
      <author><first>Eugenio</first> <last>Concepción</last></author>
      <author><first>Pablo</first> <last>Gervás</last></author>
      <author><first>Gonzalo</first> <last>Méndez</last></author>
      <pages>41–50</pages>
      <url hash="0adddd66">W16-5507</url>
      <doi>10.18653/v1/W16-5507</doi>
    </paper>
    <paper id="8">
      <title>Process Based Evaluation of Computer Generated Poetry</title>
      <author><first>Stephen</first> <last>McGregor</last></author>
      <author><first>Matthew</first> <last>Purver</last></author>
      <author><first>Geraint</first> <last>Wiggins</last></author>
      <pages>51–60</pages>
      <url hash="3d29f6c3">W16-5508</url>
      <doi>10.18653/v1/W16-5508</doi>
    </paper>
    <paper id="9">
      <title>Combinatorics vs Grammar: Archeology of Computational Poetry in Tape Mark <fixed-case>I</fixed-case></title>
      <author><first>Alessandro</first> <last>Mazzei</last></author>
      <author><first>Andrea</first> <last>Valle</last></author>
      <pages>61–70</pages>
      <url hash="d32aab8b">W16-5509</url>
      <doi>10.18653/v1/W16-5509</doi>
    </paper>
  </volume>
  <volume id="56">
    <meta>
      <booktitle>Proceedings of the First Workshop on <fixed-case>NLP</fixed-case> and Computational Social Science</booktitle>
      <url hash="ea3517ee">W16-56</url>
      <editor><first>David</first><last>Bamman</last></editor>
      <editor><first>A. Seza</first><last>Doğruöz</last></editor>
      <editor><first>Jacob</first><last>Eisenstein</last></editor>
      <editor><first>Dirk</first><last>Hovy</last></editor>
      <editor><first>David</first><last>Jurgens</last></editor>
      <editor><first>Brendan</first><last>O’Connor</last></editor>
      <editor><first>Alice</first><last>Oh</last></editor>
      <editor><first>Oren</first><last>Tsur</last></editor>
      <editor><first>Svitlana</first><last>Volkova</last></editor>
      <doi>10.18653/v1/W16-56</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Austin, Texas</address>
      <month>November</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="bd3f2b8b">W16-5600</url>
    </frontmatter>
    <paper id="1">
      <title>Relating semantic similarity and semantic association to how humans label other people</title>
      <author><first>Kenneth</first> <last>Joseph</last></author>
      <author><first>Kathleen M.</first> <last>Carley</last></author>
      <pages>1–10</pages>
      <url hash="edb98cde">W16-5601</url>
      <doi>10.18653/v1/W16-5601</doi>
    </paper>
    <paper id="2">
      <title>Identifying News from Tweets</title>
      <author><first>Jesse</first> <last>Freitas</last></author>
      <author><first>Heng</first> <last>Ji</last></author>
      <pages>11–16</pages>
      <url hash="f17c69c6">W16-5602</url>
      <doi>10.18653/v1/W16-5602</doi>
    </paper>
    <paper id="3">
      <title>Obfuscating Gender in Social Media Writing</title>
      <author><first>Sravana</first> <last>Reddy</last></author>
      <author><first>Kevin</first> <last>Knight</last></author>
      <pages>17–26</pages>
      <url hash="3eae8f80">W16-5603</url>
      <doi>10.18653/v1/W16-5603</doi>
    </paper>
    <paper id="4">
      <title>Social Proof: The Impact of Author Traits on Influence Detection</title>
      <author><first>Sara</first> <last>Rosenthal</last></author>
      <author><first>Kathy</first> <last>McKeown</last></author>
      <pages>27–36</pages>
      <url hash="7e6c860a">W16-5604</url>
      <doi>10.18653/v1/W16-5604</doi>
    </paper>
    <paper id="5">
      <title>Generating Politically-Relevant Event Data</title>
      <author><first>John</first> <last>Beieler</last></author>
      <pages>37–42</pages>
      <url hash="7597b573">W16-5605</url>
      <doi>10.18653/v1/W16-5605</doi>
    </paper>
    <paper id="6">
      <title>User profiling with geo-located posts and demographic data</title>
      <author><first>Adam</first> <last>Poulston</last></author>
      <author><first>Mark</first> <last>Stevenson</last></author>
      <author><first>Kalina</first> <last>Bontcheva</last></author>
      <pages>43–48</pages>
      <url hash="c59f3d5a">W16-5606</url>
      <doi>10.18653/v1/W16-5606</doi>
    </paper>
    <paper id="7">
      <title><fixed-case>G</fixed-case>ov2<fixed-case>V</fixed-case>ec: Learning Distributed Representations of Institutions and Their Legal Text</title>
      <author><first>John J.</first> <last>Nay</last></author>
      <pages>49–54</pages>
      <url hash="859684f9">W16-5607</url>
      <doi>10.18653/v1/W16-5607</doi>
    </paper>
    <paper id="8">
      <title>#<fixed-case>W</fixed-case>ho<fixed-case>A</fixed-case>m<fixed-case>I</fixed-case> in 160 Characters? Classifying Social Identities Based on <fixed-case>T</fixed-case>witter Profile Descriptions</title>
      <author><first>Anna</first> <last>Priante</last></author>
      <author><first>Djoerd</first> <last>Hiemstra</last></author>
      <author><first>Tijs</first> <last>van den Broek</last></author>
      <author><first>Aaqib</first> <last>Saeed</last></author>
      <author><first>Michel</first> <last>Ehrenhard</last></author>
      <author><first>Ariana</first> <last>Need</last></author>
      <pages>55–65</pages>
      <url hash="ad6a04a2">W16-5608</url>
      <doi>10.18653/v1/W16-5608</doi>
    </paper>
    <paper id="9">
      <title>Identifying Stance by Analyzing Political Discourse on <fixed-case>T</fixed-case>witter</title>
      <author><first>Kristen</first> <last>Johnson</last></author>
      <author><first>Dan</first> <last>Goldwasser</last></author>
      <pages>66–75</pages>
      <url hash="426d0425">W16-5609</url>
      <doi>10.18653/v1/W16-5609</doi>
    </paper>
    <paper id="10">
      <title>Learning Linguistic Descriptors of User Roles in Online Communities</title>
      <author><first>Alex</first> <last>Wang</last></author>
      <author><first>William L.</first> <last>Hamilton</last></author>
      <author><first>Jure</first> <last>Leskovec</last></author>
      <pages>76–85</pages>
      <url hash="a3774158">W16-5610</url>
      <doi>10.18653/v1/W16-5610</doi>
    </paper>
    <paper id="11">
      <title>The Effects of Data Collection Methods in <fixed-case>T</fixed-case>witter</title>
      <author><first>Sunghwan Mac</first> <last>Kim</last></author>
      <author><first>Stephen</first> <last>Wan</last></author>
      <author><first>Cécile</first> <last>Paris</last></author>
      <author><first>Brian</first> <last>Jin</last></author>
      <author><first>Bella</first> <last>Robinson</last></author>
      <pages>86–91</pages>
      <url hash="c316d600">W16-5611</url>
      <doi>10.18653/v1/W16-5611</doi>
    </paper>
    <paper id="12">
      <title>Expressions of Anxiety in Political Texts</title>
      <author><first>Ludovic</first> <last>Rheault</last></author>
      <pages>92–101</pages>
      <url hash="74bd4d28">W16-5612</url>
      <doi>10.18653/v1/W16-5612</doi>
    </paper>
    <paper id="13">
      <title>Constructing an Annotated Corpus for Protest Event Mining</title>
      <author><first>Peter</first> <last>Makarov</last></author>
      <author><first>Jasmine</first> <last>Lorenzini</last></author>
      <author><first>Hanspeter</first> <last>Kriesi</last></author>
      <pages>102–107</pages>
      <url hash="8b5ca864">W16-5613</url>
      <doi>10.18653/v1/W16-5613</doi>
      <attachment type="attachment" hash="db38614d">W16-5613.Attachment.zip</attachment>
    </paper>
    <paper id="14">
      <title><fixed-case>D</fixed-case>emographer: Extremely Simple Name Demographics</title>
      <author><first>Rebecca</first> <last>Knowles</last></author>
      <author><first>Josh</first> <last>Carroll</last></author>
      <author><first>Mark</first> <last>Dredze</last></author>
      <pages>108–113</pages>
      <url hash="0170676f">W16-5614</url>
      <doi>10.18653/v1/W16-5614</doi>
    </paper>
    <paper id="15">
      <title>Bag of What? Simple Noun Phrase Extraction for Text Analysis</title>
      <author><first>Abram</first> <last>Handler</last></author>
      <author><first>Matthew</first> <last>Denny</last></author>
      <author><first>Hanna</first> <last>Wallach</last></author>
      <author><first>Brendan</first> <last>O’Connor</last></author>
      <pages>114–124</pages>
      <url hash="232af62c">W16-5615</url>
      <doi>10.18653/v1/W16-5615</doi>
    </paper>
    <paper id="16">
      <title>News Sentiment and Cross-Country Fluctuations</title>
      <author><first>Samuel</first> <last>Fraiberger</last></author>
      <pages>125–131</pages>
      <url hash="cb7808c5">W16-5616</url>
      <doi>10.18653/v1/W16-5616</doi>
    </paper>
    <paper id="17">
      <title>The Clinical Panel: Leveraging Psychological Expertise During <fixed-case>NLP</fixed-case> Research</title>
      <author><first>Glen</first> <last>Coppersmith</last></author>
      <author><first>Kristy</first> <last>Hollingshead</last></author>
      <author><first>H. Andrew</first> <last>Schwartz</last></author>
      <author><first>Molly</first> <last>Ireland</last></author>
      <author><first>Rebecca</first> <last>Resnik</last></author>
      <author><first>Kate</first> <last>Loveys</last></author>
      <author><first>April</first> <last>Foreman</last></author>
      <author><first>Loring</first> <last>Ingraham</last></author>
      <pages>132–137</pages>
      <url hash="fb2c1043">W16-5617</url>
      <doi>10.18653/v1/W16-5617</doi>
    </paper>
    <paper id="18">
      <title>Are You a Racist or Am <fixed-case>I</fixed-case> Seeing Things? Annotator Influence on Hate Speech Detection on <fixed-case>T</fixed-case>witter</title>
      <author><first>Zeerak</first> <last>Waseem</last></author>
      <pages>138–142</pages>
      <url hash="4f848ee6">W16-5618</url>
      <doi>10.18653/v1/W16-5618</doi>
    </paper>
    <paper id="19">
      <title>Disentangling Topic Models: A Cross-cultural Analysis of Personal Values through Words</title>
      <author><first>Steven</first> <last>Wilson</last></author>
      <author><first>Rada</first> <last>Mihalcea</last></author>
      <author><first>Ryan</first> <last>Boyd</last></author>
      <author><first>James</first> <last>Pennebaker</last></author>
      <pages>143–152</pages>
      <url hash="42755f91">W16-5619</url>
      <doi>10.18653/v1/W16-5619</doi>
    </paper>
  </volume>
  <volume id="57">
    <meta>
      <booktitle>Proceedings of the 2nd Workshop on Computing News Storylines (<fixed-case>CNS</fixed-case> 2016)</booktitle>
      <url hash="fa090a44">W16-57</url>
      <editor><first>Tommaso</first> <last>Caselli</last></editor>
      <editor><first>Ben</first> <last>Miller</last></editor>
      <editor><first>Marieke</first> <last>van Erp</last></editor>
      <editor><first>Piek</first> <last>Vossen</last></editor>
      <editor><first>David</first> <last>Caswell</last></editor>
      <doi>10.18653/v1/W16-57</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Austin, Texas</address>
      <month>November</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="b32a9f40">W16-5700</url>
    </frontmatter>
    <paper id="1">
      <title>Computable News Ecosystems: Roles for Humans and Machines</title>
      <author><first>David</first> <last>Caswell</last></author>
      <pages>1–8</pages>
      <url hash="1bf8ef12">W16-5701</url>
      <doi>10.18653/v1/W16-5701</doi>
    </paper>
    <paper id="2">
      <title>Storyline detection and tracking using Dynamic <fixed-case>L</fixed-case>atent <fixed-case>D</fixed-case>irichlet <fixed-case>A</fixed-case>llocation</title>
      <author><first>Daniel</first> <last>Brüggermann</last></author>
      <author><first>Yannik</first> <last>Hermey</last></author>
      <author><first>Carsten</first> <last>Orth</last></author>
      <author><first>Darius</first> <last>Schneider</last></author>
      <author><first>Stefan</first> <last>Selzer</last></author>
      <author><first>Gerasimos</first> <last>Spanakis</last></author>
      <pages>9–19</pages>
      <url hash="290800dd">W16-5702</url>
      <doi>10.18653/v1/W16-5702</doi>
    </paper>
    <paper id="3">
      <title>Real-time News Story Detection and Tracking with Hashtags</title>
      <author><first>Gevorg</first> <last>Poghosyan</last></author>
      <author><first>Georgiana</first> <last>Ifrim</last></author>
      <pages>20–29</pages>
      <url hash="02e7612f">W16-5703</url>
      <doi>10.18653/v1/W16-5703</doi>
    </paper>
    <paper id="4">
      <title>Nonparametric <fixed-case>B</fixed-case>ayesian Storyline Detection from Microtexts</title>
      <author><first>Vinodh</first> <last>Krishnan</last></author>
      <author><first>Jacob</first> <last>Eisenstein</last></author>
      <pages>30–35</pages>
      <url hash="c3671474">W16-5704</url>
      <doi>10.18653/v1/W16-5704</doi>
    </paper>
    <paper id="5">
      <title>Automatic Identification of Narrative Diegesis and Point of View</title>
      <author><first>Joshua</first> <last>Eisenberg</last></author>
      <author><first>Mark</first> <last>Finlayson</last></author>
      <pages>36–46</pages>
      <url hash="7976ff3c">W16-5705</url>
      <doi>10.18653/v1/W16-5705</doi>
    </paper>
    <paper id="6">
      <title>Richer Event Description: Integrating event coreference with temporal, causal and bridging annotation</title>
      <author><first>Tim</first> <last>O’Gorman</last></author>
      <author><first>Kristin</first> <last>Wright-Bettner</last></author>
      <author><first>Martha</first> <last>Palmer</last></author>
      <pages>47–56</pages>
      <url hash="a92aa888">W16-5706</url>
      <doi>10.18653/v1/W16-5706</doi>
    </paper>
    <paper id="7">
      <title><fixed-case>NASTEA</fixed-case>: Investigating Narrative Schemas through Annotated Entities</title>
      <author><first>Dan</first> <last>Simonson</last></author>
      <author><first>Anthony</first> <last>Davis</last></author>
      <pages>57–66</pages>
      <url hash="815b5e71">W16-5707</url>
      <doi>10.18653/v1/W16-5707</doi>
    </paper>
    <paper id="8">
      <title>The Storyline Annotation and Representation Scheme (<fixed-case>S</fixed-case>ta<fixed-case>R</fixed-case>): A Proposal</title>
      <author><first>Tommaso</first> <last>Caselli</last></author>
      <author><first>Piek</first> <last>Vossen</last></author>
      <pages>67–72</pages>
      <url hash="9c1434ec">W16-5708</url>
      <doi>10.18653/v1/W16-5708</doi>
    </paper>
  </volume>
  <volume id="58">
    <meta>
      <booktitle>Proceedings of the Second Workshop on Computational Approaches to Code Switching</booktitle>
      <url hash="cacefc0d">W16-58</url>
      <editor><first>Mona</first><last>Diab</last></editor>
      <editor><first>Pascale</first><last>Fung</last></editor>
      <editor><first>Mahmoud</first><last>Ghoneim</last></editor>
      <editor><first>Julia</first><last>Hirschberg</last></editor>
      <editor><first>Thamar</first><last>Solorio</last></editor>
      <doi>10.18653/v1/W16-58</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Austin, Texas</address>
      <month>November</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="fb6973e9">W16-5800</url>
    </frontmatter>
    <paper id="1">
      <title>Challenges of Computational Processing of Code-Switching</title>
      <author><first>Özlem</first> <last>Çetinoğlu</last></author>
      <author><first>Sarah</first> <last>Schulz</last></author>
      <author><first>Ngoc Thang</first> <last>Vu</last></author>
      <pages>1–11</pages>
      <url hash="dc2ddbf3">W16-5801</url>
      <doi>10.18653/v1/W16-5801</doi>
    </paper>
    <paper id="2">
      <title>Simple Tools for Exploring Variation in Code-switching for Linguists</title>
      <author><first>Gualberto A.</first> <last>Guzman</last></author>
      <author><first>Jacqueline</first> <last>Serigos</last></author>
      <author><first>Barbara E.</first> <last>Bullock</last></author>
      <author><first>Almeida Jacqueline</first> <last>Toribio</last></author>
      <pages>12–20</pages>
      <url hash="c122bfa1">W16-5802</url>
      <doi>10.18653/v1/W16-5802</doi>
      <attachment type="attachment" hash="3d7178f3">W16-5802.Attachment.zip</attachment>
    </paper>
    <paper id="3">
      <title>Word-Level Language Identification and Predicting Codeswitching Points in <fixed-case>S</fixed-case>wahili-<fixed-case>E</fixed-case>nglish Language Data</title>
      <author><first>Mario</first> <last>Piergallini</last></author>
      <author><first>Rouzbeh</first> <last>Shirvani</last></author>
      <author><first>Gauri</first> <last>S. Gautam</last></author>
      <author><first>Mohamed</first> <last>Chouikha</last></author>
      <pages>21–29</pages>
      <url hash="ad8ed588">W16-5803</url>
      <doi>10.18653/v1/W16-5803</doi>
      <attachment type="attachment" hash="5346f833">W16-5803.Attachment.zip</attachment>
    </paper>
    <paper id="4">
      <title>Part-of-speech Tagging of Code-mixed Social Media Content: Pipeline, Stacking and Joint Modelling</title>
      <author><first>Utsab</first> <last>Barman</last></author>
      <author><first>Joachim</first> <last>Wagner</last></author>
      <author><first>Jennifer</first> <last>Foster</last></author>
      <pages>30–39</pages>
      <url hash="e4625676">W16-5804</url>
      <doi>10.18653/v1/W16-5804</doi>
      <attachment type="attachment" hash="732f3652">W16-5804.Attachment.zip</attachment>
    </paper>
    <paper id="5">
      <title>Overview for the Second Shared Task on Language Identification in Code-Switched Data</title>
      <author><first>Giovanni</first> <last>Molina</last></author>
      <author><first>Fahad</first> <last>AlGhamdi</last></author>
      <author><first>Mahmoud</first> <last>Ghoneim</last></author>
      <author><first>Abdelati</first> <last>Hawwari</last></author>
      <author><first>Nicolas</first> <last>Rey-Villamizar</last></author>
      <author><first>Mona</first> <last>Diab</last></author>
      <author><first>Thamar</first> <last>Solorio</last></author>
      <pages>40–49</pages>
      <url hash="ef1496a7">W16-5805</url>
      <doi>10.18653/v1/W16-5805</doi>
    </paper>
    <paper id="6">
      <title>Multilingual Code-switching Identification via <fixed-case>LSTM</fixed-case> Recurrent Neural Networks</title>
      <author><first>Younes</first> <last>Samih</last></author>
      <author><first>Suraj</first> <last>Maharjan</last></author>
      <author><first>Mohammed</first> <last>Attia</last></author>
      <author><first>Laura</first> <last>Kallmeyer</last></author>
      <author><first>Thamar</first> <last>Solorio</last></author>
      <pages>50–59</pages>
      <url hash="62dfb33c">W16-5806</url>
      <doi>10.18653/v1/W16-5806</doi>
    </paper>
    <paper id="7">
      <title>A Neural Model for Language Identification in Code-Switched Tweets</title>
      <author><first>Aaron</first> <last>Jaech</last></author>
      <author><first>George</first> <last>Mulcaire</last></author>
      <author><first>Mari</first> <last>Ostendorf</last></author>
      <author><first>Noah A.</first> <last>Smith</last></author>
      <pages>60–64</pages>
      <url hash="7316dd9b">W16-5807</url>
      <doi>10.18653/v1/W16-5807</doi>
      <erratum id="1" hash="38797ee1">W16-5807e1</erratum>
    </paper>
    <paper id="8">
      <title><fixed-case>SAWT</fixed-case>: Sequence Annotation Web Tool</title>
      <author><first>Younes</first> <last>Samih</last></author>
      <author><first>Wolfgang</first> <last>Maier</last></author>
      <author><first>Laura</first> <last>Kallmeyer</last></author>
      <pages>65–70</pages>
      <url hash="065e2fe7">W16-5808</url>
      <doi>10.18653/v1/W16-5808</doi>
    </paper>
    <paper id="9">
      <title>Accurate <fixed-case>P</fixed-case>inyin-<fixed-case>E</fixed-case>nglish Codeswitched Language Identification</title>
      <author><first>Meng Xuan</first> <last>Xia</last></author>
      <author><first>Jackie Chi Kit</first> <last>Cheung</last></author>
      <pages>71–79</pages>
      <url hash="01c0af26">W16-5809</url>
      <doi>10.18653/v1/W16-5809</doi>
      <attachment type="attachment" hash="60223ca6">W16-5809.Attachment.zip</attachment>
    </paper>
    <paper id="10">
      <title>Unraveling the <fixed-case>E</fixed-case>nglish-<fixed-case>B</fixed-case>engali Code-Mixing Phenomenon</title>
      <author><first>Arunavha</first> <last>Chanda</last></author>
      <author><first>Dipankar</first> <last>Das</last></author>
      <author><first>Chandan</first> <last>Mazumdar</last></author>
      <pages>80–89</pages>
      <url hash="7218f74e">W16-5810</url>
      <doi>10.18653/v1/W16-5810</doi>
      <attachment type="attachment" hash="93d09c9f">W16-5810.Attachment.zip</attachment>
    </paper>
    <paper id="11">
      <title>Part-of-speech Tagging of Code-Mixed Social Media Text</title>
      <author><first>Souvick</first> <last>Ghosh</last></author>
      <author><first>Satanu</first> <last>Ghosh</last></author>
      <author><first>Dipankar</first> <last>Das</last></author>
      <pages>90–97</pages>
      <url hash="9cf862eb">W16-5811</url>
      <doi>10.18653/v1/W16-5811</doi>
      <attachment type="attachment" hash="e6e8d681">W16-5811.Attachment.zip</attachment>
    </paper>
    <paper id="12">
      <title>Part of Speech Tagging for Code Switched Data</title>
      <author><first>Fahad</first> <last>AlGhamdi</last></author>
      <author><first>Giovanni</first> <last>Molina</last></author>
      <author><first>Mona</first> <last>Diab</last></author>
      <author><first>Thamar</first> <last>Solorio</last></author>
      <author><first>Abdelati</first> <last>Hawwari</last></author>
      <author><first>Victor</first> <last>Soto</last></author>
      <author><first>Julia</first> <last>Hirschberg</last></author>
      <pages>98–107</pages>
      <url hash="97fe96c6">W16-5812</url>
      <doi>10.18653/v1/W16-5812</doi>
      <attachment type="attachment" hash="c5fb361a">W16-5812.Attachment.zip</attachment>
    </paper>
    <paper id="13">
      <title>The <fixed-case>G</fixed-case>eorge <fixed-case>W</fixed-case>ashington <fixed-case>U</fixed-case>niversity System for the Code-Switching Workshop Shared Task 2016</title>
      <author><first>Mohamed</first> <last>Al-Badrashiny</last></author>
      <author><first>Mona</first> <last>Diab</last></author>
      <pages>108–111</pages>
      <url hash="12b64979">W16-5813</url>
      <doi>10.18653/v1/W16-5813</doi>
    </paper>
    <paper id="14">
      <title><fixed-case>C</fixed-case>olumbia-Jadavpur submission for <fixed-case>EMNLP</fixed-case> 2016 Code-Switching Workshop Shared Task: System description</title>
      <author><first>Arunavha</first> <last>Chanda</last></author>
      <author><first>Dipankar</first> <last>Das</last></author>
      <author><first>Chandan</first> <last>Mazumdar</last></author>
      <pages>112–115</pages>
      <url hash="c796d396">W16-5814</url>
      <doi>10.18653/v1/W16-5814</doi>
    </paper>
    <paper id="15">
      <title>The <fixed-case>H</fixed-case>oward <fixed-case>U</fixed-case>niversity System Submission for the Shared Task in Language Identification in <fixed-case>S</fixed-case>panish-<fixed-case>E</fixed-case>nglish Codeswitching</title>
      <author><first>Rouzbeh</first> <last>Shirvani</last></author>
      <author><first>Mario</first> <last>Piergallini</last></author>
      <author><first>Gauri Shankar</first> <last>Gautam</last></author>
      <author><first>Mohamed</first> <last>Chouikha</last></author>
      <pages>116–120</pages>
      <url hash="1ca58796">W16-5815</url>
      <doi>10.18653/v1/W16-5815</doi>
    </paper>
    <paper id="16">
      <title>Codeswitching Detection via Lexical Features in Conditional Random Fields</title>
      <author><first>Prajwol</first> <last>Shrestha</last></author>
      <pages>121–126</pages>
      <url hash="c269e0d6">W16-5816</url>
      <doi>10.18653/v1/W16-5816</doi>
    </paper>
    <paper id="17">
      <title>Language Identification in Code-Switched Text Using Conditional Random Fields and Babelnet</title>
      <author><first>Utpal Kumar</first> <last>Sikdar</last></author>
      <author><first>Björn</first> <last>Gambäck</last></author>
      <pages>127–131</pages>
      <url hash="f41d5a44">W16-5817</url>
      <doi>10.18653/v1/W16-5817</doi>
    </paper>
    <paper id="18">
      <title>Codeswitching language identification using Subword Information Enriched Word Vectors</title>
      <author><first>Meng Xuan</first> <last>Xia</last></author>
      <pages>132–136</pages>
      <url hash="3ed4cbcb">W16-5818</url>
      <doi>10.18653/v1/W16-5818</doi>
    </paper>
  </volume>
  <volume id="59">
    <meta>
      <booktitle>Proceedings of the Workshop on Structured Prediction for <fixed-case>NLP</fixed-case></booktitle>
      <url hash="d15c6610">W16-59</url>
      <editor><first>Kai-Wei</first><last>Chang</last></editor>
      <editor><first>Ming-Wei</first><last>Chang</last></editor>
      <editor><first>Alexander</first><last>Rush</last></editor>
      <editor><first>Vivek</first><last>Srikumar</last></editor>
      <doi>10.18653/v1/W16-59</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Austin, TX</address>
      <month>November</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="5a641380">W16-5900</url>
    </frontmatter>
    <paper id="1">
      <title>Inside-Outside and Forward-Backward Algorithms Are Just Backprop (tutorial paper)</title>
      <author><first>Jason</first> <last>Eisner</last></author>
      <pages>1–17</pages>
      <url hash="357325c1">W16-5901</url>
      <doi>10.18653/v1/W16-5901</doi>
    </paper>
    <paper id="2">
      <title>Research on attention memory networks as a model for learning natural language inference</title>
      <author><first>Zhuang</first> <last>Liu</last></author>
      <author><first>Degen</first> <last>Huang</last></author>
      <author><first>Jing</first> <last>Zhang</last></author>
      <author><first>Kaiyu</first> <last>Huang</last></author>
      <pages>18–24</pages>
      <url hash="d8fe1c0d">W16-5902</url>
      <doi>10.18653/v1/W16-5902</doi>
    </paper>
    <paper id="3">
      <title>A Joint Model of Rhetorical Discourse Structure and Summarization</title>
      <author><first>Naman</first> <last>Goyal</last></author>
      <author><first>Jacob</first> <last>Eisenstein</last></author>
      <pages>25–34</pages>
      <url hash="2463c3ba">W16-5903</url>
      <doi>10.18653/v1/W16-5903</doi>
    </paper>
    <paper id="4">
      <title>Posterior regularization for Joint Modeling of Multiple Structured Prediction Tasks with Soft Constraints</title>
      <author><first>Kartik</first> <last>Goyal</last></author>
      <author><first>Chris</first> <last>Dyer</last></author>
      <pages>35–43</pages>
      <url hash="06141b17">W16-5904</url>
      <doi>10.18653/v1/W16-5904</doi>
    </paper>
    <paper id="5">
      <title>A Study of Imitation Learning Methods for Semantic Role Labeling</title>
      <author><first>Travis</first> <last>Wolfe</last></author>
      <author><first>Mark</first> <last>Dredze</last></author>
      <author><first>Benjamin</first> <last>Van Durme</last></author>
      <pages>44–53</pages>
      <url hash="56d485b8">W16-5905</url>
      <doi>10.18653/v1/W16-5905</doi>
    </paper>
    <paper id="6">
      <title>Introducing <fixed-case>DRAIL</fixed-case> – a Step Towards Declarative Deep Relational Learning</title>
      <author><first>Xiao</first> <last>Zhang</last></author>
      <author><first>Maria Leonor</first> <last>Pacheco</last></author>
      <author><first>Chang</first> <last>Li</last></author>
      <author><first>Dan</first> <last>Goldwasser</last></author>
      <pages>54–62</pages>
      <url hash="e45bb71e">W16-5906</url>
      <doi>10.18653/v1/W16-5906</doi>
    </paper>
    <paper id="7">
      <title>Unsupervised Neural Hidden <fixed-case>M</fixed-case>arkov Models</title>
      <author><first>Ke M.</first> <last>Tran</last></author>
      <author><first>Yonatan</first> <last>Bisk</last></author>
      <author><first>Ashish</first> <last>Vaswani</last></author>
      <author><first>Daniel</first> <last>Marcu</last></author>
      <author><first>Kevin</first> <last>Knight</last></author>
      <pages>63–71</pages>
      <url hash="66f053f7">W16-5907</url>
      <doi>10.18653/v1/W16-5907</doi>
    </paper>
  </volume>
  <volume id="60">
    <meta>
      <booktitle>Proceedings of the Workshop on Uphill Battles in Language Processing: Scaling Early Achievements to Robust Methods</booktitle>
      <url hash="f06a93e7">W16-60</url>
      <editor><first>Annie</first><last>Louis</last></editor>
      <editor><first>Michael</first><last>Roth</last></editor>
      <editor><first>Bonnie</first><last>Webber</last></editor>
      <editor><first>Michael</first><last>White</last></editor>
      <editor><first>Luke</first><last>Zettlemoyer</last></editor>
      <doi>10.18653/v1/W16-60</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Austin, TX</address>
      <month>November</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="19589eb0">W16-6000</url>
    </frontmatter>
    <paper id="1">
      <title>An Analysis of Prerequisite Skills for Reading Comprehension</title>
      <author><first>Saku</first> <last>Sugawara</last></author>
      <author><first>Akiko</first> <last>Aizawa</last></author>
      <pages>1–5</pages>
      <url hash="efcecdd5">W16-6001</url>
      <doi>10.18653/v1/W16-6001</doi>
    </paper>
    <paper id="2">
      <title>Bridging the gap between computable and expressive event representations in Social Media</title>
      <author><first>Darina</first> <last>Benikova</last></author>
      <author><first>Torsten</first> <last>Zesch</last></author>
      <pages>6–10</pages>
      <url hash="7cf80347">W16-6002</url>
      <doi>10.18653/v1/W16-6002</doi>
      <attachment type="attachment" hash="ba00dd4d">W16-6002.Attachment.pdf</attachment>
    </paper>
    <paper id="3">
      <title>Statistical Script Learning with Recurrent Neural Networks</title>
      <author><first>Karl</first> <last>Pichotta</last></author>
      <author><first>Raymond</first> <last>Mooney</last></author>
      <pages>11–16</pages>
      <url hash="c5558460">W16-6003</url>
      <doi>10.18653/v1/W16-6003</doi>
    </paper>
    <paper id="4">
      <title>Moving away from semantic overfitting in disambiguation datasets</title>
      <author><first>Marten</first> <last>Postma</last></author>
      <author><first>Filip</first> <last>Ilievski</last></author>
      <author><first>Piek</first> <last>Vossen</last></author>
      <author><first>Marieke</first> <last>van Erp</last></author>
      <pages>17–21</pages>
      <url hash="db271c21">W16-6004</url>
      <doi>10.18653/v1/W16-6004</doi>
    </paper>
    <paper id="5">
      <title>Unsupervised Event Coreference for Abstract Words</title>
      <author><first>Dheeraj</first> <last>Rajagopal</last></author>
      <author><first>Eduard</first> <last>Hovy</last></author>
      <author><first>Teruko</first> <last>Mitamura</last></author>
      <pages>22–26</pages>
      <url hash="90c6f84c">W16-6005</url>
      <doi>10.18653/v1/W16-6005</doi>
    </paper>
    <paper id="6">
      <title>Towards Broad-coverage Meaning Representation: The Case of Comparison Structures</title>
      <author><first>Omid</first> <last>Bakhshandeh</last></author>
      <author><first>James</first> <last>Allen</last></author>
      <pages>27–31</pages>
      <url hash="406b8258">W16-6006</url>
      <doi>10.18653/v1/W16-6006</doi>
    </paper>
    <paper id="7">
      <title><fixed-case>D</fixed-case>ial<fixed-case>P</fixed-case>ort: A General Framework for Aggregating Dialog Systems</title>
      <author><first>Tiancheng</first> <last>Zhao</last></author>
      <author><first>Kyusong</first> <last>Lee</last></author>
      <author><first>Maxine</first> <last>Eskenazi</last></author>
      <pages>32–34</pages>
      <url hash="1b9ca104">W16-6007</url>
      <doi>10.18653/v1/W16-6007</doi>
    </paper>
    <paper id="8">
      <title><fixed-case>C</fixed-case>2<fixed-case>D</fixed-case>2<fixed-case>E</fixed-case>2: Using Call Centers to Motivate the Use of Dialog and Diarization in Entity Extraction</title>
      <author><first>Ken</first> <last>Church</last></author>
      <author><first>Weizhong</first> <last>Zhu</last></author>
      <author><first>Jason</first> <last>Pelecanos</last></author>
      <pages>35–38</pages>
      <url hash="dad08c9f">W16-6008</url>
      <doi>10.18653/v1/W16-6008</doi>
    </paper>
    <paper id="9">
      <title>Visualizing the Content of a Children’s Story in a Virtual World: Lessons Learned</title>
      <author><first>Quynh Ngoc Thi</first> <last>Do</last></author>
      <author><first>Steven</first> <last>Bethard</last></author>
      <author><first>Marie-Francine</first> <last>Moens</last></author>
      <pages>39–42</pages>
      <url hash="fb02fe81">W16-6009</url>
      <doi>10.18653/v1/W16-6009</doi>
    </paper>
    <paper id="10">
      <title>Stylistic Transfer in Natural Language Generation Systems Using Recurrent Neural Networks</title>
      <author><first>Jad</first> <last>Kabbara</last></author>
      <author><first>Jackie Chi Kit</first> <last>Cheung</last></author>
      <pages>43–47</pages>
      <url hash="0fb03252">W16-6010</url>
      <doi>10.18653/v1/W16-6010</doi>
    </paper>
    <paper id="11">
      <title>Using Language Groundings for Context-Sensitive Text Prediction</title>
      <author><first>Timothy</first> <last>Lewis</last></author>
      <author><first>Cynthia</first> <last>Matuszek</last></author>
      <author><first>Amy</first> <last>Hurst</last></author>
      <author><first>Matthew</first> <last>Taylor</last></author>
      <pages>48–52</pages>
      <url hash="9fa4f897">W16-6011</url>
      <doi>10.18653/v1/W16-6011</doi>
    </paper>
    <paper id="12">
      <title>Towards a continuous modeling of natural language domains</title>
      <author><first>Sebastian</first> <last>Ruder</last></author>
      <author><first>Parsa</first> <last>Ghaffari</last></author>
      <author><first>John G.</first> <last>Breslin</last></author>
      <pages>53–57</pages>
      <url hash="7735d0bf">W16-6012</url>
      <doi>10.18653/v1/W16-6012</doi>
    </paper>
  </volume>
  <volume id="61">
    <meta>
      <booktitle>Proceedings of the Seventh International Workshop on Health Text Mining and Information Analysis</booktitle>
      <url hash="f8e89075">W16-61</url>
      <editor><first>Cyril</first> <last>Grouin</last></editor>
      <editor><first>Thierry</first> <last>Hamon</last></editor>
      <editor><first>Aurélie</first> <last>Névéol</last></editor>
      <editor><first>Pierre</first> <last>Zweigenbaum</last></editor>
      <doi>10.18653/v1/W16-61</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Auxtin, TX</address>
      <month>November</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="efb9f44b">W16-6100</url>
    </frontmatter>
    <paper id="1">
      <title>An Investigation of Recurrent Neural Architectures for Drug Name Recognition</title>
      <author><first>Raghavendra</first> <last>Chalapathy</last></author>
      <author><first>Ehsan</first> <last>Zare Borzeshi</last></author>
      <author><first>Massimo</first> <last>Piccardi</last></author>
      <pages>1–5</pages>
      <url hash="f7ca0275">W16-6101</url>
      <doi>10.18653/v1/W16-6101</doi>
    </paper>
    <paper id="2">
      <title>Clinical Text Prediction with Numerically Grounded Conditional Language Models</title>
      <author><first>Georgios</first> <last>Spithourakis</last></author>
      <author><first>Steffen</first> <last>Petersen</last></author>
      <author><first>Sebastian</first> <last>Riedel</last></author>
      <pages>6–16</pages>
      <url hash="a1f7a2db">W16-6102</url>
      <doi>10.18653/v1/W16-6102</doi>
    </paper>
    <paper id="3">
      <title>Modelling Radiological Language with Bidirectional Long Short-Term Memory Networks</title>
      <author><first>Savelie</first> <last>Cornegruta</last></author>
      <author><first>Robert</first> <last>Bakewell</last></author>
      <author><first>Samuel</first> <last>Withey</last></author>
      <author><first>Giovanni</first> <last>Montana</last></author>
      <pages>17–27</pages>
      <url hash="d9105091">W16-6103</url>
      <doi>10.18653/v1/W16-6103</doi>
    </paper>
    <paper id="4">
      <title>Data Resource Acquisition from People at Various Stages of Cognitive Decline – Design and Exploration Considerations</title>
      <author><first>Dimitrios</first> <last>Kokkinakis</last></author>
      <author><first>Kristina</first> <last>Lundholm Fors</last></author>
      <author><first>Arto</first> <last>Nordlund</last></author>
      <pages>28–36</pages>
      <url hash="dc7d9c1c">W16-6104</url>
      <doi>10.18653/v1/W16-6104</doi>
    </paper>
    <paper id="5">
      <title>Analysis of Anxious Word Usage on Online Health Forums</title>
      <author><first>Nicolas</first> <last>Rey-Villamizar</last></author>
      <author><first>Prasha</first> <last>Shrestha</last></author>
      <author><first>Farig</first> <last>Sadeque</last></author>
      <author><first>Steven</first> <last>Bethard</last></author>
      <author><first>Ted</first> <last>Pedersen</last></author>
      <author><first>Arjun</first> <last>Mukherjee</last></author>
      <author><first>Thamar</first> <last>Solorio</last></author>
      <pages>37–42</pages>
      <url hash="a914eb56">W16-6105</url>
      <doi>10.18653/v1/W16-6105</doi>
    </paper>
    <paper id="6">
      <title>Retrofitting Word Vectors of <fixed-case>M</fixed-case>e<fixed-case>SH</fixed-case> Terms to Improve Semantic Similarity Measures</title>
      <author><first>Zhiguo</first> <last>Yu</last></author>
      <author><first>Trevor</first> <last>Cohen</last></author>
      <author><first>Byron</first> <last>Wallace</last></author>
      <author><first>Elmer</first> <last>Bernstam</last></author>
      <author><first>Todd</first> <last>Johnson</last></author>
      <pages>43–51</pages>
      <url hash="325458df">W16-6106</url>
      <doi>10.18653/v1/W16-6106</doi>
    </paper>
    <paper id="7">
      <title>Unsupervised Resolution of Acronyms and Abbreviations in Nursing Notes Using Document-Level Context Models</title>
      <author><first>Katrin</first> <last>Kirchhoff</last></author>
      <author><first>Anne M.</first> <last>Turner</last></author>
      <pages>52–60</pages>
      <url hash="668d092e">W16-6107</url>
      <doi>10.18653/v1/W16-6107</doi>
    </paper>
    <paper id="8">
      <title>Low-resource <fixed-case>OCR</fixed-case> error detection and correction in <fixed-case>F</fixed-case>rench Clinical Texts</title>
      <author><first>Eva</first> <last>D’hondt</last></author>
      <author><first>Cyril</first> <last>Grouin</last></author>
      <author><first>Brigitte</first> <last>Grau</last></author>
      <pages>61–68</pages>
      <url hash="52ee9d7c">W16-6108</url>
      <doi>10.18653/v1/W16-6108</doi>
    </paper>
    <paper id="9">
      <title>Citation Analysis with Neural Attention Models</title>
      <author><first>Tsendsuren</first> <last>Munkhdalai</last></author>
      <author><first>John P.</first> <last>Lalor</last></author>
      <author><first>Hong</first> <last>Yu</last></author>
      <pages>69–77</pages>
      <url hash="208dd615">W16-6109</url>
      <doi>10.18653/v1/W16-6109</doi>
    </paper>
    <paper id="10">
      <title>Replicability of Research in Biomedical Natural Language Processing: a pilot evaluation for a coding task</title>
      <author><first>Aurélie</first> <last>Névéol</last></author>
      <author><first>Kevin</first> <last>Cohen</last></author>
      <author><first>Cyril</first> <last>Grouin</last></author>
      <author><first>Aude</first> <last>Robert</last></author>
      <pages>78–84</pages>
      <url hash="42bf437a">W16-6110</url>
      <doi>10.18653/v1/W16-6110</doi>
    </paper>
    <paper id="11">
      <title><fixed-case>NLP</fixed-case> and Online Health Reports: What do we say and what do we mean?</title>
      <author><first>Nigel</first> <last>Collier</last></author>
      <pages>85</pages>
      <url hash="506606c7">W16-6111</url>
      <doi>10.18653/v1/W16-6111</doi>
    </paper>
    <paper id="12">
      <title>Leveraging coreference to identify arms in medical abstracts: An experimental study</title>
      <author><first>Elisa</first> <last>Ferracane</last></author>
      <author><first>Iain</first> <last>Marshall</last></author>
      <author><first>Byron C.</first> <last>Wallace</last></author>
      <author><first>Katrin</first> <last>Erk</last></author>
      <pages>86–95</pages>
      <url hash="cd3fab3a">W16-6112</url>
      <doi>10.18653/v1/W16-6112</doi>
      <attachment type="presentation" hash="07404348">W16-6112.Presentation.pdf</attachment>
    </paper>
    <paper id="13">
      <title>Hybrid methods for <fixed-case>ICD</fixed-case>-10 coding of death certificates</title>
      <author><first>Pierre</first> <last>Zweigenbaum</last></author>
      <author><first>Thomas</first> <last>Lavergne</last></author>
      <pages>96–105</pages>
      <url hash="7c13f2b4">W16-6113</url>
      <doi>10.18653/v1/W16-6113</doi>
    </paper>
    <paper id="14">
      <title>Exploring Query Expansion for Entity Searches in <fixed-case>P</fixed-case>ub<fixed-case>M</fixed-case>ed</title>
      <author><first>Chung-Chi</first> <last>Huang</last></author>
      <author><first>Zhiyong</first> <last>Lu</last></author>
      <pages>106–112</pages>
      <url hash="84f19b6e">W16-6114</url>
      <doi>10.18653/v1/W16-6114</doi>
    </paper>
  </volume>
  <volume id="62">
    <meta>
      <booktitle>Proceedings of The Fourth International Workshop on Natural Language Processing for Social Media</booktitle>
      <url hash="2fcd26a8">W16-62</url>
      <editor><first>Lun-Wei</first><last>Ku</last></editor>
      <editor><first>Jane Yung-jen</first><last>Hsu</last></editor>
      <editor><first>Cheng-Te</first><last>Li</last></editor>
      <doi>10.18653/v1/W16-62</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Austin, TX, USA</address>
      <month>November</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="0d86024a">W16-6200</url>
    </frontmatter>
    <paper id="1">
      <title>Identifying and Categorizing Disaster-Related Tweets</title>
      <author><first>Kevin</first> <last>Stowe</last></author>
      <author><first>Michael J.</first> <last>Paul</last></author>
      <author><first>Martha</first> <last>Palmer</last></author>
      <author><first>Leysia</first> <last>Palen</last></author>
      <author><first>Kenneth</first> <last>Anderson</last></author>
      <pages>1–6</pages>
      <url hash="ddcb63d4">W16-6201</url>
      <doi>10.18653/v1/W16-6201</doi>
      <attachment type="attachment" hash="90a3e4d9">W16-6201.Attachment.zip</attachment>
    </paper>
    <paper id="2">
      <title>Identifying Eyewitness News-worthy Events on <fixed-case>T</fixed-case>witter</title>
      <author><first>Erika</first> <last>Doggett</last></author>
      <author><first>Alejandro</first> <last>Cantarero</last></author>
      <pages>7–13</pages>
      <url hash="d57e51bb">W16-6202</url>
      <doi>10.18653/v1/W16-6202</doi>
    </paper>
    <paper id="3">
      <title>Why Do They Leave: Modeling Participation in Online Depression Forums</title>
      <author><first>Farig</first> <last>Sadeque</last></author>
      <author><first>Ted</first> <last>Pedersen</last></author>
      <author><first>Thamar</first> <last>Solorio</last></author>
      <author><first>Prasha</first> <last>Shrestha</last></author>
      <author><first>Nicolas</first> <last>Rey-Villamizar</last></author>
      <author><first>Steven</first> <last>Bethard</last></author>
      <pages>14–19</pages>
      <url hash="ee723813">W16-6203</url>
      <doi>10.18653/v1/W16-6203</doi>
      <attachment type="attachment" hash="1c6c5c18">W16-6203.Attachment.zip</attachment>
    </paper>
    <paper id="4">
      <title><fixed-case>T</fixed-case>witter at the Grammys: A Social Media Corpus for Entity Linking and Disambiguation</title>
      <author><first>Mark</first> <last>Dredze</last></author>
      <author><first>Nicholas</first> <last>Andrews</last></author>
      <author><first>Jay</first> <last>DeYoung</last></author>
      <pages>20–25</pages>
      <url hash="4483363a">W16-6204</url>
      <doi>10.18653/v1/W16-6204</doi>
    </paper>
    <paper id="5">
      <title>Steps Toward Automatic Understanding of the Function of Affective Language in Support Groups</title>
      <author><first>Amit</first> <last>Navindgi</last></author>
      <author><first>Caroline</first> <last>Brun</last></author>
      <author><first>Cécile</first> <last>Boulard Masson</last></author>
      <author><first>Scott</first> <last>Nowson</last></author>
      <pages>26–33</pages>
      <url hash="519f93cf">W16-6205</url>
      <doi>10.18653/v1/W16-6205</doi>
    </paper>
    <paper id="6">
      <title>Detecting Social Roles in <fixed-case>T</fixed-case>witter</title>
      <author><first>Sunghwan Mac</first> <last>Kim</last></author>
      <author><first>Stephen</first> <last>Wan</last></author>
      <author><first>Cécile</first> <last>Paris</last></author>
      <pages>34–40</pages>
      <url hash="ed0985a7">W16-6206</url>
      <doi>10.18653/v1/W16-6206</doi>
    </paper>
    <paper id="7">
      <title>Identifying Sensible Participants in Online Discussions</title>
      <author><first>Siddharth</first> <last>Jain</last></author>
      <pages>41–47</pages>
      <url hash="445a36d5">W16-6207</url>
      <doi>10.18653/v1/W16-6207</doi>
    </paper>
    <paper id="8">
      <title>emoji2vec: Learning Emoji Representations from their Description</title>
      <author><first>Ben</first> <last>Eisner</last></author>
      <author><first>Tim</first> <last>Rocktäschel</last></author>
      <author><first>Isabelle</first> <last>Augenstein</last></author>
      <author><first>Matko</first> <last>Bošnjak</last></author>
      <author><first>Sebastian</first> <last>Riedel</last></author>
      <pages>48–54</pages>
      <url hash="d4a5b199">W16-6208</url>
      <doi>10.18653/v1/W16-6208</doi>
    </paper>
    <paper id="9">
      <title>Learning Latent Local Conversation Modes for Predicting Comment Endorsement in Online Discussions</title>
      <author><first>Hao</first> <last>Fang</last></author>
      <author><first>Hao</first> <last>Cheng</last></author>
      <author><first>Mari</first> <last>Ostendorf</last></author>
      <pages>55–64</pages>
      <url hash="ac270412">W16-6209</url>
      <doi>10.18653/v1/W16-6209</doi>
    </paper>
    <paper id="10">
      <title>Witness Identification in <fixed-case>T</fixed-case>witter</title>
      <author><first>Rui</first> <last>Fang</last></author>
      <author><first>Armineh</first> <last>Nourbakhsh</last></author>
      <author><first>Xiaomo</first> <last>Liu</last></author>
      <author><first>Sameena</first> <last>Shah</last></author>
      <author><first>Quanzhi</first> <last>Li</last></author>
      <pages>65–73</pages>
      <url hash="fbf87645">W16-6210</url>
      <doi>10.18653/v1/W16-6210</doi>
    </paper>
    <paper id="11">
      <title>How Do <fixed-case>I</fixed-case> Look? Publicity Mining From Distributed Keyword Representation of Socially Infused News Articles</title>
      <author><first>Yu-Lun</first> <last>Hsieh</last></author>
      <author><first>Yung-Chun</first> <last>Chang</last></author>
      <author><first>Chun-Han</first> <last>Chu</last></author>
      <author><first>Wen-Lian</first> <last>Hsu</last></author>
      <pages>74–83</pages>
      <url hash="cf319b66">W16-6211</url>
      <doi>10.18653/v1/W16-6211</doi>
    </paper>
    <paper id="12">
      <title>Hierarchical Character-Word Models for Language Identification</title>
      <author><first>Aaron</first> <last>Jaech</last></author>
      <author><first>George</first> <last>Mulcaire</last></author>
      <author><first>Shobhit</first> <last>Hathi</last></author>
      <author><first>Mari</first> <last>Ostendorf</last></author>
      <author><first>Noah A.</first> <last>Smith</last></author>
      <pages>84–93</pages>
      <url hash="3b5da3b3">W16-6212</url>
      <doi>10.18653/v1/W16-6212</doi>
      <erratum id="1" hash="407a518f">W16-6212e1</erratum>
    </paper>
    <paper id="13">
      <title>Human versus Machine Attention in Document Classification: A Dataset with Crowdsourced Annotations</title>
      <author><first>Nikolaos</first> <last>Pappas</last></author>
      <author><first>Andrei</first> <last>Popescu-Belis</last></author>
      <pages>94–100</pages>
      <url hash="c93f62af">W16-6213</url>
      <doi>10.18653/v1/W16-6213</doi>
    </paper>
  </volume>
  <volume id="63">
    <meta>
      <booktitle>Proceedings of the 13th International Conference on Natural Language Processing</booktitle>
      <url hash="41519f1d">W16-63</url>
      <editor><first>Dipti Misra</first><last>Sharma</last></editor>
      <editor><first>Rajeev</first><last>Sangal</last></editor>
      <editor><first>Anil Kumar</first><last>Singh</last></editor>
      <publisher>NLP Association of India</publisher>
      <address>Varanasi, India</address>
      <month>December</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="04caa2b5">W16-6300</url>
    </frontmatter>
    <paper id="1">
      <title>Keynote Lecture 1: Practical Use of Machine Translation in International Organizations</title>
      <author><first>Bruno</first><last>Pouliquen</last></author>
      <pages>1</pages>
      <url hash="22c3d70f">W16-6301</url>
    </paper>
    <paper id="2">
      <title>Integrating <fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et for Multiple Sense Embeddings in Vector Semantics</title>
      <author><first>David</first><last>Foley</last></author>
      <author><first>Jugal</first><last>Kalita</last></author>
      <pages>2–9</pages>
      <url hash="c5506d00">W16-6302</url>
    </paper>
    <paper id="3">
      <title>Can <fixed-case>SMT</fixed-case> and <fixed-case>RBMT</fixed-case> Improve each other’s Performance?- An Experiment with <fixed-case>E</fixed-case>nglish-<fixed-case>H</fixed-case>indi Translation</title>
      <author><first>Debajyoty</first><last>Banik</last></author>
      <author><first>Sukanta</first><last>Sen</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>10–19</pages>
      <url hash="969a7a03">W16-6303</url>
    </paper>
    <paper id="4">
      <title>Composition of Compound Nouns Using Distributional Semantics</title>
      <author><first>Kyra</first><last>Yee</last></author>
      <author><first>Jugal</first><last>Kalita</last></author>
      <pages>20–29</pages>
      <url hash="f9b82938">W16-6304</url>
    </paper>
    <paper id="5">
      <title>Towards Building a <fixed-case>S</fixed-case>enti<fixed-case>W</fixed-case>ord<fixed-case>N</fixed-case>et for <fixed-case>T</fixed-case>amil</title>
      <author><first>Abishek</first><last>Kannan</last></author>
      <author><first>Gaurav</first><last>Mohanty</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <pages>30–35</pages>
      <url hash="b24de872">W16-6305</url>
    </paper>
    <paper id="6">
      <title>Extending <fixed-case>AIDA</fixed-case> framework by incorporating coreference resolution on detected mentions and pruning based on popularity of an entity</title>
      <author><first>Samaikya</first><last>Akarapu</last></author>
      <author><first>C Ravindranath</first><last>Chowdary</last></author>
      <pages>36–45</pages>
      <url hash="b7a0cf06">W16-6306</url>
    </paper>
    <paper id="7">
      <title>Sentence Based Discourse Classification for <fixed-case>H</fixed-case>indi Story Text-to-Speech (<fixed-case>TTS</fixed-case>) System</title>
      <author><first>Kumud</first><last>Tripathi</last></author>
      <author><first>Parakrant</first><last>Sarkar</last></author>
      <author><first>K. Sreenivasa</first><last>Rao</last></author>
      <pages>46–54</pages>
      <url hash="0a5aa3a7">W16-6307</url>
    </paper>
    <paper id="8">
      <title>Biomolecular Event Extraction using a Stacked Generalization based Classifier</title>
      <author><first>Amit</first><last>Majumder</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Sudip Kumar</first><last>Naskar</last></author>
      <pages>55–64</pages>
      <url hash="b770e6d4">W16-6308</url>
    </paper>
    <paper id="9">
      <title>Syntax and Pragmatics of Conversation: A Case of <fixed-case>B</fixed-case>angla</title>
      <author><first>Samir</first><last>Karmakar</last></author>
      <author><first>Soumya Sankar</first><last>Ghosh</last></author>
      <pages>65–70</pages>
      <url hash="f3b95e78">W16-6309</url>
    </paper>
    <paper id="10">
      <title>Dependency grammars as Haskell programs</title>
      <author><first>Tomasz</first><last>Obrębski</last></author>
      <pages>71–80</pages>
      <url hash="1446f3ef">W16-6310</url>
    </paper>
    <paper id="11">
      <title>Improving Document Ranking using Query Expansion and Classification Techniques for Mixed Script Information Retrieval</title>
      <author><first>Subham</first><last>Kumar</last></author>
      <author><first>Anwesh Sinha</first><last>Ray</last></author>
      <author><first>Sabyasachi</first><last>Kamila</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Sriparna</first><last>Saha</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>81–89</pages>
      <url hash="4192141a">W16-6311</url>
    </paper>
    <paper id="12">
      <title>Feature based Sentiment Analysis using a Domain Ontology</title>
      <author><first>Neha</first><last>Yadav</last></author>
      <author><first>C Ravindranath</first><last>Chowdary</last></author>
      <pages>90–98</pages>
      <url hash="6c7549ee">W16-6312</url>
    </paper>
    <paper id="13">
      <title>Cross-lingual transfer parser from <fixed-case>H</fixed-case>indi to <fixed-case>B</fixed-case>engali using delexicalization and chunking</title>
      <author><first>Ayan</first><last>Das</last></author>
      <author><first>Agnivo</first><last>Saha</last></author>
      <author><first>Sudeshna</first><last>Sarkar</last></author>
      <pages>99–108</pages>
      <url hash="ca94391d">W16-6313</url>
    </paper>
    <paper id="14">
      <title>Constraint Grammar-based conversion of Dependency Treebanks</title>
      <author><first>Eckhard</first><last>Bick</last></author>
      <pages>109–114</pages>
      <url hash="cf84f494">W16-6314</url>
    </paper>
    <paper id="15">
      <title>Meaning Matters: Senses of Words are More Informative than Words for Cross-domain Sentiment Analysis</title>
      <author><first>Raksha</first><last>Sharma</last></author>
      <author><first>Sudha</first><last>Bhingardive</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>115–119</pages>
      <url hash="8dfefafe">W16-6315</url>
    </paper>
    <paper id="16">
      <title><fixed-case>POS</fixed-case> Tagging Experts via Topic Modeling</title>
      <author><first>Atreyee</first><last>Mukherjee</last></author>
      <author><first>Sandra</first><last>Kübler</last></author>
      <author><first>Matthias</first><last>Scheutz</last></author>
      <pages>120–128</pages>
      <url hash="79cd3a1b">W16-6316</url>
    </paper>
    <paper id="17">
      <title>Graph theoretic interpretation of <fixed-case>B</fixed-case>angla traditional grammar</title>
      <author><first>Samir</first><last>Karmakar</last></author>
      <author><first>Sayantani</first><last>Banerjee</last></author>
      <author><first>Soumya</first><last>Ghosh</last></author>
      <pages>129–136</pages>
      <url hash="c941e057">W16-6317</url>
    </paper>
    <paper id="18">
      <title>A method for Automatic Text Summarization using Consensus of Multiple Similarity Measures and Ranking Techniques</title>
      <author><first>Mukesh Kumar</first><last>Jadon</last></author>
      <author><first>Ayush</first><last>Pareek</last></author>
      <pages>137–143</pages>
      <url hash="2c177248">W16-6318</url>
    </paper>
    <paper id="19">
      <title>Automatic Translation of <fixed-case>E</fixed-case>nglish Text to <fixed-case>I</fixed-case>ndian <fixed-case>S</fixed-case>ign <fixed-case>L</fixed-case>anguage Synthetic Animations</title>
      <author><first>Lalit</first><last>Goyal</last></author>
      <author><first>Vishal</first><last>Goyal</last></author>
      <pages>144–153</pages>
      <url hash="4653777e">W16-6319</url>
    </paper>
    <paper id="20">
      <title>Towards Deep Learning in <fixed-case>H</fixed-case>indi <fixed-case>NER</fixed-case>: An approach to tackle the Labelled Data Sparsity</title>
      <author><first>Vinayak</first><last>Athavale</last></author>
      <author><first>Shreenivas</first><last>Bharadwaj</last></author>
      <author><first>Monik</first><last>Pamecha</last></author>
      <author><first>Ameya</first><last>Prabhu</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <pages>154–160</pages>
      <url hash="064e837a">W16-6320</url>
    </paper>
    <paper id="21">
      <title><fixed-case>V</fixed-case>aidya: A Spoken Dialog System for Health Domain</title>
      <author><first>Prathyusha</first><last>Danda</last></author>
      <author><first>Brij Mohan Lal</first><last>Srivastava</last></author>
      <author><first>Manish</first><last>Shrivastava</last></author>
      <pages>161–166</pages>
      <url hash="284394fd">W16-6321</url>
    </paper>
    <paper id="22">
      <title>Cosmopolitan <fixed-case>M</fixed-case>umbai, Orthodox <fixed-case>D</fixed-case>elhi, Techcity <fixed-case>B</fixed-case>angalore:Understanding City Specific Societal Sentiment</title>
      <author><first>Aishwarya N</first><last>Reganti</last></author>
      <author><first>Tushar</first><last>Maheshwari</last></author>
      <author><first>Upendra</first><last>Kumar</last></author>
      <author><first>Amitava</first><last>Das</last></author>
      <pages>167–176</pages>
      <url hash="1cdc2af8">W16-6322</url>
    </paper>
    <paper id="23">
      <title>Keynote Lecture 2: Neural (and other Machine Learning) Approaches to Text Normalization</title>
      <author><first>Richard</first><last>Sproat</last></author>
      <pages>177</pages>
      <url hash="a22055d1">W16-6323</url>
    </paper>
    <paper id="24">
      <title>Wisdom of Students: A Consistent Automatic Short Answer Grading Technique</title>
      <author><first>Shourya</first><last>Roy</last></author>
      <author><first>Sandipan</first><last>Dandapat</last></author>
      <author><first>Ajay</first><last>Nagesh</last></author>
      <author><first>Y.</first><last>Narahari</last></author>
      <pages>178–187</pages>
      <url hash="39b7ecfd">W16-6324</url>
    </paper>
    <paper id="25">
      <title>A Recurrent Neural Network Architecture for De-identifying Clinical Records</title>
      <author><first/><last>Shweta</last></author>
      <author><first>Ankit</first><last>Kumar</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Sriparna</first><last>Saha</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>188–197</pages>
      <url hash="39566261">W16-6325</url>
    </paper>
    <paper id="26">
      <title><fixed-case>T</fixed-case>witter Named Entity Extraction and Linking Using Differential Evolution</title>
      <author><first>Utpal Kumar</first><last>Sikdar</last></author>
      <author><first>Björn</first><last>Gambäck</last></author>
      <pages>198–207</pages>
      <url hash="531dba80">W16-6326</url>
    </paper>
    <paper id="27">
      <title>Learning Non-Linear Functions for Text Classification</title>
      <author><first>Cohan Sujay</first><last>Carlos</last></author>
      <author><first>Geetanjali</first><last>Rakshit</last></author>
      <pages>208–218</pages>
      <url hash="6a26ceb1">W16-6327</url>
    </paper>
    <paper id="28">
      <title>A Computational Analysis of <fixed-case>M</fixed-case>ahabharata</title>
      <author><first>Debarati</first><last>Das</last></author>
      <author><first>Bhaskarjyoti</first><last>Das</last></author>
      <author><first>Kavi</first><last>Mahesh</last></author>
      <pages>219–228</pages>
      <url hash="7fc461c2">W16-6328</url>
    </paper>
    <paper id="29">
      <title>Use of Features for Accentuation of ghañanta Words</title>
      <author><first>Samir Janardan</first><last>Sohoni</last></author>
      <author><first>Malhar A.</first><last>Kulkarni</last></author>
      <pages>229–238</pages>
      <url hash="cf452445">W16-6329</url>
    </paper>
    <paper id="30">
      <title>Learning to Identify Subjective Sentences</title>
      <author><first>Girish K.</first><last>Palshikar</last></author>
      <author><first>Manoj</first><last>Apte</last></author>
      <author><first>Deepak</first><last>Pandita</last></author>
      <author><first>Vikram</first><last>Singh</last></author>
      <pages>239–248</pages>
      <url hash="aa40656b">W16-6330</url>
    </paper>
    <paper id="31">
      <title>Opinion Mining in a Code-Mixed Environment: A Case Study with Government Portals</title>
      <author><first>Deepak</first><last>Gupta</last></author>
      <author><first>Ankit</first><last>Lamba</last></author>
      <author><first>Asif</first><last>Ekbal</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>249–258</pages>
      <url hash="5ce15077">W16-6331</url>
    </paper>
    <paper id="32">
      <title>Use of Semantic Knowledge Base for Enhancement of Coherence of Code-mixed Topic-Based Aspect Clusters</title>
      <author><first>Kavita</first><last>Asnani</last></author>
      <author><first>Jyoti D</first><last>Pawar</last></author>
      <pages>259–266</pages>
      <url hash="7730f610">W16-6332</url>
    </paper>
    <paper id="33">
      <title>Genetic Algorithm (<fixed-case>GA</fixed-case>) Implementation for Feature Selection in <fixed-case>M</fixed-case>anipuri <fixed-case>POS</fixed-case> Tagging</title>
      <author><first>Kishorjit</first><last>Nongmeikapam</last></author>
      <author><first>Sivaji</first><last>Bandyopadhyay</last></author>
      <pages>267–274</pages>
      <url hash="d9f115a2">W16-6333</url>
    </paper>
    <paper id="34">
      <title>Effect of Syntactic Features in <fixed-case>B</fixed-case>angla Sentence Comprehension</title>
      <author><first>Manjira</first><last>Sinha</last></author>
      <author><first>Tirthankar</first><last>Dasgupta</last></author>
      <author><first>Anupam</first><last>Basu</last></author>
      <pages>275–284</pages>
      <url hash="50cf67d0">W16-6334</url>
    </paper>
    <paper id="35">
      <title>A New Feature Selection Technique Combined with <fixed-case>ELM</fixed-case> Feature Space for Text Classification</title>
      <author><first>Rajendra Kumar</first><last>Roul</last></author>
      <author><first>Pranav</first><last>Rai</last></author>
      <pages>285–292</pages>
      <url hash="de3459fc">W16-6335</url>
    </paper>
    <paper id="36">
      <title>On Why Coarse Class Classification is Bottleneck in Noun Compound Interpretation</title>
      <author><first>Girishkumar</first><last>Ponkiya</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <author><first>Girish K.</first><last>Palshikar</last></author>
      <pages>293–298</pages>
      <url hash="427b8424">W16-6336</url>
    </paper>
    <paper id="37">
      <title><fixed-case>V</fixed-case>erbframator:Semi-Automatic Verb Frame Annotator Tool with Special Reference to <fixed-case>M</fixed-case>arathi</title>
      <author><first>Hanumant</first><last>Redkar</last></author>
      <author><first>Sandhya</first><last>Singh</last></author>
      <author><first>Nandini</first><last>Ghag</last></author>
      <author><first>Jai</first><last>Paranjape</last></author>
      <author><first>Nilesh</first><last>Joshi</last></author>
      <author><first>Malhar</first><last>Kulkarni</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>299–304</pages>
      <url hash="8daaeeef">W16-6337</url>
    </paper>
    <paper id="38">
      <title>Towards Building A Domain Agnostic Natural Language Interface to Real-World Relational Databases</title>
      <author><first>Sree Harsha</first><last>Ramesh</last></author>
      <author><first>Jayant</first><last>Jain</last></author>
      <author><first>Sarath K</first><last>S</last></author>
      <author><first>Krishna R</first><last>Sundaresan</last></author>
      <pages>305–314</pages>
      <url hash="0283a988">W16-6338</url>
    </paper>
    <paper id="39">
      <title>Experimental Study of Vowels in <fixed-case>N</fixed-case>agamese, <fixed-case>A</fixed-case>o and <fixed-case>L</fixed-case>otha: Languages of <fixed-case>N</fixed-case>agaland</title>
      <author><first>Joyanta</first><last>Basu</last></author>
      <author><first>Tulika</first><last>Basu</last></author>
      <author><first>Soma</first><last>Khan</last></author>
      <author><first>Madhab</first><last>Pal</last></author>
      <author><first>Rajib</first><last>Roy</last></author>
      <author><first>Tapan Kumar</first><last>Basu</last></author>
      <pages>315–323</pages>
      <url hash="4f9b7c7f">W16-6339</url>
    </paper>
    <paper id="40">
      <title>Perception of Phi-Phrase boundaries in <fixed-case>H</fixed-case>indi.</title>
      <author><first>Somnath</first><last>Roy</last></author>
      <pages>324–330</pages>
      <url hash="c8317f88">W16-6340</url>
    </paper>
  </volume>
  <volume id="64">
    <meta>
      <booktitle>Proceedings of the 2nd Deep Machine Translation Workshop</booktitle>
      <url hash="3bf46f74">W16-64</url>
      <editor><first>Jan</first><last>Hajič</last></editor>
      <editor><first>Gertjan</first><last>van Noord</last></editor>
      <editor><first>António</first><last>Branco</last></editor>
      <publisher>ÚFAL MFF UK</publisher>
      <address>Lisbon, Portugal</address>
      <month>October</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="142b62c6">W16-6400</url>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>M</fixed-case>oses &amp; Treex Hybrid <fixed-case>MT</fixed-case> Systems Bestiary</title>
      <author><first>Rudolf</first> <last>Rosa</last></author>
      <author><first>Martin</first> <last>Popel</last></author>
      <author><first>Ondřej</first> <last>Bojar</last></author>
      <author><first>David</first> <last>Mareček</last></author>
      <author><first>Ondřej</first> <last>Dušek</last></author>
      <url hash="b7815992">W16-6401</url>
      <pages>1-10</pages>
    </paper>
    <paper id="2">
      <title>Factoring Adjunction in Hierarchical Phrase-Based <fixed-case>SMT</fixed-case></title>
      <author><first>Sophie</first> <last>Arnoult</last></author>
      <author><first>Khalil</first> <last>Sima’an</last></author>
      <url hash="f9f14e36">W16-6402</url>
      <pages>11-20</pages>
    </paper>
    <paper id="3">
      <title>A Hybrid Approach for Deep Machine Translation</title>
      <author><first>Kiril</first> <last>Simov</last></author>
      <author><first>Petya</first> <last>Osenova</last></author>
      <url hash="e8803939">W16-6403</url>
      <pages>21-28</pages>
    </paper>
    <paper id="4">
      <title>Deeper Machine Translation and Evaluation for <fixed-case>G</fixed-case>erman</title>
      <author><first>Eleftherios</first> <last>Avramidis</last></author>
      <author><first>Vivien</first> <last>Macketanz</last></author>
      <author><first>Aljoscha</first> <last>Burchardt</last></author>
      <author><first>Jindrich</first> <last>Helcl</last></author>
      <author><first>Hans</first> <last>Uszkoreit</last></author>
      <url hash="99b6e9e2">W16-6404</url>
      <pages>29-38</pages>
    </paper>
    <paper id="5">
      <title>Adding syntactic structure to bilingual terminology for improved domain adaptation</title>
      <author><first>Mikel</first> <last>Artetxe</last></author>
      <author><first>Gorka</first> <last>Labaka</last></author>
      <author><first>Chakaveh</first> <last>Saedi</last></author>
      <author><first>João</first> <last>Rodrigues</last></author>
      <author><first>João</first> <last>Silva</last></author>
      <author><first>António</first> <last>Branco</last></author>
      <author><first>Eneko</first> <last>Agirre</last></author>
      <url hash="448d6504">W16-6405</url>
      <pages>39-46</pages>
    </paper>
    <paper id="6">
      <title>Incorporation of a valency lexicon into a <fixed-case>T</fixed-case>ecto<fixed-case>MT</fixed-case> pipeline</title>
      <author><first>Natalia</first> <last>Klyueva</last></author>
      <author><first>Vladislav</first> <last>Kuboň</last></author>
      <url hash="5cd97c57">W16-6406</url>
      <pages>47-53</pages>
    </paper>
  </volume>
  <volume id="65">
    <meta>
      <booktitle>Proceedings of the joint workshop on <fixed-case>NLP</fixed-case> for Computer Assisted Language Learning and <fixed-case>NLP</fixed-case> for Language Acquisition</booktitle>
      <editor><first>Elena</first><last>Volodina</last></editor>
      <editor><first>Gintarė</first><last>Grigonytė</last></editor>
      <editor><first>Ildikó</first><last>Pilán</last></editor>
      <editor><first>Kristina Nilsson</first><last>Björkenstam</last></editor>
      <editor><first>Lars</first><last>Borin</last></editor>
      <publisher>LiU Electronic Press</publisher>
      <address>Umeå, Sweden</address>
      <month>November</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="207196c1">W16-6500</url>
    </frontmatter>
    <paper id="1">
      <title>From distributions to labels: A lexical proficiency analysis using learner corpora</title>
      <author><first>David</first> <last>Alfter</last></author>
      <author><first>Yuri</first> <last>Bizzoni</last></author>
      <author><first>Anders</first> <last>Agebjörn</last></author>
      <author><first>Elena</first> <last>Volodina</last></author>
      <author><first>Ildikó</first> <last>Pilán</last></author>
      <pages>1–7</pages>
      <url hash="8f20b7e0">W16-6501</url>
    </paper>
    <paper id="2">
      <title>Towards error annotation in a learner corpus of <fixed-case>P</fixed-case>ortuguese</title>
      <author><first>Iria</first> <last>del Río</last></author>
      <author><first>Sandra</first> <last>Antunes</last></author>
      <author><first>Amália</first> <last>Mendes</last></author>
      <author><first>Maarten</first> <last>Janssen</last></author>
      <pages>8–17</pages>
      <url hash="94c1ade7">W16-6502</url>
    </paper>
    <paper id="3">
      <title>Word comprehension and multilingualism among toddlers: A study using touch screens in daycares</title>
      <author><first>Laia</first> <last>Fibla</last></author>
      <author><first>Charlotte</first> <last>Maniel</last></author>
      <author><first>Alejandrina</first> <last>Cristia</last></author>
      <pages>18–23</pages>
      <url hash="f5c71672">W16-6503</url>
    </paper>
    <paper id="4">
      <title>The Language <fixed-case>EN</fixed-case>vironment Analysis (<fixed-case>LENA</fixed-case>) system: A literature review</title>
      <author><first>Hillary</first> <last>Ganek</last></author>
      <author><first>Alice</first> <last>Eriks-Brophy</last></author>
      <pages>24–32</pages>
      <url hash="c8eb09a3">W16-6504</url>
    </paper>
    <paper id="5">
      <title>Perception of lexical tones by <fixed-case>S</fixed-case>wedish learners of <fixed-case>M</fixed-case>andarin</title>
      <author><first>Man</first> <last>Gao</last></author>
      <pages>33–40</pages>
      <url hash="e3c73950">W16-6505</url>
    </paper>
    <paper id="6">
      <title>Language-independent exploration of repetition and variation in longitudinal child-directed speech: A tool and resources</title>
      <author><first>Gintarė</first> <last>Grigonytė</last></author>
      <author><first>Kristina</first> <last>Nilsson Björkenstam</last></author>
      <pages>41–50</pages>
      <url hash="68f00215">W16-6506</url>
    </paper>
    <paper id="7">
      <title>Validating bundled gap filling – Empirical evidence for ambiguity reduction and language proficiency testing capabilities</title>
      <author><first>Niklas</first> <last>Meyer</last></author>
      <author><first>Michael</first> <last>Wojatzki</last></author>
      <author><first>Torsten</first> <last>Zesch</last></author>
      <pages>51–59</pages>
      <url hash="b8963a96">W16-6507</url>
    </paper>
    <paper id="8">
      <title>Faking Intelligent <fixed-case>CALL</fixed-case>: The <fixed-case>I</fixed-case>rish context and the road ahead</title>
      <author><first>Neasa</first> <last>Ní Chiaráin</last></author>
      <author><first>Ailbhe</first> <last>Ní Chasaide</last></author>
      <pages>60–65</pages>
      <url hash="fc74153e">W16-6508</url>
    </paper>
    <paper id="9">
      <title>Building a learner corpus for <fixed-case>R</fixed-case>ussian</title>
      <author><first>Ekaterina</first> <last>Rakhilina</last></author>
      <author><first>Anastasia</first> <last>Vyrenkova</last></author>
      <author><first>Elmira</first> <last>Mustakimova</last></author>
      <author><first>Alina</first> <last>Ladygina</last></author>
      <author><first>Ivan</first> <last>Smirnov</last></author>
      <pages>66–75</pages>
      <url hash="ae0596fd">W16-6509</url>
    </paper>
    <paper id="10">
      <title><fixed-case>S</fixed-case>we<fixed-case>LL</fixed-case>ex: Second language learners’ productive vocabulary</title>
      <author><first>Elena</first> <last>Volodina</last></author>
      <author><first>Ildikó</first> <last>Pilán</last></author>
      <author><first>Lorena</first> <last>Llozhi</last></author>
      <author><first>Baptiste</first> <last>Degryse</last></author>
      <author><first>Thomas</first> <last>François</last></author>
      <pages>76–84</pages>
      <url hash="a62a9556">W16-6510</url>
    </paper>
  </volume>
  <volume id="66">
    <meta>
      <booktitle>Proceedings of the 9th International Natural Language Generation conference</booktitle>
      <url hash="143df86b">W16-66</url>
      <doi>10.18653/v1/W16-66</doi>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Edinburgh, UK</address>
      <month>September 5-8</month>
      <year>2016</year>
    </meta>
    <frontmatter>
      <url hash="c7bd042a">W16-6600</url>
    </frontmatter>
    <paper id="1">
      <title>Summarising News Stories for Children</title>
      <author><first>Iain</first> <last>Macdonald</last></author>
      <author><first>Advaith</first> <last>Siddharthan</last></author>
      <pages>1–10</pages>
      <url hash="5078c475">W16-6601</url>
      <doi>10.18653/v1/W16-6601</doi>
    </paper>
    <paper id="2">
      <title>Discourse-Driven Narrative Generation With Bipartite Planning</title>
      <author><first>David</first> <last>Winer</last></author>
      <author><first>R. Michael</first> <last>Young</last></author>
      <pages>11–20</pages>
      <url hash="fd40c902">W16-6602</url>
      <doi>10.18653/v1/W16-6602</doi>
    </paper>
    <paper id="3">
      <title>Generating <fixed-case>E</fixed-case>nglish from <fixed-case>A</fixed-case>bstract <fixed-case>M</fixed-case>eaning <fixed-case>R</fixed-case>epresentations</title>
      <author><first>Nima</first> <last>Pourdamghani</last></author>
      <author><first>Kevin</first> <last>Knight</last></author>
      <author><first>Ulf</first> <last>Hermjakob</last></author>
      <pages>21–25</pages>
      <url hash="e4566408">W16-6603</url>
      <doi>10.18653/v1/W16-6603</doi>
    </paper>
    <paper id="4">
      <title>Generating summaries of hospitalizations: A new metric to assess the complexity of medical terms and their definitions</title>
      <author><first>Sabita</first> <last>Acharya</last></author>
      <author><first>Barbara</first> <last>Di Eugenio</last></author>
      <author><first>Andrew D.</first> <last>Boyd</last></author>
      <author><first>Karen</first> <last>Dunn Lopez</last></author>
      <author><first>Richard</first> <last>Cameron</last></author>
      <author><first>Gail M</first> <last>Keenan</last></author>
      <pages>26–30</pages>
      <url hash="00b6acc1">W16-6604</url>
      <doi>10.18653/v1/W16-6604</doi>
    </paper>
    <paper id="5">
      <title>Designing Algorithms for Referring with Proper Names</title>
      <author><first>Kees</first> <last>van Deemter</last></author>
      <pages>31–35</pages>
      <url hash="eeefa65b">W16-6605</url>
      <doi>10.18653/v1/W16-6605</doi>
    </paper>
    <paper id="6">
      <title>When to Plummet and When to Soar: Corpus Based Verb Selection for Natural Language Generation</title>
      <author><first>Charese</first> <last>Smiley</last></author>
      <author><first>Vassilis</first> <last>Plachouras</last></author>
      <author><first>Frank</first> <last>Schilder</last></author>
      <author><first>Hiroko</first> <last>Bretz</last></author>
      <author><first>Jochen</first> <last>Leidner</last></author>
      <author><first>Dezhao</first> <last>Song</last></author>
      <pages>36–39</pages>
      <url hash="900c5362">W16-6606</url>
      <doi>10.18653/v1/W16-6606</doi>
    </paper>
    <paper id="7">
      <title>Sketch-to-Text Generation: Toward Contextual, Creative, and Coherent Composition</title>
      <author><first>Yejin</first> <last>Choi</last></author>
      <pages>40</pages>
      <url hash="7e903906">W16-6607</url>
      <doi>10.18653/v1/W16-6607</doi>
    </paper>
    <paper id="8">
      <title>Abstractive Compression of Captions with Attentive Recurrent Neural Networks</title>
      <author><first>Sander</first> <last>Wubben</last></author>
      <author><first>Emiel</first> <last>Krahmer</last></author>
      <author><first>Antal</first> <last>van den Bosch</last></author>
      <author><first>Suzan</first> <last>Verberne</last></author>
      <pages>41–50</pages>
      <url hash="e462b9a8">W16-6608</url>
      <doi>10.18653/v1/W16-6608</doi>
    </paper>
    <paper id="9">
      <title>Infusing <fixed-case>NLU</fixed-case> into Automatic Question Generation</title>
      <author><first>Karen</first> <last>Mazidi</last></author>
      <author><first>Paul</first> <last>Tarau</last></author>
      <pages>51–60</pages>
      <url hash="4f6793f5">W16-6609</url>
      <doi>10.18653/v1/W16-6609</doi>
    </paper>
    <paper id="10">
      <title>Automatic label generation for news comment clusters</title>
      <author><first>Ahmet</first> <last>Aker</last></author>
      <author><first>Monica</first> <last>Paramita</last></author>
      <author><first>Emina</first> <last>Kurtic</last></author>
      <author><first>Adam</first> <last>Funk</last></author>
      <author><first>Emma</first> <last>Barker</last></author>
      <author><first>Mark</first> <last>Hepple</last></author>
      <author><first>Rob</first> <last>Gaizauskas</last></author>
      <pages>61–69</pages>
      <url hash="cb62158f">W16-6610</url>
      <doi>10.18653/v1/W16-6610</doi>
    </paper>
    <paper id="11">
      <title>Improving Fluency in Narrative Text Generation With Grammatical Transformations and Probabilistic Parsing</title>
      <author><first>Emily</first> <last>Ahn</last></author>
      <author><first>Fabrizio</first> <last>Morbini</last></author>
      <author><first>Andrew</first> <last>Gordon</last></author>
      <pages>70–73</pages>
      <url hash="408e49ef">W16-6611</url>
      <doi>10.18653/v1/W16-6611</doi>
    </paper>
    <paper id="12">
      <title>The Multilingual Affective Soccer Corpus (<fixed-case>MASC</fixed-case>): Compiling a biased parallel corpus on soccer reportage in <fixed-case>E</fixed-case>nglish, <fixed-case>G</fixed-case>erman and <fixed-case>D</fixed-case>utch</title>
      <author><first>Nadine</first> <last>Braun</last></author>
      <author><first>Martijn</first> <last>Goudbeek</last></author>
      <author><first>Emiel</first> <last>Krahmer</last></author>
      <pages>74–78</pages>
      <url hash="e978412c">W16-6612</url>
      <doi>10.18653/v1/W16-6612</doi>
    </paper>
    <paper id="13">
      <title>Challenges of Argument Mining: Generating an Argument Synthesis based on the Qualia Structure</title>
      <author><first>Patrick</first> <last>Saint-Dizier</last></author>
      <pages>79–83</pages>
      <url hash="099011fc">W16-6613</url>
      <doi>10.18653/v1/W16-6613</doi>
    </paper>
    <paper id="14">
      <title>Tense and Aspect in <fixed-case>R</fixed-case>unyankore Using a Context-Free Grammar</title>
      <author><first>Joan</first> <last>Byamugisha</last></author>
      <author><first>C. Maria</first> <last>Keet</last></author>
      <author><first>Brian</first> <last>DeRenzi</last></author>
      <pages>84–88</pages>
      <url hash="449f56f5">W16-6614</url>
      <doi>10.18653/v1/W16-6614</doi>
    </paper>
    <paper id="15">
      <title>Task demands and individual variation in referring expressions</title>
      <author><first>Adriana</first> <last>Baltaretu</last></author>
      <author><first>Thiago</first> <last>Castro Ferreira</last></author>
      <pages>89–93</pages>
      <url hash="7ed9501c">W16-6615</url>
      <doi>10.18653/v1/W16-6615</doi>
    </paper>
    <paper id="16">
      <title>Category-Driven Content Selection</title>
      <author><first>Rania</first> <last>Mohammed</last></author>
      <author><first>Laura</first> <last>Perez-Beltrachini</last></author>
      <author><first>Claire</first> <last>Gardent</last></author>
      <pages>94–98</pages>
      <url hash="6a868169">W16-6616</url>
      <doi>10.18653/v1/W16-6616</doi>
    </paper>
    <paper id="17">
      <title>Evaluative Pattern Extraction for Automated Text Generation</title>
      <author><first>Chia-Chen</first> <last>Lee</last></author>
      <author><first>Shu-Kai</first> <last>Hsieh</last></author>
      <pages>99–103</pages>
      <url hash="b3b82b51">W16-6617</url>
      <doi>10.18653/v1/W16-6617</doi>
    </paper>
    <paper id="18">
      <title>Statistics-Based Lexical Choice for <fixed-case>NLG</fixed-case> from Quantitative Information</title>
      <author><first>Xiao</first> <last>Li</last></author>
      <author><first>Kees</first> <last>van Deemter</last></author>
      <author><first>Chenghua</first> <last>Lin</last></author>
      <pages>104–108</pages>
      <url hash="ef45d8df">W16-6618</url>
      <doi>10.18653/v1/W16-6618</doi>
    </paper>
    <paper id="19">
      <title>Incremental Generation of Visually Grounded Language in Situated Dialogue (demonstration system)</title>
      <author><first>Yanchao</first> <last>Yu</last></author>
      <author><first>Arash</first> <last>Eshghi</last></author>
      <author><first>Oliver</first> <last>Lemon</last></author>
      <pages>109–110</pages>
      <url hash="c56e117f">W16-6619</url>
      <doi>10.18653/v1/W16-6619</doi>
    </paper>
    <paper id="20">
      <title>Unsupervised Sentence Simplification Using Deep Semantics</title>
      <author><first>Shashi</first> <last>Narayan</last></author>
      <author><first>Claire</first> <last>Gardent</last></author>
      <pages>111–120</pages>
      <url hash="af54a3e8">W16-6620</url>
      <doi>10.18653/v1/W16-6620</doi>
    </paper>
    <paper id="21">
      <title>Enabling text readability awareness during the micro planning phase of <fixed-case>NLG</fixed-case> applications</title>
      <author><first>Priscilla</first> <last>Moraes</last></author>
      <author><first>Kathleen</first> <last>Mccoy</last></author>
      <author><first>Sandra</first> <last>Carberry</last></author>
      <pages>121–131</pages>
      <url hash="12d69569">W16-6621</url>
      <doi>10.18653/v1/W16-6621</doi>
    </paper>
    <paper id="22">
      <title>How can we adapt generation to the user’s cognitive load?</title>
      <author><first>Vera</first> <last>Demberg</last></author>
      <pages>132</pages>
      <url hash="c0102f19">W16-6622</url>
      <doi>10.18653/v1/W16-6622</doi>
    </paper>
    <paper id="23">
      <title>Selecting Domain-Specific Concepts for Question Generation With Lightly-Supervised Methods</title>
      <author><first>Yiping</first> <last>Jin</last></author>
      <author><first>Phu</first> <last>Le</last></author>
      <pages>133–142</pages>
      <url hash="77dc5aa5">W16-6623</url>
      <doi>10.18653/v1/W16-6623</doi>
    </paper>
    <paper id="24">
      <title>Statistical Natural Language Generation from Tabular Non-textual Data</title>
      <author><first>Joy</first> <last>Mahapatra</last></author>
      <author><first>Sudip Kumar</first> <last>Naskar</last></author>
      <author><first>Sivaji</first> <last>Bandyopadhyay</last></author>
      <pages>143–152</pages>
      <url hash="deafeb7e">W16-6624</url>
      <doi>10.18653/v1/W16-6624</doi>
    </paper>
    <paper id="25">
      <title>Paraphrase Generation from Latent-Variable <fixed-case>PCFG</fixed-case>s for Semantic Parsing</title>
      <author><first>Shashi</first> <last>Narayan</last></author>
      <author><first>Siva</first> <last>Reddy</last></author>
      <author><first>Shay B.</first> <last>Cohen</last></author>
      <pages>153–162</pages>
      <url hash="41102a84">W16-6625</url>
      <doi>10.18653/v1/W16-6625</doi>
    </paper>
    <paper id="26">
      <title>The <fixed-case>W</fixed-case>eb<fixed-case>NLG</fixed-case> Challenge: Generating Text from <fixed-case>DBP</fixed-case>edia Data</title>
      <author><first>Emilie</first> <last>Colin</last></author>
      <author><first>Claire</first> <last>Gardent</last></author>
      <author><first>Yassine</first> <last>M’rabet</last></author>
      <author><first>Shashi</first> <last>Narayan</last></author>
      <author><first>Laura</first> <last>Perez-Beltrachini</last></author>
      <pages>163–167</pages>
      <url hash="317dcb99">W16-6626</url>
      <doi>10.18653/v1/W16-6626</doi>
    </paper>
    <paper id="27">
      <title>The a<fixed-case>NAL</fixed-case>o<fixed-case>G</fixed-case>u<fixed-case>E</fixed-case> Challenge: Non Aligned Language <fixed-case>GE</fixed-case>neration</title>
      <author><first>Jekaterina</first> <last>Novikova</last></author>
      <author><first>Verena</first> <last>Rieser</last></author>
      <pages>168–170</pages>
      <url hash="5985e139">W16-6627</url>
      <doi>10.18653/v1/W16-6627</doi>
    </paper>
    <paper id="28">
      <title>A Challenge Proposal for Narrative Generation Using <fixed-case>CNL</fixed-case>s</title>
      <author><first>Eugenio</first> <last>Concepción</last></author>
      <author><first>Gonzalo</first> <last>Méndez</last></author>
      <author><first>Pablo</first> <last>Gervás</last></author>
      <author><first>Carlos</first> <last>León</last></author>
      <pages>171–173</pages>
      <url hash="62583539">W16-6628</url>
      <doi>10.18653/v1/W16-6628</doi>
    </paper>
    <paper id="29">
      <title>On the verbalization patterns of part-whole relations in isi<fixed-case>Z</fixed-case>ulu</title>
      <author><first>C. Maria</first> <last>Keet</last></author>
      <author><first>Langa</first> <last>Khumalo</last></author>
      <pages>174–183</pages>
      <url hash="0cb20520">W16-6629</url>
      <doi>10.18653/v1/W16-6629</doi>
    </paper>
    <paper id="30">
      <title><fixed-case>S</fixed-case>imple<fixed-case>NLG</fixed-case>-<fixed-case>IT</fixed-case>: adapting <fixed-case>S</fixed-case>imple<fixed-case>NLG</fixed-case> to <fixed-case>I</fixed-case>talian</title>
      <author><first>Alessandro</first> <last>Mazzei</last></author>
      <author><first>Cristina</first> <last>Battaglino</last></author>
      <author><first>Cristina</first> <last>Bosco</last></author>
      <pages>184–192</pages>
      <url hash="370969b6">W16-6630</url>
      <doi>10.18653/v1/W16-6630</doi>
    </paper>
    <paper id="31">
      <title>Don’t Mention the Shoe! A Learning to Rank Approach to Content Selection for Image Description Generation</title>
      <author><first>Josiah</first> <last>Wang</last></author>
      <author><first>Robert</first> <last>Gaizauskas</last></author>
      <pages>193–202</pages>
      <url hash="8f0b5a89">W16-6631</url>
      <doi>10.18653/v1/W16-6631</doi>
    </paper>
    <paper id="32">
      <title>Good Automatic Authentication Question Generation</title>
      <author><first>Simon</first> <last>Woo</last></author>
      <author><first>Zuyao</first> <last>Li</last></author>
      <author><first>Jelena</first> <last>Mirkovic</last></author>
      <pages>203–206</pages>
      <url hash="e923794a">W16-6632</url>
      <doi>10.18653/v1/W16-6632</doi>
    </paper>
    <paper id="33">
      <title>Automatic Generation of Student Report Cards</title>
      <author><first>Amy</first> <last>Isard</last></author>
      <author><first>Jeremy</first> <last>Knox</last></author>
      <pages>207–211</pages>
      <url hash="942f8910">W16-6633</url>
      <doi>10.18653/v1/W16-6633</doi>
    </paper>
    <paper id="34">
      <title>Collecting Reliable Human Judgements on Machine-Generated Language: The Case of the <fixed-case>QG</fixed-case>-<fixed-case>STEC</fixed-case> Data</title>
      <author><first>Keith</first> <last>Godwin</last></author>
      <author><first>Paul</first> <last>Piwek</last></author>
      <pages>212–216</pages>
      <url hash="572322e5">W16-6634</url>
      <doi>10.18653/v1/W16-6634</doi>
    </paper>
    <paper id="35">
      <title>Ranking Automatically Generated Questions Using Common Human Queries</title>
      <author><first>Yllias</first> <last>Chali</last></author>
      <author><first>Sina</first> <last>Golestanirad</last></author>
      <pages>217–221</pages>
      <url hash="4770ffd5">W16-6635</url>
      <doi>10.18653/v1/W16-6635</doi>
    </paper>
    <paper id="36">
      <title>Towards proper name generation: a corpus analysis</title>
      <author><first>Thiago</first> <last>Castro Ferreira</last></author>
      <author><first>Sander</first> <last>Wubben</last></author>
      <author><first>Emiel</first> <last>Krahmer</last></author>
      <pages>222–226</pages>
      <url hash="acf441e7">W16-6636</url>
      <doi>10.18653/v1/W16-6636</doi>
    </paper>
    <paper id="37">
      <title>An Analysis of the Ability of Statistical Language Models to Capture the Structural Properties of Language</title>
      <author><first>Aneiss</first> <last>Ghodsi</last></author>
      <author><first>John</first> <last>DeNero</last></author>
      <pages>227–231</pages>
      <url hash="bfe4c817">W16-6637</url>
      <doi>10.18653/v1/W16-6637</doi>
    </paper>
    <paper id="38">
      <title>Enhancing <fixed-case>PTB</fixed-case> <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies for Grammar-Based Surface Realization</title>
      <author><first>David L.</first> <last>King</last></author>
      <author><first>Michael</first> <last>White</last></author>
      <pages>232–236</pages>
      <url hash="e6097215">W16-6638</url>
      <doi>10.18653/v1/W16-6638</doi>
    </paper>
    <paper id="39">
      <title>Effect of Data Annotation, Feature Selection and Model Choice on Spatial Description Generation in <fixed-case>F</fixed-case>rench</title>
      <author><first>Anja</first> <last>Belz</last></author>
      <author><first>Adrian</first> <last>Muscat</last></author>
      <author><first>Brandon</first> <last>Birmingham</last></author>
      <author><first>Jessie</first> <last>Levacher</last></author>
      <author><first>Julie</first> <last>Pain</last></author>
      <author><first>Adam</first> <last>Quinquenel</last></author>
      <pages>237–241</pages>
      <url hash="a44a091b">W16-6639</url>
      <doi>10.18653/v1/W16-6639</doi>
    </paper>
    <paper id="40">
      <title><fixed-case>QGASP</fixed-case>: a Framework for Question Generation Based on Different Levels of Linguistic Information</title>
      <author><first>Hugo</first> <last>Patinho Rodrigues</last></author>
      <author><first>Luísa</first> <last>Coheur</last></author>
      <author><first>Eric</first> <last>Nyberg</last></author>
      <pages>242–243</pages>
      <url hash="ca09ebc3">W16-6640</url>
      <doi>10.18653/v1/W16-6640</doi>
    </paper>
    <paper id="41">
      <title>Automatic Reports from Spreadsheets: Data Analysis for the Rest of Us</title>
      <author><first>Pablo</first> <last>Duboue</last></author>
      <pages>244–245</pages>
      <url hash="0012c719">W16-6641</url>
      <doi>10.18653/v1/W16-6641</doi>
    </paper>
    <paper id="42">
      <title>Towards Generating Colour Terms for Referents in Photographs: Prefer the Expected or the Unexpected?</title>
      <author><first>Sina</first> <last>Zarrieß</last></author>
      <author><first>David</first> <last>Schlangen</last></author>
      <pages>246–255</pages>
      <url hash="c3410323">W16-6642</url>
      <doi>10.18653/v1/W16-6642</doi>
    </paper>
    <paper id="43">
      <title>Absolute and Relative Properties in Geographic Referring Expressions</title>
      <author><first>Rodrigo</first> <last>de Oliveira</last></author>
      <author><first>Somayajulu</first> <last>Sripada</last></author>
      <author><first>Ehud</first> <last>Reiter</last></author>
      <pages>256–264</pages>
      <url hash="2daf6b2b">W16-6643</url>
      <doi>10.18653/v1/W16-6643</doi>
    </paper>
    <paper id="44">
      <title>Crowd-sourcing <fixed-case>NLG</fixed-case> Data: Pictures Elicit Better Data.</title>
      <author><first>Jekaterina</first> <last>Novikova</last></author>
      <author><first>Oliver</first> <last>Lemon</last></author>
      <author><first>Verena</first> <last>Rieser</last></author>
      <pages>265–273</pages>
      <url hash="3a6245de">W16-6644</url>
      <doi>10.18653/v1/W16-6644</doi>
    </paper>
  </volume>
</collection>
