<?xml version='1.0' encoding='UTF-8'?>
<collection id="2023.dmr">
  <volume id="1" ingest-date="2023-10-22" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Fourth International Workshop on Designing Meaning Representations</booktitle>
      <editor><first>Julia</first><last>Bonn</last></editor>
      <editor><first>Nianwen</first><last>Xue</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Nancy, France</address>
      <month>June</month>
      <year>2023</year>
      <url hash="8f135e66">2023.dmr-1</url>
      <venue>dmr</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="97b81357">2023.dmr-1.0</url>
      <bibkey>dmr-2023-international</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Structural and Global Features for Comparing Semantic Representation Formalisms</title>
      <author><first>Siyana</first><last>Pavlova</last></author>
      <author><first>Maxime</first><last>Amblard</last></author>
      <author><first>Bruno</first><last>Guillaume</last></author>
      <pages>1–12</pages>
      <abstract>The area of designing semantic/meaning representations is a dynamic one with new formalisms and extensions being proposed continuously. It may be challenging for users of semantic representations to select the relevant formalism for their purpose or for newcomers to the field to select the features they want to represent in a new formalism. In this paper, we propose a set of structural and global features to consider when designing formalisms, and against which formalisms can be compared. We also propose a sample comparison of a number of existing formalisms across the selected features, complemented by a more entailment-oriented comparison on the phenomena of the FraCaS corpus.</abstract>
      <url hash="e24542bc">2023.dmr-1.1</url>
      <bibkey>pavlova-etal-2023-structural</bibkey>
    </paper>
    <paper id="2">
      <title>Evaluation of Universal Semantic Representation (<fixed-case>USR</fixed-case>)</title>
      <author><first>Kirti</first><last>Garg</last></author>
      <author><first>Soma</first><last>Paul</last></author>
      <author><first>Sukhada</first><last>Sukhada</last></author>
      <author><first>Fatema</first><last>Bawahir</last></author>
      <author><first>Riya</first><last>Kumari</last></author>
      <pages>13–22</pages>
      <abstract>Universal Semantic Representation (USR) is designed as a language-independent information packaging system that captures information at three levels: (a) Lexico-conceptual, (b) Syntactico-Semantic, and (c) Discourse. Unlike other representations that mainly encode predicates and their argument structures, our proposed representation captures the speaker’s vivakṣā- how the speaker views the activity. The idea of “speaker’s vivakṣā is inspired by Indian Grammatical Tradition. There can be some amount of idiosyncrasy of the speaker in the annotation since it is the speaker’s view- point that has been captured in the annotation. Hence the evaluation metrics of such resources need to be also thought through from scratch. This paper presents an extensive evaluation procedure of this semantic representation from two perspectives (a) Inter- Annotator Agreement and (b) one downstream task, namely multilingual Natural Language Generation. We also qualitatively evaluate the experience of natural language generation by manual parsing of USR, so as to understand the readability of USR. We have achieved above 80% Inter-Annotator Agreement for USR annotations and above 80% semantic closeness in multi-lingual generation tasks suggesting the reliability of USR annotations and utility for multi-lingual generations. The qualitative evaluation also suggests high readability and hence the utility of USR as a semantic representation.</abstract>
      <url hash="f947197e">2023.dmr-1.2</url>
      <bibkey>garg-etal-2023-evaluation</bibkey>
    </paper>
    <paper id="3">
      <title>Comparing <fixed-case>UMR</fixed-case> and Cross-lingual Adaptations of <fixed-case>AMR</fixed-case></title>
      <author><first>Shira</first><last>Wein</last></author>
      <author><first>Julia</first><last>Bonn</last></author>
      <pages>23–33</pages>
      <abstract>Abstract Meaning Representation (AMR) is a popular semantic annotation schema that presents sentence meaning as a graph while abstracting away from syntax. It was originally designed for English, but has since been extended to a variety of non-English versions of AMR. These cross-lingual adaptations, to varying degrees, incorporate language-specific features necessary to effectively capture the semantics of the language being annotated. Uniform Meaning Representation (UMR) on the other hand, the multilingual extension of AMR, was designed specifically for cross-lingual applications. In this work, we discuss these two approaches to extending AMR beyond English. We describe both approaches, compare the information they capture for a case language (Spanish), and outline implications for future work.</abstract>
      <url hash="cb94e632">2023.dmr-1.3</url>
      <bibkey>wein-bonn-2023-comparing</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>A</fixed-case>bstract <fixed-case>M</fixed-case>eaning <fixed-case>R</fixed-case>epresentation for Grounded Human-Robot Communication</title>
      <author><first>Claire</first><last>Bonial</last></author>
      <author><first>Julie</first><last>Foresta</last></author>
      <author><first>Nicholas C.</first><last>Fung</last></author>
      <author><first>Cory J.</first><last>Hayes</last></author>
      <author><first>Philip</first><last>Osteen</last></author>
      <author><first>Jacob</first><last>Arkin</last></author>
      <author><first>Benned</first><last>Hedegaard</last></author>
      <author><first>Thomas</first><last>Howard</last></author>
      <pages>34–44</pages>
      <abstract>To collaborate effectively in physically situated tasks, robots must be able to ground concepts in natural language to the physical objects in the environment as well as their own capabilities. We describe the implementation and the demonstration of a system architecture that sup- ports tasking robots using natural language. In this architecture, natural language instructions are first handled by a dialogue management component, which provides feedback to the user and passes executable instructions along to an Abstract Meaning Representation (AMR) parser. The parse distills the action primitives and parameters of the instructed behavior in the form of a directed a-cyclic graph, passed on to the grounding component. We find AMR to be an efficient formalism for grounding the nodes of the graph using a Distributed Correspondence Graph. Thus, in our approach, the concepts of language are grounded to entities in the robot’s world model, which is populated by its sensors, thereby enabling grounded natural language communication. The demonstration of this system will allow users to issue navigation commands in natural language to direct a simulated ground robot (running the Robot Operating System) to various landmarks observed by the user within a simulated environment.</abstract>
      <url hash="0b132a06">2023.dmr-1.4</url>
      <bibkey>bonial-etal-2023-abstract</bibkey>
    </paper>
    <paper id="5">
      <title>Annotating Situated Actions in Dialogue</title>
      <author><first>Christopher</first><last>Tam</last></author>
      <author><first>Richard</first><last>Brutti</last></author>
      <author><first>Kenneth</first><last>Lai</last></author>
      <author><first>James</first><last>Pustejovsky</last></author>
      <pages>45–51</pages>
      <abstract>Actions are critical for interpreting dialogue: they provide context for demonstratives and definite descriptions in discourse, and they continually update the common ground. This paper describes how Abstract Meaning Representation (AMR) can be used to annotate actions in multimodal human-human and human-object interactions. We conduct initial annotations of shared task and first-person point-of-view videos. We show that AMRs can be interpreted by a proxy language, such as VoxML, as executable annotation structures in order to recreate and simulate a series of annotated events.</abstract>
      <url hash="0185db45">2023.dmr-1.5</url>
      <bibkey>tam-etal-2023-annotating</bibkey>
    </paper>
    <paper id="6">
      <title>From Sentence to Action: Splitting <fixed-case>AMR</fixed-case> Graphs for Recipe Instructions</title>
      <author><first>Katharina</first><last>Stein</last></author>
      <author><first>Lucia</first><last>Donatelli</last></author>
      <author><first>Alexander</first><last>Koller</last></author>
      <pages>52–67</pages>
      <abstract>Accurately interpreting the relationships between actions in a recipe text is essential to successful recipe completion. We explore using Abstract Meaning Representation (AMR) to represent recipe instructions, abstracting away from syntax and sentence structure that may order recipe actions in arbitrary ways. We present an algorithm to split sentence-level AMRs into action-level AMRs for individual cooking steps. Our approach provides an automatic way to derive fine-grained AMR representations of actions in cooking recipes and can be a useful tool for downstream, instructional tasks.</abstract>
      <url hash="0a3aad7a">2023.dmr-1.6</url>
      <bibkey>stein-etal-2023-sentence</bibkey>
    </paper>
    <paper id="7">
      <title>Meaning Representation of <fixed-case>E</fixed-case>nglish Prepositional Phrase Roles: <fixed-case>SNACS</fixed-case> Supersenses vs. Tectogrammatical Functors</title>
      <author><first>Wesley</first><last>Scivetti</last></author>
      <author><first>Nathan</first><last>Schneider</last></author>
      <pages>68–73</pages>
      <abstract>This work compares two ways of annotating semantic relations expressed in prepositional phrases: semantic classes in the Semantic Network of Adposition and Case Supersenses (SNACS), and tectogrammatical functors from the Prague English Dependency Treebank (PEDT). We compare the label definitions in the respective annotation guidelines to determine expected mappings, then check how well these work empirically using Wall Street Journal text. In the definitions we find substantial overlap in the distributions of the two schemata with respect to participants and circumstantials, but substantial divergence for configurational relationships between nominals. This is borne out by the empirical analysis. Examining the data more closely for participants and circumstantials reveals that there are some unexpected, yet systematic divergences between definitionally aligned groups.</abstract>
      <url hash="4b956520">2023.dmr-1.7</url>
      <bibkey>scivetti-schneider-2023-meaning</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>QA</fixed-case>-Adj: Adding Adjectives to <fixed-case>QA</fixed-case>-based Semantics</title>
      <author><first>Leon</first><last>Pesahov</last></author>
      <author><first>Ayal</first><last>Klein</last></author>
      <author><first>Ido</first><last>Dagan</last></author>
      <pages>74–88</pages>
      <abstract>Identifying all predicate-argument relations in a sentence has been a fundamental research target in NLP. While traditionally these relations were modeled via formal schemata, the recent QA-SRL paradigm (and its extensions) present appealing advantages of capturing such relations through intuitive natural language question-answer (QA) pairs. In this paper, we extend the QA-based semantics framework to cover adjectival predicates, which carry important information in many downstream settings yet have been scarcely addressed in NLP research. Firstly, based on some prior literature and empirical assessment, we propose capturing four types of core adjectival arguments, through corresponding question types. Notably, our coverage goes beyond prior annotations of adjectival arguments, while also explicating valuable implicit arguments. Next, we develop an extensive data annotation methodology, involving controlled crowdsourcing and targeted expert review. Following, we create a high-quality dataset, consisting of 9K adjective mentions with 12K predicate-argument instances (QAs). Finally, we present and analyze baseline models based on text-to-text language modeling, indicating challenges for future research, particularly regarding the scarce argument types. Overall, we suggest that our contributions can provide the basis for research on contemporary modeling of adjectival information.</abstract>
      <url hash="bd8349fd">2023.dmr-1.8</url>
      <attachment type="OptionalSupplementaryMaterial" hash="ebbcc2de">2023.dmr-1.8.OptionalSupplementaryMaterial.zip</attachment>
      <bibkey>pesahov-etal-2023-qa</bibkey>
    </paper>
    <paper id="9">
      <title>The long and the short of it: <fixed-case>DRASTIC</fixed-case>, a semantically annotated dataset containing sentences of more natural length</title>
      <author><first>Dag</first><last>Haug</last></author>
      <author><first>Jamie Yates</first><last>Findlay</last></author>
      <author><first>Ahmet</first><last>Yildirim</last></author>
      <pages>89–98</pages>
      <abstract>This paper presents a new dataset with Discourse Representation Structures (DRSs) annotated over naturally-occurring sentences. Importantly, these sentences are more varied in length and on average longer than those in the existing gold-standard DRS dataset, the Parallel Meaning Bank, and we show that they are therefore much harder for parsers. We argue, though, that this provides a more realistic assessment of the difficulties of DRS parsing.</abstract>
      <url hash="d991b90e">2023.dmr-1.9</url>
      <bibkey>haug-etal-2023-long</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>UMR</fixed-case> Annotation of Multiword Expressions</title>
      <author><first>Julia</first><last>Bonn</last></author>
      <author><first>Andrew</first><last>Cowell</last></author>
      <author><first>Jan</first><last>Hajič</last></author>
      <author><first>Alexis</first><last>Palmer</last></author>
      <author><first>Martha</first><last>Palmer</last></author>
      <author><first>James</first><last>Pustejovsky</last></author>
      <author><first>Haibo</first><last>Sun</last></author>
      <author><first>Zdenka</first><last>Uresova</last></author>
      <author><first>Shira</first><last>Wein</last></author>
      <author><first>Nianwen</first><last>Xue</last></author>
      <author><first>Jin</first><last>Zhao</last></author>
      <pages>99–109</pages>
      <abstract>Rooted in AMR, Uniform Meaning Representation (UMR) is a graph-based formalism with nodes as concepts and edges as relations between them. When used to represent natural language semantics, UMR maps words in a sentence to concepts in the UMR graph. Multiword expressions (MWEs) pose a particular challenge to UMR annotation because they deviate from the default one-to-one mapping between words and concepts. There are different types of MWEs which require different kinds of annotation that must be specified in guidelines. This paper discusses the specific treatment for each type of MWE in UMR.</abstract>
      <url hash="c861d258">2023.dmr-1.10</url>
      <bibkey>bonn-etal-2023-umr</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>MR</fixed-case>4<fixed-case>AP</fixed-case>: Meaning Representation for Application Purposes</title>
      <author><first>Bastien</first><last>Giordano</last></author>
      <author><first>Cédric</first><last>Lopez</last></author>
      <pages>110–121</pages>
      <abstract>Despite the significant progress made in Natural Language Processing (NLP) thanks to deep learning techniques, efforts are still needed to model explicit, factual, and accurate meaning representation formalisms. In this article, we present a comparative table of ten formalisms that have been proposed over the last thirty years, and we describe and put forth our own, Meaning Representation for Application Purposes (MR4AP), developed in an industrial context with a definitive applicative aim.</abstract>
      <url hash="7bf66312">2023.dmr-1.11</url>
      <bibkey>giordano-lopez-2023-mr4ap</bibkey>
    </paper>
    <paper id="12">
      <title>Claim Extraction via Subgraph Matching over Modal and Syntactic Dependencies</title>
      <author><first>Benjamin</first><last>Rozonoyer</last></author>
      <author><first>David</first><last>Zajic</last></author>
      <author><first>Ilana</first><last>Heintz</last></author>
      <author><first>Michael</first><last>Selvaggio</last></author>
      <pages>122–135</pages>
      <abstract>We propose the use of modal dependency parses (MDPs) aligned with syntactic dependency parse trees as an avenue for the novel task of claim extraction. MDPs provide a document-level structure that links linguistic expression of events to the conceivers responsible for those expressions. By defining the event-conceiver links as claims and using subgraph pattern matching to exploit the complementarity of these modal links and syntactic claim patterns, we outline a method for aggregating and classifying claims, with the potential for supplying a novel perspective on large natural language data sets. Abstracting away from the task of claim extraction, we prototype an interpretable information extraction (IE) paradigm over sentence- and document-level parse structures, framing inference as subgraph matching and learning as subgraph mining. We make our code open-sourced at https://github.com/BBN-E/nlp-graph-pattern-matching-and-mining.</abstract>
      <url hash="b84cf7e6">2023.dmr-1.12</url>
      <bibkey>rozonoyer-etal-2023-claim</bibkey>
    </paper>
    <paper id="13">
      <title>Which Argumentative Aspects of Hate Speech in Social Media can be reliably identified?</title>
      <author><first>Damián Ariel</first><last>Furman</last></author>
      <author><first>Pablo</first><last>Torres</last></author>
      <author><first>José A.</first><last>Rodríguez</last></author>
      <author><first>Laura</first><last>Alonso Alemany</last></author>
      <author><first>Diego</first><last>Letzen</last></author>
      <author><first>Vanina</first><last>Martínez</last></author>
      <pages>136–153</pages>
      <abstract>The expansion of Large Language Models (LLMs) into more serious areas of application, involving decision-making and the forming of public opinion, calls for a more thoughtful treatment of texts. Augmenting them with explicit and understandable argumentative analysis could foster a more reasoned usage of chatbots, text completion mechanisms or other applications. However, it is unclear which aspects of argumentation can be reliably identified and integrated by them. In this paper we propose an adaptation of Wagemans (2016)’s Periodic Table of Arguments to identify different argumentative aspects of texts, with a special focus on hate speech in social media. We have empirically assessed the reliability with which each of these aspects can be automatically identified. We analyze the implications of these results, and how to adapt the proposal to obtain reliable representations of those that cannot be successfully identified.</abstract>
      <url hash="50ff8e6f">2023.dmr-1.13</url>
      <attachment type="OptionalSupplementaryMaterial" hash="2695e071">2023.dmr-1.13.OptionalSupplementaryMaterial.zip</attachment>
      <bibkey>furman-etal-2023-argumentative</bibkey>
    </paper>
  </volume>
</collection>
