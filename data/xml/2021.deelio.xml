<?xml version='1.0' encoding='UTF-8'?>
<collection id="2021.deelio">
  <volume id="1" ingest-date="2021-05-24">
    <meta>
      <booktitle>Proceedings of Deep Learning Inside Out (DeeLIO): The 2nd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures</booktitle>
      <editor><first>Eneko</first><last>Agirre</last></editor>
      <editor><first>Marianna</first><last>Apidianaki</last></editor>
      <editor><first>Ivan</first><last>Vulić</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Online</address>
      <month>June</month>
      <year>2021</year>
      <url hash="85c83d62">2021.deelio-1</url>
      <venue>deelio</venue>
    </meta>
    <frontmatter>
      <url hash="3cc0ef1a">2021.deelio-1.0</url>
      <bibkey>deelio-2021-deep</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Transformer visualization via dictionary learning: contextualized embedding as a linear superposition of transformer factors</title>
      <author><first>Zeyu</first><last>Yun</last></author>
      <author><first>Yubei</first><last>Chen</last></author>
      <author><first>Bruno</first><last>Olshausen</last></author>
      <author><first>Yann</first><last>LeCun</last></author>
      <pages>1–10</pages>
      <abstract>Transformer networks have revolutionized NLP representation learning since they were introduced. Though a great effort has been made to explain the representation in transformers, it is widely recognized that our understanding is not sufficient. One important reason is that there lack enough visualization tools for detailed analysis. In this paper, we propose to use dictionary learning to open up these ‘black boxes’ as linear superpositions of transformer factors. Through visualization, we demonstrate the hierarchical semantic structures captured by the transformer factors, e.g., word-level polysemy disambiguation, sentence-level pattern formation, and long-range dependency. While some of these patterns confirm the conventional prior linguistic knowledge, the rest are relatively unexpected, which may provide new insights. We hope this visualization tool can bring further knowledge and a better understanding of how transformer networks work. The code is available at: https://github.com/zeyuyun1/TransformerVis.</abstract>
      <url hash="2e4d8e40">2021.deelio-1.1</url>
      <attachment type="OptionalSupplementaryData" hash="cb5139b2">2021.deelio-1.1.OptionalSupplementaryData.pdf</attachment>
      <doi>10.18653/v1/2021.deelio-1.1</doi>
      <bibkey>yun-etal-2021-transformer</bibkey>
      <pwccode url="https://github.com/zeyuyun1/transformervis" additional="false">zeyuyun1/transformervis</pwccode>
    </paper>
    <paper id="2">
      <title>Reconstructing Implicit Knowledge with Language Models</title>
      <author><first>Maria</first><last>Becker</last></author>
      <author><first>Siting</first><last>Liang</last></author>
      <author><first>Anette</first><last>Frank</last></author>
      <pages>11–24</pages>
      <abstract>In this work we propose an approach for generating statements that explicate implicit knowledge connecting sentences in text. We make use of pre-trained language models which we refine by fine-tuning them on specifically prepared corpora that we enriched with implicit information, and by constraining them with relevant concepts and connecting commonsense knowledge paths. Manual and automatic evaluation of the generations shows that by refining language models as proposed, we can generate coherent and grammatically sound sentences that explicate implicit knowledge which connects sentence pairs in texts – on both in-domain and out-of-domain test data.</abstract>
      <url hash="b31bb754">2021.deelio-1.2</url>
      <attachment type="OptionalSupplementaryData" hash="bb67909e">2021.deelio-1.2.OptionalSupplementaryData.pdf</attachment>
      <doi>10.18653/v1/2021.deelio-1.2</doi>
      <bibkey>becker-etal-2021-reconstructing</bibkey>
      <pwccode url="https://github.com/heidelberg-nlp/lms4implicit-knowledge-generation" additional="false">heidelberg-nlp/lms4implicit-knowledge-generation</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/genericskb">GenericsKB</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/snli">SNLI</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/e-snli">e-SNLI</pwcdataset>
    </paper>
    <paper id="3">
      <title>Investigating the Effect of Background Knowledge on Natural Questions</title>
      <author><first>Vidhisha</first><last>Balachandran</last></author>
      <author><first>Bhuwan</first><last>Dhingra</last></author>
      <author><first>Haitian</first><last>Sun</last></author>
      <author><first>Michael</first><last>Collins</last></author>
      <author><first>William</first><last>Cohen</last></author>
      <pages>25–30</pages>
      <abstract>Existing work shows the benefits of integrating KBs with textual evidence for QA only on questions that are answerable by KBs alone (Sun et al., 2019). In contrast, real world QA systems often have to deal with questions that might not be directly answerable by KBs. Here, we investigate the effect of integrating background knowledge from KBs for the Natural Questions (NQ) task. We create a subset of the NQ data, Factual Questions (FQ), where the questions have evidence in the KB in the form of paths that link question entities to answer entities but still must be answered using text, to facilitate further research into KB integration methods. We propose and analyze a simple, model-agnostic approach for incorporating KB paths into text-based QA systems and establish a strong upper bound on FQ for our method using an oracle retriever. We show that several variants of Personalized PageRank based fact retrievers lead to a low recall of answer entities and consequently fail to improve QA performance. Our results suggest that fact retrieval is a bottleneck for integrating KBs into real world QA datasets</abstract>
      <url hash="249681a0">2021.deelio-1.3</url>
      <doi>10.18653/v1/2021.deelio-1.3</doi>
      <bibkey>balachandran-etal-2021-investigating</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/natural-questions">Natural Questions</pwcdataset>
    </paper>
    <paper id="4">
      <title>Augmenting Topic Aware Knowledge-Grounded Conversations with Dynamic Built Knowledge Graphs</title>
      <author><first>Junjie</first><last>Wu</last></author>
      <author><first>Hao</first><last>Zhou</last></author>
      <pages>31–39</pages>
      <abstract>Dialog topic management and background knowledge selection are essential factors for the success of knowledge-grounded open-domain conversations. However, existing models are primarily performed with symmetric knowledge bases or stylized with pre-defined roles between conversational partners, while people usually have their own knowledge before a real chit-chat. To address this problem, we propose a dynamic knowledge graph-based topical conversation model (DKGT). Given a dialog history context, our model first builds knowledge graphs from the context as an imitation of human’s ability to form logical relationships between known and unknown topics during a conversation. This logical information will be fed into a topic predictor to promote topic management, then facilitate background knowledge selection and response generation. To the best of our knowledge, this is the first attempt to dynamically form knowledge graphs between chatting topics to assist dialog topic management during a conversation. Experimental results manifest that our model can properly schedule conversational topics and pick suitable knowledge to generate informative responses comparing to several strong baselines.</abstract>
      <url hash="c3c44be3">2021.deelio-1.4</url>
      <doi>10.18653/v1/2021.deelio-1.4</doi>
      <bibkey>wu-zhou-2021-augmenting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/topical-chat">Topical-Chat</pwcdataset>
    </paper>
    <paper id="5">
      <title>What Makes My Model Perplexed? A Linguistic Investigation on Neural Language Models Perplexity</title>
      <author><first>Alessio</first><last>Miaschi</last></author>
      <author><first>Dominique</first><last>Brunato</last></author>
      <author><first>Felice</first><last>Dell’Orletta</last></author>
      <author><first>Giulia</first><last>Venturi</last></author>
      <pages>40–47</pages>
      <abstract>This paper presents an investigation aimed at studying how the linguistic structure of a sentence affects the perplexity of two of the most popular Neural Language Models (NLMs), BERT and GPT-2. We first compare the sentence-level likelihood computed with BERT and the GPT-2’s perplexity showing that the two metrics are correlated. In addition, we exploit linguistic features capturing a wide set of morpho-syntactic and syntactic phenomena showing how they contribute to predict the perplexity of the two NLMs.</abstract>
      <url hash="6e44f56d">2021.deelio-1.5</url>
      <doi>10.18653/v1/2021.deelio-1.5</doi>
      <bibkey>miaschi-etal-2021-makes</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="6">
      <title>How Do <fixed-case>BERT</fixed-case> Embeddings Organize Linguistic Knowledge?</title>
      <author><first>Giovanni</first><last>Puccetti</last></author>
      <author><first>Alessio</first><last>Miaschi</last></author>
      <author><first>Felice</first><last>Dell’Orletta</last></author>
      <pages>48–57</pages>
      <abstract>Several studies investigated the linguistic information implicitly encoded in Neural Language Models. Most of these works focused on quantifying the amount and type of information available within their internal representations and across their layers. In line with this scenario, we proposed a different study, based on Lasso regression, aimed at understanding how the information encoded by BERT sentence-level representations is arrange within its hidden units. Using a suite of several probing tasks, we showed the existence of a relationship between the implicit knowledge learned by the model and the number of individual units involved in the encodings of this competence. Moreover, we found that it is possible to identify groups of hidden units more relevant for specific linguistic properties.</abstract>
      <url hash="04786039">2021.deelio-1.6</url>
      <doi>10.18653/v1/2021.deelio-1.6</doi>
      <bibkey>puccetti-etal-2021-bert</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/universal-dependencies">Universal Dependencies</pwcdataset>
    </paper>
    <paper id="7">
      <title><fixed-case>ERNIE</fixed-case>-<fixed-case>NLI</fixed-case>: Analyzing the Impact of Domain-Specific External Knowledge on Enhanced Representations for <fixed-case>NLI</fixed-case></title>
      <author><first>Lisa</first><last>Bauer</last></author>
      <author><first>Lingjia</first><last>Deng</last></author>
      <author><first>Mohit</first><last>Bansal</last></author>
      <pages>58–69</pages>
      <abstract>We examine the effect of domain-specific external knowledge variations on deep large scale language model performance. Recent work in enhancing BERT with external knowledge has been very popular, resulting in models such as ERNIE (Zhang et al., 2019a). Using the ERNIE architecture, we provide a detailed analysis on the types of knowledge that result in a performance increase on the Natural Language Inference (NLI) task, specifically on the Multi-Genre Natural Language Inference Corpus (MNLI). While ERNIE uses general TransE embeddings, we instead train domain-specific knowledge embeddings and insert this knowledge via an information fusion layer in the ERNIE architecture, allowing us to directly control and analyze knowledge input. Using several different knowledge training objectives, sources of knowledge, and knowledge ablations, we find a strong correlation between knowledge and classification labels within the same polarity, illustrating that knowledge polarity is an important feature in predicting entailment. We also perform classification change analysis across different knowledge variations to illustrate the importance of selecting appropriate knowledge input regarding content and polarity, and show representative examples of these changes.</abstract>
      <url hash="b0915a14">2021.deelio-1.7</url>
      <doi>10.18653/v1/2021.deelio-1.7</doi>
      <bibkey>bauer-etal-2021-ernie</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/multinli">MultiNLI</pwcdataset>
    </paper>
    <paper id="8">
      <title>Enhancing Multiple-Choice Question Answering with Causal Knowledge</title>
      <author><first>Dhairya</first><last>Dalal</last></author>
      <author><first>Mihael</first><last>Arcan</last></author>
      <author><first>Paul</first><last>Buitelaar</last></author>
      <pages>70–80</pages>
      <abstract>The task of causal question answering aims to reason about causes and effects over a provided real or hypothetical premise. Recent approaches have converged on using transformer-based language models to solve question answering tasks. However, pretrained language models often struggle when external knowledge is not present in the premise or when additional context is required to answer the question. To the best of our knowledge, no prior work has explored the efficacy of augmenting pretrained language models with external causal knowledge for multiple-choice causal question answering. In this paper, we present novel strategies for the representation of causal knowledge. Our empirical results demonstrate the efficacy of augmenting pretrained models with external causal knowledge. We show improved performance on the COPA (Choice of Plausible Alternatives) and WIQA (What If Reasoning Over Procedural Text) benchmark tasks. On the WIQA benchmark, our approach is competitive with the state-of-the-art and exceeds it within the evaluation subcategories of In-Paragraph and Out-of-Paragraph perturbations.</abstract>
      <url hash="319d7909">2021.deelio-1.8</url>
      <doi>10.18653/v1/2021.deelio-1.8</doi>
      <bibkey>dalal-etal-2021-enhancing</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/conceptnet">ConceptNet</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/wiqa">WIQA</pwcdataset>
    </paper>
    <paper id="9">
      <title>Low Anisotropy Sense Retrofitting (<fixed-case>LAS</fixed-case>e<fixed-case>R</fixed-case>) : Towards Isotropic and Sense Enriched Representations</title>
      <author><first>Geetanjali</first><last>Bihani</last></author>
      <author><first>Julia</first><last>Rayz</last></author>
      <pages>81–95</pages>
      <abstract>Contextual word representation models have shown massive improvements on a multitude of NLP tasks, yet their word sense disambiguation capabilities remain poorly explained. To address this gap, we assess whether contextual word representations extracted from deep pretrained language models create distinguishable representations for different senses of a given word. We analyze the representation geometry and find that most layers of deep pretrained language models create highly anisotropic representations, pointing towards the existence of representation degeneration problem in contextual word representations. After accounting for anisotropy, our study further reveals that there is variability in sense learning capabilities across different language models. Finally, we propose LASeR, a ‘Low Anisotropy Sense Retrofitting’ approach that renders off-the-shelf representations isotropic and semantically more meaningful, resolving the representation degeneration problem as a post-processing step, and conducting sense-enrichment of contextualized representations extracted from deep neural language models.</abstract>
      <url hash="f6a7a6e0">2021.deelio-1.9</url>
      <attachment type="OptionalSupplementaryData" hash="a1e42583">2021.deelio-1.9.OptionalSupplementaryData.zip</attachment>
      <doi>10.18653/v1/2021.deelio-1.9</doi>
      <bibkey>bihani-rayz-2021-low</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>KW</fixed-case>-<fixed-case>ATTN</fixed-case>: Knowledge Infused Attention for Accurate and Interpretable Text Classification</title>
      <author><first>Hyeju</first><last>Jang</last></author>
      <author><first>Seojin</first><last>Bang</last></author>
      <author><first>Wen</first><last>Xiao</last></author>
      <author><first>Giuseppe</first><last>Carenini</last></author>
      <author><first>Raymond</first><last>Ng</last></author>
      <author><first>Young ji</first><last>Lee</last></author>
      <pages>96–107</pages>
      <abstract>Text classification has wide-ranging applications in various domains. While neural network approaches have drastically advanced performance in text classification, they tend to be powered by a large amount of training data, and interpretability is often an issue. As a step towards better accuracy and interpretability especially on small data, in this paper we present a new knowledge-infused attention mechanism, called KW-ATTN (KnoWledge-infused ATTentioN) to incorporate high-level concepts from external knowledge bases into Neural Network models. We show that KW-ATTN outperforms baseline models using only words as well as other approaches using concepts by classification accuracy, which indicates that high-level concepts help model prediction. Furthermore, crowdsourced human evaluation suggests that additional concept information helps interpretability of the model.</abstract>
      <url hash="e21386b2">2021.deelio-1.10</url>
      <doi>10.18653/v1/2021.deelio-1.10</doi>
      <bibkey>jang-etal-2021-kw</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/yahoo-answers">Yahoo! Answers</pwcdataset>
    </paper>
    <paper id="11">
      <title>Multi-input Recurrent Independent Mechanisms for leveraging knowledge sources: Case studies on sentiment analysis and health text mining</title>
      <author><first>Parsa</first><last>Bagherzadeh</last></author>
      <author><first>Sabine</first><last>Bergler</last></author>
      <pages>108–118</pages>
      <abstract>This paper presents a way to inject and leverage existing knowledge from external sources in a Deep Learning environment, extending the recently proposed Recurrent Independent Mechnisms (RIMs) architecture, which comprises a set of interacting yet independent modules. We show that this extension of the RIMs architecture is an effective framework with lower parameter implications compared to purely fine-tuned systems.</abstract>
      <url hash="0f2d5479">2021.deelio-1.11</url>
      <doi>10.18653/v1/2021.deelio-1.11</doi>
      <bibkey>bagherzadeh-bergler-2021-multi</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/glue">GLUE</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/sst">SST</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/tweeteval">TweetEval</pwcdataset>
    </paper>
    <paper id="12">
      <title>What <fixed-case>BERT</fixed-case>s and <fixed-case>GPT</fixed-case>s know about your brand? Probing contextual language models for affect associations</title>
      <author><first>Vivek</first><last>Srivastava</last></author>
      <author><first>Stephen</first><last>Pilli</last></author>
      <author><first>Savita</first><last>Bhat</last></author>
      <author><first>Niranjan</first><last>Pedanekar</last></author>
      <author><first>Shirish</first><last>Karande</last></author>
      <pages>119–128</pages>
      <abstract>Investigating brand perception is fundamental to marketing strategies. In this regard, brand image, defined by a set of attributes (Aaker, 1997), is recognized as a key element in indicating how a brand is perceived by various stakeholders such as consumers and competitors. Traditional approaches (e.g., surveys) to monitor brand perceptions are time-consuming and inefficient. In the era of digital marketing, both brand managers and consumers engage with a vast amount of digital marketing content. The exponential growth of digital content has propelled the emergence of pre-trained language models such as BERT and GPT as essential tools in solving myriads of challenges with textual data. This paper seeks to investigate the extent of brand perceptions (i.e., brand and image attribute associations) these language models encode. We believe that any kind of bias for a brand and attribute pair may influence customer-centric downstream tasks such as recommender systems, sentiment analysis, and question-answering, e.g., suggesting a specific brand consistently when queried for innovative products. We use synthetic data and real-life data and report comparison results for five contextual LMs, viz. BERT, RoBERTa, DistilBERT, ALBERT and BART.</abstract>
      <url hash="9789e6f1">2021.deelio-1.12</url>
      <attachment type="OptionalSupplementaryData" hash="d10d3633">2021.deelio-1.12.OptionalSupplementaryData.pdf</attachment>
      <doi>10.18653/v1/2021.deelio-1.12</doi>
      <bibkey>srivastava-etal-2021-berts</bibkey>
    </paper>
    <paper id="13">
      <title>Attention vs non-attention for a Shapley-based explanation method</title>
      <author><first>Tom</first><last>Kersten</last></author>
      <author><first>Hugh Mee</first><last>Wong</last></author>
      <author><first>Jaap</first><last>Jumelet</last></author>
      <author><first>Dieuwke</first><last>Hupkes</last></author>
      <pages>129–139</pages>
      <abstract>The field of explainable AI has recently seen an explosion in the number of explanation methods for highly non-linear deep neural networks. The extent to which such methods – that are often proposed and tested in the domain of computer vision – are appropriate to address the explainability challenges in NLP is yet relatively unexplored. In this work, we consider Contextual Decomposition (CD) – a Shapley-based input feature attribution method that has been shown to work well for recurrent NLP models – and we test the extent to which it is useful for models that contain attention operations. To this end, we extend CD to cover the operations necessary for attention-based models. We then compare how long distance subject-verb relationships are processed by models with and without attention, considering a number of different syntactic structures in two different languages: English and Dutch. Our experiments confirm that CD can successfully be applied for attention-based models as well, providing an alternative Shapley-based attribution method for modern neural networks. In particular, using CD, we show that the English and Dutch models demonstrate similar processing behaviour, but that under the hood there are consistent differences between our attention and non-attention models.</abstract>
      <url hash="6374db31">2021.deelio-1.13</url>
      <doi>10.18653/v1/2021.deelio-1.13</doi>
      <bibkey>kersten-etal-2021-attention</bibkey>
    </paper>
    <paper id="14">
      <title>Predicting Numerals in Natural Language Text Using a Language Model Considering the Quantitative Aspects of Numerals</title>
      <author><first>Taku</first><last>Sakamoto</last></author>
      <author><first>Akiko</first><last>Aizawa</last></author>
      <pages>140–150</pages>
      <abstract>Numerical common sense (NCS) is necessary to fully understand natural language text that includes numerals. NCS is knowledge about the numerical features of objects in text, such as size, weight, or color. Existing neural language models treat numerals in a text as string tokens in the same way as other words. Therefore, they cannot reflect the quantitative aspects of numerals in the training process, making it difficult to learn NCS. In this paper, we measure the NCS acquired by existing neural language models using a masked numeral prediction task as an evaluation task. In this task, we use two evaluation metrics to evaluate the language models in terms of the symbolic and quantitative aspects of the numerals, respectively. We also propose methods to reflect not only the symbolic aspect but also the quantitative aspect of numerals in the training of language models, using a loss function that depends on the magnitudes of the numerals and a regression model for the masked numeral prediction task. Finally, we quantitatively evaluate our proposed approaches on four datasets with different properties using the two metrics. Compared with methods that use existing language models, the proposed methods reduce numerical absolute errors, although exact match accuracy was reduced. This result confirms that the proposed methods, which use the magnitudes of the numerals for model training, are an effective way for models to capture NCS.</abstract>
      <url hash="88527634">2021.deelio-1.14</url>
      <doi>10.18653/v1/2021.deelio-1.14</doi>
      <bibkey>sakamoto-aizawa-2021-predicting</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/drop">DROP</pwcdataset>
    </paper>
  </volume>
</collection>
