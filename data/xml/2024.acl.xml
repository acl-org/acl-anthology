<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.acl">
  <volume id="short" ingest-date="2024-08-09" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</booktitle>
      <editor><first>Lun-Wei</first><last>Ku</last><affiliation>Academia Sinica</affiliation></editor>
      <editor><first>Andre</first><last>Martins</last><affiliation>Instituto Superior Técnico / Instituto de Telecomunicações / Unbabel</affiliation></editor>
      <editor><first>Vivek</first><last>Srikumar</last><affiliation>University of Utah</affiliation></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Bangkok, Thailand and virtual meeting</address>
      <month>August</month>
      <year>2024</year>
      <url hash="eda01777">2024.acl-short</url>
      <venue>acl</venue>
    </meta>
    <frontmatter>
      <url hash="df1b51c6">2024.acl-short.0</url>
    </frontmatter>
    <paper id="1">
      <title>Can Language Models Serve as Text-Based World Simulators?</title>
      <author><first>Ruoyao</first><last>Wang</last><affiliation>University of Arizona</affiliation></author>
      <author><first>Graham</first><last>Todd</last></author>
      <author><first>Ziang</first><last>Xiao</last><affiliation>Department of Computer Science, Whiting School of Engineering</affiliation></author>
      <author><first>Xingdi</first><last>Yuan</last><affiliation>Microsoft Research</affiliation></author>
      <author><first>Marc-Alexandre</first><last>Côté</last><affiliation>Microsoft</affiliation></author>
      <author><first>Peter</first><last>Clark</last><affiliation>Allen Institute for Artificial Intelligence</affiliation></author>
      <author><first>Peter</first><last>Jansen</last><affiliation>University of Arizona</affiliation></author>
      <pages>1-17</pages>
      <abstract>Virtual environments play a key role in benchmarking advances in complex planning and decision-making tasks but are expensive and complicated to build by hand. Can current language models themselves serve as world simulators, correctly predicting how actions change different world states, thus bypassing the need for extensive manual coding? Our goal is to answer this question in the context of text-based simulators. Our approach is to build and use a new benchmark, called ByteSized32-State-Prediction, containing a dataset of text game state transitions and accompanying game tasks. We use this to directly quantify, for the first time, how well LLMs can serve as text-based world simulators. We test GPT-4 on this dataset and find that, despite its impressive performance, it is still an unreliable world simulator without further innovations. This work thus contributes both new insights into current LLM’s capabilities and weaknesses, as well as a novel benchmark to track future progress as new models appear.</abstract>
      <url hash="1a6973d9">2024.acl-short.1</url>
    </paper>
    <paper id="2">
      <title><fixed-case>F</fixed-case>an<fixed-case>O</fixed-case>ut<fixed-case>QA</fixed-case>: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models</title>
      <author><first>Andrew</first><last>Zhu</last><affiliation>University of Pennsylvania, University of Pennsylvania</affiliation></author>
      <author><first>Alyssa</first><last>Hwang</last><affiliation>University of Pennsylvania, University of Pennsylvania</affiliation></author>
      <author><first>Liam</first><last>Dugan</last><affiliation>University of Pennsylvania</affiliation></author>
      <author><first>Chris</first><last>Callison-Burch</last><affiliation>Allen Institute for Artificial Intelligence and University of Pennsylvania</affiliation></author>
      <pages>18-37</pages>
      <abstract>One type of question that is commonly found in day-to-day scenarios is “fan-out” questions, complex multi-hop, multi-document reasoning questions that require finding information about a large number of entities. However, there exist few resources to evaluate this type of question-answering capability among large language models. To evaluate complex reasoning in LLMs more fully, we present FanOutQA, a high-quality dataset of fan-out question-answer pairs and human-annotated decompositions with English Wikipedia as the knowledge base. We formulate three benchmark settings across our dataset and benchmark 7 LLMs, including GPT-4, LLaMA 2, Claude-2.1, and Mixtral-8x7B, finding that contemporary models still have room to improve reasoning over inter-document dependencies in a long context. We provide our dataset, along with open-source tools to run models to encourage evaluation.</abstract>
      <url hash="c42cf9cb">2024.acl-short.2</url>
    </paper>
    <paper id="3">
      <title>Revisiting Code Similarity Evaluation with Abstract Syntax Tree Edit Distance</title>
      <author><first>Yewei</first><last>Song</last></author>
      <author><first>Cedric</first><last>Lothritz</last><affiliation>Luxembourg Institute of Science and Technology</affiliation></author>
      <author><first>Xunzhu</first><last>Tang</last></author>
      <author><first>Tegawendé</first><last>Bissyandé</last><affiliation>University of Luxemburg</affiliation></author>
      <author><first>Jacques</first><last>Klein</last><affiliation>University of Luxemburg</affiliation></author>
      <pages>38-46</pages>
      <abstract>This paper revisits recent code similarity evaluation metrics, particularly focusing on the application of Abstract Syntax Tree (AST) editing distance in diverse programming languages. In particular, we explore the usefulness of these metrics and compare them to traditional sequence similarity metrics. Our experiments showcase the effectiveness of AST editing distance in capturing intricate code structures, revealing a high correlation with established metrics. Furthermore, we explore the strengths and weaknesses of AST editing distance and prompt-based GPT similarity scores in comparison to BLEU score, execution match, and Jaccard Similarity. We propose, optimize, and publish an adaptable metric that demonstrates effectiveness across all tested languages, representing an enhanced version of Tree Similarity of Edit Distance (TSED).</abstract>
      <url hash="5af1adda">2024.acl-short.3</url>
    </paper>
    <paper id="4">
      <title>Resisting the Lure of the Skyline: Grounding Practices in Active Learning for Morphological Inflection</title>
      <author><first>Saliha</first><last>Muradoglu</last></author>
      <author><first>Michael</first><last>Ginn</last><affiliation>University of Colorado at Boulder</affiliation></author>
      <author><first>Miikka</first><last>Silfverberg</last><affiliation>University of British Columbia</affiliation></author>
      <author><first>Mans</first><last>Hulden</last><affiliation>University of Colorado at Boulder</affiliation></author>
      <pages>47-55</pages>
      <abstract>Active learning (AL) aims to lower the demand of annotation by selecting informative unannotated samples for the model building. In this paper, we explore the importance of conscious experimental design in the language documentation and description setting, particularly the distribution of the unannotated sample pool. We focus on the task of morphological inflection using a Transformer model. We propose context motivated benchmarks: a baseline and skyline. The baseline describes the frequency weighted distribution encountered in natural speech. We simulate this using Wikipedia texts. The skyline defines the more common approach, uniform sampling from a large, balanced corpus (UniMorph, in our case), which often yields mixed results. We note the unrealistic nature of this unannotated pool. When these factors are considered, our results show a clear benefit to targeted sampling.</abstract>
      <url hash="044ebcaa">2024.acl-short.4</url>
    </paper>
    <paper id="5">
      <title>Speculative Contrastive Decoding</title>
      <author><first>Hongyi</first><last>Yuan</last></author>
      <author><first>Keming</first><last>Lu</last></author>
      <author><first>Fei</first><last>Huang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Zheng</first><last>Yuan</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Chang</first><last>Zhou</last></author>
      <pages>56-64</pages>
      <abstract>Large language models (LLMs) exhibit exceptional performance in language tasks, yet their auto-regressive inference is limited due to high computational requirements and is sub-optimal due to the exposure bias. Inspired by speculative decoding and contrastive decoding, we introduce Speculative Contrastive Decoding (SCD), a straightforward yet powerful decoding approach that leverages predictions from smaller language models (LMs) to achieve both decoding acceleration and quality improvement. Extensive evaluations and analyses on four diverse language tasks demonstrate the effectiveness of SCD, showing that decoding efficiency and quality can compatibly benefit from one smaller LM.</abstract>
      <url hash="db6bb454">2024.acl-short.5</url>
    </paper>
    <paper id="6">
      <title><fixed-case>RDR</fixed-case>ec: Rationale Distillation for <fixed-case>LLM</fixed-case>-based Recommendation</title>
      <author><first>Xinfeng</first><last>Wang</last></author>
      <author><first>Jin</first><last>Cui</last></author>
      <author><first>Yoshimi</first><last>Suzuki</last><affiliation>Yamanashi University</affiliation></author>
      <author><first>Fumiyo</first><last>Fukumoto</last><affiliation>Yamanashi University</affiliation></author>
      <pages>65-74</pages>
      <abstract>Large language model (LLM)-based recommender models that bridge users and items through textual prompts for effective semantic reasoning have gained considerable attention. However, few methods consider the underlying rationales behind interactions, such as user preferences and item attributes, limiting the reasoning ability of LLMs for recommendations. This paper proposes a rationale distillation recommender (RDRec), a compact model designed to learn rationales generated by a larger language model (LM). By leveraging rationales from reviews related to users and items, RDRec remarkably specifies their profiles for recommendations. Experiments show that RDRec achieves state-of-the-art (SOTA) performance in both top-N and sequential recommendations. Our code is available online.</abstract>
      <url hash="481b3ea8">2024.acl-short.6</url>
    </paper>
    <paper id="7">
      <title>Isotropy, Clusters, and Classifiers</title>
      <author><first>Timothee</first><last>Mickus</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Stig-Arne</first><last>Grönroos</last><affiliation>University of Helsinki</affiliation></author>
      <author><first>Joseph</first><last>Attieh</last><affiliation>University of Helsinki</affiliation></author>
      <pages>75-84</pages>
      <abstract>Whether embedding spaces use all their dimensions equally, i.e., whether they are isotropic, has been a recent subject of discussion. Evidence has been accrued both for and against enforcing isotropy in embedding spaces. In the present paper, we stress that isotropy imposes requirements on the embedding space that are not compatible with the presence of clusters—which also negatively impacts linear classification objectives. We demonstrate this fact both empirically and mathematically and use it to shed light on previous results from the literature.</abstract>
      <url hash="7f35ec1e">2024.acl-short.7</url>
    </paper>
    <paper id="8">
      <title>Language Models Do Hard Arithmetic Tasks Easily and Hardly Do Easy Arithmetic Tasks</title>
      <author><first>Andrew</first><last>Gambardella</last><affiliation>The University of Tokyo, Tokyo University</affiliation></author>
      <author><first>Yusuke</first><last>Iwasawa</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Yutaka</first><last>Matsuo</last><affiliation>The University of Tokyo and The University of Tokyo</affiliation></author>
      <pages>85-91</pages>
      <abstract>The ability (and inability) of large language models (LLMs) to perform arithmetic tasks has been the subject of much theoretical and practical debate. We show that LLMs are frequently able to correctly and confidently predict the first digit of <tex-math>n</tex-math>-digit by <tex-math>m</tex-math>-digit multiplication tasks without using chain of thought reasoning, despite these tasks require compounding operations to solve. Simultaneously, LLMs in practice often fail to correctly or confidently predict the last digit of an <tex-math>n</tex-math>-digit by <tex-math>m</tex-math>-digit multiplication, a task equivalent to 1-digit by 1-digit multiplication which can be easily learned or memorized. We show that the latter task can be solved more robustly when the LLM is conditioned on all of the correct higher-order digits, which on average increases the confidence of the correct last digit on 5-digit by 5-digit multiplication tasks using Llama 2-13B by over 230% (0.13→0.43) and Mistral-7B by 150% (0.22→0.55).</abstract>
      <url hash="15739f07">2024.acl-short.8</url>
    </paper>
    <paper id="9">
      <title>Simpson’s Paradox and the Accuracy-Fluency Tradeoff in Translation</title>
      <author><first>Zheng Wei</first><last>Lim</last></author>
      <author><first>Ekaterina</first><last>Vylomova</last><affiliation>The University of Melbourne</affiliation></author>
      <author><first>Trevor</first><last>Cohn</last><affiliation>Google and The University of Melbourne</affiliation></author>
      <author><first>Charles</first><last>Kemp</last><affiliation>University of Melbourne</affiliation></author>
      <pages>92-103</pages>
      <abstract>A good translation should be faithful to the source and should respect the norms of the target language. We address a theoretical puzzle about the relationship between these objectives. On one hand, intuition and some prior work suggest that accuracy and fluency should trade off against each other, and that capturing every detail of the source can only be achieved at the cost of fluency. On the other hand, quality assessment researchers often suggest that accuracy and fluency are highly correlated and difficult for human raters to distinguish (Callison-Burch et al., 2007). We show that the tension between these views is an instance of Simpson’s paradox, and that accuracy and fluency are positively correlated at the level of the corpus but trade off at the level of individual source segments. We further suggest that the relationship between accuracy and fluency is best evaluated at the segment (or sentence) level, and that the trade off between these dimensions has implications both for assessing translation quality and developing improved MT systems.</abstract>
      <url hash="72955d32">2024.acl-short.9</url>
    </paper>
    <paper id="10">
      <title><fixed-case>U</fixed-case>ltra<fixed-case>S</fixed-case>parse<fixed-case>BERT</fixed-case>: 99% Conditionally Sparse Language Modelling</title>
      <author><first>Peter</first><last>Belcak</last><affiliation>ETHZ - ETH Zurich</affiliation></author>
      <author><first>Roger</first><last>Wattenhofer</last><affiliation>Swiss Federal Institute of Technology</affiliation></author>
      <pages>104-108</pages>
      <abstract>We present UltraSparseBERT, a BERT variant that uses 0.3% of its neurons during inference while performing on par with similar BERT models. UltraSparseBERT selectively engages just 12 out of 4095 neurons for each layer inference. This is achieved by reorganizing feedforward networks into fast feedforward networks (FFFs).To showcase but one benefit of high sparsity, we provide an Intel MKL implementation achieving 78x speedup over the optimized feedforward baseline on CPUs, and an OpenAI Triton implementation performing forward passes 4.1x faster than the corresponding native GPU implementation. The training and benchmarking code is enclosed.</abstract>
      <url hash="241a64b1">2024.acl-short.10</url>
    </paper>
    <paper id="11">
      <title><fixed-case>S</fixed-case>ce<fixed-case>MQA</fixed-case>: A Scientific College Entrance Level Multimodal Question Answering Benchmark</title>
      <author><first>Zhenwen</first><last>Liang</last></author>
      <author><first>Kehan</first><last>Guo</last></author>
      <author><first>Gang</first><last>Liu</last></author>
      <author><first>Taicheng</first><last>Guo</last><affiliation>University of Notre Dame</affiliation></author>
      <author><first>Yujun</first><last>Zhou</last><affiliation>University of Notre Dame</affiliation></author>
      <author><first>Tianyu</first><last>Yang</last></author>
      <author><first>Jiajun</first><last>Jiao</last></author>
      <author><first>Renjie</first><last>Pi</last></author>
      <author><first>Jipeng</first><last>Zhang</last></author>
      <author><first>Xiangliang</first><last>Zhang</last><affiliation>University of Notre Dame</affiliation></author>
      <pages>109-119</pages>
      <abstract>The paper introduces SceMQA, a novel benchmark for scientific multimodal question answering at the college entrance level. It addresses a critical educational phase often overlooked in existing benchmarks, spanning high school to pre-college levels. SceMQA focuses on core science subjects including Mathematics, Physics, Chemistry, and Biology. It features a blend of multiple-choice and free-response formats, ensuring a comprehensive evaluation of AI models’ abilities. Additionally, our benchmark provides specific knowledge points for each problem and detailed explanations for each answer. SceMQA also uniquely presents problems with identical contexts but varied questions to facilitate a more thorough and accurate assessment of reasoning capabilities. In the experiment, we evaluate both open-source and close-source state-of-the-art Multimodal Large Language Models (MLLMs), across various experimental settings. The results show that further research and development are needed in developing more capable MLLM, as highlighted by only 50% to 60% accuracy achieved by the strongest models.</abstract>
      <url hash="64b77b1a">2024.acl-short.11</url>
    </paper>
    <paper id="12">
      <title>On the Role of Long-tail Knowledge in Retrieval Augmented Large Language Models</title>
      <author><first>Dongyang</first><last>Li</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Junbing</first><last>Yan</last></author>
      <author><first>Taolin</first><last>Zhang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Chengyu</first><last>Wang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Xiaofeng</first><last>He</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Longtao</first><last>Huang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Hui</first><last>Xue’</last></author>
      <author><first>Jun</first><last>Huang</last></author>
      <pages>120-126</pages>
      <abstract>Retrieval augmented generation (RAG) exhibits outstanding performance in promoting the knowledge capabilities of large language models (LLMs) with retrieved documents related to user queries. However, RAG only focuses on improving the response quality of LLMs via enhancing queries indiscriminately with retrieved information, paying little attention to what type of knowledge LLMs really need to answer original queries more accurately. In this paper, we suggest that long-tail knowledge is crucial for RAG as LLMs have already remembered common world knowledge during large-scale pre-training. Based on our observation, we propose a simple but effective long-tail knowledge detection method for LLMs. Specifically, the novel Generative Expected Calibration Error (GECE) metric is derived to measure the “long-tailness” of knowledge based on both statistics and semantics. Hence, we retrieve relevant documents and infuse them into the model for patching knowledge loopholes only when the input query relates to long-tail knowledge. Experiments show that, compared to existing RAG pipelines, our method achieves over 4x speedup in average inference time and consistent performance improvement in downstream tasks.</abstract>
      <url hash="7bd43fdb">2024.acl-short.12</url>
    </paper>
    <paper id="13">
      <title><fixed-case>IEP</fixed-case>ile: Unearthing Large Scale Schema-Conditioned Information Extraction Corpus</title>
      <author><first>Honghao</first><last>Gui</last></author>
      <author><first>Lin</first><last>Yuan</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Hongbin</first><last>Ye</last></author>
      <author><first>Ningyu</first><last>Zhang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Mengshu</first><last>Sun</last></author>
      <author><first>Lei</first><last>Liang</last></author>
      <author><first>Huajun</first><last>Chen</last><affiliation>Zhejiang University</affiliation></author>
      <pages>127-146</pages>
      <abstract>Large Language Models (LLMs) demonstrate remarkable potential across various domains; however, they exhibit a significant performance gap in Information Extraction (IE). Note that high-quality instruction data is the vital key for enhancing the specific capabilities of LLMs, while current IE datasets tend to be small in scale, fragmented, and lack standardized schema. To this end, we introduce IEPile, a comprehensive bilingual (English and Chinese) IE instruction corpus, which contains approximately 0.32B tokens. We construct IEPile by collecting and cleaning 33 existing IE datasets, and introduce schema-based instruction generation to unearth a large-scale corpus. Experimentally, IEPile enhance the performance of LLMs for IE, with notable improvements in zero-shot generalization. We open-source the resource and pre-trained models, hoping to provide valuable support to the NLP community.</abstract>
      <url hash="e7fe954f">2024.acl-short.13</url>
    </paper>
    <paper id="14">
      <title>Bi-Directional Multi-Granularity Generation Framework for Knowledge Graph-to-Text with Large Language Model</title>
      <author><first>Haowei</first><last>Du</last><affiliation>Peking University</affiliation></author>
      <author><first>Chen</first><last>Li</last><affiliation>HPC-AI Tech</affiliation></author>
      <author><first>Dinghao</first><last>Zhang</last></author>
      <author><first>Dongyan</first><last>Zhao</last><affiliation>Peking University</affiliation></author>
      <pages>147-152</pages>
      <abstract>The knowledge graph-to-text (KG-to-text) generation task aims to synthesize coherent and engaging sentences that accurately convey the complex information derived from an input knowledge graph. Existing methods generate the whole target text based on all KG triples at once and may incorporate incorrect KG triples for each sentence. To this end, we propose the bi-directional multi-granularity generation framework. Instead of generating the whole text at a time, we construct the sentence level generation based on the corresponding triples and generate the graph-level text as a result. Moreover, we design a backward relation extraction task to enhance the correctness of relational information. Our method achieves the new state-of-the-art in benchmark dataset WebNLG and further analysis shows the efficiency of different modules.</abstract>
      <url hash="9d90514a">2024.acl-short.14</url>
    </paper>
    <paper id="15">
      <title>Code-Switching Can be Better Aligners: Advancing Cross-Lingual <fixed-case>SLU</fixed-case> through Representation-Level and Prediction-Level Alignment</title>
      <author><first>Zhihong</first><last>Zhu</last><affiliation>Tencent</affiliation></author>
      <author><first>Xuxin</first><last>Cheng</last></author>
      <author><first>Zhanpeng</first><last>Chen</last></author>
      <author><first>Xianwei</first><last>Zhuang</last></author>
      <author><first>Zhiqi</first><last>Huang</last><affiliation>Tencent Game</affiliation></author>
      <author><first>Yuexian</first><last>Zou</last><affiliation>Peking University</affiliation></author>
      <pages>153-160</pages>
      <abstract>Zero-shot cross-lingual spoken language understanding (SLU) can promote the globalization application of dialog systems, which has attracted increasing attention. While current code-switching based cross-lingual SLU frameworks have shown promising results, they (i) predominantly utilize contrastive objectives to model hard alignment, which may disrupt the inherent structure within sentences of each language; and (ii) focus optimization objectives solely on the original sentences, neglecting the relation between original sentences and code-switched sentences, which may hinder contextualized embeddings from further alignment. In this paper, we propose a novel framework dubbed REPE (short for Representation-Level and Prediction-Level Alignment), which leverages both code-switched and original sentences to achieve multi-level alignment. Specifically, REPE introduces optimal transport to facilitate soft alignment between the representations of code-switched and original sentences, thereby preserving structural integrity as much as possible. Moreover, REPE adopts multi-view learning to enforce consistency regularization between the prediction of the two sentences, aligning them into a more refined language-invariant space. Based on this, we further incorporate a self-distillation layer to boost the robustness of REPE. Extensive experiments on two benchmarks across ten languages demonstrate the superiority of the proposed REPE framework.</abstract>
      <url hash="9eafc813">2024.acl-short.15</url>
    </paper>
    <paper id="16">
      <title><fixed-case>AFL</fixed-case>o<fixed-case>RA</fixed-case>: Adaptive Freezing of Low Rank Adaptation in Parameter Efficient Fine-Tuning of Large Models</title>
      <author><first>Zeyu</first><last>Liu</last></author>
      <author><first>Souvik</first><last>Kundu</last><affiliation>Intel</affiliation></author>
      <author><first>Anni</first><last>Li</last></author>
      <author><first>Junrui</first><last>Wan</last></author>
      <author><first>Lianghao</first><last>Jiang</last></author>
      <author><first>Peter</first><last>Beerel</last><affiliation>University of Southern California</affiliation></author>
      <pages>161-167</pages>
      <abstract>We present a novel Parameter-Efficient Fine-Tuning (PEFT) method, dubbed as <tex-math>\textit{Adaptive Freezing of Low-Rank Adaptation}</tex-math> (AFLoRA). Specifically, for each pre-trained frozen weight tensor, we add a parallel path of trainable low-rank matrices, namely a down-projection and an up-projection matrix, each of which is followed by a feature transformation vector. Based on a novel <i>freezing score</i>, we incrementally freeze these projection matrices during fine-tuning to reduce the computation and alleviate over-fitting. Our experimental results demonstrate that we can achieve state-of-the-art performance with an average improvement of up to 0.85% as evaluated on the GLUE benchmark while yielding up to <tex-math>9.5\times</tex-math> fewer average trainable parameters. While compared in terms of runtime, AFLoRA can yield up to <tex-math>1.86\times</tex-math> improvement as opposed to similar PEFT alternatives. Besides the practical utility of our approach, we provide insights on the trainability requirements of LoRA paths at different modules and the freezing schedule for the different projection matrices.</abstract>
      <url hash="df002b6a">2024.acl-short.16</url>
    </paper>
    <paper id="17">
      <title><fixed-case>DDP</fixed-case>rompt: Differential Diversity Prompting in Large Language Models</title>
      <author><first>Lin</first><last>Mu</last><affiliation>Anhui University</affiliation></author>
      <author><first>Wenhao</first><last>Zhang</last></author>
      <author><first>Yiwen</first><last>Zhang</last><affiliation>Anhui University</affiliation></author>
      <author><first>Peiquan</first><last>Jin</last><affiliation>University of Science and Technology of China</affiliation></author>
      <pages>168-174</pages>
      <abstract>Large Language Models (LLMs) have shown that their reasoning ability could be enhanced through approaches like Chain-of-Thought (CoT) prompting. However, these methods use single prompts for different types of questions and do not design appropriate prompts for questions with different characteristics. In this paper, we aim to explore a methodology that generates differentially diverse reasoning paths for different types of questions. To achieve this, we propose a novel prompting strategy called Differential Diversity Prompting (DDPrompt). Firstly, we generate the optimal prompts collection based on question characteristics. Then, we use this optimal prompts collection to generate multiple answers for a question and choose the final answer by voting. We evaluated DDPrompt on twelve reasoning benchmarks and significant improvement in the performance of LLMs on complex reasoning tasks (e.g., GSM8K 75%-&gt;84%, Tracking Shuffled Objects (68.8%-&gt;83.9%))</abstract>
      <url hash="2ca857f1">2024.acl-short.17</url>
    </paper>
    <paper id="18">
      <title>Monotonic Representation of Numeric Attributes in Language Models</title>
      <author><first>Benjamin</first><last>Heinzerling</last><affiliation>RIKEN and Tohoku University</affiliation></author>
      <author><first>Kentaro</first><last>Inui</last><affiliation>Mohamed bin Zayed University of Artificial Intelligence, RIKEN and Tohoku University</affiliation></author>
      <pages>175-195</pages>
      <abstract>Language models (LMs) can express factual knowledge involving numeric properties such as Karl Popper was born in 1902. However, how this information is encoded in the model’s internal representations is not understood well. Here, we introduce a method for finding and editing representations of numeric properties such as an entity’s birth year. We find directions that encode numeric properties monotonically, in an interpretable fashion. When editing representations along these directions, LM output changes accordingly. For example, by patching activations along a “birthyear” direction we can make the LM express an increasingly late birthyear. Property-encoding directions exist across several numeric properties in all models under consideration, suggesting the possibility that monotonic representation of numeric properties consistently emerges during LM pretraining.Code: https://github.com/bheinzerling/numeric-property-reprA long version of this short paper is available at: https://arxiv.org/abs/2403.10381</abstract>
      <url hash="cc347586">2024.acl-short.18</url>
    </paper>
    <paper id="19">
      <title>Two Issues with <fixed-case>C</fixed-case>hinese Spelling Correction and A Refinement Solution</title>
      <author><first>Changxuan</first><last>Sun</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Linlin</first><last>She</last></author>
      <author><first>Xuesong</first><last>Lu</last><affiliation>East China Normal University</affiliation></author>
      <pages>196-204</pages>
      <abstract>The Chinese Spelling Correction (CSC) task aims to detect and correct misspelled characters in Chinese text, and has received lots of attention in the past few years. Most recent studies adopt a Transformer-based model and leverage different features of characters such as pronunciation, glyph and contextual information to enhance the model’s ability to complete the task. Despite their state-of-the-art performance, we observe two issues that should be addressed to further advance the CSC task. First, the widely-used benchmark datasets SIGHAN13, SIGHAN14 and SIGHAN15, contain many mistakes. Hence the performance of existing models is not accurate and should be re-evaluated. Second, existing models seem to have reached a performance bottleneck, where the improvements on the SIGHAN’s testing sets are increasingly smaller and unstable. To deal with the two issues, we make two contributions: (1) we manually fix the SIGHAN datasets and re-evaluate four representative CSC models using the fixed datasets; (2) we analyze the new results to identify the spelling errors that none of the four models successfully corrects, based on which we propose a simple yet effective refinement solution. Experimental results show that our solution improves the four models in all metrics by notable margins.</abstract>
      <url hash="db24814e">2024.acl-short.19</url>
    </paper>
    <paper id="20">
      <title><fixed-case>D</fixed-case>yna<fixed-case>S</fixed-case>emble: Dynamic Ensembling of Textual and Structure-Based Models for Knowledge Graph Completion</title>
      <author><first>Ananjan</first><last>Nandi</last><affiliation>Stanford University</affiliation></author>
      <author><first>Navdeep</first><last>Kaur</last><affiliation>Alan Turing Institute</affiliation></author>
      <author><first>Parag</first><last>Singla</last><affiliation>IIT Delhi</affiliation></author>
      <author><first>Mausam</first><last>.</last><affiliation>Indian Institute of Technology Delhi</affiliation></author>
      <pages>205-216</pages>
      <abstract>We consider two popular approaches to KnowledgeGraph Completion (KGC): textual modelsthat rely on textual entity descriptions, andstructure-based models that exploit the connectivitystructure of the Knowledge Graph(KG). Preliminary experiments show that theseapproaches have complementary strengths:structure-based models perform exceptionallywell when the gold answer is easily reachablefrom the query head in the KG, while textualmodels exploit descriptions to give goodperformance even when the gold answer isnot easily reachable. In response, we proposeDynaSemble, a novel method for learningquery-dependent ensemble weights to combinethese approaches by using the distributions ofscores assigned by the models in the ensembleto all candidate entities. DynaSemble achievesstate-of-the-art results on three standard KGCdatasets, with up to 6.8 pt MRR and 8.3 ptHits@1 gains over the best baseline model forthe WN18RR dataset.</abstract>
      <url hash="fb19b1f5">2024.acl-short.20</url>
    </paper>
    <paper id="21">
      <title>Fine-Tuning Pre-Trained Language Models with Gaze Supervision</title>
      <author><first>Shuwen</first><last>Deng</last><affiliation>Universität Potsdam</affiliation></author>
      <author><first>Paul</first><last>Prasse</last><affiliation>Universität Potsdam</affiliation></author>
      <author><first>David</first><last>Reich</last><affiliation>Universität Potsdam</affiliation></author>
      <author><first>Tobias</first><last>Scheffer</last><affiliation>Universität Potsdam</affiliation></author>
      <author><first>Lena</first><last>Jäger</last><affiliation>University of Zurich and Universität Potsdam</affiliation></author>
      <pages>217-224</pages>
      <abstract>Human gaze data provide cognitive information that reflect human language comprehension and has been effectively integrated into a variety of natural language processing (NLP) tasks, demonstrating improved performance over corresponding plain text-based models. In this work, we propose to integrate a gaze module into pre-trained language models (LMs) at the fine-tuning stage to improve their capabilities to learn representations that are grounded in human language processing. This is done by extending the conventional purely text-based fine-tuning objective with an auxiliary loss to exploit cognitive signals. The gaze module is only included during training, retaining compatibility with existing pre-trained LM-based pipelines. We evaluate the proposed approach using two distinct pre-trained LMs on the GLUE benchmark and observe that the proposed model improves performance compared to both standard fine-tuning and traditional text augmentation baselines.</abstract>
      <url hash="596ede70">2024.acl-short.21</url>
    </paper>
    <paper id="22">
      <title>Growing Trees on Sounds: Assessing Strategies for End-to-End Dependency Parsing of Speech</title>
      <author><first>Adrien</first><last>Pupier</last><affiliation>Université Grenoble Alpes</affiliation></author>
      <author><first>Maximin</first><last>Coavoux</last><affiliation>CNRS</affiliation></author>
      <author><first>Jérôme</first><last>Goulian</last><affiliation>Université Grenoble Alpes</affiliation></author>
      <author><first>Benjamin</first><last>Lecouteux</last><affiliation>University of Grenoble-Alpes</affiliation></author>
      <pages>225-233</pages>
      <abstract>Direct dependency parsing of the speech signal –as opposed to parsing speech transcriptions– has recently been proposed as a task (Pupier et al. 2022), as a way of incorporating prosodic information in the parsing system and bypassing the limitations of a pipeline approach that would consist of using first an Automatic Speech Recognition (ASR) system and then a syntactic parser. In this article, we report on a set of experiments aiming at assessing the performance of two parsing paradigms (graph-based parsing and sequence labeling based parsing) on speech parsing. We perform this evaluation on a large treebank of spoken French, featuring realistic spontaneous conversations. Our findings show that (i) the graph based approach obtain better results across the board (ii) parsing directly from speech outperforms a pipeline approach, despite having 30% fewer parameters.</abstract>
      <url hash="10701cad">2024.acl-short.22</url>
    </paper>
    <paper id="23">
      <title>Sketch-Guided Constrained Decoding for Boosting Blackbox Large Language Models without Logit Access</title>
      <author><first>Saibo</first><last>Geng</last><affiliation>EPFL - EPF Lausanne</affiliation></author>
      <author><first>Berkay</first><last>Döner</last><affiliation>EPFL - EPF Lausanne</affiliation></author>
      <author><first>Chris</first><last>Wendler</last><affiliation>EPFL - EPF Lausanne</affiliation></author>
      <author><first>Martin</first><last>Josifoski</last><affiliation>Swiss Federal Institute of Technology Lausanne</affiliation></author>
      <author><first>Robert</first><last>West</last><affiliation>EPFL - EPF Lausanne</affiliation></author>
      <pages>234-245</pages>
      <abstract>Constrained decoding, a technique for enforcing constraints on language model outputs, offers a way to control text generation without retraining or architectural modifications. Its application is, however, typically restricted to models that give users access to next-token distributions (usually via softmax logits), which poses a limitation with blackbox large language models (LLMs). This paper introduces sketch-guided constrained decoding (SketchGCD), a novel approach to constrained decoding for blackbox LLMs, which operates without access to the logits of the blackbox LLM. SketchGCD utilizes a locally hosted auxiliary model to refine the output of an unconstrained blackbox LLM, effectively treating this initial output as a “sketch” for further elaboration. This approach is complementary to traditional logit-based techniques and enables the application of constrained decoding in settings where full model transparency is unavailable. We demonstrate the efficacy of SketchGCD through experiments in closed information extraction and constituency parsing, showing how it enhances the utility and flexibility of blackbox LLMs for complex NLP tasks.</abstract>
      <url hash="a1d900c7">2024.acl-short.23</url>
    </paper>
    <paper id="24">
      <title>On the Semantic Latent Space of Diffusion-Based Text-To-Speech Models</title>
      <author><first>Miri</first><last>Varshavsky-Hassid</last><affiliation>Verily Life Sciences</affiliation></author>
      <author><first>Roy</first><last>Hirsch</last></author>
      <author><first>Regev</first><last>Cohen</last><affiliation>Google</affiliation></author>
      <author><first>Tomer</first><last>Golany</last><affiliation>Google</affiliation></author>
      <author><first>Daniel</first><last>Freedman</last><affiliation>Verily</affiliation></author>
      <author><first>Ehud</first><last>Rivlin</last><affiliation>Technion, Technion</affiliation></author>
      <pages>246-255</pages>
      <abstract>The incorporation of Denoising Diffusion Models (DDMs) in the Text-to-Speech (TTS) domain is rising, providing great value in synthesizing high quality speech. Although they exhibit impressive audio quality, the extent of their semantic capabilities is unknown, and controlling their synthesized speech’s vocal properties remains a challenge. Inspired by recent advances in image synthesis, we explore the latent space of frozen TTS models, which is composed of the latent bottleneck activations of the DDM’s denoiser. We identify that this space contains rich semantic information, and outline several novel methods for finding semantic directions within it, both supervised and unsupervised. We then demonstrate how these enable off-the-shelf audio editing, without any further training, architectural changes or data requirements. We present evidence of the semantic and acoustic qualities of the edited audio, and provide supplemental samples: https://latent-analysis-grad-tts.github.io/speech-samples/.</abstract>
      <url hash="a4915b36">2024.acl-short.24</url>
    </paper>
    <paper id="25">
      <title>Learnable Privacy Neurons Localization in Language Models</title>
      <author><first>Ruizhe</first><last>Chen</last></author>
      <author><first>Tianxiang</first><last>Hu</last></author>
      <author><first>Yang</first><last>Feng</last></author>
      <author><first>Zuozhu</first><last>Liu</last><affiliation>Zhejiang University</affiliation></author>
      <pages>256-264</pages>
      <abstract>Concerns regarding Large Language Models (LLMs) to memorize and disclose private information, particularly Personally Identifiable Information (PII), become prominent within the community. Many efforts have been made to mitigate the privacy risks.However, the mechanism through which LLMs memorize PII remains poorly understood. To bridge this gap, we introduce a pioneering method for pinpointing PII-sensitive neurons (privacy neurons) within LLMs. Our method employs learnable binary weight masks to localize specific neurons that account for the memorization of PII in LLMs through adversarial training. Our investigations discover that PII is memorized by a small subset of neurons across all layers, which shows the property of PII specificity. Furthermore, we propose to validate the potential in PII risk mitigation by deactivating the localized privacy neurons. Both quantitative and qualitative experiments demonstrate the effectiveness of our neuron localization algorithm.</abstract>
      <url hash="02ffbcf6">2024.acl-short.25</url>
    </paper>
    <paper id="26">
      <title>Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Non-Literal Intent Resolution in <fixed-case>LLM</fixed-case>s</title>
      <author><first>Akhila</first><last>Yerukola</last></author>
      <author><first>Saujas</first><last>Vaduguru</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Daniel</first><last>Fried</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Maarten</first><last>Sap</last><affiliation>Carnegie Mellon University</affiliation></author>
      <pages>265-275</pages>
      <abstract>Humans often express their communicative intents indirectly or non-literally, which requires their interlocutors—human or AI—to understand beyond the literal meaning of words. While most existing work has focused on discriminative evaluations, we present a new approach to generatively evaluate large language models’ (LLMs’) intention understanding by examining their responses to non-literal utterances. Ideally, an LLM should respond in line with the true intention of a non-literal utterance, not its literal interpretation. Our findings show that LLMs struggle to generate contextually relevant responses to non-literal language. We also find that providing oracle intentions substantially improves response appropriateness, but using chain-of-thought to make models spell out intentions before responding improves much less. These findings suggest that LLMs are not yet pragmatic interlocutors, and that explicitly modeling intention could improve LLM responses to non-literal language.</abstract>
      <url hash="1363252b">2024.acl-short.26</url>
    </paper>
    <paper id="27">
      <title>Generating Harder Cross-document Event Coreference Resolution Datasets using Metaphoric Paraphrasing</title>
      <author><first>Shafiuddin Rehan</first><last>Ahmed</last></author>
      <author><first>Zhiyong</first><last>Wang</last></author>
      <author><first>George</first><last>Baker</last></author>
      <author><first>Kevin</first><last>Stowe</last></author>
      <author><first>James</first><last>Martin</last></author>
      <pages>276-286</pages>
      <abstract>The most popular Cross-Document Event Coreference Resolution (CDEC) datasets fail to convey the true difficulty of the task, due to the lack of lexical diversity between coreferring event triggers (words or phrases that refer to an event). Furthermore, there is a dearth of event datasets for figurative language, limiting a crucial avenue of research in event comprehension. We address these two issues by introducing ECB+META, a lexically rich variant of Event Coref Bank Plus (ECB+) for CDEC on symbolic and metaphoric language. We use ChatGPT as a tool for the metaphoric transformation of sentences in the documents of ECB+, then tag the original event triggers in the transformed sentences in a semi-automated manner. In this way, we avoid the re-annotation of expensive coreference links. We present results that show existing methods that work well on ECB+ struggle with ECB+META, thereby paving the way for CDEC research on a much more challenging dataset. Code/data: https://github.com/ahmeshaf/llms_coref</abstract>
      <url hash="dfbc8132">2024.acl-short.27</url>
    </paper>
    <paper id="28">
      <title>Soft Self-Consistency Improves Language Models Agents</title>
      <author><first>Han</first><last>Wang</last><affiliation>University of North Carolina at Chapel Hill</affiliation></author>
      <author><first>Archiki</first><last>Prasad</last></author>
      <author><first>Elias</first><last>Stengel-Eskin</last></author>
      <author><first>Mohit</first><last>Bansal</last><affiliation>University of North Carolina at Chapel Hill</affiliation></author>
      <pages>287-301</pages>
      <abstract>Generations from large language models (LLMs) can be improved by sampling and scoring multiple solutions to select a final answer. Current “sample and select” methods such as self-consistency (SC) rely on majority voting to score answers. However, when tasks have many distinct and valid answers, selection by voting requires a large number of samples. This makes SC prohibitively expensive for interactive tasks that involve generating multiple actions (answers) sequentially. After establishing that majority voting fails to provide consistent gains on such tasks, we demonstrate how to increase success rates by softening the scoring criterion. We introduce Soft Self-Consistency (SOFT-SC), which replaces SC’s discontinuous scoring with a continuous score computed from model likelihoods, allowing for selection even when actions are sparsely distributed. SOFT-SC improves both performance and efficiency on long-horizon interactive tasks, requiring half as many samples as SC for comparable or better performance. For a fixed number of samples, SOFT-SC leads to a 1.3% increase over SC in absolute success rate on writing bash programs, a 6.6% increase on online shopping (WebShop), and a 4.7% increase for an interactive household game (ALFWorld). Finally, we show that SOFT-SC can be applied to both open-source and black-box models.</abstract>
      <url hash="61386437">2024.acl-short.28</url>
    </paper>
    <paper id="29">
      <title><fixed-case>R</fixed-case>ec<fixed-case>GPT</fixed-case>: Generative Pre-training for Text-based Recommendation</title>
      <author><first>Hoang</first><last>Ngo</last><affiliation>VinAI Research</affiliation></author>
      <author><first>Dat Quoc</first><last>Nguyen</last><affiliation>VinAI Research, Vietnam</affiliation></author>
      <pages>302-313</pages>
      <abstract>We present the first domain-adapted and fully-trained large language model, RecGPT-7B, and its instruction-following variant, RecGPT-7B-Instruct, for text-based recommendation. Experimental results on rating prediction and sequential recommendation tasks show that our model, RecGPT-7B-Instruct, outperforms previous strong baselines. We are releasing our RecGPT models as well as their pre-training and fine-tuning datasets to facilitate future research and downstream applications in text-based recommendation. Public “huggingface” links to our RecGPT models and datasets are available at: https://github.com/VinAIResearch/RecGPT</abstract>
      <url hash="a7d3643e">2024.acl-short.29</url>
    </paper>
    <paper id="30">
      <title><fixed-case>MTP</fixed-case>: A Dataset for Multi-Modal Turning Points in Casual Conversations</title>
      <author><first>Gia-Bao</first><last>Ho</last><affiliation>VinUniversity</affiliation></author>
      <author><first>Chang</first><last>Tan</last><affiliation>Monash University</affiliation></author>
      <author><first>Zahra</first><last>Darban</last></author>
      <author><first>Mahsa</first><last>Salehi</last><affiliation>Monash University</affiliation></author>
      <author><first>Reza</first><last>Haf</last><affiliation>Monash University</affiliation></author>
      <author><first>Wray</first><last>Buntine</last><affiliation>VinUniversity</affiliation></author>
      <pages>314-326</pages>
      <abstract>Detecting critical moments, such as emotional outbursts or changes in decisions during conversations, is crucial for understanding shifts in human behavior and their consequences. Our work introduces a novel problem setting focusing on these moments as turning points (TPs), accompanied by a meticulously curated, high-consensus, human-annotated multi-modal dataset. We provide precise timestamps, descriptions, and visual-textual evidence high-lighting changes in emotions, behaviors, perspectives, and decisions at these turning points. We also propose a framework, TPMaven, utilizing state-of-the-art vision-language models to construct a narrative from the videos and large language models to classify and detect turning points in our multi-modal dataset. Evaluation results show that TPMaven achieves an F1-score of 0.88 in classification and 0.61 in detection, with additional explanations aligning with human expectations.</abstract>
      <url hash="66b04e8f">2024.acl-short.30</url>
    </paper>
    <paper id="31">
      <title>What Does Parameter-free Probing Really Uncover?</title>
      <author><first>Tommi</first><last>Buder-Gröndahl</last></author>
      <pages>327-336</pages>
      <abstract>Supervised approaches to probing large language models (LLMs) have been criticized of using pre-defined theory-laden target labels. As an alternative, parameter-free probing constructs structural representations bottom-up via information derived from the LLM alone. This has been suggested to capture a genuine “LLM-internal grammar”. However, its relation to familiar linguistic formalisms remains unclear. I extend prior work on a parameter-free probing technique called perturbed masking applied to BERT, by comparing its results to the Universal Dependencies (UD) formalism for English. The results highlight several major discrepancies between BERT and UD, which lack correlates in linguistic theory. This raises the question of whether human grammar is the correct analogy to interpret BERT in the first place.</abstract>
      <url hash="6b49333f">2024.acl-short.31</url>
    </paper>
    <paper id="32">
      <title><fixed-case>ATLAS</fixed-case>: Improving Lay Summarisation with Attribute-based Control</title>
      <author><first>Zhihao</first><last>Zhang</last><affiliation>Beijing University of Technology</affiliation></author>
      <author><first>Tomas</first><last>Goldsack</last><affiliation>University of Sheffield</affiliation></author>
      <author><first>Carolina</first><last>Scarton</last><affiliation>University of Sheffield</affiliation></author>
      <author><first>Chenghua</first><last>Lin</last><affiliation>University of Manchester</affiliation></author>
      <pages>337-345</pages>
      <abstract>Lay summarisation aims to produce summaries of scientific articles that are comprehensible to non-expert audiences. However, previous work assumes a one-size-fits-all approach, where the content and style of the produced summary are entirely dependent on the data used to train the model. In practice, audiences with different levels of expertise will have specific needs, impacting what content should appear in a lay summary and how it should be presented. Aiming to address this, we propose ATLAS, a novel abstractive summarisation approach that can control various properties that contribute to the overall “layness” of the generated summary using targeted control attributes. We evaluate ATLAS on a combination of biomedical lay summarisation datasets, where it outperforms state-of-the-art baselines using mainstream summarisation metrics.Additional analyses provided on the discriminatory power and emergent influence of our selected controllable attributes further attest to the effectiveness of our approach.</abstract>
      <url hash="7ae4f972">2024.acl-short.32</url>
    </paper>
    <paper id="33">
      <title><fixed-case>E</fixed-case>mb<fixed-case>S</fixed-case>patial-Bench: Benchmarking Spatial Understanding for Embodied Tasks with Large Vision-Language Models</title>
      <author><first>Mengfei</first><last>Du</last></author>
      <author><first>Binhao</first><last>Wu</last><affiliation>Fudan University</affiliation></author>
      <author><first>Zejun</first><last>Li</last></author>
      <author><first>Xuanjing</first><last>Huang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Zhongyu</first><last>Wei</last><affiliation>Fudan University</affiliation></author>
      <pages>346-355</pages>
      <abstract>The recent rapid development of Large Vision-Language Models (LVLMs) has indicated their potential for embodied tasks. However, the critical skill of spatial understanding in embodied environments has not been thoroughly evaluated, leaving the gap between current LVLMs and qualified embodied intelligence unknown. Therefore, we construct EmbSpatial-Bench, a benchmark for evaluating embodied spatial understanding of LVLMs. The benchmark is automatically derived from embodied scenes and covers 6 spatial relationships from an egocentric perspective. Experiments expose the insufficient capacity of current LVLMs (even GPT-4V). We further present EmbSpatial-SFT, an instruction-tuning dataset designed to improve LVLMs’ embodied spatial understanding.</abstract>
      <url hash="c26a34e0">2024.acl-short.33</url>
    </paper>
    <paper id="34">
      <title>Understanding the Effects of Noise in Text-to-<fixed-case>SQL</fixed-case>: An Examination of the <fixed-case>BIRD</fixed-case>-Bench Benchmark</title>
      <author><first>Niklas</first><last>Wretblad</last></author>
      <author><first>Fredrik</first><last>Riseby</last></author>
      <author><first>Rahul</first><last>Biswas</last></author>
      <author><first>Amin</first><last>Ahmadi</last></author>
      <author><first>Oskar</first><last>Holmström</last></author>
      <pages>356-369</pages>
      <abstract>Text-to-SQL, which involves translating natural language into Structured Query Language (SQL), is crucial for enabling broad access to structured databases without expert knowledge. However, designing models for such tasks is challenging due to numerous factors, including the presence of noise, such as ambiguous questions and syntactical errors. This study provides an in-depth analysis of the distribution and types of noise in the widely used BIRD-Bench benchmark and the impact of noise on models. While BIRD-Bench was created to model dirty and noisy database values, it was not created to contain noise and errors in the questions and gold SQL queries. We found that noise in questions and gold queries are prevalent in the dataset, with varying amounts across domains, and with an uneven distribution between noise types. The presence of incorrect gold SQL queries, which then generate incorrect gold answers, has a significant impact on the benchmark’s reliability. Surprisingly, when evaluating models on corrected SQL queries, zero-shot baselines surpassed the performance of state-of-the-art prompting methods. We conclude that informative noise labels and reliable benchmarks are crucial to developing new Text-to-SQL methods that can handle varying types of noise.</abstract>
      <url hash="56c71ace">2024.acl-short.34</url>
    </paper>
    <paper id="35">
      <title>Dwell in the Beginning: How Language Models Embed Long Documents for Dense Retrieval</title>
      <author><first>João</first><last>Coelho</last></author>
      <author><first>Bruno</first><last>Martins</last><affiliation>Instituto Superior Técnico</affiliation></author>
      <author><first>Joao</first><last>Magalhaes</last><affiliation>Universidade Nova de Lisboa</affiliation></author>
      <author><first>Jamie</first><last>Callan</last><affiliation>Carnegie Mellon University</affiliation></author>
      <author><first>Chenyan</first><last>Xiong</last><affiliation>School of Computer Science, Carnegie Mellon University</affiliation></author>
      <pages>370-377</pages>
      <abstract>This study investigates the existence of positional biases in Transformer-based language models for text representation learning, particularly in the context of web document retrieval. We build on previous research that demonstrated loss of information in the middle of input sequences for causal language models, extending it to the domain of embedding learning. We examine positional biases at multiple stages of the training pipeline for an encoder-decoder neural retrieval model, namely language model pre-training, contrastive pre-training, and contrastive fine-tuning. Experiments with the MS-MARCO document collection reveal that after contrastive pre-training the model already generates embeddings that better capture the beginning of the input content, with fine-tuning further aggravating this effect.</abstract>
      <url hash="82c5545e">2024.acl-short.35</url>
    </paper>
    <paper id="36">
      <title>That’s Optional: A Contemporary Exploration of “that” Omission in <fixed-case>E</fixed-case>nglish Subordinate Clauses</title>
      <author><first>Ella</first><last>Rabinovich</last><affiliation>International Business Machines</affiliation></author>
      <pages>378-385</pages>
      <abstract>The Uniform Information Density (UID) hypothesis posits that speakers optimize the communicative properties of their utterances by avoiding spikes in information, thereby maintaining a relatively uniform information profile over time. This paper investigates the impact of UID principles on syntactic reduction, specifically focusing on the optional omission of the connector “that” in English subordinate clauses. Building upon previous research, we extend our investigation to a larger corpus of written English, utilize contemporary large language models (LLMs) and extend the information-uniformity principles by the notion of entropy, to estimate the UID manifestations in the usecase of syntactic reduction choices.</abstract>
      <url hash="938e849c">2024.acl-short.36</url>
    </paper>
    <paper id="37">
      <title>Do Large Language Models Discriminate in Hiring Decisions on the Basis of Race, Ethnicity, and Gender?</title>
      <author><first>Haozhe</first><last>An</last><affiliation>Google and University of Maryland, College Park</affiliation></author>
      <author><first>Christabel</first><last>Acquaye</last></author>
      <author><first>Colin</first><last>Wang</last></author>
      <author><first>Zongxia</first><last>Li</last><affiliation>University of Maryland, College Park</affiliation></author>
      <author><first>Rachel</first><last>Rudinger</last><affiliation>University of Maryland, College Park</affiliation></author>
      <pages>386-397</pages>
      <abstract>We examine whether large language models (LLMs) exhibit race- and gender-based name discrimination in hiring decisions, similar to classic findings in the social sciences (Bertrand and Mullainathan, 2004). We design a series of templatic prompts to LLMs to write an email to a named job applicant informing them of a hiring decision. By manipulating the applicant’s first name, we measure the effect of perceived race, ethnicity, and gender on the probability that the LLM generates an acceptance or rejection email. We find that the hiring decisions of LLMs in many settings are more likely to favor White applicants over Hispanic applicants. In aggregate, the groups with the highest and lowest acceptance rates respectively are masculine White names and masculine Hispanic names. However, the comparative acceptance rates by group vary under different templatic settings, suggesting that LLMs’ race- and gender-sensitivity may be idiosyncratic and prompt-sensitive.</abstract>
      <url hash="b21b0407">2024.acl-short.37</url>
    </paper>
    <paper id="38">
      <title>Explainability and Hate Speech: Structured Explanations Make Social Media Moderators Faster</title>
      <author><first>Agostina</first><last>Calabrese</last><affiliation>University of Edinburgh</affiliation></author>
      <author><first>Leonardo</first><last>Neves</last></author>
      <author><first>Neil</first><last>Shah</last><affiliation>Snap Inc.</affiliation></author>
      <author><first>Maarten</first><last>Bos</last><affiliation>Snap Inc.</affiliation></author>
      <author><first>Björn</first><last>Ross</last><affiliation>University of Edinburgh, University of Edinburgh</affiliation></author>
      <author><first>Mirella</first><last>Lapata</last><affiliation>Edinburgh University, University of Edinburgh</affiliation></author>
      <author><first>Francesco</first><last>Barbieri</last><affiliation>Snap Inc.</affiliation></author>
      <pages>398-408</pages>
      <abstract>Content moderators play a key role in keeping the conversation on social media healthy. While the high volume of content they need to judge represents a bottleneck to the moderation pipeline, no studies have explored how models could support them to make faster decisions. There is, by now, a vast body of research into detecting hate speech, sometimes explicitly motivated by a desire to help improve content moderation, but published research using real content moderators is scarce. In this work we investigate the effect of explanations on the speed of real-world moderators. Our experiments show that while generic explanations do not affect their speed and are often ignored, structured explanations lower moderators’ decision making time by 7.4%.</abstract>
      <url hash="d1fc4d91">2024.acl-short.38</url>
    </paper>
    <paper id="39">
      <title>Born Differently Makes a Difference: Counterfactual Study of Bias in Biography Generation from a Data-to-Text Perspective</title>
      <author><first>Biaoyan</first><last>Fang</last><affiliation>CSIRO</affiliation></author>
      <author><first>Ritvik</first><last>Dinesh</last><affiliation>University of Sydney, University of Sydney</affiliation></author>
      <author><first>Xiang</first><last>Dai</last><affiliation>CSIRO</affiliation></author>
      <author><first>Sarvnaz</first><last>Karimi</last><affiliation>CSIRO</affiliation></author>
      <pages>409-424</pages>
      <abstract>How do personal attributes affect biography generation? Addressing this question requires an identical pair of biographies where only the personal attributes of interest are different. However, it is rare in the real world. To address this, we propose a counterfactual methodology from a data-to-text perspective, manipulating the personal attributes of interest while keeping the co-occurring attributes unchanged. We first validate that the fine-tuned Flan-T5 model generates the biographies based on the given attributes. This work expands the analysis of gender-centered bias in text generation. Our results confirm the well-known bias in gender and also show the bias in regions, in both individual and its related co-occurring attributes in semantic machining and sentiment.</abstract>
      <url hash="7df401a6">2024.acl-short.39</url>
    </paper>
    <paper id="40">
      <title>Sign Language Translation with Sentence Embedding Supervision</title>
      <author><first>Hamidullah</first><last>Yasser</last></author>
      <author><first>Josef</first><last>Genabith</last><affiliation>German Research Center for AI and Universität des Saarlandes</affiliation></author>
      <author><first>Cristina</first><last>España-Bonet</last><affiliation>German Research Center for AI</affiliation></author>
      <pages>425-434</pages>
      <abstract>State-of-the-art sign language translation (SLT) systems facilitate the learning process through gloss annotations, either in an end2end manner or by involving an intermediate step. Unfortunately, gloss labelled sign language data is usually not available at scale and, when available, gloss annotations widely differ from dataset to dataset. We present a novel approach using sentence embeddings of the target sentences at training time that take the role of glosses. The new kind of supervision does not need any manual annotation but it is learned on raw textual data. As our approach easily facilitates multilinguality, we evaluate it on datasets covering German (PHOENIX-2014T) and American (How2Sign) sign languages and experiment with mono- and multilingual sentence embeddings and translation systems. Our approach significantly outperforms other gloss-free approaches, setting the new state-of-the-art for data sets where glosses are not available and when no additional SLT datasets are used for pretraining, diminishing the gap between gloss-free and gloss-dependent systems.</abstract>
      <url hash="f46d957e">2024.acl-short.40</url>
    </paper>
    <paper id="41">
      <title><fixed-case>STREAM</fixed-case>: Simplified Topic Retrieval, Exploration, and Analysis Module</title>
      <author><first>Anton</first><last>Thielmann</last><affiliation>Technische Universität Clausthal and Georg-August Universität Göttingen</affiliation></author>
      <author><first>Arik</first><last>Reuter</last><affiliation>Technische Universität Clausthal and Ludwig-Maximilians-Universität München</affiliation></author>
      <author><first>Christoph</first><last>Weisser</last><affiliation>BASF</affiliation></author>
      <author><first>Gillian</first><last>Kant</last></author>
      <author><first>Manish</first><last>Kumar</last><affiliation>BASF</affiliation></author>
      <author><first>Benjamin</first><last>Säfken</last><affiliation>Technische Universität Clausthal</affiliation></author>
      <pages>435-444</pages>
      <abstract>Topic modeling is a widely used technique to analyze large document corpora. With the ever-growing emergence of scientific contributions in the field, non-technical users may often use the simplest available software module, independent of whether there are potentially better models available. We present a Simplified Topic Retrieval, Exploration, and Analysis Module (STREAM) for user-friendly topic modelling and especially subsequent interactive topic visualization and analysis. For better topic analysis, we implement multiple intruder-word based topic evaluation metrics. Additionally, we publicize multiple new datasets that can extend the so far very limited number of publicly available benchmark datasets in topic modeling. We integrate downstream interpretable analysis modules to enable users to easily analyse the created topics in downstream tasks together with additional tabular information.The code is available at the following link: https://github.com/AnFreTh/STREAM</abstract>
      <url hash="ceef0db3">2024.acl-short.41</url>
    </paper>
    <paper id="42">
      <title><fixed-case>D</fixed-case>oc<fixed-case>F</fixed-case>in<fixed-case>QA</fixed-case>: A Long-Context Financial Reasoning Dataset</title>
      <author><first>Varshini</first><last>Reddy</last></author>
      <author><first>Rik</first><last>Koncel-Kedziorski</last><affiliation>Apple</affiliation></author>
      <author><first>Viet</first><last>Lai</last><affiliation>Adobe Systems</affiliation></author>
      <author><first>Michael</first><last>Krumdick</last><affiliation>Kensho</affiliation></author>
      <author><first>Charles</first><last>Lovering</last><affiliation>Kensho</affiliation></author>
      <author><first>Chris</first><last>Tanner</last><affiliation>Massachusetts Institute of Technology and Kensho</affiliation></author>
      <pages>445-458</pages>
      <abstract>For large language models (LLMs) to be effective in the financial domain – where each decision can have a significant impact – it is necessary to investigate realistic tasks and data. Financial professionals often interact with documents spanning hundreds of pages, but most financial research datasets only deal with short excerpts from these documents. To address this, we introduce a long-document financial QA task. We augment 7,437 questions from the existing FinQA dataset with full-document context, extending the average context length from under 700 words in FinQA to 123k words in DocFinQA. We conduct extensive experiments over retrieval-based QA pipelines and long-context language models. Based on our experiments, DocFinQA proves a significant challenge for even state-of-the-art systems. We also provide a case study on a subset of the longest documents in DocFinQA and find that models particularly struggle with these documents. Addressing these challenges may have a wide-reaching impact across applications where specificity and long-range contexts are critical, like gene sequences and legal document contract analysis. DocFinQA dataset is publicly accessible.</abstract>
      <url hash="44fa643d">2024.acl-short.42</url>
    </paper>
    <paper id="43">
      <title><fixed-case>M</fixed-case>ask<fixed-case>LID</fixed-case>: Code-Switching Language Identification through Iterative Masking</title>
      <author><first>Amir Hossein</first><last>Kargaran</last><affiliation>Ludwig-Maximilians-Universität München</affiliation></author>
      <author><first>François</first><last>Yvon</last><affiliation>ISIR, Sorbonne Université &amp; CNRS</affiliation></author>
      <author><first>Hinrich</first><last>Schuetze</last></author>
      <pages>459-469</pages>
      <abstract>We present MaskLID, a simple, yet effective, code-switching (CS) language identification (LID) method. MaskLID does not require any training and is designed to complement current high-performance sentence-level LIDs. Sentence-level LIDs are classifiers trained on monolingual texts to provide single labels, typically using a softmax layer to turn scores into probabilities. However, in cases where a sentence is composed in both L1 and L2 languages, the LID classifier often only returns the dominant label L1. To address this limitation, MaskLID employs a strategy to mask text features associated with L1, allowing the LID to classify the text as L2 in the next round. This method uses the LID itself to identify the features that require masking and does not rely on any external resource. In this work, we explore the use of MaskLID for two open-source LIDs (GlotLID and OpenLID), that are both based on the FastText architecture. Code and demo are available at https://github.com/cisnlp/MaskLID.</abstract>
      <url hash="2f342948">2024.acl-short.43</url>
    </paper>
    <paper id="44">
      <title>An Empirical Analysis on Large Language Models in Debate Evaluation</title>
      <author><first>Xinyi</first><last>Liu</last></author>
      <author><first>Pinxin</first><last>Liu</last></author>
      <author><first>Hangfeng</first><last>He</last><affiliation>University of Rochester</affiliation></author>
      <pages>470-487</pages>
      <abstract>In this study, we investigate the capabilities and inherent biases of advanced large language models (LLMs) such as GPT-3.5 and GPT-4 in the context of debate evaluation. We discover that LLM’s performance exceeds humans and surpasses the performance of state-of-the-art methods fine-tuned on extensive datasets. We additionally explore and analyze biases present in LLMs, including positional bias, lexical bias, order bias, which may affect their evaluative judgments. Our findings reveal a consistent bias in both GPT-3.5 and GPT-4 towards the second candidate response presented, attributed to prompt design. We also uncover a lexical bias in both GPT-3.5 and GPT-4, especially when label sets carry connotations such as numerical or sequential, highlighting the critical need for careful label verbalizer selection in prompt design. Additionally, our analysis indicates a tendency of both models to favor the debate’s concluding side as the winner, suggesting an end-of-discussion bias.</abstract>
      <url hash="d901584a">2024.acl-short.44</url>
    </paper>
    <paper id="45">
      <title>Fine-Tuned Machine Translation Metrics Struggle in Unseen Domains</title>
      <author><first>Vilém</first><last>Zouhar</last><affiliation>Department of Computer Science, ETHZ - ETH Zurich</affiliation></author>
      <author><first>Shuoyang</first><last>Ding</last><affiliation>NVIDIA</affiliation></author>
      <author><first>Anna</first><last>Currey</last><affiliation>Amazon</affiliation></author>
      <author><first>Tatyana</first><last>Badeka</last><affiliation>Amazon</affiliation></author>
      <author><first>Jenyuan</first><last>Wang</last><affiliation>Amazon</affiliation></author>
      <author><first>Brian</first><last>Thompson</last><affiliation>Amazon</affiliation></author>
      <pages>488-500</pages>
      <abstract>We introduce a new, extensive multidimensional quality metrics (MQM) annotated dataset covering 11 language pairs in the biomedical domain. We use this dataset to investigate whether machine translation (MT) metrics which are fine-tuned on human-generated MT quality judgements are robust to domain shifts between training and inference. We find that fine-tuned metrics exhibit a substantial performance drop in the unseen domain scenario relative to both metrics that rely on the surface form and pre-trained metrics that are not fine-tuned on MT quality judgments.</abstract>
      <url hash="ef91549c">2024.acl-short.45</url>
    </paper>
    <paper id="46">
      <title><fixed-case>I</fixed-case>ndic<fixed-case>IRS</fixed-case>uite: Multilingual Dataset and Neural Information Models for <fixed-case>I</fixed-case>ndian Languages</title>
      <author><first>Saiful</first><last>Haq</last></author>
      <author><first>Ashutosh</first><last>Sharma</last></author>
      <author><first>Omar</first><last>Khattab</last></author>
      <author><first>Niyati</first><last>Chhaya</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last><affiliation>Indian Institute of Technology, Bombay, Dhirubhai Ambani Institute Of Information and Communication Technology</affiliation></author>
      <pages>501-509</pages>
      <abstract>In this paper, we introduce Neural Information Retrieval resources for 11 widely spoken Indian Languages (Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, and Telugu) from two major Indian language families (Indo-Aryan and Dravidian). These resources include (a) INDIC-MARCO, a multilingual version of the MS MARCO dataset in 11 Indian Languages created using Machine Translation, and (b) Indic-ColBERT, a collection of 11 distinct Monolingual Neural Information Retrieval models, each trained on one of the 11 languages in the INDIC-MARCO dataset. To the best of our knowledge, IndicIRSuite is the first attempt at building large-scale Neural Information Retrieval resources for a large number of Indian languages, and we hope that it will help accelerate research in Neural IR for Indian Languages. Experiments demonstrate that Indic-ColBERT achieves 47.47% improvement in the MRR@10 score averaged over the INDIC-MARCO baselines for all 11 Indian languages except Oriya, 12.26% improvement in the NDCG@10 score averaged over the MIRACL Bengali and Hindi Language baselines, and 20% improvement in the MRR@100 Score over the Mr. Tydi Bengali Language baseline.</abstract>
      <url hash="ca45c907">2024.acl-short.46</url>
    </paper>
    <paper id="47">
      <title><fixed-case>AGR</fixed-case>: Reinforced Causal Agent-Guided Self-explaining Rationalization</title>
      <author><first>Yunxiao</first><last>Zhao</last></author>
      <author><first>Zhiqiang</first><last>Wang</last><affiliation>Shanxi University</affiliation></author>
      <author><first>Xiaoli</first><last>Li</last></author>
      <author><first>Jiye</first><last>Liang</last><affiliation>Shanxi University</affiliation></author>
      <author><first>Ru</first><last>Li</last><affiliation>Shanxi University</affiliation></author>
      <pages>510-518</pages>
      <abstract>Most existing rationalization approaches are susceptible to degeneration accumulation due to a lack of effective control over the learning direction of the model during training. To address this issue, we propose a novel approach AGR (<b>A</b>gent-<b>G</b>uided <b>R</b>ationalization), guiding the next action of the model based on its current training state. Specifically, we introduce causal intervention calculus to quantify the causal effects inherent during rationale training, and utilize reinforcement learning process to refine the learning bias of them. Furthermore, we pretrain an agent within this reinforced causal environment to guide the next step of the model. We <i>theoretically</i> demonstrate that a good model needs the desired guidance, and <i>empirically</i> show the effectiveness of our approach, outperforming existing state-of-the-art methods on BeerAdvocate and HotelReview datasets.</abstract>
      <url hash="e3de078e">2024.acl-short.47</url>
    </paper>
    <paper id="48">
      <title>Shoulders of Giants: A Look at the Degree and Utility of Openness in <fixed-case>NLP</fixed-case> Research</title>
      <author><first>Surangika</first><last>Ranathunga</last><affiliation>Massey University</affiliation></author>
      <author><first>Nisansa</first><last>De Silva</last><affiliation>University of Moratuwa</affiliation></author>
      <author><first>Dilith</first><last>Jayakody</last></author>
      <author><first>Aloka</first><last>Fernando</last><affiliation>University of Moratuwa</affiliation></author>
      <pages>519-529</pages>
      <abstract>We analysed a sample of NLP research papers archived in ACL Anthology as an attempt to quantify the degree of openness and the benefit of such an open culture in the NLP community. We observe that papers published in different NLP venues show different patterns related to artefact reuse. We also note that more than 30% of the papers we analysed do not release their artefacts publicly. Further, we observe a wide language-wise disparity in publicly available NLP-related artefacts.</abstract>
      <url hash="b8ac134e">2024.acl-short.48</url>
    </paper>
    <paper id="49">
      <title>The Probabilities Also Matter: A More Faithful Metric for Faithfulness of Free-Text Explanations in Large Language Models</title>
      <author><first>Noah</first><last>Siegel</last><affiliation>University College London, University of London and Google DeepMind</affiliation></author>
      <author><first>Oana-Maria</first><last>Camburu</last><affiliation>Department of Computer Science, University College London, University of London</affiliation></author>
      <author><first>Nicolas</first><last>Heess</last><affiliation>Google</affiliation></author>
      <author><first>Maria</first><last>Perez-Ortiz</last><affiliation>University College London, University of London</affiliation></author>
      <pages>530-546</pages>
      <abstract>In order to oversee advanced AI systems, it is important to understand their reasons for generating a given output. When prompted, large language models (LLMs) can provide natural language explanations or reasoning traces that sound plausible and receive high ratings from human annotators. However, it is unclear to what extent these explanations are truly capturing the factors responsible for the model’s predictions: the most “human-like” explanation may be different from the one that is most faithful to the model’s true decision making process. In this work, we introduce the correlational counterfactual test (CCT), a faithfulness metric based on counterfactual input edits that takes into account not just the binary label change, but the total shift in the model’s predicted label distribution. We evaluate the faithfulness of free-text explanations generated by few-shot-prompted LLMs from the Llama-2 family on three NLP tasks. We find that these explanations are indeed more likely to mention factors when they are impactful to the model’s prediction, with the degree of association increasing with model size but varying significantly by task.</abstract>
      <url hash="c9b96567">2024.acl-short.49</url>
    </paper>
    <paper id="50">
      <title>Naming, Describing, and Quantifying Visual Objects in Humans and <fixed-case>LLM</fixed-case>s</title>
      <author><first>Alberto</first><last>Testoni</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Juell</first><last>Sprott</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Sandro</first><last>Pezzelle</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>547-557</pages>
      <abstract>While human speakers use a variety of different expressions when describing the same object in an image, giving rise to a distribution of plausible labels driven by pragmatic constraints, the extent to which current Vision &amp; Language Large Language Models (VLLMs) can mimic this crucial feature of language use is an open question. This applies to common, everyday objects, but it is particularly interesting for uncommon or novel objects for which a category label may be lacking or fuzzy. Furthermore, similar patterns of variation are observed among human speakers for highly context-sensitive expressions, such as the quantifiers ‘few’ or ‘most’. In our work, we evaluate VLLMs (FROMAGe, BLIP-2, LLaVA) on three categories (nouns, attributes, and quantifiers) where humans show great subjective variability concerning the distribution over plausible labels, using datasets and resources mostly under-explored in previous work. Our results reveal mixed evidence on the ability of VLLMs to capture human naming preferences at generation time: while some models are good at mimicking human distributions for nouns and attributes, all of them fail to assign quantifiers, a task that requires more accurate, high-level reasoning.</abstract>
      <url hash="23bf0014">2024.acl-short.50</url>
    </paper>
    <paper id="51">
      <title>Are <fixed-case>LLM</fixed-case>s classical or nonmonotonic reasoners? Lessons from generics</title>
      <author><first>Alina</first><last>Leidinger</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Robert</first><last>Van Rooij</last></author>
      <author><first>Ekaterina</first><last>Shutova</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>558-573</pages>
      <abstract>Recent scholarship on reasoning in LLMs has supplied evidence of impressive performance and flexible adaptation to machine generated or human critique. Nonmonotonic reasoning, crucial to human cognition for navigating the real world, remains a challenging, yet understudied task. In this work, we study nonmonotonic reasoning capabilities of seven state-of-the-art LLMs in one abstract and one commonsense reasoning task featuring generics, such as ‘Birds fly’, and exceptions, ‘Penguins don’t fly’ (see Fig. 1). While LLMs exhibit reasoning patterns in accordance with human nonmonotonic reasoning abilities, they fail to maintain stable beliefs on truth conditions of generics at the addition of supporting examples (‘Owls fly’) or unrelated information (‘Lions have manes’).Our findings highlight pitfalls in attributing human reasoning behaviours to LLMs as long as consistent reasoning remains elusive.</abstract>
      <url hash="c73e53d9">2024.acl-short.51</url>
    </paper>
    <paper id="52">
      <title><fixed-case>C</fixed-case>onstitutional<fixed-case>E</fixed-case>xperts: Training a Mixture of Principle-based Prompts</title>
      <author><first>Savvas</first><last>Petridis</last><affiliation>Google</affiliation></author>
      <author><first>Ben</first><last>Wedin</last><affiliation>Google</affiliation></author>
      <author><first>Ann</first><last>Yuan</last><affiliation>Google</affiliation></author>
      <author><first>James</first><last>Wexler</last><affiliation>Google</affiliation></author>
      <author><first>Nithum</first><last>Thain</last><affiliation>Google</affiliation></author>
      <pages>574-582</pages>
      <abstract>Large language models (LLMs) are highly capable at a variety of tasks given the right prompt, but writing one is still a difficult and tedious process. In this work, we introduce ConstitutionalExperts, a method for learning a prompt consisting of constitutional principles (i.e. rules), given a training dataset. Unlike prior methods that optimize the prompt as a single entity, our method incrementally improves the prompt by surgically editing individual principles. We also show that we can improve overall performance by learning unique prompts for different semantic regions of the training data and using a mixture-of-experts (MoE) architecture to route inputs at inference time. We compare our method to other state of the art prompt-optimization techniques across six benchmark datasets. We also investigate whether MoE improves these other techniques. Our results suggest that ConstitutionalExperts outperforms other prompt optimization techniques by 10.9% (F1) and that mixture-of-experts improves all techniques, suggesting its broad applicability.</abstract>
      <url hash="6867b217">2024.acl-short.52</url>
    </paper>
    <paper id="53">
      <title>Time Sensitive Knowledge Editing through Efficient Finetuning</title>
      <author><first>Xiou</first><last>Ge</last><affiliation>Apple</affiliation></author>
      <author><first>Ali</first><last>Mousavi</last><affiliation>Apple</affiliation></author>
      <author><first>Edouard</first><last>Grave</last><affiliation>Facebook</affiliation></author>
      <author><first>Armand</first><last>Joulin</last><affiliation>Facebook</affiliation></author>
      <author><first>Kun</first><last>Qian</last><affiliation>Adobe Systems</affiliation></author>
      <author><first>Benjamin</first><last>Han</last><affiliation>Apple</affiliation></author>
      <author><first>Mostafa</first><last>Arefiyan</last><affiliation>Apple</affiliation></author>
      <author><first>Yunyao</first><last>Li</last><affiliation>Adobe Systems</affiliation></author>
      <pages>583-593</pages>
      <abstract>Large Language Models (LLMs) have demonstrated impressive capability in different tasks and are bringing transformative changes to many domains. However, keeping the knowledge in LLMs up-to-date remains a challenge once pretraining is complete. It is thus essential to design effective methods to both update obsolete knowledge and induce new knowledge into LLMs. Existing locate-and-edit knowledge editing (KE) method suffers from two limitations. First, the post-edit LLMs by such methods generally have poor capability in answering complex queries that require multi-hop reasoning. Second, the long run-time of such locate-and-edit methods to perform knowledge edits make it infeasible for large scale KE in practice. In this paper, we explore Parameter-Efficient Fine-Tuning (PEFT) techniques as an alternative for KE. We curate a more comprehensive temporal KE dataset with both knowledge update and knowledge injection examples for KE performance benchmarking. We further probe the effect of fine-tuning on a range of layers in an LLM for the multi-hop QA task. We find that PEFT performs better than locate-and-edit techniques for time-sensitive knowledge edits.</abstract>
      <url hash="5632a14b">2024.acl-short.53</url>
    </paper>
    <paper id="54">
      <title><fixed-case>PR</fixed-case>ewrite: Prompt Rewriting with Reinforcement Learning</title>
      <author><first>Weize</first><last>Kong</last><affiliation>Google</affiliation></author>
      <author><first>Spurthi</first><last>Hombaiah</last><affiliation>Google Research</affiliation></author>
      <author><first>Mingyang</first><last>Zhang</last><affiliation>Google</affiliation></author>
      <author><first>Qiaozhu</first><last>Mei</last><affiliation>University of Michigan</affiliation></author>
      <author><first>Michael</first><last>Bendersky</last><affiliation>Google</affiliation></author>
      <pages>594-601</pages>
      <abstract>Prompt engineering is critical for the development of LLM-based applications. However, it is usually done manually in a “trial and error” fashion that can be time consuming, ineffective, and sub-optimal. Even for the prompts which seemingly work well, there is always a lingering question: can the prompts be made better with further modifications?To address these problems, we investigate automated prompt engineering in this paper. Specifically, we propose PRewrite, an automated method to rewrite an under-optimized prompt to a more effective prompt. We instantiate the prompt rewriter using an LLM. The rewriter LLM is trained using reinforcement learning to optimize the performance on a given downstream task. We conduct experiments on diverse benchmark datasets, which demonstrates the effectiveness of PRewrite.</abstract>
      <url hash="69dbfe63">2024.acl-short.54</url>
    </paper>
    <paper id="55">
      <title>Paraphrasing in Affirmative Terms Improves Negation Understanding</title>
      <author><first>MohammadHossein</first><last>Rezaei</last></author>
      <author><first>Eduardo</first><last>Blanco</last><affiliation>University of Arizona</affiliation></author>
      <pages>602-615</pages>
      <abstract>Negation is a common linguistic phenomenon. Yet language models face challenges with negation in many natural language understanding tasks such as question answering and natural language inference. In this paper, we experiment with seamless strategies that incorporate affirmative interpretations (i.e., paraphrases without negation) to make models more robust against negation. Crucially, our affirmative interpretations are obtained automatically. We show improvements with CondaQA, a large corpus requiring reasoning with negation, and five natural language understanding tasks.</abstract>
      <url hash="9faafc91">2024.acl-short.55</url>
    </paper>
    <paper id="56">
      <title>Exploring Conditional Variational Mechanism to <fixed-case>P</fixed-case>inyin Input Method for Addressing One-to-Many Mappings in Low-Resource Scenarios</title>
      <author><first>Bin</first><last>Sun</last></author>
      <author><first>Jianfeng</first><last>Li</last><affiliation>Wechat AI</affiliation></author>
      <author><first>Hao</first><last>Zhou</last><affiliation>Tencent, Wechat AI</affiliation></author>
      <author><first>Fandong</first><last>Meng</last><affiliation>WeChat AI, Tencent Inc.</affiliation></author>
      <author><first>Kan</first><last>Li</last></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>616-629</pages>
      <abstract>Pinyin input method engine (IME) refers to the transformation tool from pinyin sequence to Chinese characters, which is widely used on mobile phone applications. Due to the homophones, Pinyin IME suffers from the one-to-many mapping problem in the process of pinyin sequences to Chinese characters. To solve the above issue, this paper makes the first exploration to leverage an effective conditional variational mechanism (CVM) for pinyin IME. However, to ensure the stable and smooth operation of Pinyin IME under low-resource conditions (e.g., on offline mobile devices), we should balance diversity, accuracy, and efficiency with CVM, which is still challenging. To this end, we employ a novel strategy that simplifies the complexity of semantic encoding by facilitating the interaction between pinyin and the Chinese character information during the construction of continuous latent variables. Concurrently, the accuracy of the outcomes is enhanced by capitalizing on the discrete latent variables. Experimental results demonstrate the superior performance of our method.</abstract>
      <url hash="42f5e08e">2024.acl-short.56</url>
    </paper>
    <paper id="57">
      <title>Consistency Training by Synthetic Question Generation for Conversational Question Answering</title>
      <author><first>Hamed</first><last>Hemati</last><affiliation>Sharif University of Technology</affiliation></author>
      <author><first>Hamid</first><last>Beigy</last></author>
      <pages>630-639</pages>
      <abstract>Efficiently modeling historical information is a critical component in addressing user queries within a conversational question-answering (QA) context, as historical context plays a vital role in clarifying the user’s questions. However, irrelevant history induces noise in the reasoning process, especially for those questions with a considerable historical context. In our novel model-agnostic approach, referred to as **CoTaH** (**Co**nsistency-**T**rained **a**ugmented **H**istory), we augment the historical information with synthetic questions and subsequently employ consistency training to train a model that utilizes both real and augmented historical data to implicitly make the reasoning robust to irrelevant history. To the best of our knowledge, this is the first instance of research using synthetic question generation as a form of data augmentation to model conversational QA settings. By citing a common modeling error prevalent in previous research, we introduce a new baseline and compare our model’s performance against it, demonstrating an improvement in results, particularly in later turns of the conversation, when dealing with questions that include a large historical context.</abstract>
      <url hash="754ad937">2024.acl-short.57</url>
    </paper>
    <paper id="58">
      <title>How Good is Zero-Shot <fixed-case>MT</fixed-case> Evaluation for Low Resource <fixed-case>I</fixed-case>ndian Languages?</title>
      <author><first>Anushka</first><last>Singh</last></author>
      <author><first>Ananya</first><last>Sai</last><affiliation>Indian Institute of Technology, Madras</affiliation></author>
      <author><first>Raj</first><last>Dabre</last><affiliation>National Institute of Information and Communications Technology (NICT), National Institute of Advanced Industrial Science and Technology</affiliation></author>
      <author><first>Ratish</first><last>Puduppully</last><affiliation>A*STAR</affiliation></author>
      <author><first>Anoop</first><last>Kunchukuttan</last><affiliation>Microsoft and Indian Institute of Technology, Madras, Dhirubhai Ambani Institute Of Information and Communication Technology</affiliation></author>
      <author><first>Mitesh</first><last>Khapra</last><affiliation>Indian Institute of Technology, Madras, Dhirubhai Ambani Institute Of Information and Communication Technology</affiliation></author>
      <pages>640-649</pages>
      <abstract>While machine translation evaluation has been studied primarily for high-resource languages, there has been a recent interest in evaluation for low-resource languages due to the increasing availability of data and models. In this paper, we focus on a zero-shot evaluation setting focusing on low-resource Indian languages, namely Assamese, Kannada, Maithili, and Punjabi. We collect sufficient Multi-Dimensional Quality Metrics (MQM) and Direct Assessment (DA) annotations to create test sets and meta-evaluate a plethora of automatic evaluation metrics. We observe that even for learned metrics, which are known to exhibit zero-shot performance, the Kendall Tau and Pearson correlations with human annotations are only as high as 0.32 and 0.45. Synthetic data approaches show mixed results and overall do not help close the gap by much for these languages. This indicates that there is still a long way to go for low-resource evaluation.</abstract>
      <url hash="aceec2ad">2024.acl-short.58</url>
    </paper>
    <paper id="59">
      <title>Zero-Shot Cross-Lingual Reranking with Large Language Models for Low-Resource Languages</title>
      <author><first>Mofetoluwa</first><last>Adeyemi</last><affiliation>University of Waterloo</affiliation></author>
      <author><first>Akintunde</first><last>Oladipo</last></author>
      <author><first>Ronak</first><last>Pradeep</last></author>
      <author><first>Jimmy</first><last>Lin</last><affiliation>University of Waterloo</affiliation></author>
      <pages>650-656</pages>
      <abstract>Large language models (LLMs) as listwise rerankers have shown impressive zero-shot capabilities in various passage ranking tasks. Despite their success, there is still a gap in existing literature on their effectiveness in reranking low-resource languages. To address this, we investigate how LLMs function as listwise rerankers in cross-lingual information retrieval (CLIR) systems with queries in English and passages in four African languages: Hausa, Somali, Swahili, and Yoruba. We analyze and compare the effectiveness of monolingual reranking using either query or document translations. We also evaluate the effectiveness of LLMs when leveraging their own generated translations. To grasp the general picture, we examine the effectiveness of multiple LLMs — the proprietary models RankGPT-4 and RankGPT-3.5, along with the open-source model RankZephyr. While the document translation setting, i.e., both queries and documents are in English, leads to the best reranking effectiveness, our results indicate that for specific LLMs, reranking in the African language setting achieves competitive effectiveness with the cross-lingual setting, and even performs better when using the LLM’s own translations.</abstract>
      <url hash="19fc32f3">2024.acl-short.59</url>
    </paper>
    <paper id="60">
      <title>Cross-Modal Projection in Multimodal <fixed-case>LLM</fixed-case>s Doesn’t Really Project Visual Attributes to Textual Space</title>
      <author><first>Gaurav</first><last>Verma</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Minje</first><last>Choi</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Kartik</first><last>Sharma</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Jamelle</first><last>Watson-Daniels</last><affiliation>Harvard University</affiliation></author>
      <author><first>Sejoon</first><last>Oh</last></author>
      <author><first>Srijan</first><last>Kumar</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <pages>657-664</pages>
      <abstract>Multimodal large language models (MLLMs) like LLaVA and GPT-4(V) enable general-purpose conversations about images with the language modality. As off-the-shelf MLLMs may have limited capabilities on images from domains like dermatology and agriculture, they must be fine-tuned to unlock domain-specific applications. The prevalent architecture of current open-source MLLMs comprises two major modules: an image-language (cross-modal) projection network and a large language model. It is desirable to understand the roles of these two modules in modeling domain-specific visual attributes to inform the design of future models and streamline the interpretability efforts on the current models. To this end, via experiments on 4 datasets and under 2 fine-tuning settings, we find that as the MLLM is fine-tuned, it indeed gains domain-specific visual capabilities, but the updates do not lead to the projection extracting relevant domain-specific visual attributes. Our results indicate that the domain-specific visual attributes are modeled by the LLM, even when only the projection is fine-tuned. Through this study, we offer a potential reinterpretation of the role of cross-modal projections in MLLM architectures.</abstract>
      <url hash="f9f43b58">2024.acl-short.60</url>
    </paper>
    <paper id="61">
      <title>Guidance-Based Prompt Data Augmentation in Specialized Domains for Named Entity Recognition</title>
      <author><first>Hyeonseok</first><last>Kang</last><affiliation>Chungnam National University</affiliation></author>
      <author><first>Hyein</first><last>Seo</last><affiliation>Chungnam National University</affiliation></author>
      <author><first>Jeesu</first><last>Jung</last></author>
      <author><first>Sangkeun</first><last>Jung</last></author>
      <author><first>Du-Seong</first><last>Chang</last></author>
      <author><first>Riwoo</first><last>Chung</last></author>
      <pages>665-672</pages>
      <abstract>While the abundance of rich and vast datasets across numerous fields has facilitated the advancement of natural language processing, sectors in need of specialized data types continue to struggle with the challenge of finding quality data. Our study introduces a novel guidance data augmentation technique utilizing abstracted context and sentence structures to produce varied sentences while maintaining context-entity relationships, addressing data scarcity challenges. By fostering a closer relationship between context, sentence structure, and role of entities, our method enhances data augmentation’s effectiveness. Consequently, by showcasing diversification in both entity-related vocabulary and overall sentence structure, and simultaneously improving the training performance of named entity recognition task.</abstract>
      <url hash="916fb77b">2024.acl-short.61</url>
    </paper>
    <paper id="62">
      <title>Aligning Large Language Models via Fine-grained Supervision</title>
      <author><first>Dehong</first><last>Xu</last><affiliation>University of California, Los Angeles</affiliation></author>
      <author><first>Liang</first><last>Qiu</last><affiliation>Amazon</affiliation></author>
      <author><first>Minseok</first><last>Kim</last><affiliation>Amazon</affiliation></author>
      <author><first>Faisal</first><last>Ladhak</last><affiliation>Columbia University</affiliation></author>
      <author><first>Jaeyoung</first><last>Do</last></author>
      <pages>673-680</pages>
      <abstract>Pre-trained large-scale language models (LLMs) excel at producing coherent articles, yet their outputs may be untruthful, toxic, or fail to align with user expectations. Current approaches focus on using reinforcement learning with human feedback (RLHF) to improve model alignment, which works by transforming coarse human preferences of LLM outputs into a feedback signal that guides the model learning process. However, because this approach operates on sequence-level feedback, it lacks the precision to identify the exact parts of the output affecting user preferences. To address this gap, we propose a method to enhance LLM alignment through fine-grained token-level supervision. Specifically, we ask annotators to minimally edit less preferred responses within the standard reward modeling dataset to make them more favorable, ensuring changes are made only where necessary while retaining most of the original content. The refined dataset is used to train a token-level reward model, which is then used for training our fine-grained Proximal Policy Optimization (PPO) model. Our experiment results demonstrate that this approach can improve LLM performance by up to 5.1% in terms of win rate against the reference model, compared with the traditional PPO model.</abstract>
      <url hash="824990e5">2024.acl-short.62</url>
    </paper>
    <paper id="63">
      <title>Annotating <fixed-case>F</fixed-case>rame<fixed-case>N</fixed-case>et via Structure-Conditioned Language Generation</title>
      <author><first>Xinyue</first><last>Cui</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Swabha</first><last>Swayamdipta</last><affiliation>University of Southern California</affiliation></author>
      <pages>681-692</pages>
      <abstract>Despite the remarkable generative capabilities of language models in producing naturalistic language, their effectiveness on explicit manipulation and generation of linguistic structures remain understudied. In this paper, we investigate the task of generating new sentences preserving a given semantic structure, following the FrameNet formalism. We propose a framework to produce novel frame-semantically annotated sentences following an overgenerate-and-filter approach. Our results show that conditioning on rich, explicit semantic information tends to produce generations with high human acceptance, under both prompting and finetuning. Our generated frame-semantic structured annotations are effective at training data augmentation for frame-semantic role labeling in low-resource settings; however, we do not see benefits under higher resource settings. Our study concludes that while generating high-quality, semantically rich data might be within reach, the downstream utility of such generations remains to be seen, highlighting the outstanding challenges with automating linguistic annotation tasks.</abstract>
      <url hash="a7d738ab">2024.acl-short.63</url>
    </paper>
    <paper id="64">
      <title><fixed-case>DUAL</fixed-case>-<fixed-case>REFLECT</fixed-case>: Enhancing Large Language Models for Reflective Translation through Dual Learning Feedback Mechanisms</title>
      <author><first>Andong</first><last>Chen</last></author>
      <author><first>Lianzhang</first><last>Lou</last></author>
      <author><first>Kehai</first><last>Chen</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <author><first>Xuefeng</first><last>Bai</last></author>
      <author><first>Yang</first><last>Xiang</last></author>
      <author><first>Muyun</first><last>Yang</last></author>
      <author><first>Tiejun</first><last>Zhao</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <pages>693-704</pages>
      <abstract>Recently, large language models (LLMs) enhanced by self-reflection have achieved promising performance on machine transla004 tion. The key idea is guiding LLMs to generate translation with human-like feedback. However, existing self-reflection methods lack effective feedback information, limiting the translation performance. To address this, we introduce a DUAL-REFLECT framework, leveraging the dual learning of translation tasks to provide effective feedback, thereby enhancing the models’ self-reflective abilities and improving translation performance. The application of this method across various translation tasks has proven its effectiveness in improving translation accuracy and eliminating ambiguities, especially in translation tasks with low-resource language pairs.</abstract>
      <url hash="4f65d128">2024.acl-short.64</url>
    </paper>
    <paper id="65">
      <title>Towards Artwork Explanation in Large-scale Vision Language Models</title>
      <author><first>Kazuki</first><last>Hayashi</last></author>
      <author><first>Yusuke</first><last>Sakai</last><affiliation>Nara Institute of Science and Technology, Japan</affiliation></author>
      <author><first>Hidetaka</first><last>Kamigaito</last><affiliation>Division of Information Science, Nara Institute of Science and Technology</affiliation></author>
      <author><first>Katsuhiko</first><last>Hayashi</last><affiliation>The University of Tokyo</affiliation></author>
      <author><first>Taro</first><last>Watanabe</last><affiliation>Nara Institute of Science and Technology, Japan</affiliation></author>
      <pages>705-729</pages>
      <abstract>Large-scale Vision-Language Models (LVLMs) output text from images and instructions, demonstrating advanced capabilities in text generation and comprehension. However, it has not been clarified to what extent LVLMs understand the knowledge necessary for explaining images, the complex relationships between various pieces of knowledge, and how they integrate these understandings into their explanations. To address this issue, we propose a new task: the artwork explanation generation task, along with its evaluation dataset and metric for quantitatively assessing the understanding and utilization of knowledge about artworks. This task is apt for image description based on the premise that LVLMs are expected to have pre-existing knowledge of artworks, which are often subjects of wide recognition and documented information.It consists of two parts: generating explanations from both images and titles of artworks, and generating explanations using only images, thus evaluating the LVLMs’ language-based and vision-based knowledge.Alongside, we release a training dataset for LVLMs to learn explanations that incorporate knowledge about artworks.Our findings indicate that LVLMs not only struggle with integrating language and visual information but also exhibit a more pronounced limitation in acquiring knowledge from images alone. The datasets ExpArt=Explain Artworks are available at https://huggingface.co/datasets/naist-nlp/ExpArt</abstract>
      <url hash="75b55d2f">2024.acl-short.65</url>
    </paper>
    <paper id="66">
      <title>On the Hallucination in Simultaneous Machine Translation</title>
      <author><first>Meizhi</first><last>Zhong</last></author>
      <author><first>Kehai</first><last>Chen</last><affiliation>Harbin Institute of Technology (Shenzhen)</affiliation></author>
      <author><first>Zhengshan</first><last>Xue</last><affiliation>Tianjin University and OPPO</affiliation></author>
      <author><first>Lemao</first><last>Liu</last><affiliation>Tencent</affiliation></author>
      <author><first>Mingming</first><last>Yang</last><affiliation>Tencent AI Lab</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <pages>730-742</pages>
      <abstract>It is widely known that hallucination is a critical issue in Simultaneous Machine Translation (SiMT) due to the absence of source-side information. While many efforts have been made to enhance performance for SiMT, few of them attempt to understand and analyze hallucination in SiMT.Therefore, we conduct a comprehensive analysis of hallucination in SiMT from two perspectives: understanding the distribution of hallucination words and the target-side context usage of them.Intensive experiments demonstrate some valuable findings and particularly show that it is possible to alleviate hallucination by decreasing the over usage of target-side information for SiMT.</abstract>
      <url hash="c8fb840a">2024.acl-short.66</url>
    </paper>
    <paper id="67">
      <title>Self-Augmented In-Context Learning for Unsupervised Word Translation</title>
      <author><first>Yaoyiran</first><last>Li</last></author>
      <author><first>Anna</first><last>Korhonen</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Ivan</first><last>Vulić</last><affiliation>University of Cambridge and PolyAI Limited</affiliation></author>
      <pages>743-753</pages>
      <abstract>Recent work has shown that, while large language models (LLMs) demonstrate strong word translation or bilingual lexicon induction (BLI) capabilities in few-shot setups, they still cannot match the performance of ‘traditional’ mapping-based approaches in the unsupervised scenario where no seed translation pairs are available, especially for lower-resource languages. To address this challenge with LLMs, we propose self-augmented in-context learning (SAIL) for unsupervised BLI: starting from a zero-shot prompt, SAIL iteratively induces a set of high-confidence word translation pairs for in-context learning (ICL) from an LLM, which it then reapplies to the same LLM in the ICL fashion. Our method shows substantial gains over zero-shot prompting of LLMs on two established BLI benchmarks spanning a wide range of language pairs, also outperforming mapping-based baselines across the board. In addition to achieving state-of-the-art unsupervised BLI performance, we also conduct comprehensive analyses on SAIL and discuss its limitations.</abstract>
      <url hash="a83166d2">2024.acl-short.67</url>
    </paper>
    <paper id="68">
      <title><fixed-case>RAM</fixed-case>-<fixed-case>EHR</fixed-case>: Retrieval Augmentation Meets Clinical Predictions on Electronic Health Records</title>
      <author><first>Ran</first><last>Xu</last><affiliation>Emory University</affiliation></author>
      <author><first>Wenqi</first><last>Shi</last><affiliation>University of Texas Southwestern Medical Center</affiliation></author>
      <author><first>Yue</first><last>Yu</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Yuchen</first><last>Zhuang</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Bowen</first><last>Jin</last></author>
      <author><first>May Dongmei</first><last>Wang</last></author>
      <author><first>Joyce</first><last>Ho</last><affiliation>Emory University</affiliation></author>
      <author><first>Carl</first><last>Yang</last><affiliation>Emory University</affiliation></author>
      <pages>754-765</pages>
      <abstract>We present RAM-EHR, a Retrieval AugMentation pipeline to improve clinical predictions on Electronic Health Records (EHRs). RAM-EHR first collects multiple knowledge sources, converts them into text format, and uses dense retrieval to obtain information related to medical concepts. This strategy addresses the difficulties associated with complex names for the concepts. RAM-EHR then augments the local EHR predictive model co-trained with consistency regularization to capture complementary information from patient visits and summarized knowledge. Experiments on two EHR datasets show the efficacy of RAM-EHR over previous knowledge-enhanced baselines (3.4% gain in AUROC and 7.2% gain in AUPR), emphasizing the effectiveness of the summarized knowledge from RAM-EHR for clinical prediction tasks.</abstract>
      <url hash="fce30056">2024.acl-short.68</url>
    </paper>
  </volume>
  <volume id="srw" ingest-date="2024-08-08" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)</booktitle>
      <editor><first>Xiyan</first><last>Fu</last><affiliation>Heidelberg University</affiliation></editor>
      <editor><first>Eve</first><last>Fleisig</last><affiliation>UC Berkeley</affiliation></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Bangkok, Thailand and virtual meeting</address>
      <month>August</month>
      <year>2024</year>
      <url hash="bed3d6fa">2024.acl-srw</url>
      <venue>acl</venue>
    </meta>
    <frontmatter>
      <url hash="e9c7245d">2024.acl-srw.0</url>
    </frontmatter>
    <paper id="1">
      <title>Feriji: A <fixed-case>F</fixed-case>rench-<fixed-case>Z</fixed-case>arma Parallel Corpus, Glossary &amp; Translator</title>
      <author><first>Mamadou</first><last>Keita</last></author>
      <author><first>Elysabhete</first><last>Ibrahim</last></author>
      <author><first>Habibatou</first><last>Alfari</last></author>
      <author><first>Christopher</first><last>Homan</last></author>
      <pages>1-9</pages>
      <abstract>Machine translation (MT) is a rapidly expanding field that has experienced significant advancements in recent years with the development of models capable of translating multiple languages with remarkable accuracy. However, the representation of African languages in this field still needs improvement due to linguistic complexities and limited resources. This applies to the Zarma language, a dialect of Songhay (of the Nilo-Saharan language family) spoken by over 5 million people across Niger and neighboring countries (Lewis et al., 2016). This paper introduces Feriji, the first robust French-Zarma parallel corpus and glossary designed for MT. The corpus, containing 61,085 sentences in Zarma and 42,789 in French, and a glossary of 4,062 words represents a significant step in addressing the need for more resources for Zarma. We fine-tune three large language models on our dataset, obtaining a BLEU score of 30.06 on the best-performing model. We further evaluate the models on human judgments of fluency, comprehension, and readability and the importance and impact of the corpus and models. Our contributions help to bridge a significant language gap and promote an essential and overlooked indigenous African language.</abstract>
      <url hash="64cb8c14">2024.acl-srw.1</url>
    </paper>
    <paper id="2">
      <title>Pragmatic inference of scalar implicature by <fixed-case>LLM</fixed-case>s</title>
      <author><first>Ye-eun</first><last>Cho</last></author>
      <author><first>Ismkim99@skku.edu</first><last>Ismkim99@skku.edu</last><affiliation>NA</affiliation></author>
      <pages>10-20</pages>
      <abstract>This study investigates how Large Language Models (LLMs), particularly BERT (Devlin et al., 2019) and GPT-2 (Radford et al., 2019), engage in pragmatic inference of scalar implicature, such as some. Two sets of experiments were conducted using cosine similarity and next sentence/token prediction as experimental methods. The results in experiment 1 showed that, both models interpret some as pragmatic implicature not all in the absence of context, aligning with human language processing. In experiment 2, in which Question Under Discussion (QUD) was presented as a contextual cue, BERT showed consistent performance regardless of types of QUDs, while GPT-2 encountered processing difficulties since a certain type of QUD required pragmatic inference for implicature. The findings revealed that, in terms of theoretical approaches, BERT inherently incorporates pragmatic implicature not all within the term some, adhering to Default model (Levinson, 2000). In contrast, GPT-2 seems to encounter processing difficulties in inferring pragmatic implicature within context, consistent with Context-driven model (Sperber and Wilson, 2002).</abstract>
      <url hash="b056f7d3">2024.acl-srw.2</url>
    </paper>
    <paper id="3">
      <title>Topic Modeling for Short Texts with Large Language Models</title>
      <author><first>Tomoki</first><last>Doi</last></author>
      <author><first>Masaru</first><last>Isonuma</last></author>
      <author><first>Hitomi</first><last>Yanaka</last><affiliation>the University of Tokyo</affiliation></author>
      <pages>21-33</pages>
      <abstract>As conventional topic models rely on word co-occurrence to infer latent topics, topic modeling for short texts has been a long-standing challenge. Large Language Models (LLMs) can potentially overcome this challenge by contextually learning the meanings of words via pretraining. In this paper, we study two approaches to using LLMs for topic modeling: parallel prompting and sequential prompting. Input length limitations prevent LLMs from processing many texts at once. However, an arbitrary number of texts can be handled by LLMs by splitting the texts into smaller subsets and processing them in parallel or sequentially. Our experimental results demonstrate that our methods can identify more coherent topics than existing ones while maintaining the diversity of the induced topics. Furthermore, we found that the inferred topics cover the input texts to some extent, while hallucinated topics are hardly generated.</abstract>
      <url hash="49f3cdbb">2024.acl-srw.3</url>
    </paper>
    <paper id="4">
      <title>Can <fixed-case>LLM</fixed-case>s substitute <fixed-case>SQL</fixed-case>? Comparing Resource Utilization of Querying <fixed-case>LLM</fixed-case>s versus Traditional Relational Databases</title>
      <author><first>Xiang</first><last>Zhang</last><affiliation>Metropolitan College, Boston University</affiliation></author>
      <author><first>Khatoon</first><last>Khedri</last></author>
      <author><first>Reza</first><last>Rawassizadeh</last></author>
      <pages>34-41</pages>
      <abstract>Large Language Models (LLMs) can automate or substitute different types of tasks in the software engineering process. This study evaluates the resource utilization and accuracy of LLM in interpreting and executing natural language queries against traditional SQL within relational database management systems. We empirically examine the resource utilization and accuracy of nine LLMs varying from 7 to 34 Billion parameters, including Llama2 7B, Llama2 13B, Mistral, Mixtral, Optimus-7B, SUS-chat-34B, platypus-yi-34b, NeuralHermes-2.5-Mistral-7B and Starling-LM-7B-alpha, using a small transaction dataset. Our findings indicate that using LLMs for database queries incurs significant energy overhead (even small and quantized models), making it an environmentally unfriendly approach. Therefore, we advise against replacing relational databases with LLMs due to their substantial resource utilization.</abstract>
      <url hash="5a5d8056">2024.acl-srw.4</url>
    </paper>
    <paper id="5">
      <title>Speech-to-Speech Translation with Discrete-Unit-Based Style Transfer</title>
      <author><first>Yongqi</first><last>Wang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Bai</first><last>Jionghao</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Rongjie</first><last>Huang</last><affiliation>FAIR</affiliation></author>
      <author><first>Ruiqi</first><last>Li</last></author>
      <author><first>Zhiqing</first><last>Hong</last></author>
      <author><first>Zhou</first><last>Zhao</last><affiliation>Zhejiang University and Zhejiang University</affiliation></author>
      <pages>42-49</pages>
      <abstract>Direct speech-to-speech translation (S2ST) with discrete self-supervised representations has achieved remarkable accuracy, but is unable to preserve the speaker timbre of the source speech. Meanwhile, the scarcity of high-quality speaker-parallel data poses a challenge for learning style transfer during translation. We design an S2ST pipeline with style-transfer capability on the basis of discrete self-supervised speech representations and codec units. The acoustic language model we introduce for style transfer leverages self-supervised in-context learning, acquiring style transfer ability without relying on any speaker-parallel data, thereby overcoming data scarcity. By using extensive training data, our model achieves zero-shot cross-lingual style transfer on previously unseen source languages. Experiments show that our model generates translated speeches with high fidelity and speaker similarity. Audio samples are available at http://stylelm.github.io/ .</abstract>
      <url hash="42b083ff">2024.acl-srw.5</url>
    </paper>
    <paper id="6">
      <title><fixed-case>I</fixed-case>nstruct<fixed-case>C</fixed-case>oder: Instruction Tuning Large Language Models for Code Editing</title>
      <author><first>Kaixin</first><last>Li</last></author>
      <author><first>Qisheng</first><last>Hu</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>James</first><last>Zhao</last><affiliation>national university of singaore, National University of Singapore</affiliation></author>
      <author><first>Hui</first><last>Chen</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Yuxi</first><last>Xie</last></author>
      <author><first>Tiedong</first><last>Liu</last></author>
      <author><first>Michael</first><last>Shieh</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Junxian</first><last>He</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <pages>50-70</pages>
      <abstract>Code editing encompasses a variety of pragmatic tasks that developers deal with daily. Despite its relevance and practical usefulness, automatic code editing remains an underexplored area in the evolution of deep learning models, partly due to data scarcity. In this work, we explore the use of Large Language Models (LLMs) to edit code based on user instructions. Evaluated on a novel human-written execution-based benchmark dubbed EditEval, we found current models often struggle to fulfill the instructions. In light of this, we contribute InstructCoder, the first instruction-tuning dataset designed to adapt LLMs for general-purpose code editing, containing high-diversity code-editing tasks such as comment insertion, code optimization, and code refactoring. It consists of over 114,000 instruction-input-output triplets and covers multiple distinct code editing scenarios. The collection process starts with filtered commit data sourced from GitHub Python repositories as seeds. Subsequently, the dataset is systematically expanded through an iterative process, where both seed and generated tasks are used to prompt ChatGPT for more data. Our findings reveal that open-source LLMs fine-tuned on InstructCoder can significantly enhance the accuracy of code edits, exhibiting superior code-editing performance matching advanced proprietary LLMs. The datasets and the source code are publicly available.</abstract>
      <url hash="f674712d">2024.acl-srw.6</url>
    </paper>
    <paper id="7">
      <title><fixed-case>B</fixed-case>ias<fixed-case>DPO</fixed-case>: Mitigating Bias in Language Models through Direct Preference Optimization</title>
      <author><first>Ahmed</first><last>Allam</last></author>
      <pages>71-79</pages>
      <abstract>Large Language Models (LLMs) have become pivotal in advancing natural language processing, yet their potential to perpetuate biases poses significant concerns. This paper introduces a new framework employing Direct Preference Optimization (DPO) to mitigate gender, racial, and religious biases in LLM-generated English text. By developing a loss function that favors less biased over biased completions, our approach cultivates a preference for respectful and non-discriminatory language in LLMs. We also contribute a manually designed dataset for training LLMs to recognize and correct biases. This dataset encompasses a diverse range of prompts paired with both biased and unbiased completions. Implementing this approach on the Microsoft Phi-2 model, we demonstrate substantial reductions in biased outputs as our model outperforms the baseline model on almost all bias benchmarks. Our model also achieves better performance compared to other open-source models on most benchmarks. By reducing biases in the language generated by the model, our study marks a significant step towards developing more ethical and socially responsible LLMs. We publicly release BiasDPO dataset on HuggingFace.</abstract>
      <url hash="8a3968a2">2024.acl-srw.7</url>
    </paper>
    <paper id="8">
      <title><fixed-case>M</fixed-case>o<fixed-case>E</fixed-case>xtend: Tuning New Experts for Modality and Task Extension</title>
      <author><first>Shanshan</first><last>Zhong</last></author>
      <author><first>Shanghua</first><last>Gao</last><affiliation>Harvard University</affiliation></author>
      <author><first>Zhongzhan</first><last>Huang</last><affiliation>Sun Yat-Sen University</affiliation></author>
      <author><first>Wushao</first><last>Wen</last><affiliation>SUN YAT-SEN UNIVERSITY</affiliation></author>
      <author><first>Marinka</first><last>Zitnik</last><affiliation>Harvard University</affiliation></author>
      <author><first>Pan</first><last>Zhou</last><affiliation>Singapore Management University</affiliation></author>
      <pages>80-91</pages>
      <abstract>Large language models (LLMs) excel in various tasks but are primarily trained on text data, limiting their application scope. Expanding LLM capabilities to include vision-language understanding is vital, yet training them on multimodal data from scratch is challenging and costly. Existing instruction tuning methods, e.g., LLAVA, often connects a pretrained CLIP vision encoder and LLMs via fully fine-tuning LLMs to bridge the modality gap. However, full fine-tuning is plagued by catastrophic forgetting, i.e., forgetting previous knowledge, and high training costs particularly in the era of increasing tasks and modalities. To solve this issue, we introduce MoExtend, an effective framework designed to streamline the modality adaptation and extension of Mixture-of-Experts (MoE) models. MoExtend seamlessly integrates new experts into pre-trained MoE models, endowing them with novel knowledge without the need to tune pretrained models such as MoE and vision encoders. This approach enables rapid adaptation and extension to new modal data or tasks, effectively addressing the challenge of accommodating new modalities within LLMs. Furthermore, MoExtend avoids tuning pretrained models, thus mitigating the risk of catastrophic forgetting. Experimental results demonstrate the efficacy and efficiency of MoExtend in enhancing the multimodal capabilities of LLMs, contributing to advancements in multimodal AI research.</abstract>
      <url hash="2c73b595">2024.acl-srw.8</url>
    </paper>
    <paper id="9">
      <title>On the Interpretability of Deep Learning Models for Collaborative Argumentation Analysis in Classrooms</title>
      <author><first>Deliang</first><last>Wang</last></author>
      <author><first>Gaowei</first><last>Chen</last><affiliation>University of Hong Kong</affiliation></author>
      <pages>92-102</pages>
      <abstract>Collaborative argumentation holds significant potential for enhancing students’ learning outcomes within classroom settings. Consequently, researchers have explored the application of artificial intelligence (AI) to automatically analyze argumentation in these contexts. Despite the remarkable performance of deep learning models in this task, their lack of interpretability poses a critical challenge, leading to teachers’ skepticism and limited utilization. To cultivate trust among teachers, this PhD thesis proposal aims to leverage explainable AI techniques to provide explanations for these deep learning models. Specifically, the study develops two deep learning models for automated analysis of argument moves (claim, evidence, and warrant) and specificity levels (low, medium, and high) within collaborative argumentation. To address the interpretability issue, four explainable AI methods are proposed: gradient sensitivity, gradient input, integrated gradient, and LIME. Computational experiments demonstrate the efficacy of these methods in elucidating model predictions by computing word contributions, with LIME delivering exceptional performance. Moreover, a quasi-experiment is designed to evaluate the impact of model explanations on user trust and knowledge, serving as a future study of this PhD proposal. By tackling the challenges of interpretability and trust, this PhD thesis proposal aims to contribute to fostering user trust in AI and facilitating the practical implementation of AI in educational contexts.</abstract>
      <url hash="6121b687">2024.acl-srw.9</url>
    </paper>
    <paper id="10">
      <title>Document Alignment based on Overlapping Fixed-Length Segments</title>
      <author><first>Xiaotian</first><last>Wang</last></author>
      <author><first>Takehito</first><last>Utsuro</last><affiliation>University of Tsukuba</affiliation></author>
      <author><first>Masaaki</first><last>Nagata</last><affiliation>NTT Corporation</affiliation></author>
      <pages>103-113</pages>
      <abstract>Acquiring large-scale parallel corpora is crucial for NLP tasks such asNeural Machine Translation, and web crawling has become a popularmethodology for this purpose. Previous studies have been conductedbased on sentence-based segmentation (SBS) when aligning documents invarious languages which are obtained through web crawling. Among them,the TK-PERT method (Thompson and Koehn, 2020) achieved state-of-the-artresults and addressed the boilerplate text in web crawling data wellthrough a down-weighting approach. However, there remains a problemwith how to handle long-text encoding better. Thus, we introduce thestrategy of Overlapping Fixed-Length Segmentation (OFLS) in place ofSBS, and observe a pronounced enhancement when performing the sameapproach for document alignment. In this paper, we compare the SBS andOFLS using three previous methods, Mean-Pool, TK-PERT (Thompson andKoehn, 2020), and Optimal Transport (Clark et al., 2019; El- Kishky andGuzman, 2020), on the WMT16 document alignment shared task forFrench-English, as well as on our self-established Japanese-Englishdataset MnRN. As a result, for the WMT16 task, various SBS basedmethods showed an increase in recall by 1% to 10% after reproductionwith OFLS. For MnRN data, OFLS demonstrated notable accuracyimprovements and exhibited faster document embedding speed.</abstract>
      <url hash="5bb0d7cc">2024.acl-srw.10</url>
    </paper>
    <paper id="11">
      <title>Automatically Suggesting Diverse Example Sentences for <fixed-case>L</fixed-case>2 <fixed-case>J</fixed-case>apanese Learners Using Pre-Trained Language Models</title>
      <author><first>Enrico</first><last>Benedetti</last></author>
      <author><first>Akiko</first><last>Aizawa</last><affiliation>NII, Tokyo Institute of Technology</affiliation></author>
      <author><first>Florian</first><last>Boudin</last><affiliation>University of Nantes</affiliation></author>
      <pages>114-131</pages>
      <abstract>Providing example sentences that are diverse and aligned with learners’ proficiency levels is essential for fostering effective language acquisition.This study examines the use of Pre-trained Language Models (PLMs) to produce example sentences targeting L2 Japanese learners.We utilize PLMs in two ways: as quality scoring components in a retrieval system that draws from a newly curated corpus of Japanese sentences, and as direct sentence generators using zero-shot learning.We evaluate the quality of sentences by considering multiple aspects such as difficulty, diversity, and naturalness, with a panel of raters consisting of learners of Japanese, native speakers – and GPT-4.Our findings suggest that there is inherent disagreement among participants on the ratings of sentence qualities, except for difficulty. Despite that, the retrieval approach was preferred by all evaluators, especially for beginner and advanced target proficiency, while the generative approaches received lower scores on average.Even so, our experiments highlight the potential for using PLMs to enhance the adaptability of sentence suggestion systems and therefore improve the language learning journey.</abstract>
      <url hash="bffa5386">2024.acl-srw.11</url>
    </paper>
    <paper id="12">
      <title><fixed-case>Z</fixed-case>-coref: <fixed-case>T</fixed-case>hai Coreference and Zero Pronoun Resolution</title>
      <author><first>Poomphob</first><last>Suwannapichat</last><affiliation>King Mongkut’s University of Technology Thonburi</affiliation></author>
      <author><first>Sansiri.tarn@kmutt.ac.th</first><last>Sansiri.tarn@kmutt.ac.th</last><affiliation>NA</affiliation></author>
      <author><first>Santitham.pro@kmutt.ac.th</first><last>Santitham.pro@kmutt.ac.th</last><affiliation>NA</affiliation></author>
      <pages>132-139</pages>
      <abstract>Coreference Resolution (CR) and Zero Pronoun Resolution (ZPR) are vital for extracting meaningful information from text. However, limited research and datasets pose significant challenges in Thai language. To address this, we developed an annotated joint CR and ZPR dataset. Additionally, we introduced the Z-coref model, capable of simultaneously handling CR and ZPR tasks by adjusting the span definition of a prior CR architecture to include token gaps. The proposed model trained on our dataset outperformed the state-of-the-art in resolving both coreference resolution and zero-pronoun resolution, while taking less time to train.</abstract>
      <url hash="3734a9dd">2024.acl-srw.12</url>
    </paper>
    <paper id="13">
      <title><fixed-case>R</fixed-case>e<fixed-case>MAG</fixed-case>-<fixed-case>KR</fixed-case>: Retrieval and Medically Assisted Generation with Knowledge Reduction for Medical Question Answering</title>
      <author><first>Sidhaarth</first><last>Murali</last></author>
      <author><first>Sowmya</first><last>S.</last><affiliation>National Institute of Technology Karnataka</affiliation></author>
      <author><first>Supreetha</first><last>R</last></author>
      <pages>140-145</pages>
      <abstract>Large Language Models (LLMs) have significant potential for facilitating intelligent end-user applications in healthcare. However, hallucinations remain an inherent problem with LLMs, making it crucial to address this issue with extensive medical knowledge and data. In this work, we propose a Retrieve-and-Medically-Augmented-Generation with Knowledge Reduction (ReMAG-KR) pipeline, employing a carefully curated knowledge base using cross-encoder re-ranking strategies. The pipeline is tested on medical MCQ-based QA datasets as well as general QA datasets. It was observed that when the knowledge base is reduced, the model’s performance decreases by 2-8%, while the inference time improves by 47%.</abstract>
      <url hash="3ae8d443">2024.acl-srw.13</url>
    </paper>
    <paper id="14">
      <title>Plot Retrieval as an Assessment of Abstract Semantic Association</title>
      <author><first>Shicheng</first><last>Xu</last></author>
      <author><first>Liang</first><last>Pang</last><affiliation>Institute of Computing Technology, Chinese Academy of Sciences</affiliation></author>
      <author><first>Jiangnan</first><last>Li</last><affiliation>WeChat, Tencent Inc.</affiliation></author>
      <author><first>Mo</first><last>Yu</last><affiliation>WeChat AI, Tencent</affiliation></author>
      <author><first>Fandong</first><last>Meng</last><affiliation>WeChat AI, Tencent Inc.</affiliation></author>
      <author><first>Huawei</first><last>Shen</last><affiliation>Institute of Computing Technology, Chinese Academy of Sciences</affiliation></author>
      <author><first>Xueqi</first><last>Cheng</last><affiliation>, Chinese Academy of Sciences</affiliation></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <pages>146-161</pages>
      <abstract>Retrieving relevant plots from the book for a query is a critical task, which can improve the reading experience and efficiency of readers. Readers usually only give an abstract and vague description as the query based on their own understanding, summaries, or speculations of the plot, which requires the retrieval model to have a strong ability to estimate the abstract semantic associations between the query and candidate plots. However, existing information retrieval (IR) datasets cannot reflect this ability well. In this paper, we propose PlotRetrieval, a labeled dataset to train and evaluate the performance of IR models on the novel task Plot Retrieval. Text pairs in PlotRetrieval have less word overlap and more abstract semantic association, which can reflect the ability of the IR models to estimate the abstract semantic association, rather than just traditional lexical or semantic matching. Extensive experiments across various lexical retrieval, sparse retrieval, dense retrieval, and cross-encoder methods compared with human studies on PlotRetrieval show current IR models still struggle in capturing abstract semantic association between texts. PlotRetrieval can be the benchmark for further research on the semantic association modeling ability of IR models.</abstract>
      <url hash="e20cd3fd">2024.acl-srw.14</url>
    </paper>
    <paper id="15">
      <title>Demystifying Instruction Mixing for Fine-tuning Large Language Models</title>
      <author><first>Renxi</first><last>Wang</last></author>
      <author><first>Haonan</first><last>Li</last></author>
      <author><first>Minghao</first><last>Wu</last></author>
      <author><first>Yuxia</first><last>Wang</last></author>
      <author><first>Xudong</first><last>Han</last><affiliation>University of Melbourne</affiliation></author>
      <author><first>Chiyu</first><last>Zhang</last><affiliation>University of British Columbia</affiliation></author>
      <author><first>Timothy</first><last>Baldwin</last><affiliation>Mohamed bin Zayed University of Artificial Intelligence and The University of Melbourne</affiliation></author>
      <pages>162-169</pages>
      <abstract>Instruction tuning significantly enhances the performance of large language models (LLMs) across various tasks. However, the procedure to optimizing the mixing of instruction datasets for LLM fine-tuning is still poorly understood. This study categorizes instructions into three primary types: NLP downstream tasks, coding, and general chat. We explore the effects of instruction tuning on different combinations of datasets on LLM performance, and find that certain instruction types are more advantageous for specific applications but can negatively impact other areas. This work provides insights into instruction mixtures, laying the foundations for future research.</abstract>
      <url hash="85592cb9">2024.acl-srw.15</url>
    </paper>
    <paper id="16">
      <title>Fine-Tuning <fixed-case>ASR</fixed-case> models for Very Low-Resource Languages: A Study on Mvskoke</title>
      <author><first>Julia</first><last>Mainzinger</last></author>
      <author><first>Gina-Anne</first><last>Levow</last><affiliation>University of Washington and University of Washington</affiliation></author>
      <pages>170-176</pages>
      <abstract>Recent advancements in multilingual models for automatic speech recognition (ASR) have been able to achieve a high accuracy for languages with extremely limited resources. This study examines ASR modeling for the Mvskoke language, an indigenous language of America. The parameter efficiency of adapter training is contrasted with training entire models, and it is demonstrated how performance varies with different amounts of data. Additionally, the models are evaluated with trigram language model decoding, and the outputs are compared across different types of speech recordings. Results show that training an adapter is both parameter efficient and gives higher accuracy for a relatively small amount of data.</abstract>
      <url hash="452f498f">2024.acl-srw.16</url>
    </paper>
    <paper id="17">
      <title>Automating Qualitative Data Analysis with Large Language Models</title>
      <author><first>Angelina</first><last>Parfenova</last><affiliation>Universit� Grenoble Alpes</affiliation></author>
      <author><first>Alexander.denzler@hslu.ch</first><last>Alexander.denzler@hslu.ch</last><affiliation>NA</affiliation></author>
      <author><first>J�rgen</first><last>Pfeffer</last><affiliation>Technische Universit�t M�nchen</affiliation></author>
      <pages>177-185</pages>
      <abstract>This PhD proposal aims to investigate ways of automating qualitative data analysis, specifically the thematic coding of texts. Despite existing methods vastly covered in literature, they mainly use Topic Modeling and other quantitative approaches which are far from resembling a human’s analysis outcome. This proposal examines the limitations of current research in the field. It proposes a novel methodology based on Large Language Models to tackle automated coding and make it as close as possible to the results of human researchers. This paper covers studies already done in this field and their limitations, existing software, the problem of duplicating the researcher bias, and the proposed methodology.</abstract>
      <url hash="c0e0eb97">2024.acl-srw.17</url>
    </paper>
    <paper id="18">
      <title><fixed-case>ANHALTEN</fixed-case>: Cross-Lingual Transfer for <fixed-case>G</fixed-case>erman Token-Level Reference-Free Hallucination Detection</title>
      <author><first>Janek</first><last>Herrlein</last><affiliation>Bayerische Julius-Maximilians-Universit�t W�rzburg</affiliation></author>
      <author><first>Chia-Chien</first><last>Hung</last><affiliation>NEC Laboratories Europe and Universit�t Mannheim</affiliation></author>
      <author><first>Goran</first><last>Glava�</last><affiliation>Julius-Maximilians-Universit�t W�rzburg</affiliation></author>
      <pages>186-194</pages>
      <abstract>Research on token-level reference-free hallucination detection has predominantly focused on English, primarily due to the scarcity of robust datasets in other languages. This has hindered systematic investigations into the effectiveness of cross-lingual transfer for this important NLP application. To address this gap, we introduce ANHALTEN, a new evaluation dataset that extends the English hallucination detection dataset to German. To the best of our knowledge, this is the first work that explores cross-lingual transfer for token-level reference-free hallucination detection. ANHALTEN contains gold annotations in German that are parallel (i.e., directly comparable to the original English instances). We benchmark several prominent cross-lingual transfer approaches, demonstrating that larger context length leads to better hallucination detection in German, even without succeeding context. Importantly, we show that the sample-efficient few-shot transfer is the most effective approach in most setups. This highlights the practical benefits of minimal annotation effort in the target language for reference-free hallucination detection. Aiming to catalyze future research on cross-lingual token-level reference-free hallucination detection, we make ANHALTEN publicly available: https://github.com/janekh24/anhalten</abstract>
      <url hash="25cae645">2024.acl-srw.18</url>
    </paper>
    <paper id="19">
      <title>Label-Aware Automatic Verbalizer for Few-Shot Text Classification in Mid-To-Low Resource Languages</title>
      <author><first>Thanakorn</first><last>Thaminkaew</last><affiliation>Chulalongkorn University</affiliation></author>
      <author><first>Piyawat</first><last>Lertvittayakumjorn</last><affiliation>Google</affiliation></author>
      <author><first>Peerapon</first><last>Vateekul</last><affiliation>Chulalongkorn University</affiliation></author>
      <pages>195-203</pages>
      <abstract>Prompt-based learning has shown its effectiveness in few-shot text classification. A key factor in its success is a verbalizer, which translates output from a language model into a predicted class. Notably, the simplest and widely acknowledged verbalizer employs manual labels to represent the classes. However, manual selection may not yield the optimal words for a given language model, potentially leading to subpar classification performance, especially in mid-to-low resource languages with weaker language models. Therefore, we propose Label-Aware Automatic Verbalizer (LAAV), effectively augmenting manual labels for improved few-shot classification results. Specifically, we utilize the label name along with the conjunction “and” to induce the model to generate more effective words for the verbalizer. Experimental results on four mid-to-low resource Southeast Asian languages demonstrate that LAAV significantly outperforms existing verbalizers.</abstract>
      <url hash="65f0271d">2024.acl-srw.19</url>
    </paper>
    <paper id="20">
      <title>Vector Spaces for Quantifying Disparity of Multiword Expressions in Annotated Text</title>
      <author><first>Louis</first><last>Est�ve</last></author>
      <author><first>Agata</first><last>Savary</last><affiliation>Universit� Paris-Saclay</affiliation></author>
      <author><first>Thomas</first><last>Lavergne</last></author>
      <pages>204-224</pages>
      <abstract>Multiword Expressions (MWEs) make a goodcase study for linguistic diversity due to theiridiosyncratic nature. Defining MWE canonicalforms as types, diversity may be measurednotably through disparity, based on pairwisedistances between types. To this aim, wetrain static MWE-aware word embeddings forverbal MWEs in 14 languages, and we showinteresting properties of these vector spaces.We use these vector spaces to implement theso-called functional diversity measure. Weapply this measure to the results of severalMWE identification systems. We find that,although MWE vector spaces are meaningful ata local scale, the disparity measure aggregatingthem at a global scale strongly correlateswith the number of types, which questions itsusefulness in presence of simpler diversitymetrics such as variety. We make the vectorspaces we generated available.</abstract>
      <url hash="3bb4baaf">2024.acl-srw.20</url>
    </paper>
    <paper id="21">
      <title>Narratives at Conflict: Computational Analysis of News Framing in Multilingual Disinformation Campaigns</title>
      <author><first>Antonina</first><last>Sinelnik</last></author>
      <author><first>Dirk</first><last>Hovy</last><affiliation>Bocconi University</affiliation></author>
      <pages>225-237</pages>
      <abstract>Any report frames issues to favor a particular interpretation by highlighting or excluding certain aspects of a story. Despite the widespread use of framing in disinformation, framing properties and detection methods remain underexplored outside the English-speaking world. We explore how multilingual framing of the same issue differs systematically. We use eight years of Russia-backed disinformation campaigns, spanning 8k news articles in 4 languages targeting 15 countries. We find that disinformation campaigns consistently and intentionally favor specific framing, depending on the target language of the audience. We further discover how Russian-language articles consistently highlight selected frames depending on the region of the media coverage. We find that the two most prominent models for automatic frame analysis underperform and show high disagreement, highlighting the need for further research.</abstract>
      <url hash="6efed0d5">2024.acl-srw.21</url>
    </paper>
    <paper id="22">
      <title>Assessing In-context Learning and Fine-tuning for Topic Classification of <fixed-case>G</fixed-case>erman Web Data</title>
      <author><first>Julian</first><last>Schelb</last><affiliation>Universit�t Konstanz</affiliation></author>
      <author><first>Andreas</first><last>Spitz</last><affiliation>Universit�t Konstanz</affiliation></author>
      <author><first>Roberto</first><last>Ulloa</last></author>
      <pages>238-252</pages>
      <abstract>Researchers in the political and social sciences often rely on classification models to analyze trends in information consumption by examining browsing histories of millions of webpages. Automated scalable methods are necessary due to the impracticality of manual labeling. In this paper, we model the detection of topic-related content as a binary classification task and compare the accuracy of fine-tuned pre-trained encoder models against in-context learning strategies. Using only a few hundred annotated data points per topic, we detect content related to three German policies in a database of scraped webpages. We compare multilingual and monolingual models, as well as zero and few-shot approaches, and investigate the impact of negative sampling strategies and the combination of URL &amp; content-based features. Our results show that a small sample of annotated data is sufficient to train an effective classifier. Fine-tuning encoder-based models yields better results than in-context learning. Classifiers using both URL &amp; content-based features perform best, while using URLs alone provides adequate results when content is unavailable.</abstract>
      <url hash="58f2f8eb">2024.acl-srw.22</url>
    </paper>
    <paper id="23">
      <title>Knowledge Editing of Large Language Models Unconstrained by Word Order</title>
      <author><first>Ryoma</first><last>Ishigaki</last></author>
      <author><first>Jundai</first><last>Suzuki</last><affiliation>Tokyo Denki University, Tokyo Institute of Technology</affiliation></author>
      <author><first>Masaki</first><last>Shuzo</last><affiliation>Tokyo Denki University</affiliation></author>
      <author><first>Eisaku</first><last>Maeda</last><affiliation>Tokyo Denki University</affiliation></author>
      <pages>253-263</pages>
      <abstract>Large Language Models (LLMs) are considered to have potentially extensive knowledge, but because their internal processing is black-boxed, it has been difficult to directly edit the knowledge held by the LLMs themselves. To address this issue, a method called local modification-based knowledge editing has been developed. This method identifies the knowledge neurons that encode the target knowledge and adjusts the parameters associated with these neurons to update the knowledge. Knowledge neurons are identified by masking the <tex-math>\it{o}</tex-math> part from sentences representing relational triplets (<tex-math>\it{s, r, o}</tex-math>), having the LLM predict the masked part, and observing the LLM�s activation during the prediction. When the architecture is decoder-based, the predicted <tex-math>\it{o}</tex-math> needs to be located at the end of the sentence. Previous local modification-based knowledge editing methods for decoder-based models have assumed SVO languages and faced challenges when applied to SOV languages such as Japanese. In this study, we propose a knowledge editing method that eliminates the need for word order constraints by converting the input for identifying knowledge neurons into a question where <tex-math>\it{o}</tex-math> is the answer. We conducted validation experiments on 500 examples and confirmed that the proposed method is effective for Japanese, a non-SVO language. We also applied this method to English, an SVO language, and demonstrated that it outperforms conventional methods.</abstract>
      <url hash="f90117c0">2024.acl-srw.23</url>
    </paper>
    <paper id="24">
      <title>Exploring the Effectiveness and Consistency of Task Selection in Intermediate-Task Transfer Learning</title>
      <author><first>Pin-Jie</first><last>Lin</last></author>
      <author><first>Miaoran</first><last>Zhang</last><affiliation>Saarland University</affiliation></author>
      <author><first>Marius</first><last>Mosbach</last><affiliation>McGill University and Mila - Quebec Artificial Intelligence Institute</affiliation></author>
      <author><first>Dietrich</first><last>Klakow</last><affiliation>Saarland University</affiliation></author>
      <pages>264-279</pages>
      <abstract>Identifying beneficial tasks to transfer from is a critical step toward successful intermediate-task transfer learning. In this work, we experiment with 130 source-target task combinations and demonstrate that the transfer performance exhibits severe variance across different source tasks and training seeds, highlighting the crucial role of intermediate-task selection in a broader context. We compare four representative task selection methods in a unified setup, focusing on their effectiveness and consistency. Compared to embedding-free methods and text embeddings, task embeddings constructed from fine-tuned weights can better estimate task transferability by improving task prediction scores from 2.59% to 3.96%. Despite their strong performance, we observe that the task embeddings do not consistently demonstrate superiority for tasks requiring reasoning abilities. Furthermore, we introduce a novel method that measures pairwise token similarity using maximum inner product search, leading to the highest performance in task prediction. Our findings suggest that token-wise similarity is better predictive for predicting transferability compared to averaging weights.</abstract>
      <url hash="0139ec25">2024.acl-srw.24</url>
    </paper>
    <paper id="25">
      <title>Does the structure of textual content have an impact on language models for automatic summarization?</title>
      <author><first>Eve</first><last>Sauvage</last></author>
      <author><first>Sabrina</first><last>Campano</last><affiliation>EDF R&amp;D</affiliation></author>
      <author><first>Lydia</first><last>Ouali</last></author>
      <author><first>Cyril</first><last>Grouin</last><affiliation>CNRS</affiliation></author>
      <pages>280-285</pages>
      <abstract>The processing of long sequences with models remains a subject in its own right, including automatic summary, despite recent improvements. In this work, we present experiments on the automatic summarization of scientific articles using BART models, taking into account textual information coming from distinct passages from the long texts to be summarized. We demonstrate that taking into account document structure improves the performance of state-of-the-art models and approaches the performance of LongFormer on English.</abstract>
      <url hash="52fa8d53">2024.acl-srw.25</url>
    </paper>
    <paper id="26">
      <title>Action Inference for Destination Prediction in Vision-and-Language Navigation</title>
      <author><first>Anirudh</first><last>Kondapally</last><affiliation>Honda R&amp;D Co., Ltd.</affiliation></author>
      <author><first>Kentaro_yamada@jp.honda</first><last>Kentaro_yamada@jp.honda</last><affiliation>NA</affiliation></author>
      <author><first>Hitomi</first><last>Yanaka</last><affiliation>the University of Tokyo</affiliation></author>
      <pages>286-293</pages>
      <abstract>Vision-and-Language Navigation (VLN) encompasses interacting with autonomous vehicles using language and visual input from the perspective of mobility.Most of the previous work in this field focuses on spatial reasoning and the semantic grounding of visual information.However, reasoning based on the actions of pedestrians in the scene is not much considered.In this study, we provide a VLN dataset for destination prediction with action inference to investigate the extent to which current VLN models perform action inference.We introduce a crowd-sourcing process to construct a dataset for this task in two steps: (1) collecting beliefs about the next action for a pedestrian and (2) annotating the destination considering the pedestrian’s next action.Our benchmarking results of the models on destination prediction lead us to believe that the models can learn to reason about the effect of the action and the next action on the destination to a certain extent.However, there is still much scope for improvement.</abstract>
      <url hash="ba6af917">2024.acl-srw.26</url>
    </paper>
    <paper id="27">
      <title>A Computational Analysis and Exploration of Linguistic Borrowings in <fixed-case>F</fixed-case>rench Rap Lyrics</title>
      <author><first>Lucas</first><last>Zurbuchen</last></author>
      <author><first>Rob</first><last>Voigt</last><affiliation>Northwestern University</affiliation></author>
      <pages>294-302</pages>
      <abstract>In France, linguistic borrowings in the relatively conservative French language are an important site of cultural debate, and rap in particular is a hotspot for borrowings. In this work, we use computational methods to understand the factors that affect the prominence and prevalence of a borrowing. To do so, we manually annotate a lexicon of over 700 borrowings occurring in this context (including key aspects for each borrowing such as origin and semantic class). We analyze the prevalence of these borrowings in a newly collected corpus of over 8000 French rap song lyrics and find that there are increases in the proportion of linguistic borrowings, interjections, and Niger-Congo borrowings while terms related to the arts are decreasing in prevalence. We release our code and data to facilitate further research in this area and discuss potential future directions.</abstract>
      <url hash="1193dd7b">2024.acl-srw.27</url>
    </paper>
    <paper id="28">
      <title>On Improving Repository-Level Code <fixed-case>QA</fixed-case> for Large Language Models</title>
      <author><first>Jan</first><last>Strich</last></author>
      <author><first>Florian</first><last>Schneider</last><affiliation>Universit�t Hamburg</affiliation></author>
      <author><first>Irina</first><last>Nikishina</last></author>
      <author><first>Chris</first><last>Biemann</last><affiliation>U Hamburg</affiliation></author>
      <pages>303-338</pages>
      <abstract>Large Language Models (LLMs) such as ChatGPT, GitHub Copilot, Llama, or Mistral assist programmers as copilots and knowledge sources to make the coding process faster and more efficient. This paper aims to improve the copilot performance by implementing different self-alignment processes and retrieval-augmented generation (RAG) pipelines, as well as their combination. To test the effectiveness of all approaches, we create a dataset and apply a model-based evaluation, using LLM as a judge. It is designed to check the model’s abilities to understand the source code semantics, the dependency between files, and the overall meta-information about the repository. We also compare our approach with other existing solutions, e.g. ChatGPT-3.5, and evaluate on the existing benchmarks. Code and dataset are available online (https://anonymous.4open.science/r/ma_llm-382D).</abstract>
      <url hash="55a69700">2024.acl-srw.28</url>
    </paper>
    <paper id="29">
      <title>Compromesso! <fixed-case>I</fixed-case>talian Many-Shot Jailbreaks undermine the safety of Large Language Models</title>
      <author><first>Fabio</first><last>Pernisi</last></author>
      <author><first>Dirk</first><last>Hovy</last><affiliation>Bocconi University</affiliation></author>
      <author><first>Paul</first><last>R�ttger</last><affiliation>Bocconi University</affiliation></author>
      <pages>339-345</pages>
      <abstract>As diverse linguistic communities and users adopt Large Language Models (LLMs), assessing their safety across languages becomes critical. Despite ongoing efforts to align these models with safe and ethical guidelines, they can still be induced into unsafe behavior with jailbreaking, a technique in which models are prompted to act outside their operational guidelines. What research has been conducted on these vulnerabilities was predominantly on English, limiting the understanding of LLM behavior in other languages. We address this gap by investigating Many-Shot Jailbreaking (MSJ) in Italian, underscoring the importance of understanding LLM behavior in different languages. We base our analysis on a newly created Italian dataset to identify unique safety vulnerabilities in 4 families of open-source LLMs.We find that the models exhibit unsafe behaviors even with minimal exposure to harmful prompts, and–more alarmingly–this tendency rapidly escalates with more demonstrations.</abstract>
      <url hash="9255c313">2024.acl-srw.29</url>
    </paper>
    <paper id="30">
      <title>Foundation Model for Biomedical Graphs: Integrating Knowledge Graphs and Protein Structures to Large Language Models</title>
      <author><first>Yunsoo</first><last>Kim</last></author>
      <pages>346-355</pages>
      <abstract>Transformer model has been a de-facto standard in natural language processing. Its adaptations in other fields such as computer vision showed promising results that this architecture is a powerful neural network in representation learning regardless of the data type. This recent success has led to research in multimodal Large Language Model (LLM), which enabled us to new types of tasks and applications with multiple data types. However, multimodal LLM in the biomedical domain is primarily limited to images, text, and/or sequence data. Here I propose to work on multimodal LLM architecture for biomedical graphs such as protein structure and chemical molecules. The research hypothesis is based on the fact that clinicians and researchers in computational biology and clinical research take advantage of various information for their decision-making process. Therefore, an AI model being able to handle multiple data types should boost its ability to use diverse knowledge for improved performances in clinical applications.</abstract>
      <url hash="76544871">2024.acl-srw.30</url>
    </paper>
    <paper id="31">
      <title><fixed-case>V</fixed-case>i<fixed-case>M</fixed-case>ed<fixed-case>AQA</fixed-case>: A <fixed-case>V</fixed-case>ietnamese Medical Abstractive Question-Answering Dataset and Findings of Large Language Model</title>
      <author><first>Minh-Nam</first><last>Tran</last></author>
      <author><first>Phu-Vinh</first><last>Nguyen</last></author>
      <author><first>Long</first><last>Nguyen</last><affiliation>Ho Chi Minh city University of Science, Vietnam National University</affiliation></author>
      <author><first>Dien</first><last>Dinh</last></author>
      <pages>356-364</pages>
      <abstract>Question answering involves creating answers to questions. With the growth of large language models, the ability of question-answering systems has dramatically improved. However, there is a lack of Vietnamese abstractive question-answering datasets, especially in the medical domain. Therefore, this research aims to mitigate this gap by introducing ViMedAQA. This **Vi**etnamese **Med**ical **A**bstractive **Q**uestion-**A**nswering dataset covers four topics in the Vietnamese medical domain, including body parts, disease, drugs and medicine. Additionally, the empirical results on the proposed dataset examine the capability of the large language models in the Vietnamese medical domain, including reasoning, memorizing and awareness of essential information.</abstract>
      <url hash="700922aa">2024.acl-srw.31</url>
    </paper>
    <paper id="32">
      <title>Rescue: Ranking <fixed-case>LLM</fixed-case> Responses with Partial Ordering to Improve Response Generation</title>
      <author><first>Yikun</first><last>Wang</last></author>
      <author><first>Rui</first><last>Zheng</last></author>
      <author><first>Haoming</first><last>Li</last></author>
      <author><first>Qi</first><last>Zhang</last><affiliation>Fudan University</affiliation></author>
      <author><first>Tao</first><last>Gui</last><affiliation>Fudan University</affiliation></author>
      <author id="fei-liu"><first>Fei</first><last>Liu</last><affiliation>Emory University</affiliation></author>
      <pages>365-376</pages>
      <abstract>Customizing LLMs for a specific task involves separating high-quality responses from lower-quality ones. This skill can be developed using supervised fine-tuning with extensive human preference data. However, obtaining a large volume of expert-annotated data is costly for most tasks. In this paper, we explore a novel method to optimize LLMs using ranking metrics. This method trains the model to prioritize the best responses from a pool of candidates created for a particular task. Rather than a traditional full ordering, we advocate for a partial ordering, as achieving consensus on the perfect order of candidate responses can be challenging. Our partial ordering is more robust, less sensitive to noise, and can be achieved with limited human annotations or through heuristic methods. We test our system’s improved response generation ability using benchmark datasets, including textual entailment and multi-document question answering. We conduct ablation studies to understand crucial factors, such as how to gather candidate responses for a specific task, determine their most suitable order, and balance supervised fine-tuning with ranking metrics. Our approach, named RESCUE, offers a promising avenue for enhancing the response generation and task accuracy of LLMs.</abstract>
      <url hash="8770faa4">2024.acl-srw.32</url>
    </paper>
    <paper id="33">
      <title>Basreh or Basra? Geoparsing Historical Locations in the Svoboda Diaries</title>
      <author><first>Jolie</first><last>Zhou</last><affiliation>University of Washington</affiliation></author>
      <author><first>Camille</first><last>Cole</last><affiliation>Illinois State University</affiliation></author>
      <author><first>Annie</first><last>Chen</last><affiliation>University of Washington</affiliation></author>
      <pages>377-390</pages>
      <abstract>Geoparsing, the task of assigning coordinates to locations extracted from free text, is invaluable in enabling us to place locations in time and space. In the historical domain, many geoparsing corpora are from large news collections. We examine the Svoboda Diaries, a small historical corpus written primarily in English, with many location names in transliterated Arabic. We develop a pipeline employing named entity recognition for geotagging, and a map-based generate-and-rank approach incorporating candidate name augmentation and clustering of location context words for geocoding. Our system outperforms existing map-based geoparsers in terms of accuracy, lowest mean distance error, and number of locations correctly identified. As location names may vary from those in knowledge bases, we find that augmented candidate generation is instrumental in the system’s performance. Among our candidate generation methods, the generation of transliterated names contributed the most to increased location matches in the knowledge base. Our main contribution is proposing an integrated pipeline for geoparsing of historical corpora using augmented candidate location name generation and clustering methods – an approach that can be generalized to other texts with foreign or non-standard spellings.</abstract>
      <url hash="2305199c">2024.acl-srw.33</url>
    </paper>
    <paper id="34">
      <title><fixed-case>H</fixed-case>omophone2<fixed-case>V</fixed-case>ec: Embedding Space Analysis for Empirical Evaluation of Phonological and Semantic Similarity</title>
      <author><first>Sophie</first><last>Wu</last></author>
      <author><first>Anita</first><last>Zheng</last></author>
      <author><first>Ching-i-chuang@mail.mcgill.ca</first><last>Ching-i-chuang@mail.mcgill.ca</last><affiliation>NA</affiliation></author>
      <pages>391-396</pages>
      <abstract>This paper introduces a novel method for empirically evaluating the relationship between the phonological and semantic similarity of linguistic units using embedding spaces. Chinese character homophones are used as a proof-of-concept. We employ cosine similarity as a proxy for semantic similarity between characters, and compare relationships between phonologically-related characters and baseline characters (chosen as similar-frequency characters). We show there is a strongly statistically significant positive semantic relationship among different Chinese characters at varying levels of sound-sharing. We also perform some basic probing using t-SNE and UMAP visualizations, and indicate directions for future applications of this method.</abstract>
      <url hash="7a4b426d">2024.acl-srw.34</url>
    </paper>
    <paper id="35">
      <title>Trace-of-Thought Prompting: Investigating Prompt-Based Knowledge Distillation Through Question Decomposition</title>
      <author><first>Tyler</first><last>McDonald</last><affiliation>Brock University</affiliation></author>
      <author><first>Ali</first><last>Emami</last><affiliation>Brock University</affiliation></author>
      <pages>397-410</pages>
      <abstract>Knowledge distillation allows smaller neural networks to emulate the performance of larger, teacher models with reduced computational demands. Traditional methods for Large Language Models (LLMs) often necessitate extensive fine-tuning, which limits their accessibility. To address this, we introduce Trace-of-Thought Prompting, a novel framework designed to distill critical reasoning capabilities from large-scale teacher models (over 8 billion parameters) to small-scale student models (up to 8 billion parameters). This approach leverages problem decomposition to enhance interpretability and facilitate human-in-the-loop interventions. Empirical evaluations on the GSM8K and MATH datasets show that student models achieve accuracy gains of up to 113% on GSM8K and 20% on MATH, with significant improvements particularly notable in smaller models like Llama 2 and Zephyr. Our results suggest a promising pathway for open-source, small-scale models to eventually serve as both students and teachers, potentially reducing our reliance on large-scale, proprietary models. Our code, featuring data analytics and testing scripts, is provided here: https://github.com/traceofthought/trace-of-thought-prompting/tree/main.</abstract>
      <url hash="e14b0a5a">2024.acl-srw.35</url>
    </paper>
    <paper id="36">
      <title>Can <fixed-case>LLM</fixed-case>s Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges</title>
      <author><first>Vinay</first><last>Samuel</last></author>
      <author><first>Houda</first><last>Aynaou</last></author>
      <author><first>Arijit</first><last>Chowdhury</last><affiliation>Amazon</affiliation></author>
      <author><first>Karthik</first><last>Venkat Ramanan</last></author>
      <author><first>Aman</first><last>Chadha</last><affiliation>Amazon</affiliation></author>
      <pages>411-421</pages>
      <abstract>Large Language Models (LLMs) have demonstrated impressive zero-shot performance on a wide range of NLP tasks, demonstrating the ability to reason and apply common sense. A relevant application is to use them for creating high-quality synthetic datasets for downstream tasks. In this work, we probe whether GPT-4 can be used to augment existing extractive reading comprehension datasets. Automating data annotation processes has the potential to save large amounts of time, money, and effort that goes into manually labeling datasets. In this paper, we evaluate the performance of GPT-4 as a replacement for human annotators for low-resource reading comprehension tasks, by comparing performance after fine-tuning, and the cost associated with annotation. This work serves to be the first analysis of LLMs as synthetic data augmenters for QA systems, highlighting the unique opportunities and challenges. Additionally, we release augmented versions of low-resource datasets, that will allow the research community to create further benchmarks for evaluation of generated datasets. Github available at https://github.com/vsamuel2003/qa-gpt4</abstract>
      <url hash="80b13500">2024.acl-srw.36</url>
    </paper>
    <paper id="37">
      <title>Automatic Derivation of Semantic Representations for <fixed-case>T</fixed-case>hai Serial Verb Constructions: A Grammar-Based Approach</title>
      <author><first>Vipasha</first><last>Bansal</last></author>
      <pages>422-437</pages>
      <abstract>Deep semantic representations are useful for many NLU tasks (Droganova and Zeman 2019; Schuster and Manning-2016). Manual annotation to build these representations is time-consuming, and so automatic approaches are preferred (Droganova and Zeman 2019; Bender et al. 2015). This paper demonstrates how rich semantic representations can be automatically derived for Thai Serial Verb Constructions (SVCs), where the semantic relationship between component verbs is not immediately clear from the surface forms. I present the first fully-implemented HPSG analysis for Thai SVCs, deriving appropriate semantic representations (MRS; Copestake et al. 2005) from syntactic features, implemented within a DELPH-IN computational grammar (Slayden 2009). This analysis increases verified coverage of SVCs by 73% and decreases ambiguity by 46%. The final grammar can be found at: https://github.com/VipashaB94/ThaiGrammar</abstract>
      <url hash="bd7b0824">2024.acl-srw.37</url>
    </paper>
    <paper id="38">
      <title>Seed-Free Synthetic Data Generation Framework for Instruction-Tuning <fixed-case>LLM</fixed-case>s: A Case Study in <fixed-case>T</fixed-case>hai</title>
      <author><first>Parinthapat</first><last>Pengpun</last></author>
      <author><first>Can</first><last>Udomcharoenchaikit</last><affiliation>Vidyasirimedhi Institute of Science and Technology (VISTEC)</affiliation></author>
      <author><first>Weerayut</first><last>Buaphet</last></author>
      <author><first>Peerat</first><last>Limkonchotiwat</last></author>
      <pages>438-457</pages>
      <abstract>We present a synthetic data approach for instruction-tuning large language models (LLMs) for low-resource languages in a data-efficient manner, specifically focusing on Thai. We identify three key properties that contribute to the effectiveness of instruction-tuning datasets: fluency, diversity, and cultural context. We propose a seed-data-free framework for generating synthetic instruction-tuning data that incorporates these essential properties. Our framework employs an LLM to generate diverse topics, retrieve relevant contexts from Wikipedia, and create instructions for various tasks, such as question answering, summarization, and conversation. The experimental results show that our best-performing synthetic dataset, which incorporates all three key properties, achieves competitive performance using only 5,000 instructions when compared to state-of-the-art Thai LLMs trained on hundreds of thousands of instructions. Our code and dataset are publicly available at https://github.com/parinzee/seed-free-synthetic-instruct.</abstract>
      <url hash="80fc5d98">2024.acl-srw.38</url>
    </paper>
    <paper id="39">
      <title>Bridging Distribution Gap via Semantic Rewriting with <fixed-case>LLM</fixed-case>s to Enhance <fixed-case>OOD</fixed-case> Robustness</title>
      <author><first>Manas</first><last>Madine</last></author>
      <pages>458-468</pages>
      <abstract>This paper investigates the robustness of Large Language Models (LLMs) against Out-Of-Distribution (OOD) data within the context of sentiment analysis. Traditional fine-tuning approaches often fail to generalize effectively across different data distributions, limiting the practical deployment of LLMs in dynamic real-world scenarios. To address this challenge, we introduce a novel method called “Semantic Rewriting,” which leverages the inherent flexibility of LLMs to align both in-distribution (ID) and OOD data with the LLMs distributions. By semantically transforming sentences to minimize linguistic discrepancies, our approach helps to standardize features across datasets, thus enhancing model robustness. We conduct extensive experiments with several benchmark datasets and LLMs to validate the efficacy of our method. The results demonstrate that Semantic Rewriting significantly improves the performance of models on OOD tasks, outperforming traditional methods in both robustness and generalization capabilities. Our findings suggest that Semantic Rewriting is a promising technique for developing more reliable and versatile NLP systems capable of performing robustly across diverse operational environments.</abstract>
      <url hash="da3dcd7d">2024.acl-srw.39</url>
    </paper>
    <paper id="40">
      <title><fixed-case>C</fixed-case>o<fixed-case>V</fixed-case>o<fixed-case>S</fixed-case>witch: Machine Translation of Synthetic Code-Switched Text Based on Intonation Units</title>
      <author><first>Yeeun</first><last>Kang</last></author>
      <pages>469-481</pages>
      <abstract>Multilingual code-switching research is often hindered by the lack and linguistically biased status of available datasets. To expand language representation, we synthesize code-switching data by replacing intonation units detected through PSST, a speech segmentation model fine-tuned from OpenAI’s Whisper, using a speech-to-text translation dataset, CoVoST 2. With our dataset, CoVoSwitch, spanning 13 languages, we evaluate the code-switching translation performance of two multilingual translation models, M2M-100 418M and NLLB-200 600M. We reveal that the inclusion of code-switching units results in higher translation performance than monolingual settings and that models are better at code-switching translation into English than non-English. Further, low-resource languages gain most from integration of code-switched units when translating into English but much less when translating into non-English. Translations into low-resource languages also perform worse than even raw code-switched inputs. We find that systems excel at copying English tokens but struggle with non-English tokens, that the off-target problem in monolingual settings is also relevant in code-switching settings, and that models hallucinate in code-switching translation by introducing words absent in both of the original source sentences. CoVoSwitch and code are available at https://github.com/sophiayk20/covoswitch.</abstract>
      <url hash="a36aa248">2024.acl-srw.40</url>
    </paper>
    <paper id="41">
      <title>An Analysis under a Unified Formulation of Learning Algorithms with Output Constraints</title>
      <author><first>Mooho</first><last>Song</last><affiliation>Seoul National University</affiliation></author>
      <author><first>Jay-Yoon</first><last>Lee</last><affiliation>Seoul National University</affiliation></author>
      <pages>482-498</pages>
      <abstract>Neural networks (NN) perform well in diverse tasks, but sometimes produce nonsensical results to humans. Most NN models “solely” learn from (input, output) pairs, occasionally conflicting with human knowledge. Many studies indicate injecting human knowledge by reducing output constraints during training can improve model performance and reduce constraint violations.While there have been several attempts to compare different existing algorithms under the same programming framework, nonetheless, there has been no previous work that categorizes learning algorithms with output constraints in a unified manner. Our contributions are as follows: (1) We categorize the previous studies based on three axes: type of constraint loss used (e.g. probabilistic soft logic, REINFORCE), exploration strategy of constraint-violating examples, and integration mechanism of learning signals from main task and constraint.(2) We propose new algorithms to integrate the information of main task and constraint injection, inspired by continual-learning algorithms.(3) Furthermore, we propose the <tex-math>H\beta</tex-math>-score as a metric for considering the main task metric and constraint violation simultaneously.To provide a thorough analysis, we examine all the algorithms on three NLP tasks: natural language inference (NLI), synthetic transduction examples (STE), and semantic role labeling (SRL). We explore and reveal the key factors of various algorithms associated with achieving high <tex-math>H\beta</tex-math>-scores.</abstract>
      <url hash="20a0fa1a">2024.acl-srw.41</url>
    </paper>
    <paper id="42">
      <title>Beyond Abstracts: A New Dataset, Prompt Design Strategy and Method for Biomedical Synthesis Generation</title>
      <author><first>James</first><last>O’Doherty</last></author>
      <author><first>Cian</first><last>Nolan</last></author>
      <author><first>Yufang</first><last>Hou</last><affiliation>Technische Universit�t Darmstadt and IBM Research Ireland</affiliation></author>
      <author><first>Anya</first><last>Belz</last><affiliation>Dublin City University</affiliation></author>
      <pages>499-518</pages>
      <abstract>The biomedical field relies on cost and time intensive systematic reviews of papers to enable practitioners to keep up to date with research. Impressive recent advances in large language models (LLMs) have made the task of automating at least part of the systematic review process feasible, but progress is slow. This paper identifies some factors that may have been holding research back, and proposes a new, enhanced dataset and prompting-based method for automatic synthesis generation, the most challenging step for automation. We test different models and types of information from and about biomedical studies for their usefulness in obtaining high-quality results.We find that, surprisingly, inclusion of paper abstracts can worsens results. Instead, study summary information, and system instructions informed by domain knowledge, are key to producing high-quality syntheses.</abstract>
      <url hash="9cb6897d">2024.acl-srw.42</url>
    </paper>
    <paper id="43">
      <title>Improving Sentence Embeddings with Automatic Generation of Training Data Using Few-shot Examples</title>
      <author><first>Soma</first><last>Sato</last></author>
      <author><first>Hayato</first><last>Tsukagoshi</last></author>
      <author><first>Ryohei</first><last>Sasano</last><affiliation>Nagoya University</affiliation></author>
      <author><first>Koichi</first><last>Takeda</last><affiliation>Nagoya University</affiliation></author>
      <pages>519-530</pages>
      <abstract>Decoder-based large language models (LLMs) have shown high performance on many tasks in natural language processing. This is also true for sentence embedding learning, where a decoder-based model, PromptEOL, has achieved the best performance on semantic textual similarity (STS) tasks. However, PromptEOL requires a manually annotated natural language inference (NLI) dataset for fine-tuning.We aim to improve sentence embeddings without using large manually annotated datasets by automatically generating an NLI dataset with an LLM and using it for fine-tuning of PromptEOL. To achieve this, we explore methods of data generation suitable for sentence embedding learning in this study. Specifically, we will focus on automatic dataset generation through few-shot learning and explore the appropriate methods to leverage few-shot examples. Experimental results on the STS tasks demonstrate that our approach outperforms existing models in settings without large manually annotated datasets.</abstract>
      <url hash="1a718125">2024.acl-srw.43</url>
    </paper>
    <paper id="44">
      <title>Curriculum Learning for Small Code Language Models</title>
      <author><first>Marwa</first><last>Na�r</last><affiliation>New York University, Abu Dhabi and �cole Nationale Sup�rieure d’Informatique</affiliation></author>
      <author><first>Kamel</first><last>Yamani</last><affiliation>New York University, Abu Dhabi and Ecole Nationale Sup�rieure d’Informatique (ESI)</affiliation></author>
      <author><first>Lynda</first><last>Lhadj</last><affiliation>ESI</affiliation></author>
      <author><first>Riyadh</first><last>Baghdadi</last><affiliation>New York University</affiliation></author>
      <pages>531-542</pages>
      <abstract>Code language models have emerged as useful tools for various programming tasks, yet they often struggle when it comes to complex ones. In this paper, we explore the potential of curriculum learning in enhancing the performance of these models. While prior research has suggested that curriculum learning does not necessarily help in improving the performance of language models, our results surprisingly show that this may not be the case for code language models. We demonstrate that a well-designed curriculum learning approach significantly improves the accuracy of small decoder-only code language models on the task of code execution, while its effect on code completion is less significant. To explore the potential of curriculum learning, we train multiple GPT models with 1 million parameters each to predict the next token and evaluate them on code completion and execution tasks. Our contributions include proposing a novel code difficulty assessment metric by combining software code measures, investigating the effectiveness of Curriculum Learning for code language models, and introducing a Novel Curriculum Learning schedule that enhances the performance of small decoder-only language models in code execution tasks. The results of this paper open the door for more research on the use of curriculum learning for code language models.</abstract>
      <url hash="f702f70f">2024.acl-srw.44</url>
    </paper>
    <paper id="45">
      <title>Question-Analysis Prompting Improves <fixed-case>LLM</fixed-case> Performance in Reasoning Tasks</title>
      <author><first>Dharunish</first><last>Yugeswardeenoo</last><affiliation>Algoverse</affiliation></author>
      <author><first>Kevin</first><last>Zhu</last><affiliation>Algoverse AI Research</affiliation></author>
      <author><first>Sean</first><last>O’Brien</last><affiliation>University of California, San Diego</affiliation></author>
      <pages>543-554</pages>
      <abstract>Although LLMs have the potential to transform many fields, they still underperform humans in reasoning tasks. Existing methods induce the model to produce step-by-step calculations, but this research explores the question: Does making the LLM analyze the question improve its performance? We propose a novel prompting strategy called Question Analysis Prompting (QAP), in which the model is prompted to explain the question in ’n’ words before solving. The value of ’n’ influences the length of response generated by the model. QAP is evaluated on GPT-3.5 Turbo and GPT-4 Turbo on arithmetic datasets GSM8K, AQuA, and SAT and commonsense dataset StrategyQA. QAP is compared with other state-of-the-art prompts including chain-of-thought (CoT), Plan and Solve Prompting (PS+) and Take A Deep Breath (TADB). QAP outperforms all state-of-the-art prompts on AQuA and SAT datasets on both GPT-3.5 and GPT-4. QAP consistently ranks among the top-2 prompts on 75% of the tests. A key factor of QAP performance can be attributed to response length, where detailed responses are beneficial when answering harder questions, but can negatively affect easy questions.</abstract>
      <url hash="561d051a">2024.acl-srw.45</url>
    </paper>
    <paper id="46">
      <title>An Individualized News Affective Response Dataset</title>
      <author><first>Tiancheng</first><last>Hu</last><affiliation>University of Cambridge</affiliation></author>
      <author><first>Nigel</first><last>Collier</last><affiliation>University of Cambridge</affiliation></author>
      <pages>555-563</pages>
      <abstract>The rise of sensationalism in news reporting, driven by market saturation and online competition, has compromised news quality and trust. At the core of sensationalism is the evocation of affective responses in the readers. Current NLP approaches to emotion detection often overlook the subjective differences in groups and individuals, relying on aggregation techniques that can obscure nuanced reactions. We introduce a novel large-scale dataset capturing subjective affective responses to news headlines. The dataset includes Facebook post screenshots from popular UK media outlets and uses a comprehensive annotation scheme. Annotators report their affective responses, provide discrete emotion labels, assess relevance to current events, and indicate sharing likelihood. Additionally, we collect demographic, personality, and media consumption data. This ongoing dataset aims to enable more accurate models of affective response by considering individual and contextual factors. This work is ongoing and we highly appreciate any feedback.</abstract>
      <url hash="958f6d67">2024.acl-srw.46</url>
    </paper>
    <paper id="47">
      <title>How Well Do Vision Models Encode Diagram Attributes?</title>
      <author><first>Haruto</first><last>Yoshida</last></author>
      <author><first>Keito</first><last>Kudo</last></author>
      <author><first>Yoichi</first><last>Aoki</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Ryota</first><last>Tanaka</last><affiliation>NTT</affiliation></author>
      <author><first>Itsumi</first><last>Saito</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Keisuke</first><last>Sakaguchi</last><affiliation>Tohoku University</affiliation></author>
      <author><first>Kentaro</first><last>Inui</last><affiliation>Mohamed bin Zayed University of Artificial Intelligence, RIKEN and Tohoku University</affiliation></author>
      <pages>564-575</pages>
      <abstract>Research on understanding and generating diagrams has used vision models such as CLIP. However, it remains unclear whether these models accurately identify diagram attributes, such as node colors and shapes, along with edge colors and connection patterns. This study evaluates how well vision models recognize the diagram attributes by probing the model and retrieving diagrams using text queries. Experimental results showed that while vision models can recognize differences in node colors, shapes, and edge colors, they struggle to identify differences in edge connection patterns that play a pivotal role in the semantics of diagrams. Moreover, we revealed inadequate alignment between diagram attributes and language representations in the embedding space.</abstract>
      <url hash="8d86833f">2024.acl-srw.47</url>
    </paper>
    <paper id="48">
      <title><fixed-case>C</fixed-case>heckers<fixed-case>GPT</fixed-case>: Learning World Models through Language Modeling</title>
      <author><first>Abhinav</first><last>Joshi</last><affiliation>Indian Institute of Technology, Kanpur</affiliation></author>
      <author><first>Vaibhav</first><last>Sharma</last></author>
      <author><first>Ashutosh</first><last>Modi</last><affiliation>IIT Kanpur</affiliation></author>
      <pages>576-588</pages>
      <abstract>Although Large Language Models (LLMs) have been trained using just the next token prediction objective, these have shown impressive performance on various tasks. Consequently, it has attracted research interests in this regard. While one line of work in the past has suggested that LLMs learn surface-level statistics from the dataset, another line of work emphasizes that the learned representations are effective for simulating the underlying world model, considering the causal relationship for the next token prediction. This phenomenon is often referred to as the emergence of a world model in sequence prediction tasks. Recent work has demonstrated this phenomenon in a simulated setting of board games like Othello and Chess. In this paper, we analyze the game of Checkers to find out the emergence of a world model in a language model. By training a GPT-style autoregressive language model using only the next character prediction objective, we find that the model does show a hint of learning a world model representation of the board positions. We perform our analysis on two datasets: 1) synthetic dataset, which comes from the checkers game tree, and 2) human gameplay dataset. With multiple models trained with different layer sizes, we find that increasing the parameter size does help learn better world model representation decoded by linear probes.</abstract>
      <url hash="0604ec50">2024.acl-srw.48</url>
    </paper>
    <paper id="49">
      <title>In-Context Symbolic Regression: Leveraging Large Language Models for Function Discovery</title>
      <author><first>Matteo</first><last>Merler</last></author>
      <author><first>Katsiaryna</first><last>Haitsiukevich</last><affiliation>Aalto University</affiliation></author>
      <author><first>Nicola</first><last>Dainese</last><affiliation>Aalto University</affiliation></author>
      <author><first>Pekka</first><last>Marttinen</last><affiliation>Aalto University</affiliation></author>
      <pages>589-606</pages>
      <abstract>State of the art Symbolic Regression (SR) methods currently build specialized models, while the application of Large Language Models (LLMs) remains largely unexplored. In this work, we introduce the first comprehensive framework that utilizes LLMs for the task of SR.We propose In-Context Symbolic Regression (ICSR), an SR method which iteratively refines a functional form with an LLM and determines its coefficients with an external optimizer. ICSR leverages LLMs’ strong mathematical prior both to propose an initial set of possible functions given the observations and to refine them based on their errors.Our findings reveal that LLMs are able to successfully find symbolic equations that fit the given data, matching or outperforming the overall performance of the best SR baselines on four popular benchmarks, while yielding simpler equations with better out of distribution generalization.</abstract>
      <url hash="21389a3b">2024.acl-srw.49</url>
    </paper>
    <paper id="50">
      <title><fixed-case>STEP</fixed-case>: Staged Parameter-Efficient Pre-training for Large Language Models</title>
      <author><first>Kazuki</first><last>Yano</last></author>
      <author><first>Takumi</first><last>Ito</last><affiliation>Langsmith Inc., Tohoku University and Machine Learning Solutions</affiliation></author>
      <author><first>Jun</first><last>Suzuki</last><affiliation>Tohoku University</affiliation></author>
      <pages>607-614</pages>
      <abstract>Pre-training large language models faces significant memory challenges due to the large size of model weights.We propose STaged parameter-Efficient Pre-training (STEP), which combines ideas from parameter-efficient tuning and staged training. We conduct experiments on pre-training models of various sizes and demonstrate that STEP can achieve up to a 40.4% reduction in maximum memory requirement compared to vanilla pre-training while maintaining comparable performance.</abstract>
      <url hash="f05b9673">2024.acl-srw.50</url>
    </paper>
  </volume>
  <volume id="demos" ingest-date="2024-08-08" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 3: System Demonstrations)</booktitle>
      <editor><first>Yixin</first><last>Cao</last><affiliation>Singapore Management University</affiliation></editor>
      <editor><first>Yang</first><last>Feng</last><affiliation>Chinese Academy of Science</affiliation></editor>
      <editor><first>Deyi</first><last>Xiong</last><affiliation>Tianjin University</affiliation></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Bangkok, Thailand and virtual meeting</address>
      <month>August</month>
      <year>2024</year>
      <url hash="7988e48f">2024.acl-demos</url>
      <venue>acl</venue>
    </meta>
    <frontmatter>
      <url hash="f23682e8">2024.acl-demos.0</url>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>PAI</fixed-case>-Diffusion: Constructing and Serving a Family of Open <fixed-case>C</fixed-case>hinese Diffusion Models for Text-to-image Synthesis on the Cloud</title>
      <author><first>Chengyu</first><last>Wang</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Zhongjie</first><last>Duan</last></author>
      <author><first>Bingyan</first><last>Liu</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Xinyi</first><last>Zou</last></author>
      <author><first>Cen</first><last>Chen</last><affiliation>East China Normal University</affiliation></author>
      <author><first>Kui</first><last>Jia</last><affiliation>South China University of Technology</affiliation></author>
      <author><first>Jun</first><last>Huang</last></author>
      <pages>1-8</pages>
      <abstract>Text-to-image synthesis for the Chinese language poses unique challenges due to its large vocabulary size, and intricate character relationships. While existing diffusion models have shown promise in generating images from textual descriptions, they often neglect domain-specific contexts and lack robustness in handling the Chinese language. This paper introduces PAI-Diffusion, a comprehensive framework that addresses these limitations. PAI-Diffusion incorporates both general and domain-specific Chinese diffusion models, enabling the generation of contextually relevant images. It explores the potential of using LoRA and ControlNet for fine-grained image style transfer and image editing, empowering users with enhanced control over image generation. Moreover, PAI-Diffusion seamlessly integrates with Alibaba Cloud’s Platform for AI, providing accessible and scalable solutions. All the Chinese diffusion model checkpoints, LoRAs, and ControlNets, including domain-specific ones, are publicly available. A user-friendly Chinese WebUI and the diffusers-api elastic inference toolkit, also open-sourced, further facilitate the easy deployment of PAI-Diffusion models in various local and cloud environments, making it a valuable resource for Chinese text-to-image synthesis.</abstract>
      <url hash="0dfd3046">2024.acl-demos.1</url>
    </paper>
    <paper id="2">
      <title><fixed-case>O</fixed-case>pen<fixed-case>VNA</fixed-case>: A Framework for Analyzing the Behavior of Multimodal Language Understanding System under Noisy Scenarios</title>
      <author><first>Ziqi</first><last>Yuan</last></author>
      <author><first>Baozheng</first><last>Zhang</last></author>
      <author><first>Hua</first><last>Xu</last><affiliation>Tsinghua University, Tsinghua University</affiliation></author>
      <author><first>Zhiyun</first><last>Liang</last></author>
      <author><first>Kai</first><last>Gao</last></author>
      <pages>9-18</pages>
      <abstract>We present OpenVNA, an open-source framework designed for analyzing the behavior of multimodal language understanding systems under noisy conditions. OpenVNA serves as an intuitive toolkit tailored for researchers, facilitating convenience batch-level robustness evaluation and on-the-fly instance-level demonstration. It primarily features a benchmark Python library for assessing global model robustness, offering high flexibility and extensibility, thereby enabling customization with user-defined noise types and models. Additionally, a GUI-based interface has been developed to intuitively analyze local model behavior. In this paper, we delineate the design principles and utilization of the created library and GUI-based web platform. Currently, OpenVNA is publicly accessible at <url>https://github.com/thuiar/OpenVNA</url>, with a demonstration video available at <url>https://youtu.be/0Z9cW7RGct4</url>.</abstract>
      <url hash="519feae3">2024.acl-demos.2</url>
    </paper>
    <paper id="3">
      <title><fixed-case>XNLP</fixed-case>: An Interactive Demonstration System for Universal Structured <fixed-case>NLP</fixed-case></title>
      <author><first>Hao</first><last>Fei</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Meishan</first><last>Zhang</last><affiliation>Harbin Institute of Technology (Shenzhen), China and Tianjin University, China</affiliation></author>
      <author><first>Min</first><last>Zhang</last><affiliation>Harbin Institute of Technology, Shenzhen</affiliation></author>
      <author><first>Tat-Seng</first><last>Chua</last><affiliation>National University of Singapore</affiliation></author>
      <pages>19-30</pages>
      <abstract>Structured Natural Language Processing (XNLP) is an important subset of NLP that entails understanding the underlying semantic or syntactic structure of texts, which serves as a foundational component for many downstream applications. Despite certain recent efforts to explore universal solutions for specific categories of XNLP tasks, a comprehensive and effective approach for unifying all XNLP tasks long remains underdeveloped. Meanwhile, while XNLP demonstration systems are vital for researchers exploring various XNLP tasks, existing platforms can be limited to, e.g., supporting few XNLP tasks, lacking interactivity and universalness. To this end, we propose an advanced XNLP demonstration system, where we leverage LLM to achieve universal XNLP, with one model for all with high generalizability. Overall, our system advances in multiple aspects, including universal XNLP modeling, high performance, interpretability, scalability, and interactivity, offering a unified platform for exploring diverse XNLP tasks in the community.</abstract>
      <url hash="b5bdf322">2024.acl-demos.3</url>
    </paper>
    <paper id="4">
      <title>Towards the <fixed-case>T</fixed-case>op<fixed-case>M</fixed-case>ost: A Topic Modeling System Toolkit</title>
      <author><first>Xiaobao</first><last>Wu</last><affiliation>Nanyang Technological University</affiliation></author>
      <author><first>Fengjun</first><last>Pan</last></author>
      <author><first>Anh Tuan</first><last>Luu</last><affiliation>Nanyang Technological University</affiliation></author>
      <pages>31-41</pages>
      <abstract>Topic models have a rich history with various applications and have recently been reinvigorated by neural topic modeling. However, these numerous topic models adopt totally distinct datasets, implementations, and evaluations. This impedes quick utilization and fair comparisons, and thereby hinders their research progress and applications. To tackle this challenge, we in this paper propose a Topic Modeling System Toolkit (TopMost). Compared to existing toolkits, TopMost stands out by supporting more extensive features. It covers a broader spectrum of topic modeling scenarios with their complete lifecycles, including datasets, preprocessing, models, training, and evaluations. Thanks to its highly cohesive and decoupled modular design, TopMost enables rapid utilization, fair comparisons, and flexible extensions of diverse cutting-edge topic models. Our code, tutorials, and documentation are available at https://github.com/bobxwu/topmost.</abstract>
      <url hash="77a9397c">2024.acl-demos.4</url>
    </paper>
    <paper id="5">
      <title>Wordflow: Social Prompt Engineering for Large Language Models</title>
      <author><first>Zijie</first><last>Wang</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Aishwarya</first><last>Chakravarthy</last></author>
      <author><first>David</first><last>Munechika</last></author>
      <author><first>Duen Horng</first><last>Chau</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <pages>42-50</pages>
      <abstract>Large language models (LLMs) require well-crafted prompts for effective use. Prompt engineering, the process of designing prompts, is challenging, particularly for non-experts who are less familiar with AI technologies. While researchers have proposed techniques and tools to assist LLM users in prompt design, these works primarily target AI application developers rather than non-experts. To address this research gap, we propose social prompt engineering, a novel paradigm that leverages social computing techniques to facilitate collaborative prompt design. To investigate social prompt engineering, we introduce Wordflow, an open-source and social text editor that enables everyday users to easily create, run, share, and discover LLM prompts. Additionally, by leveraging modern web technologies, Wordflow allows users to run LLMs locally and privately in their browsers. Two usage scenarios highlight how social prompt engineering and our tool can enhance laypeople’s interaction with LLMs. Wordflow is publicly accessible at https://poloclub.github.io/wordflow.</abstract>
      <url hash="c4225137">2024.acl-demos.5</url>
    </paper>
    <paper id="6">
      <title><fixed-case>LM</fixed-case> Transparency Tool: Interactive Tool for Analyzing Transformer Language Models</title>
      <author><first>Igor</first><last>Tufanov</last><affiliation>Facebook</affiliation></author>
      <author><first>Karen</first><last>Hambardzumyan</last><affiliation>Facebook and University College London, University of London</affiliation></author>
      <author><first>Javier</first><last>Ferrando</last></author>
      <author><first>Elena</first><last>Voita</last><affiliation>FAIR at Meta AI and University of Amsterdam</affiliation></author>
      <pages>51-60</pages>
      <abstract>We present the LM Transparency Tool (LM-TT), an open-source interactive toolkit for analyzing the internal workings of Transformer-based language models. Differently from previously existing tools that focus on isolated parts of the decision-making process, our framework is designed to make the entire prediction process transparent, and allows tracing back model behavior from the top-layer representation to very fine-grained parts of the model. Specifically, it (i) shows the important part of the whole input-to-output information flow, (ii) allows attributing any changes done by a model block to individual attention heads and feed-forward neurons, (iii) allows interpreting the functions of those heads or neurons. A crucial part of this pipeline is showing the importance of specific model components at each step. As a result, we are able to look at the roles of model components only in cases where they are important for a prediction. Since knowing which components should be inspected is key for analyzing large models where the number of these components is extremely high, we believe our tool will greatly support the interpretability community both in research settings and in practical applications.</abstract>
      <url hash="4bf23d7a">2024.acl-demos.6</url>
    </paper>
    <paper id="7">
      <title><fixed-case>E</fixed-case>mpathy<fixed-case>E</fixed-case>ar: An Open-source Avatar Multimodal Empathetic Chatbot</title>
      <author><first>Hao</first><last>Fei</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Han</first><last>Zhang</last><affiliation>Xidian University</affiliation></author>
      <author><first>Bin</first><last>Wang</last></author>
      <author><first>Lizi</first><last>Liao</last><affiliation>Singapore Management University</affiliation></author>
      <author><first>Qian</first><last>Liu</last><affiliation>University of Auckland</affiliation></author>
      <author><first>Erik</first><last>Cambria</last><affiliation>Nanyang Technological University</affiliation></author>
      <pages>61-71</pages>
      <abstract>This paper introduces EmpathyEar, a pioneering open-source, avatar-based multimodal empathetic chatbot, to fill the gap in traditional text-only empathetic response generation (ERG) systems. Leveraging the advancements of a large language model, combined with multimodal encoders and generators, EmpathyEar supports user inputs in any combination of text, sound, and vision, and produces multimodal empathetic responses, offering users, not just textual responses but also digital avatars with talking faces and synchronized speeches. A series of emotion-aware instruction-tuning is performed for comprehensive emotional understanding and generation capabilities. In this way, EmpathyEar provides users with responses that achieve a deeper emotional resonance, closely emulating human-like empathy. The system paves the way for the next emotional intelligence, for which we open-source the code for public access.</abstract>
      <url hash="5575f300">2024.acl-demos.7</url>
    </paper>
    <paper id="8">
      <title><fixed-case>O</fixed-case>pen<fixed-case>W</fixed-case>eb<fixed-case>A</fixed-case>gent: An Open Toolkit to Enable Web Agents on Large Language Models</title>
      <author><first>Iat Long</first><last>Iong</last></author>
      <author><first>Xiao</first><last>Liu</last></author>
      <author><first>Yuxuan</first><last>Chen</last></author>
      <author><first>Hanyu</first><last>Lai</last></author>
      <author><first>Shuntian</first><last>Yao</last><affiliation>Beijing University of Posts and Telecommunications</affiliation></author>
      <author><first>Pengbo</first><last>Shen</last></author>
      <author><first>Hao</first><last>Yu</last></author>
      <author><first>Yuxiao</first><last>Dong</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Jie</first><last>Tang</last><affiliation>Tsinghua University, Tsinghua University</affiliation></author>
      <pages>72-81</pages>
      <abstract>We introduce OpenWebAgent, an open toolkit designed to optimize web automation by integrating both large language models (LLMs) and large multimodal models (LMMs). This toolkit focuses on enhancing human-computer interactions on the web, simplifying complex tasks through an advanced HTML parser, a rapid action generation module, and an intuitive user interface. At the core of OpenWebAgent is an innovative web agent framework that uses a modular design to allow developers to seamlessly integrate a variety of models and tools to process web information and automate tasks on the web. This enables the development of powerful, task-oriented web agents, significantly enhancing user experience and operational efficiency on the web. The OpenWebAgent framework, Chrome plugin, and demo video are available at https://github.com/THUDM/OpenWebAgent/.</abstract>
      <url hash="693211b1">2024.acl-demos.8</url>
    </paper>
    <paper id="9">
      <title><fixed-case>E</fixed-case>asy<fixed-case>E</fixed-case>dit: An Easy-to-use Knowledge Editing Framework for Large Language Models</title>
      <author><first>Peng</first><last>Wang</last></author>
      <author><first>Ningyu</first><last>Zhang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Bozhong</first><last>Tian</last></author>
      <author><first>Zekun</first><last>Xi</last></author>
      <author><first>Yunzhi</first><last>Yao</last></author>
      <author><first>Ziwen</first><last>Xu</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Mengru</first><last>Wang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Shengyu</first><last>Mao</last></author>
      <author><first>Xiaohan</first><last>Wang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Siyuan</first><last>Cheng</last></author>
      <author><first>Kangwei</first><last>Liu</last></author>
      <author><first>Yuansheng</first><last>Ni</last></author>
      <author><first>Guozhou</first><last>Zheng</last></author>
      <author><first>Huajun</first><last>Chen</last><affiliation>Zhejiang University</affiliation></author>
      <pages>82-93</pages>
      <abstract>Large Language Models (LLMs) usually suffer from knowledge cutoff or fallacy issues, which means they are unaware of unseen events or generate text with incorrect facts owing to outdated/noisy data. To this end, many knowledge editing approaches for LLMs have emerged – aiming to subtly inject/edit updated knowledge or adjust undesired behavior while minimizing the impact on unrelated inputs. Nevertheless, due to significant differences among various knowledge editing methods and the variations in task setups, there is no standard implementation framework available for the community, which hinders practitioners from applying knowledge editing to applications. To address these issues, we propose EasyEdit, an easy-to-use knowledge editing framework for LLMs. It supports various cutting-edge knowledge editing approaches and can be readily applied to many well-known LLMs such as T5, GPT-J, LlaMA, etc. Empirically, we report the knowledge editing results on LlaMA-2 with EasyEdit, demonstrating that knowledge editing surpasses traditional fine-tuning in terms of reliability and generalization. We have released the source code on GitHub, along with Google Colab tutorials and comprehensive documentation for beginners to get started. Besides, we present an online system for real-time knowledge editing, and a demo video.</abstract>
      <url hash="00639017">2024.acl-demos.9</url>
    </paper>
    <paper id="10">
      <title><fixed-case>E</fixed-case>asy<fixed-case>I</fixed-case>nstruct: An Easy-to-use Instruction Processing Framework for Large Language Models</title>
      <author><first>Yixin</first><last>Ou</last></author>
      <author><first>Ningyu</first><last>Zhang</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Honghao</first><last>Gui</last></author>
      <author><first>Ziwen</first><last>Xu</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Shuofei</first><last>Qiao</last></author>
      <author><first>Runnan</first><last>Fang</last></author>
      <author><first>Lei</first><last>Li</last><affiliation>Tencent</affiliation></author>
      <author><first>Zhen</first><last>Bi</last><affiliation>Zhejiang University</affiliation></author>
      <author><first>Guozhou</first><last>Zheng</last></author>
      <author><first>Huajun</first><last>Chen</last><affiliation>Zhejiang University</affiliation></author>
      <pages>94-106</pages>
      <abstract>In recent years, instruction tuning has gained increasing attention and emerged as a crucial technique to enhance the capabilities of Large Language Models (LLMs). To construct high-quality instruction datasets, many instruction processing approaches have been proposed, aiming to achieve a delicate balance between data quantity and data quality. Nevertheless, due to inconsistencies that persist among various instruction processing methods, there is no standard open-source instruction processing implementation framework available for the community, which hinders practitioners from further developing and advancing. To facilitate instruction processing research and development, we present EasyInstruct, an easy-to-use instruction processing framework for LLMs, which modularizes instruction generation, selection, and prompting, while also considering their combination and interaction. EasyInstruct is publicly released and actively maintained at Github, along with an online demo app and a demo video for quick-start, calling for broader research centered on instruction data and synthetic data.</abstract>
      <url hash="3b8296e3">2024.acl-demos.10</url>
    </paper>
    <paper id="11">
      <title><fixed-case>B</fixed-case>ot<fixed-case>E</fixed-case>val: Facilitating Interactive Human Evaluation</title>
      <author><first>Hyundong</first><last>Cho</last><affiliation>USC/ISI</affiliation></author>
      <author><first>Thamme</first><last>Gowda</last><affiliation>Microsoft Translator</affiliation></author>
      <author><first>Yuyang</first><last>Huang</last></author>
      <author><first>Zixun</first><last>Lu</last><affiliation>University of Southern California</affiliation></author>
      <author><first>Tianli</first><last>Tong</last></author>
      <author><first>Jonathan</first><last>May</last><affiliation>University of Southern California and USC/ISI</affiliation></author>
      <pages>107-116</pages>
      <abstract>Following the rapid progress in natural language processing (NLP) models, language models are applied to increasingly more complex interactive tasks such as negotiations and conversation moderations. Having human evaluators directly interact with these NLP models is essential for adequately evaluating the performance on such interactive tasks. We develop BotEval, an easily customizable, open-source, evaluation toolkit that focuses on enabling human-bot interactions as part of the evaluation process, as opposed to human evaluators making judgements for a static input. BotEval balances flexibility for customization and user-friendliness by providing templates for common use cases that span various degrees of complexity and built-in compatibility with popular crowdsourcing platforms.We showcase the numerous useful features of BotEval through a study that evaluates the performance of various chatbots on their effectiveness for conversational moderation and discuss how BotEval differs from other annotation tools.</abstract>
      <url hash="b97fdfcb">2024.acl-demos.11</url>
    </paper>
    <paper id="12">
      <title><fixed-case>G</fixed-case>en<fixed-case>GO</fixed-case>: <fixed-case>ACL</fixed-case> Paper Explorer with Semantic Features</title>
      <author><first>Sotaro</first><last>Takeshita</last><affiliation>Universit�t Mannheim</affiliation></author>
      <author><first>Simone</first><last>Ponzetto</last><affiliation>University of Mannheim</affiliation></author>
      <author><first>Kai</first><last>Eckert</last><affiliation>Mannheim University of Applied Sciences</affiliation></author>
      <pages>117-126</pages>
      <abstract>We present GenGO, a system for exploring papers published in ACL conferences. Paper data stored in our database is enriched with multi-aspect summaries, extracted named entities, a field of study label, and text embeddings by our data processing pipeline. These metadata are used in our web-based user interface to enable researchers to quickly find papers relevant to their interests, and grasp an overview of papers without reading full-text of papers. To make GenGO to be available online as long as possible, we design GenGO to be simple and efficient to reduce maintenance and financial costs. In addition, the modularity of our data processing pipeline lets developers easily extend it to add new features. We make our code available to foster open development and transparency: https://gengo.sotaro.io.</abstract>
      <url hash="bf16a5a6">2024.acl-demos.12</url>
    </paper>
    <paper id="13">
      <title><fixed-case>NLP</fixed-case>-<fixed-case>KG</fixed-case>: A System for Exploratory Search of Scientific Literature in Natural Language Processing</title>
      <author><first>Tim</first><last>Schopf</last></author>
      <author><first>Florian</first><last>Matthes</last><affiliation>Technische Universit�t M�nchen</affiliation></author>
      <pages>127-135</pages>
      <abstract>Scientific literature searches are often exploratory, whereby users are not yet familiar with a particular field or concept but are interested in learning more about it. However, existing systems for scientific literature search are typically tailored to keyword-based lookup searches, limiting the possibilities for exploration. We propose NLP-KG, a feature-rich system designed to support the exploration of research literature in unfamiliar natural language processing (NLP) fields. In addition to a semantic search, NLP-KG allows users to easily find survey papers that provide a quick introduction to a field of interest. Further, a Fields of Study hierarchy graph enables users to familiarize themselves with a field and its related areas. Finally, a chat interface allows users to ask questions about unfamiliar concepts or specific articles in NLP and obtain answers grounded in knowledge retrieved from scientific publications. Our system provides users with comprehensive exploration possibilities, supporting them in investigating the relationships between different fields, understanding unfamiliar concepts in NLP, and finding relevant research literature. Demo, video, and code are available at: https://github.com/NLP-Knowledge-Graph/NLP-KG-WebApp.</abstract>
      <url hash="adc7117f">2024.acl-demos.13</url>
    </paper>
    <paper id="14">
      <title><fixed-case>L</fixed-case>ocal<fixed-case>RQA</fixed-case>: From Generating Data to Locally Training, Testing, and Deploying Retrieval-Augmented <fixed-case>QA</fixed-case> Systems</title>
      <author><first>Xiao</first><last>Yu</last></author>
      <author><first>Yunan</first><last>Lu</last><affiliation>Columbia University</affiliation></author>
      <author><first>Zhou</first><last>Yu</last><affiliation>Columbia University</affiliation></author>
      <pages>136-151</pages>
      <abstract>Retrieval-augmented question-answering systems combine retrieval techniques with large language models to provide answers that are more accurate and informative. Many existing toolkits allow users to quickly build such systems using off-the-shelf models, but they fall short in supporting researchers and developers to customize the *model training, testing, and deployment process*. We propose LocalRQA, an open-source toolkit that features a wide selection of model training algorithms, evaluation methods, and deployment tools curated from the latest research. As a showcase, we build QA systems using online documentation obtained from Databricks and Faire’s websites. We find 7B-models trained and deployed using LocalRQA reach a similar performance compared to using OpenAI’s text-ada-002 and GPT-4-turbo.</abstract>
      <url hash="d1973c8c">2024.acl-demos.14</url>
    </paper>
    <paper id="15">
      <title><fixed-case>JORA</fixed-case>: <fixed-case>JAX</fixed-case> Tensor-Parallel <fixed-case>L</fixed-case>o<fixed-case>RA</fixed-case> Library for Retrieval Augmented Fine-Tuning</title>
      <author><first>Anique</first><last>Tahir</last><affiliation>Arizona State University</affiliation></author>
      <author><first>Lu</first><last>Cheng</last><affiliation>University of Illinois at Chicago</affiliation></author>
      <author><first>Huan</first><last>Liu</last><affiliation>Arizona State University</affiliation></author>
      <pages>152-159</pages>
      <abstract>The scaling of Large Language Models (LLMs) for retrieval-based tasks, particularly in Retrieval Augmented Generation (RAG), faces significant memory constraints, especially when fine-tuning extensive prompt sequences. Current open-source libraries support full-model inference and fine-tuning across multiple GPUs but fall short of accommodating the efficient parameter distribution required for retrieved context. Addressing this gap, we introduce a novel framework for PEFT-compatible fine-tuning of GPT models, leveraging distributed training. Our framework uniquely utilizes JAX’s just-in-time (JIT) compilation and tensor-sharding for efficient resource management, thereby enabling accelerated fine-tuning with reduced memory requirements. This advancement significantly improves the scalability and feasibility of fine-tuning LLMs for complex RAG applications, even on systems with limited GPU resources. Our experiments show more than 12x improvement in runtime compared to Hugging Face/DeepSpeed implementation with four GPUs while consuming less than half the VRAM per GPU.</abstract>
      <url hash="d6ea1a95">2024.acl-demos.15</url>
    </paper>
    <paper id="16">
      <title><fixed-case>L</fixed-case>ingua<fixed-case>L</fixed-case>inked: Distributed Large Language Model Inference on Mobile Devices</title>
      <author><first>Junchen</first><last>Zhao</last></author>
      <author><first>Yurun</first><last>Song</last><affiliation>University of California, Irvine</affiliation></author>
      <author><first>Simenl3@uci.edu</first><last>Simenl3@uci.edu</last><affiliation>NA</affiliation></author>
      <author><first>Ian</first><last>Harris</last><affiliation>University of California-Irvine</affiliation></author>
      <author><first>Sangeetha</first><last>Abdu Jyothi</last><affiliation>University of California, Irvine</affiliation></author>
      <pages>160-171</pages>
      <abstract>Deploying Large Language Models (LLMs) locally on mobile devices presents a significant challenge due to their extensive memory requirements. In this paper, we introduce LinguaLinked, a system for decentralized, distributed LLM inference on mobile devices. LinguaLinked enables collaborative execution of the inference task across multiple trusted devices and ensures data privacy by processing information locally. LinguaLinked uses three key strategies. First, an optimized model assignment technique segments LLMs and uses linear optimization to align segments with each device�s capabilities. Second, an optimized data transmission mechanism ensures efficient and structured data flow between model segments while also maintaining the integrity of the original model structure. Finally, LinguaLinked incorporates a runtime load balancer that actively monitors and redistributes tasks among mobile devices to prevent bottlenecks, enhancing the system�s overall efficiency and responsiveness. We demonstrate that LinguaLinked facilitates efficient LLM inference while maintaining consistent throughput and minimal latency through extensive testing across various mobile devices, from high-end to low-end Android devices.</abstract>
      <url hash="e0f790bd">2024.acl-demos.16</url>
    </paper>
    <paper id="17">
      <title><fixed-case>IMGTB</fixed-case>: A Framework for Machine-Generated Text Detection Benchmarking</title>
      <author><first>Michal</first><last>Spiegel</last><affiliation>Kempelen Institute of Intelligent Technologies</affiliation></author>
      <author><first>Dominik</first><last>Macko</last><affiliation>Kempelen Institute of Intelligent Technologies</affiliation></author>
      <pages>172-179</pages>
      <abstract>In the era of large language models generating high quality texts, it is a necessity to develop methods for detection of machine-generated text to avoid their harmful use or simply for annotation purposes. It is, however, also important to properly evaluate and compare such developed methods. Recently, a few benchmarks have been proposed for this purpose; however, integration of newest detection methods is rather challenging, since new methods appear each month and provide slightly different evaluation pipelines.In this paper, we present the IMGTB framework, which simplifies the benchmarking of machine-generated text detection methods by easy integration of custom (new) methods and evaluation datasets. In comparison to existing frameworks, it enables to objectively compare statistical metric-based zero-shot detectors with classification-based detectors and with differently fine-tuned detectors. Its configurability and flexibility makes research and development of new detection methods easier, especially their comparison to the existing state-of-the-art detectors. The default set of analyses, metrics and visualizations offered by the tool follows the established practices of machine-generated text detection benchmarking found in state-of-the-art literature.</abstract>
      <url hash="abb49eaf">2024.acl-demos.17</url>
    </paper>
    <paper id="18">
      <title><fixed-case>D</fixed-case>rug<fixed-case>W</fixed-case>atch: A Comprehensive Multi-Source Data Visualisation Platform for Drug Safety Information</title>
      <author><first>Artem</first><last>Bobrov</last><affiliation>King’s College London, University of London</affiliation></author>
      <author><first>Domantas</first><last>Saltenis</last></author>
      <author><first>Zhaoyue</first><last>Sun</last><affiliation>University of Warwick</affiliation></author>
      <author><first>Gabriele</first><last>Pergola</last><affiliation>University of Warwick</affiliation></author>
      <author><first>Yulan</first><last>He</last><affiliation>King’s College London, University of London</affiliation></author>
      <pages>180-189</pages>
      <abstract>Drug safety research is crucial for maintaining public health, often requiring comprehensive data support. However, the resources currently available to the public are limited and fail to provide a comprehensive understanding of the relationship between drugs and their side effects. This paper introduces “DrugWatch”, an easy-to-use and interactive multi-source information visualisation platform for drug safety study. It allows users to understand common side effects of drugs and their statistical information, flexibly retrieve relevant medical reports, or annotate their own medical texts with our automated annotation tool. Supported by NLP technology and enriched with interactive visual components, we are committed to providing researchers and practitioners with a one-stop information analysis, retrieval, and annotation service. The demonstration video is available at https://www.youtube.com/watch?v=RTqDgxzETjw. We also deployed an online demonstration system at https://drugwatch.net/.</abstract>
      <url hash="bfb6ca29">2024.acl-demos.18</url>
    </paper>
    <paper id="19">
      <title><fixed-case>O</fixed-case>pen<fixed-case>E</fixed-case>val: Benchmarking <fixed-case>C</fixed-case>hinese <fixed-case>LLM</fixed-case>s across Capability, Alignment and Safety</title>
      <author><first>Chuang</first><last>Liu</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Linhao</first><last>Yu</last></author>
      <author><first>Jiaxuan</first><last>Li</last><affiliation>Tianjin University</affiliation></author>
      <author><first>Renren</first><last>Jin</last></author>
      <author><first>Yufei</first><last>Huang</last></author>
      <author><first>Ling</first><last>Shi</last></author>
      <author><first>Junhui</first><last>Zhang</last></author>
      <author><first>Xinmeng</first><last>Ji</last></author>
      <author><first>Tingting</first><last>Cui</last></author>
      <author><first>Liutao</first><last>Liutao</last></author>
      <author><first>Jinwang</first><last>Song</last></author>
      <author><first>Hongying</first><last>Zan</last><affiliation>Zhengzhou University</affiliation></author>
      <author><first>Sun</first><last>Li</last><affiliation>China Academy of Information and Communications Technology</affiliation></author>
      <author><first>Deyi</first><last>Xiong</last><affiliation>Tianjin University</affiliation></author>
      <pages>190-210</pages>
      <abstract>The rapid development of Chinese large language models (LLMs) poses big challenges for efficient LLM evaluation. While current initiatives have introduced new benchmarks or evaluation platforms for assessing Chinese LLMs, many of these focus primarily on capabilities, usually overlooking potential alignment and safety issues. To address this gap, we introduce OpenEval, an evaluation testbed that benchmarks Chinese LLMs across capability, alignment and safety. For capability assessment, we include 12 benchmark datasets to evaluate Chinese LLMs from 4 sub-dimensions: NLP tasks, disciplinary knowledge, commonsense reasoning and mathematical reasoning. For alignment assessment, OpenEval contains 7 datasets that examines the bias, offensiveness and illegalness in the outputs yielded by Chinese LLMs. To evaluate safety, especially anticipated risks (e.g., power-seeking, self-awareness) of advanced LLMs, we include 6 datasets. In addition to these benchmarks, we have implemented a phased public evaluation and benchmark update strategy to ensure that OpenEval is in line with the development of Chinese LLMs or even able to provide cutting-edge benchmark datasets to guide the development of Chinese LLMs. In our first public evaluation, we have tested a range of Chinese LLMs, spanning from 7B to 72B parameters, including both open-source and proprietary models. Evaluation results indicate that while Chinese LLMs have shown impressive performance in certain tasks, more attention should be directed towards broader aspects such as commonsense reasoning, alignment, and safety.</abstract>
      <url hash="c19a1ae0">2024.acl-demos.19</url>
    </paper>
    <paper id="20">
      <title><fixed-case>A</fixed-case>uto<fixed-case>RE</fixed-case>: Document-Level Relation Extraction with Large Language Models</title>
      <author><first>Lilong</first><last>Xue</last></author>
      <author><first>Dan</first><last>Zhang</last></author>
      <author><first>Yuxiao</first><last>Dong</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Jie</first><last>Tang</last><affiliation>Tsinghua University, Tsinghua University</affiliation></author>
      <pages>211-220</pages>
      <abstract>Large Language Models (LLMs) have demonstrated exceptional abilities in comprehending and generating text, motivating numerous researchers to utilize them for Information Extraction (IE) purposes, including Relation Extraction (RE). Nonetheless, most existing methods are predominantly designed for Sentence-level Relation Extraction (SentRE) tasks, which typically encompass a restricted set of relations and triplet facts within a single sentence. Furthermore, certain approaches resort to treating relations as candidate choices integrated into prompt templates, leading to inefficient processing and suboptimal performance when tackling Document-Level Relation Extraction (DocRE) tasks, which entail handling multiple relations and triplet facts distributed across a given document, posing distinct challenges. To overcome these limitations, we introduce AutoRE, an end-to-end DocRE model that adopts a novel RE extraction paradigm named RHF (Relation-Head-Facts). Unlike existing approaches, AutoRE does not rely on the assumption of known relation options, making it more reflective of real-world scenarios. Additionally, we have developed an easily extensible RE framework using a Parameters Efficient Fine Tuning (PEFT) algorithm (QLoRA). Our experiments on the RE-DocRED dataset showcase AutoRE’s best performance, achieving state-of-the-art results, surpassing TAG by 10.03% and 9.03% respectively on the dev and test set. The code is available and the demonstration video is provided.</abstract>
      <url hash="8f8994d2">2024.acl-demos.20</url>
    </paper>
    <paper id="21">
      <title><fixed-case>L</fixed-case>ink<fixed-case>T</fixed-case>ransformer: A Unified Package for Record Linkage with Transformer Language Models</title>
      <author><first>Abhishek</first><last>Arora</last><affiliation>Harvard University, Harvard University</affiliation></author>
      <author><first>Melissa</first><last>Dell</last><affiliation>Harvard University, Harvard University</affiliation></author>
      <pages>221-231</pages>
      <abstract>Many computational analyses require linking information across noisy text datasets. While large language models (LLMs) offer significant promise, approximate string matching packages in popular statistical softwares such as R and Stata remain predominant in academic applications. These packages have simple interfaces and can be easily extended to a diversity of languages and settings, and for academic applications, ease-of-use and extensibility are essential. In contrast, packages for record linkage with LLMs require significant familiarity with deep learning frameworks and often focus on specialized applications of commercial value in English. The open-source package LinkTransformer aims to bridge this gap by providing an end-to-end software for performing record linkage and other data cleaning tasks with transformer LLMs, treating linkage as a text retrieval problem. At its core is an off-the-shelf toolkit for applying transformer models to record linkage. LinkTransformer contains a rich repository of pre-trained models for multiple languages and supports easy integration of any transformer language model from Hugging Face or OpenAI, providing the extensibility required for many scholarly applications. Its APIs also perform common data processing tasks, e.g., aggregation, noisy de-duplication, and translation-free cross-lingual linkage. LinkTransformer contains comprehensive tools for efficient model tuning, allowing for highly customized applications, and users can easily contribute their custom-trained models to its model hub to ensure reproducibility. Using a novel benchmark dataset geared towards academic applications, we show that LinkTransformer - with both custom models and Hugging Face or OpenAI models off-the-shelf - outperforms string matching by a wide margin. By combining transformer LMs with intuitive APIs, LinkTransformer aims to democratize these performance gains for those who lack familiarity with deep learning frameworks.</abstract>
      <url hash="a5ac53d4">2024.acl-demos.21</url>
    </paper>
    <paper id="22">
      <title><fixed-case>D</fixed-case>oc<fixed-case>P</fixed-case>ilot: Copilot for Automating <fixed-case>PDF</fixed-case> Edit Workflows in Documents</title>
      <author><first>Puneet</first><last>Mathur</last><affiliation>Adobe Systems</affiliation></author>
      <author><first>Alexa</first><last>Siu</last><affiliation>Adobe</affiliation></author>
      <author><first>Varun</first><last>Manjunatha</last><affiliation>Adobe Systems</affiliation></author>
      <author><first>Tong</first><last>Sun</last><affiliation>Adobe Systems</affiliation></author>
      <pages>232-246</pages>
      <abstract>Digital documents, such as PDFs, are vital in business workflows, enabling communication, documentation, and collaboration. Handling PDFs can involve navigating complex workflows and numerous tools (e.g., comprehension, annotation, editing), which can be tedious and time-consuming for users. We introduce DocPilot, an AI-assisted document workflow Copilot system capable of understanding user intent and executing tasks accordingly to help users streamline their workflows. DocPilot undertakes intelligent orchestration of various tools through LLM prompting in four steps: (1) Task plan generation, (2) Task plan verification and self-correction, (3) Multi-turn User Feedback, and (4) Task Plan Execution via Code Generation and Error log-based Code Self-Revision. The primary goal of this system is to free the user from the intricacies of document editing, enabling them to focus on the creative aspects and enrich their document management experience.</abstract>
      <url hash="ebd97356">2024.acl-demos.22</url>
    </paper>
    <paper id="23">
      <title><fixed-case>U</fixed-case>ltra<fixed-case>E</fixed-case>val: A Lightweight Platform for Flexible and Comprehensive Evaluation for <fixed-case>LLM</fixed-case>s</title>
      <author><first>Chaoqun</first><last>He</last></author>
      <author><first>Renjie</first><last>Luo</last></author>
      <author><first>Shengding</first><last>Hu</last></author>
      <author><first>Ranchi</first><last>Zhao</last><affiliation>ModelBest</affiliation></author>
      <author><first>Jie</first><last>Zhou</last></author>
      <author><first>Hanghao</first><last>Wu</last></author>
      <author><first>Jiajie</first><last>Zhang</last><affiliation>Northeastern University</affiliation></author>
      <author><first>Xu</first><last>Han</last><affiliation>Tsinghua University, Tsinghua University</affiliation></author>
      <author><first>Zhiyuan</first><last>Liu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <pages>247-257</pages>
      <abstract>Evaluation is pivotal for honing Large Language Models (LLMs), pinpointing their capabilities and guiding enhancements. The rapid development of LLMs calls for a lightweight and easy-to-use framework for swift evaluation deployment. However, due to the various implementation details to consider, developing a comprehensive evaluation platform is never easy. Existing platforms are often complex and poorly modularized, hindering seamless incorporation into researcher’s workflows. This paper introduces UltraEval, a user-friendly evaluation framework characterized by lightweight, comprehensiveness, modularity, and efficiency. We identify and reimplement three core components of model evaluation (models, data, and metrics). The resulting composability allows for the free combination of different models, tasks, prompts, and metrics within a unified evaluation workflow. Additionally, UltraEval supports diverse models owing to a unified HTTP service and provides sufficient inference acceleration.</abstract>
      <url hash="0296efd2">2024.acl-demos.23</url>
    </paper>
    <paper id="24">
      <title><fixed-case>P</fixed-case>y<fixed-case>F</fixed-case>oma: a Python finite-state compiler module</title>
      <author><first>Mans</first><last>Hulden</last><affiliation>University of Colorado at Boulder</affiliation></author>
      <author><first>Michael</first><last>Ginn</last><affiliation>University of Colorado at Boulder</affiliation></author>
      <author><first>Miikka</first><last>Silfverberg</last><affiliation>University of British Columbia</affiliation></author>
      <author><first>Michael</first><last>Hammond</last><affiliation>University of Arizona</affiliation></author>
      <pages>258-265</pages>
      <abstract>We describe PyFoma, an open-source Python module for constructing weighted and unweighted finite-state transducers and automata from regular expressions, string rewriting rules, right-linear grammars, or low-level state/transition manipulation. A large variety of standard algorithms for working with finite-state machines is included, with a particular focus on the needs of linguistic and NLP applications. The data structures and code in the module are designed for legibility to allow for potential use in teaching the theory and algorithms associated with finite-state machines.</abstract>
      <url hash="e953c5d9">2024.acl-demos.24</url>
    </paper>
    <paper id="25">
      <title><fixed-case>V</fixed-case>era<fixed-case>CT</fixed-case> Scan: Retrieval-Augmented Fake News Detection with Justifiable Reasoning</title>
      <author><first>Cheng</first><last>Niu</last></author>
      <author><first>Yang</first><last>Guan</last></author>
      <author><first>Yuanhao</first><last>Wu</last><affiliation>Newsbreak</affiliation></author>
      <author><first>Juno</first><last>Zhu</last></author>
      <author><first>Juntong</first><last>Song</last></author>
      <author><first>Randy</first><last>Zhong</last></author>
      <author><first>Kaihua</first><last>Zhu</last></author>
      <author><first>Siliang</first><last>Xu</last></author>
      <author><first>Shizhe</first><last>Diao</last><affiliation>Hong Kong University of Science and Technology</affiliation></author>
      <author><first>Tong</first><last>Zhang</last><affiliation>UIUC</affiliation></author>
      <pages>266-277</pages>
      <abstract>The proliferation of fake news poses a significant threat not only by disseminating misleading information but also by undermining the very foundations of democracy. The recent advance of generative artificial intelligence has further exacerbated the challenge of distinguishing genuine news from fabricated stories. In response to this challenge, we introduce VeraCT Scan, a novel retrieval-augmented system for fake news detection. This system operates by extracting the core facts from a given piece of news and subsequently conducting an internet-wide search to identify corroborating or conflicting reports. Then sources’ credibility is leveraged for information verification. Besides determining the veracity of news, we also provide transparent evidence and reasoning to support its conclusions, resulting in the interpretability and trust in the results. In addition to GPT-4 Turbo, Llama-2 13B is also fine-tuned for news content understanding, information verification, and reasoning. Both implementations have demonstrated state-of-the-art accuracy in the realm of fake news detection.</abstract>
      <url hash="5772bcbb">2024.acl-demos.25</url>
    </paper>
    <paper id="26">
      <title>string2string: A Modern Python Library for String-to-String Algorithms</title>
      <author><first>Mirac</first><last>Suzgun</last><affiliation>Stanford University</affiliation></author>
      <author><first>Stuart</first><last>Shieber</last><affiliation>Harvard University</affiliation></author>
      <author><first>Dan</first><last>Jurafsky</last><affiliation>Stanford University</affiliation></author>
      <pages>278-285</pages>
      <abstract>We introduce **string2string**, an open-source library that offers a comprehensive suite of efficient algorithms for a broad range of string-to-string problems. It includes traditional algorithmic solutions as well as recent advanced neural approaches to tackle various problems in string alignment, distance measurement, lexical and semantic search, and similarity analysis�along with several helpful visualization tools and metrics to facilitate the interpretation and analysis of these methods. Notable algorithms featured in the library include the Smith-Waterman algorithm for pairwise local alignment, the Hirschberg algorithm for global alignment, the Wagner-Fischer algorithm for edit distance, BARTScore and BERTScore for similarity analysis, the Knuth-Morris-Pratt algorithm for lexical search, and Faiss for semantic search. In addition, it wraps existing efficient and widely-used implementations of certain frameworks and metrics, such as sacreBLEU and ROUGE. Overall, the library aims to provide extensive coverage and increased flexibility in comparison to existing libraries for strings. It can be used for many downstream applications, tasks, and problems in natural-language processing, bioinformatics, and computational social sciences. It is implemented in Python, easily installable via pip, and accessible through a simple API. Source code, documentation, and tutorials are all available on our GitHub page: https://github.com/stanfordnlp/string2string* Documentation: https://string2string.readthedocs.io/en/latest/* GitHub page: https://github.com/stanfordnlp/string2string* Short video: https://drive.google.com/file/d/1IT-pBACDVUoEHewk__5Pz5mU5oAMq5k_/view?usp=sharing</abstract>
      <url hash="dfc43a85">2024.acl-demos.26</url>
    </paper>
    <paper id="27">
      <title>Proofread: Fixes All Errors with One Tap</title>
      <author><first>Renjie</first><last>Liu</last></author>
      <author><first>Yanxiang</first><last>Zhang</last></author>
      <author><first>Yun</first><last>Zhu</last><affiliation>Google</affiliation></author>
      <author><first>Haicheng</first><last>Sun</last></author>
      <author><first>Yuanbo</first><last>Zhang</last></author>
      <author><first>Michael</first><last>Huang</last><affiliation>Google</affiliation></author>
      <author><first>Shanqing</first><last>Cai</last><affiliation>Google</affiliation></author>
      <author><first>Lei</first><last>Meng</last></author>
      <author><first>Shumin</first><last>Zhai</last><affiliation>Google</affiliation></author>
      <pages>286-293</pages>
      <abstract>The impressive capabilities in Large Language Models (LLMs) provide a powerful approach to reimagine users’ typing experience. This paper demonstrates the Proofread feature in Gboard, a virtual keyboard running on mobile phones. Proofread enables seamless sentence-level and paragraph-level corrections with a single tap. We describe the complete system in this paper, from data generation, metrics design to model tuning and deployment. To obtain models with sufficient quality, we implement a careful data synthetic pipeline tailored to online use cases, design multifaceted metrics, employ a two-stage tuning approach to acquire the dedicated LLM for the feature: the Supervised Fine Tuning (SFT) for foundational quality, followed by the Reinforcement Learning (RL) tuning approach for targeted refinement. Specifically, we find sequential tuning on Rewrite and proofread tasks yields the best quality in SFT stage, and propose global and direct rewards in the RL tuning stage to seek further improvement. Extensive experiments on a human-labeled golden set showed our tuned PaLM2-XS model achieved 85.56% good ratio. We launched the feature to Pixel 8 devices by serving the model on TPU v5 in Google Cloud, with thousands of daily active users. Serving latency was significantly reduced by quantization, bucket inference, text segmentation, and speculative decoding. Our demo could be seen in Youtube.</abstract>
      <url hash="a4223881">2024.acl-demos.27</url>
    </paper>
    <paper id="28">
      <title><fixed-case>S</fixed-case>ea<fixed-case>LLM</fixed-case>s - Large Language Models for <fixed-case>S</fixed-case>outheast <fixed-case>A</fixed-case>sia</title>
      <author><first>Xuan-Phi</first><last>Nguyen</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Wenxuan</first><last>Zhang</last></author>
      <author><first>Xin</first><last>Li</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Mahani</first><last>Aljunied</last><affiliation>Alibaba Group</affiliation></author>
      <author><first>Zhiqiang</first><last>Hu</last><affiliation>Singapore University of Technology and Design</affiliation></author>
      <author><first>Chenhui</first><last>Shen</last><affiliation>National University of Singapore</affiliation></author>
      <author><first>Yew Ken</first><last>Chia</last></author>
      <author><first>Xingxuan</first><last>Li</last></author>
      <author><first>Jianyu</first><last>Wang</last><affiliation>Alibaba DAMO Academy</affiliation></author>
      <author><first>Qingyu</first><last>Tan</last><affiliation>national university of singaore, National University of Singapore</affiliation></author>
      <author><first>Liying</first><last>Cheng</last></author>
      <author><first>Guanzheng</first><last>Chen</last></author>
      <author><first>Yue</first><last>Deng</last><affiliation>School of Computer Science and Engineering, Nanyang Technological University</affiliation></author>
      <author><first>Sen</first><last>Yang</last><affiliation>The Chinese University of Hong Kong</affiliation></author>
      <author><first>Chaoqun</first><last>Liu</last></author>
      <author><first>Hang</first><last>Zhang</last></author>
      <author><first>Lidong</first><last>Bing</last><affiliation>Alibaba Group</affiliation></author>
      <pages>294-304</pages>
      <abstract>Despite the remarkable achievements of large language models (LLMs) in various tasks, there remains a linguistic bias that favors high-resource languages, such as English, often at the expense of low-resource and regional languages. To address this imbalance, we introduce SeaLLMs, an innovative series of language models that specifically focuses on Southeast Asian (SEA) languages. SeaLLMs are built upon popular English-centric models through continued pre-training with an extended vocabulary, specialized instruction and alignment tuning to better capture the intricacies of regional languages. This allows them to respect and reflect local cultural norms, customs, stylistic preferences, and legal considerations. Our comprehensive evaluation demonstrates that SeaLLM models exhibit superior performance across a wide spectrum of linguistic tasks and assistant-style instruction-following capabilities relative to comparable open-source models. Moreover, they outperform ChatGPT-3.5 in non-Latin languages, such as Thai, Khmer, Lao, and Burmese, by large margins while remaining lightweight and cost-effective to operate.</abstract>
      <url hash="b2b6086c">2024.acl-demos.28</url>
    </paper>
    <paper id="29">
      <title>Fundus: A Simple-to-Use News Scraper Optimized for High Quality Extractions</title>
      <author><first>Max</first><last>Dallabetta</last><affiliation>Department of Computer Science, Humboldt University Berlin, Humboldt Universit�t Berlin</affiliation></author>
      <author><first>Conrad</first><last>Dobberstein</last><affiliation>Technische Universit�t Berlin</affiliation></author>
      <author><first>Adrian</first><last>Breiding</last></author>
      <author><first>Alan</first><last>Akbik</last><affiliation>Humboldt Universit�t Berlin</affiliation></author>
      <pages>305-314</pages>
      <abstract>This paper introduces Fundus, a user-friendly news scraper that enables users to obtain millions of high-quality news articles with just a few lines of code. Unlike existing news scrapers, we use manually crafted, bespoke content extractors that are specifically tailored to the formatting guidelines of each supported online newspaper. This allows us to optimize our scraping for quality such that retrieved news articles are textually complete and without HTML artifacts. Further, our framework combines both crawling (retrieving HTML from the web or large web archives) and content extraction into a single pipeline. By providing a unified interface for a predefined collection of newspapers, we aim to make Fundus broadly usable even for non-technical users. This paper gives an overview of the framework, discusses our design choices, and presents a comparative evaluation against other popular news scrapers. Our evaluation shows that Fundus yields significantly higher quality extractions (complete and artifact-free news articles) than prior work.The framework is available on GitHub under https://github.com/flairNLP/fundus and can be simply installed using pip.</abstract>
      <url hash="356e496a">2024.acl-demos.29</url>
    </paper>
    <paper id="30">
      <title><fixed-case>C</fixed-case>har<fixed-case>P</fixed-case>oet: A <fixed-case>C</fixed-case>hinese Classical Poetry Generation System Based on Token-free <fixed-case>LLM</fixed-case></title>
      <author><first>Chengyue</first><last>Yu</last><affiliation>Ant Group</affiliation></author>
      <author><first>Lei</first><last>Zang</last></author>
      <author><first>Jiaotuan</first><last>Wang</last></author>
      <author><first>Chenyi</first><last>Zhuang</last></author>
      <author><first>Jinjie</first><last>Gu</last></author>
      <pages>315-325</pages>
      <abstract>Automatic Chinese classical poetry generation has attracted much research interest, but achieving effective control over format and content simultaneously remains challenging. Traditional systems usually accept keywords as user inputs, resulting in limited control over content. Large language models (LLMs) improve content control by allowing unrestricted user instructions, but the token-by-token generation process frequently makes format errors. Motivated by this, we propose CharPoet, a Chinese classical poetry generation system based on token-free LLM, which provides effective control over both format and content. Our token-free architecture generates in a character-by-character manner, enabling precise control over the number of characters. Pruned from existing token-based LLMs, CharPoet inherits their pretrained capabilities and can generate poetry following instructions like �Write me a poem for my mother’s birthday.� CharPoet achieves format accuracy above 0.96, outperforming Jiuge-GPT-2 (0.91) and GPT-4 (0.38). In terms of content quality, CharPoet surpasses traditional systems including Jiuge, and is comparable to other LLMs. Our system is open source and available at https://modelscope.cn/models/CharPoet/CharPoet. A video demonstration of CharPoet is available at https://youtu.be/voZ25qEp3Dc.</abstract>
      <url hash="e359bfda">2024.acl-demos.30</url>
    </paper>
    <paper id="31">
      <title><fixed-case>ITAKE</fixed-case>: Interactive Unstructured Text Annotation and Knowledge Extraction System with <fixed-case>LLM</fixed-case>s and <fixed-case>M</fixed-case>odel<fixed-case>O</fixed-case>ps</title>
      <author><first>Jiahe</first><last>Song</last></author>
      <author><first>Hongxin</first><last>Ding</last></author>
      <author><first>Zhiyuan</first><last>Wang</last></author>
      <author><first>Yongxin</first><last>Xu</last></author>
      <author><first>Yasha</first><last>Wang</last></author>
      <author><first>Junfeng</first><last>Zhao</last><affiliation>Peking University</affiliation></author>
      <pages>326-334</pages>
      <abstract>Extracting structured knowledge from unstructured text data has a wide range of application prospects, and a pervasive trend is to develop text annotation tools to help extraction. However, they often encounter issues such as single scenario usage, lack of effective human-machine collaboration, insufficient model supervision, and suboptimal utilization of Large Language Models (LLMs). We introduces an interactive unstructured text annotation and knowledge extraction system that synergistically integrates LLMs and ModelOps to alleviate these issues. The system leverages LLMs for enhanced performance in low-resource contexts, employs a ModelOps platform to monitor models throughout their lifecycle, and amalgamates interactive annotation methods with online machine learning and active learning. The demo video and website are now publicly available.</abstract>
      <url hash="b2a6b68f">2024.acl-demos.31</url>
    </paper>
    <paper id="32">
      <title><fixed-case>LEGENT</fixed-case>: Open Platform for Embodied Agents</title>
      <author><first>Zhili</first><last>Cheng</last></author>
      <author><first>Zhitong</first><last>Wang</last></author>
      <author><first>Jinyi</first><last>Hu</last></author>
      <author><first>Shengding</first><last>Hu</last></author>
      <author><first>An</first><last>Liu</last></author>
      <author><first>Yuge</first><last>Tu</last></author>
      <author><first>Pengkai</first><last>Li</last><affiliation>Central South University</affiliation></author>
      <author><first>Lei</first><last>Shi</last></author>
      <author><first>Zhiyuan</first><last>Liu</last><affiliation>Tsinghua University</affiliation></author>
      <author><first>Maosong</first><last>Sun</last></author>
      <pages>335-345</pages>
      <abstract>Despite advancements in Large Language Models (LLMs) and Large Multimodal Models (LMMs), their integration into language-grounded, human-like embodied agents remains incomplete, hindering complex real-life task performance in 3D environments. Existing integrations often feature limited open-sourcing, challenging collective progress in this field. We introduce LEGENT, an open, scalable platform for developing embodied agents using LLMs and LMMs. LEGENT offers a dual approach: a rich 3D environment with interactive, communicable, and actionable agents, paired with a user-friendly interface, and a sophisticated data generation pipeline utilizing advanced algorithms to exploit supervision from simulated worlds at scale. In our experiments, an embryonic vision-language-action model trained on LEGENT-generated data surpasses GPT-4V in embodied tasks, showcasing promising generalization capabilities. The demo video is available at the following link https://video.legent.ai.</abstract>
      <url hash="3189f1e9">2024.acl-demos.32</url>
    </paper>
    <paper id="33">
      <title>Variationist: Exploring Multifaceted Variation and Bias in Written Language Data</title>
      <author><first>Alan</first><last>Ramponi</last><affiliation>Fondazione Bruno Kessler</affiliation></author>
      <author><first>Camilla</first><last>Casula</last><affiliation>University of Trento and Fondazione Bruno Kessler</affiliation></author>
      <author><first>Stefano</first><last>Menini</last></author>
      <pages>346-354</pages>
      <abstract>Exploring and understanding language data is a fundamental stage in all areas dealing with human language. It allows NLP practitioners to uncover quality concerns and harmful biases in data before training, and helps linguists and social scientists to gain insight into language use and human behavior. Yet, there is currently a lack of a unified, customizable tool to seamlessly inspect and visualize language variation and bias across multiple variables, language units, and diverse metrics that go beyond descriptive statistics. In this paper, we introduce Variationist, a highly-modular, extensible, and task-agnostic tool that fills this gap. Variationist handles at once a potentially unlimited combination of variable types and semantics across diversity and association metrics with regards to the language unit of choice, and orchestrates the creation of up to five-dimensional interactive charts for over 30 variable type-semantics combinations. Through our case studies on computational dialectology, human label variation, and text generation, we show how Variationist enables researchers from different disciplines to effortlessly answer specific research questions or unveil undesired associations in language data. A Python library, code, documentation, and tutorials are made publicly available to the research community.</abstract>
      <url hash="8ed90a72">2024.acl-demos.33</url>
    </paper>
    <paper id="34">
      <title>An <fixed-case>LLM</fixed-case>-based Knowledge Synthesis and Scientific Reasoning Framework for Biomedical Discovery</title>
      <author><first>Oskar</first><last>Wysocki</last></author>
      <author><first>Magdalena.wysocka@cruk.manchester.ac.uk</first><last>Magdalena.wysocka@cruk.manchester.ac.uk</last><affiliation>NA</affiliation></author>
      <author><first>Danilo</first><last>Carvalho</last><affiliation>University of Manchester</affiliation></author>
      <author><first>Alex</first><last>Bogatu</last></author>
      <author><first>Danilo.miranda@idiap.ch</first><last>Danilo.miranda@idiap.ch</last><affiliation>NA</affiliation></author>
      <author><first>Maxime.delmas@idiap.ch</first><last>Maxime.delmas@idiap.ch</last><affiliation>NA</affiliation></author>
      <author><first>Harriet.unsworth@cruk.manchester.ac.uk</first><last>Harriet.unsworth@cruk.manchester.ac.uk</last><affiliation>NA</affiliation></author>
      <author><first>Andre</first><last>Freitas</last><affiliation>Idiap Research Institute and University of Manchester</affiliation></author>
      <pages>355-364</pages>
      <abstract>We present BioLunar, developed using the Lunar framework, as a tool for supporting biological analyses, with a particular emphasis on molecular-level evidence enrichment for biomarker discovery in oncology. The platform integrates Large Language Models (LLMs) to facilitate complex scientific reasoning across distributed evidence spaces, enhancing the capability for harmonizing and reasoning over heterogeneous data sources. Demonstrating its utility in cancer research, BioLunar leverages modular design, reusable data access and data analysis components, and a low-code user interface, enabling researchers of all programming levels to construct LLM-enabled scientific workflows. By facilitating automatic scientific discovery and inference from heterogeneous evidence, BioLunar exemplifies the potential of the integration between LLMs, specialised databases and biomedical tools to support expert-level knowledge synthesis and discovery.</abstract>
      <url hash="d0f121d9">2024.acl-demos.34</url>
    </paper>
    <paper id="35">
      <title><fixed-case>C</fixed-case>og<fixed-case>MG</fixed-case>: Collaborative Augmentation Between Large Language Model and Knowledge Graph</title>
      <author><first>Tong</first><last>Zhou</last></author>
      <author><first>Yubo</first><last>Chen</last><affiliation>Institute of automation, Chinese academy of science</affiliation></author>
      <author><first>Kang</first><last>Liu</last><affiliation>Institute of automation, Chinese academy of science, Chinese Academy of Sciences</affiliation></author>
      <author><first>Jun</first><last>Zhao</last><affiliation>Institute of automation, Chinese academy of science</affiliation></author>
      <pages>365-373</pages>
      <abstract>Large language models have become integral to question-answering applications despite their propensity for generating hallucinations and factually inaccurate content. Querying knowledge graphs to reduce hallucinations in LLM meets the challenge of incomplete knowledge coverage in knowledge graphs. On the other hand, updating knowledge graphs by information extraction and knowledge graph completion faces the knowledge update misalignment issue. In this work, we introduce a collaborative augmentation framework, CogMG, leveraging knowledge graphs to address the limitations of LLMs in QA scenarios, explicitly targeting the problems of incomplete knowledge coverage and knowledge update misalignment. The LLMs identify and decompose required knowledge triples that are not present in the KG, enriching them and aligning updates with real-world demands. We demonstrate the efficacy of this approach through a supervised fine-tuned LLM within an agent framework, showing significant improvements in reducing hallucinations and enhancing factual accuracy in QA responses. Our code and video are publicly available.</abstract>
      <url hash="cc0e3625">2024.acl-demos.35</url>
    </paper>
    <paper id="36">
      <title><fixed-case>ELLA</fixed-case>: Empowering <fixed-case>LLM</fixed-case>s for Interpretable, Accurate and Informative Legal Advice</title>
      <author><first>Yutong</first><last>Hu</last></author>
      <author><first>Kangcheng</first><last>Luo</last><affiliation>Peking University</affiliation></author>
      <author><first>Yansong</first><last>Feng</last><affiliation>Peking University</affiliation></author>
      <pages>374-387</pages>
      <abstract>Despite remarkable performance in legal consultation exhibited by legal Large Language Models(LLMs) combined with legal article retrieval components, there are still cases when the advice given is incorrect or baseless. To alleviate these problems, we propose <b>ELLA</b>, a tool for <b>E</b>mpowering <b>L</b>LMs for interpretable, accurate, and informative <b>L</b>egal <b>A</b>dvice. ELLA visually presents the correlation between legal articles and LLM’s response by calculating their similarities, providing users with an intuitive legal basis for the responses. Besides, based on the users’ queries, ELLA retrieves relevant legal articles and displays them to users. Users can interactively select legal articles for LLM to generate more accurate responses. ELLA also retrieves relevant legal cases for user reference. Our user study shows that presenting the legal basis for the response helps users understand better. The accuracy of LLM’s responses also improves when users intervene in selecting legal articles for LLM. Providing relevant legal cases also aids individuals in obtaining comprehensive information. Our github repo is: <url>https://github.com/Huyt00/ELLA</url>.</abstract>
      <url hash="b2d5717d">2024.acl-demos.36</url>
    </paper>
    <paper id="37">
      <title><fixed-case>LLMB</fixed-case>ox: A Comprehensive Library for Large Language Models</title>
      <author><first>Tianyi</first><last>Tang</last></author>
      <author><first>Hu</first><last>Yiwen</last></author>
      <author><first>Bingqian</first><last>Li</last></author>
      <author><first>Wenyang</first><last>Luo</last></author>
      <author><first>ZiJing</first><last>Qin</last></author>
      <author><first>Haoxiang</first><last>Sun</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Jiapeng</first><last>Wang</last></author>
      <author><first>Shiyi</first><last>Xu</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Xiaoxue</first><last>Cheng</last></author>
      <author><first>Geyang</first><last>Guo</last><affiliation>Georgia Institute of Technology</affiliation></author>
      <author><first>Han</first><last>Peng</last></author>
      <author><first>Bowen</first><last>Zheng</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Yiru</first><last>Tang</last></author>
      <author><first>Yingqian</first><last>Min</last></author>
      <author><first>Yushuo</first><last>Chen</last></author>
      <author><first>Jie</first><last>Chen</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Ranchi</first><last>Zhao</last><affiliation>ModelBest</affiliation></author>
      <author><first>Luran</first><last>Ding</last></author>
      <author><first>Yuhao</first><last>Wang</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Zican</first><last>Dong</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Xia</first><last>Chunxuan</last></author>
      <author><first>Junyi</first><last>Li</last></author>
      <author><first>Kun</first><last>Zhou</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Xin</first><last>Zhao</last><affiliation>Renmin University of China</affiliation></author>
      <author><first>Ji-Rong</first><last>Wen</last><affiliation>Renmin University of China</affiliation></author>
      <pages>388-399</pages>
      <abstract>To facilitate the research on large language models (LLMs), this paper presents a comprehensive and unified library, LLMBox, to ease the development, use, and evaluation of LLMs. This library is featured with three main merits: (1) a unified data interface that supports the flexible implementation of various training strategies, (2) a comprehensive evaluation that covers extensive tasks, datasets, and models, and (3) more practical consideration, especially on user-friendliness and efficiency. With our library, users can easily reproduce existing methods, train new models, and conduct comprehensive performance comparisons. To rigorously test LLMBox, we conduct extensive experiments in a diverse coverage of evaluation settings, and experimental results demonstrate the effectiveness and efficiency of our library in supporting various implementations related to LLMs. The detailed introduction and usage guidance can be found at <url>https://github.com/RUCAIBox/LLMBox</url>.</abstract>
      <url hash="1ad071d1">2024.acl-demos.37</url>
    </paper>
    <paper id="38">
      <title><fixed-case>L</fixed-case>lama<fixed-case>F</fixed-case>actory: Unified Efficient Fine-Tuning of 100+ Language Models</title>
      <author><first>Yaowei</first><last>Zheng</last></author>
      <author><first>Richong</first><last>Zhang</last></author>
      <author><first>Junhao</first><last>Zhang</last></author>
      <author><first>YeYanhan</first><last>YeYanhan</last></author>
      <author><first>Zheyan</first><last>Luo</last></author>
      <pages>400-410</pages>
      <abstract>Efficient fine-tuning is vital for adapting large language models (LLMs) to downstream tasks. However, it requires non-trivial efforts to implement these methods on different models. We present LlamaFactory, a unified framework that integrates a suite of cutting-edge efficient training methods. It provides a solution for flexibly customizing the fine-tuning of 100+ LLMs without the need for coding through the built-in web UI LlamaBoard. We empirically validate the efficiency and effectiveness of our framework on language modeling and text generation tasks. It has been released at https://github.com/hiyouga/LLaMA-Factory and received over 25,000 stars and 3,000 forks.</abstract>
      <url hash="5a5b0cc0">2024.acl-demos.38</url>
    </paper>
  </volume>
  <event id="acl-2023">
    <colocated>
      <volume-id>2024.alvr-1</volume-id>
      <volume-id>2024.arabicnlp-1</volume-id>
      <volume-id>2024.argmining-1</volume-id>
      <volume-id>2024.bionlp-1</volume-id>
      <volume-id>2024.c3nlp-1</volume-id>
      <volume-id>2024.climatenlp-1</volume-id>
      <volume-id>2024.cmcl-1</volume-id>
      <volume-id>2024.conda-1</volume-id>
      <volume-id>2024.fieldmatters-1</volume-id>
      <volume-id>2024.gebnlp-1</volume-id>
      <volume-id>2024.hucllm-1</volume-id>
      <volume-id>2024.iwslt-1</volume-id>
      <volume-id>2024.kallm-1</volume-id>
      <volume-id>2024.knowledgenlp-1</volume-id>
      <volume-id>2024.knowllm-1</volume-id>
      <volume-id>2024.langmol-1</volume-id>
      <volume-id>2024.lchange-1</volume-id>
      <volume-id>2024.loresmt-1</volume-id>
      <volume-id>2024.ml4al-1</volume-id>
      <volume-id>2024.nlp4convai-1</volume-id>
      <volume-id>2024.nlrse-1</volume-id>
      <volume-id>2024.privatenlp-1</volume-id>
      <volume-id>2024.repl4nlp-1</volume-id>
      <volume-id>2024.sdp-1</volume-id>
      <volume-id>2024.sighan-1</volume-id>
      <volume-id>2024.sigturk-1</volume-id>
      <volume-id>2024.smm4h-1</volume-id>
      <volume-id>2024.splurobonlp-1</volume-id>
      <volume-id>2024.teachingnlp-1</volume-id>
      <volume-id>2024.textgraphs-1</volume-id>
      <volume-id>2024.wassa-1</volume-id>
    </colocated>
  </event>
</collection>
