<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.dstc">
  <volume id="1" ingest-date="2025-09-27" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Twelfth Dialog System Technology Challenge (DSTC12)</booktitle>
      <editor><first>Behnam</first><last>Hedayatnia</last><affiliation>Apple</affiliation></editor>
      <editor><first>Vivian</first><last>Chen</last><affiliation>National Taiwan University</affiliation></editor>
      <editor><first>Zhang</first><last>Chen</last><affiliation>National Taiwan University, Taiwan</affiliation></editor>
      <editor><first>Raghav</first><last>Gupta</last><affiliation>Google</affiliation></editor>
      <editor><first>Michel</first><last>Galley</last><affiliation>Microsoft</affiliation></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Avignon, France</address>
      <month>August</month>
      <year>2025</year>
      <url hash="be5178a1">2025.dstc-1</url>
      <venue>dstc</venue>
      <venue>ws</venue>
      <isbn>979-8-89176-330-2</isbn>
    </meta>
    <frontmatter>
      <url hash="ea33d0fa">2025.dstc-1.0</url>
      <bibkey>dstc-ws-2025-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Neural Models and Language Model Prompting for the Multidimensional Evaluation of Open-Ended Conversations</title>
      <author><first>Michelle</first><last>Elizabeth</last></author>
      <author><first>Alicja</first><last>Kasicka</last><affiliation>Orange Innovation Poland</affiliation></author>
      <author orcid="0009-0004-7442-2123"><first>Natalia</first><last>Krawczyk</last><affiliation>Orange-labs</affiliation></author>
      <author><first>Magalie</first><last>Ochs</last><affiliation>Université d’Aix-Marseille</affiliation></author>
      <author><first>Gwénolé</first><last>Lecorvé</last><affiliation>Orange</affiliation></author>
      <author><first>Justyna</first><last>Gromada</last><affiliation>Orange-labs</affiliation></author>
      <author><first>Lina M.</first><last>Rojas-Barahona</last></author>
      <pages>1-16</pages>
      <abstract>The growing number of generative AI-based dialogue systems has made their evaluation a crucial challenge. This paper presents our contribution to this important problem through the Dialogue System Technology Challenge (DSTC-12, Track 1), where we developed models to predict dialogue-level, dimension-specific scores. Given the constraint of using relatively small models (i.e. fewer than 13 billion parameters) our work follows two main strategies: employing Language Models (LMs) as evaluators through prompting, and training encoder-based classification and regression models.Our results show that while LM prompting achieves only modest correlations with human judgments, it still ranks second on the test set, outperformed only by the baseline.The regression and classification models, with significantly fewer parameters, demonstrate high correlation for some dimensions on the validation set. Although their performance decreases on the test set, it is important to note that the test set contains annotations with significantly different score ranges for some of the dimensions with respect to the train and validation sets.</abstract>
      <url hash="746dc7ec">2025.dstc-1.1</url>
      <bibkey>elizabeth-etal-2025-neural</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>CATCH</fixed-case>: A Controllable Theme Detection Framework with Contextualized Clustering and Hierarchical Generation</title>
      <author><first>Rui</first><last>Ke</last></author>
      <author><first>Jiahui</first><last>Xu</last></author>
      <author><first>Kuang</first><last>Wang</last></author>
      <author><first>Shenghao</first><last>Yang</last></author>
      <author orcid="0000-0002-3465-311X"><first>Feng</first><last>Jiang</last><affiliation>Shenzhen University of Advanced Technology</affiliation></author>
      <author orcid="0000-0001-9158-9401"><first>Haizhou</first><last>Li</last><affiliation>The Chinese University of Hong Kong (Shenzhen); National University of Singapore and National University of Singapore</affiliation></author>
      <pages>17-26</pages>
      <abstract>Theme detection is a fundamental task in user-centric dialogue systems, aiming to identify the latent topic of each utterance without relying on predefined schemas. Unlike intent induction, which operates within fixed label spaces, theme detection requires cross-dialogue consistency and alignment with personalized user preferences, posing significant challenges. Existing methods often struggle with sparse, short utterances and fail to capture user-level thematic preferences across dialogues. To address these challenges, we propose CATCH (Controllable Theme Detection with Contextualized Clustering and Hierarchical Generation), a unified framework that integrates three core components: (1) context-aware topic representation, which enriches utterance-level semantics using surrounding topic segments; (2) preference-guided topic clustering, which jointly models semantic proximity and personalized feedback to align themes across conversations; and (3) a hierarchical theme generation mechanism designed to suppress noise and produce robust, coherent topic labels. Experiments on a multi-domain customer dialogue benchmark demonstrate that CATCH achieves state-of-the-art performance in both theme classification and topic distribution quality. Notably, it ranked second in the official blind evaluation of the DSTC-12 Controllable Theme Detection Track, showcasing its effectiveness and generalizability in real-world dialogue systems.</abstract>
      <url hash="b55e1762">2025.dstc-1.2</url>
      <bibkey>ke-etal-2025-catch</bibkey>
    </paper>
    <paper id="3">
      <title>Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at <fixed-case>DSTC</fixed-case> 12</title>
      <author orcid="0000-0002-4865-6290"><first>John</first><last>Mendonça</last><affiliation>Instituto Superior Técnico</affiliation></author>
      <author><first>Lining</first><last>Zhang</last></author>
      <author><first>Rahul</first><last>Mallidi</last></author>
      <author orcid="0000-0001-9934-6519"><first>Alon</first><last>Lavie</last><affiliation>Phrase and School of Computer Science, Carnegie Mellon University</affiliation></author>
      <author orcid="0000-0001-5874-6313"><first>Isabel</first><last>Trancoso</last><affiliation>Instituto Superior Técnico</affiliation></author>
      <author orcid="0000-0002-3411-7384"><first>Luis Fernando</first><last>D’Haro</last><affiliation>Universidad Politécnica de Madrid</affiliation></author>
      <author><first>João</first><last>Sedoc</last><affiliation>New York University</affiliation></author>
      <pages>27-35</pages>
      <abstract>The rapid advancement of Large Language Models (LLMs) has intensified the need for robust dialogue system evaluation, yet comprehensive assessment remains challenging. Traditional metrics often prove insufficient, and safety considerations are frequently narrowly defined or culturally biased. The DSTC12 Track 1, “Dialog System Evaluation: Dimensionality, Language, Culture and Safety,” is part of the ongoing effort to address these critical gaps. The track comprised two subtasks: (1) Dialogue-level, Multi-dimensional Automatic Evaluation Metrics, and (2) Multilingual and Multicultural Safety Detection. For Task 1, focused on 10 dialogue dimensions, a Llama-3-8B baseline achieved the highest average Spearman’s correlation (0.1681), indicating substantial room for improvement. In Task 2, while participating teams significantly outperformed a Llama-Guard-3-1B baseline on the multilingual safety subset (top ROC-AUC 0.9648), the baseline proved superior on the cultural subset (0.5126 ROC-AUC), highlighting critical needs in culturally-aware safety. This paper describes the datasets and baselines provided to participants, as well as submission evaluation results for each of the two proposed subtasks.</abstract>
      <url hash="1f8bb879">2025.dstc-1.3</url>
      <bibkey>mendonca-etal-2025-overview</bibkey>
    </paper>
    <paper id="4">
      <title>The Limits of Post-hoc Preference Adaptation: A Case Study on <fixed-case>DSTC</fixed-case>12 Clustering</title>
      <author><first>Jihyun</first><last>Lee</last></author>
      <author><first>Gary</first><last>Lee</last></author>
      <pages>36-43</pages>
      <abstract>Understanding user intent in dialogue is essential for controllable and coherent conversational AI. In this work, we present a case study on controllable theme induction in dialogue systems using the DSTC12 Track 2 dataset. Our pipeline integrates LLM-based summarization, utterance clustering, and synthetic preference modeling based on should-link and cannot-link predictions. While preference signals offer moderate improvements in cluster refinement, we observe that their effectiveness is significantly constrained by coarse initial clustering. Experiments on the Finance and Insurance domains show that even authentic human labeled preference struggle when initial clusters do not align with human intent. These findings highlight the need to incorporate preference supervision earlier in the pipeline to ensure semantically coherent clustering.</abstract>
      <url hash="b3faab8c">2025.dstc-1.4</url>
      <bibkey>lee-lee-2025-limits</bibkey>
    </paper>
    <paper id="5">
      <title><fixed-case>KSTC</fixed-case>: Keyphrase-driven Sentence embedding and Task independent prompting for filling slot in the Generation of theme label</title>
      <author orcid="0009-0002-6400-3158"><first>Sua</first><last>Kim</last></author>
      <author><first>Taeyoung</first><last>Jeong</last><affiliation>Sogang University</affiliation></author>
      <author><first>Seokyoung</first><last>Hong</last></author>
      <author><first>Seongjun</first><last>Kim</last></author>
      <author><first>Jeongpil</first><last>Lee</last></author>
      <author orcid="0000-0001-6692-962X"><first>Du-Seong</first><last>Chang</last><affiliation>Sogang University</affiliation></author>
      <author><first>Myoung-Wan</first><last>Koo</last><affiliation>Sogang University</affiliation></author>
      <pages>44-73</pages>
      <abstract>Intent discovery in task-oriented dialogue is typically cast as single-turn intent classification, leaving systems brittle when user goals fall outside predefined inventories. We reformulate the task as multi-turn zero-shot intent discovery and present KSTC, a framework that (i) embeds dialogue contexts, (ii) performs coarse clustering, (iii) generates predicted theme label for each cluster, (iv) refines clusters using the Large Language Model (LLM) using predicted theme label, and (v) relocates utterances according to user’s preference. Because generating informative predicted theme label is crucial during the LLM-driven cluster refinement process, we propose the Task Independent Slots (TIS), which generates effective theme label by extracting verb and noun slot–value.Evaluated on DSTC12 Track2 dataset, KSTC took the first place, improving clustering and labeling quality without in-domain supervision. Results show that leveraging conversational context and slot-guided LLM labeling yields domain-agnostic theme clusters that remain consistent under distributional shift. KSTC thus offers a scalable, label-free solution for real-world dialogue systems that must continuously surface novel user intents. We will release our code and prompts publicly.</abstract>
      <url hash="06c89b93">2025.dstc-1.5</url>
      <bibkey>kim-etal-2025-kstc</bibkey>
    </paper>
    <paper id="6">
      <title>Controllable Conversational Theme Detection Track at <fixed-case>DSTC</fixed-case> 12</title>
      <author orcid="0000-0001-9664-1774"><first>Igor</first><last>Shalyminov</last><affiliation>Amazon</affiliation></author>
      <author><first>Hang</first><last>Su</last><affiliation>Amazon</affiliation></author>
      <author orcid="0000-0002-4794-4370"><first>Jake W.</first><last>Vincent</last><affiliation>Amazon</affiliation></author>
      <author><first>Siffi</first><last>Singh</last></author>
      <author><first>Jason</first><last>Cai</last><affiliation>Amazon</affiliation></author>
      <author><first>James</first><last>Gung</last><affiliation>AWS AI Labs</affiliation></author>
      <author><first>Raphael</first><last>Shu</last><affiliation>Amazon</affiliation></author>
      <author><first>Saab</first><last>Mansour</last><affiliation>Amazon</affiliation></author>
      <pages>74-90</pages>
      <abstract>Conversational analytics has been on the forefront of transformation driven by the advances in Speech and Natural Language Processing techniques. Rapid adoption of Large Language Models (LLMs) in the analytics field has taken the problems that can be automated to a new level of complexity and scale.In this paper, we introduce Theme Detection as a critical task in conversational analytics, aimed at automatically identifying and categorizing topics within conversations. This process can significantly reduce the manual effort involved in analyzing expansive dialogs, particularly in domains like customer support or sales. Unlike traditional dialog intent detection, which often relies on a fixed set of intents for downstream system logic, themes are intended as a direct, user-facing summary of the conversation’s core inquiry. This distinction allows for greater flexibility in theme surface forms and user-specific customizations.We pose Controllable Conversational Theme Detection problem as a public competition track at Dialog System Technology Challenge (DSTC) 12 — it is framed as joint clustering and theme labeling of dialog utterances, with the distinctive aspect being controllability of the resulting theme clusters’ granularity achieved via the provided user preference data.We give an overview of the problem, the associated dataset and the evaluation metrics, both automatic and human. Finally, we discuss the participant teams’ submissions and provide insights from those. The track materials (data and code) are openly available in the GitHub repository.</abstract>
      <url hash="3ebab303">2025.dstc-1.6</url>
      <bibkey>shalyminov-etal-2025-controllable</bibkey>
    </paper>
  </volume>
</collection>
