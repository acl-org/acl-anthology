<?xml version='1.0' encoding='UTF-8'?>
<collection id="2023.crac">
  <volume id="main" ingest-date="2023-12-06" type="proceedings">
    <meta>
      <booktitle>Proceedings of The Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023)</booktitle>
      <editor><first>Maciej</first><last>Ogrodniczuk</last></editor>
      <editor><first>Vincent</first><last>Ng</last></editor>
      <editor><first>Sameer</first><last>Pradhan</last></editor>
      <editor><first>Massimo</first><last>Poesio</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Singapore</address>
      <month>December</month>
      <year>2023</year>
      <url hash="5fc7482f">2023.crac-main</url>
      <venue>crac</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="9e54f05e">2023.crac-main.0</url>
      <bibkey>crac-2023-models</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Filling in the Gaps: Efficient Event Coreference Resolution using Graph Autoencoder Networks</title>
      <author><first>Loic</first><last>De Langhe</last></author>
      <author><first>Orphee</first><last>De Clercq</last></author>
      <author><first>Veronique</first><last>Hoste</last></author>
      <pages>1–7</pages>
      <url hash="2d278a0a">2023.crac-main.1</url>
      <bibkey>de-langhe-etal-2023-filling</bibkey>
      <doi>10.18653/v1/2023.crac-main.1</doi>
    </paper>
    <paper id="2">
      <title><fixed-case>CAW</fixed-case>-coref: Conjunction-Aware Word-level Coreference Resolution</title>
      <author><first>Karel</first><last>D’Oosterlinck</last></author>
      <author><first>Semere Kiros</first><last>Bitew</last></author>
      <author><first>Brandon</first><last>Papineau</last></author>
      <author><first>Christopher</first><last>Potts</last></author>
      <author><first>Thomas</first><last>Demeester</last></author>
      <author><first>Chris</first><last>Develder</last></author>
      <pages>8–14</pages>
      <url hash="0b05a1e4">2023.crac-main.2</url>
      <bibkey>doosterlinck-etal-2023-caw</bibkey>
      <doi>10.18653/v1/2023.crac-main.2</doi>
    </paper>
    <paper id="3">
      <title>Towards Transparency in Coreference Resolution: A Quantum-Inspired Approach</title>
      <author><first>Hadi</first><last>Wazni</last></author>
      <author><first>Mehrnoosh</first><last>Sadrzadeh</last></author>
      <pages>15–27</pages>
      <url hash="4da5af23">2023.crac-main.3</url>
      <bibkey>wazni-sadrzadeh-2023-towards</bibkey>
      <doi>10.18653/v1/2023.crac-main.3</doi>
    </paper>
    <paper id="4">
      <title>Scalar Anaphora: Annotating Degrees of Coreference in Text</title>
      <author><first>Bingyang</first><last>Ye</last></author>
      <author><first>Jingxuan</first><last>Tu</last></author>
      <author><first>James</first><last>Pustejovsky</last></author>
      <pages>28–38</pages>
      <url hash="49f1d399">2023.crac-main.4</url>
      <bibkey>ye-etal-2023-scalar</bibkey>
      <doi>10.18653/v1/2023.crac-main.4</doi>
    </paper>
    <paper id="5">
      <title>Better Handling Coreference Resolution in Aspect Level Sentiment Classification by Fine-Tuning Language Models</title>
      <author><first>Dhruv</first><last>Mullick</last></author>
      <author><first>Bilal</first><last>Ghanem</last></author>
      <author><first>Alona</first><last>Fyshe</last></author>
      <pages>39–47</pages>
      <url hash="83b93d10">2023.crac-main.5</url>
      <bibkey>mullick-etal-2023-better</bibkey>
      <doi>10.18653/v1/2023.crac-main.5</doi>
      <video href="2023.crac-main.5.mp4"/>
    </paper>
    <paper id="6">
      <title>The pragmatics of characters’ mental perspectives in pronominal reference resolution</title>
      <author><first>Tiana</first><last>Simovic</last></author>
      <author><first>Craig</first><last>Chambers</last></author>
      <pages>48–50</pages>
      <url hash="05afd127">2023.crac-main.6</url>
      <bibkey>simovic-chambers-2023-pragmatics</bibkey>
      <doi>10.18653/v1/2023.crac-main.6</doi>
      <video href="2023.crac-main.6.mp4"/>
    </paper>
    <paper id="7">
      <title><fixed-case>MARRS</fixed-case>: Multimodal Reference Resolution System</title>
      <author><first>Halim Cagri</first><last>Ates</last></author>
      <author><first>Shruti</first><last>Bhargava</last></author>
      <author><first>Site</first><last>Li</last></author>
      <author><first>Jiarui</first><last>Lu</last></author>
      <author><first>Siddhardha</first><last>Maddula</last></author>
      <author><first>Joel Ruben Antony</first><last>Moniz</last></author>
      <author><first>Anil Kumar</first><last>Nalamalapu</last></author>
      <author><first>Roman Hoang</first><last>Nguyen</last></author>
      <author><first>Melis</first><last>Ozyildirim</last></author>
      <author><first>Alkesh</first><last>Patel</last></author>
      <author><first>Dhivya</first><last>Piraviperumal</last></author>
      <author><first>Vincent</first><last>Renkens</last></author>
      <author><first>Ankit</first><last>Samal</last></author>
      <author><first>Thy</first><last>Tran</last></author>
      <author><first>Bo-Hsiang</first><last>Tseng</last></author>
      <author><first>Hong</first><last>Yu</last></author>
      <author><first>Yuan</first><last>Zhang</last></author>
      <author><first>Shirley</first><last>Zou</last></author>
      <pages>51–58</pages>
      <url hash="b0141ff4">2023.crac-main.7</url>
      <bibkey>ates-etal-2023-marrs</bibkey>
      <doi>10.18653/v1/2023.crac-main.7</doi>
    </paper>
    <paper id="8">
      <title>Towards Harmful Erotic Content Detection through Coreference-Driven Contextual Analysis</title>
      <author><first>Inez</first><last>Okulska</last></author>
      <author><first>Emilia</first><last>Wisnios</last></author>
      <pages>59–70</pages>
      <url hash="83f1b5a5">2023.crac-main.8</url>
      <bibkey>okulska-wisnios-2023-towards</bibkey>
      <doi>10.18653/v1/2023.crac-main.8</doi>
    </paper>
    <paper id="9">
      <title>Integrated Annotation of Event Structure, Object States, and Entity Coreference</title>
      <author><first>Kyeongmin</first><last>Rim</last></author>
      <author><first>James</first><last>Pustejovsky</last></author>
      <pages>71–77</pages>
      <url hash="501377da">2023.crac-main.9</url>
      <bibkey>rim-pustejovsky-2023-integrated</bibkey>
      <doi>10.18653/v1/2023.crac-main.9</doi>
    </paper>
  </volume>
  <volume id="sharedtask" ingest-date="2023-12-06" type="proceedings">
    <meta>
      <booktitle>Proceedings of the CRAC 2023 Shared Task on Multilingual Coreference Resolution</booktitle>
      <editor><first>Zdeněk</first><last>Žabokrtský</last></editor>
      <editor><first>Maciej</first><last>Ogrodniczuk</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Singapore</address>
      <month>December</month>
      <year>2023</year>
      <url hash="3b8ca183">2023.crac-sharedtask</url>
      <venue>crac</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="56ac2021">2023.crac-sharedtask.0</url>
      <bibkey>crac-2023-crac</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Findings of the Second Shared Task on Multilingual Coreference Resolution</title>
      <author><first>Zdeněk</first><last>Žabokrtský</last></author>
      <author><first>Miloslav</first><last>Konopik</last></author>
      <author><first>Anna</first><last>Nedoluzhko</last></author>
      <author><first>Michal</first><last>Novák</last></author>
      <author><first>Maciej</first><last>Ogrodniczuk</last></author>
      <author><first>Martin</first><last>Popel</last></author>
      <author><first>Ondrej</first><last>Prazak</last></author>
      <author><first>Jakub</first><last>Sido</last></author>
      <author><first>Daniel</first><last>Zeman</last></author>
      <pages>1–18</pages>
      <abstract>This paper summarizes the second edition of the shared task on multilingual coreference resolution, held with the CRAC 2023 workshop. Just like last year, participants of the shared task were to create trainable systems that detect mentions and group them based on identity coreference; however, this year’s edition uses a slightly different primary evaluation score, and is also broader in terms of covered languages: version 1.1 of the multilingual collection of harmonized coreference resources CorefUD was used as the source of training and evaluation data this time, with 17 datasets for 12 languages. 7 systems competed in this shared task.</abstract>
      <url hash="1913e31c">2023.crac-sharedtask.1</url>
      <bibkey>zabokrtsky-etal-2023-findings</bibkey>
      <doi>10.18653/v1/2023.crac-sharedtask.1</doi>
      <video href="2023.crac-sharedtask.1.mp4"/>
    </paper>
    <paper id="2">
      <title>Multilingual coreference resolution: Adapt and Generate</title>
      <author><first>Natalia</first><last>Skachkova</last></author>
      <author><first>Tatiana</first><last>Anikina</last></author>
      <author><first>Anna</first><last>Mokhova</last></author>
      <pages>19–33</pages>
      <abstract>The paper presents two multilingual coreference resolution systems submitted for the CRAC Shared Task 2023. The DFKI-Adapt system achieves 61.86 F1 score on the shared task test data, outperforming the official baseline by 4.9 F1 points. This system uses a combination of different features and training settings, including character embeddings, adapter modules, joint pre-training and loss-based re-training. We provide evaluation for each of the settings on 12 different datasets and compare the results. The other submission DFKI-MPrompt uses a novel approach that involves prompting for mention generation. Although the scores achieved by this model are lower compared to the baseline, the method shows a new way of approaching the coreference task and provides good results with just five epochs of training.</abstract>
      <url hash="ea9762c3">2023.crac-sharedtask.2</url>
      <bibkey>skachkova-etal-2023-multilingual</bibkey>
      <doi>10.18653/v1/2023.crac-sharedtask.2</doi>
      <video href="2023.crac-sharedtask.2.mp4"/>
    </paper>
    <paper id="3">
      <title>Neural End-to-End Coreference Resolution using Morphological Information</title>
      <author><first>Tuğba</first><last>Pamay Arslan</last></author>
      <author><first>Kutay</first><last>Acar</last></author>
      <author><first>Gülşen</first><last>Eryiğit</last></author>
      <pages>34–40</pages>
      <abstract>In morphologically rich languages, words consist of morphemes containing deeper information in morphology, and thus such languages may necessitate the use of morpheme-level representations as well as word representations. This study introduces a neural multilingual end-to-end coreference resolution system by incorporating morphological information in transformer-based word embeddings on the baseline model. This proposed model participated in the Sixth Workshop on Computational Models of Reference, Anaphora and Coreference (CRAC 2023). Including morphological information explicitly into the coreference resolution improves the performance, especially in morphologically rich languages (e.g., Catalan, Hungarian, and Turkish). The introduced model outperforms the baseline system by 2.57 percentage points on average by obtaining 59.53% CoNLL F-score.</abstract>
      <url hash="aaf6fb69">2023.crac-sharedtask.3</url>
      <bibkey>pamay-arslan-etal-2023-neural</bibkey>
      <doi>10.18653/v1/2023.crac-sharedtask.3</doi>
    </paper>
    <paper id="4">
      <title><fixed-case>ÚFAL</fixed-case> <fixed-case>C</fixed-case>or<fixed-case>P</fixed-case>ipe at <fixed-case>CRAC</fixed-case> 2023: Larger Context Improves Multilingual Coreference Resolution</title>
      <author><first>Milan</first><last>Straka</last></author>
      <pages>41–51</pages>
      <abstract>We present CorPipe, the winning entry to the CRAC 2023 Shared Task on Multilingual Coreference Resolution. Our system is an improved version of our earlier multilingual coreference pipeline, and it surpasses other participants by a large margin of 4.5 percent points. CorPipe first performs mention detection, followed by coreference linking via an antecedent-maximization approach on the retrieved spans. Both tasks are trained jointly on all available corpora using a shared pretrained language model. Our main improvements comprise inputs larger than 512 subwords and changing the mention decoding to support ensembling. The source code is available at https://github.com/ufal/crac2023-corpipe.</abstract>
      <url hash="656f20eb">2023.crac-sharedtask.4</url>
      <bibkey>straka-2023-ufal</bibkey>
      <doi>10.18653/v1/2023.crac-sharedtask.4</doi>
      <video href="2023.crac-sharedtask.4.mp4"/>
    </paper>
    <paper id="5">
      <title><fixed-case>M</fixed-case>c<fixed-case>G</fixed-case>ill at <fixed-case>CRAC</fixed-case> 2023: Multilingual Generalization of Entity-Ranking Coreference Resolution Models</title>
      <author><first>Ian</first><last>Porada</last></author>
      <author><first>Jackie Chi Kit</first><last>Cheung</last></author>
      <pages>52–57</pages>
      <abstract>Our submission to the CRAC 2023 shared task, described herein, is an adapted entity-ranking model jointly trained on all 17 datasets spanning 12 languages. Our model outperforms the shared task baselines by a difference in F1 score of +8.47, achieving an ultimate F1 score of 65.43 and fourth place in the shared task. We explore design decisions related to data preprocessing, the pretrained encoder, and data mixing.</abstract>
      <url hash="50ce88ff">2023.crac-sharedtask.5</url>
      <bibkey>porada-cheung-2023-mcgill</bibkey>
      <doi>10.18653/v1/2023.crac-sharedtask.5</doi>
    </paper>
  </volume>
</collection>
