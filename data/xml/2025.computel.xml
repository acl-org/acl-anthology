<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.computel">
  <volume id="main" ingest-date="2025-07-20" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Eight Workshop on the Use of Computational Methods in the Study of Endangered Languages</booktitle>
      <editor><first>Jordan</first><last>Lachler</last></editor>
      <editor><first>Godfred</first><last>Agyapong</last></editor>
      <editor><first>Antti</first><last>Arppe</last></editor>
      <editor><first>Sarah</first><last>Moeller</last></editor>
      <editor><first>Aditi</first><last>Chaudhary</last></editor>
      <editor><first>Shruti</first><last>Rijhwani</last></editor>
      <editor><first>Daisy</first><last>Rosenblum</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Honolulu, Hawaii, USA</address>
      <month>March</month>
      <year>2025</year>
      <url hash="b84f7b8d">2025.computel-main</url>
      <venue>computel</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="562098b1">2025.computel-main.0</url>
      <bibkey>computel-ws-2025-main</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Formalizing the Morphology of Rromani Adjectives</title>
      <author><first>Masako</first><last>Watabe</last></author>
      <author><first>Max</first><last>Silberztein</last></author>
      <pages>1-10</pages>
      <abstract>This paper presents a set of linguistic resources that formalizes the morphological behavior of simple Rromani adjectives. We describe the formalization of the adjectives’ morphology and the implementation with the NooJ linguistic platform of an electronic dictionary associated with a formal morpho-syntactic grammar. We can then apply this set of resources to a corpus to evaluate the resources and automatically annotate adjectival forms in Rromani texts. The final set of resources can then be used to identify each Rromani dialectal variant and can be used as a pedagogical tool to teach Rromani as a second language.</abstract>
      <url hash="f15c0d48">2025.computel-main.1</url>
      <bibkey>watabe-silberztein-2025-formalizing</bibkey>
    </paper>
    <paper id="2">
      <title>Bilingual Sentence Mining for Low-Resource Languages: a Case Study on Upper and <fixed-case>L</fixed-case>ower <fixed-case>S</fixed-case>orbian</title>
      <author><first>Shu</first><last>Okabe</last></author>
      <author><first>Alexander</first><last>Fraser</last></author>
      <pages>11-19</pages>
      <abstract>Parallel sentence mining is crucial for down- stream tasks such as Machine Translation, especially for low-resource languages, where such resources are scarce. In this context, we apply a pipeline approach with contextual embeddings on two endangered Slavic languages spoken in Germany, Upper and Lower Sorbian, to evaluate mining quality. To this end, we compare off-the-shelf multilingual language models and word encoders pre-trained on Upper Sorbian to understand their impact on sentence mining. Moreover, to filter out irrelevant pairs, we experiment with a post-processing of mined sentences through an unsupervised word aligner based on word embeddings. We observe the usefulness of additional pre-training in Upper Sorbian, which leads to direct improvements when mining the same language but also its related language, Lower Sorbian.</abstract>
      <url hash="ecd80365">2025.computel-main.2</url>
      <bibkey>okabe-fraser-2025-bilingual</bibkey>
    </paper>
    <paper id="3">
      <title>Citizen linguists and decolonial lexicography: Co-creative dictionary-building in grassroots digital language documentation</title>
      <author><first>Anna Luisa</first><last>Daigneault</last></author>
      <author><first>Gregory</first><last>Anderson</last></author>
      <pages>20-28</pages>
      <abstract>Many endangered, under-represented, minority and Indigenous language communities around the world need access to multilingual online resources to survive in the digital age. The Living Dictionaries platform provides a collaborative online space for professional linguists and citizen-linguists alike to produce their own grassroots digital dictionaries that include multimedia such as audio recordings and images. These online lexica can play an important role in assisting present and future generations in combatting language loss and creating visibility for their languages and cultures on the Internet.</abstract>
      <url hash="f106f171">2025.computel-main.3</url>
      <bibkey>daigneault-anderson-2025-citizen</bibkey>
    </paper>
    <paper id="4">
      <title>Supporting <fixed-case>SENĆOŦEN</fixed-case> Language Documentation Efforts with Automatic Speech Recognition</title>
      <author><first>Mengzhe</first><last>Geng</last></author>
      <author><first>Patrick</first><last>Littell</last></author>
      <author><first>Aidan</first><last>Pine</last></author>
      <author><first/><last>Penáć</last></author>
      <author><first>Marc</first><last>Tessier</last></author>
      <author><first>Roland</first><last>Kuhn</last></author>
      <pages>29-39</pages>
      <abstract>The SENĆOŦEN language, spoken on the Saanich peninsula of southern Vancouver Island, is in the midst of vigorous language revitalization efforts to turn the tide of language loss as a result of colonial language policies. To support these on-the-ground efforts, the community is turning to digital technology. Automatic Speech Recognition (ASR) technology holds great promise for accelerating language documentation and the creation of educational resources. However, developing ASR systems for SENCOTEN is challenging due to limited data and significant vocabulary variation from its polysynthetic structure and stress-driven metathesis. To address these challenges, we propose an ASR-driven documentation pipeline that leverages augmented speech data from a text-to-speech (TTS) system and cross-lingual transfer learning with Speech Foundation Models (SFMs). An n-gram language model is also incorporated via shallow fusion or n-best restoring to maximize the use of available data. Experiments on the SENCOTEN dataset show aword error rate (WER) of 19.34% and a character error rate (CER) of 5.09% on the test set with a 57.02% out-of-vocabulary (OOV) rate. After filtering minor cedilla-related errors,WER improves to 14.32% (26.48% on unseen words) and CER to 3.45%, demonstrating the potential of our ASR-driven pipeline to support SENCOTEN language documentation.</abstract>
      <url hash="5dcfe7f7">2025.computel-main.4</url>
      <bibkey>geng-etal-2025-supporting</bibkey>
    </paper>
    <paper id="5">
      <title>Speech Technologies with Fieldwork Recordings: the Case of <fixed-case>H</fixed-case>aitian <fixed-case>C</fixed-case>reole</title>
      <author><first>William N.</first><last>Havard</last></author>
      <author><first>Renauld</first><last>Govain</last></author>
      <author><first>Benjamin</first><last>Lecouteux</last></author>
      <author><first>Emmanuel</first><last>Schang</last></author>
      <pages>40-46</pages>
      <abstract>We use 40-year-old digitalised tape-recorded fieldwork data in Haitian Creole to train a native self-supervised learning (SSL) model of speech representation (WAV2VEC2). We also use a continued pre-training approach on pre-trained SSL models of two foreign languages: the lexifier language – French – and an unrelated language – English. We compare the performances of these three SSL models, and of two other foreign SSL models directly finetuned, on an ASR task, where all five models are fine-tuned on transcribed fieldwork recordings in Haitian Creole. Our results show the best-performing model is the one trained using a continued pre-training approach on the lexifier language, followed by the native model. We conclude that the ‘mobilising the archive’-approach advocated by (Bird, 2020) is a promising way forward to design speech technologies for new languages.</abstract>
      <url hash="3b59a849">2025.computel-main.5</url>
      <bibkey>havard-etal-2025-speech</bibkey>
    </paper>
    <paper id="6">
      <title>Evaluating Indigenous language speech synthesis for education: A participatory design workshop on <fixed-case>O</fixed-case>jibwe text-to-speech</title>
      <author><first>Viann Sum Yat</first><last>Chan</last></author>
      <author><first>Christopher</first><last>Hammerly</last></author>
      <pages>47-64</pages>
      <abstract>This paper reports methods and results from a participatory design workshop aimed at evaluating the use of speech synthesis and text-to-speech for Ojibwe language education. Using an existing text-to-speech feature as a starting point, we worked with two groups of Ojibwe language instructors using a guided trial of the speech synthesis system and a two hour semistructured workshop with the aim of creating a lesson plan that utilizes text-to-speech. We highlight the insights from this work, both in how to design and deliver speech synthesis systems for Indigenous language education, but also how to approach and design such a workshop to ensure a fruitful discourse.</abstract>
      <url hash="a3caf8e3">2025.computel-main.6</url>
      <bibkey>chan-hammerly-2025-evaluating</bibkey>
    </paper>
    <paper id="7">
      <title>Zero-Shot Query Generation for Approximate Search Algorithm Evaluation</title>
      <author><first>Aidan</first><last>Pine</last></author>
      <author><first>David</first><last>Huggins-Daines</last></author>
      <author><first>Carmen</first><last>Leeming</last></author>
      <author><first>Patrick</first><last>Littell</last></author>
      <author><first>Timothy</first><last>Montler</last></author>
      <author><first>Heather</first><last>Souter</last></author>
      <author><first>Mark</first><last>Turin</last></author>
      <pages>65-73</pages>
      <abstract>Approximate search is a valuable component of online dictionaries for learners, allowing them to find words even when they have not fully mastered the orthography or cannot reliably perceive phonemic differences in the language. However, evaluating the performance of different approximate search algorithms remains difficult in the absence of real user queries. We detail several methods for generating synthetic queries representing various user personas. We then compare the performance of several search algorithms on both real and synthetic queries in two Indigenous languages, SENĆOŦEN and Michif, that are phonologically and morphologically very different from English.</abstract>
      <url hash="7db38239">2025.computel-main.7</url>
      <bibkey>pine-etal-2025-zero</bibkey>
    </paper>
    <paper id="8">
      <title>Exploring Limitations and Risks of <fixed-case>LLM</fixed-case>-Based Grammatical Error Correction for Indigenous Languages</title>
      <author><first>Flammie A</first><last>Pirinen</last></author>
      <author><first>Linda</first><last>Wiechetek</last></author>
      <pages>74-81</pages>
      <abstract>Rule-based grammatical error correction has long been seen as the most effective way to create user-friendly end-user systems for gram- matical error correction (GEC). However, in the recent years the large language models and generative AI systems based on that technol- ogy have been progressed fast to challenge the traditional GEC approach. In this article we show which possibilities and limitations this approach bears for Indigenous languages that have more limited digital presence in the large language model data and a different literacy background than English. We show experi- ments in North Sámi, an Indigenous language of Northern Europe.</abstract>
      <url hash="d8312af8">2025.computel-main.8</url>
      <bibkey>pirinen-wiechetek-2025-exploring</bibkey>
    </paper>
    <paper id="9">
      <title>Speech Technologies Datasets for <fixed-case>A</fixed-case>frican Under-Served Languages</title>
      <author><first>Emmanuel</first><last>Ngue Um</last></author>
      <author><first>Francis</first><last>Tyers</last></author>
      <author><first>Eliette-Caroline Emilie</first><last>Ngo Tjomb</last></author>
      <author><first>Florus Landry</first><last>Dibengue</last></author>
      <author><first>Blaise-Mathieu</first><last>Banoum Manguele</last></author>
      <author><first>Blaise Abbo</first><last>Djoulde</last></author>
      <author><first>Mathilde</first><last>Nyambe A</last></author>
      <author><first>Brice Martial</first><last>Atangana Eloundou</last></author>
      <author><first>Jeff Sterling</first><last>Ngami Kamagoua</last></author>
      <author><first>José</first><last>Mpouda Avom</last></author>
      <author><first>Zacharie</first><last>Nyobe</last></author>
      <author><first>Emmanuel Giovanni</first><last>Eloundou Eyenga</last></author>
      <author><first>André</first><last>Likwai</last></author>
      <pages>82-90</pages>
      <abstract>The expansion of the speech technology sector has given rise to a novel economic model in language research, with the objective of developing speech datasets. This model is expanding to under-served African languages through collaborative efforts between industries, organisations, and the active participation of communities. This collaboration is yielding new datasets for machine learning, while also disclosing vulnerabilities and sociolinguistic discrepancies between industrialised and non-industrialised societies. A case study of a speech data collection camp that took place in September 2024 in Cameroon, involving representatives of 31 languages throughout the continent, illustrates both the prospects of the new economic model for research on under-served languages and the challenges of fair, effective, and responsible participation.</abstract>
      <url hash="93b299c7">2025.computel-main.9</url>
      <bibkey>ngue-um-etal-2025-speech</bibkey>
    </paper>
    <paper id="10">
      <title>Towards a Hän morphological transducer</title>
      <author><first>Maura</first><last>O’Leary</last></author>
      <author><first>Joseph</first><last>Lukner</last></author>
      <author><first>Finn</first><last>Verdonk</last></author>
      <author><first>Willem</first><last>de Reuse</last></author>
      <author><first>Jonathan</first><last>Washington</last></author>
      <pages>91-99</pages>
      <abstract>This paper presents work towards a morphological transducer for Hän, a Dene language spoken in Alaska and the Yukon Territory. We present the implementation of several complex morphological features of Dene languages into a morphological transducer, an evaluation of the transducer on corpus data, and a discussion of the future uses of such a transducer towards Hän revitalization efforts.</abstract>
      <url hash="637bc009">2025.computel-main.10</url>
      <bibkey>oleary-etal-2025-towards</bibkey>
    </paper>
    <paper id="11">
      <title>Multilingual <fixed-case>MFA</fixed-case>: Forced Alignment on Low-Resource Related Languages</title>
      <author><first>Alessio</first><last>Tosolini</last></author>
      <author><first>Claire</first><last>Bowern</last></author>
      <pages>100-109</pages>
      <abstract>We compare the outcomes of multilingual and crosslingual training for related and unrelated Australian languages with similar phonologi- cal inventories. We use the Montreal Forced Aligner to train acoustic models from scratch and adapt a large English model, evaluating results against seen data, unseen data (seen lan- guage), and unseen data and language. Results indicate benefits of adapting the English base- line model for previously unseen languages.</abstract>
      <url hash="86b8895d">2025.computel-main.11</url>
      <bibkey>tosolini-bowern-2025-multilingual</bibkey>
    </paper>
    <paper id="12">
      <title>Creating an intelligent dictionary of Tsuut’ina one verb at a time</title>
      <author><first>Christopher</first><last>Cox</last></author>
      <author><first>Bruce</first><last>Starlight</last></author>
      <author><first>Janelle</first><last>Crane-Starlight</last></author>
      <author><first>Hanna</first><last>Big Crow</last></author>
      <author><first>Antti</first><last>Arppe</last></author>
      <pages>110-119</pages>
      <abstract>In this paper, we discuss the development of a long-term partnership between community and university-based language workers to create supportive language technologies for Tsuutina, a critically endangered Dene language spoken in southern Alberta, Canada. Initial development activities in this partnership sought to rapidly integrate existing language materials, with the aim of arriving at tools that would be effective and impactful for community use by virtue of their extensive lexical coverage. We describe how, as this partnership developed, this approach was gradually superseded by one that involved a more targeted, lexical-item-by-lexical-item review process that was directly informed by other community language priorities and connected to the work a local language authority. We describe how this shift in processes correlated with other changes in local language programs and priorities, noting how ongoing communication allowed this partnership to adapt to the evolving needs of local organizations.</abstract>
      <url hash="db29dc5c">2025.computel-main.12</url>
      <bibkey>cox-etal-2025-creating</bibkey>
    </paper>
    <paper id="13">
      <title><fixed-case>AILLA</fixed-case>-<fixed-case>OCR</fixed-case>: A First Textual and Structural Post-<fixed-case>OCR</fixed-case> Dataset for 8 Indigenous Languages of <fixed-case>L</fixed-case>atin <fixed-case>A</fixed-case>merica</title>
      <author><first>Milind</first><last>Agarwal</last></author>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <pages>120-127</pages>
      <abstract>It is by now common knowledge in the NLP community that low-resource languages need large-scale data creation efforts and novel con- tributions in the form of robust algorithms that work in data-scarce settings. Amongst these languages, however, many have a large amount of data, ripe for NLP applications, except that this data exists in image-based formats. This includes scanned copies of extremely valuable dictionaries, linguistic field notes, children’s stories, plays, and other textual material. To extract the text data from these non machine- readable images, Optical Character Recogni- tion (OCR) is the most popular technique, but it has proven to be challenging for low-resource languages because of their unique properties (uncommon diacritics, rare words etc.) and due to a general lack of preserved page-structure in the OCR output. So, to contribute to the reduc- tion of these two big bottlenecks (lack of text data and layout quality), we release the first textual and structural OCR dataset for 8 indige- nous languages of Latin America. We hope that our dataset will encourage researchers within the NLP and Computational Linguistics com- munities to work with these languages.</abstract>
      <url hash="92d68aa9">2025.computel-main.13</url>
      <bibkey>agarwal-anastasopoulos-2025-ailla</bibkey>
    </paper>
    <paper id="14">
      <title>Connecting Automated Speech Recognition to Transcription Practices</title>
      <author><first>Blaine</first><last>Billings</last></author>
      <author><first>Bradley</first><last>McDonnell</last></author>
      <pages>128-132</pages>
      <abstract>One of the greatest issues facing documentary linguists is the transcription bottleneck. While the large quantity of audio and video data gener- ated as part of a documentary project serves as a long-lasting record of the language, without corresponding text transcriptions, it remains largely inaccessible for revitalization efforts and linguistic analysis. Automated Speech Recognition (ASR) is frequently proposed as the solution to this problem. However, two is- sues often prevent documentary linguists from making use of ASR models: 1) the thought that the typical documentary project does not have sufficient data to develop an adequate ASR model and 2) that correcting the output of an ASR model would be more time-consuming for transcribers than simply creating a transcription from scratch. In this paper, we tackle both of these issues by developing an ASR model in the larger context of a documentation project for Nasal, a low-resource language of western Indonesia. Fine-tuning a larger pre-trained lan- guage model on 25 hours of transcribed Nasal speech, we produce a model that has a 44% word error rate. Despite this relatively high error rate, tests comparing speed of transcrib- ing from scratch and correcting ASR-generated transcripts show that the ASR model can sig- nificantly speed up the transcription process.</abstract>
      <url hash="ffe753c1">2025.computel-main.14</url>
      <bibkey>billings-mcdonnell-2025-connecting</bibkey>
    </paper>
    <paper id="15">
      <title>Developing a Mixed-Methods Pipeline for Community-Oriented Digitization of Kwak’wala Legacy Texts</title>
      <author><first>Milind</first><last>Agarwal</last></author>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <author><first>Daisy</first><last>Rosenblum</last></author>
      <pages>133-138</pages>
      <abstract>Kwak’wala is an Indigenous language spoken in British Columbia, with a rich legacy of pub- lished documentation spanning more than a century, and an active community of speakers, teachers, and learners engaged in language revi- talization. Over 11 volumes of the earliest texts created during the collaboration between Franz Boas and George Hunt have been scanned but remain unreadable by machines. Complete dig- itization through optical character recognition has the potential to facilitate transliteration into modern orthographies and the creation of other language technologies. In this paper, we ap- ply the latest OCR techniques to a series of Kwak’wala texts only accessible as images, and discuss the challenges and unique adaptations necessary to make such technologies work for these real-world texts. Building on previous methods, we propose using a mix of off-the- shelf OCR methods, language identification, and masking to effectively isolate Kwak’wala text, along with post-correction models, to pro- duce a final high-quality transcription.</abstract>
      <url hash="05f4e18c">2025.computel-main.15</url>
      <bibkey>agarwal-etal-2025-developing</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>AI</fixed-case> for Interlinearization and <fixed-case>POS</fixed-case>-tagging: Teaching Linguists to Fish</title>
      <author><first>Olga</first><last>Kriukova</last></author>
      <author><first>Katherine</first><last>Schmirler</last></author>
      <author><first>Sarah</first><last>Moeller</last></author>
      <author><first>Olga</first><last>Lovick</last></author>
      <author><first>Inge</first><last>Genee</last></author>
      <author><first>Antti</first><last>Arppe</last></author>
      <author><first>Alexandra</first><last>Smith</last></author>
      <pages>139-149</pages>
      <abstract>This paper describes the process and learn- ing outcomes of a three-day workshop on ma- chine learning basics for documentary linguists. During this workshop, two groups of linguists working with two Indigenous languages of North America, Blackfoot and Dënë Su ̨łıné, became acquainted with machine learning prin- ciples, explored how machine learning can be used in data processing for under-resourced languages and then applied different machine learning methods for automatic morphologi- cal interlinearization and parts-of-speech tag- ging. As a result, participants discovered paths to greater collaboration between computer sci- ence and documentary linguistics and reflected on how linguists might be enabled to apply ma- chine learning with less dependence on experts.</abstract>
      <url hash="bce4493b">2025.computel-main.16</url>
      <bibkey>kriukova-etal-2025-ai</bibkey>
    </paper>
    <paper id="17">
      <title><fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies for <fixed-case>A</fixed-case>mahuaca</title>
      <author><first>Candy</first><last>Angulo</last></author>
      <author><first>Pilar</first><last>Valenzuela</last></author>
      <author><first>Roberto</first><last>Zariquiey</last></author>
      <pages>150-154</pages>
      <abstract>This paper presents the creation of a Universal Dependency (UD) treebank for Amahuaca (Peru), marking the first UD treebank within the Headwaters subbranch of the Panoan family, spoken mostly in Peru and Brazil. While the UD guidelines provided a general framework for our annotations, language-specific decisions were necessary due to the rich morphology of the Amahuaca language. The paper also describes specific constructions to initiate a discussion on several general UD annotation guidelines, particularly those concerning clitics and morpheme-level dependencies.</abstract>
      <url hash="c77943ac">2025.computel-main.17</url>
      <bibkey>angulo-etal-2025-universal</bibkey>
    </paper>
    <paper id="18">
      <title>Data augmentation for low-resource bilingual <fixed-case>ASR</fixed-case> from <fixed-case>T</fixed-case>ira linguistic elicitation using Whisper</title>
      <author><first>Mark</first><last>Simmons</last></author>
      <pages>155-161</pages>
      <abstract>This paper explores finetuning Whisper for transcribing audio from linguistic elicitation of Tira, a Heiban language of Sudan. Audio originates from linguistic fieldwork and is bilingual in English and Tira. We finetune Whisper large-v3 using hand-labeled Tira audio and evaluate the resulting model on bilingual audio. We show that Whisper exhibits catastrophic forgetting of English after only a small amount of training, but that including automatically annotated English spans of audio in the training data dramatically reduces catastrophic forgetting of English while largely preserving ASR performance on monolingual Tira audio. This work is relevant to the study of automatic speech recognition for under-resourced languages and for contexts of bilingualism in a high and low-resourced language.</abstract>
      <url hash="b8a9ec28">2025.computel-main.18</url>
      <bibkey>simmons-2025-data</bibkey>
    </paper>
    <paper id="19">
      <title>Integrating diverse corpora for training an endangered language machine translation system</title>
      <author><first>Hunter</first><last>Scheppat</last></author>
      <author><first>Joshua</first><last>Hartshorne</last></author>
      <author><first>Dylan</first><last>Leddy</last></author>
      <author><first>Eric</first><last>Le Ferrand</last></author>
      <author><first>Emily</first><last>Prudhommeaux</last></author>
      <pages>162-169</pages>
      <abstract>Machine translation (MT) can be a useful technology for language documentation and for promoting language use in endangered language communities. Few endangered languages, however, have an existing parallel corpus large enough to train a reasonable MT model. In this paper, we re-purpose a wide range of diverse data sources containing Amis, English, and Mandarin text to serve as parallel corpora for training MT systems for Amis, one of the Indigenous languages of Taiwan. To supplement the small amount of Amis-English data, we produce synthetic Amis-English data by using a high quality MT system to generate English translations for the Mandarin side of the Amis-Mandarin corpus. Using two popular neural MT systems, OpenNMT and NLLB, we train models to translate between English and Amis, and Mandarin and Amis. We find that including synthetic data is helpful only when translating to English. In addition, we observe that neither MT architecture is consistently superior to other and that performance seems to vary according to the direction of translation and the amount of data used. These results indicate that MT is possible for an under-resourced language even without a formally prepared parallel corpus, but multiple training methods should be explored to produce optimal results.</abstract>
      <url hash="9196e7b1">2025.computel-main.19</url>
      <bibkey>scheppat-etal-2025-integrating</bibkey>
    </paper>
    <paper id="20">
      <title>Comparing efficacy of <fixed-case>IPA</fixed-case> vs <fixed-case>P</fixed-case>inyin romanisation transcriptions for complex tonal languages: A case study in <fixed-case>B</fixed-case>aima</title>
      <author><first>Katia</first><last>Chirkova</last></author>
      <author><first>Rolando</first><last>Coto-Solano</last></author>
      <author><first>Rachael</first><last>Griffiths</last></author>
      <author><first>Marieke</first><last>Meelen</last></author>
      <pages>170-181</pages>
      <abstract>How is automated tone transcription affected by the choice of transcription orthography? In this paper we present a range of experiments that indicate that, even when the tonal repre- sentations are kept the same, the way vowels and consonants are transcribed can affect tonal character outputs. Our results also indicate that using a Language Model (LM) for decoding can mitigate problems with tonal outputs, but tones remain the most difficult part of the tran- scription. In doing this we also present the first Automatic Speech Recognition (ASR) models for the Baima language, spoken in Sichuan and Gansu, China. We hope to use these models to contribute to ongoing documentation efforts.</abstract>
      <url hash="6c8b1220">2025.computel-main.20</url>
      <bibkey>chirkova-etal-2025-comparing</bibkey>
    </paper>
    <paper id="21">
      <title>Kuene: A Web Platform for Facilitating <fixed-case>H</fixed-case>awaiian Word Neologism</title>
      <author><first>Sunny</first><last>Walker</last></author>
      <author><first>Winston</first><last>Wu</last></author>
      <author><first>Bruce</first><last>Torres Fischer</last></author>
      <author><first>Larry</first><last>Kimura</last></author>
      <pages>182-187</pages>
      <abstract>This paper presents Kuene, a web-based collaborative dictionary editing platform designed to facilitate the creation and publication of Hawaiian neologisms by the Hawaiian Lexicon Committee. Through Kuene, the Committee can create, edit, and refine new dictionary entries with a multi-round approval process, ensuring accuracy and consistency. The platform’s tech- nical features enable flexible access control, fine-grained approval states, and support for multimedia content and AI-assisted orthogra- phy modernization. Just in the past two months, Kuene has enabled the publication of over 400 new Hawaiian words. By streamlining the dic- tionary editing process, Kuene aims to alleviate the scarcity of modern Hawaiian words and fa- cilitate the revitalization efforts of the Hawaiian</abstract>
      <url hash="3a6e5697">2025.computel-main.21</url>
      <bibkey>walker-etal-2025-kuene</bibkey>
    </paper>
    <paper id="22">
      <title>Evaluation of Morphological Segmentation Methods for <fixed-case>H</fixed-case>upa</title>
      <author><first>Nathaniel</first><last>Parkes</last></author>
      <author><first>Zoey</first><last>Liu</last></author>
      <pages>188-193</pages>
      <abstract>Building downstream NLP applications with tokenization systems built on morphological segmentation has been shown to be fruitful for certain morphologically-rich languages. Yet, indigenous and endangered languages, which tend to be highly polysynthetic, thereby a po- tential beneficiary of this approach, pose ad- ditional difficulties in their limited access to annotated data for morphological segmenta- tion tasks. In this study, we develop mor- phological segmentation models for Hupa, a Dene/Athabaskan language critically endan- gered to North America. With a total of 595 word types, we seek to identify an optimal mor- phological segmentation model and illustrate how those tested perform under different levels of training data limitation. We propose a simple method that casts morphological segmentation as a sequence binary classification task. While this approach does not outperform the estab- lished practice of multi-class classification, it outperforms neural alternatives. This work is conducted under the intention to act as a start- ing point for future technological developments with Hupa looking to leverage its morpholog- ical qualities, which we hope can serve as a reflection for work with other indigenous lan- guages being studied under similar constraints.</abstract>
      <url hash="1b511f2e">2025.computel-main.22</url>
      <bibkey>parkes-liu-2025-evaluation</bibkey>
    </paper>
  </volume>
</collection>
