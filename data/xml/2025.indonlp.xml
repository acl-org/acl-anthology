<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.indonlp">
  <volume id="1" ingest-date="2025-01-24" type="proceedings">
    <meta>
      <booktitle>Proceedings of the First Workshop on Natural Language Processing for Indo-Aryan and Dravidian Languages</booktitle>
      <editor><first>Ruvan</first><last>Weerasinghe</last></editor>
      <editor><first>Isuri</first><last>Anuradha</last></editor>
      <editor><first>Deshan</first><last>Sumanathilaka</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Abu Dhabi</address>
      <month>January</month>
      <year>2025</year>
      <url hash="d3024667">2025.indonlp-1</url>
      <venue>indonlp</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="f4b48186">2025.indonlp-1.0</url>
      <bibkey>indonlp-ws-2025-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>H</fixed-case>indi Reading Comprehension: Do Large Language Models Exhibit Semantic Understanding?</title>
      <author><first>Daisy Monika</first><last>Lal</last></author>
      <author><first>Paul</first><last>Rayson</last></author>
      <author><first>Mo</first><last>El-Haj</last></author>
      <pages>1–10</pages>
      <abstract>In this study, we explore the performance of four advanced Generative AI models—GPT-3.5, GPT-4, Llama3, and HindiGPT, for the Hindi reading comprehension task. Using a zero-shot, instruction-based prompting strategy, we assess model responses through a comprehensive triple evaluation framework using the HindiRC dataset. Our framework combines (1) automatic evaluation using ROUGE, BLEU, BLEURT, METEOR, and Cosine Similarity; (2) rating-based assessments focussing on correctness, comprehension depth, and informativeness; and (3) preference-based selection to identify the best responses. Human ratings indicate that GPT-4 outperforms the other LLMs on all parameters, followed by HindiGPT, GPT-3.5, and then Llama3. Preference-based evaluation similarly placed GPT-4 (80%) as the best model, followed by HindiGPT(74%). However, automatic evaluation showed GPT-4 to be the lowest performer on n-gram metrics, yet the best performer on semantic metrics, suggesting it captures deeper meaning and semantic alignment over direct lexical overlap, which aligns with its strong human evaluation scores. This study also highlights that even though the models mostly address literal factual recall questions with high precision, they still face the challenge of specificity and interpretive bias at times.</abstract>
      <url hash="1edf0163">2025.indonlp-1.1</url>
      <bibkey>lal-etal-2025-hindi</bibkey>
    </paper>
    <paper id="2">
      <title>Machine Translation and Transliteration for <fixed-case>I</fixed-case>ndo-<fixed-case>A</fixed-case>ryan Languages: A Systematic Review</title>
      <author><first>Sandun Sameera</first><last>Perera</last></author>
      <author><first>Deshan Koshala</first><last>Sumanathilaka</last></author>
      <pages>11–21</pages>
      <abstract>This systematic review paper provides an overview of recent machine translation and transliteration developments for Indo-Aryan languages spoken by a large population across South Asia. The paper examines advancements in translation and transliteration systems for a few language pairs which appear in recently published papers. The review summarizes the current state of these technologies, providing a worthful resource for anyone who is doing research in these fields to understand and find existing systems and techniques for translation and transliteration.</abstract>
      <url hash="d028af3f">2025.indonlp-1.2</url>
      <bibkey>perera-sumanathilaka-2025-machine</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>BERT</fixed-case>opic for Topic Modeling of <fixed-case>H</fixed-case>indi Short Texts: A Comparative Study</title>
      <author><first>Atharva</first><last>Mutsaddi</last></author>
      <author><first>Anvi</first><last>Jamkhande</last></author>
      <author><first>Aryan Shirish</first><last>Thakre</last></author>
      <author><first>Yashodhara</first><last>Haribhakta</last></author>
      <pages>22–32</pages>
      <abstract>As short text data in native languages like Hindi increasingly appear in modern media, robust methods for topic modeling on such data have gained importance. This study investigates the performance of BERTopic in modeling Hindi short texts, an area that has been under-explored in existing research. Using contextual embeddings, BERTopic can capture semantic relationships in data, making it potentially more effective than traditional models, especially for short and diverse texts. We evaluate BERTopic using 6 different document embedding models and compare its performance against 8 established topic modeling techniques, such as Latent Dirichlet Allocation (LDA), Non-negative Matrix Factorization (NMF), Latent Semantic Indexing (LSI), Additive Regularization of Topic Models (ARTM), Probabilistic Latent Semantic Analysis (PLSA), Embedded Topic Model (ETM), Combined Topic Model (CTM), and Top2Vec. The models are assessed using coherence scores across a range of topic counts. Our results reveal that BERTopic consistently outperforms other models in capturing coherent topics from short Hindi texts.</abstract>
      <url hash="4c3d41be">2025.indonlp-1.3</url>
      <bibkey>mutsaddi-etal-2025-bertopic</bibkey>
    </paper>
    <paper id="4">
      <title>Evaluating Structural and Linguistic Quality in <fixed-case>U</fixed-case>rdu <fixed-case>DRS</fixed-case> Parsing and Generation through Bidirectional Evaluation</title>
      <author><first>Muhammad Saad</first><last>Amin</last></author>
      <author><first>Luca</first><last>Anselma</last></author>
      <author><first>Alessandro</first><last>Mazzei</last></author>
      <pages>33–43</pages>
      <abstract>Evaluating Discourse Representation Structure (DRS)-based systems for semantic parsing (Text-to-DRS) and generation (DRS-to-Text) poses unique challenges, particularly in low-resource languages like Urdu. Traditional metrics often fall short, focusing either on structural accuracy or linguistic quality, but rarely capturing both. To address this limitation, we introduce two complementary evaluation methodologies—Parse-Generate (PARS-GEN) and Generate-Parse (GEN-PARS)—designed for a more comprehensive assessment of DRS-based systems. PARS-GEN evaluates the parsing process by converting DRS outputs back to the text, revealing linguistic nuances often missed by structure-focused metrics like SMATCH. Conversely, GEN-PARS assesses text generation by converting generated text into DRS, providing a semantic perspective that complements surface-level metrics such as BLEU, METEOR, and BERTScore. Using the Parallel Meaning Bank (PMB) dataset, we demonstrate our methodology across Urdu, uncovering unique insights into Urdu’s structural and linguistic interplay. Findings show that traditional metrics frequently overlook the complexity of linguistic and semantic fidelity, especially in low-resource languages. Our dual approach offers a robust framework for evaluating DRS-based systems, enhancing semantic parsing and text generation quality.</abstract>
      <url hash="b0b51275">2025.indonlp-1.4</url>
      <bibkey>amin-etal-2025-evaluating</bibkey>
    </paper>
    <paper id="5">
      <title>Studying the Effect of <fixed-case>H</fixed-case>indi Tokenizer Performance on Downstream Tasks</title>
      <author><first>Rashi</first><last>Goel</last></author>
      <author><first>Fatiha</first><last>Sadat</last></author>
      <pages>44–49</pages>
      <abstract>This paper deals with a study on the effect of training data size and tokenizer performance for Hindi language on the eventual downstream model performance and comprehension. Multiple monolingual Hindi tokenizers are trained for large language models such as BERT and intrinsic and extrinsic evaluations are performed on multiple Hindi datasets. The objective of this study is to understand the precise effects of tokenizer performance on downstream task performance to gain insight on how to develop better models for low-resource languages.</abstract>
      <url hash="b0cca844">2025.indonlp-1.5</url>
      <bibkey>goel-sadat-2025-studying</bibkey>
    </paper>
    <paper id="6">
      <title>Adapting Multilingual <fixed-case>LLM</fixed-case>s to Low-Resource Languages using Continued Pre-training and Synthetic Corpus: A Case Study for <fixed-case>H</fixed-case>indi <fixed-case>LLM</fixed-case>s</title>
      <author><first>Raviraj</first><last>Joshi</last></author>
      <author><first>Kanishk</first><last>Singla</last></author>
      <author><first>Anusha</first><last>Kamath</last></author>
      <author><first>Raunak</first><last>Kalani</last></author>
      <author><first>Rakesh</first><last>Paul</last></author>
      <author><first>Utkarsh</first><last>Vaidya</last></author>
      <author><first>Sanjay Singh</first><last>Chauhan</last></author>
      <author><first>Niranjan</first><last>Wartikar</last></author>
      <author><first>Eileen</first><last>Long</last></author>
      <pages>50–57</pages>
      <abstract>Multilingual LLMs support a variety of languages; however, their performance is suboptimal for low-resource languages. In this work, we emphasize the importance of continued pre-training of multilingual LLMs and the use of translation-based synthetic pre-training corpora for improving LLMs in low-resource languages. We conduct our study in the context of the low-resource Indic language Hindi. We introduce Nemotron-Mini-Hindi 4B, a bilingual SLM supporting both Hindi and English, based on Nemotron-Mini 4B. The model is trained using a mix of real and synthetic Hindi + English tokens, with continuous pre-training performed on 400B tokens. We demonstrate that both the base and instruct models achieve state-of-the-art results on Hindi benchmarks while remaining competitive on English tasks. Additionally, we observe that the continued pre-training approach enhances the model’s overall factual accuracy.</abstract>
      <url hash="25ba228c">2025.indonlp-1.6</url>
      <bibkey>joshi-etal-2025-adapting</bibkey>
    </paper>
    <paper id="7">
      <title><fixed-case>OVQA</fixed-case>: A Dataset for Visual Question Answering and Multimodal Research in <fixed-case>O</fixed-case>dia Language</title>
      <author><first>Shantipriya</first><last>Parida</last></author>
      <author><first>Shashikanta</first><last>Sahoo</last></author>
      <author><first>Sambit</first><last>Sekhar</last></author>
      <author><first>Kalyanamalini</first><last>Sahoo</last></author>
      <author><first>Ketan</first><last>Kotwal</last></author>
      <author><first>Sonal</first><last>Khosla</last></author>
      <author><first>Satya Ranjan</first><last>Dash</last></author>
      <author><first>Aneesh</first><last>Bose</last></author>
      <author><first>Guneet Singh</first><last>Kohli</last></author>
      <author><first>Smruti Smita</first><last>Lenka</last></author>
      <author><first>Ondřej</first><last>Bojar</last></author>
      <pages>58–66</pages>
      <abstract>This paper introduces OVQA, the first multimodal dataset designed for visual question-answering (VQA), visual question elicitation (VQE), and multimodal research for the low-resource Odia language. The dataset was created by manually translating 6,149 English question-answer pairs, each associated with 6,149 unique images from the Visual Genome dataset. This effort resulted in 27,809 English-Odia parallel sentences, ensuring a semantic match with the corresponding visual information. Several baseline experiments were conducted on the dataset, including visual question answering and visual question elicitation. The dataset is the first VQA dataset for the low-resource Odia language and will be released for multimodal research purposes and also help researchers extend for other low-resource languages.</abstract>
      <url hash="c05dc867">2025.indonlp-1.7</url>
      <bibkey>parida-etal-2025-ovqa</bibkey>
    </paper>
    <paper id="8">
      <title>Advancing Multilingual Speaker Identification and Verification for <fixed-case>I</fixed-case>ndo-<fixed-case>A</fixed-case>ryan and <fixed-case>D</fixed-case>ravidian Languages</title>
      <author><first>Braveenan</first><last>Sritharan</last></author>
      <author><first>Uthayasanker</first><last>Thayasivam</last></author>
      <pages>67–73</pages>
      <abstract>Multilingual speaker identification and verification is a challenging task, especially for languages with diverse acoustic and linguistic features such as Indo-Aryan and Dravidian languages. Previous models have struggled to generalize across multilingual environments, leading to significant performance degradation when applied to multiple languages. In this paper, we propose an advanced approach to multilingual speaker identification and verification, specifically designed for Indo-Aryan and Dravidian languages. Empirical results on the Kathbath dataset show that our approach significantly improves speaker identification accuracy, reducing the performance gap between monolingual and multilingual systems from 15% to just 1%. Additionally, our model reduces the equal error rate for speaker verification from 15% to 5% in noisy conditions. Our method demonstrates strong generalization capabilities across diverse languages, offering a scalable solution for multilingual voice-based biometric systems.</abstract>
      <url hash="0fb755af">2025.indonlp-1.8</url>
      <bibkey>sritharan-thayasivam-2025-advancing</bibkey>
    </paper>
    <paper id="9">
      <title>Sentiment Analysis of <fixed-case>S</fixed-case>inhala News Comments Using Transformers</title>
      <author><first>Isuru</first><last>Bandaranayake</last></author>
      <author><first>Hakim</first><last>Usoof</last></author>
      <pages>74–82</pages>
      <abstract>Sentiment analysis has witnessed significant advancements with the emergence of deep learning models such as transformer models. Transformer models adopt the mechanism of self-attention and have achieved state-of-the-art performance across various natural language processing (NLP) tasks, including sentiment analysis. However, limited studies are exploring the application of these recent advancements in sentiment analysis of Sinhala text. This study addresses this research gap by employing transformer models such as BERT, DistilBERT, RoBERTa, and XLM-RoBERTa (XLM-R) for sentiment analysis of Sinhala News comments. This study was conducted for 4 classes: positive, negative, neutral, and conflict, as well as for 3 classes: positive, negative, and neutral. It revealed that the XLM-R-large model outperformed the other four models, and the transformer models used in previous studies for the Sinhala language. The XLM-R-large model achieved an accuracy of 65.84% and a macro-F1 score of 62.04% for sentiment analysis with four classes and an accuracy of 75.90% and a macro-F1 score of 72.31% for three classes.</abstract>
      <url hash="6c71b490">2025.indonlp-1.9</url>
      <bibkey>bandaranayake-usoof-2025-sentiment</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>E</fixed-case>x<fixed-case>M</fixed-case>ute: A Context-Enriched Multimodal Dataset for Hateful Memes</title>
      <author><first>Riddhiman Swanan</first><last>Debnath</last></author>
      <author><first>Nahian Beente</first><last>Firuj</last></author>
      <author><first>Abdul Wadud</first><last>Shakib</last></author>
      <author><first>Sadia</first><last>Sultana</last></author>
      <author><first>Md Saiful</first><last>Islam</last></author>
      <pages>83–89</pages>
      <abstract>In this paper, we introduce ExMute, an extended dataset for classifying hateful memes that incorporates critical contextual information, addressing a significant gap in existing resources. Building on a previous dataset of 4,158 memes without contextual annotations, ExMute expands the collection by adding 2,041 new memes and providing comprehensive annotations for all 6,199 memes. Each meme is labeled across six defined contexts with language markers indicating code-mixing, code-switching, and Bengali captions, enhancing its value for linguistic and cultural research. These memes are systematically labeled across six contexts: religion, politics, celebrity, male, female, and others, facilitating a more nuanced understanding of meme content and intent. To evaluate ExMute, we apply state-of-the-art textual, visual, and multimodal approaches, leveraging models including BanglaBERT, Visual Geometry Group (VGG), Inception, ResNet, and Vision Transformer (ViT). Our experiments show that our custom LSTM-based attention-based textual model achieves an accuracy of 0.60, while VGG-based visual models reach up to 0.63. Multimodal models, which combine visual and textual features, consistently achieve accuracy scores of around 0.64, demonstrating the dataset’s robustness for advancing multimodal classification tasks. ExMute establishes a valuable benchmark for future NLP research, particularly in low-resource language settings, highlighting the importance of context-aware labeling in improving classification accuracy and reducing bias.</abstract>
      <url hash="7a3d708d">2025.indonlp-1.10</url>
      <bibkey>debnath-etal-2025-exmute</bibkey>
    </paper>
    <paper id="11">
      <title>Studying the capabilities of Large Language Models in solving Combinatorics Problems posed in <fixed-case>H</fixed-case>indi</title>
      <author><first>Yash</first><last>Kumar</last></author>
      <author><first>Subhajit</first><last>Roy</last></author>
      <pages>90–99</pages>
      <abstract>There are serious attempts at improving the mathematical acumen of LLMs in questions posed in English. In India, where a large fraction of the students study in regional languages, there is a need to assess and improve these state-of-the-art LLMs in their reasoning abilities in regional languages as well. As Hindi is a language predominantly used in India, this study proposes a new dataset on mathematical combinatorics problems consisting of a parallel corpus of problems in English and Hindi collected from NCERT textbooks. We evaluate the “raw” single-shot capabilities of these LLMs in solving problems posed in Hindi. Then we apply a chain-of-thought approach to evaluate the improvement in the abilities of the LLMs at solving combinatorics problems posed in Hindi. Our study reveals that while smaller LLMs like LLaMa3-8B shows a significant drop in performance when questions are posed in Hindi, versus questions posed in English, larger LLMs like GPT4-turbo shows excellent capabilities at solving problems posed in Hindi, almost at par its abilities in English. We make two primary inferences from our study: (1) large models like GPT4 can be readily deployed in schools where Hindi is the primary language of study, especially in rural India; (2) there is a need to improve the multilingual capabilities of smaller models. As these smaller open-source models can be deployed on not so expensive GPUs, it is easier for schools to provide these models to the students, and hence, the latter is an important direction for future research.</abstract>
      <url hash="f673de45">2025.indonlp-1.11</url>
      <bibkey>kumar-roy-2025-studying</bibkey>
    </paper>
    <paper id="12">
      <title>From Scarcity to Capability: Empowering Fake News Detection in Low-Resource Languages with <fixed-case>LLM</fixed-case>s</title>
      <author><first>Hrithik Majumdar</first><last>Shibu</last></author>
      <author><first>Shrestha</first><last>Datta</last></author>
      <author><first>Md. Sumon</first><last>Miah</last></author>
      <author><first>Nasrullah</first><last>Sami</last></author>
      <author><first>Mahruba Sharmin</first><last>Chowdhury</last></author>
      <author><first>Md Saiful</first><last>Islam</last></author>
      <pages>100–107</pages>
      <abstract>The rapid spread of fake news presents a significant global challenge, particularly in low-resource languages like Bangla, which lack adequate datasets and detection tools. Although manual fact-checking is accurate, it is expensive and slow to prevent the dissemination of fake news. Addressing this gap, we introduce BanFakeNews-2.0, a robust dataset to enhance Bangla fake news detection. This version includes 11,700 additional, meticulously curated fake news articles validated from credible sources, creating a proportional dataset of 47,000 authentic and 13,000 fake news items across 13 categories. In addition, we created a manually curated independent test set of 460 fake and 540 authentic news items for rigorous evaluation. We invest efforts in collecting fake news from credible sources and manually verified while preserving the linguistic richness. We develop a benchmark system utilizing transformer-based architectures, including fine-tuned Bidirectional Encoder Representations from Transformers variants (F1-87%) and Large Language Models with Quantized Low-Rank Approximation (F1-89%), that significantly outperforms traditional methods. BanFakeNews-2.0 offers a valuable resource to advance research and application in fake news detection for low-resourced languages. We publicly release our dataset and model on GitHub to foster research in this direction.</abstract>
      <url hash="9ce7701e">2025.indonlp-1.12</url>
      <bibkey>shibu-etal-2025-scarcity</bibkey>
    </paper>
    <paper id="13">
      <title>Enhancing Participatory Development Research in <fixed-case>S</fixed-case>outh <fixed-case>A</fixed-case>sia through <fixed-case>LLM</fixed-case> Agents System: An Empirically-Grounded Methodological Initiative from Field Evidence in <fixed-case>S</fixed-case>ri <fixed-case>L</fixed-case>ankan</title>
      <author><first>Xinjie</first><last>Zhao</last></author>
      <author><first>Hao</first><last>Wang</last></author>
      <author><first>Shyaman Maduranga</first><last>Sriwarnasinghe</last></author>
      <author><first>Jiacheng</first><last>Tang</last></author>
      <author><first>Shiyun</first><last>Wang</last></author>
      <author><first>Sayaka</first><last>Sugiyama</last></author>
      <author><first>So</first><last>Morikawa</last></author>
      <pages>108–121</pages>
      <abstract>The integration of artificial intelligence into development research methodologies offers unprecedented opportunities to address persistent challenges in participatory research, particularly in linguistically diverse regions like South Asia. Drawing on empirical implementation in Sri Lanka’s Sinhala-speaking communities, this study presents a methodological framework designed to transform participatory development research in the multilingual context of Sri Lanka’s flood-prone Nilwala River Basin. Moving beyond conventional translation and data collection tools, the proposed framework leverages a multi-agent system architecture to redefine how data collection, analysis, and community engagement are conducted in linguistically and culturally complex research settings. This structured, agent-based approach facilitates participatory research that is both scalable and adaptive, ensuring that community perspectives remain central to research outcomes. Field experiences underscore the immense potential of LLM-based systems in addressing long-standing issues in development research across resource-limited regions, delivering both quantitative efficiencies and qualitative improvements in inclusivity. At a broader methodological level, this research advocates for AI-driven participatory research tools that prioritize ethical considerations, cultural sensitivity, and operational efficiency. It highlights strategic pathways for deploying AI systems to reinforce community agency and equitable knowledge generation, offering insights that could inform broader research agendas across the Global South.</abstract>
      <url hash="e032a650">2025.indonlp-1.13</url>
      <bibkey>zhao-etal-2025-enhancing</bibkey>
    </paper>
    <paper id="14">
      <title>Identifying Aggression and Offensive Language in Code-Mixed Tweets: A Multi-Task Transfer Learning Approach</title>
      <author><first>Bharath</first><last>Kancharla</last></author>
      <author><first>Prabhjot</first><last>Singh</last></author>
      <author><first>Lohith Bhagavan</first><last>Kancharla</last></author>
      <author><first>Yashita</first><last>Chama</last></author>
      <author><first>Raksha</first><last>Sharma</last></author>
      <pages>122–128</pages>
      <abstract>The widespread use of social media has contributed to the increase in hate speech and offensive language, impacting people of all ages. This issue is particularly difficult to address when the text is in a code-mixed language. Twitter is commonly used to express opinions in code-mixed language. In this paper, we introduce a novel Multi-Task Transfer Learning (MTTL) framework to detect aggression and offensive language. By focusing on the dual facets of cyberbullying, aggressiveness and offensiveness, our model leverages the MTTL approach to enhance the performance of the model on the aggression and offensive language detection. Results show that our Multi-Task Transfer Learning (MTTL) setup significantly enhances the performance of state-of-the-art pretrained language models, BERT, RoBERTa, and Hing-RoBERTa for Hindi-English code-mixed data from Twitter.</abstract>
      <url hash="20d0099d">2025.indonlp-1.14</url>
      <bibkey>kancharla-etal-2025-identifying</bibkey>
    </paper>
    <paper id="15">
      <title>Team <fixed-case>I</fixed-case>ndi<fixed-case>D</fixed-case>ata<fixed-case>M</fixed-case>iner at <fixed-case>I</fixed-case>ndo<fixed-case>NLP</fixed-case> 2025: <fixed-case>H</fixed-case>indi Back Transliteration - <fixed-case>R</fixed-case>oman to <fixed-case>D</fixed-case>evanagari using <fixed-case>LL</fixed-case>a<fixed-case>M</fixed-case>a</title>
      <author><first>Saurabh</first><last>Kumar</last></author>
      <author><first>Dhruvkumar Babubhai</first><last>Kakadiya</last></author>
      <author><first>Sanasam Ranbir</first><last>Singh</last></author>
      <pages>129–134</pages>
      <abstract>The increasing use of Romanized typing for Indo-Aryan languages on social media poses challenges due to its lack of standardization and loss of linguistic richness. To address this, we propose a sentence-level back-transliteration approach using the LLaMa 3.1 model for Hindi. Leveraging fine-tuning with the Dakshina dataset, our approach effectively resolves ambiguities in Romanized Hindi text, offering a robust solution for converting it into the native Devanagari script.</abstract>
      <url hash="cabd789a">2025.indonlp-1.15</url>
      <bibkey>kumar-etal-2025-team</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>I</fixed-case>ndo<fixed-case>NLP</fixed-case> 2025 Shared Task: <fixed-case>R</fixed-case>omanized <fixed-case>S</fixed-case>inhala to <fixed-case>S</fixed-case>inhala Reverse Transliteration Using <fixed-case>BERT</fixed-case></title>
      <author><first>Sandun Sameera</first><last>Perera</last></author>
      <author><first>Lahiru Prabhath</first><last>Jayakodi</last></author>
      <author><first>Deshan Koshala</first><last>Sumanathilaka</last></author>
      <author><first>Isuri</first><last>Anuradha</last></author>
      <pages>135–140</pages>
      <abstract>The Romanized text has become popu lar with the growth of digital communi cation platforms, largely due to the fa miliarity with English keyboards. In Sri Lanka, Romanized Sinhala, commonly re ferred to as “Singlish” is widely used in digi tal communications. This paper introduces a novel context-aware back-transliteration system designed to address the ad-hoc typ ing patterns and lexical ambiguity inher ent in Singlish. The proposed system com bines dictionary-based mapping for Singlish words, a rule-based transliteration for out of-vocabulary words and a BERT-based language model for addressing lexical am biguities. Evaluation results demonstrate the robustness of the proposed approach, achieving high BLEU scores along with low Word Error Rate (WER) and Character Er ror Rate (CER) across test datasets. This study provides an effective solution for Ro manized Sinhala back-transliteration and establishes the foundation for improving NLP tools for similar low-resourced lan guages.</abstract>
      <url hash="4721b8e5">2025.indonlp-1.16</url>
      <bibkey>perera-etal-2025-indonlp</bibkey>
    </paper>
  </volume>
</collection>
