<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.mwe">
  <volume id="1" ingest-date="2024-05-18" type="proceedings">
    <meta>
      <booktitle>Proceedings of the Joint Workshop on Multiword Expressions and Universal Dependencies (MWE-UD) @ LREC-COLING 2024</booktitle>
      <editor><first>Archna</first><last>Bhatia</last></editor>
      <editor><first>Gosse</first><last>Bouma</last></editor>
      <editor><first>A. Seza</first><last>Doğruöz</last></editor>
      <editor><first>Kilian</first><last>Evang</last></editor>
      <editor><first>Marcos</first><last>Garcia</last></editor>
      <editor><first>Voula</first><last>Giouli</last></editor>
      <editor><first>Lifeng</first><last>Han</last></editor>
      <editor><first>Joakim</first><last>Nivre</last></editor>
      <editor><first>Alexandre</first><last>Rademaker</last></editor>
      <publisher>ELRA and ICCL</publisher>
      <address>Torino, Italia</address>
      <month>May</month>
      <year>2024</year>
      <url hash="b5769b4d">2024.mwe-1</url>
      <venue>mwe</venue>
      <venue>udw</venue>
      <venue>ws</venue>
    </meta>
    <frontmatter>
      <url hash="7ca5715c">2024.mwe-1.0</url>
      <bibkey>mwe-2024-joint</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Every Time We Hire an <fixed-case>LLM</fixed-case>, the Reasoning Performance of the Linguists Goes Up</title>
      <author><first>Harish</first><last>Tayyar Madabushi</last></author>
      <pages>1</pages>
      <abstract/>
      <url hash="7ad6e083">2024.mwe-1.1</url>
      <bibkey>tayyar-madabushi-2024-every</bibkey>
    </paper>
    <paper id="2">
      <title>Using <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies for testing hypotheses about communicative efficiency</title>
      <author><first>Natalia</first><last>Levshina</last></author>
      <pages>2–3</pages>
      <abstract/>
      <url hash="5febabbe">2024.mwe-1.2</url>
      <bibkey>levshina-2024-using</bibkey>
    </paper>
    <paper id="3">
      <title>Automatic Manipulation of Training Corpora to Make Parsers Accept Real-world Text</title>
      <author><first>Hiroshi</first><last>Kanayama</last></author>
      <author><first>Ran</first><last>Iwamoto</last></author>
      <author><first>Masayasu</first><last>Muraoka</last></author>
      <author><first>Takuya</first><last>Ohko</last></author>
      <author><first>Kohtaroh</first><last>Miyamoto</last></author>
      <pages>4–13</pages>
      <abstract>This paper discusses how to build a practical syntactic analyzer, and addresses the distributional differences between existing corpora and actual documents in applications. As a case study we focus on noun phrases that are not headed by a main verb and sentences without punctuation at the end, which are rare in a number of Universal Dependencies corpora but frequently appear in the real-world use cases of syntactic parsers. We converted the training corpora so that their distribution is closer to that in realistic inputs, and obtained the better scores both in general syntax benchmarking and a sentiment detection task, a typical application of dependency analysis.</abstract>
      <url hash="a4e5206b">2024.mwe-1.3</url>
      <bibkey>kanayama-etal-2024-automatic</bibkey>
    </paper>
    <paper id="4">
      <title>Assessing <fixed-case>BERT</fixed-case>’s sensitivity to idiomaticity</title>
      <author><first>Li</first><last>Liu</last></author>
      <author><first>Francois</first><last>Lareau</last></author>
      <pages>14–23</pages>
      <abstract>BERT-like language models have been demonstrated to capture the idiomatic meaning of multiword expressions. Linguists have also shown that idioms have varying degrees of idiomaticity. In this paper, we assess CamemBERT’s sensitivity to the degree of idiomaticity within idioms, as well as the dependency of this sensitivity on part of speech and idiom length. We used a demasking task on tokens from 3127 idioms and 22551 tokens corresponding to simple lexemes taken from the French Lexical Network (LN-fr), and observed that CamemBERT performs distinctly on tokens embedded within idioms compared to simple ones. When demasking tokens within idioms, the model is not proficient in discerning their level of idiomaticity. Moreover, regardless of idiomaticity, CamemBERT excels at handling function words. The length of idioms also impacts CamemBERT’s performance to a certain extent. The last two observations partly explain the difference between the model’s performance on idioms versus simple lexemes. We conclude that the model treats idioms differently from simple lexemes, but that it does not capture the difference in compositionality between subclasses of idioms.</abstract>
      <url hash="72225b50">2024.mwe-1.4</url>
      <bibkey>liu-lareau-2024-assessing</bibkey>
    </paper>
    <paper id="5">
      <title>Identification and Annotation of Body Part Multiword Expressions in Old <fixed-case>E</fixed-case>gyptian</title>
      <author><first>Roberto</first><last>Díaz Hernández</last></author>
      <pages>24–32</pages>
      <abstract>This paper presents the preliminary results of an ongoing study on the diachronic and synchronic use of multiword expressions (MWEs) in Egyptian, begun when I joined the COST Action Universality, Diversity and Idiosyncrasy in Language Technology (UniDive, CA21167). It analyzes, as a case study, Old Egyptian body part MWEs based on lexicographic and textual resources, and its aim is both to open up a research line in Egyptology, where the study of MWEs has been neglected, and to contribute to Natural Language Processing studies by determining the rules governing the morpho-syntactic formation of Old Egyptian body part MWEs in order to facilitate the identification of other types of MWEs.</abstract>
      <url hash="8935413a">2024.mwe-1.5</url>
      <bibkey>diaz-hernandez-2024-identification</bibkey>
    </paper>
    <paper id="6">
      <title>Fitting Fixed Expressions into the <fixed-case>UD</fixed-case> Mould: <fixed-case>S</fixed-case>wedish as a Use Case</title>
      <author><first>Lars</first><last>Ahrenberg</last></author>
      <pages>33–42</pages>
      <abstract>Fixed multiword expressions are common in many, if not all, natural languages. In the Universal Dependencies framework, UD, a subset of these expressions are modelled with the dependency relation ‘fixed’ targeting the most grammaticalized cases of functional multiword items. In this paper we perform a detailed analysis of 439 expressions modelled with ‘fixed’ in two Swedish UD treebanks in order to reduce their numbers and fit the definition better. We identify a large number of dimensions of variation for fixed multiword expressions that can be used for the purpose. We also point out several problematic aspects of the current UD approach to multiword expressions and discuss different alternative solutions for modelling fixed expresions. We suggest that insights from Constructional Grammar (CxG) can help with a more systematic treatment of fixed expressions in UD.</abstract>
      <url hash="1bf98096">2024.mwe-1.6</url>
      <attachment type="OptionalSupplementaryMaterial" hash="2a0752c9">2024.mwe-1.6.OptionalSupplementaryMaterial.zip</attachment>
      <bibkey>ahrenberg-2024-fitting</bibkey>
    </paper>
    <paper id="7">
      <title>Synthetic-Error Augmented Parsing of <fixed-case>S</fixed-case>wedish as a Second Language: Experiments with Word Order</title>
      <author><first>Arianna</first><last>Masciolini</last></author>
      <author><first>Emilie</first><last>Francis</last></author>
      <author><first>Maria Irena</first><last>Szawerna</last></author>
      <pages>43–49</pages>
      <abstract>Ungrammatical text poses significant challenges for off-the-shelf dependency parsers. In this paper, we explore the effectiveness of using synthetic data to improve performance on essays written by learners of Swedish as a second language. Due to their relevance and ease of annotation, we restrict our initial experiments to word order errors. To do that, we build a corrupted version of the standard Swedish Universal Dependencies (UD) treebank Talbanken, mimicking the error patterns and frequency distributions observed in the Swedish Learner Language (SweLL) corpus. We then use the MaChAmp (Massive Choice, Ample tasks) toolkit to train an array of BERT-based dependency parsers, fine-tuning on different combinations of original and corrupted data. We evaluate the resulting models not only on their respective test sets but also, most importantly, on a smaller collection of sentence-correction pairs derived from SweLL. Results show small but significant performance improvements on the target domain, with minimal decline on normative data.</abstract>
      <url hash="294912ec">2024.mwe-1.7</url>
      <bibkey>masciolini-etal-2024-synthetic</bibkey>
    </paper>
    <paper id="8">
      <title>The <fixed-case>V</fixed-case>edic Compound Dataset</title>
      <author><first>Sven</first><last>Sellmer</last></author>
      <author><first>Oliver</first><last>Hellwig</last></author>
      <pages>50–55</pages>
      <abstract>This paper introduces the Vedic Compound Dataset (VCD), the first resource providing annotated compounds from Vedic Sanskrit, a South Asian Indo-European language used from ca. 1500 to 500 BCE. The VCD aims at facilitating the study of language change in early Indo-Iranian and offers comparative material for quantitative cross-linguistic research on compounds. The process of annotating Vedic compounds is complex as they contain five of the six basic types of compounds defined by Scalise &amp; Bisetto (2005), which are, however, not consistently marked in morphosyntax, making their automatic classification a significant challenge. The paper details the process of collecting and preprocessing the relevant data, with a particular focus on the question of how to distinguish exocentric from endocentric usage. It further discusses experiments with a simple ML classifier that uses compound internal syntactic relations, outlines the composition of the dataset, and sketches directions for future research.</abstract>
      <url hash="2c97022b">2024.mwe-1.8</url>
      <bibkey>sellmer-hellwig-2024-vedic</bibkey>
    </paper>
    <paper id="9">
      <title>A <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies Treebank for <fixed-case>G</fixed-case>ujarati</title>
      <author><first>Mayank</first><last>Jobanputra</last></author>
      <author><first>Maitrey</first><last>Mehta</last></author>
      <author><first>Çağrı</first><last>Çöltekin</last></author>
      <pages>56–62</pages>
      <abstract>The Universal Dependencies (UD) project has presented itself as a valuable platform to develop various resources for the languages of the world. We present and release a sample treebank for the Indo-Aryan language of Gujarati – a widely spoken language with little linguistic resources. This treebank is the first labeled dataset for dependency parsing in the language and the script (the Gujarati script). The treebank contains 187 part-of-speech and dependency annotated sentences from diverse genres. We discuss various idiosyncratic examples, annotation choices and present an elaborate corpus along with agreement statistics. We see this work as a valuable resource and a stepping stone for research in Gujarati Computational Linguistics.</abstract>
      <url hash="c66591f0">2024.mwe-1.9</url>
      <bibkey>jobanputra-etal-2024-universal</bibkey>
    </paper>
    <paper id="10">
      <title>Overcoming Early Saturation on Low-Resource Languages in Multilingual Dependency Parsing</title>
      <author><first>Jiannan</first><last>Mao</last></author>
      <author><first>Chenchen</first><last>Ding</last></author>
      <author><first>Hour</first><last>Kaing</last></author>
      <author><first>Hideki</first><last>Tanaka</last></author>
      <author><first>Masao</first><last>Utiyama</last></author>
      <author><first>Tadahiro</first><last>Matsumoto.</last></author>
      <pages>63–69</pages>
      <abstract>UDify is a multilingual and multi-task parser fine-tuned on mBERT that achieves remarkable performance in high-resource languages. However, the performance saturates early and decreases gradually in low-resource languages as training proceeds. This work applies a data augmentation method and conducts experiments on seven few-shot and four zero-shot languages. The unlabeled attachment scores were improved on the zero-shot languages dependency parsing tasks, with the average score rising from 67.1% to 68.7%. Meanwhile, dependency parsing tasks for high-resource languages and other tasks were hardly affected. Experimental results indicate the data augmentation method is effective for low-resource languages in a multilingual dependency parsing.</abstract>
      <url hash="fa0a5c37">2024.mwe-1.10</url>
      <bibkey>mao-etal-2024-overcoming</bibkey>
    </paper>
    <paper id="11">
      <title>Part-of-Speech Tagging for <fixed-case>N</fixed-case>orthern <fixed-case>K</fixed-case>urdish</title>
      <author><first>Peshmerge</first><last>Morad</last></author>
      <author><first>Sina</first><last>Ahmadi</last></author>
      <author><first>Lorenzo</first><last>Gatti</last></author>
      <pages>70–80</pages>
      <abstract>In the growing domain of natural language processing, low-resourced languages like Northern Kurdish remain largely unexplored due to the lack of resources needed to be part of this growth. In particular, the tasks of part-of-speech tagging and tokenization for Northern Kurdish are still insufficiently addressed. In this study, we aim to bridge this gap by evaluating a range of statistical, neural, and fine-tuned-based models specifically tailored for Northern Kurdish. Leveraging limited but valuable datasets, including the Universal Dependency Kurmanji treebank and a novel manually annotated and tokenized gold-standard dataset consisting of 136 sentences (2,937 tokens). We evaluate several POS tagging models and report that the fine-tuned transformer-based model outperforms others, achieving an accuracy of 0.87 and a macro-averaged F1 score of 0.77. Data and models are publicly available under an open license at https://github.com/peshmerge/northern-kurdish-pos-tagging</abstract>
      <url hash="f91a231c">2024.mwe-1.11</url>
      <bibkey>morad-etal-2024-part</bibkey>
    </paper>
    <paper id="12">
      <title>Diachronic Analysis of Multi-word Expression Functional Categories in Scientific <fixed-case>E</fixed-case>nglish</title>
      <author><first>Diego</first><last>Alves</last></author>
      <author><first>Stefania</first><last>Degaetano-Ortlieb</last></author>
      <author><first>Elena</first><last>Schmidt</last></author>
      <author><first>Elke</first><last>Teich</last></author>
      <pages>81–87</pages>
      <abstract>We present a diachronic analysis of multi-word expressions (MWEs) in English based on the Royal Society Corpus, a dataset containing 300+ years of the scientific publications of the Royal Society of London. Specifically, we investigate the functions of MWEs, such as stance markers (“is is interesting”) or discourse organizers (“in this section”), and their development over time. Our approach is multi-disciplinary: to detect MWEs we use Universal Dependencies, to classify them functionally we use an approach from register linguistics, and to assess their role in diachronic development we use an information-theoretic measure, relative entropy.</abstract>
      <url hash="17aad2be">2024.mwe-1.12</url>
      <bibkey>alves-etal-2024-diachronic</bibkey>
    </paper>
    <paper id="13">
      <title>Lexicons Gain the Upper Hand in <fixed-case>A</fixed-case>rabic <fixed-case>MWE</fixed-case> Identification</title>
      <author><first>Najet</first><last>Hadj Mohamed</last></author>
      <author><first>Agata</first><last>Savary</last></author>
      <author><first>Cherifa</first><last>Ben Khelil</last></author>
      <author><first>Jean-Yves</first><last>Antoine</last></author>
      <author><first>Iskandar</first><last>Keskes</last></author>
      <author><first>Lamia</first><last>Hadrich-Belguith</last></author>
      <pages>88–97</pages>
      <abstract>This paper highlights the importance of integrating MWE identification with the development of syntactic MWE lexicons. It suggests that lexicons with minimal morphosyntactic information can amplify current MWE-annotated datasets and refine identification strategies. To our knowledge, this work represents the first attempt to focus on both seen and unseen of VMWEs for Arabic. It also deals with the challenge of differentiating between literal and figurative interpretations of idiomatic expressions. The approach involves a dual-phase procedure: first projecting a VMWE lexicon onto a corpus to identify candidate occurrences, then disambiguating these occurrences to distinguish idiomatic from literal instances. Experiments outlined in the paper aim to assess the efficacy of this technique, utilizing a lexicon known as LEXAR and the “parseme-ar” corpus. The findings suggest that lexicon-driven strategies have the potential to refine MWE identification, particularly for unseen occurrences.</abstract>
      <url hash="c1331bf3">2024.mwe-1.13</url>
      <bibkey>hadj-mohamed-etal-2024-lexicons</bibkey>
    </paper>
    <paper id="14">
      <title>Revisiting <fixed-case>VMWE</fixed-case>s in <fixed-case>H</fixed-case>indi: Annotating Layers of Predication</title>
      <author><first>Kanishka</first><last>Jain</last></author>
      <author><first>Ashwini</first><last>Vaidya</last></author>
      <pages>98–105</pages>
      <abstract>Multiword expressions in languages like Hindi are both productive and challenging. Hindi not only uses a variety of verbal multiword expressions (VMWEs) but also employs different combinatorial strategies to create new types of multiword expressions. In this paper we are investigating two such strategies that are quite common in the language. Firstly, we describe that VMWEs in Hindi are not just lexical but also morphological. Causatives are formed morphologically in Hindi. Second, we examine Stacked VMWEs i.e. when at least two VMWEs occur together. We suggest that the existing PARSEME annotation framework can be extended to these two phenomena without changing the existing guidelines. We also propose rule-based heuristics using existing Universal Dependency annotations to automatically identify and annotate some of the VMWEs in the language. The goal of this paper is to refine the existing PARSEME corpus of Hindi for VMWEs while expanding its scope giving a more comprehensive picture of VMWEs in Hindi.</abstract>
      <url hash="f9ec0aff">2024.mwe-1.14</url>
      <bibkey>jain-vaidya-2024-revisiting</bibkey>
    </paper>
    <paper id="15">
      <title>Towards the semantic annotation of <fixed-case>SR</fixed-case>-<fixed-case>ELEXIS</fixed-case> corpus: Insights into Multiword Expressions and Named Entities</title>
      <author><first>Cvetana</first><last>Krstev</last></author>
      <author><first>Ranka</first><last>Stanković</last></author>
      <author><first>Aleksandra M.</first><last>Marković</last></author>
      <author><first>Teodora Sofija</first><last>Mihajlov</last></author>
      <pages>106–114</pages>
      <abstract>This paper presents the work in progress on ELEXIS-sr corpus, the Serbian addition to the ELEXIS multilingual annotated corpus ElexisWSD, comprising semantic annotations and word sense repositories. The ELEXIS corpus has parallel annotations in ten European languages, serving as a cross-lingual benchmark for evaluating low and medium-resourced European languages. The focus in this paper is on multiword expressions (MWEs) and named entities (NEs), their recognition in the ELEXIS-sr sentence set, and comparison with annotations in other languages. The first steps in building the Serbian sense inventory are discussed, and some results concerning MWEs and NEs are analysed. Once completed, the ELEXIS-sr corpus will be the first sense annotated corpus using the Serbian WordNet (SrpWN). Finally, ideas to represent MWE lexicon entries as Linguistic Linked-Open Data (LLOD) and connect them with occurrences in the corpus are presented.</abstract>
      <url hash="31a02399">2024.mwe-1.15</url>
      <bibkey>krstev-etal-2024-towards</bibkey>
    </paper>
    <paper id="16">
      <title>To Leave No Stone Unturned: Annotating Verbal Idioms in the <fixed-case>P</fixed-case>arallel <fixed-case>M</fixed-case>eaning <fixed-case>B</fixed-case>ank</title>
      <author><first>Rafael</first><last>Ehren</last></author>
      <author><first>Kilian</first><last>Evang</last></author>
      <author><first>Laura</first><last>Kallmeyer</last></author>
      <pages>115–124</pages>
      <abstract>Idioms present many challenges to semantic annotation in a lexicalized framework, which leads to them being underrepresented or inadequately annotated in sembanks. In this work, we address this problem with respect to verbal idioms in the Parallel Meaning Bank (PMB), specifically in its German part, where only some idiomatic expressions have been annotated correctly. We first select candidate idiomatic expressions, then determine their idiomaticity status and whether they are decomposable or not, and then we annotate their semantics using WordNet senses and VerbNet semantic roles. Overall, inter-annotator agreement is very encouraging. A difficulty, however, is to choose the correct word sense. This is not surprising, given that English synsets are many and there is often no unique mapping from German idioms and words to them. Besides this, there are many subtle differences and interesting challenging cases. We discuss some of them in this paper.</abstract>
      <url hash="31b7ab4f">2024.mwe-1.16</url>
      <bibkey>ehren-etal-2024-leave</bibkey>
    </paper>
    <paper id="17">
      <title>Universal Feature-based Morphological Trees</title>
      <author><first>Federica</first><last>Gamba</last></author>
      <author><first>Abishek</first><last>Stephen</last></author>
      <author><first>Zdeněk</first><last>Žabokrtský</last></author>
      <pages>125–137</pages>
      <abstract>The paper proposes a novel data representation inspired by Universal Dependencies (UD) syntactic trees, which are extended to capture the internal morphological structure of word forms. As a result, morphological segmentation is incorporated within the UD representation of syntactic dependencies. To derive the proposed data structure we leverage existing annotation of UD treebanks as well as available resources for segmentation, and we select 10 languages to work with in the presented case study. Additionally, statistical analysis reveals a robust correlation between morphs and sets of morphological features of words. We thus align the morphs to the observed feature inventories capturing the morphological meaning of morphs. Through the beneficial exploitation of cross-lingual correspondence of morphs, the proposed syntactic representation based on morphological segmentation proves to enhance the comparability of sentence structures across languages.</abstract>
      <url hash="70a01a21">2024.mwe-1.17</url>
      <bibkey>gamba-etal-2024-universal</bibkey>
    </paper>
    <paper id="18">
      <title>Combining Grammatical and Relational Approaches. A Hybrid Method for the Identification of Candidate Collocations from Corpora</title>
      <author><first>Damiano</first><last>Perri</last></author>
      <author><first>Irene</first><last>Fioravanti</last></author>
      <author><first>Osvaldo</first><last>Gervasi</last></author>
      <author><first>Stefania</first><last>Spina</last></author>
      <pages>138–146</pages>
      <abstract>We present an evaluation of three different methods for the automatic identification of candidate collocations in corpora, part of a research project focused on the development of a learner dictionary of Italian collocations. We compare the commonly used POS-based method and the syntactic dependency-based method with a hybrid method integrating both approaches. We conduct a statistical analysis on a sample corpus of written and spoken texts of different registers. Results show that the hybrid method can correctly detect more candidate collocations against a human annotated benchmark. The scores are particularly high in adjectival modifier rela- tions. A hybrid approach to candidate collocation identification seems to lead to an improvement in the quality of results.</abstract>
      <url hash="0afd7911">2024.mwe-1.18</url>
      <bibkey>perri-etal-2024-combining</bibkey>
    </paper>
    <paper id="19">
      <title>Multiword Expressions between the Corpus and the Lexicon: Universality, Idiosyncrasy, and the Lexicon-Corpus Interface</title>
      <author><first>Verginica</first><last>Barbu Mititelu</last></author>
      <author><first>Voula</first><last>Giouli</last></author>
      <author><first>Kilian</first><last>Evang</last></author>
      <author><first>Daniel</first><last>Zeman</last></author>
      <author><first>Petya</first><last>Osenova</last></author>
      <author><first>Carole</first><last>Tiberius</last></author>
      <author><first>Simon</first><last>Krek</last></author>
      <author><first>Stella</first><last>Markantonatou</last></author>
      <author><first>Ivelina</first><last>Stoyanova</last></author>
      <author><first>Ranka</first><last>Stanković</last></author>
      <author><first>Christian</first><last>Chiarcos</last></author>
      <pages>147–153</pages>
      <abstract>We present ongoing work towards defining a lexicon-corpus interface to serve as a benchmark in the representation of multiword expressions (of various parts of speech) in dedicated lexica and the linking of these entries to their corpus occurrences. The final aim is the harnessing of such resources for the automatic identification of multiword expressions in a text. The involvement of several natural languages aims at the universality of a solution not centered on a particular language, and also accommodating idiosyncrasies. Challenges in the lexicographic description of multiword expressions are discussed, the current status of lexica dedicated to this linguistic phenomenon is outlined, as well as the solution we envisage for creating an ecosystem of interlinked lexica and corpora containing and, respectively, annotated with multiword expressions.</abstract>
      <url hash="1e372b69">2024.mwe-1.19</url>
      <bibkey>barbu-mititelu-etal-2024-multiword</bibkey>
    </paper>
    <paper id="20">
      <title>Annotation of Multiword Expressions in the <fixed-case>SUK</fixed-case> 1.0 Training Corpus of <fixed-case>S</fixed-case>lovene: Lessons Learned and Future Steps</title>
      <author><first>Jaka</first><last>Čibej</last></author>
      <author><first>Polona</first><last>Gantar</last></author>
      <author><first>Mija</first><last>Bon</last></author>
      <pages>154–162</pages>
      <abstract>Recent progress within the UniDive COST Action on the compilation of universal guidelines for the annotation of non-verbal multiword expressions (MWEs) has provided an opportunity to improve and expand the work previously done within the PARSEME COST Action on the annotation of verbal multiword expressions in the SUK 1.0 Training Corpus of Slovene. A segment of the training corpus had already been annotated with verbal MWEs during PARSEME. As a follow-up and part of the New Grammar of Modern Standard Slovene (NSSSS) project, the same segment was annotated with non verbal MWEs, resulting in approximately 6, 500 sentences annotated by at least three annotators (described in Gantar et al., 2019). Since then, the entire SUK 1.0 was also manually annotated with UD part-of-speech tags. In the paper, we present an analysis of the MWE annotations exported from the corpus along with their part-of-speech structures through the lens of Universal Dependencies. We discuss the usefulness of the data in terms of potential insight for the further compilation and fine-tuning of guidelines particularly for non-verbal MWEs, and conclude with our plans for future work.</abstract>
      <url hash="aa0d1477">2024.mwe-1.20</url>
      <bibkey>cibej-etal-2024-annotation</bibkey>
    </paper>
    <paper id="21">
      <title>Light Verb Constructions in <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies for <fixed-case>S</fixed-case>outh <fixed-case>A</fixed-case>sian Languages</title>
      <author><first>Abishek</first><last>Stephen</last></author>
      <author><first>Daniel</first><last>Zeman</last></author>
      <pages>163–177</pages>
      <abstract>We conduct a morphosyntactic investigation into the light verb constructions (LVCs) or the verbo-nominal predicates in South Asian languages. This work spans the Indo-Aryan and Dravidian language families in treebanks based on Universal Dependencies (UD). For the selected languages we show how well the existing annotation guidelines fare for the LVCs. We also reiterate the importance of the core and oblique distinction in UD and how informative it is for making accurate morphosyntactic annotation judgments for such predicates.</abstract>
      <url hash="3b28ad6e">2024.mwe-1.21</url>
      <bibkey>stephen-zeman-2024-light</bibkey>
    </paper>
    <paper id="22">
      <title>Sign of the Times: Evaluating the use of Large Language Models for Idiomaticity Detection</title>
      <author><first>Dylan</first><last>Phelps</last></author>
      <author><first>Thomas M. R.</first><last>Pickard</last></author>
      <author><first>Maggie</first><last>Mi</last></author>
      <author><first>Edward</first><last>Gow-Smith</last></author>
      <author><first>Aline</first><last>Villavicencio</last></author>
      <pages>178–187</pages>
      <abstract>Despite the recent ubiquity of large language models and their high zero-shot prompted performance across a wide range of tasks, it is still not known how well they perform on tasks which require processing of potentially idiomatic language. In particular, how well do such models perform in comparison to encoder-only models fine-tuned specifically for idiomaticity tasks? In this work, we attempt to answer this question by looking at the performance of a range of LLMs (both local and software-as-a-service models) on three idiomaticity datasets: SemEval 2022 Task 2a, FLUTE, and MAGPIE. Overall, we find that whilst these models do give competitive performance, they do not match the results of fine-tuned task-specific models, even at the largest scales (e.g. for GPT-4). Nevertheless, we do see consistent performance improvements across model scale. Additionally, we investigate prompting approaches to improve performance, and discuss the practicalities of using LLMs for these tasks.</abstract>
      <url hash="5bc7839f">2024.mwe-1.22</url>
      <bibkey>phelps-etal-2024-sign</bibkey>
    </paper>
    <paper id="23">
      <title><fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependencies for <fixed-case>S</fixed-case>araiki</title>
      <author><first>Meesum</first><last>Alam</last></author>
      <author><first>Francis</first><last>Tyers</last></author>
      <author><first>Emily</first><last>Hanink</last></author>
      <author><first>Sandra</first><last>Kübler</last></author>
      <pages>188–197</pages>
      <abstract>We present the first treebank of the Saraiki/Siraiki [ISO 639-3 skr] language, using the Universal Dependency annotation scheme (de Marneffe et al., 2021). The treebank currently comprises 587 annotated sentences and 7597 tokens. We explain the most relevant syntactic and morphological features of Saraiki, along with the decision we have made for a range of language specific constructions, namely compounds, verbal structures including light verb and serial verb constructions, and relative clauses.</abstract>
      <url hash="1026f1dc">2024.mwe-1.23</url>
      <bibkey>alam-etal-2024-universal</bibkey>
    </paper>
    <paper id="24">
      <title>Domain-Weighted Batch Sampling for Neural Dependency Parsing</title>
      <author><first>Jacob</first><last>Striebel</last></author>
      <author><first>Daniel</first><last>Dakota</last></author>
      <author><first>Sandra</first><last>Kübler</last></author>
      <pages>198–206</pages>
      <abstract>In neural dependency parsing, as well as in the broader field of NLP, domain adaptation remains a challenging problem. When adapting a parser to a target domain, there is a fundamental tension between the need to make use of out-of-domain data and the need to ensure that syntactic characteristic of the target domain are learned. In this work we explore a way to balance these two competing concerns, namely using domain-weighted batch sampling, which allows us to use all available training data, while controlling the probability of sampling in- and out-of-domain data when constructing training batches. We conduct experiments using ten natural language domains and find that domain-weighted batch sampling yields substantial performance improvements in all ten domains compared to a baseline of conventional randomized batch sampling.</abstract>
      <url hash="8cf4b706">2024.mwe-1.24</url>
      <bibkey>striebel-etal-2024-domain</bibkey>
    </paper>
    <paper id="25">
      <title>Strategies for the Annotation of Pronominalised Locatives in <fixed-case>T</fixed-case>urkic <fixed-case>U</fixed-case>niversal <fixed-case>D</fixed-case>ependency Treebanks</title>
      <author><first>Jonathan</first><last>Washington</last></author>
      <author><first>Çağrı</first><last>Çöltekin</last></author>
      <author><first>Furkan</first><last>Akkurt</last></author>
      <author><first>Bermet</first><last>Chontaeva</last></author>
      <author><first>Soudabeh</first><last>Eslami</last></author>
      <author><first>Gulnura</first><last>Jumalieva</last></author>
      <author><first>Aida</first><last>Kasieva</last></author>
      <author><first>Aslı</first><last>Kuzgun</last></author>
      <author><first>Büşra</first><last>Marşan</last></author>
      <author><first>Chihiro</first><last>Taguchi</last></author>
      <pages>207–219</pages>
      <abstract>As part of our efforts to develop unified Universal Dependencies (UD) guidelines for Turkic languages, we evaluate multiple approaches to a difficult morphosyntactic phenomenon, pronominal locative expressions formed by a suffix -ki. These forms result in multiple syntactic words, with potentially conflicting morphological features, and participating in different dependency relations. We describe multiple approaches to the problem in current (and upcoming) Turkic UD treebanks, and show that none of them offers a solution that satisfies a number of constraints we consider (including constraints imposed by UD guidelines). This calls for a compromise with the ‘least damage’ that should be adopted by most, if not all, Turkic treebanks. Our discussion of the phenomenon and various annotation approaches may also help treebanking efforts for other languages or language families with similar constructions.</abstract>
      <url hash="1c2219f8">2024.mwe-1.25</url>
      <bibkey>washington-etal-2024-strategies</bibkey>
    </paper>
    <paper id="26">
      <title><fixed-case>BERT</fixed-case>-based Idiom Identification using Language Translation and Word Cohesion</title>
      <author><first>Arnav</first><last>Yayavaram</last></author>
      <author><first>Siddharth</first><last>Yayavaram</last></author>
      <author><first>Prajna Devi</first><last>Upadhyay</last></author>
      <author><first>Apurba</first><last>Das</last></author>
      <pages>220–230</pages>
      <abstract>An idiom refers to a special type of multi-word expression whose meaning is figurative and cannot be deduced from the literal interpretation of its components. Idioms are prevalent in almost all languages and text genres, necessitating explicit handling by comprehensive NLP systems. Such phrases are referred to as Potentially Idiomatic Expressions (PIEs) and automatically identifying them in text is a challenging task. In this paper, we propose using a BERT-based model fine-tuned with custom objectives, to improve the accuracy of detecting PIEs in text. Our custom loss functions capture two important properties (word cohesion and language translation) to distinguish PIEs from non-PIEs. We conducted several experiments on 7 datasets and showed that incorporating custom objectives while training the model leads to substantial gains. Our models trained using this approach also have better sequence accuracy over DISC, a state-of-the-art PIE detection technique, along with good transfer capabilities.</abstract>
      <url hash="5b0c98a8">2024.mwe-1.26</url>
      <bibkey>yayavaram-etal-2024-bert</bibkey>
    </paper>
    <paper id="27">
      <title>Ad Hoc Compounds for Stance Detection</title>
      <author><first>Qi</first><last>Yu</last></author>
      <author><first>Fabian</first><last>Schlotterbeck</last></author>
      <author><first>Hening</first><last>Wang</last></author>
      <author><first>Naomi</first><last>Reichmann</last></author>
      <author><first>Britta</first><last>Stolterfoht</last></author>
      <author><first>Regine</first><last>Eckardt</last></author>
      <author><first>Miriam</first><last>Butt</last></author>
      <pages>231–242</pages>
      <abstract>In this paper we focus on a subclass of multi-word expressions, namely compound formation in German. The automatic detection of compounds is a known problem and we argue that its resolution should be given more urgency in light of a new role we uncovered with respect to ad hoc compound formation: the systematic expression of attitudinal meaning and its potential importance for the down-stream NLP task of stance detection. We demonstrate that ad hoc compounds in German indeed systematically express attitudinal meaning by adducing corpus linguistic and psycholinguistic experimental data. However, an investigation of state-of-the-art dependency parsers and Universal Dependency treebanks shows that German compounds are parsed and annotated very unevenly, so that currently one cannot reliably identify or access ad hoc compounds with attitudinal meaning in texts. Moreover, we report initial experiments with large language models underlining the challenges in capturing attitudinal meanings conveyed by ad hoc compounds. We consequently suggest a systematized way of annotating (and thereby also parsing) ad hoc compounds that is based on positive experiences from within the multilingual ParGram grammar development effort.</abstract>
      <url hash="9bd57308">2024.mwe-1.27</url>
      <bibkey>yu-etal-2024-ad</bibkey>
    </paper>
  </volume>
</collection>
