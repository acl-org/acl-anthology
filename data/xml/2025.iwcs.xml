<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.iwcs">
  <volume id="1" ingest-date="2025-09-08" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 16th International Conference on Computational Semantics</booktitle>
      <editor><first>Kilian</first><last>Evang</last></editor>
      <editor><first>Laura</first><last>Kallmeyer</last></editor>
      <editor><first>Sylvain</first><last>Pogodalla</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Düsseldorf, Germany</address>
      <month>September</month>
      <year>2025</year>
      <url hash="85413485">2025.iwcs-1</url>
      <venue>iwcs</venue>
      <venue>ws</venue>
      <isbn>979-8-89176-316-6</isbn>
    </meta>
    <frontmatter>
      <url hash="18050fdb">2025.iwcs-1.0</url>
      <bibkey>iwcs-ws-2025-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Advancing the Database of Cross-Linguistic Colexifications with New Workflows and Data</title>
      <author orcid="0000-0003-3678-1817"><first>Annika</first><last>Tjuka</last></author>
      <author orcid="0000-0003-1081-086X"><first>Robert</first><last>Forkel</last><affiliation>Max-Planck Institute for Evolutionary Anthropology</affiliation></author>
      <author orcid="0000-0002-6165-0440"><first>Christoph</first><last>Rzymski</last><affiliation>Max-Planck Institute</affiliation></author>
      <author orcid="0000-0003-2133-8919"><first>Johann-Mattis</first><last>List</last><affiliation>Universität Passau and Max-Planck Institute</affiliation></author>
      <pages>1-15</pages>
      <abstract>Lexical resources are crucial for cross-linguistic analysis and can provide new insights into computational models for natural language learning. Here, we present an advanced database for comparative studies of words with multiple meanings, a phenomenon known as colexification. The new version includes improvements in the handling, selection and presentation of the data. We compare the new database with previous versions and find that our improvements provide a more balanced sample covering more language families worldwide, with enhanced data quality, given that all word forms are provided in phonetic transcription. We conclude that the new Database of Cross-Linguistic Colexifications has the potential to inspire exciting new studies that link cross-linguistic data to open questions in linguistic typology, historical linguistics, psycholinguistics, and computational linguistics.</abstract>
      <url hash="123019bf">2025.iwcs-1.1</url>
      <bibkey>tjuka-etal-2025-advancing</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>FRIDA</fixed-case> to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response</title>
      <author><first>Mollie</first><last>Shichman</last></author>
      <author><first>Claire</first><last>Bonial</last><affiliation>Georgetown University and Army Research Lab</affiliation></author>
      <author><first>Austin</first><last>Blodgett</last></author>
      <author><first>Taylor</first><last>Pellegrin</last></author>
      <author orcid="0000-0003-2413-9368"><first>Francis</first><last>Ferraro</last><affiliation>University of Maryland, Baltimore County</affiliation></author>
      <author><first>Rachel</first><last>Rudinger</last></author>
      <pages>16-29</pages>
      <abstract>During Human Robot Interactions in disaster relief scenarios, Large Language Models (LLMs) have the potential for substantial physical reasoning to assist in mission objectives. However, these reasoning capabilities are often found only in larger models, which are not currently reasonable to deploy on robotic systems due to size constraints. To meet our problem space requirements, we introduce a dataset and pipeline to create Field Reasoning and Instruction Decoding Agent (FRIDA) models. In our pipeline, domain experts and linguists combine their knowledge to make high-quality, few-shot prompts used to generate synthetic data for fine-tuning. We hand-curate datasets for this few-shot prompting and for evaluation to improve LLM reasoning on both general and disaster-specific objects. We concurrently run an ablation study to understand which kinds of synthetic data most affect performance. We fine-tune several small instruction-tuned models and find that ablated FRIDA models only trained on objects’ physical state and function data outperformed both the FRIDA models trained on all synthetic data and the base models in our evaluation. We demonstrate that the FRIDA pipeline is capable of instilling physical common sense with minimal data.</abstract>
      <url hash="6beabcb1">2025.iwcs-1.2</url>
      <bibkey>shichman-etal-2025-frida</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>S</fixed-case>em<fixed-case>T</fixed-case>oken: Semantic-Aware Tokenization for Efficient Long-Context Language Modeling</title>
      <author><first>Dong</first><last>Liu</last><affiliation>University of California, Los Angeles and Yale University</affiliation></author>
      <author><first>Yanxuan</first><last>Yu</last></author>
      <pages>30-39</pages>
      <abstract>Tokenization plays a critical role in language modeling, yet existing approaches such as Byte-Pair Encoding (BPE) or WordPiece operate purely on frequency statistics, ignoring the underlying semantic structure of text. This leads to over-tokenization of semantically redundant spans and underutilization of contextual coherence, particularly in long-context scenarios. In this work, we propose <b>SemToken</b>, a semantic-aware tokenization framework that jointly reduces token redundancy and improves computation efficiency. SemToken first extracts contextual semantic embeddings via lightweight encoders and performs local semantic clustering to merge semantically equivalent tokens. Then, it allocates heterogeneous token granularity based on semantic density, allowing finer-grained tokenization in content-rich regions and coarser compression in repetitive or low-entropy spans. SemToken can be seamlessly integrated with modern language models and attention acceleration methods. Experiments on long-context language modeling benchmarks such as WikiText-103 and LongBench show that SemToken achieves up to <tex-math>2.4\times</tex-math> reduction in token count and <tex-math>1.9\times</tex-math> speedup, with negligible or no degradation in perplexity and downstream accuracy. Our findings suggest that semantic structure offers a promising new axis for optimizing tokenization and computation in large language models.</abstract>
      <url hash="b3224a3d">2025.iwcs-1.3</url>
      <bibkey>liu-yu-2025-semtoken</bibkey>
    </paper>
    <paper id="4">
      <title>ding-01 :<fixed-case>ARG</fixed-case>0: An <fixed-case>AMR</fixed-case> Corpus for Spontaneous <fixed-case>F</fixed-case>rench Dialogue</title>
      <author><first>Jeongwoo</first><last>Kang</last></author>
      <author orcid="0009-0003-0821-5567"><first>Maria</first><last>Boritchev</last><affiliation>Télécom Paris</affiliation></author>
      <author><first>Maximin</first><last>Coavoux</last><affiliation>CNRS</affiliation></author>
      <pages>40-50</pages>
      <abstract>We present our work to build a French semantic corpus by annotating French dialogue in Abstract Meaning Representation (AMR).Specifically, we annotate the DinG corpus, consisting of transcripts of spontaneous French dialogues recorded during the board game Catan. As AMR has insufficient coverage of the dynamics of spontaneous speech, we extend the framework to better represent spontaneous speech and sentence structures specific to French. Additionally, to support consistent annotation, we provide an annotation guideline detailing these extensions. We publish our corpus under a free license (CC-SA-BY). We also train and evaluate an AMR parser on our data. This model can be used as an assistance annotation tool to provide initial annotations that can be refined by human annotators. Our work contributes to the development of semantic resources for French dialogue.</abstract>
      <url hash="bdf2de62">2025.iwcs-1.4</url>
      <bibkey>kang-etal-2025-ding</bibkey>
    </paper>
    <paper id="5">
      <title>A Graph Autoencoder Approach for Gesture Classification with Gesture <fixed-case>AMR</fixed-case></title>
      <author><first>Huma</first><last>Jamil</last><affiliation>Colorado State University</affiliation></author>
      <author><first>Ibrahim</first><last>Khebour</last><affiliation>Colorado State University</affiliation></author>
      <author orcid="0000-0003-2870-7019"><first>Kenneth</first><last>Lai</last><affiliation>Brandeis University and Mass General Brigham</affiliation></author>
      <author orcid="0000-0003-2233-9761"><first>James</first><last>Pustejovsky</last><affiliation>Brandeis University</affiliation></author>
      <author orcid="0000-0001-7878-7227"><first>Nikhil</first><last>Krishnaswamy</last><affiliation>Colorado State University</affiliation></author>
      <pages>51-58</pages>
      <abstract>We present a novel graph autoencoder (GAE) architecture for classifying gestures using Gesture Abstract Meaning Representation (GAMR), a structured semantic annotation framework for gestures in collaborative tasks. We leverage the inherent graphical structure of GAMR by employing Graph Neural Networks (GNNs), specifically an Edge-aware Graph Attention Network (EdgeGAT), to learn embeddings of gesture semantic representations. Using the EGGNOG dataset, which captures diverse physical gesture forms expressing similar semantics, we evaluate our GAE on a multi-label classification task for gestural actions. Results indicate that our approach significantly outperforms naive baselines and is competitive with specialized Transformer-based models like AMRBART, despite using considerably fewer parameters and no pretraining. This work highlights the effectiveness of structured graphical representations in modeling multimodal semantics, offering a scalable and efficient approach to gesture interpretation in situated human-agent collaborative scenarios.</abstract>
      <url hash="70c6bfcb">2025.iwcs-1.5</url>
      <bibkey>jamil-etal-2025-graph</bibkey>
    </paper>
    <paper id="6">
      <title>Retrieval-Augmented Semantic Parsing: Improving Generalization with Lexical Knowledge</title>
      <author orcid="0000-0002-9582-7662"><first>Xiao</first><last>Zhang</last></author>
      <author><first>Qianru</first><last>Meng</last></author>
      <author orcid="0000-0002-9079-5438"><first>Johan</first><last>Bos</last><affiliation>University of Groningen</affiliation></author>
      <pages>59-72</pages>
      <abstract>Open-domain semantic parsing remains a challenging task, as neural models often rely on heuristics and struggle to handle unseen concepts. In this paper, we investigate the potential of large language models (LLMs) for this task and introduce Retrieval-Augmented Semantic Parsing (RASP), a simple yet effective approach that integrates external symbolic knowledge into the parsing process. Our experiments not only show that LLMs outperform previous encoder-decoder baselines for semantic parsing, but that RASP further enhances their ability to predict unseen concepts, nearly doubling the performance of previous models on out-of-distribution concepts. These findings highlight the promise of leveraging large language models and retrieval mechanisms for robust and open-domain semantic parsing.</abstract>
      <url hash="9e756b1b">2025.iwcs-1.6</url>
      <bibkey>zhang-etal-2025-retrieval</bibkey>
    </paper>
    <paper id="7">
      <title>Not Just Who or What: Modeling the Interaction of Linguistic and Annotator Variation in Hateful Word Interpretation</title>
      <author><first>Sanne</first><last>Hoeken</last><affiliation>Universität Bielefeld</affiliation></author>
      <author orcid="0000-0003-1055-8334"><first>Özge</first><last>Alacam</last><affiliation>Bielefeld University</affiliation></author>
      <author><first>Dong</first><last>Nguyen</last><affiliation>Utrecht University</affiliation></author>
      <author orcid="0000-0001-8469-2072"><first>Massimo</first><last>Poesio</last><affiliation>Utrecht University and Queen Mary, University of London</affiliation></author>
      <author orcid="0000-0002-1384-1218"><first>Sina</first><last>Zarrieß</last><affiliation>Bielefeld University</affiliation></author>
      <pages>73-87</pages>
      <abstract>Interpreting whether a word is hateful in context is inherently subjective. While growing research in NLP recognizes the importance of annotation variation and moves beyond treating it as noise, most work focuses primarily on annotator-related factors, often overlooking the role of linguistic context and its interaction with individual interpretation.In this paper, we investigate the factors driving variation in hateful word meaning interpretation by extending the HateWiC dataset with linguistic and annotator-level features. Our empirical analysis shows that variation in annotations is not solely a function of <i>who</i> is interpreting or <i>what</i> is being interpreted, but of the interaction between the two. We evaluate how well models replicate the patterns of human variation. We find that incorporating annotator information can improve alignment with human disagreement but still underestimates it. Our findings further demonstrate that capturing interpretation variation requires modeling the interplay between annotators and linguistic content and that neither surface-level agreement nor predictive accuracy alone is sufficient for truly reflecting human variation.</abstract>
      <url hash="16f2fea7">2025.iwcs-1.7</url>
      <bibkey>hoeken-etal-2025-just</bibkey>
    </paper>
    <paper id="8">
      <title>Evaluating Compositional Generalisation in <fixed-case>VLM</fixed-case>s and Diffusion Models</title>
      <author><first>Beth</first><last>Pearson</last><affiliation>University of Bristol</affiliation></author>
      <author><first>Bilal</first><last>Boulbarss</last><affiliation>University of Amsterdam</affiliation></author>
      <author><first>Michael</first><last>Wray</last><affiliation>University of Bristol</affiliation></author>
      <author orcid="0000-0002-9951-9413"><first>Martha</first><last>Lewis</last><affiliation>University of Amsterdam</affiliation></author>
      <pages>88-98</pages>
      <abstract>A fundamental aspect of the semantics of nat-ural language is that novel meanings can beformed from the composition of previouslyknown parts. Vision-language models (VLMs)have made significant progress in recent years,however, there is evidence that they are unableto perform this kind of composition. For exam-ple, given an image of a red cube and a bluecylinder, a VLM such as CLIP is likely to in-correctly label the image as a red cylinder ora blue cube, indicating it represents the imageas a ‘bag-of-words’ and fails to capture com-positional semantics. Diffusion models haverecently gained significant attention for theirimpressive generative abilities, and zero-shotclassifiers based on diffusion models have beenshown to perform competitively with CLIPin certain compositional tasks. In this workwe explore whether the generative DiffusionClassifier has improved compositional gener-alisation abilities compared to discriminativemodels. We assess three models—DiffusionClassifier, CLIP, and ViLT—on their abilityto bind objects with attributes and relations inboth zero-shot learning (ZSL) and generalisedzero-shot learning (GZSL) settings. Our resultsshow that the Diffusion Classifier and ViLTperform well at concept binding tasks, but thatall models struggle significantly with the re-lational GZSL task, underscoring the broaderchallenges VLMs face with relational reason-ing. Analysis of CLIP embeddings suggeststhat the difficulty may stem from overly similarrepresentations of relational concepts such asleft and right. Code and dataset are availableat: https://github.com/otmive/diffusion_classifier_clip</abstract>
      <url hash="ced18ffc">2025.iwcs-1.8</url>
      <bibkey>pearson-etal-2025-evaluating</bibkey>
    </paper>
    <paper id="9">
      <title>Context Effects on the Interpretation of Complement Coercion: A Comparative Study with Language Models in <fixed-case>N</fixed-case>orwegian</title>
      <author orcid="0009-0003-0492-8703"><first>Matteo</first><last>Radaelli</last></author>
      <author orcid="0000-0001-8742-0451"><first>Emmanuele</first><last>Chersoni</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author orcid="0000-0001-5790-4308"><first>Alessandro</first><last>Lenci</last><affiliation>University of Pisa</affiliation></author>
      <author><first>Giosuè</first><last>Baggio</last><affiliation>Norwegian University of Science and Technology</affiliation></author>
      <pages>99-109</pages>
      <abstract>In complement coercion sentences, like *John began the book*, a covert event (e.g., reading) may be recovered based on lexical meanings, world knowledge, and context. We investigate how context influences coercion interpretation performance for 17 language models (LMs) in Norwegian, a low-resource language. Our new dataset contained isolated coercion sentences (context-neutral), plus the same sentences with a subject NP that suggests a particular covert event and sentences that have a similar effect but that precede or follow the coercion sentence. LMs generally benefit from contextual enrichment, but performance varies depending on the model. Models that struggled in context-neutral sentences showed greater improvements from contextual enrichment. Subject NPs and pre-coercion sentences had the largest effect in facilitating coercion interpretation.</abstract>
      <url hash="6198276c">2025.iwcs-1.9</url>
      <bibkey>radaelli-etal-2025-context</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>LLM</fixed-case>s Struggle with <fixed-case>NLI</fixed-case> for Perfect Aspect: A Cross-Linguistic Study in <fixed-case>C</fixed-case>hinese and <fixed-case>J</fixed-case>apanese</title>
      <author><first>Lu</first><last>Jie</last></author>
      <author orcid="0009-0007-8923-7897"><first>Du</first><last>Jin</last></author>
      <author orcid="0000-0003-0354-6116"><first>Hitomi</first><last>Yanaka</last><affiliation>the University of Tokyo</affiliation></author>
      <pages>110-118</pages>
      <abstract>Unlike English, which uses distinct forms (e.g., had, has, will have) to mark the perfect aspect across tenses, Chinese and Japanese lack sep- arate grammatical forms for tense within the perfect aspect, which complicates Natural Lan- guage Inference (NLI). Focusing on the per- fect aspect in these languages, we construct a linguistically motivated, template-based NLI dataset (1,350 pairs per language). Experi- ments reveal that even advanced LLMs strug- gle with temporal inference, particularly in de- tecting subtle tense and reference-time shifts. These findings highlight model limitations and underscore the need for cross-linguistic evalua- tion in temporal semantics. Our dataset is avail- able at https://github.com/Lujie2001/ CrossNLI.</abstract>
      <url hash="72cc4284">2025.iwcs-1.10</url>
      <bibkey>jie-etal-2025-llms</bibkey>
    </paper>
    <paper id="11">
      <title>Assessing <fixed-case>LLM</fixed-case>s’ Understanding of Structural Contrasts in the Lexicon</title>
      <author><first>Shuxu</first><last>Li</last></author>
      <author><first>Antoine</first><last>Venant</last><affiliation>Université de Montréal</affiliation></author>
      <author orcid="0000-0002-7319-1595"><first>Philippe</first><last>Langlais</last><affiliation>Université de Montréal</affiliation></author>
      <author orcid="0000-0001-7027-0514"><first>François</first><last>Lareau</last><affiliation>Université de Montréal</affiliation></author>
      <pages>119-130</pages>
      <abstract>We present a new benchmark to evaluate the lexical competence of large language models (LLMs), built on a hierarchical classification of lexical functions (LFs) within the Meaning-Text Theory (MTT) framework. Based on a dataset called French Lexical Network (LN-fr), the benchmark employs contrastive tasks to probe the models’ sensitivity to fine-grained paradigmatic and syntagmatic distinctions. Our results show that performance varies significantly across different LFs and systematically declines with increased distinction granularity, highlighting current LLMs’ limitations in relational and structured lexical understanding.</abstract>
      <url hash="f63891a1">2025.iwcs-1.11</url>
      <bibkey>li-etal-2025-assessing-llms</bibkey>
    </paper>
    <paper id="12">
      <title>A <fixed-case>G</fixed-case>erman <fixed-case>WSC</fixed-case> dataset comparing coreference resolution by humans and machines</title>
      <author orcid="0000-0001-6750-5351"><first>Wiebke</first><last>Petersen</last><affiliation>Heinrich-Heine Universität Düsseldorf</affiliation></author>
      <author orcid="0000-0001-7641-7310"><first>Katharina</first><last>Spalek</last></author>
      <pages>131-138</pages>
      <abstract>We present a novel German Winograd-style dataset for direct comparison of human and model behavior in coreference resolution. Ten participants per item provided accuracy, confidence ratings, and response times. Unlike classic WSC tasks, humans select among three pronouns rather than between two potential antecedents, increasing task difficulty. While majority vote accuracy is high, individual responses reveal that not all items are trivial and that variability is obscured by aggregation. Pretrained language models evaluated without fine-tuning show clear performance gaps, yet their accuracy and confidence scores correlate notably with human data, mirroring certain patterns of human uncertainty and error. Dataset-specific limitations, including pragmatic reinterpretations and imbalanced pronoun distributions, highlight the importance of high-quality, balanced resources for advancing computational and cognitive models of coreference resolution.</abstract>
      <url hash="08274890">2025.iwcs-1.12</url>
      <bibkey>petersen-spalek-2025-german</bibkey>
    </paper>
    <paper id="13">
      <title>Finding Answers to Questions: Bridging between Type-based and Computational Neuroscience Approaches</title>
      <author orcid="0000-0002-5459-054X"><first>Staffan</first><last>Larsson</last><affiliation>Göteborg University</affiliation></author>
      <author><first>Jonathan</first><last>Ginzburg</last><affiliation>Stanford University</affiliation></author>
      <author orcid="0000-0002-8133-4592"><first>Robin</first><last>Cooper</last><affiliation>University of Gothenburg</affiliation></author>
      <author orcid="0000-0002-5070-2233"><first>Andy</first><last>Lücking</last><affiliation>Johann Wolfgang Goethe Universität Frankfurt am Main and Université Paris Diderot</affiliation></author>
      <pages>139-147</pages>
      <abstract>The paper outlines an account of how the brain might process questions and answers in linguistic interaction, focusing on accessing answers in memory and combining questions and answers into propositions. To enable this, we provide an approximation of the lambda calculus implemented in the Semantic Pointer Architecture (SPA), a neural implementation of a Vector Symbolic Architecture. The account builds a bridge between the type-based accounts of propositions in memory (as in the treatments of belief by Ranta (1994) and Cooper (2023) and the suggestion for question answering made by Eliasmith (2013) question answering is described in terms of transformations of structured representations in memory providing an answer. We will take such representations to correspond to beliefs of the agent. On Cooper’s analysis, beliefs are considered to be types which have a record structure closely related to the structure which Eliasmith codes in vector representations (Larsson et al, 2023). Thus the act of answering a question can be seen to have a neural base in a vector transformation translatable in Eliasmith’s system to activity of spiking neurons and to correspond to using an item in memory (abelief) to provide an answer to the question.</abstract>
      <url hash="95bb18b6">2025.iwcs-1.13</url>
      <bibkey>larsson-etal-2025-finding</bibkey>
    </paper>
    <paper id="14">
      <title>Can Large Language Models Robustly Perform Natural Language Inference for <fixed-case>J</fixed-case>apanese Comparatives?</title>
      <author><first>Yosuke</first><last>Mikami</last></author>
      <author><first>Daiki</first><last>Matsuoka</last></author>
      <author orcid="0000-0003-0354-6116"><first>Hitomi</first><last>Yanaka</last><affiliation>the University of Tokyo</affiliation></author>
      <pages>148-157</pages>
      <abstract>Large Language Models (LLMs) perform remarkably well in Natural Language Inference (NLI).However, NLI involving numerical and logical expressions remains challenging.Comparatives are a key linguistic phenomenon related to such inference, but the robustness of LLMs in handling them, especially in languages that are not dominant in the models’ training data, such as Japanese, has not been sufficiently explored.To address this gap, we construct a Japanese NLI dataset that focuses on comparatives and evaluate various LLMs in zero-shot and few-shot settings.Our results show that the performance of the models is sensitive to the prompt formats in the zero-shot setting and influenced by the gold labels in the few-shot examples.The LLMs also struggle to handle linguistic phenomena unique to Japanese.Furthermore, we observe that prompts containing logical semantic representations help the models predict the correct labels for inference problems that they struggle to solve even with few-shot examples.</abstract>
      <url hash="1f5bc819">2025.iwcs-1.14</url>
      <bibkey>mikami-etal-2025-large</bibkey>
    </paper>
    <paper id="15">
      <title>Is neural semantic parsing good at ellipsis resolution, or isn’t it?</title>
      <author orcid="0000-0002-9582-7662"><first>Xiao</first><last>Zhang</last></author>
      <author orcid="0000-0002-9079-5438"><first>Johan</first><last>Bos</last><affiliation>University of Groningen</affiliation></author>
      <pages>158-163</pages>
      <abstract>Neural semantic parsers have shown good overall performance for a variety of linguistic phenomena, reaching semantic matching scores of more than 90%. But how do such parsers perform on strongly context-sensitive phenomena, where large pieces of semantic information need to be duplicated to form a meaningful semantic representation? A case in point is English verb phrase ellipsis, a construct where entire verb phrases can be abbreviated by a single auxiliary verb. Are the otherwise known as powerful semantic parsers able to deal with ellipsis or aren’t they? We constructed a corpus of 120 cases of ellipsis with their fully resolved meaning representation and used this as a challenge set for a large battery of neural semantic parsers. Although these parsers performed very well on the standard test set, they failed in the instances with ellipsis. Data augmentation helped improve the parsing results. The reason for the difficulty of parsing elided phrases is not that copying semantic material is hard, but that usually occur in linguistically complicated contexts causing most of the parsing errors.</abstract>
      <url hash="6d3c557e">2025.iwcs-1.15</url>
      <bibkey>zhang-bos-2025-neural</bibkey>
    </paper>
    <paper id="16">
      <title>Extracting Behaviors from <fixed-case>G</fixed-case>erman Clinical Interviews in Support of Autism Spectrum Diagnosis</title>
      <author><first>Margareta A.</first><last>Kulcsar</last></author>
      <author><first>Ian Paul</first><last>Grant</last></author>
      <author orcid="0000-0001-8469-2072"><first>Massimo</first><last>Poesio</last><affiliation>Utrecht University and Queen Mary, University of London</affiliation></author>
      <pages>164-176</pages>
      <abstract>Accurate identification of behaviors is essential for diagnosing developmental disorders such as Autism Spectrum Disorder (ASD). We frame the extraction of behaviors from text as a specialized form of event extraction grounded in the TimeML framework and evaluate two approaches: a pipeline model and an end-to-end model that directly extracts behavior spans from raw text. We introduce two novel datasets: a new clinical annotation of an existing Reddit corpus of parent-authored posts in English and a clinically annotated corpus of German ASD diagnostic interviews. On the English dataset, the end-to-end BERT model achieved an F1 score of 73.4% in behavior classification, outperforming the pipeline models (F1: 66.8% and 53.65%). On the German clinical dataset, the end-to-end model reached an even higher F1 score of 80.1%, again outperforming the pipeline (F1: 78.7%) and approaching the gold-annotated upper bound (F1: 92.9%). These results demonstrate that behavior classification benefits from direct extraction, and that our method generalizes across domains and languages.</abstract>
      <url hash="2eb1f79f">2025.iwcs-1.16</url>
      <bibkey>kulcsar-etal-2025-extracting</bibkey>
    </paper>
    <paper id="17">
      <title>The Proper Treatment of Verbal Idioms in <fixed-case>G</fixed-case>erman Discourse Representation Structure Parsing</title>
      <author><first>Kilian</first><last>Evang</last><affiliation>Heinrich Heine University Düsseldorf</affiliation></author>
      <author><first>Rafael</first><last>Ehren</last><affiliation>Heinrich Heine University Düsseldorf</affiliation></author>
      <author><first>Laura</first><last>Kallmeyer</last><affiliation>Heinrich Heine University Düsseldorf</affiliation></author>
      <pages>177-186</pages>
      <abstract>Existing datasets for semantic parsing lack adequate representations of potentially idiomatic expressions (PIEs), i.e., expressions consisting of two or more lexemes that can occur with either a literal or an idiomatic reading. As a result, we cannot test semantic parsers for their ability to correctly distinguish between the two cases, and to assign appropriate meaning representations. We address this situation by combining two semantically annotated resources to obtain a corpus of German sentences containing literal and idiomatic occurrences of PIEs, paired with meaning representations whose concepts and roles reflect the respective literal or idiomatic meaning. Experiments with a state-of-the-art semantic parser show that given appropriate training data, it can learn to predict the idiomatic meanings and improve performance also for literal readings, even though predicting the correct concepts in context remains challenging. We provide additional insights through evaluation on synthetic data.</abstract>
      <url hash="5623c7d8">2025.iwcs-1.17</url>
      <bibkey>evang-etal-2025-proper</bibkey>
    </paper>
    <paper id="18">
      <title>Does discourse structure help action prediction? A look at Correction Triangles.</title>
      <author><first>Kate</first><last>Thompson</last></author>
      <author><first>Akshay</first><last>Chaturvedi</last><affiliation>IRIT, Toulouse, France</affiliation></author>
      <author><first>Nicholas</first><last>Asher</last><affiliation>CNRS</affiliation></author>
      <pages>187-195</pages>
      <abstract>An understanding of natural language corrections is essential for artificial agents that are meant to collaborate and converse with humans. We present some preliminary experiments using language-to-action models investigating whether discourse structure, in particular Correction relations, improves the action prediction capabilities of language-to-action models for simple block world tasks. We focus on scenarios in which a model must correct a previous action, and present a corpus of synthetic dialogues to help explain model performance.</abstract>
      <url hash="948c5f54">2025.iwcs-1.18</url>
      <bibkey>thompson-etal-2025-discourse</bibkey>
    </paper>
    <paper id="19">
      <title><fixed-case>FAMWA</fixed-case>: A new taxonomy for classifying word associations (which humans improve at but <fixed-case>LLM</fixed-case>s still struggle with)</title>
      <author><first>Maria</first><last>A. Rodriguez</last><affiliation>University of Fribourg and HSLU - Lucerne University of Applied Sciences and Arts</affiliation></author>
      <author orcid="0000-0001-8306-4859"><first>Marie</first><last>Candito</last><affiliation>Université Paris Cité</affiliation></author>
      <author><first>Richard</first><last>Huyghe</last><affiliation>University of Fribourg</affiliation></author>
      <pages>196-209</pages>
      <abstract>Word associations have a longstanding tradition of being instrumental for investigating the organization of the mental lexicon. Despite their wide application in psychology and psycholinguistics, analyzing word associations remains challenging due to their inherent heterogeneity and variability, shaped by linguistic and extralinguistic factors. Existing word-association taxonomies often suffer limitations due to a lack of comprehensive frameworks that capture their complexity.To address these limitations, we introduce a linguistically motivated taxonomy consisting of co-existing meaning-related and form-related relations, while accounting for the directionality of word associations.We applied the taxonomy to a dataset of 1,300 word associations (FAMWA) and assessed it using various LLMs, analyzing their ability to classify word associations.The results show an improved inter-annotator agreement for our taxonomies compared to previous studies (<tex-math>\kappa</tex-math> = .60 for meaning and <tex-math>\kappa</tex-math> = .58 for form). However, models such as GPT-4o perform only modestly in relation labeling (with accuracies of 46.2% for meaning and 78.3% for form), which calls into question their ability to fully grasp the underlying principles of human word associations.</abstract>
      <url hash="3cfa2cf2">2025.iwcs-1.19</url>
      <bibkey>a-rodriguez-etal-2025-famwa</bibkey>
    </paper>
    <paper id="20">
      <title>Computational Semantics Tools for Glue Semantics</title>
      <author><first>Mark-Matthias</first><last>Zymla</last></author>
      <author><first>Mary</first><last>Dalrymple</last><affiliation>University of Oxford</affiliation></author>
      <author orcid="0000-0002-2367-9170"><first>Agnieszka</first><last>Patejuk</last><affiliation>Institute of Computer Science, Polish Academy of Sciences</affiliation></author>
      <pages>210-228</pages>
      <abstract>This paper introduces a suite of computational semantic tools for Glue Semantics, an approach to compositionality developed in the context of Lexical Functional Grammar (LFG), but applicable to a variety of syntactic representations, including Universal Dependencies (UD). The three tools are: 1) a Glue Semantics prover, 2) an interface between this prover and a platform for implementing LFG grammars, and 3) a system to rewrite and add semantic annotations to LFG and UD syntactic analyses, with a native support for the prover. The main use of these tools is computational verification of theoretical linguistic analyses, but they have also been used for teaching formal semantic concepts.</abstract>
      <url hash="cc675c20">2025.iwcs-1.20</url>
      <bibkey>zymla-etal-2025-computational</bibkey>
    </paper>
    <paper id="21">
      <title>Which Model Mimics Human Mental Lexicon Better? A Comparative Study of Word Embedding and Generative Models</title>
      <author orcid="0009-0007-9915-3398"><first>Huacheng</first><last>Song</last></author>
      <author><first>Zhaoxin</first><last>Feng</last></author>
      <author orcid="0000-0001-8742-0451"><first>Emmanuele</first><last>Chersoni</last><affiliation>The Hong Kong Polytechnic University</affiliation></author>
      <author orcid="0000-0002-8526-5520"><first>Chu-Ren</first><last>Huang</last></author>
      <pages>229-251</pages>
      <abstract>Word associations are commonly applied in psycholinguistics to investigate the nature and structure of the human mental lexicon, and at the same time an important data source for measuring the alignment of language models with human semantic representations.Taking this view, we compare the capacities of different language models to model collective human association norms via five word association tasks (WATs), with predictions about associations driven by either word vector similarities for traditional embedding models or prompting large language models (LLMs).Our results demonstrate that neither approach could produce human-like performances in all five WATs. Hence, none of them can successfully model the human mental lexicon yet. Our detailed analysis shows that static word-type embeddings and prompted LLMs have overall better alignment with human norms compared to word-token embeddings from pretrained models like BERT. Further analysis suggests that the performance discrepancies may be due to different model architectures, especially in terms of approximating human-like associative reasoning through either semantic similarity or relatedness evaluation. Our codes and data are publicly available at: https://github.com/florethsong/word_association.</abstract>
      <url hash="958f65fa">2025.iwcs-1.21</url>
      <bibkey>song-etal-2025-model</bibkey>
    </paper>
    <paper id="22">
      <title>Semantic Analysis Experiments for <fixed-case>F</fixed-case>rench Citizens’ Contribution : Combinations of Language Models and Community Detection Algorithms</title>
      <author><first>Sami</first><last>Guembour</last></author>
      <author><first>Dominguès</first><last>Dominguès</last><affiliation>Institut national de l’information géographique et forestière</affiliation></author>
      <author><first>Sabine</first><last>Ploux</last><affiliation>NA</affiliation></author>
      <pages>252-262</pages>
      <abstract>Following the Yellow Vest crisis that occurred in France in 2018, the French government launched the Grand Débat National, which gathered citizens’ contributions.This paper presents a semantic analysis of these contributions by segmenting them into sentences and identifying the topics addressed using clustering techniques. The study tests several combinations of French language models and community detection algorithms, aiming to identify the most effective pairing for grouping sentences based on thematic similarity. Performance is evaluated using the number of clusters generated and standard clustering metrics.Principal Component Analysis (PCA) is employed to assess the impact of dimensionality reduction on sentence embeddings and clustering quality. Cluster merging methods are also developed to reduce redundancy and improve the relevance of the identified topics.Finally, the results help refine semantic analysis and shed light on the main concerns expressed by citizens.</abstract>
      <url hash="cba81552">2025.iwcs-1.22</url>
      <bibkey>guembour-etal-2025-semantic</bibkey>
    </paper>
    <paper id="23">
      <title>Neurosymbolic <fixed-case>AI</fixed-case> for Natural Language Inference in <fixed-case>F</fixed-case>rench : combining <fixed-case>LLM</fixed-case>s and theorem provers for semantic parsing and natural language reasoning</title>
      <author orcid="0000-0003-2361-5115"><first>Maximos</first><last>Skandalis</last></author>
      <author><first>Lasha</first><last>Abzianidze</last><affiliation>Utrecht University</affiliation></author>
      <author><first>Richard</first><last>Moot</last><affiliation>CNRS and LIRMM</affiliation></author>
      <author orcid="0000-0002-2401-9158"><first>Christian</first><last>Retoré</last></author>
      <author><first>Simon</first><last>Robillard</last><affiliation>NA</affiliation></author>
      <pages>263-274</pages>
      <abstract>In this article, we describe the first comprehensive neurosymbolic pipeline for the task of Natural Language Inference (NLI) for French, with the synergy of Large Language Models (CamemBERT) and automated theorem provers (GrailLight, LangPro). LLMs prepare the input for GrailLight by tagging each token with Part-of-Speech and grammatical information based on the Type-Logical Grammar formalism. GrailLight then produces the lambda-terms given as input to the LangPro theorem prover, a tableau-based theorem prover for natural logic originally developped for English. Currently, the proposed system works on the French version of SICK dataset. The results obtained are comparable to the ones on the English and Dutch versions of SICK with the same LangPro theorem prover, and are better than the results of recent transformers on this specific dataset.Finally, we have identified ways to further improve the results obtained, such as giving access to the theorem prover to lexical knowledge via a knowledge base for French.</abstract>
      <url hash="06bb0b14">2025.iwcs-1.23</url>
      <bibkey>skandalis-etal-2025-neurosymbolic</bibkey>
    </paper>
    <paper id="24">
      <title><fixed-case>P</fixed-case>ro<fixed-case>P</fixed-case>ara-<fixed-case>CRTS</fixed-case>: Canonical Referent Tracking for Reliable Evaluation of Entity State Tracking in Process Narratives</title>
      <author><first>Bingyang</first><last>Ye</last></author>
      <author orcid="0009-0004-9561-4124"><first>Timothy</first><last>Obiso</last><affiliation>Brandeis University</affiliation></author>
      <author><first>Jingxuan</first><last>Tu</last></author>
      <author orcid="0000-0003-2233-9761"><first>James</first><last>Pustejovsky</last><affiliation>Brandeis University</affiliation></author>
      <pages>275-289</pages>
      <abstract>Despite the abundance of datasets for procedural texts such as cooking recipes, resources that capture full process narratives, paragraph-long descriptions that follow how multiple entities evolve across a sequence of steps, remain scarce.Although synthetic resources offer useful toy settings, they fail to capture the linguistic variability of naturally occurring prose. ProPara remains the only sizeable, naturally occurring corpus of process narratives, yet ambiguities and inconsistencies in its schema and annotations hinder reliable evaluation of its core task Entity State Tracking (EST).In this paper, we introduce a Canonical Referent Tracking Schema (CRTS) that assigns every surface mention to a unique, immutable discourse referent and records that referent’s existence and location at each step. Applying CRTS to ProPara, we release the re-annotated result as ProPara-CRTS. The new corpus resolves ambiguous participant mentions in ProPara and consistently boosts performance across a variety of models.This suggests that principled schema design and targeted re-annotation can unlock measurable improvements in EST, providing a sharper diagnostic of model capacity in process narratives understanding without any changes to model architecture.</abstract>
      <url hash="f9accf7b">2025.iwcs-1.24</url>
      <bibkey>ye-etal-2025-propara</bibkey>
    </paper>
    <paper id="25">
      <title>The Difficult Case of Intended and Perceived Sarcasm: a Challenge for Humans and Large Language Models</title>
      <author orcid="0009-0004-0346-4633"><first>Hyewon</first><last>Jang</last><affiliation>Göteborg University</affiliation></author>
      <author orcid="0000-0002-1517-2185"><first>Diego</first><last>Frassinelli</last><affiliation>Ludwig-Maximilians-Universität München</affiliation></author>
      <pages>290-302</pages>
      <abstract>We examine the cases of failed communication in sarcasm, defined as ‘the discrepancy between what speakers and observers perceive as sarcasm’. We identify factors that are associated with such failures, and how those difficult instances affect the detection performance of encoder-only and decoder-only generative models. We find that speakers’ incongruity between their felt annoyance and sarcasm in their utterance is highly correlated with sarcasm that fails to be communicated to human observers. This factor also relates to the drop of classification performance of large language models (LLMs). Additionally, disagreement among multiple observers about sarcasm is correlated with poorer performance of LLMs. Finally, we find that generative models produce better results with ground-truth labels from speakers than from observers, in contrast to encoder-only models, which suggests a general tendency by generative models to identify with speakers’ perspective by default.</abstract>
      <url hash="27ce0e9b">2025.iwcs-1.25</url>
      <bibkey>jang-frassinelli-2025-difficult</bibkey>
    </paper>
    <paper id="26">
      <title>A Model of Information State in Situated Multimodal Dialogue</title>
      <author orcid="0000-0003-2870-7019"><first>Kenneth</first><last>Lai</last><affiliation>Brandeis University and Mass General Brigham</affiliation></author>
      <author orcid="0000-0002-5974-7454"><first>Lucia</first><last>Donatelli</last><affiliation>Vrije Universiteit Amsterdam</affiliation></author>
      <author><first>Richard</first><last>Brutti</last><affiliation>Brandeis University</affiliation></author>
      <author orcid="0000-0003-2233-9761"><first>James</first><last>Pustejovsky</last><affiliation>Brandeis University</affiliation></author>
      <pages>303-309</pages>
      <abstract>In a successful dialogue, participants come to a mutual understanding of the content being communicated through a process called conversational grounding. This can occur through language, and also via other communicative modalities like gesture. Other kinds of actions also give information as to what has been understood from the dialogue. Moreover, achieving common ground not only involves establishing agreement on a set of facts about discourse referents, but also agreeing on what those entities refer to in the outside world, i.e., situated grounding. We use examples from a corpus of multimodal interaction in a task-based setting, annotated with Abstract Meaning Representation (AMR), to explore how speech, gesture, and action contribute to the construction of common ground. Using a simple model of information state, we discuss ways in which existing annotation schemes facilitate this analysis, as well as information that current annotations do not yet capture. Our research sheds light on the interplay between language, gesture, and action in multimodal communication.</abstract>
      <url hash="cfd5cbbb">2025.iwcs-1.26</url>
      <bibkey>lai-etal-2025-model</bibkey>
    </paper>
    <paper id="27">
      <title>Learning to Refer: How Scene Complexity Affects Emergent Communication in Neural Agents</title>
      <author><first>Dominik</first><last>Künkele</last><affiliation>Independent</affiliation></author>
      <author orcid="0000-0002-4019-7966"><first>Simon</first><last>Dobnik</last><affiliation>University of Gothenburg</affiliation></author>
      <pages>310-318</pages>
      <abstract>We explore how neural network-based agents learn to map continuous sensory input to discrete linguistic symbols through interactive language games. One agent describes objects in 3D scenes using invented vocabulary; the other interprets references based on attributes like shape, color, and size. Learning is guided by feedback from successful interactions. We extend the CLEVR dataset with more complex scenes to study how increased referential complexity impacts language acquisition and symbol grounding in artificial agents.</abstract>
      <url hash="af7fd811">2025.iwcs-1.27</url>
      <bibkey>kunkele-dobnik-2025-learning</bibkey>
    </paper>
    <paper id="28">
      <title>On the Role of Linguistic Features in <fixed-case>LLM</fixed-case> Performance on Theory of Mind Tasks</title>
      <author><first>Ekaterina</first><last>Kozachenko</last><affiliation>Université de Lorraine</affiliation></author>
      <author><first>Gonçalo</first><last>Guiomar</last><affiliation>ETHZ - ETH Zurich and , University of Zurich</affiliation></author>
      <author orcid="0000-0001-7326-9594"><first>Karolina</first><last>Stanczak</last><affiliation>ETHZ - ETH Zurich and McGill University, McGill University</affiliation></author>
      <pages>319-327</pages>
      <abstract>Theory of Mind presents a fundamental challenge for Large Language Models (LLMs), revealing gaps in processing intensional contexts where beliefs diverge from reality. We analyze six LLMs across 2,860 annotated stories, measuring factors such as idea density, mental state verb distribution, and perspectival complexity markers. Notably, and in contrast to humans, we find that LLMs show positive correlations with linguistic complexity. In fact, they achieve high accuracy (74-95%) on high complexity stories with explicit mental state scaffolding, yet struggle with low complexity tasks requiring implicit reasoning (51-77%). Furthermore, we find that linguistic markers systematically influence performance, with contrast markers decreasing accuracy by 5-9% and knowledge verbs increasing it by 4-10%. This inverse relationship between linguistic complexity and performance, contrary to human cognition, may suggest that current LLMs rely on surface-level linguistic cues rather than genuine mental state reasoning.</abstract>
      <url hash="c7e47423">2025.iwcs-1.28</url>
      <bibkey>kozachenko-etal-2025-role</bibkey>
    </paper>
    <paper id="29">
      <title>Mapping Semantic Domains Across <fixed-case>I</fixed-case>ndia’s Social Media: Networks, Geography, and Social Factors</title>
      <author><first>Gunjan</first><last>Anand</last><affiliation>University of Illinois at Urbana-Champaign</affiliation></author>
      <author orcid="0000-0002-1189-1908"><first>Jonathan</first><last>Dunn</last><affiliation>University of Illinois Urbana-Champaign</affiliation></author>
      <pages>328-341</pages>
      <abstract>This study examines socially-conditioned variation within semantic domains like kinship and weather using thirteen Indian cities as a case-study. Using bilingual social media data, we infer six semantic domains from corpora representing individual cities with a lexicon including terms from English, Hindi and Transliterated Hindi. The process of inferring semantic domains uses character-based embeddings to retrieve nearest neighbors and Jaccard similarity to operationalize the edge weights between lexical items within each domain. These representations reveal distinct regional variation across all six domains. We then examine the relationship between variation in semantic domains and external social factors such as literacy rates and local demographics. The results show that semantic domains exhibit systematic influences from sociolinguistic factors, a finding that has significant implications for the idea that semantic domains can be studied as abstractions distinct from specific speech communities.</abstract>
      <url hash="e7874604">2025.iwcs-1.29</url>
      <bibkey>anand-dunn-2025-mapping</bibkey>
    </paper>
    <paper id="30">
      <title>Disentangling lexical and grammatical information in word embeddings</title>
      <author><first>Li</first><last>Liu</last><affiliation>Université de Montréal</affiliation></author>
      <author orcid="0000-0001-7027-0514"><first>François</first><last>Lareau</last><affiliation>Université de Montréal</affiliation></author>
      <pages>342-351</pages>
      <abstract>To enable finer-grained linguistic analysis, we propose a method for the separation of lexical and grammatical information within contextualized word embeddings. Using CamemBERT embeddings for French, we apply our method to 14,472 inflected word forms extracted from the Lexical Network of French ( LN-fr ), covering 1,468 nouns, 202 adjectives and 299 verbs inflected via 14 distinct grammatical feature values. Our iterative distillation alternates two steps until convergence: (i) estimating lexical or grammatical vectors by averaging the embeddings of words that share the same lexeme or grammatical feature value, and (ii) isolating the complementary component of each word embedding by subtracting the estimated vector. To assess the quality of the decomposition, we measure whether the resulting lexical and grammatical vectors form more compact clusters within their respective groups and whether their sum better reconstructs the original word embeddings. All evaluations rely on L2 distance. The observed improvements in both clustering and reconstruction accuracy demonstrate the effectiveness of our approach.</abstract>
      <url hash="86bb6310">2025.iwcs-1.30</url>
      <bibkey>liu-lareau-2025-disentangling</bibkey>
    </paper>
  </volume>
  <event id="iwcs-2025">
    <colocated>
      <volume-id>2025.isa-1</volume-id>
    </colocated>
  </event>
</collection>
