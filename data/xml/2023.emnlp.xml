<?xml version='1.0' encoding='UTF-8'?>
<collection id="2023.emnlp">
  <volume id="tutorial" ingest-date="2023-11-25" type="proceedings">
    <meta>
      <booktitle>The 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts</booktitle>
      <editor><first>Qi</first><last>Zhang</last></editor>
      <editor><first>Hassan</first><last>Sajjad</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Singapore</address>
      <month>December</month>
      <year>2023</year>
      <url hash="db1fcf67">2023.emnlp-tutorial</url>
      <venue>emnlp</venue>
    </meta>
    <frontmatter>
      <url hash="713d6ee4">2023.emnlp-tutorial.0</url>
      <bibkey>emnlp-2023-2023</bibkey>
    </frontmatter>
    <paper id="1">
      <title><fixed-case>NLP</fixed-case>+<fixed-case>V</fixed-case>is: <fixed-case>NLP</fixed-case> Meets Visualization</title>
      <author><first>Shafiq</first><last>Joty</last></author>
      <author><first>Enamul</first><last>Hoque</last></author>
      <author><first>Jesse</first><last>Vig</last></author>
      <pages>1-6</pages>
      <abstract>Natural language and visualization (Vis) are two powerful modalities of human communication. The goal of this tutorial is to push forward the agenda of tightly integrating these two modalities. To this end, the tutorial will introduce NLP+Vis with a focus on two main threads of work: <i>(i) NLP for Vis:</i> How to develop and adapt state-of-the-art NLP models for solving various visualization tasks? and <i>(ii) Vis for NLP:</i> How to leverage visualization techniques to interpret and explain complex NLP models effectively? The tutorial will first motivate why NLP+Vis is an important area of research and provide an overview of research topics on combining NLP and Vis techniques. Then an overview of state-of-the-art deep learning models for NLP will be covered. Next, we will provide an overview of applying visualization techniques to help make NLP models more interpretable and explainable. In the final part, we will focus on various application tasks at the intersection of NLP and Vis. We will conclude with an interactive discussion of future challenges for NLP+Vis applications. The audience will include researchers interested in applying NLP for visualizations as well as others who focus more generally at the intersection of machine learning and visualization.</abstract>
      <url hash="b4f4e1de">2023.emnlp-tutorial.1</url>
      <bibkey>joty-etal-2023-nlp</bibkey>
    </paper>
    <paper id="2">
      <title>Security Challenges in Natural Language Processing Models</title>
      <author><first>Qiongkai</first><last>Xu</last></author>
      <author><first>Xuanli</first><last>He</last></author>
      <pages>7-12</pages>
      <abstract>Large-scale natural language processing models have been developed and integrated into numerous applications, given the advantage of their remarkable performance. Nonetheless, the security concerns associated with these models prevent the widespread adoption of these black-box machine learning models. In this tutorial, we will dive into three emerging security issues in NLP research, i.e., backdoor attacks, private data leakage, and imitation attacks. These threats will be introduced in accordance with their threatening usage scenarios, attack methodologies, and defense technologies.</abstract>
      <url hash="49353684">2023.emnlp-tutorial.2</url>
      <bibkey>xu-he-2023-security</bibkey>
    </paper>
    <paper id="3">
      <title>Designing, Evaluating, and Learning from Humans Interacting with <fixed-case>NLP</fixed-case> Models</title>
      <author><first>Tongshuang</first><last>Wu</last></author>
      <author><first>Diyi</first><last>Yang</last></author>
      <author><first>Sebastin</first><last>Santy</last></author>
      <pages>13-18</pages>
      <abstract/>
      <url hash="64c118bf">2023.emnlp-tutorial.3</url>
      <bibkey>wu-etal-2023-designing</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>LLM</fixed-case>-driven Instruction Following: Progresses and Concerns</title>
      <author><first>Wenpeng</first><last>Yin</last></author>
      <author><first>Qinyuan</first><last>Ye</last></author>
      <author><first>Pengfei</first><last>Liu</last></author>
      <author><first>Xiang</first><last>Ren</last></author>
      <author><first>Hinrich</first><last>Schütze</last></author>
      <pages>19-25</pages>
      <abstract>The progress of natural language processing (NLP) is primarily driven by machine learning that optimizes a system on a large-scale set of task-specific labeled examples. This learning paradigm limits the ability of machines to have the same capabilities as humans in handling new tasks since humans can often solve unseen tasks with a couple of examples accompanied by task instructions. In addition, we may not have a chance to prepare task-specific examples of large-volume for new tasks because we cannot foresee what task needs to be addressed next and how complex to annotate for it. Therefore, task instructions act as a novel and promising resource for supervision. This tutorial targets researchers and practitioners who are interested in AI and ML technologies for NLP generalization in a low-shot scenario. In particular, we will present a diverse thread of instruction-driven NLP studies that try to answer the following questions: (i) What is task instruction? (ii) How is the process of creating datasets and evaluating systems conducted? (iii) How to encode task instructions? (iv) When and why do some instructions work better? (v) What concerns remain in LLM-driven instruction following? We will discuss several lines of frontier research that tackle those challenges and will conclude the tutorial by outlining directions for further investigation.</abstract>
      <url hash="2d27f490">2023.emnlp-tutorial.4</url>
      <bibkey>yin-etal-2023-llm</bibkey>
    </paper>
    <paper id="5">
      <title>Mitigating Societal Harms in Large Language Models</title>
      <author><first>Sachin</first><last>Kumar</last></author>
      <author><first>Vidhisha</first><last>Balachandran</last></author>
      <author><first>Lucille</first><last>Njoo</last></author>
      <author><first>Antonios</first><last>Anastasopoulos</last></author>
      <author><first>Yulia</first><last>Tsvetkov</last></author>
      <pages>26-33</pages>
      <abstract>Numerous recent studies have highlighted societal harms that can be caused by language technologies deployed in the wild. While several surveys, tutorials, and workshops have discussed the risks of harms in specific contexts – e.g., detecting and mitigating gender bias in NLP models – no prior work has developed a unified typology of technical approaches for mitigating harms of language generation models. Our tutorial is based on a survey we recently wrote that proposes such a typology. We will provide an overview of potential social issues in language generation, including toxicity, social biases, misinformation, factual inconsistency, and privacy violations. Our primary focus will be on how to systematically identify risks, and how eliminate them at various stages of model development, from data collection, to model development, to inference/language generation. Through this tutorial, we aim to equip NLP researchers and engineers with a suite of practical tools for mitigating safety risks from pretrained language generation models.</abstract>
      <url hash="fdbfec94">2023.emnlp-tutorial.5</url>
      <bibkey>kumar-etal-2023-mitigating</bibkey>
    </paper>
    <paper id="6">
      <title>Creative Natural Language Generation</title>
      <author><first>Tuhin</first><last>Chakrabarty</last></author>
      <author><first>Vishakh</first><last>Padmakumar</last></author>
      <author><first>He</first><last>He</last></author>
      <author><first>Nanyun</first><last>Peng</last></author>
      <pages>34-40</pages>
      <abstract/>
      <url hash="6972fb41">2023.emnlp-tutorial.6</url>
      <bibkey>chakrabarty-etal-2023-creative</bibkey>
    </paper>
  </volume>
</collection>
