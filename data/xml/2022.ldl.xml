<?xml version='1.0' encoding='UTF-8'?>
<collection id="2022.ldl">
  <volume id="1" ingest-date="2022-09-23" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 8th Workshop on Linked Data in Linguistics within the 13th Language Resources and Evaluation Conference</booktitle>
      <editor><first>Thierry</first><last>Declerck</last></editor>
      <editor><first>John P.</first><last>McCrae</last></editor>
      <editor><first>Elena</first><last>Montiel</last></editor>
      <editor><first>Christian</first><last>Chiarcos</last></editor>
      <editor><first>Maxim</first><last>Ionov</last></editor>
      <publisher>European Language Resources Association</publisher>
      <address>Marseille, France</address>
      <month>June</month>
      <year>2022</year>
      <url hash="8d0114aa">2022.ldl-1</url>
      <venue>ldl</venue>
    </meta>
    <frontmatter>
      <url hash="2cc5bd02">2022.ldl-1.0</url>
      <bibkey>ldl-2022-linked</bibkey>
    </frontmatter>
    <paper id="1">
      <title>The Annohub Web Portal</title>
      <author><first>Frank</first><last>Abromeit</last></author>
      <pages>1–6</pages>
      <abstract>We introduce the Annohub web portal, specialized on metadata for annotated language resources like corpora, lexica and linguistic terminologies. The new portal provides easy access to our previously released Annohub Linked Data set, by allowing users to explore the annotation metadata in the web browser. In addition, we added features that will allow users to contribute to Annohub by means of uploading language data, in RDF, CoNNL or XML formats, for annotation scheme and language analysis. The generated metadata is finally available for personal use, or for release in Annohub.</abstract>
      <url hash="4852049a">2022.ldl-1.1</url>
      <bibkey>abromeit-2022-annohub</bibkey>
    </paper>
    <paper id="2">
      <title>From <fixed-case>ELT</fixed-case>e<fixed-case>C</fixed-case> Text Collection Metadata and Named Entities to Linked-data (and Back)</title>
      <author><first>Milica</first><last>Ikonić Nešić</last></author>
      <author><first>Ranka</first><last>Stanković</last></author>
      <author><first>Christof</first><last>Schöch</last></author>
      <author><first>Mihailo</first><last>Skoric</last></author>
      <pages>7–16</pages>
      <abstract>In this paper we present the wikification of the ELTeC (European Literary Text Collection), developed within the COST Action “Distant Reading for European Literary History” (CA16204). ELTeC is a multilingual corpus of novels written in the time period 1840—1920, built to apply distant reading methods and tools to explore the European literary history. We present the pipeline that led to the production of the linked dataset, the novels’ metadata retrieval and named entity recognition, transformation, mapping and Wikidata population, followed by named entity linking and export to NIF (NLP Interchange Format). The speeding up of the process of data preparation and import to Wikidata is presented on the use case of seven sub-collections of ELTeC (English, Portuguese, French, Slovenian, German, Hungarian and Serbian). Our goal was to automate the process of preparing and importing information, so OpenRefine and QuickStatements were chosen as the best options. The paper also includes examples of SPARQL queries for retrieval of authors, novel titles, publication places and other metadata with different visualisation options as well as statistical overviews.</abstract>
      <url hash="ba4fdd46">2022.ldl-1.2</url>
      <bibkey>ikonic-nesic-etal-2022-eltec</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>IMTV</fixed-case>ault: Extracting and Enriching Low-resource Language Interlinear Glossed Text from Grammatical Descriptions and Typological Survey Articles</title>
      <author><first>Sebastian</first><last>Nordhoff</last></author>
      <author><first>Thomas</first><last>Krämer</last></author>
      <pages>17–25</pages>
      <abstract>Many NLP resources and programs focus on a handful of major languages. But there are thousands of languages with low or no resources available as structured data. This paper shows the extraction of 40k examples with interlinear morpheme translation in 280 different languages from LaTeX-based publications of the open access publisher Language Science Press. These examples are transformed into Linked Data. We use LIGT for modelling and enrich the data with Wikidata and Glottolog. The data is made available as HTML, JSON, JSON-LD and N-quads, and query facilities for humans (Elasticsearch) and machines (API) are provided.</abstract>
      <url hash="2879e450">2022.ldl-1.3</url>
      <bibkey>nordhoff-kramer-2022-imtvault</bibkey>
    </paper>
    <paper id="4">
      <title>Linking the <fixed-case>LASLA</fixed-case> Corpus in the <fixed-case>L</fixed-case>i<fixed-case>L</fixed-case>a Knowledge Base of Interoperable Linguistic Resources for <fixed-case>L</fixed-case>atin</title>
      <author><first>Margherita</first><last>Fantoli</last></author>
      <author><first>Marco</first><last>Passarotti</last></author>
      <author><first>Francesco</first><last>Mambrini</last></author>
      <author><first>Giovanni</first><last>Moretti</last></author>
      <author><first>Paolo</first><last>Ruffolo</last></author>
      <pages>26–34</pages>
      <abstract>This paper describes the process of interlinking the 130 Classical Latin texts provided by an annotated corpus developed at the LASLA laboratory with the LiLa Knowledge Base, which makes linguistic resources for Latin interoperable by following the principles of the Linked Data paradigm and making reference to classes and properties of widely adopted ontologies to model the relevant information. After introducing the overall architecture of the LiLa Knowledge Base and the LASLA corpus, the paper details the phases of the process of linking the corpus with the collection of lemmas of LiLa and presents a federated query to exemplify the added value of interoperability of LASLA’s texts with other resources for Latin.</abstract>
      <url hash="58d06e24">2022.ldl-1.4</url>
      <bibkey>fantoli-etal-2022-linking</bibkey>
    </paper>
    <paper id="5">
      <title>Use Case: <fixed-case>R</fixed-case>omanian Language Resources in the <fixed-case>LOD</fixed-case> Paradigm</title>
      <author><first>Verginica</first><last>Barbu Mititelu</last></author>
      <author><first>Elena</first><last>Irimia</last></author>
      <author><first>Vasile</first><last>Pais</last></author>
      <author><first>Andrei-Marius</first><last>Avram</last></author>
      <author><first>Maria</first><last>Mitrofan</last></author>
      <pages>35–44</pages>
      <abstract>In this paper, we report on (i) the conversion of Romanian language resources to the Linked Open Data specifications and requirements, on (ii) their publication and (iii) interlinking with other language resources (for Romanian or for other languages). The pool of converted resources is made up of the Romanian Wordnet, the morphosyntactic and phonemic lexicon RoLEX, four treebanks, one for the general language (the Romanian Reference Treebank) and others for specialised domains (SiMoNERo for medicine, LegalNERo for the legal domain, PARSEME-Ro for verbal multiword expressions), frequency information on lemmas and tokens and word embeddings as extracted from the reference corpus for contemporary Romanian (CoRoLa) and a bi-modal (text and speech) corpus. We also present the limitations coming from the representation of the resources in Linked Data format. The metadata of LOD resources have been published in the LOD Cloud. The resources are available for download on our website and a SPARQL endpoint is also available for querying them.</abstract>
      <url hash="1ff2433e">2022.ldl-1.5</url>
      <bibkey>barbu-mititelu-etal-2022-use</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/legalnero">LegalNERo</pwcdataset>
      <pwcdataset url="https://paperswithcode.com/dataset/rtasc">RTASC</pwcdataset>
    </paper>
    <paper id="6">
      <title>Fuzzy Lemon: Making Lexical Semantic Relations More Juicy</title>
      <author><first>Fernando</first><last>Bobillo</last></author>
      <author><first>Julia</first><last>Bosque-Gil</last></author>
      <author><first>Jorge</first><last>Gracia</last></author>
      <author><first>Marta</first><last>Lanau-Coronas</last></author>
      <pages>45–51</pages>
      <abstract>The OntoLex-Lemon model provides a vocabulary to enrich ontologies with linguistic information that can be exploited by Natural Language Processing applications. The increasing uptake of Lemon illustrates the growing interest in combining linguistic information and Semantic Web technologies. In this paper, we present Fuzzy Lemon, an extension of Lemon that allows to assign an uncertainty degree to lexical semantic relations. Our approach is based on an OWL ontology that defines a hierarchy of data properties encoding different types of uncertainty. We also illustrate the usefulness of Fuzzy Lemon by showing that it can be used to represent the confidence degrees of automatically discovered translations between pairs of bilingual dictionaries from the Apertium family.</abstract>
      <url hash="d622a620">2022.ldl-1.6</url>
      <bibkey>bobillo-etal-2022-fuzzy</bibkey>
    </paper>
    <paper id="7">
      <title>A Cheap and Dirty Cross-Lingual Linking Service in the Cloud</title>
      <author><first>Christian</first><last>Chiarcos</last></author>
      <author><first>Gilles</first><last>Sérasset</last></author>
      <pages>52–60</pages>
      <abstract>In this paper, we describe the application of Linguistic Linked Open Data (LLOD) technology for dynamic cross-lingual querying on demand. Whereas most related research is focusing on providing a static linking, i.e., cross-lingual inference, and then storing the resulting links, we demonstrate the application of the federation capabilities of SPARQL to perform lexical linking on the fly. In the end, we provide a baseline functionality that uses the connection of two web services – a SPARQL end point for multilingual lexical data and another SPARQL end point for querying an English language knowledge graph – in order to perform querying an English language knowledge graph using foreign language labels. We argue that, for low-resource languages where substantial native knowledge graphs are lacking, this functionality can be used to lower the language barrier by allowing to formulate cross-linguistically applicable queries mediated by a multilingual dictionary.</abstract>
      <url hash="c04b8e32">2022.ldl-1.7</url>
      <bibkey>chiarcos-serasset-2022-cheap</bibkey>
    </paper>
    <paper id="8">
      <title>Spicy Salmon: Converting between 50+ Annotation Formats with Fintan, Pepper, Salt and Powla</title>
      <author><first>Christian</first><last>Fäth</last></author>
      <author><first>Christian</first><last>Chiarcos</last></author>
      <pages>61–68</pages>
      <abstract>Heterogeneity of formats, models and annotations has always been a primary hindrance for exploiting the ever increasing amount of existing linguistic resources for real world applications in and beyond NLP. Fintan - the Flexible INtegrated Transformation and Annotation eNgineering platform introduced in 2020 is designed to rapidly convert, combine and manipulate language resources both in and outside the Semantic Web by transforming it into segmented RDF representations which can be processed in parallel on a multithreaded environment and integrating it with ontologies and taxonomies. Fintan has recently been extended with a set of additional modules increasing the amount of supported non-RDF formats and the interoperability with existing non-JAVA conversion tools, and parts of this work are demonstrated in this paper. In particular, we focus on a novel recipe for resource transformation in which Fintan works in tandem with the Pepper toolset to allow computational linguists to transform their data between over 50 linguistic corpus formats with a graphical workflow manager.</abstract>
      <url hash="bf1da5e8">2022.ldl-1.8</url>
      <bibkey>fath-chiarcos-2022-spicy</bibkey>
    </paper>
    <paper id="9">
      <title>A Survey of Guidelines and Best Practices for the Generation, Interlinking, Publication, and Validation of Linguistic Linked Data</title>
      <author><first>Fahad</first><last>Khan</last></author>
      <author><first>Christian</first><last>Chiarcos</last></author>
      <author><first>Thierry</first><last>Declerck</last></author>
      <author><first>Maria Pia</first><last>Di Buono</last></author>
      <author><first>Milan</first><last>Dojchinovski</last></author>
      <author><first>Jorge</first><last>Gracia</last></author>
      <author><first>Giedre Valunaite</first><last>Oleskeviciene</last></author>
      <author><first>Daniela</first><last>Gifu</last></author>
      <pages>69–77</pages>
      <abstract>This article discusses a survey carried out within the NexusLinguarum COST Action which aimed to give an overview of existing guidelines (GLs) and best practices (BPs) in linguistic linked data. In particular it focused on four core tasks in the production/publication of linked data: generation, interlinking, publication, and validation. We discuss the importance of GLs and BPs for LLD before describing the survey and its results in full. Finally we offer a number of directions for future work in order to address the findings of the survey.</abstract>
      <url hash="f5259adc">2022.ldl-1.9</url>
      <bibkey>khan-etal-2022-survey</bibkey>
    </paper>
    <paper id="10">
      <title>Computational Morphology with <fixed-case>O</fixed-case>nto<fixed-case>L</fixed-case>ex-Morph</title>
      <author><first>Christian</first><last>Chiarcos</last></author>
      <author><first>Katerina</first><last>Gkirtzou</last></author>
      <author><first>Fahad</first><last>Khan</last></author>
      <author><first>Penny</first><last>Labropoulou</last></author>
      <author><first>Marco</first><last>Passarotti</last></author>
      <author><first>Matteo</first><last>Pellegrini</last></author>
      <pages>78–86</pages>
      <abstract>This paper describes the current status of the emerging OntoLex module for linguistic morphology. It serves as an update to the previous version of the vocabulary (Klimek et al. 2019). Whereas this earlier model was exclusively focusing on descriptive morphology and focused on applications in lexicography, we now present a novel part and a novel application of the vocabulary to applications in language technology, i.e., the rule-based generation of lexicons, introducing a dynamic component into OntoLex.</abstract>
      <url hash="153145c6">2022.ldl-1.10</url>
      <bibkey>chiarcos-etal-2022-computational</bibkey>
    </paper>
  </volume>
</collection>
