<?xml version='1.0' encoding='UTF-8'?>
<collection id="2022.ccgpk">
  <volume id="1" ingest-date="2022-10-06">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on Customized Chat Grounding Persona and Knowledge</booktitle>
      <editor><first>Heuiseok</first><last>Lim</last></editor>
      <editor><first>Seungryong</first><last>Kim</last></editor>
      <editor><first>Yeonsoo</first><last>Lee</last></editor>
      <editor><first>Steve</first><last>Lin</last></editor>
      <editor><first>Paul Hongsuck</first><last>Seo</last></editor>
      <editor><first>Yumin</first><last>Suh</last></editor>
      <editor><first>Yoonna</first><last>Jang</last></editor>
      <editor><first>Jungwoo</first><last>Lim</last></editor>
      <editor><first>Yuna</first><last>Hur</last></editor>
      <editor><first>Suhyune</first><last>Son</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Gyeongju, Republic of Korea</address>
      <month>October</month>
      <year>2022</year>
      <url hash="fffd6e40">2022.ccgpk-1</url>
      <venue>ccgpk</venue>
    </meta>
    <frontmatter>
      <url hash="a5f23bc2">2022.ccgpk-1.0</url>
      <bibkey>ccgpk-2022-customized</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Focus on <fixed-case>F</fixed-case>o<fixed-case>C</fixed-case>us: Is <fixed-case>F</fixed-case>o<fixed-case>C</fixed-case>us focused on Context, Knowledge and Persona?</title>
      <author><first>SeungYoon</first><last>Lee</last></author>
      <author><first>Jungseob</first><last>Lee</last></author>
      <author><first>Chanjun</first><last>Park</last></author>
      <author><first>Sugyeong</first><last>Eo</last></author>
      <author><first>Hyeonseok</first><last>Moon</last></author>
      <author><first>Jaehyung</first><last>Seo</last></author>
      <author><first>Jeongbae</first><last>Park</last></author>
      <author><first>Heuiseok</first><last>Lim</last></author>
      <pages>1–8</pages>
      <abstract>Rather than continuing the conversation based on personalized or implicit information, the existing conversation system generates dialogue by focusing only on the superficial content. To solve this problem, FoCus was recently released. FoCus is a persona-knowledge grounded dialogue generation dataset that leverages Wikipedia’s knowledge and personal persona, focusing on the landmarks provided by Google, enabling user-centered conversation. However, a closer empirical study is needed since research in the field is still in its early stages. Therefore, we fling two research questions about FoCus. “Is the FoCus whether for conversation or question answering?” to identify the structural problems of the dataset. “Does the FoCus model do real knowledge blending?” to closely demonstrate that the model acquires actual knowledge. As a result of the experiment, we present that the FoCus model could not correctly blend the knowledge according to the input dialogue and that the dataset design is unsuitable for the multi-turn conversation.</abstract>
      <url hash="23f694ac">2022.ccgpk-1.1</url>
      <bibkey>lee-etal-2022-focus</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/focus">FoCus</pwcdataset>
    </paper>
    <paper id="2">
      <title>Proto-Gen: An end-to-end neural generator for persona and knowledge grounded response generation</title>
      <author><first>Sougata</first><last>Saha</last></author>
      <author><first>Souvik</first><last>Das</last></author>
      <author><first>Rohini</first><last>Srihari</last></author>
      <pages>9–14</pages>
      <abstract>In this paper we detail the implementation of Proto-Gen, an end-to-end neural response generator capable of selecting appropriate persona and fact sentences from available options, and generating persona and fact grounded responses. Incorporating a novel interaction layer in an encoder-decoder architecture, Proto-Gen facilitates learning dependencies between facts, persona and the context, and outperforms existing baselines on the FoCus dataset for both the sub-tasks of persona and fact selection, and response generation. We further fine tune Proto-Gen’s hyperparameters, and share our results and findings.</abstract>
      <url hash="c66fe922">2022.ccgpk-1.2</url>
      <bibkey>saha-etal-2022-proto</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/focus">FoCus</pwcdataset>
    </paper>
    <paper id="3">
      <title>Evaluating Agent Interactions Through Episodic Knowledge Graphs</title>
      <author><first>Selene</first><last>Baez Santamaria</last></author>
      <author><first>Piek</first><last>Vossen</last></author>
      <author><first>Thomas</first><last>Baier</last></author>
      <pages>15–28</pages>
      <abstract>We present a new method based on episodic Knowledge Graphs (eKGs) for evaluating (multimodal) conversational agents in open domains. This graph is generated by interpreting raw signals during conversation and is able to capture the accumulation of knowledge over time. We apply structural and semantic analysis of the resulting graphs and translate the properties into qualitative measures. We compare these measures with existing automatic and manual evaluation metrics commonly used for conversational agents. Our results show that our Knowledge-Graph-based evaluation provides more qualitative insights into interaction and the agent’s behavior.</abstract>
      <url hash="f6df07c4">2022.ccgpk-1.3</url>
      <bibkey>baez-santamaria-etal-2022-evaluating</bibkey>
      <pwccode url="https://github.com/selbaez/evaluating-conversations-as-ekg" additional="false">selbaez/evaluating-conversations-as-ekg</pwccode>
      <pwcdataset url="https://paperswithcode.com/dataset/topical-chat">Topical-Chat</pwcdataset>
    </paper>
    <paper id="4">
      <title><fixed-case>PERSONACHATGEN</fixed-case>: Generating Personalized Dialogues using <fixed-case>GPT</fixed-case>-3</title>
      <author><first>Young-Jun</first><last>Lee</last></author>
      <author><first>Chae-Gyun</first><last>Lim</last></author>
      <author><first>Yunsu</first><last>Choi</last></author>
      <author><first>Ji-Hui</first><last>Lm</last></author>
      <author><first>Ho-Jin</first><last>Choi</last></author>
      <pages>29–48</pages>
      <abstract>Recently, many prior works have made their own agents generate more personalized and engaging responses using personachat. However, since this dataset is frozen in 2018, the dialogue agents trained on this dataset would not know how to interact with a human who loves “Wandavision.” One way to alleviate this problem is to create a large-scale dataset. In this work, we introduce the pipeline of creating personachatgen, which is comprised of three main components: Creating (1) profilegen, (2) Persona Set, and (3) personachatgen. To encourage GPT-3’s generation ability, we also defined a taxonomy of hierarchical persona category derived from social profiling taxonomy. To create the speaker consistent persona set, we propose a simple contradiction-based iterative sentence replacement algorithm, named CoNL. Moreover, to prevent GPT-3 generating harmful content, we presented two filtering pipelines, one each for profilegen and personachatgen. Through analyzing of personachatgen, we showed that GPT-3 can generate personalized dialogue containing diverse persona. Furthermore, we revealed a state-of-the-art Blender 90M trained on our dataset that leads to higher performance.</abstract>
      <url hash="f4e8cb4a">2022.ccgpk-1.4</url>
      <bibkey>lee-etal-2022-personachatgen</bibkey>
    </paper>
  </volume>
</collection>
