<?xml version='1.0' encoding='UTF-8'?>
<collection id="2020.stoc">
  <volume id="1">
    <meta>
      <booktitle>Proceedings for the First International Workshop on Social Threats in Online Conversations: Understanding and Management</booktitle>
      <editor><first>Archna</first><last>Bhatia</last></editor>
      <editor><first>Samira</first><last>Shaikh</last></editor>
      <publisher>European Language Resources Association</publisher>
      <address>Marseille, France</address>
      <month>May</month>
      <year>2020</year>
      <isbn>979-10-95546-39-9</isbn>
    </meta>
    <frontmatter>
      <url hash="eafb0485">2020.stoc-1.0</url>
    </frontmatter>
    <paper id="1">
      <title>Active Defense Against Social Engineering: The Case for Human Language Technology</title>
      <author><first>Adam</first><last>Dalton</last></author>
      <author><first>Ehsan</first><last>Aghaei</last></author>
      <author><first>Ehab</first><last>Al-Shaer</last></author>
      <author><first>Archna</first><last>Bhatia</last></author>
      <author><first>Esteban</first><last>Castillo</last></author>
      <author><first>Zhuo</first><last>Cheng</last></author>
      <author><first>Sreekar</first><last>Dhaduvai</last></author>
      <author><first>Qi</first><last>Duan</last></author>
      <author><first>Bryanna</first><last>Hebenstreit</last></author>
      <author><first>Md Mazharul</first><last>Islam</last></author>
      <author><first>Younes</first><last>Karimi</last></author>
      <author><first>Amir</first><last>Masoumzadeh</last></author>
      <author><first>Brodie</first><last>Mather</last></author>
      <author><first>Sashank</first><last>Santhanam</last></author>
      <author><first>Samira</first><last>Shaikh</last></author>
      <author><first>Alan</first><last>Zemel</last></author>
      <author><first>Tomek</first><last>Strzalkowski</last></author>
      <author><first>Bonnie J.</first><last>Dorr</last></author>
      <pages>1–8</pages>
      <abstract>We describe a system that supports natural language processing (NLP) components for active defenses against social engineering attacks. We deploy a pipeline of human language technology, including Ask and Framing Detection, Named Entity Recognition, Dialogue Engineering, and Stylometry. The system processes modern message formats through a plug-in architecture to accommodate innovative approaches for message analysis, knowledge representation and dialogue generation. The novelty of the system is that it uses NLP for cyber defense and engages the attacker using bots to elicit evidence to attribute to the attacker and to waste the attacker’s time and resources.</abstract>
      <url hash="e4cc603f">2020.stoc-1.1</url>
      <language>eng</language>
    </paper>
    <paper id="2">
      <title>Adaptation of a Lexical Organization for Social Engineering Detection and Response Generation</title>
      <author><first>Archna</first><last>Bhatia</last></author>
      <author><first>Adam</first><last>Dalton</last></author>
      <author><first>Brodie</first><last>Mather</last></author>
      <author><first>Sashank</first><last>Santhanam</last></author>
      <author><first>Samira</first><last>Shaikh</last></author>
      <author><first>Alan</first><last>Zemel</last></author>
      <author><first>Tomek</first><last>Strzalkowski</last></author>
      <author><first>Bonnie J.</first><last>Dorr</last></author>
      <pages>9–14</pages>
      <abstract>We present a paradigm for extensible lexicon development based on Lexical Conceptual Structure to support social engineering detection and response generation. We leverage the central notions of ask (elicitation of behaviors such as providing access to money) and framing (risk/reward implied by the ask). We demonstrate improvements in ask/framing detection through refinements to our lexical organization and show that response generation qualitatively improves as ask/framing detection performance improves. The paradigm presents a systematic and efficient approach to resource adaptation for improved task-specific performance.</abstract>
      <url hash="f4da60fe">2020.stoc-1.2</url>
      <language>eng</language>
    </paper>
    <paper id="3">
      <title>Analysis of Online Conversations to Detect Cyberpredators Using Recurrent Neural Networks</title>
      <author><first>Jinhwa</first><last>Kim</last></author>
      <author><first>Yoon Jo</first><last>Kim</last></author>
      <author><first>Mitra</first><last>Behzadi</last></author>
      <author><first>Ian G.</first><last>Harris</last></author>
      <pages>15–20</pages>
      <abstract>We present an automated approach to analyze the text of an online conversation and determine whether one of the participants is a cyberpredator who is preying on another participant. The task is divided into two stages, 1) the classification of each message, and 2) the classification of the entire conversation. Each stage uses a Recurrent Neural Network (RNN) to perform the classification task.</abstract>
      <url hash="81ba85ff">2020.stoc-1.3</url>
      <language>eng</language>
    </paper>
    <paper id="4">
      <title>A Privacy Preserving Data Publishing Middleware for Unstructured, Textual Social Media Data</title>
      <author><first>Prasadi</first><last>Abeywardana</last></author>
      <author><first>Uthayasanker</first><last>Thayasivam</last></author>
      <pages>21–28</pages>
      <abstract>Privacy is going to be an integral part of data science and analytics in the coming years. The next hype of data experimentation is going to be heavily dependent on privacy preserving techniques mainly as it’s going to be a legal responsibility rather than a mere social responsibility. Privacy preservation becomes more challenging specially in the context of unstructured data. Social networks have become predominantly popular over the past couple of decades and they are creating a huge data lake at a high velocity. Social media profiles contain a wealth of personal and sensitive information, creating enormous opportunities for third parties to analyze them with different algorithms, draw conclusions and use in disinformation campaigns and micro targeting based dark advertising. This study provides a mitigation mechanism for disinformation campaigns that are done based on the insights extracted from personal/sensitive data analysis. Specifically, this research is aimed at building a privacy preserving data publishing middleware for unstructured social media data without compromising the true analytical value of those data. A novel way is proposed to apply traditional structured privacy preserving techniques on unstructured data. Creating a comprehensive twitter corpus annotated with privacy attributes is another objective of this research, especially because the research community is lacking one.</abstract>
      <url hash="8082d154">2020.stoc-1.4</url>
      <language>eng</language>
    </paper>
    <paper id="5">
      <title>Information Space Dashboard</title>
      <author><first>Theresa</first><last>Krumbiegel</last></author>
      <author><first>Albert</first><last>Pritzkau</last></author>
      <author><first>Hans-Christian</first><last>Schmitz</last></author>
      <pages>29–34</pages>
      <abstract>The information space, where information is generated, stored, exchanged and discussed, is not idyllic but a space where campaigns of disinformation and destabilization are conducted. Such campaigns are subsumed under the terms “hybrid warfare” and “information warfare” (Woolley and Howard, 2017). In order to enable awareness of them, we propose an information state dashboard comprising various components/apps for data collection, analysis and visualization. The aim of the dashboard is to support an analyst in generating a common operational picture of the information space, link it with an operational picture of the physical space and, thus, contribute to overarching situational awareness. The dashboard is work in progress. However, a first prototype with components for exploiting elementary language statistics, keyword and metadata analysis, text classification and network analysis has been implemented. Further components, in particular, for event extraction and sentiment analysis are under development. As a demonstration case, we briefly discuss the analysis of historical data regarding violent anti-migrant protests and respective counter-protests that took place in Chemnitz in 2018.</abstract>
      <url hash="42387451">2020.stoc-1.5</url>
      <language>eng</language>
    </paper>
    <paper id="6">
      <title>Is this hotel review truthful or deceptive? A platform for disinformation detection through computational stylometry</title>
      <author><first>Antonio</first><last>Pascucci</last></author>
      <author><first>Raffaele</first><last>Manna</last></author>
      <author><first>Ciro</first><last>Caterino</last></author>
      <author><first>Vincenzo</first><last>Masucci</last></author>
      <author><first>Johanna</first><last>Monti</last></author>
      <pages>35–40</pages>
      <abstract>In this paper, we present a web service platform for disinformation detection in hotel reviews written in English. The platform relies on a hybrid approach of computational stylometry techniques, machine learning and linguistic rules written using COGITO, Expert System Corp.’s semantic intelligence software thanks to which it is possible to analyze texts and extract all their characteristics. We carried out a research experiment on the Deceptive Opinion Spam corpus, a balanced corpus composed of 1,600 hotel reviews of 20 Chicago hotels split into four datasets: positive truthful, negative truthful, positive deceptive and negative deceptive reviews. We investigated four different classifiers and we detected that Simple Logistic is the most performing algorithm for this type of classification.</abstract>
      <url hash="665b9b58">2020.stoc-1.6</url>
      <language>eng</language>
    </paper>
    <paper id="7">
      <title>Corpus Development for Studying Online Disinformation Campaign: A Narrative + Stance Approach</title>
      <author><first>Mack</first><last>Blackburn</last></author>
      <author><first>Ning</first><last>Yu</last></author>
      <author><first>John</first><last>Berrie</last></author>
      <author><first>Brian</first><last>Gordon</last></author>
      <author><first>David</first><last>Longfellow</last></author>
      <author><first>William</first><last>Tirrell</last></author>
      <author><first>Mark</first><last>Williams</last></author>
      <pages>41–47</pages>
      <abstract>Disinformation on social media is impacting our personal life and society. The outbreak of the new coronavirus is the most recent example for which a wealth of disinformation provoked fear, hate, and even social panic. While there are emerging interests in studying how disinformation campaigns form, spread, and influence target audiences, developing disinformation campaign corpora is challenging given the high volume, fast evolution, and wide variation of messages associated with each campaign. Disinformation cannot always be captured by simple factchecking, which makes it even more challenging to validate and create ground truth. This paper presents our approach to develop a corpus for studying disinformation campaigns targeting the White Helmets of Syria. We bypass directly classifying a piece of information as disinformation or not. Instead, we label the narrative and stance of tweets and YouTube comments about White Helmets. Narratives is defined as a recurring statement that is used to express a point of view. Stance is a high-level point of view on a topic. We demonstrate that narrative and stance together can provide a dynamic method for real world users, e.g., intelligence analysts, to quickly identify and counter disinformation campaigns based on their knowledge at the time.</abstract>
      <url hash="392cff84">2020.stoc-1.7</url>
      <language>eng</language>
    </paper>
    <paper id="8">
      <title>Email Threat Detection Using Distinct Neural Network Approaches</title>
      <author><first>Esteban</first><last>Castillo</last></author>
      <author><first>Sreekar</first><last>Dhaduvai</last></author>
      <author><first>Peng</first><last>Liu</last></author>
      <author><first>Kartik-Singh</first><last>Thakur</last></author>
      <author><first>Adam</first><last>Dalton</last></author>
      <author><first>Tomek</first><last>Strzalkowski</last></author>
      <pages>48–55</pages>
      <abstract>This paper describes different approaches to detect malicious content in email interactions through a combination of machine learning and natural language processing tools. Specifically, several neural network designs are tested on word embedding representations to detect suspicious messages and separate them from non-suspicious, benign email. The proposed approaches are trained and tested on distinct email collections, including datasets constructed from publicly available corpora (such as Enron, APWG, etc.) as well as several smaller, non-public datasets used in recent government evaluations. Experimental results show that back-propagation both with and without recurrent neural layers outperforms current state of the art techniques that include supervised learning algorithms with stylometric elements of texts as features. Our results also demonstrate that word embedding vectors are effective means for capturing certain aspects of text meaning that can be teased out through machine learning in non-linear/complex neural networks, in order to obtain highly accurate detection of malicious emails based on email text alone.</abstract>
      <url hash="13c4b37f">2020.stoc-1.8</url>
      <language>eng</language>
    </paper>
  </volume>
</collection>
