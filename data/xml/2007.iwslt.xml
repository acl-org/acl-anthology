<?xml version='1.0' encoding='UTF-8'?>
<collection id="2007.iwslt">
  <volume id="1" ingest-date="2021-08-04">
    <meta>
      <booktitle>Proceedings of the Fourth International Workshop on Spoken Language Translation</booktitle>
      <address>Trento, Italy</address>
      <month>October 15-16</month>
      <year>2007</year>
      <venue>iwslt</venue>
    </meta>
    <paper id="1">
      <title>Overview of the <fixed-case>IWSLT</fixed-case> 2007 evaluation campaign</title>
      <author><first>Cameron Shaw</first><last>Fordyce</last></author>
      <url hash="855c090b">2007.iwslt-1.1</url>
      <abstract>In this paper we give an overview of the 2007 evaluation campaign for the International Workshop on Spoken Language Translation (IWSLT)1. As with previous evaluation campaigns, the primary focus of the workshop was the translation of spoken language in the travel domain. This year there were four language pairs; the translation of Chinese, Italian, Arabic, and Japanese into English. The input data consisted of the output of ASR systems for read speech and clean text. The exceptions were the challenge task of the Italian English language pair which used spontaneous speech ASR outputs and transcriptions and the Chinese English task which used only clean text. A new characteristic of this year’s evaluation campaign was an increased focus on the sharing of resources. Participants were requested to submit the data and supplementary resources used in building their systems so that the other participants might be able to take advantage of the same resources. A second new characteristic this year was the focus on the human evaluation of systems. Each primary run was judged in the human evaluation for every task using a straightforward ranking of systems. This year's workshop saw an increased participation over last year's workshop. This year 24 groups submitted runs to one or more of the tasks, compared to the 19 groups that submitted runs last year [1]. Automatic and human evaluation were carried out to measure MT performance under each condition, ASR system outputs for read speech, spontaneous travel dialogues, and clean text.</abstract>
      <bibkey>fordyce-2007-overview</bibkey>
    </paper>
    <paper id="2">
      <title>A comparison of linguistically and statistically enhanced models for speech-to-speech machine translation</title>
      <author><first>Alicia</first><last>Pérez</last></author>
      <author><first>Víctor</first><last>Guijarrubia</last></author>
      <author><first>Raquel</first><last>Justo</last></author>
      <author><first>M. Inés</first><last>Torres</last></author>
      <author><first>Francisco</first><last>Casacuberta</last></author>
      <url hash="48622ccd">2007.iwslt-1.2</url>
      <abstract>The goal of this work is to improve current translation models by taking into account additional knowledge sources such as semantically motivated segmentation or statistical categorization. Specifically, two different approaches are discussed. On the one hand, phrase-based approach, and on the other hand, categorization. For both approaches, both statistical and linguistic alternatives are explored. As for translation framework, finite-state transducers are considered. These are versatile models that can be easily integrated on-the-fly with acoustic models for speech translation purposes. In what the experimental framework concerns, all the models presented were evaluated and compared taking confidence intervals into account.</abstract>
      <bibkey>perez-etal-2007-comparison</bibkey>
    </paper>
    <paper id="3">
      <title>Improved chunk-level reordering for statistical machine translation</title>
      <author><first>Yuqi</first><last>Zhang</last></author>
      <author><first>Richard</first><last>Zens</last></author>
      <author><first>Hermann</first><last>Ney</last></author>
      <url hash="6c4dba26">2007.iwslt-1.3</url>
      <abstract>Inspired by previous chunk-level reordering approaches to statistical machine translation, this paper presents two methods to improve the reordering at the chunk level. By introducing a new lattice weighting factor and by reordering the training source data, an improvement is reported on TER and BLEU. Compared to the previous chunklevel reordering approach, the BLEU score improves 1.4% absolutely. The translation results are reported on IWSLT Chinese-English task.</abstract>
      <bibkey>zhang-etal-2007-improved</bibkey>
    </paper>
    <paper id="4">
      <title>The <fixed-case>CMU</fixed-case> <fixed-case>T</fixed-case>rans<fixed-case>T</fixed-case>ac 2007 eyes-free two-way speech-to-speech translation system</title>
      <author><first>Nguyen</first><last>Bach</last></author>
      <author><first>Matthais</first><last>Eck</last></author>
      <author><first>Paisarn</first><last>Charoenpornsawat</last></author>
      <author><first>Thilo</first><last>Köhler</last></author>
      <author><first>Sebastian</first><last>Stüker</last></author>
      <author><first>ThuyLinh</first><last>Nguyen</last></author>
      <author><first>Roger</first><last>Hsiao</last></author>
      <author><first>Alex</first><last>Waibel</last></author>
      <author><first>Stephan</first><last>Vogel</last></author>
      <author><first>Tanja</first><last>Schultz</last></author>
      <author><first>Alan W.</first><last>Black</last></author>
      <url hash="4a39ee37">2007.iwslt-1.4</url>
      <abstract>The paper describes our portable two-way speech-to-speech translation system using a completely eyes-free/hands-free user interface. This system translates between the language pair English and Iraqi Arabic as well as between English and Farsi, and was built within the framework of the DARPA TransTac program. The Farsi language support was developed within a 90-day period, testing our ability to rapidly support new languages. The paper gives an overview of the system’s components along with the individual component objective measures and a discussion of issues relevant for the overall usage of the system. We found that usability, flexibility, and robustness serve as severe constraints on system architecture and design.</abstract>
      <bibkey>bach-etal-2007-cmu</bibkey>
    </paper>
    <paper id="5">
      <title><fixed-case>CASIA</fixed-case> phrase-based <fixed-case>SMT</fixed-case> system for <fixed-case>IWSLT</fixed-case>’07</title>
      <author><first>Yu</first><last>Zhou</last></author>
      <author><first>Yanqing</first><last>He</last></author>
      <author><first>Chengqing</first><last>Zong</last></author>
      <url hash="65cf4c25">2007.iwslt-1.5</url>
      <bibkey>zhou-etal-2007-casia</bibkey>
    </paper>
    <paper id="6">
      <title>The <fixed-case>U</fixed-case>niversity of <fixed-case>E</fixed-case>dinburgh system description for <fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Josh</first><last>Schroeder</last></author>
      <author><first>Philipp</first><last>Koehn</last></author>
      <url hash="06d280ac">2007.iwslt-1.6</url>
      <abstract>We present the University of Edinburgh’s submission for the IWSLT 2007 shared task. Our efforts focused on adapting our statistical machine translation system to the open data conditions for the Italian-English task of the evaluation campaign. We examine the challenges of building a system with a limited set of in-domain development data (SITAL), a small training corpus in a related but distinct domain (BTEC), and a large out of domain corpus (Europarl). We concentrated on the corrected text track, and present additional results of our experiments using the open-source Moses MT system with speech input.</abstract>
      <bibkey>schroeder-koehn-2007-university</bibkey>
    </paper>
    <paper id="7">
      <title>The <fixed-case>GREYC</fixed-case> machine translation system for the <fixed-case>IWSLT</fixed-case> 2007 evaluation campaign</title>
      <author><first>Yves</first><last>Lepage</last></author>
      <author><first>Adrien</first><last>Lardilleux</last></author>
      <url hash="871daa33">2007.iwslt-1.7</url>
      <abstract>The GREYC machine translation (MT) system is a slight evolution of the ALEPH machine translation system that participated in the IWLST 2005 campaign. It is a pure example-based MT system that exploits proportional analogies. The training data used for this campaign were limited on purpose to the sole data provided by the organizers. However, the training data were expanded with the results of sub-sentential alignments. Thesystemparticipatedinthetwoclassicaltasks of translation of manually transcribed texts from Japanese to English and Arabic to English.</abstract>
      <bibkey>lepage-lardilleux-2007-greyc</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>I</fixed-case>2<fixed-case>R</fixed-case> <fixed-case>C</fixed-case>hinese-<fixed-case>E</fixed-case>nglish translation system for <fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Boxing</first><last>Chen</last></author>
      <author><first>Jun</first><last>Sun</last></author>
      <author><first>Hongfei</first><last>Jiang</last></author>
      <author><first>Min</first><last>Zhang</last></author>
      <author><first>Ai Ti</first><last>Aw</last></author>
      <url hash="0b19016b">2007.iwslt-1.8</url>
      <abstract>In this paper, we describe the system and approach used by Institute for Infocomm Research (I2R) for the IWSLT 2007 spoken language evaluation campaign. A multi-pass approach is exploited to generate and select best translation. First, we use two decoders namely the open source Moses and an in-home syntax-based decoder to generate N-best lists. Next we spawn new translation entries through a word-based n-gram language model estimated on the former N-best entries. Finally, we join the N-best lists from the previous two passes, and select the best translation by rescoring them with additional feature functions. In particular, this paper reports our effort on new translation entry generation and system combination. The performance on development and test sets are reported. The system was ranked first with respect to the BLEU measure in Chinese-to-English open data track.</abstract>
      <bibkey>chen-etal-2007-i2r</bibkey>
    </paper>
    <paper id="9">
      <title>The <fixed-case>CMU</fixed-case>-<fixed-case>UKA</fixed-case> statistical machine translation systems for <fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Ian</first><last>Lane</last></author>
      <author><first>Andreas</first><last>Zollmann</last></author>
      <author><first>Thuy Linh</first><last>Nguyen</last></author>
      <author><first>Nguyen</first><last>Bach</last></author>
      <author><first>Ashish</first><last>Venugopal</last></author>
      <author><first>Stephan</first><last>Vogel</last></author>
      <author><first>Kay</first><last>Rottmann</last></author>
      <author><first>Ying</first><last>Zhang</last></author>
      <author><first>Alex</first><last>Waibel</last></author>
      <url hash="cbb0f523">2007.iwslt-1.9</url>
      <abstract>This paper describes the CMU-UKA statistical machine translation systems submitted to the IWSLT 2007 evaluation campaign. Systems were submitted for three language-pairs: Japanese→English, Chinese→English and Arabic→English. All systems were based on a common phrase-based SMT (statistical machine translation) framework but for each language-pair a specific research problem was tackled. For Japanese→English we focused on two problems: first, punctuation recovery, and second, how to incorporate topic-knowledge into the translation framework. Our Chinese→English submission focused on syntax-augmented SMT and for the Arabic→English task we focused on incorporating morphological-decomposition into the SMT framework. This research strategy enabled us to evaluate a wide variety of approaches which proved effective for the language pairs they were evaluated on.</abstract>
      <bibkey>lane-etal-2007-cmu</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>M</fixed-case>a<fixed-case>T</fixed-case>r<fixed-case>E</fixed-case>x: the <fixed-case>DCU</fixed-case> machine translation system for <fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Hany</first><last>Hassan</last></author>
      <author><first>Yanjun</first><last>Ma</last></author>
      <author><first>Andy</first><last>Way</last></author>
      <url hash="aa2d947a">2007.iwslt-1.10</url>
      <abstract>In this paper, we give a description of the machine translation system developed at DCU that was used for our second participation in the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT 2007). In this participation, we focus on some new methods to improve system quality. Specifically, we try our word packing technique for different language pairs, we smooth our translation tables with out-of-domain word translations for the Arabic–English and Chinese–English tasks in order to solve the high number of out of vocabulary items, and finally we deploy a translation-based model for case and punctuation restoration. We participated in both the classical and challenge tasks for the following translation directions: Chinese–English, Japanese–English and Arabic–English. For the last two tasks, we translated both the single-best ASR hypotheses and the correct recognition results; for Chinese–English, we just translated the correct recognition results. We report the results of the system for the provided evaluation sets, together with some additional experiments carried out following identification of some simple tokenisation errors in the official runs.</abstract>
      <bibkey>hassan-etal-2007-matrex</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>FBK</fixed-case>@<fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Nicola</first><last>Bertoldi</last></author>
      <author><first>Mauro</first><last>Cettolo</last></author>
      <author><first>Roldano</first><last>Cattoni</last></author>
      <author><first>Marcello</first><last>Federico</last></author>
      <url hash="43ba75f0">2007.iwslt-1.11</url>
      <abstract>This paper reports on the participation of FBK (formerly ITC-irst) at the IWSLT 2007 Evaluation. FBK participated in three tasks, namely Chinese-to-English, Japanese-to-English, and Italian-to-English. With respect to last year, translation systems were developed with the Moses Toolkit and the IRSTLM library, both available as open source software. Moreover, several novel ideas were investigated: the use of confusion networks in input to manage ambiguity in punctuation, the estimation of an additional language model by means of the Google’s Web 1T 5-gram collection, the combination of true case and lower case language models, and finally the use of multiple phrase-tables. By working on top of a state-of-the art baseline, experiments showed that the above methods accounted for significant BLEU score improvements.</abstract>
      <bibkey>bertoldi-etal-2007-fbk</bibkey>
    </paper>
    <paper id="12">
      <title><fixed-case>HKUST</fixed-case> statistical machine translation experiments for <fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Yihai</first><last>Shen</last></author>
      <author><first>Chi-kiu</first><last>Lo</last></author>
      <author><first>Marine</first><last>Carpuat</last></author>
      <author><first>Dekai</first><last>Wu</last></author>
      <url hash="70da82e3">2007.iwslt-1.12</url>
      <abstract>This paper describes the HKUST experiments in the IWSLT 2007 evaluation campaign on spoken language translation. Our primary objective was to compare the open-source phrase-based statistical machine translation toolkit Moses against Pharaoh. We focused on Chinese to English translation, but we also report results on the Arabic to English, Italian to English, and Japanese to English tasks.</abstract>
      <bibkey>shen-etal-2007-hkust</bibkey>
    </paper>
    <paper id="13">
      <title>The <fixed-case>U</fixed-case>niversity of <fixed-case>W</fixed-case>ashington machine translation system for the <fixed-case>IWSLT</fixed-case> 2007 competition</title>
      <author><first>Katrin</first><last>Kirchhoff</last></author>
      <author><first>Mei</first><last>Yang</last></author>
      <url hash="317c5e2d">2007.iwslt-1.13</url>
      <abstract>This paper presents the University of Washington’s submission to the 2007 IWSLT benchmark evaluation. The UW system participated in two data tracks, Italian-to-English and Arabic-to-English. Our main focus was on incorporating out-of-domain data, which contributed to improvements for both language pairs in both the clean text and ASR output conditions. In addition, we compared supervised and semi-supervised preprocessing schemes for the Arabic-to-English task and found that the semi-supervised scheme performs competitively with the supervised algorithm while using a fraction of the run-time.</abstract>
      <bibkey>kirchhoff-yang-2007-university</bibkey>
    </paper>
    <paper id="14">
      <title>The <fixed-case>MIT</fixed-case>-<fixed-case>LL</fixed-case>/<fixed-case>AFRL</fixed-case> <fixed-case>IWSLT</fixed-case>-2007 <fixed-case>MT</fixed-case> system</title>
      <author><first>Wade</first><last>Shen</last></author>
      <author><first>Brian</first><last>Delaney</last></author>
      <author><first>Tim</first><last>Anderson</last></author>
      <author><first>Ray</first><last>Slyh</last></author>
      <url hash="263c336a">2007.iwslt-1.14</url>
      <abstract>The MIT-LL/AFRL MT system implements a standard phrase-based, statistical translation model. It incorporates a number of extensions that improve performance for speech-based translation. During this evaluation our efforts focused on the rapid porting of our SMT system to a new language (Arabic) and novel approaches to translation from speech input. This paper discusses the architecture of the MIT-LL/AFRL MT system, improvements over our 2006 system, and experiments we ran during the IWSLT-2007 evaluation. Specifically, we focus on 1) experiments comparing the performance of confusion network decoding and direct lattice decoding techniques for machine translation of speech, 2) the application of lightweight morphology for Arabic MT preprocessing and 3) improved confusion network decoding.</abstract>
      <bibkey>shen-etal-2007-mit</bibkey>
    </paper>
    <paper id="15">
      <title>The <fixed-case>NICT</fixed-case>/<fixed-case>ATR</fixed-case> speech translation system for <fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Andrew</first><last>Finch</last></author>
      <author><first>Etienne</first><last>Denoual</last></author>
      <author><first>Hideo</first><last>Okuma</last></author>
      <author><first>Michael</first><last>Paul</last></author>
      <author><first>Hirofumi</first><last>Yamamoto</last></author>
      <author><first>Keiji</first><last>Yasuda</last></author>
      <author><first>Ruiqiang</first><last>Zhang</last></author>
      <author><first>Eiichiro</first><last>Sumita</last></author>
      <url hash="15f6db74">2007.iwslt-1.15</url>
      <abstract>This paper describes the NiCT-ATR statistical machine translation (SMT) system used for the IWSLT 2007 evaluation campaign. We participated in three of the four language pair translation tasks (CE, JE, and IE). We used a phrase-based SMT system using log-linear feature models for all tracks. This year we decoded from the ASR n-best lists in the JE track and found a gain in performance. We also applied some new techniques to facilitate the use of out-of-domain external resources by model combination and also by utilizing a huge corpus of n-grams provided by Google Inc.. Using these resources gave mixed results that depended on the technique also the language pair however, in some cases we achieved consistently positive results. The results from model-interpolation in particular were very promising.</abstract>
      <bibkey>finch-etal-2007-nict</bibkey>
    </paper>
    <paper id="16">
      <title>Larger feature set approach for machine translation in <fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Taro</first><last>Watanabe</last></author>
      <author><first>Jun</first><last>Suzuki</last></author>
      <author><first>Katsuhito</first><last>Sudoh</last></author>
      <author><first>Hajime</first><last>Tsukada</last></author>
      <author><first>Hideki</first><last>Isozaki</last></author>
      <url hash="5739dc8b">2007.iwslt-1.16</url>
      <abstract>The NTT Statistical Machine Translation System employs a large number of feature functions. First, k-best translation candidates are generated by an efficient decoding method of hierarchical phrase-based translation. Second, the k-best translations are reranked. In both steps, sparse binary features — of the order of millions — are integrated during the search. This paper gives the details of the two steps and shows the results for the Evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT) 2007.</abstract>
      <bibkey>watanabe-etal-2007-larger</bibkey>
    </paper>
    <paper id="17">
      <title>The <fixed-case>ICT</fixed-case> statistical machine translation systems for <fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Zhongjun</first><last>He</last></author>
      <author><first>Haitao</first><last>Mi</last></author>
      <author id="yang-liu-ict"><first>Yang</first><last>Liu</last></author>
      <author><first>Deyi</first><last>Xiong</last></author>
      <author><first>Weihua</first><last>Luo</last></author>
      <author><first>Yun</first><last>Huang</last></author>
      <author><first>Zhixiang</first><last>Ren</last></author>
      <author><first>Yajuan</first><last>Lu</last></author>
      <author><first>Qun</first><last>Liu</last></author>
      <url hash="3b013c2d">2007.iwslt-1.17</url>
      <abstract>In this paper, we give an overview of the ICT statistical machine translation systems for the evaluation campaign of the International Workshop on Spoken Language Translation (IWSLT) 2007. In this year’s evaluation, we participated in the Chinese-English transcript translation task, and developed three systems based on different techniques: a formally syntax-based system Bruin, an extended phrase-based system Confucius and a linguistically syntax-based system Lynx. We will describe the models of these three systems, and compare their performance in detail. We set Bruin as our primary system, which ranks 2 among the 15 primary results according to the official evaluation results.</abstract>
      <bibkey>he-etal-2007-ict</bibkey>
    </paper>
    <paper id="18">
      <title>The <fixed-case>INESC</fixed-case>-<fixed-case>ID</fixed-case> <fixed-case>IWSLT</fixed-case>07 <fixed-case>SMT</fixed-case> system</title>
      <author><first>João V.</first><last>Graça</last></author>
      <author><first>Diamantino</first><last>Caseiro</last></author>
      <author><first>Luísa</first><last>Coheur</last></author>
      <url hash="2b88182d">2007.iwslt-1.18</url>
      <abstract>We present the machine translation system used by L2F from INESC-ID in the evaluation campaign of the International Workshop on Spoken Language Translation (2007), in the task of translating spontaneous conversations in the travel domain from Italian to English.</abstract>
      <bibkey>graca-etal-2007-inesc</bibkey>
    </paper>
    <paper id="19">
      <title>Using word posterior probabilities in lattice translation</title>
      <author><first>Vicente</first><last>Alabau</last></author>
      <author><first>Alberto</first><last>Sanchis</last></author>
      <author><first>Francisco</first><last>Casacuberta</last></author>
      <url hash="6bbb2e06">2007.iwslt-1.19</url>
      <abstract>In this paper we describe the statistical machine translation system developed at ITI/UPV, which aims especially at speech recognition and statistical machine translation integration, for the evaluation campaign of the International Workshop on Spoken Language Translation (2007). The system we have developed takes advantage of an improved word lattice representation that uses word posterior probabilities. These word posterior probabilities are then added as a feature to a log-linear model. This model includes a stochastic finite-state transducer which allows an easy lattice integration. Furthermore, it provides a statistical phrase-based reordering model that is able to perform local reorderings of the output. We have tested this model on the Italian-English corpus, for clean text, 1-best ASR and lattice ASR inputs. The results and conclusions of such experiments are reported at the end of this paper.</abstract>
      <bibkey>alabau-etal-2007-using</bibkey>
    </paper>
    <paper id="20">
      <title>The <fixed-case>LIG</fixed-case> <fixed-case>A</fixed-case>rabic/<fixed-case>E</fixed-case>nglish speech translation system at <fixed-case>IWSLT</fixed-case>07</title>
      <author><first>Laurent</first><last>Besacier</last></author>
      <author><first>Amar</first><last>Mahdhaoui</last></author>
      <author><first>Viet-Bac</first><last>Le</last></author>
      <url hash="5b5cbc8c">2007.iwslt-1.20</url>
      <abstract>This paper is a description of the system presented by the LIG laboratory to the IWSLT07 speech translation evaluation. The LIG participated, for the first time this year, in the Arabic to English speech translation task. For translation, we used a conventional statistical phrase-based system developed using the moses open source decoder. Our baseline MT system is described and we discuss particularly the use of an additional bilingual dictionary which seems useful when few training data is available. The main contribution of this paper concerns the proposal of a lattice decomposition algorithm that allows transforming a word lattice into a sub word lattice compatible with our MT model that uses word segmentation on the Arabic part. The lattice is then transformed into a confusion network which can be directly decoded into moses. The results show that this method outperforms the conventional 1-best translation which consists in translating only the most probable ASR hypothesis. The best BLEU score, from ASR output obtained on IWSLT06 evaluation data is 0.2253. The results confirm the interest of full CN decoding for speech translation, compared to traditional ASR 1-best approach. Our primary system was ranked 7/14 for IWSLT07 AE ASR task with a BLEU score of 0.3804.</abstract>
      <bibkey>besacier-etal-2007-lig</bibkey>
    </paper>
    <paper id="21">
      <title><fixed-case>NUDT</fixed-case> machine translation system for <fixed-case>IWSLT</fixed-case>2007</title>
      <author><first>Wen-Han</first><last>Chao</last></author>
      <author><first>Zhou-Jun</first><last>Li</last></author>
      <url hash="6ef5aed3">2007.iwslt-1.21</url>
      <abstract>In this paper, we describe our machine translation system which was used for the Chinese-to-English task in the IWSLT2007 evaluation campaign. The system is a statistical machine translation (SMT) system, while containing an example-based decoder. In this way, it will help to solve the re-ordering problem and other problems for spoken language MT, such as lots of omissions, idioms etc. We report the results of the system for the provided evaluation sets.</abstract>
      <bibkey>chao-li-2007-nudt</bibkey>
    </paper>
    <paper id="22">
      <title><fixed-case>MISTRAL</fixed-case>: a lattice translation system for <fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Alexandre</first><last>Patry</last></author>
      <author><first>Philippe</first><last>Langlais</last></author>
      <author><first>Frédéric</first><last>Béchet</last></author>
      <url hash="22e059fe">2007.iwslt-1.22</url>
      <abstract>This paper describes MISTRAL, the lattice translation system that we developed for the Italian-English track of the International Workshop on Spoken Language Translation 2007. MISTRAL is a discriminative phrase-based system that translates a source word lattice in two passes. The first pass extracts a list of top ranked sentence pairs from the lattice and the second pass rescores this list with more complex features. Our experiments show that our system, when translating pruned lattices, is at least as good as a fair baseline that translates the first ranked sentences returned by a speech recognition system.</abstract>
      <bibkey>patry-etal-2007-mistral</bibkey>
    </paper>
    <paper id="23">
      <title>Statistical machine translation using large <fixed-case>J</fixed-case>/<fixed-case>E</fixed-case> parallel corpus and long phrase tables</title>
      <author><first>Jin’ichi</first><last>Murakami</last></author>
      <author><first>Masato</first><last>Tokuhisa</last></author>
      <author><first>Satoru</first><last>Ikehara</last></author>
      <url hash="cdb29703">2007.iwslt-1.23</url>
      <abstract>Our statistical machine translation system that uses large Japanese-English parallel sentences and long phrase tables is described. We collected 698,973 Japanese-English parallel sentences, and we used long phrase tables. Also, we utilized general tools for statistical machine translation, such as ”Giza++”[1], ”moses”[2], and ”training-phrasemodel.perl”[3]. We used these data and these tools, We challenge the contest for IWSLT07. In which task was the result (0.4321 BLEU) obtained.</abstract>
      <bibkey>murakami-etal-2007-statistical</bibkey>
    </paper>
    <paper id="24">
      <title>The <fixed-case>XMU</fixed-case> <fixed-case>SMT</fixed-case> system for <fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Yidong</first><last>Chen</last></author>
      <author><first>Xiaodong</first><last>Shi</last></author>
      <author><first>Changle</first><last>Zhou</last></author>
      <url hash="076d56bd">2007.iwslt-1.24</url>
      <abstract>In this paper, an overview of the XMU statistical machine translation (SMT) system for the 2007 IWSLT Speech Translation Evaluation is given. Our system is a phrase-based system with a reordering model based on chunking and reordering of source language. In this year’s evaluation, we participated in the open data track for Clean Transcripts for the Chinese-English translation direction. The system ranked the 12th among the 15 participating systems.</abstract>
      <bibkey>chen-etal-2007-xmu</bibkey>
    </paper>
    <paper id="25">
      <title>The <fixed-case>RWTH</fixed-case> machine translation system for <fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Arne</first><last>Mauser</last></author>
      <author><first>David</first><last>Vilar</last></author>
      <author><first>Gregor</first><last>Leusch</last></author>
      <author><first>Yuqi</first><last>Zhang</last></author>
      <author><first>Hermann</first><last>Ney</last></author>
      <url hash="9a591e8b">2007.iwslt-1.25</url>
      <abstract>The RWTH system for the IWSLT 2007 evaluation is a combination of several statistical machine translation systems. The combination includes Phrase-Based models, a n-gram translation model and a hierarchical phrase model. We describe the individual systems and the method that was used for combining the system outputs. Compared to our 2006 system, we newly introduce a hierarchical phrase-based translation model and show improvements in system combination for Machine Translation. RWTH participated in the Italian-to-English and Chinese-to-English translation directions.</abstract>
      <bibkey>mauser-etal-2007-rwth</bibkey>
    </paper>
    <paper id="26">
      <title>The <fixed-case>TALP</fixed-case> ngram-based <fixed-case>SMT</fixed-case> system for <fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Patrik</first><last>Lambert</last></author>
      <author><first>Marta R.</first><last>Costa-jussà</last></author>
      <author><first>Josep M.</first><last>Crego</last></author>
      <author><first>Maxim</first><last>Khalilov</last></author>
      <author><first>José B.</first><last>Mariño</last></author>
      <author><first>Rafael E.</first><last>Banchs</last></author>
      <author><first>José A. R.</first><last>Fonollosa</last></author>
      <author><first>Holger</first><last>Schwenk</last></author>
      <url hash="e95a9ab7">2007.iwslt-1.26</url>
      <abstract>This paper describes TALPtuples, the 2007 N-gram-based statistical machine translation system developed at the TALP Research Center of the UPC (Universitat Polite`cnica de Catalunya) in Barcelona. Emphasis is put on improvements and extensions of the system of previous years. Mainly, these include optimizing alignment parameters in function of translation metric scores and rescoring with a neural network language model. Results on two translation directions are reported, namely from Arabic and Chinese into English, thoroughly explaining all language-related preprocessing and translation schemes.</abstract>
      <bibkey>lambert-etal-2007-talp</bibkey>
    </paper>
    <paper id="27">
      <title>The <fixed-case>TÜBÍTAK</fixed-case>-<fixed-case>UEKAE</fixed-case> statistical machine translation system for <fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Coşkun</first><last>Mermer</last></author>
      <author><first>Hamza</first><last>Kaya</last></author>
      <author><first>Mehmet Uğur</first><last>Doğan</last></author>
      <url hash="baade68b">2007.iwslt-1.27</url>
      <abstract>We describe the TÜBITAK-UEKAE system that participated in the Arabic-to-English and Japanese-to-English translation tasks of the IWSLT 2007 evaluation campaign. Our system is built on the open-source phrase-based statistical machine translation software Moses. Among available corpora and linguistic resources, only the supplied training data and an Arabic morphological analyzer are used in the system. We present the run-time lexical approximation method to cope with out-of-vocabulary words during decoding. We tested our system under both automatic speech recognition (ASR) and clean transcript (clean) input conditions. Our system was ranked first in both Arabic-to-English and Japanese-to-English tasks under the “clean” condition.</abstract>
      <bibkey>mermer-etal-2007-tubitak</bibkey>
    </paper>
    <paper id="28">
      <title>The <fixed-case>U</fixed-case>niversity of <fixed-case>M</fixed-case>aryland translation system for <fixed-case>IWSLT</fixed-case> 2007</title>
      <author><first>Christopher J.</first><last>Dyer</last></author>
      <url hash="a3231d19">2007.iwslt-1.28</url>
      <abstract>This paper describes the University of Maryland statistical machine translation system used in the IWSLT 2007 evaluation. Our focus was threefold: using hierarchical phrase-based models in spoken language translation, the incorporation of sub-lexical information in model estimation via morphological analysis (Arabic) and word and character segmentation (Chinese), and the use of n-gram sequence models for source-side punctuation prediction. Our efforts yield significant improvements in Chinese-English and Arabic-English translation tasks for both spoken language and human transcription conditions.</abstract>
      <bibkey>dyer-2007-university</bibkey>
    </paper>
  </volume>
</collection>
