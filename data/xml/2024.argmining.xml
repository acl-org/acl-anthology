<?xml version='1.0' encoding='UTF-8'?>
<collection id="2024.argmining">
  <volume id="1" ingest-date="2024-07-23" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 11th Workshop on Argument Mining (ArgMining 2024)</booktitle>
      <editor><first>Yamen</first><last>Ajjour</last></editor>
      <editor><first>Roy</first><last>Bar-Haim</last></editor>
      <editor><first>Roxanne</first><last>El Baff</last></editor>
      <editor><first>Zhexiong</first><last>Liu</last></editor>
      <editor><first>Gabriella</first><last>Skitalinskaya</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Bangkok, Thailand</address>
      <month>August</month>
      <year>2024</year>
      <url hash="fd001b46">2024.argmining-1</url>
      <venue>argmining</venue>
    </meta>
    <paper id="1">
      <title><fixed-case>ARIES</fixed-case>: A General Benchmark for Argument Relation Identification</title>
      <author><first>Debela</first><last>Gemechu</last></author>
      <author><first>Ramon</first><last>Ruiz-Dolz</last><affiliation>University of Dundee</affiliation></author>
      <author><first>Chris</first><last>Reed</last><affiliation>University of Dundee</affiliation></author>
      <pages>1-14</pages>
      <abstract>Measuring advances in argument mining is one of the main challenges in the area. Different theories of argument, heterogeneous annotations, and a varied set of argumentation domains make it difficult to contextualise and understand the results reported in different work from a general perspective. In this paper, we present ARIES, a general benchmark for Argument Relation Identification aimed at providing with a standard evaluation for argument mining research. ARIES covers the three different language modelling approaches: sequence and token modelling, and sequence-to-sequence-to-sequence alignment, together with the three main Transformer-based model architectures: encoder-only, decoder-only, and encoder-decoder. Furthermore, the benchmark consists of eight different argument mining datasets, covering the most common argumentation domains, and standardised with the same annotation structures. This paper provides a first comprehensive and comparative set of results in argument mining across a broad range of configurations to compare with, both advancing the state-of-the-art, and establishing a standard way to measure future advances in the area. Across varied task setups and architectures, our experiments reveal consistent challenges in cross-dataset evaluation, with notably poor results. Given the models’ struggle to acquire transferable skills, the task remains challenging, opening avenues for future research.</abstract>
      <url hash="062a6bae">2024.argmining-1.1</url>
      <bibkey>gemechu-etal-2024-aries</bibkey>
    </paper>
    <paper id="2">
      <title>Detecting Scientific Fraud Using Argument Mining</title>
      <author><first>Gabriel</first><last>Freedman</last></author>
      <author><first>Francesca</first><last>Toni</last><affiliation>Imperial College London</affiliation></author>
      <pages>15-28</pages>
      <abstract>A proliferation of fraudulent scientific research in recent years has precipitated a greater interest in more effective methods of detection. There are many varieties of academic fraud, but a particularly challenging type to detect is the use of paper mills and the faking of peer-review. To the best of our knowledge, there have so far been no attempts to automate this process.The complexity of this issue precludes the use of heuristic methods, like pattern-matching techniques, which are employed for other types of fraud. Our proposed method in this paper uses techniques from the Computational Argumentation literature (i.e. argument mining and argument quality evaluation). Our central hypothesis stems from the assumption that articles that have not been subject to the proper level of scrutiny will contain poorly formed and reasoned arguments, relative to legitimately published papers. We use a variety of corpora to test this approach, including a collection of abstracts taken from retracted papers. We show significant improvement compared to a number of baselines, suggesting that this approach merits further investigation.</abstract>
      <url hash="c9bfc833">2024.argmining-1.2</url>
      <bibkey>freedman-toni-2024-detecting</bibkey>
    </paper>
    <paper id="3">
      <title><fixed-case>D</fixed-case>eep<fixed-case>CT</fixed-case>-enhanced Lexical Argument Retrieval</title>
      <author><first>Alexander</first><last>Bondarenko</last><affiliation>Friedrich-Schiller Universität Jena and Universität Leipzig</affiliation></author>
      <author><first>Maik</first><last>Fröbe</last><affiliation>Martin-Luther Universität Halle-Wittenberg</affiliation></author>
      <author><first>Danik</first><last>Hollatz</last><affiliation>Martin-Luther-Universität Halle-Wittenberg</affiliation></author>
      <author><first>Jan</first><last>Merker</last><affiliation>Friedrich-Schiller Universität Jena</affiliation></author>
      <author><first>Matthias</first><last>Hagen</last><affiliation>Friedrich-Schiller Universität Jena</affiliation></author>
      <pages>29-35</pages>
      <abstract>The recent Touché lab’s argument retrieval task focuses on controversial topics like ‘Should bottled water be banned?’ and asks to retrieve relevant pro/con arguments. Interestingly, the most effective systems submitted to that task still are based on lexical retrieval models like BM25. In other domains, neural retrievers that capture semantics are more effective than lexical baselines. To add more “semantics” to argument retrieval, we propose to combine lexical models with DeepCT-based document term weights. Our evaluation shows that our approach is more effective than all the systems submitted to the Touché lab while being on par with modern neural re-rankers that themselves are computationally more expensive.</abstract>
      <url hash="1442d97c">2024.argmining-1.3</url>
      <bibkey>bondarenko-etal-2024-deepct</bibkey>
    </paper>
    <paper id="4">
      <title>Exploiting Dialogue Acts and Context to Identify Argumentative Relations in Online Debates</title>
      <author><first>Stefano</first><last>Mezza</last></author>
      <author><first>Wayne</first><last>Wobcke</last><affiliation>University of New South Wales</affiliation></author>
      <author><first>Alan</first><last>Blair</last></author>
      <pages>36-45</pages>
      <abstract>Argumentative Relation Classification is the task of determining the relationship between two contributions in the context of an argumentative dialogue. Existing models in the literature rely on a combination of lexical features and pre-trained language models to tackle this task; while this approach is somewhat effective, it fails to take into account the importance of pragmatic features such as the illocutionary force of the argument or the structure of previous utterances in the discussion; relying solely on lexical features also produces models that over-fit their initial training set and do not scale to unseen domains. In this work, we introduce ArguNet, a new model for Argumentative Relation Classification which relies on a combination of Dialogue Acts and Dialogue Context to improve the representation of argument structures in opinionated dialogues. We show that our model achieves state-of-the-art results on the Kialo benchmark test set, and provide evidence of its robustness in an open-domain scenario.</abstract>
      <url hash="6d46182b">2024.argmining-1.4</url>
      <bibkey>mezza-etal-2024-exploiting</bibkey>
    </paper>
    <paper id="5">
      <title>Multi-Task Learning Improves Performance in Deep Argument Mining Models</title>
      <author><first>Amirhossein</first><last>Farzam</last><affiliation>Duke University, Duke University</affiliation></author>
      <author><first>Shashank</first><last>Shekhar</last><affiliation>New York University</affiliation></author>
      <author><first>Isaac</first><last>Mehlhaff</last><affiliation>Texas A&amp;M University - College Station and Texas A&amp;M University - College Station</affiliation></author>
      <author><first>Marco</first><last>Morucci</last></author>
      <pages>46-58</pages>
      <abstract>The successful analysis of argumentative techniques in user-generated text is central to many downstream tasks such as political and market analysis. Recent argument mining tools use state-of-the-art deep learning methods to extract and annotate argumentative techniques from various online text corpora, but each task is treated as separate and different bespoke models are fine-tuned for each dataset. We show that different argument mining tasks share common semantic and logical structure by implementing a multi-task approach to argument mining that meets or exceeds performance from existing methods for the same problems. Our model builds a shared representation of the input and exploits similarities between tasks in order to further boost performance via parameter-sharing. Our results are important for argument mining as they show that different tasks share substantial similarities and suggest a holistic approach to the extraction of argumentative techniques from text.</abstract>
      <url hash="4eafe73f">2024.argmining-1.5</url>
      <bibkey>farzam-etal-2024-multi</bibkey>
    </paper>
    <paper id="6">
      <title>Computational Modelling of Undercuts in Real-world Arguments</title>
      <author><first>Yuxiao</first><last>Ye</last></author>
      <author><first>Simone</first><last>Teufel</last><affiliation>Department of Computer Science and Technology (Formerly Computer Laboratory)</affiliation></author>
      <pages>59-68</pages>
      <abstract>Argument Mining (AM) is the task of automatically analysing arguments, such that the unstructured information contained in them is converted into structured representations. Undercut is a unique structure in arguments, as it challenges the relationship between a premise and a claim, unlike direct attacks which challenge the claim or the premise itself. Undercut is also an important counterargument device as it often reflects the value of arguers. However, undercuts have not received the attention in the filed of AM they should have — there is neither much corpus data about undercuts, nor an existing AM model that can automatically recognise them. In this paper, we present a real-world dataset of arguments with explicitly annotated undercuts, and the first computational model that is able to recognise them. The dataset consists of 400 arguments, containing 326 undercuts. On this dataset, our approach beats a strong baseline in undercut recognition, with <tex-math>F_1 = 38.8\%</tex-math>, which is comparable to the performance on recognising direct attacks. We also conduct experiments on a benchmark dataset containing no undercuts, and prove that our approach is as good as the state of the art in terms of recognising the overall structure of arguments. Our work pioneers the systematic analysis and computational modelling of undercuts in real-world arguments, setting a foundation for future research in the role of undercuts in the dynamics of argumentation.</abstract>
      <url hash="5fb4b111">2024.argmining-1.6</url>
      <bibkey>ye-teufel-2024-computational</bibkey>
    </paper>
    <paper id="7">
      <title><fixed-case>MAMK</fixed-case>it: A Comprehensive Multimodal Argument Mining Toolkit</title>
      <author><first>Eleonora</first><last>Mancini</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Federico</first><last>Ruggeri</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Stefano</first><last>Colamonaco</last></author>
      <author><first>Andrea</first><last>Zecca</last></author>
      <author><first>Samuele</first><last>Marro</last><affiliation>University of Bologna and Institute of Superior Studies</affiliation></author>
      <author><first>Paolo</first><last>Torroni</last><affiliation>University of Bologna</affiliation></author>
      <pages>69-82</pages>
      <abstract>Multimodal Argument Mining (MAM) is a recent area of research aiming to extend argument analysis and improve discourse understanding by incorporating multiple modalities. Initial results confirm the importance of paralinguistic cues in this field. However, the research community still lacks a comprehensive platform where results can be easily reproduced, and methods and models can be stored, compared, and tested against a variety of benchmarks. To address these challenges, we propose MAMKit, an open, publicly available, PyTorch toolkit that consolidates datasets and models, providing a standardized platform for experimentation. MAMKit also includes some new baselines, designed to stimulate research on text and audio encoding and fusion for MAM tasks. Our initial results with MAMKit indicate that advancements in MAM require novel annotation processes to encompass auditory cues effectively.</abstract>
      <url hash="b49b2de2">2024.argmining-1.7</url>
      <bibkey>mancini-etal-2024-mamkit</bibkey>
    </paper>
    <paper id="8">
      <title>Overview of <fixed-case>D</fixed-case>ial<fixed-case>AM</fixed-case>-2024: Argument Mining in Natural Language Dialogues</title>
      <author><first>Ramon</first><last>Ruiz-Dolz</last><affiliation>Centre for Argument Technology (ARG-tech), University of Dundee</affiliation></author>
      <author><first>John</first><last>Lawrence</last><affiliation>Centre for Argument Technology (ARG-tech), University of Dundee</affiliation></author>
      <author><first>Ella</first><last>Schad</last><affiliation>Centre for Argument Technology (ARG-tech), University of Dundee</affiliation></author>
      <author><first>Chris</first><last>Reed</last><affiliation>Centre for Argument Technology (ARG-tech), University of Dundee</affiliation></author>
      <pages>83-92</pages>
      <abstract>Argumentation is the process by which humans rationally elaborate their thoughts and opinions in written (e.g., essays) or spoken (e.g., debates) contexts. Argument Mining research, however, has been focused on either written argumentation or spoken argumentation but without considering any additional information, e.g., speech acts and intentions. In this paper, we present an overview of DialAM-2024, the first shared task in dialogical argument mining, where argumentative relations and speech illocutions are modelled together in a unified framework. The task was divided into two different sub-tasks: the identification of propositional relations and the identification of illocutionary relations. Six different teams explored different methodologies to leverage both sources of information to reconstruct argument maps containing the locutions uttered in the speeches and the argumentative propositions implicit in them. The best performing team achieved an F1-score of 67.05% in the overall evaluation of the reconstruction of complete argument maps, considering both sub-tasks included in the DialAM-2024 shared task.</abstract>
      <url hash="8dd5e35e">2024.argmining-1.8</url>
      <bibkey>ruiz-dolz-etal-2024-overview</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>DFKI</fixed-case>-<fixed-case>MLST</fixed-case> at <fixed-case>D</fixed-case>ial<fixed-case>AM</fixed-case>-2024 Shared Task: System Description</title>
      <author><first>Arne</first><last>Binder</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Tatiana</first><last>Anikina</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Leonhard</first><last>Hennig</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <author><first>Simon</first><last>Ostermann</last><affiliation>German Research Center for Artificial Intelligence (DFKI)</affiliation></author>
      <pages>93-102</pages>
      <abstract>This paper presents the dfki-mlst submission for the DialAM shared task (Ruiz-Dolz et al., 2024) on identification of argumentative and illocutionary relations in dialogue. Our model achieves best results in the global setting: 48.25 F1 at the focused level when looking only at the related arguments/locutions and 67.05 F1 at the general level when evaluating the complete argument maps. We describe our implementation of the data pre-processing, relation encoding and classification, evaluating 11 different base models and performing experiments with, e.g., node text combination and data augmentation. Our source code is publicly available.</abstract>
      <url hash="cf9abfdc">2024.argmining-1.9</url>
      <bibkey>binder-etal-2024-dfki</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>K</fixed-case>now<fixed-case>C</fixed-case>omp at <fixed-case>D</fixed-case>ial<fixed-case>AM</fixed-case>-2024: Fine-tuning Pre-trained Language Models for Dialogical Argument Mining with Inference Anchoring Theory</title>
      <author><first>Yuetong</first><last>Wu</last><affiliation>Department of Computer Science and Engineering, HKUST, Hong Kong SAR, China</affiliation></author>
      <author><first>Yukai</first><last>Zhou</last><affiliation>Department of Computer Science and Engineering, HKUST, Hong Kong SAR, China</affiliation></author>
      <author><first>Baixuan</first><last>Xu</last><affiliation>Department of Computer Science and Engineering, HKUST, Hong Kong SAR, China</affiliation></author>
      <author><first>Weiqi</first><last>Wang</last><affiliation>Department of Computer Science and Engineering, HKUST, Hong Kong SAR, China</affiliation></author>
      <author><first>Yangqiu</first><last>Song</last><affiliation>Department of Computer Science and Engineering, HKUST, Hong Kong SAR, China</affiliation></author>
      <pages>103-109</pages>
      <abstract>In this paper, we present our framework for DialAM-2024 TaskA: Identification of Propositional Relations and TaskB: Identification of Illocutionary Relations. The goal of task A is to detect argumentative relations between propositions in an argumentative dialogue. i.e., Inference, Conflict, Rephrase while task B aims to detect illocutionary relations between locutions and argumentative propositions in a dialogue. e.g., Asserting, Agreeing, Arguing, Disagreeing. Noticing the definition of the relations are strict and professional under the context of IAT framework, we meticulously curate prompts which not only incorporate formal definition of the relations, but also exhibit the subtle differences between them. The PTLMs are then fine-tuned on the human-designed prompts to enhance its discrimination capability in classifying different theoretical relations by learning from the human instruction and the ground truth samples. After extensive experiments, a fine-tuned DeBERTa-v3-base model exhibits the best performance among all PTLMs with an F1 score of 78.90% on Task B. It is worth noticing that our framework ranks #2 in the ILO - General official leaderboard.</abstract>
      <url hash="b13a27c8">2024.argmining-1.10</url>
      <bibkey>wu-etal-2024-knowcomp</bibkey>
    </paper>
    <paper id="11">
      <title><fixed-case>KNOWCOMP</fixed-case> <fixed-case>POKEMON</fixed-case> Team at <fixed-case>D</fixed-case>ial<fixed-case>AM</fixed-case>-2024: A Two-Stage Pipeline for Detecting Relations in Dialogue Argument Mining</title>
      <author><first>Zihao</first><last>Zheng</last><affiliation>Harbin Institute of Technology</affiliation></author>
      <author><first>Zhaowei</first><last>Wang</last><affiliation>Department of Computer Science and Engineering, HKUST</affiliation></author>
      <author><first>Qing</first><last>Zong</last><affiliation>Department of Computer Science and Engineering, HKUST</affiliation></author>
      <author><first>Yangqiu</first><last>Song</last><affiliation>Department of Computer Science and Engineering, HKUST</affiliation></author>
      <pages>110-118</pages>
      <abstract>Dialogue Argument Mining(DialAM) is an important branch of Argument Mining(AM). DialAM-2024 is a shared task focusing on dialogue argument mining, which requires us to identify argumentative relations and illocutionary relations among proposition nodes and locution nodes. To accomplish this, we propose a two-stage pipeline, which includes the Two-Step S-Node Prediction Model in Stage 1 and the YA-Node Prediction Model in Stage 2. We also augment the training data in both stages and introduce context in the prediction of Stage 2. We successfully completed the task and achieved good results. Our team KNOWCOMP POKEMON ranked 1st in the ARI Focused score and 4th in the Global Focused score.</abstract>
      <url hash="e64f1019">2024.argmining-1.11</url>
      <bibkey>zheng-etal-2024-knowcomp</bibkey>
    </paper>
    <paper id="12">
      <title>Pungene at <fixed-case>D</fixed-case>ial<fixed-case>AM</fixed-case>-2024: Identification of Propositional and Illocutionary Relations</title>
      <author><first>Sirawut</first><last>Chaixanien</last><affiliation>Cornell University</affiliation></author>
      <author><first>Eugene</first><last>Choi</last><affiliation>Cornell University</affiliation></author>
      <author><first>Shaden</first><last>Shaar</last><affiliation>Cornell University</affiliation></author>
      <author><first>Claire</first><last>Cardie</last><affiliation>Cornell University</affiliation></author>
      <pages>119-123</pages>
      <abstract>In this paper we tackle the shared task DialAM-2024 aiming to annotate dialogue based on the inference anchoring theory (IAT). The task can be split into two parts, identification of propositional relations and identification of illocutionary relations. We propose a pipelined system made up of three parts: (1) locutionary-propositions relation detection, (2) propositional relations detection, and (3) illocutionary relations identification. We fine-tune models independently for each step, and combine at the end for the final system. Our proposed system ranks second overall compared to other participants in the shared task, scoring an average f1-score on both sub-parts of 63.7.</abstract>
      <url hash="a81b88bc">2024.argmining-1.12</url>
      <bibkey>chaixanien-etal-2024-pungene</bibkey>
    </paper>
    <paper id="13">
      <title>Turiya at <fixed-case>D</fixed-case>ial<fixed-case>AM</fixed-case>-2024: Inference Anchoring Theory Based <fixed-case>LLM</fixed-case> Parsers</title>
      <author><first>Sougata</first><last>Saha</last><affiliation>State University of New York at Buffalo</affiliation></author>
      <author><first>Rohini</first><last>Srihari</last><affiliation>State University of New York at Buffalo</affiliation></author>
      <pages>124-129</pages>
      <abstract>Representing discourse as argument graphs facilitates robust analysis. Although computational frameworks for constructing graphs from monologues exist, there is a lack of frameworks for parsing dialogue. Inference Anchoring Theory (IAT) is a theoretical framework for extracting graphical argument structures and relationships from dialogues. Here, we introduce computational models for implementing the IAT framework for parsing dialogues. We experiment with a classification-based biaffine parser and Large Language Model (LLM)-based generative methods and compare them. Our results demonstrate the utility of finetuning LLMs for constructing IAT-based argument graphs from dialogues, which is a nuanced task.</abstract>
      <url hash="eaace3c6">2024.argmining-1.13</url>
      <bibkey>saha-srihari-2024-turiya</bibkey>
    </paper>
    <paper id="14">
      <title>Overview of <fixed-case>P</fixed-case>erpective<fixed-case>A</fixed-case>rg2024 The First Shared Task on Perspective Argument Retrieval</title>
      <author><first>Neele</first><last>Falk</last></author>
      <author><first>Andreas</first><last>Waldis</last></author>
      <author><first>Iryna</first><last>Gurevych</last></author>
      <pages>130-149</pages>
      <abstract>Argument retrieval is the task of finding relevant arguments for a given query. While existing approaches rely solely on the semantic alignment of queries and arguments, this first shared task on perspective argument retrieval incorporates perspectives during retrieval, ac- counting for latent influences in argumenta- tion. We present a novel multilingual dataset covering demographic and socio-cultural (so- cio) variables, such as age, gender, and politi- cal attitude, representing minority and major- ity groups in society. We distinguish between three scenarios to explore how retrieval systems consider explicitly (in both query and corpus) and implicitly (only in query) formulated per- spectives. This paper provides an overview of this shared task and summarizes the results of the six submitted systems. We find substantial challenges in incorporating perspectivism, especially when aiming for personalization based solely on the text of arguments without explicitly providing socio profiles. Moreover, re- trieval systems tend to be biased towards the majority group but partially mitigate bias for the female gender. While we bootstrap per- spective argument retrieval, further research is essential to optimize retrieval systems to facilitate personalization and reduce polarization.</abstract>
      <url hash="5f27538b">2024.argmining-1.14</url>
      <bibkey>falk-etal-2024-overview</bibkey>
    </paper>
    <paper id="15">
      <title>Sövereign at The Perspective Argument Retrieval Shared Task 2024: Using <fixed-case>LLM</fixed-case>s with Argument Mining</title>
      <author><first>Robert</first><last>Günzler</last></author>
      <author><first>Özge</first><last>Sevgili</last></author>
      <author><first>Steffen</first><last>Remus</last><affiliation>Universität Hamburg</affiliation></author>
      <author><first>Chris</first><last>Biemann</last><affiliation>U Hamburg</affiliation></author>
      <author><first>Irina</first><last>Nikishina</last></author>
      <pages>150-158</pages>
      <abstract>This paper presents the Sövereign submission for the shared task on perspective argument retrieval for the Argument Mining Workshop 2024. The main challenge is to perform argument retrieval considering socio-cultural aspects such as political interests, occupation, age, and gender. To address the challenge, we apply open-access Large Language Models (Mistral-7b) in a zero-shot fashion for re-ranking and explicit similarity scoring. Additionally, we combine different features in an ensemble setup using logistic regression. Our system ranks second in the competition for all test set rounds on average for the logistic regression approach using LLM similarity scores as a feature. In addition to the description of the approach, we also provide further results of our ablation study. Our code will be open-sourced upon acceptance.</abstract>
      <url hash="f28b9e7c">2024.argmining-1.15</url>
      <bibkey>gunzler-etal-2024-sovereign</bibkey>
    </paper>
    <paper id="16">
      <title>Turiya at <fixed-case>P</fixed-case>erpective<fixed-case>A</fixed-case>rg2024: A Multilingual Argument Retriever and Reranker</title>
      <author><first>Sougata</first><last>Saha</last><affiliation>Mohamed bin Zayed University of Artificial Intelligence</affiliation></author>
      <author><first>Rohini</first><last>Srihari</last><affiliation>State University of New York at Buffalo</affiliation></author>
      <pages>159-163</pages>
      <abstract>While general argument retrieval systems have significantly matured, multilingual argument retrieval in a socio-cultural setting is an overlooked problem. Advancements in such systems are imperative to enhance the inclusivity of society. The Perspective Argument Retrieval (PAR) task addresses these aspects and acknowledges their potential latent influence on argumentation. Here, we present a multilingual retrieval system for PAR that accounts for societal diversity during retrieval. Our approach couples a retriever and a re-ranker and spans multiple languages, thus factoring in diverse socio-cultural settings. The performance of our end-to-end system on three distinct test sets testify to its robustness.</abstract>
      <url hash="20c6867c">2024.argmining-1.16</url>
      <bibkey>saha-srihari-2024-turiya-perpectivearg2024</bibkey>
    </paper>
    <paper id="17">
      <title>Twente-<fixed-case>BMS</fixed-case>-<fixed-case>NLP</fixed-case> at <fixed-case>P</fixed-case>erspective<fixed-case>A</fixed-case>rg 2024: Combining Bi-Encoder and Cross-Encoder for Argument Retrieval</title>
      <author><first>Leixin</first><last>Zhang</last></author>
      <author><first>Daniel</first><last>Braun</last><affiliation>University of Twente</affiliation></author>
      <pages>164-168</pages>
      <abstract>The paper describes our system for the Perspective Argument Retrieval Shared Task. The shared task consists of three scenarios in which relevant political arguments have to be retrieved based on queries (Scenario 1). In Scenario 2 explicit socio-cultural properties are provided and in Scenario 3 implicit socio-cultural properties within the arguments have to be used. We combined a Bi-Encoder and a Cross-Encoder to retrieve relevant arguments for each query. For the third scenario, we extracted linguistic features to predict socio-demographic labels as a separate task. However, the socio-demographic match task proved challenging due to the constraints of argument lengths and genres. The described system won both tracks of the shared task.</abstract>
      <url hash="d19ac77f">2024.argmining-1.17</url>
      <bibkey>zhang-braun-2024-twente</bibkey>
    </paper>
    <paper id="18">
      <title><fixed-case>GESIS</fixed-case>-<fixed-case>DSM</fixed-case> at <fixed-case>P</fixed-case>erpective<fixed-case>A</fixed-case>rg2024: A Matter of Style? Socio-Cultural Differences in Argumentation</title>
      <author><first>Maximilian</first><last>Maurer</last><affiliation>GESIS Leibniz Institute for the Social Sciences</affiliation></author>
      <author><first>Julia</first><last>Romberg</last><affiliation>GESIS Leibniz Institute for the Social Sciences</affiliation></author>
      <author><first>Myrthe</first><last>Reuver</last><affiliation>Vrije Universiteit Amsterdam</affiliation></author>
      <author><first>Negash</first><last>Weldekiros</last></author>
      <author><first>Gabriella</first><last>Lapesa</last><affiliation>GESIS – Leibniz Institute for the Social Sciences and Heinrich-Heine University Düsseldorf</affiliation></author>
      <pages>169-181</pages>
      <abstract>This paper describes the contribution of team GESIS-DSM to the Perspective Argument Retrieval Task, a task on retrieving socio-culturally relevant and diverse arguments for different user queries. Our experiments and analyses aim to explore the nature of the socio-cultural specialization in argument retrieval: (how) do the arguments written by different socio-cultural groups differ? We investigate the impact of content and style for the task of identifying arguments relevant to a query and a certain demographic attribute. In its different configurations, our system employs sentence embedding representations, arguments generated with Large Language Model, as well as stylistic features. final method places third overall in the shared task, and, in comparison, does particularly well in the most difficult evaluation scenario, where the socio-cultural background of the argument author is implicit (i.e. has to be inferred from the text). This result indicates that socio-cultural differences in argument production may indeed be a matter of style.</abstract>
      <url hash="2a673163">2024.argmining-1.18</url>
      <bibkey>maurer-etal-2024-gesis</bibkey>
    </paper>
    <paper id="19">
      <title><fixed-case>XFACT</fixed-case> Team0331 at <fixed-case>P</fixed-case>erspective<fixed-case>A</fixed-case>rg2024: Sampling from Bounded Clusters for Diverse Relevant Argument Retrieval</title>
      <author><first>Wan Ju</first><last>Kang</last></author>
      <author><first>Jiyoung</first><last>Han</last><affiliation>kaist</affiliation></author>
      <author><first>Jaemin</first><last>Jung</last></author>
      <author><first>James</first><last>Thorne</last><affiliation>KAIST</affiliation></author>
      <pages>182-188</pages>
      <abstract>This paper reports on the argument mining system submitted to the ArgMining workshop 2024 for The Perspective Argument Retrieval Shared Task (Falk et al., 2024). We com- bine the strengths of a smaller Sentence BERT model and a Large Language Model: the for- mer is fine-tuned for a contrastive embedding objective and a classification objective whereas the latter is invoked to augment the query and populate the latent space with diverse relevant arguments. We conduct an ablation study on these components to find that each contributes substantially to the diversity and relevance cri- teria for the top-k retrieval of arguments from the given corpus.</abstract>
      <url hash="fa17d111">2024.argmining-1.19</url>
      <bibkey>kang-etal-2024-xfact</bibkey>
    </paper>
  </volume>
</collection>
