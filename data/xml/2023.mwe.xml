<?xml version='1.0' encoding='UTF-8'?>
<collection id="2023.mwe">
  <volume id="1" ingest-date="2023-04-29" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 19th Workshop on Multiword Expressions (MWE 2023)</booktitle>
      <editor><first>Archna</first><last>Bhatia</last></editor>
      <editor><first>Kilian</first><last>Evang</last></editor>
      <editor><first>Marcos</first><last>Garcia</last></editor>
      <editor><first>Voula</first><last>Giouli</last></editor>
      <editor><first>Lifeng</first><last>Han</last></editor>
      <editor><first>Shiva</first><last>Taslimipoor</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Dubrovnik, Croatia</address>
      <month>May</month>
      <year>2023</year>
      <url hash="e3bac99e">2023.mwe-1</url>
      <venue>mwe</venue>
    </meta>
    <frontmatter>
      <url hash="0ebf9be9">2023.mwe-1.0</url>
      <bibkey>mwe-2023-multiword</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Token-level Identification of Multiword Expressions using Pre-trained Multilingual Language Models</title>
      <author><first>Raghuraman</first><last>Swaminathan</last><affiliation>University of New Brunswick</affiliation></author>
      <author><first>Paul</first><last>Cook</last><affiliation>University of New Brunswick</affiliation></author>
      <pages>1-6</pages>
      <abstract>In this paper, we consider novel cross-lingual settings for multiword expression (MWE) identification (Ramisch et al., 2020) and idiomaticity prediction (Tayyar Madabushi et al., 2022) in which systems are tested on languages that are unseen during training. Our findings indicate that pre-trained multilingual language models are able to learn knowledge about MWEs and idiomaticity that is not languagespecific. Moreover, we find that training data from other languages can be leveraged to give improvements over monolingual models.</abstract>
      <url hash="e31eb866">2023.mwe-1.1</url>
      <bibkey>swaminathan-cook-2023-token</bibkey>
      <video href="2023.mwe-1.1.mp4"/>
      <doi>10.18653/v1/2023.mwe-1.1</doi>
    </paper>
    <paper id="4">
      <title><fixed-case>R</fixed-case>omanian Multiword Expression Detection Using Multilingual Adversarial Training and Lateral Inhibition</title>
      <author><first>Andrei</first><last>Avram</last><affiliation>University Politehnica of Bucharest</affiliation></author>
      <author><first>Verginica</first><last>Barbu Mititelu</last><affiliation>Racai</affiliation></author>
      <author><first>Dumitru-Clementin</first><last>Cercel</last><affiliation>University Politehnica of Bucharest</affiliation></author>
      <pages>7-13</pages>
      <abstract>Multiword expressions are a key ingredient for developing large-scale and linguistically sound natural language processing technology. This paper describes our improvements in automatically identifying Romanian multiword expressions on the corpus released for the PARSEME v1.2 shared task. Our approach assumes a multilingual perspective based on the recently introduced lateral inhibition layer and adversarial training to boost the performance of the employed multilingual language models. With the help of these two methods, we improve the F1-score of XLM-RoBERTa by approximately 2.7% on unseen multiword expressions, the main task of the PARSEME 1.2 edition. In addition, our results can be considered SOTA performance, as they outperform the previous results on Romanian obtained by the participants in this competition.</abstract>
      <url hash="1c16e1c2">2023.mwe-1.4</url>
      <bibkey>avram-etal-2023-romanian</bibkey>
      <video href="2023.mwe-1.4.mp4"/>
      <doi>10.18653/v1/2023.mwe-1.4</doi>
    </paper>
    <paper id="5">
      <title>Predicting Compositionality of Verbal Multiword Expressions in <fixed-case>P</fixed-case>ersian</title>
      <author><first>Mahtab</first><last>Sarlak</last><affiliation>Shahid Beheshti University</affiliation></author>
      <author><first>Yalda</first><last>Yarandi</last><affiliation>Shahid Beheshti University</affiliation></author>
      <author><first>Mehrnoush</first><last>Shamsfard</last><affiliation>Faculty of Computer Science and Engineering, Shahid Beheshti University</affiliation></author>
      <pages>14-23</pages>
      <abstract>The identification of Verbal Multiword Expressions (VMWEs) presents a greater challenge compared to non-verbal MWEs due to their higher surface variability. VMWEs are linguistic units that exhibit varying levels of semantic opaqueness and pose difficulties for computational models in terms of both their identification and the degree of compositionality. In this study, a new approach to predicting the compositional nature of VMWEs in Persian is presented. The method begins with an automatic identification of VMWEs in Persian sentences, which is approached as a sequence labeling problem for recognizing the components of VMWEs. The method then creates word embeddings that better capture the semantic properties of VMWEs and uses them to determine the degree of compositionality through multiple criteria. The study compares two neural architectures for identification, BiLSTM and ParsBERT, and shows that a fine-tuned BERT model surpasses the BiLSTM model in evaluation metrics with an F1 score of 89%. Next, a word2vec embedding model is trained to capture the semantics of identified VMWEs and is used to estimate their compositionality, resulting in an accuracy of 70.9% as demonstrated by experiments on a collected dataset of expert-annotated compositional and non-compositional VMWEs.</abstract>
      <url hash="2d89b980">2023.mwe-1.5</url>
      <bibkey>sarlak-etal-2023-predicting</bibkey>
      <video href="2023.mwe-1.5.mp4"/>
      <doi>10.18653/v1/2023.mwe-1.5</doi>
    </paper>
    <paper id="6">
      <title><fixed-case>PARSEME</fixed-case> corpus release 1.3</title>
      <author><first>Agata</first><last>Savary</last><affiliation>Paris-Saclay University</affiliation></author>
      <author><first>Cherifa</first><last>Ben Khelil</last><affiliation>LIFAT - Université de Tours</affiliation></author>
      <author><first>Carlos</first><last>Ramisch</last><affiliation>Aix Marseille University, CNRS, LIS</affiliation></author>
      <author><first>Voula</first><last>Giouli</last><affiliation>Institute for Language &amp; Speech Processing, ATHENA Research &amp; Innovation Centre</affiliation></author>
      <author><first>Verginica</first><last>Barbu Mititelu</last><affiliation>Racai</affiliation></author>
      <author><first>Najet</first><last>Hadj Mohamed</last><affiliation>LIFAT - Université de Tours</affiliation></author>
      <author><first>Cvetana</first><last>Krstev</last><affiliation>University of Belgrade, Faculty of Philology</affiliation></author>
      <author><first>Chaya</first><last>Liebeskind</last><affiliation>Jerusalem College of Technology , Lev Academic Center</affiliation></author>
      <author><first>Hongzhi</first><last>Xu</last><affiliation>Shanghai International Studies University</affiliation></author>
      <author><first>Sara</first><last>Stymne</last><affiliation>Uppsala University</affiliation></author>
      <author><first>Tunga</first><last>Güngör</last><affiliation>Bogazici University</affiliation></author>
      <author><first>Thomas</first><last>Pickard</last><affiliation>University of Sheffield</affiliation></author>
      <author><first>Bruno</first><last>Guillaume</last><affiliation>LORIA / Inria Nancy Grand-Est</affiliation></author>
      <author><first>Eduard</first><last>Bejček</last><affiliation>Charles University in Prague, Faculty of Mathematics and Physics, Institute of Formal and Applied Linguistics</affiliation></author>
      <author><first>Archna</first><last>Bhatia</last><affiliation>The Florida Institute for Human and Machine Cognition</affiliation></author>
      <author><first>Marie</first><last>Candito</last><affiliation>LLF (Université Paris Cité / CNRS)</affiliation></author>
      <author><first>Polona</first><last>Gantar</last><affiliation>University of Ljubljana</affiliation></author>
      <author><first>Uxoa</first><last>Iñurrieta</last><affiliation>University of the Basque Country</affiliation></author>
      <author><first>Albert</first><last>Gatt</last><affiliation>Utrecht University</affiliation></author>
      <author><first>Jolanta</first><last>Kovalevskaite</last><affiliation>Vytautas Magnus University in Kaunas</affiliation></author>
      <author><first>Timm</first><last>Lichte</last><affiliation>University of Tübingen</affiliation></author>
      <author><first>Nikola</first><last>Ljubešić</last><affiliation>Jožef Stefan Institute</affiliation></author>
      <author><first>Johanna</first><last>Monti</last><affiliation>L’OrientaleÜniversity of Naples</affiliation></author>
      <author><first>Carla</first><last>Parra Escartín</last><affiliation>RWS Language Weaver</affiliation></author>
      <author><first>Mehrnoush</first><last>Shamsfard</last><affiliation>Faculty of Computer Science and Engineering, Shahid Beheshti University</affiliation></author>
      <author><first>Ivelina</first><last>Stoyanova</last><affiliation>Department of Computational Linguistics, IBL - BAS</affiliation></author>
      <author><first>Veronika</first><last>Vincze</last><affiliation>University of Szeged</affiliation></author>
      <author><first>Abigail</first><last>Walsh</last><affiliation>ADAPT Centre / Dublin City University</affiliation></author>
      <pages>24-35</pages>
      <abstract>We present version 1.3 of the PARSEME multilingual corpus annotated with verbal multiword expressions. Since the previous version, new languages have joined the undertaking of creating such a resource, some of the already existing corpora have been enriched with new annotated texts, while others have been enhanced in various ways. The PARSEME multilingual corpus represents 26 languages now. All monolingual corpora therein use Universal Dependencies v.2 tagset. They are (re-)split observing the PARSEME v.1.2 standard, which puts impact on unseen VMWEs. With the current iteration, the corpus release process has been detached from shared tasks; instead, a process for continuous improvement and systematic releases has been introduced.</abstract>
      <url hash="7c806356">2023.mwe-1.6</url>
      <bibkey>savary-etal-2023-parseme</bibkey>
      <video href="2023.mwe-1.6.mp4"/>
      <doi>10.18653/v1/2023.mwe-1.6</doi>
    </paper>
    <paper id="7">
      <title>Investigating the Effects of <fixed-case>MWE</fixed-case> Identification in Structural Topic Modelling</title>
      <author><first>Dimitrios</first><last>Kokkinakis</last><affiliation>University of Gothenburg</affiliation></author>
      <author><first>Ricardo</first><last>Muñoz Sánchez</last><affiliation>University of Gothenburg</affiliation></author>
      <author><first>Sebastianus</first><last>Bruinsma</last><affiliation>Chalmers University of Technology</affiliation></author>
      <author><first>Mia-Marie</first><last>Hammarlin</last><affiliation>Lund University and Birgit Rausing Centre for Medical Humanities</affiliation></author>
      <pages>36-44</pages>
      <abstract>Multiword expressions (MWEs) are common word combinations which exhibit idiosyncrasies in various linguistic levels. For various downstream natural language processing applications and tasks, the identification and discovery of MWEs has been proven to be potentially practical and useful, but still challenging to codify. In this paper we investigate various, relevant to MWE, resources and tools for Swedish, and, within a specific application scenario, namely ‘vaccine skepticism’, we apply structural topic modelling to investigate whether there are any interpretative advantages of identifying MWEs.</abstract>
      <url hash="63a77aaa">2023.mwe-1.7</url>
      <bibkey>kokkinakis-etal-2023-investigating</bibkey>
      <video href="2023.mwe-1.7.mp4"/>
      <doi>10.18653/v1/2023.mwe-1.7</doi>
    </paper>
    <paper id="8">
      <title>Idioms, Probing and Dangerous Things: Towards Structural Probing for Idiomaticity in Vector Space</title>
      <author><first>Filip</first><last>Klubička</last><affiliation>Technological University Dublin</affiliation></author>
      <author><first>Vasudevan</first><last>Nedumpozhimana</last><affiliation>TU Dublin</affiliation></author>
      <author><first>John</first><last>Kelleher</last><affiliation>Technological University Dublin</affiliation></author>
      <pages>45-57</pages>
      <abstract>The goal of this paper is to learn more about how idiomatic information is structurally encoded in embeddings, using a structural probing method. We repurpose an existing English verbal multi-word expression (MWE) dataset to suit the probing framework and perform a comparative probing study of static (GloVe) and contextual (BERT) embeddings. Our experiments indicate that both encode some idiomatic information to varying degrees, but yield conflicting evidence as to whether idiomaticity is encoded in the vector norm, leaving this an open question. We also identify some limitations of the used dataset and highlight important directions for future work in improving its suitability for a probing analysis.</abstract>
      <url hash="613deea6">2023.mwe-1.8</url>
      <bibkey>klubicka-etal-2023-idioms</bibkey>
      <video href="2023.mwe-1.8.mp4"/>
      <doi>10.18653/v1/2023.mwe-1.8</doi>
    </paper>
    <paper id="9">
      <title>Graph-based multi-layer querying in Parseme Corpora</title>
      <author><first>Bruno</first><last>Guillaume</last><affiliation>LORIA / Inria Nancy Grand-Est</affiliation></author>
      <pages>58-64</pages>
      <abstract>We present a graph-based tool which can be used to explore Verbal Multi-Word Expression (VMWE) annotated in the Parseme project. The tool can be used for linguistic exploration on the data, for helping the manual annotation process and to search for errors or inconsistencies in the annotations.</abstract>
      <url hash="d6696a11">2023.mwe-1.9</url>
      <bibkey>guillaume-2023-graph</bibkey>
      <video href="2023.mwe-1.9.mp4"/>
      <doi>10.18653/v1/2023.mwe-1.9</doi>
    </paper>
    <paper id="10">
      <title>Enriching Multiword Terms in <fixed-case>W</fixed-case>iktionary with Pronunciation Information</title>
      <author><first>Lenka</first><last>Bajcetic</last><affiliation>Innovation Center of the School of Electrical Engineering</affiliation></author>
      <author><first>Thierry</first><last>Declerck</last><affiliation>DFKI GmbH</affiliation></author>
      <author><first>Gilles</first><last>Sérasset</last><affiliation>Université Grenoble Alpes</affiliation></author>
      <pages>65-72</pages>
      <abstract>We report on work in progress dealing with the automated generation of pronunciation information for English multiword terms (MWTs) in Wiktionary, combining information available for their single components. We describe the issues we were encountering, the building of an evaluation dataset, and our teaming with the DBnary resource maintainer. Our approach shows potential for automatically adding morphosyntactic and semantic information to the components of such MWTs.</abstract>
      <url hash="d2d86c73">2023.mwe-1.10</url>
      <bibkey>bajcetic-etal-2023-enriching</bibkey>
      <video href="2023.mwe-1.10.mp4"/>
      <doi>10.18653/v1/2023.mwe-1.10</doi>
    </paper>
    <paper id="11">
      <title>Detecting Idiomatic Multiword Expressions in Clinical Terminology using Definition-Based Representation Learning</title>
      <author><first>François</first><last>Remy</last><affiliation>Ghent University - imec</affiliation></author>
      <author><first>Alfiya</first><last>Khabibullina</last><affiliation>University of Malaga</affiliation></author>
      <author><first>Thomas</first><last>Demeester</last><affiliation>Ghent University - imec</affiliation></author>
      <pages>73-80</pages>
      <abstract>This paper shines a light on the potential of definition-based semantic models for detecting idiomatic and semi-idiomatic multiword expressions (MWEs) in clinical terminology. Our study focuses on biomedical entities defined in the UMLS ontology and aims to help prioritize the translation efforts of these entities. In particular, we develop an effective tool for scoring the idiomaticity of biomedical MWEs based on the degree of similarity between the semantic representations of those MWEs and a weighted average of the representation of their constituents. We achieve this using a biomedical language model trained to produce similar representations for entity names and their definitions, called BioLORD. The importance of this definition-based approach is highlighted by comparing the BioLORD model to two other state-of-the-art biomedical language models based on Transformer: SapBERT and CODER. Our results show that the BioLORD model has a strong ability to identify idiomatic MWEs, not replicated in other models. Our corpus-free idiomaticity estimation helps ontology translators to focus on more challenging MWEs.</abstract>
      <url hash="be05af65">2023.mwe-1.11</url>
      <bibkey>remy-etal-2023-detecting</bibkey>
      <video href="2023.mwe-1.11.mp4"/>
      <doi>10.18653/v1/2023.mwe-1.11</doi>
    </paper>
    <paper id="12">
      <title>Automatic Generation of Vocabulary Lists with Multiword Expressions</title>
      <author><first>John</first><last>Lee</last><affiliation>City University of Hong Kong</affiliation></author>
      <author><first>Adilet</first><last>Uvaliyev</last></author>
      <pages>81-86</pages>
      <abstract>The importance of multiword expressions (MWEs) for language learning is well established. While MWE research has been evaluated on various downstream tasks such as syntactic parsing and machine translation, its applications in computer-assisted language learning has been less explored. This paper investigates the selection of MWEs for graded vocabulary lists. Widely used by language teachers and students, these lists recommend a language acquisition sequence to optimize learning efficiency. We automatically generate these lists using difficulty-graded corpora and MWEs extracted based on semantic compositionality. We evaluate these lists on their ability to facilitate text comprehension for learners. Experimental results show that our proposed method generates higher-quality lists than baselines using collocation measures.</abstract>
      <url hash="f2c11040">2023.mwe-1.12</url>
      <bibkey>lee-uvaliyev-2023-automatic</bibkey>
      <video href="2023.mwe-1.12.mp4"/>
      <doi>10.18653/v1/2023.mwe-1.12</doi>
    </paper>
    <paper id="13">
      <title>Are Frequent Phrases Directly Retrieved like Idioms? An Investigation with Self-Paced Reading and Language Models</title>
      <author><first>Giulia</first><last>Rambelli</last><affiliation>University of Bologna</affiliation></author>
      <author><first>Emmanuele</first><last>Chersoni</last><affiliation>Hong Kong Polytechnic University</affiliation></author>
      <author><first>Marco S. G.</first><last>Senaldi</last><affiliation>McGill University</affiliation></author>
      <author><first>Philippe</first><last>Blache</last><affiliation>Lpl Cnrs</affiliation></author>
      <author><first>Alessandro</first><last>Lenci</last><affiliation>University of Pisa</affiliation></author>
      <pages>87-98</pages>
      <abstract>An open question in language comprehension studies is whether non-compositional multiword expressions like idioms and compositional-but-frequent word sequences are processed differently. Are the latter constructed online, or are instead directly retrieved from the lexicon, with a degree of entrenchment depending on their frequency? In this paper, we address this question with two different methodologies. First, we set up a self-paced reading experiment comparing human reading times for idioms and both highfrequency and low-frequency compositional word sequences. Then, we ran the same experiment using the Surprisal metrics computed with Neural Language Models (NLMs). Our results provide evidence that idiomatic and high-frequency compositional expressions are processed similarly by both humans and NLMs. Additional experiments were run to test the possible factors that could affect the NLMs’ performance.</abstract>
      <url hash="295e84cb">2023.mwe-1.13</url>
      <bibkey>rambelli-etal-2023-frequent</bibkey>
      <video href="2023.mwe-1.13.mp4"/>
      <doi>10.18653/v1/2023.mwe-1.13</doi>
    </paper>
    <paper id="14">
      <title>Annotation of lexical bundles with discourse functions in a <fixed-case>S</fixed-case>panish academic corpus</title>
      <author><first>Eleonora</first><last>Guzzi</last><affiliation>Universidade da Coruña</affiliation></author>
      <author><first>Margarita</first><last>Alonso-Ramos</last><affiliation>Universidade da Coruña</affiliation></author>
      <author><first>Marcos</first><last>Garcia</last><affiliation>Universidade de Santiago de Compostela</affiliation></author>
      <author><first>Marcos</first><last>García Salido</last><affiliation>Universidade da Coruña</affiliation></author>
      <pages>99-105</pages>
      <abstract>This paper describes the process of annotation of 996 lexical bundles (LB) assigned to 39 different discourse functions in a Spanish academic corpus. The purpose of the annotation is to obtain a new Spanish gold-standard corpus of 1,800,000 words useful for training and evaluating computational models that are capable of identifying automatically LBs for each context in new corpora, as well as for linguistic analysis about the role of LBs in academic discourse. The annotation process revealed that correspondence between LBs and discourse functions is not biunivocal and that the degree of ambiguity is high, so linguists’ contribution has been essential for improving the automatic assignation of tags.</abstract>
      <url hash="8f853bc1">2023.mwe-1.14</url>
      <bibkey>guzzi-etal-2023-annotation</bibkey>
      <video href="2023.mwe-1.14.mp4"/>
      <doi>10.18653/v1/2023.mwe-1.14</doi>
    </paper>
    <paper id="15">
      <title>A Survey of <fixed-case>MWE</fixed-case> Identification Experiments: The Devil is in the Details</title>
      <author><first>Carlos</first><last>Ramisch</last><affiliation>Aix Marseille University, CNRS, LIS</affiliation></author>
      <author><first>Abigail</first><last>Walsh</last><affiliation>ADAPT Centre / Dublin City University</affiliation></author>
      <author><first>Thomas</first><last>Blanchard</last><affiliation>Aix Marseille University, CNRS, LIS</affiliation></author>
      <author><first>Shiva</first><last>Taslimipoor</last><affiliation>University of Cambridge</affiliation></author>
      <pages>106-120</pages>
      <abstract>Multiword expression (MWE) identification has been the focus of numerous research papers, especially in the context of the DiMSUM and PARSEME Shared Tasks (STs). This survey analyses 40 MWE identification papers with experiments on data from these STs. We look at corpus selection, pre- and post-processing, MWE encoding, evaluation metrics, statistical significance, and error analyses. We find that these aspects are usually considered minor and/or omitted in the literature. However, they may considerably impact the results and the conclusions drawn from them. Therefore, we advocate for more systematic descriptions of experimental conditions to reduce the risk of misleading conclusions drawn from poorly designed experimental setup.</abstract>
      <url hash="16fa8676">2023.mwe-1.15</url>
      <attachment type="software" hash="7003392f">2023.mwe-1.15.software.zip</attachment>
      <bibkey>ramisch-etal-2023-survey</bibkey>
      <video href="2023.mwe-1.15.mp4"/>
      <doi>10.18653/v1/2023.mwe-1.15</doi>
    </paper>
    <paper id="16">
      <title>A <fixed-case>MWE</fixed-case> lexicon formalism optimised for observational adequacy</title>
      <author><first>Adam</first><last>Lion-Bouton</last><affiliation>University of Tours, LIFAT</affiliation></author>
      <author><first>Agata</first><last>Savary</last><affiliation>Paris-Saclay University</affiliation></author>
      <author><first>Jean-Yves</first><last>Antoine</last><affiliation>Tours U., LIFAT Lab</affiliation></author>
      <pages>121-130</pages>
      <abstract>Past research advocates that, in order to handle the unpredictable nature of multiword expressions (MWEs), their identification should be assisted with lexicons. The choice of the format for such lexicons, however, is far from obvious. We propose the first – to our knowledge – method to quantitatively evaluate some MWE lexicon formalisms based on the notion of observational adequacy. We apply it to derive a simple yet adequate MWE-lexicon formalism, dubbed λ-CSS, based on syntactic dependencies. It proves competitive with lexicons based on sequential representation of MWEs, and even comparable to a state-of-the art MWE identifier.</abstract>
      <url hash="40c460da">2023.mwe-1.16</url>
      <bibkey>lion-bouton-etal-2023-mwe</bibkey>
      <doi>10.18653/v1/2023.mwe-1.16</doi>
    </paper>
  </volume>
</collection>
