<?xml version='1.0' encoding='UTF-8'?>
<collection id="2021.ltedi">
  <volume id="1" ingest-date="2021-04-19" type="proceedings">
    <meta>
      <booktitle>Proceedings of the First Workshop on Language Technology for Equality, Diversity and Inclusion</booktitle>
      <editor><first>Bharathi Raja</first><last>Chakravarthi</last></editor>
      <editor><first>John P.</first><last>McCrae</last></editor>
      <editor><first>Manel</first><last>Zarrouk</last></editor>
      <editor><first>Kalika</first><last>Bali</last></editor>
      <editor><first>Paul</first><last>Buitelaar</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Kyiv</address>
      <month>April</month>
      <year>2021</year>
      <venue>ltedi</venue>
    </meta>
    <frontmatter>
      <url hash="bdaa4076">2021.ltedi-1.0</url>
      <bibkey>ltedi-2021-language</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Impact of <fixed-case>COVID</fixed-case>-19 in Natural Language Processing Publications: a Disaggregated Study in Gender, Contribution and Experience</title>
      <author><first>Christine</first><last>Basta</last></author>
      <author><first>Marta R.</first><last>Costa-jussa</last></author>
      <pages>1–6</pages>
      <abstract>This study sheds light on the effects of COVID-19 in the particular field of Computational Linguistics and Natural Language Processing within Artificial Intelligence. We provide an inter-sectional study on gender, contribution, and experience that considers one school year (from August 2019 to August 2020) as a pandemic year. August is included twice for the purpose of an inter-annual comparison. While the trend in publications increased with the crisis, the results show that the ratio between female and male publications decreased. This only helps to reduce the importance of the female role in the scientific contributions of computational linguistics (it is now far below its peak of 0.24). The pandemic has a particularly negative effect on the production of female senior researchers in the first position of authors (maximum work), followed by the female junior researchers in the last position of authors (supervision or collaborative work).</abstract>
      <url hash="3e3f01c0">2021.ltedi-1.1</url>
      <bibkey>basta-costa-jussa-2021-impact</bibkey>
    </paper>
    <paper id="2">
      <title>Adapting the <fixed-case>P</fixed-case>ortuguese <fixed-case>B</fixed-case>raille System to Formal Semantics</title>
      <author><first>Luís Filipe</first><last>Cunha</last></author>
      <pages>7–14</pages>
      <abstract>Since the seminal work of Richard Montague in the 1970s, mathematical and logic tools have successfully been used to model several aspects of the meaning of natural language. However, visually impaired people continue to face serious difficulties in getting full access to this important instrument. Our paper aims to present a work in progress whose main goal is to provide blind students and researchers with an adequate method to deal with the different resources that are used in formal semantics. In particular, we intend to adapt the Portuguese Braille system in order to accommodate the most common symbols and formulas used in this kind of approach and to develop pedagogical procedures to facilitate its learnability. By making this formalization compatible with the Braille coding (either traditional and electronic), we hope to help blind people to learn and use this notation, essential to acquire a better understanding of a great number of semantic properties displayed by natural language.</abstract>
      <url hash="8d172b6b">2021.ltedi-1.2</url>
      <bibkey>cunha-2021-adapting</bibkey>
    </paper>
    <paper id="3">
      <title>Cross-Lingual Transfer Learning for Hate Speech Detection</title>
      <author><first>Irina</first><last>Bigoulaeva</last></author>
      <author><first>Viktor</first><last>Hangya</last></author>
      <author><first>Alexander</first><last>Fraser</last></author>
      <pages>15–25</pages>
      <abstract>We address the task of automatic hate speech detection for low-resource languages. Rather than collecting and annotating new hate speech data, we show how to use cross-lingual transfer learning to leverage already existing data from higher-resource languages. Using bilingual word embeddings based classifiers we achieve good performance on the target language by training only on the source dataset. Using our transferred system we bootstrap on unlabeled target language data, improving the performance of standard cross-lingual transfer approaches. We use English as a high resource language and German as the target language for which only a small amount of annotated corpora are available. Our results indicate that cross-lingual transfer learning together with our approach to leverage additional unlabeled data is an effective way of achieving good performance on low-resource target languages without the need for any target-language annotations.</abstract>
      <url hash="34394535">2021.ltedi-1.3</url>
      <attachment type="Dataset" hash="ff6f7216">2021.ltedi-1.3.Dataset.txt</attachment>
      <bibkey>bigoulaeva-etal-2021-cross</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hate-speech">Hate Speech</pwcdataset>
    </paper>
    <paper id="4">
      <title>h<fixed-case>BERT</fixed-case> + <fixed-case>B</fixed-case>ias<fixed-case>C</fixed-case>orp - Fighting Racism on the Web</title>
      <author><first>Olawale</first><last>Onabola</last></author>
      <author><first>Zhuang</first><last>Ma</last></author>
      <author><first>Xie</first><last>Yang</last></author>
      <author><first>Benjamin</first><last>Akera</last></author>
      <author><first>Ibraheem</first><last>Abdulrahman</last></author>
      <author><first>Jia</first><last>Xue</last></author>
      <author><first>Dianbo</first><last>Liu</last></author>
      <author><first>Yoshua</first><last>Bengio</last></author>
      <pages>26–33</pages>
      <abstract>Subtle and overt racism is still present both in physical and online communities today and has impacted many lives in different segments of the society. In this short piece of work, we present how we’re tackling this societal issue with Natural Language Processing. We are releasing BiasCorp, a dataset containing 139,090 comments and news segment from three specific sources - Fox News, BreitbartNews and YouTube. The first batch (45,000 manually annotated) is ready for publication. We are currently in the final phase of manually labeling the remaining dataset using Amazon Mechanical Turk. BERT has been used widely in several downstream tasks. In this work, we present hBERT, where we modify certain layers of the pretrained BERT model with the new Hopfield Layer. hBert generalizes well across different distributions with the added advantage of a reduced model complexity. We are also releasing a JavaScript library 3 and a Chrome Extension Application, to help developers make use of our trained model in web applications (say chat application) and for users to identify and report racially biased contents on the web respectively</abstract>
      <url hash="d39effc3">2021.ltedi-1.4</url>
      <bibkey>onabola-etal-2021-hbert</bibkey>
    </paper>
    <paper id="5">
      <title>An Overview of Fairness in Data – Illuminating the Bias in Data Pipeline</title>
      <author><first>Senthil Kumar</first><last>B</last></author>
      <author><first>Aravindan</first><last>Chandrabose</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <pages>34–45</pages>
      <abstract>Data in general encodes human biases by default; being aware of this is a good start, and the research around how to handle it is ongoing. The term ‘bias’ is extensively used in various contexts in NLP systems. In our research the focus is specific to biases such as gender, racism, religion, demographic and other intersectional views on biases that prevail in text processing systems responsible for systematically discriminating specific population, which is not ethical in NLP. These biases exacerbate the lack of equality, diversity and inclusion of specific population while utilizing the NLP applications. The tools and technology at the intermediate level utilize biased data, and transfer or amplify this bias to the downstream applications. However, it is not enough to be colourblind, gender-neutral alone when designing a unbiased technology – instead, we should take a conscious effort by designing a unified framework to measure and benchmark the bias. In this paper, we recommend six measures and one augment measure based on the observations of the bias in data, annotations, text representations and debiasing techniques.</abstract>
      <url hash="6b831c7c">2021.ltedi-1.5</url>
      <bibkey>b-etal-2021-overview</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/winobias">WinoBias</pwcdataset>
    </paper>
    <paper id="6">
      <title><fixed-case>GEPSA</fixed-case>, a tool for monitoring social challenges in digital press</title>
      <author><first>Iñaki</first><last>San Vicente</last></author>
      <author><first>Xabier</first><last>Saralegi</last></author>
      <author><first>Nerea</first><last>Zubia</last></author>
      <pages>46–50</pages>
      <abstract>This papers presents a platform for monitoring press narratives with respect to several social challenges, including gender equality, migrations and minority languages. As narratives are encoded in natural language, we have to use natural processing techniques to automate their analysis. Thus, crawled news are processed by means of several NLP modules, including named entity recognition, keyword extraction,document classification for social challenge detection, and sentiment analysis. A Flask powered interface provides data visualization for a user-based analysis of the data. This paper presents the architecture of the system and describes in detail its different components. Evaluation is provided for the modules related to extraction and classification of information regarding social challenges.</abstract>
      <url hash="f8e7ae96">2021.ltedi-1.6</url>
      <bibkey>san-vicente-etal-2021-gepsa</bibkey>
    </paper>
    <paper id="7">
      <title>Finding Spoiler Bias in Tweets by Zero-shot Learning and Knowledge Distilling from Neural Text Simplification</title>
      <author><first>Avi</first><last>Bleiweiss</last></author>
      <pages>51–60</pages>
      <abstract>Automatic detection of critical plot information in reviews of media items poses unique challenges to both social computing and computational linguistics. In this paper we propose to cast the problem of discovering spoiler bias in online discourse as a text simplification task. We conjecture that for an item-user pair, the simpler the user review we learn from an item summary the higher its likelihood to present a spoiler. Our neural model incorporates the advanced transformer network to rank the severity of a spoiler in user tweets. We constructed a sustainable high-quality movie dataset scraped from unsolicited review tweets and paired with a title summary and meta-data extracted from a movie specific domain. To a large extent, our quantitative and qualitative results weigh in on the performance impact of named entity presence in plot summaries. Pretrained on a split-and-rephrase corpus with knowledge distilled from English Wikipedia and fine-tuned on our movie dataset, our neural model shows to outperform both a language modeler and monolingual translation baselines.</abstract>
      <url hash="cb3c8c3f">2021.ltedi-1.7</url>
      <attachment type="Dataset" hash="2e3925d5">2021.ltedi-1.7.Dataset.zip</attachment>
      <bibkey>bleiweiss-2021-finding</bibkey>
      <pwccode url="https://github.com/bshalem/mst" additional="false">bshalem/mst</pwccode>
    </paper>
    <paper id="8">
      <title>Findings of the Shared Task on Hope Speech Detection for Equality, Diversity, and Inclusion</title>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <author><first>Vigneshwaran</first><last>Muralidaran</last></author>
      <pages>61–72</pages>
      <abstract>Hope is considered significant for the well-being, recuperation and restoration of human life by health professionals. Hope speech reflects the belief that one can discover pathways to their desired objectives and become roused to utilise those pathways. To encourage research in natural language processing towards positive reinforcement approach, we created a hope speech detection dataset. This paper reports on the shared task of hope speech detection for Tamil, English, and Malayalam languages. The shared task was conducted as a part of the EACL 2021 workshop on Language Technology for Equality, Diversity, and Inclusion (LT-EDI-2021). We summarize here the datasets for this challenge which are openly available at <url>https://competitions.codalab.org/competitions/27653</url>, and present an overview of the methods and the results of the competing systems. To the best of our knowledge, this is the first shared task to conduct hope speech detection.</abstract>
      <url hash="32fd7407">2021.ltedi-1.8</url>
      <bibkey>chakravarthi-muralidaran-2021-findings</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hopeedi">HopeEDI</pwcdataset>
    </paper>
    <paper id="9">
      <title>dhivya-hope-detection@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Multilingual Hope Speech Detection for Code-mixed and Transliterated Texts</title>
      <author><first>Dhivya</first><last>Chinnappa</last></author>
      <pages>73–78</pages>
      <abstract>In this paper we work with a hope speech detection corpora that includes English, Tamil, and Malayalam datasets. We present a two phase mechanism to detect hope speech. In the first phase we build a classifier to identify the language of the text. In the second phase, we build a classifier to detect hope speech, non hope speech, or not lang labels. Experimental results show that hope speech detection is challenging and there is scope for improvement.</abstract>
      <url hash="cbc8d859">2021.ltedi-1.9</url>
      <bibkey>chinnappa-2021-dhivya</bibkey>
    </paper>
    <paper id="10">
      <title><fixed-case>KU</fixed-case>_<fixed-case>NLP</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: A Multilingual Hope Speech Detection for Equality, Diversity, and Inclusion using Context Aware Embeddings</title>
      <author><first>Junaida</first><last>M K</last></author>
      <author><first>Ajees</first><last>A P</last></author>
      <pages>79–85</pages>
      <abstract>Hope speech detection is a new task for finding and highlighting positive comments or supporting content from user-generated social media comments. For this task, we have used a Shared Task multilingual dataset on Hope Speech Detection for Equality, Diversity, and Inclusion (HopeEDI) for three languages English, code-switched Tamil and Malayalam. In this paper, we present deep learning techniques using context-aware string embeddings for word representations and Recurrent Neural Network (RNN) and pooled document embeddings for text representation. We have evaluated and compared the three models for each language with different approaches. Our proposed methodology works fine and achieved higher performance than baselines. The highest weighted average F-scores of 0.93, 0.58, and 0.84 are obtained on the task organisers’ final evaluation test set. The proposed models are outperforming the baselines by 3%, 2% and 11% in absolute terms for English, Tamil and Malayalam respectively.</abstract>
      <url hash="f4b19de6">2021.ltedi-1.10</url>
      <attachment type="Software" hash="fa3e1d3c">2021.ltedi-1.10.Software.zip</attachment>
      <bibkey>m-k-a-p-2021-ku</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hopeedi">HopeEDI</pwcdataset>
    </paper>
    <paper id="11">
      <title><fixed-case>EDIO</fixed-case>ne@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Pre-trained Transformers with Convolutional Neural Networks for Hope Speech Detection.</title>
      <author><first>Suman</first><last>Dowlagar</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <pages>86–91</pages>
      <abstract>Hope is an essential aspect of mental health stability and recovery in every individual in this fast-changing world. Any tools and methods developed for detection, analysis, and generation of hope speech will be beneficial. In this paper, we propose a model on hope-speech detection to automatically detect web content that may play a positive role in diffusing hostility on social media. We perform the experiments by taking advantage of pre-processing and transfer-learning models. We observed that the pre-trained multilingual-BERT model with convolution neural networks gave the best results. Our model ranked first, third, and fourth ranks on English, Malayalam-English, and Tamil-English code-mixed datasets.</abstract>
      <url hash="daf7ece2">2021.ltedi-1.11</url>
      <attachment type="Software" hash="8e47551b">2021.ltedi-1.11.Software.zip</attachment>
      <bibkey>dowlagar-mamidi-2021-edione</bibkey>
    </paper>
    <paper id="12">
      <title>ssn_di<fixed-case>BERT</fixed-case>sity@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021:Hope Speech Detection on multilingual <fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube comments via transformer based approach</title>
      <author><first>Arunima</first><last>S</last></author>
      <author><first>Akshay</first><last>Ramakrishnan</last></author>
      <author><first>Avantika</first><last>Balaji</last></author>
      <author><first>Thenmozhi</first><last>D.</last></author>
      <author><first>Senthil Kumar</first><last>B</last></author>
      <pages>92–97</pages>
      <abstract>In recent times, there exists an abundance of research to classify abusive and offensive texts focusing on negative comments but only minimal research using the positive reinforcement approach. The task was aimed at classifying texts into ‘Hope_speech’, ‘Non_hope_speech’, and ‘Not in language’. The datasets were provided by the LT-EDI organisers in English, Tamil, and Malayalam language with texts sourced from YouTube comments. We trained our data using transformer models, specifically mBERT for Tamil and Malayalam and BERT for English, and achieved weighted average F1-scores of 0.46, 0.81, 0.92 for Tamil, Malayalam, and English respectively.</abstract>
      <url hash="52bc196e">2021.ltedi-1.12</url>
      <attachment type="Software" hash="a4dcc1b9">2021.ltedi-1.12.Software.zip</attachment>
      <bibkey>s-etal-2021-ssn</bibkey>
    </paper>
    <paper id="13">
      <title><fixed-case>IIITT</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021-Hope Speech Detection: There is always hope in Transformers</title>
      <author><first>Karthik</first><last>Puranik</last></author>
      <author><first>Adeep</first><last>Hande</last></author>
      <author><first>Ruba</first><last>Priyadharshini</last></author>
      <author><first>Sajeetha</first><last>Thavareesan</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <pages>98–106</pages>
      <abstract>In a world with serious challenges like climate change, religious and political conflicts, global pandemics, terrorism, and racial discrimination, an internet full of hate speech, abusive and offensive content is the last thing we desire for. In this paper, we work to identify and promote positive and supportive content on these platforms. We work with several transformer-based models to classify social media comments as hope speech or not hope speech in English, Malayalam, and Tamil languages. This paper portrays our work for the Shared Task on Hope Speech Detection for Equality, Diversity, and Inclusion at LT-EDI 2021- EACL 2021. The codes for our best submission can be viewed.</abstract>
      <url hash="35a0ebf4">2021.ltedi-1.13</url>
      <attachment type="Software" hash="b54b3da8">2021.ltedi-1.13.Software.zip</attachment>
      <bibkey>puranik-etal-2021-iiitt</bibkey>
      <pwccode url="https://github.com/karthikpuranik11/Hope-Speech-Detection-" additional="false">karthikpuranik11/Hope-Speech-Detection-</pwccode>
    </paper>
    <paper id="14">
      <title><fixed-case>IIIT</fixed-case>_<fixed-case>DWD</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Hope Speech Detection in <fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube multilingual comments</title>
      <author><first>Sunil</first><last>Saumya</last></author>
      <author><first>Ankit Kumar</first><last>Mishra</last></author>
      <pages>107–113</pages>
      <abstract>Language as a significant part of communication should be inclusive of equality and diversity. The internet user’s language has a huge influence on peer users all over the world. People express their views through language on virtual platforms like Facebook, Twitter, YouTube etc. People admire the success of others, pray for their well-being, and encourage on their failure. Such inspirational comments are hope speech comments. At the same time, a group of users promotes discrimination based on gender, racial, sexual orientation, persons with disability, and other minorities. The current paper aims to identify hope speech comments which are very important to move on in life. Various machine learning and deep learning based models (such as support vector machine, logistics regression, convolutional neural network, recurrent neural network) are employed to identify the hope speech in the given YouTube comments. The YouTube comments are available in English, Tamil and Malayalam languages and are part of the task “EACL-2021:Hope Speech Detection for Equality, Diversity and Inclusion”.</abstract>
      <url hash="e1ac1d4d">2021.ltedi-1.14</url>
      <attachment type="Software" hash="5d7e710d">2021.ltedi-1.14.Software.zip</attachment>
      <bibkey>saumya-mishra-2021-iiit</bibkey>
    </paper>
    <paper id="15">
      <title><fixed-case>IRNLP</fixed-case>_<fixed-case>DAIICT</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Hope Speech detection in Code Mixed text using <fixed-case>TF</fixed-case>-<fixed-case>IDF</fixed-case> Char N-grams and <fixed-case>M</fixed-case>u<fixed-case>RIL</fixed-case></title>
      <author><first>Bhargav</first><last>Dave</last></author>
      <author><first>Shripad</first><last>Bhat</last></author>
      <author><first>Prasenjit</first><last>Majumder</last></author>
      <pages>114–117</pages>
      <abstract>This paper presents the participation of the IRNLP_DAIICT team from Information Retrieval and Natural Language Processing lab at DA-IICT, India in LT-EDI@EACL2021 Hope Speech Detection task. The aim of this shared task is to identify hope speech from a code-mixed data-set of YouTube comments. The task is to classify comments into Hope Speech, Non Hope speech or Not in language, for three languages: English, Malayalam-English and Tamil-English. We use TF-IDF character n-grams and pretrained MuRIL embeddings for text representation and Logistic Regression and Linear SVM for classification. Our best approach achieved second, eighth and fifth rank with weighted F1 score of 0.92, 0.75 and 0.57 in English, Malayalam-English and Tamil-English on test dataset respectively</abstract>
      <url hash="b459f912">2021.ltedi-1.15</url>
      <attachment type="Software" hash="0142f225">2021.ltedi-1.15.Software.zip</attachment>
      <bibkey>dave-etal-2021-irnlp-daiict</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>ZYJ</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021:<fixed-case>XLM</fixed-case>-<fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a-Based Model with Attention for Hope Speech Detection</title>
      <author><first>Yingjia</first><last>Zhao</last></author>
      <author><first>Xin</first><last>Tao</last></author>
      <pages>118–121</pages>
      <abstract>Due to the development of modern computer technology and the increase in the number of online media users, we can see all kinds of posts and comments everywhere on the internet. Hope speech can not only inspire the creators but also make other viewers pleasant. It is necessary to effectively and automatically detect hope speech. This paper describes the approach of our team in the task of hope speech detection. We use the attention mechanism to adjust the weight of all the output layers of XLM-RoBERTa to make full use of the information extracted from each layer, and use the weighted sum of all the output layers to complete the classification task. And we use the Stratified-K-Fold method to enhance the training data set. We achieve a weighted average F1-score of 0.59, 0.84, and 0.92 for Tamil, Malayalam, and English language, ranked 3rd, 2nd, and 2nd.</abstract>
      <url hash="9c6805ad">2021.ltedi-1.16</url>
      <attachment type="Software" hash="ce5760dc">2021.ltedi-1.16.Software.zip</attachment>
      <bibkey>zhao-tao-2021-zyj</bibkey>
    </paper>
    <paper id="17">
      <title><fixed-case>TEAM</fixed-case> <fixed-case>HUB</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Hope Speech Detection Based On Pre-trained Language Model</title>
      <author><first>Bo</first><last>Huang</last></author>
      <author><first>Yang</first><last>Bai</last></author>
      <pages>122–127</pages>
      <abstract>This article introduces the system description of TEAM_HUB team participating in LT-EDI 2021: Hope Speech Detection. This shared task is the first task related to the desired voice detection. The data set in the shared task consists of three different languages (English, Tamil, and Malayalam). The task type is text classification. Based on the analysis and understanding of the task description and data set, we designed a system based on a pre-trained language model to complete this shared task. In this system, we use methods and models that combine the XLM-RoBERTa pre-trained language model and the Tf-Idf algorithm. In the final result ranking announced by the task organizer, our system obtained F1 scores of 0.93, 0.84, 0.59 on the English dataset, Malayalam dataset, and Tamil dataset. Our submission results are ranked 1, 2, and 3 respectively.</abstract>
      <url hash="3613412e">2021.ltedi-1.17</url>
      <attachment type="Software" hash="7e299286">2021.ltedi-1.17.Software.zip</attachment>
      <bibkey>huang-bai-2021-team</bibkey>
    </paper>
    <paper id="18">
      <title>cs_english@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Hope Speech Detection Based On Fine-tuning <fixed-case>ALBERT</fixed-case> Model</title>
      <author><first>Shi</first><last>Chen</last></author>
      <author><first>Bing</first><last>Kong</last></author>
      <pages>128–131</pages>
      <abstract>This paper mainly introduces the relevant content of the task “Hope Speech Detection for Equality, Diversity, and Inclusion at LT-EDI 2021-EACL 2021”. A total of three language datasets were provided, and we chose the English dataset to complete this task. The specific task objective is to classify the given speech into ‘Hope speech’, ‘Not Hope speech’, and ‘Not in intended language’. In terms of method, we use fine-tuned ALBERT and K fold cross-validation to accomplish this task. In the end, we achieved a good result in the rank list of the task result, and the final F1 score was 0.93, tying for first place. However, we will continue to try to improve methods to get better results in future work.</abstract>
      <url hash="3907ab6d">2021.ltedi-1.18</url>
      <attachment type="Software" hash="ef024015">2021.ltedi-1.18.Software.zip</attachment>
      <bibkey>chen-kong-2021-cs-english</bibkey>
    </paper>
    <paper id="19">
      <title><fixed-case>GCDH</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: <fixed-case>XLM</fixed-case>-<fixed-case>R</fixed-case>o<fixed-case>BERT</fixed-case>a for Hope Speech Detection in <fixed-case>E</fixed-case>nglish, <fixed-case>M</fixed-case>alayalam, and <fixed-case>T</fixed-case>amil</title>
      <author><first>Stefan</first><last>Ziehe</last></author>
      <author><first>Franziska</first><last>Pannach</last></author>
      <author><first>Aravind</first><last>Krishnan</last></author>
      <pages>132–135</pages>
      <abstract>This paper describes approaches to identify Hope Speech in short, informal texts in English, Malayalam and Tamil using different machine learning techniques. We demonstrate that even very simple baseline algorithms perform reasonably well on this task if provided with enough training data. However, our best performing algorithm is a cross-lingual transfer learning approach in which we fine-tune XLM-RoBERTa.</abstract>
      <url hash="3709ed46">2021.ltedi-1.19</url>
      <attachment type="Software" hash="fe141de7">2021.ltedi-1.19.Software.zip</attachment>
      <bibkey>ziehe-etal-2021-gcdh</bibkey>
    </paper>
    <paper id="20">
      <title><fixed-case>T</fixed-case>eam<fixed-case>UNCC</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Hope Speech Detection using Transfer Learning with Transformers</title>
      <author><first>Khyati</first><last>Mahajan</last></author>
      <author><first>Erfan</first><last>Al-Hossami</last></author>
      <author><first>Samira</first><last>Shaikh</last></author>
      <pages>136–142</pages>
      <abstract>In this paper, we describe our approach towards utilizing pre-trained models for the task of hope speech detection. We participated in Task 2: Hope Speech Detection for Equality, Diversity and Inclusion at LT-EDI-2021 @ EACL2021. The goal of this task is to predict the presence of hope speech, along with the presence of samples that do not belong to the same language in the dataset. We describe our approach to fine-tuning RoBERTa for Hope Speech detection in English and our approach to fine-tuning XLM-RoBERTa for Hope Speech detection in Tamil and Malayalam, two low resource Indic languages. We demonstrate the performance of our approach on classifying text into hope-speech, non-hope and not-language. Our approach ranked 1st in English (F1 = 0.93), 1st in Tamil (F1 = 0.61) and 3rd in Malayalam (F1 = 0.83).</abstract>
      <url hash="b7e23c3d">2021.ltedi-1.20</url>
      <attachment type="Software" hash="dea413ca">2021.ltedi-1.20.Software.zip</attachment>
      <bibkey>mahajan-etal-2021-teamuncc</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hopeedi">HopeEDI</pwcdataset>
    </paper>
    <paper id="21">
      <title>Autobots@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: One World, One Family: Hope Speech Detection with <fixed-case>BERT</fixed-case> Transformer Model</title>
      <author><first>Sunil</first><last>Gundapu</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <pages>143–148</pages>
      <abstract>The rapid rise of online social networks like YouTube, Facebook, Twitter allows people to express their views more widely online. However, at the same time, it can lead to an increase in conflict and hatred among consumers in the form of freedom of speech. Therefore, it is essential to take a positive strengthening method to research on encouraging, positive, helping, and supportive social media content. In this paper, we describe a Transformer-based BERT model for Hope speech detection for equality, diversity, and inclusion, submitted for LT-EDI-2021 Task 2. Our model achieves a weighted averaged f1-score of 0.93 on the test set.</abstract>
      <url hash="ca01867b">2021.ltedi-1.21</url>
      <attachment type="Software" hash="d95ae8fa">2021.ltedi-1.21.Software.zip</attachment>
      <bibkey>gundapu-mamidi-2021-autobots</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hopeedi">HopeEDI</pwcdataset>
    </paper>
    <paper id="22">
      <title>Amrita@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Hope Speech Detection on Multilingual Text</title>
      <author><first>Thara</first><last>S</last></author>
      <author><first>Ravi teja</first><last>Tasubilli</last></author>
      <author><first>Kothamasu</first><last>Sai rahul</last></author>
      <pages>149–156</pages>
      <abstract>Analysis and deciphering code-mixed data is imperative in academia and industry, in a multilingual country like India, in order to solve problems apropos Natural Language Processing. This paper proposes a bidirectional long short-term memory (BiLSTM) with the attention-based approach, in solving the hope speech detection problem. Using this approach an F1-score of 0.73 (9thrank) in the Malayalam-English data set was achieved from a total of 31 teams who participated in the competition.</abstract>
      <url hash="f476ab90">2021.ltedi-1.22</url>
      <attachment type="Software" hash="9f71d089">2021.ltedi-1.22.Software.zip</attachment>
      <bibkey>s-etal-2021-amrita</bibkey>
    </paper>
    <paper id="23">
      <title>Hopeful Men@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Hope Speech Detection Using Indic Transliteration and Transformers</title>
      <author><first>Ishan Sanjeev</first><last>Upadhyay</last></author>
      <author><first>Nikhil</first><last>E</last></author>
      <author><first>Anshul</first><last>Wadhawan</last></author>
      <author><first>Radhika</first><last>Mamidi</last></author>
      <pages>157–163</pages>
      <abstract>This paper aims to describe the approach we used to detect hope speech in the HopeEDI dataset. We experimented with two approaches. In the first approach, we used contextual embeddings to train classifiers using logistic regression, random forest, SVM, and LSTM based models. The second approach involved using a majority voting ensemble of 11 models which were obtained by fine-tuning pre-trained transformer models (BERT, ALBERT, RoBERTa, IndicBERT) after adding an output layer. We found that the second approach was superior for English, Tamil and Malayalam. Our solution got a weighted F1 score of 0.93, 0.75 and 0.49 for English, Malayalam and Tamil respectively. Our solution ranked 1st in English, 8th in Malayalam and 11th in Tamil.</abstract>
      <url hash="0926ccdc">2021.ltedi-1.23</url>
      <attachment type="Dataset" hash="84fedf5c">2021.ltedi-1.23.Dataset.txt</attachment>
      <attachment type="Software" hash="bb353e6c">2021.ltedi-1.23.Software.zip</attachment>
      <bibkey>upadhyay-etal-2021-hopeful</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hopeedi">HopeEDI</pwcdataset>
    </paper>
    <paper id="24">
      <title>Hopeful <fixed-case>NLP</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Finding Hope in <fixed-case>Y</fixed-case>ou<fixed-case>T</fixed-case>ube Comment Section</title>
      <author><first>Vasudev</first><last>Awatramani</last></author>
      <pages>164–167</pages>
      <abstract>The proliferation of Hate Speech and misinformation in social media is fast becoming a menace to society. In compliment, the dissemination of hate-diffusing, promising and anti-oppressive messages become a unique alternative. Unfortunately, due to its complex nature as well as the relatively limited manifestation in comparison to hostile and neutral content, the identification of Hope Speech becomes a challenge. This work revolves around the detection of Hope Speech in Youtube comments, for the Shared Task on Hope Speech Detection for Equality, Diversity, and Inclusion. We achieve an f-score of 0.93, ranking 1st on the leaderboard for English comments.</abstract>
      <url hash="9ea81a68">2021.ltedi-1.24</url>
      <bibkey>awatramani-2021-hopeful</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/hopeedi">HopeEDI</pwcdataset>
    </paper>
    <paper id="25">
      <title><fixed-case>NLP</fixed-case>-<fixed-case>CUET</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Multilingual Code-Mixed Hope Speech Detection using Cross-lingual Representation Learner</title>
      <author><first>Eftekhar</first><last>Hossain</last></author>
      <author><first>Omar</first><last>Sharif</last></author>
      <author><first>Mohammed Moshiul</first><last>Hoque</last></author>
      <pages>168–174</pages>
      <abstract>In recent years, several systems have been developed to regulate the spread of negativity and eliminate aggressive, offensive or abusive contents from the online platforms. Nevertheless, a limited number of researches carried out to identify positive, encouraging and supportive contents. In this work, our goal is to identify whether a social media post/comment contains hope speech or not. We propose three distinct models to identify hope speech in English, Tamil and Malayalam language to serve this purpose. To attain this goal, we employed various machine learning (SVM, LR, ensemble), deep learning (CNN+BiLSTM) and transformer (m-BERT, Indic-BERT, XLNet, XLM-R) based methods. Results indicate that XLM-R outdoes all other techniques by gaining a weighted f_1-score of 0.93, 0.60 and 0.85 respectively for English, Tamil and Malayalam language. Our team has achieved 1st, 2nd and 1st rank in these three tasks respectively.</abstract>
      <url hash="11b16ff6">2021.ltedi-1.25</url>
      <attachment type="Software" hash="53b2858d">2021.ltedi-1.25.Software.zip</attachment>
      <bibkey>hossain-etal-2021-nlp-cuet</bibkey>
      <pwccode url="https://github.com/eftekhar-hossain/CUET_NLP-EACL_2021" additional="false">eftekhar-hossain/CUET_NLP-EACL_2021</pwccode>
    </paper>
    <paper id="26">
      <title>Simon @ <fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Detecting Hope Speech with <fixed-case>BERT</fixed-case></title>
      <author><first>Qinyu</first><last>Que</last></author>
      <pages>175–179</pages>
      <abstract>In today’s society, the rapid development of communication technology allows us to communicate with people from different parts of the world. In the process of communication, each person treats others differently. Some people are used to using offensive and sarcastic language to express their views. These words cause pain to others and make people feel down. Some people are used to sharing happiness with others and encouraging others. Such people bring joy and hope to others through their words. On social media platforms, these two kinds of language are all over the place. If people want to make the online world a better place, they will have to deal with both. So identifying offensive language and hope language is an essential task. There have been many assignments about offensive language. Shared Task on Hope Speech Detection for Equality, Diversity, and Inclusion at LT-EDI 2021-EACL 2021 uses another unique perspective – to identify the language of Hope to make contributions to society. The XLM-Roberta model is an excellent multilingual model. Our team used a fine-tuned XLM-Roberta model to accomplish this task.</abstract>
      <url hash="ab7ab04c">2021.ltedi-1.26</url>
      <attachment type="Software" hash="1cce9f15">2021.ltedi-1.26.Software.zip</attachment>
      <bibkey>que-2021-simon-lt</bibkey>
    </paper>
    <paper id="27">
      <title><fixed-case>MUCS</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021:<fixed-case>C</fixed-case>o<fixed-case>H</fixed-case>ope-Hope Speech Detection for Equality, Diversity, and Inclusion in Code-Mixed Texts</title>
      <author><first>Fazlourrahman</first><last>Balouchzahi</last></author>
      <author><first>Aparna</first><last>B K</last></author>
      <author><first>H L</first><last>Shashirekha</last></author>
      <pages>180–187</pages>
      <abstract>This paper describes the models submitted by the team MUCS for “Hope Speech Detection for Equality, Diversity, and Inclusion-EACL 2021” shared task that aims at classifying a comment / post in English and code-mixed texts in two language pairs, namely, Tamil-English (Ta-En) and Malayalam-English (Ma-En) into one of the three predefined categories, namely, “Hope_speech”, “Non_hope_speech”, and “other_languages”. Three models namely, CoHope-ML, CoHope-NN, and CoHope-TL based on Ensemble of classifiers, Keras Neural Network (NN) and BiLSTM with Conv1d model respectively are proposed for the shared task. CoHope-ML, CoHope-NN models are trained on a feature set comprised of char sequences extracted from sentences combined with words for Ma-En and Ta-En code-mixed texts and a combination of word and char ngrams along with syntactic word ngrams for English text. CoHope-TL model consists of three major parts: training tokenizer, BERT Language Model (LM) training and then using pre-trained BERT LM as weights in BiLSTM-Conv1d model. Out of three proposed models, CoHope-ML model (best among our models) obtained 1st, 2nd, and 3rd ranks with weighted F1-scores of 0.85, 0.92, and 0.59 for Ma-En, English and Ta-En texts respectively.</abstract>
      <url hash="9ab66a57">2021.ltedi-1.27</url>
      <attachment type="Software" hash="791852a4">2021.ltedi-1.27.Software.zip</attachment>
      <bibkey>balouchzahi-etal-2021-mucs-lt</bibkey>
      <pwcdataset url="https://paperswithcode.com/dataset/dakshina">Dakshina</pwcdataset>
    </paper>
    <paper id="28">
      <title>Spartans@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Inclusive Speech Detection using Pretrained Language Models</title>
      <author><first>Megha</first><last>Sharma</last></author>
      <author><first>Gaurav</first><last>Arora</last></author>
      <pages>188–192</pages>
      <abstract>We describe our system that ranked first in Hope Speech Detection (HSD) shared task and fourth in Offensive Language Identification (OLI) shared task, both in Tamil language. The goal of HSD and OLI is to identify if a code-mixed comment or post contains hope speech or offensive content respectively. We pre-train a transformer-based model RoBERTa using synthetically generated code-mixed data and use it in an ensemble along with their pre-trained ULMFiT model available from iNLTK.</abstract>
      <url hash="0c7a2996">2021.ltedi-1.28</url>
      <attachment type="Software" hash="6b9ae7c3">2021.ltedi-1.28.Software.zip</attachment>
      <bibkey>sharma-arora-2021-spartans</bibkey>
    </paper>
    <paper id="29">
      <title><fixed-case>CFILT</fixed-case> <fixed-case>IIT</fixed-case> <fixed-case>B</fixed-case>ombay@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Hope Speech Detection for Equality, Diversity, and Inclusion using Multilingual Representation from<fixed-case>T</fixed-case>ransformers</title>
      <author><first>Pankaj</first><last>Singh</last></author>
      <author><first>Prince</first><last>Kumar</last></author>
      <author><first>Pushpak</first><last>Bhattacharyya</last></author>
      <pages>193–196</pages>
      <abstract>With the internet becoming part and parcel of our lives, engagement in social media has increased a lot. Identifying and eliminating offensive content from social media has become of utmost priority to prevent any kind of violence. However, detecting encouraging, supportive and positive content is equally important to prevent misuse of censorship targeted to attack freedom of speech. This paper presents our system for the shared task Hope Speech Detection for Equality, Diversity, and Inclusion at LT-EDI, EACL 2021. The data for this shared task is provided in English, Tamil, and Malayalam which was collected from YouTube comments. It is a multiclass classification problem where each data instance is categorized into one of the three classes: ‘Hope speech’, ‘Not hope speech’, and ‘Not in intended language’. We propose a system that employs multilingual transformer models to obtain the representation of text and classifies it into one of the three classes. We explored the use of multilingual models trained specifically for Indian languages along with generic multilingual models. Our system was ranked 2nd for English, 2nd for Malayalam, and 7th for the Tamil language in the final leader board published by organizers and obtained a weighted F1-score of 0.92, 0.84, 0.55 respectively on the hidden test dataset used for the competition. We have made our system publicly available at GitHub.</abstract>
      <url hash="9b981e4b">2021.ltedi-1.29</url>
      <attachment type="Software" hash="8a528fa1">2021.ltedi-1.29.Software.zip</attachment>
      <bibkey>singh-etal-2021-cfilt</bibkey>
    </paper>
    <paper id="30">
      <title><fixed-case>IIITK</fixed-case>@<fixed-case>LT</fixed-case>-<fixed-case>EDI</fixed-case>-<fixed-case>EACL</fixed-case>2021: Hope Speech Detection for Equality, Diversity, and Inclusion in <fixed-case>T</fixed-case>amil , <fixed-case>M</fixed-case>alayalam and <fixed-case>E</fixed-case>nglish</title>
      <author><first>Nikhil</first><last>Ghanghor</last></author>
      <author><first>Rahul</first><last>Ponnusamy</last></author>
      <author><first>Prasanna Kumar</first><last>Kumaresan</last></author>
      <author><first>Ruba</first><last>Priyadharshini</last></author>
      <author><first>Sajeetha</first><last>Thavareesan</last></author>
      <author><first>Bharathi Raja</first><last>Chakravarthi</last></author>
      <pages>197–203</pages>
      <abstract>This paper describes the IIITK’s team submissions to the hope speech detection for equality, diversity and inclusion in Dravidian languages shared task organized by LT-EDI 2021 workshop@EACL 2021. Our best configurations for the shared tasks achieve weighted F1 scores of 0.60 for Tamil, 0.83 for Malayalam, and 0.93 for English. We have secured ranks of 4, 3, 2 in Tamil, Malayalam and English respectively.</abstract>
      <url hash="24b969f1">2021.ltedi-1.30</url>
      <attachment type="Software" hash="c3a9e640">2021.ltedi-1.30.Software.zip</attachment>
      <bibkey>ghanghor-etal-2021-iiitk-lt</bibkey>
    </paper>
  </volume>
</collection>
