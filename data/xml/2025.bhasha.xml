<?xml version='1.0' encoding='UTF-8'?>
<collection id="2025.bhasha">
  <volume id="1" ingest-date="2026-01-13" type="proceedings">
    <meta>
      <booktitle>Proceedings of the 1st Workshop on Benchmarks, Harmonization, Annotation, and Standardization for Human-Centric AI in Indian Languages (BHASHA 2025)</booktitle>
      <editor><first>Arnab</first><last>Bhattacharya</last></editor>
      <editor><first>Pawan</first><last>Goyal</last></editor>
      <editor><first>Saptarshi</first><last>Ghosh</last></editor>
      <editor><first>Kripabandhu</first><last>Ghosh</last></editor>
      <publisher>Association for Computational Linguistics</publisher>
      <address>Mumbai, India</address>
      <month>December</month>
      <year>2025</year>
      <url hash="5049b8b4">2025.bhasha-1</url>
      <venue>bhasha</venue>
      <venue>ws</venue>
      <isbn>979-8-89176-313-5</isbn>
    </meta>
    <frontmatter>
      <url hash="5eabc8cf">2025.bhasha-1.0</url>
      <bibkey>bhasha-ws-2025-1</bibkey>
    </frontmatter>
    <paper id="1">
      <title>Multi-Feature Graph Convolution Network for <fixed-case>H</fixed-case>indi <fixed-case>OCR</fixed-case> Verification</title>
      <author><first>Shikhar</first><last>Dubey</last><affiliation>IIT Mandi, India</affiliation></author>
      <author><first>Krish</first><last>Mittal</last><affiliation>IIT Mandi, India</affiliation></author>
      <author><first>Sourava Kumar</first><last>Behera</last><affiliation>IIT Mandi, India</affiliation></author>
      <author><first>Manikandan</first><last>Ravikiran</last><affiliation>IIT Mandi, India</affiliation></author>
      <author><first>Nitin</first><last>Kumar</last><affiliation>Shiv Nadar University, Delhi, India</affiliation></author>
      <author><first>Saurabh</first><last>Shigwan</last><affiliation>Shiv Nadar University, Delhi, India</affiliation></author>
      <author><first>Rohit</first><last>Saluja</last><affiliation>IIT Mandi, India</affiliation></author>
      <pages>1-10</pages>
      <abstract>This paper presents a novel Graph Convolutional Network (GCN) based framework for verifying OCR predictions on real Hindi document images, specifically addressing the challenges of complex conjuncts and character segmentation. Our approach first segments Hindi characters in real book images at different levels of granularity, while also synthetically generating word images from OCR predictions. Both real and synthetic images are processed through ResNet-50 to extract feature representations, which are then segmented using multiple patching strategies (uniform, akshara, random, and letter patches). The bounding boxes created using segmentation masks are scaled proportionally to the feature space while extracting features for GCN. We construct a line graph where each node represents a real-synthetic character pair (in feature space). Each node of the line graph captures semantic and geometric features including i) cross-entropy between original and synthetic features, ii) Hu moments difference for shape properties, and iii) and pixel count difference for size variation. The GCN with three convolutional layers (and ELU activation) processes these graph-structured features to verify the correctness of OCR predictions. Experimental evaluation on 1000 images from diverse Hindi books demonstrates the effectiveness of our graph-based verification approach in detecting OCR errors, particularly for challenging conjunct characters where traditional methods struggle.</abstract>
      <url hash="3350e6c8">2025.bhasha-1.1</url>
      <bibkey>dubey-etal-2025-multi</bibkey>
    </paper>
    <paper id="2">
      <title><fixed-case>I</fixed-case>ndian Grammatical Tradition-Inspired Universal Semantic Representation Bank (<fixed-case>USR</fixed-case> Bank 1.0)</title>
      <author><first>Soma</first><last>Paul</last><affiliation>IIIT Hyderabad, India</affiliation></author>
      <author><first>Sukhada</first><last>Sukhada</last><affiliation>IIT BHU, Varanasi, India</affiliation></author>
      <author><first>Bidisha</first><last>Bhattacharjee</last><affiliation>IIIT Hyderabad, India</affiliation></author>
      <author><first>Kumari</first><last>Riya</last><affiliation>IIT BHU, Varanasi, India</affiliation></author>
      <author><first>Sashank</first><last>Tatavolu</last><affiliation>IIIT Hyderabad, India</affiliation></author>
      <author><first>Kamesh</first><last>R</last><affiliation>SIST, Chennai, India</affiliation></author>
      <author><first>Isma</first><last>Anwar</last><affiliation>IIIT Hyderabad, India</affiliation></author>
      <author><first>Pratibha</first><last>Rani</last><affiliation>IIIT Hyderabad, India</affiliation></author>
      <pages>11-22</pages>
      <abstract>In this paper, we introduce USR Bank 1.0, a multi-layered, text-level semantic representation framework designed to capture not only the predicate-argument structure of an utterance but also the speaker’s communicative intent as expressed linguistically. Built on the Universal Semantic Grammar (USG), which is grounded in Pāṇinian grammar and the Indian Grammatical Tradition (IGT), USR systematically encodes semantic, morpho-syntactic, discourse, and pragmatic information across distinct layers. In the USR generation process, initial USRs are automatically generated using a dedicated USR-builder tool and subsequently validated via a web-based interface (SAVI), ensuring high inter-annotator agreement and semantic fidelity. Our evaluation on Hindi texts demonstrates robust dependency and discourse annotation consistency and strong semantic similarity in USR-to-text generation. By distributing semantic-pragmatic information across layers and capturing the speaker’s perspective, USR provides a cognitively motivated, language-agnostic framework with promising applications in multilingual natural language processing.</abstract>
      <url hash="6c664674">2025.bhasha-1.2</url>
      <bibkey>paul-etal-2025-indian</bibkey>
    </paper>
    <paper id="3">
      <title>Auditing Political Bias in Text Generation by <fixed-case>GPT</fixed-case>-4 using Sociocultural and Demographic Personas: Case of <fixed-case>B</fixed-case>engali Ethnolinguistic Communities</title>
      <author><first>Dipto</first><last>Das</last><affiliation>University of Toronto, Canada</affiliation></author>
      <author><first>Syed Ishtiaque</first><last>Ahmed</last><affiliation>University of Toronto, Canada</affiliation></author>
      <author><first>Shion</first><last>Guha</last><affiliation>University of Toronto, Canada</affiliation></author>
      <pages>23-36</pages>
      <abstract>Though large language models (LLMs) are increasingly used in multilingual contexts, their political and sociocultural biases in low-resource languages remain critically underexplored. In this paper, we investigate how LLM-generated texts in Bengali shift in response to personas with varying political orientations (left vs. right), religious identities (Hindu vs. Muslim), and national affiliations (Bangladeshi vs. Indian). In a quasi-experimental study, we simulate these personas and prompt an LLM to respond to political discussions. Measuring the shifts relative to responses for a baseline Bengali persona, we examined how political orientation influences LLM outputs, how topical association shape the political leanings of outputs, and how demographic persona-induced changes align with differently politically oriented variations. Our findings highlight left-leaning political bias in Bengali text generation and its significant association with Muslim sociocultural and demographic identity. We also connect our findings with broader discussions around emancipatory politics, epistemological considerations, and alignment of multilingual models.</abstract>
      <url hash="1c79619e">2025.bhasha-1.3</url>
      <bibkey>das-etal-2025-auditing</bibkey>
    </paper>
    <paper id="4">
      <title><fixed-case>INDRA</fixed-case>: Iterative Difficulty Refinement Attention for <fixed-case>MCQ</fixed-case> Difficulty Estimation for <fixed-case>I</fixed-case>ndic Languages</title>
      <author><first>Manikandan</first><last>Ravikiran</last><affiliation>IIT Mandi, India</affiliation></author>
      <author><first>Rohit</first><last>Saluja</last><affiliation>IIT Mandi, India</affiliation></author>
      <author><first>Arnav</first><last>Bhavsar</last><affiliation>IIT Mandi, India</affiliation></author>
      <pages>37-51</pages>
      <abstract>Estimating the difficulty of multiple-choice questions (MCQs) is central to adaptive testing and learner modeling. We introduce <b>INDRA</b> (Iterative Difficulty Refinement Attention), a novel attention mechanism that unifies psychometric priors with neural refinement for Indic MCQ difficulty estimation. INDRA incorporates three key innovations: (i) <i>IRT-informed initialization</i>, which assigns token-level discrimination and difficulty scores to embed psychometric interpretability; (ii) <i>entropy-driven iterative refinement</i>, which progressively sharpens attention to mimic the human process of distractor elimination; and (iii) <i>Indic Aware Graph Coupling</i>, which propagates plausibility across morphologically and semantically related tokens, a critical feature for Indic languages. Experiments on TEEMIL-H and TEEMIL-K datasets show that INDRA achieves consistent improvements, with absolute gains of up to +1.02 F1 and +1.68 F1 over state-of-the-art, while demonstrating through ablation studies that psychometric priors, entropy refinement, and graph coupling contribute complementary gains to accuracy and robustness.</abstract>
      <url hash="fd1d46e1">2025.bhasha-1.4</url>
      <bibkey>ravikiran-etal-2025-indra</bibkey>
    </paper>
    <paper id="5">
      <title>Benchmarking <fixed-case>H</fixed-case>indi <fixed-case>LLM</fixed-case>s: A New Suite of Datasets and a Comparative Analysis</title>
      <author><first>Anusha</first><last>Kamath</last><affiliation>NVidia, India</affiliation></author>
      <author><first>Kanishk</first><last>Singla</last><affiliation>NVidia, India</affiliation></author>
      <author><first>Rakesh</first><last>Paul</last><affiliation>NVidia, India</affiliation></author>
      <author><first>Raviraj Bhuminand</first><last>Joshi</last><affiliation>NVidia, India</affiliation></author>
      <author><first>Utkarsh</first><last>Vaidya</last><affiliation>NVidia, India</affiliation></author>
      <author><first>Sanjay Singh</first><last>Chauhan</last><affiliation>NVidia, India</affiliation></author>
      <author><first>Niranjan</first><last>Wartikar</last><affiliation>NVidia, India</affiliation></author>
      <pages>52-68</pages>
      <abstract>Evaluating instruction-tuned Large Language Models (LLMs) in Hindi is challenging due to a lack of high-quality benchmarks, as direct translation of English datasets fails to capture crucial linguistic and cultural nuances. To address this, we introduce a suite of five Hindi LLM evaluation datasets: IFEval-Hi, MT-Bench-Hi, GSM8K-Hi, ChatRAG-Hi, and BFCL-Hi. These were created using a methodology that combines from-scratch human annotation with a translate-and-verify process. We leverage this suite to conduct an extensive benchmarking of open-source LLMs supporting Hindi, providing a detailed comparative analysis of their current capabilities. Our curation process also serves as a replicable methodology for developing benchmarks in other low-resource languages.</abstract>
      <url hash="4214ca0f">2025.bhasha-1.5</url>
      <bibkey>kamath-etal-2025-benchmarking</bibkey>
    </paper>
    <paper id="6">
      <title>Aligning Large Language Models to Low-Resource Languages through <fixed-case>LLM</fixed-case>-Based Selective Translation: A Systematic Study</title>
      <author><first>Rakesh</first><last>Paul</last><affiliation>NVidia, India</affiliation></author>
      <author><first>Anusha</first><last>Kamath</last><affiliation>NVidia, India</affiliation></author>
      <author><first>Kanishk</first><last>Singla</last><affiliation>NVidia, India</affiliation></author>
      <author><first>Raviraj</first><last>Joshi</last><affiliation>NVidia, India</affiliation></author>
      <author><first>Utkarsh</first><last>Vaidya</last><affiliation>NVidia, India</affiliation></author>
      <author><first>Sanjay Singh</first><last>Chauhan</last><affiliation>NVidia, India</affiliation></author>
      <author><first>Niranjan</first><last>Wartikar</last><affiliation>NVidia, India</affiliation></author>
      <pages>69-82</pages>
      <abstract>Multilingual large language models (LLMs) often demonstrate a performance gap between English and non-English languages, particularly in low-resource settings. Aligning these models to low-resource languages is essential yet challenging due to limited high-quality data. While English alignment datasets are readily available, curating equivalent data in other languages is expensive and time-consuming. A common workaround is to translate existing English alignment data; however, standard translation techniques often fail to preserve critical elements such as code, mathematical expressions, and structured formats like JSON. In this work, we investigate LLM-based selective translation, a technique that selectively translates only the translatable parts of a text while preserving non-translatable content and sentence structure. We conduct a systematic study to explore key questions around this approach, including its effectiveness compared to vanilla translation, the importance of filtering noisy outputs, and the benefits of mixing translated samples with original English data during alignment. Our experiments focus on the low-resource Indic language Hindi and compare translations generated by Google Cloud Platform (GCP) and Llama-3.1-405B. The results highlight the promise of selective translation as a practical and effective method for improving multilingual alignment in LLMs.</abstract>
      <url hash="7b2eee8a">2025.bhasha-1.6</url>
      <bibkey>paul-etal-2025-aligning</bibkey>
    </paper>
    <paper id="7">
      <title>Automatic Accent Restoration in <fixed-case>V</fixed-case>edic <fixed-case>S</fixed-case>anskrit with Neural Language Models</title>
      <author><first>Yuzuki</first><last>Tsukagoshi</last><affiliation>University of Tokyo, Japan</affiliation></author>
      <author><first>Ikki</first><last>Ohmukai</last><affiliation>University of Tokyo, Japan</affiliation></author>
      <pages>83-90</pages>
      <abstract>Vedic Sanskrit, the oldest attested form of Sanskrit, employs a distinctive pitch-accent system that marks one syllable per word. This work presents the first application of large language models to the automatic restoration of accent marks in transliterated Vedic Sanskrit texts. A comprehensive corpus was assembled by extracting major Vedic works from the TITUS project and constructing paired samples of unaccented input and correctly accented references, yielding more than 100,000 training examples. Three generative LLMs were fine-tuned on this corpus: a LoRA-adapted Llama 3.1 8B Instruct model, OpenAI GPT‐4.1 nano, and Google Gemini 2.5 Flash. These models were trained in a sequence‐to‐sequence fashion to insert accent marks at appropriate positions. Evaluation on roughly 2,000 sentences using precision, recall, F1, character error rate, word error rate, and ChrF1 metrics shows that fine‐tuned models substantially outperform their untuned baselines. The LoRA-tuned Llama achieves the highest F1, followed by Gemini 2.5 Flash and GPT‐4.1 nano. Error analysis reveals that the models learn to infer accents from grammatical and phonological context. These results demonstrate that LLMs can capture complex accentual patterns and recover lost information, opening possibilities for improved sandhi splitting, morphological analysis, syntactic parsing and machine translation in Vedic NLP pipelines.</abstract>
      <url hash="68e827b7">2025.bhasha-1.7</url>
      <bibkey>tsukagoshi-ohmukai-2025-automatic</bibkey>
    </paper>
    <paper id="8">
      <title><fixed-case>A</fixed-case>nci<fixed-case>D</fixed-case>ev: A Dataset for High-Accuracy Handwritten Text Recognition of <fixed-case>A</fixed-case>ncient <fixed-case>D</fixed-case>evanagari Manuscripts</title>
      <author><first>Vriti</first><last>Sharma</last><affiliation>IIT Mandi, India</affiliation></author>
      <author><first>Rajat</first><last>Verma</last><affiliation>IIT Mandi, India</affiliation></author>
      <author><first>Rohit</first><last>Saluja</last><affiliation>IIT Mandi, India</affiliation></author>
      <pages>91-101</pages>
      <abstract>The digital preservation and accessibility of historical documents require accurate and scalable Handwritten Text Recognition (HTR). However, progress in this field is significantly hampered for low-resource scripts, such as ancient forms of the scripts used in historical manuscripts, due to the scarcity of high-quality, transcribed training data. We address this critical gap by introducing the <b>AnciDev</b> Dataset, a novel, publicly available resource comprising 3,000 transcribed text lines sourced from 500 pages of different ancient Devanagari manuscripts. To validate the utility of this new resource, we systematically evaluate and fine-tune several HTR models on the <b>AnciDev</b> Dataset. Our experiments demonstrate a significant performance uplift across all fine-tuned models, with the best-performing architecture achieving a substantial reduction in Character Error Rate (CER), confirming the dataset’s efficacy in addressing the unique complexities of ancient handwriting. This work not only provides a crucial, well-curated dataset to the research community but also sets a new, reproducible state-of-the-art for the HTR of historical Devanagari, advancing the effort to digitally preserve India’s documentary heritage.</abstract>
      <url hash="aa1d282b">2025.bhasha-1.8</url>
      <bibkey>sharma-etal-2025-ancidev</bibkey>
    </paper>
    <paper id="9">
      <title><fixed-case>BHRAM</fixed-case>-<fixed-case>IL</fixed-case>: A Benchmark for Hallucination Recognition and Assessment in Multiple <fixed-case>I</fixed-case>ndian Languages</title>
      <author><first>Hrishikesh</first><last>Terdalkar</last><affiliation>BITS Pilani, Hyderabad Campus, India</affiliation></author>
      <author><first>Kirtan</first><last>Bhojani</last><affiliation>BITS Pilani, Hyderabad Campus, India</affiliation></author>
      <author><first>Aryan</first><last>Dongare</last><affiliation>BITS Pilani, Hyderabad Campus, India</affiliation></author>
      <author><first>Omm Aditya</first><last>Behera</last><affiliation>BITS Pilani, Hyderabad Campus, India</affiliation></author>
      <pages>102-116</pages>
      <abstract>Large language models (LLMs) are increasingly deployed in multilingual applications but often generate plausible yet incorrect or misleading outputs, known as hallucinations. While hallucination detection has been studied extensively in English, under-resourced Indian languages remain largely unexplored. We present BHRAM-IL, a benchmark for hallucination recognition and assessment in multiple Indian languages, covering Hindi, Gujarati, Marathi, Odia, along with English. The benchmark comprises 36,047 curated questions across nine categories spanning factual, numerical, reasoning, and linguistic tasks. We evaluate 14 state-of-the-art multilingual LLMs on a benchmark subset of 10,265 questions, analyzing cross-lingual and factual hallucinations across languages, models, scales, categories, and domains using category-specific metrics normalized to (0,1) range. Aggregation over all categories and models yields a primary score of 0.23 and a language-corrected fuzzy score of 0.385, demonstrating the usefulness of BHRAM-IL for hallucination-focused evaluation. The dataset, and the code for generation and evaluation are available on GitHub (https://github.com/sambhashana/BHRAM-IL/) and HuggingFace (https://huggingface.co/datasets/sambhashana/BHRAM-IL/) to support future research in multilingual hallucination detection and mitigation.</abstract>
      <url hash="0f29306c">2025.bhasha-1.9</url>
      <bibkey>terdalkar-etal-2025-bhram</bibkey>
    </paper>
    <paper id="10">
      <title>Mātṛkā: Multilingual Jailbreak Evaluation of Open-Source Large Language Models</title>
      <author><first>Murali</first><last>Emani</last><affiliation>Argonne National Lab, USA</affiliation></author>
      <author><first>Kashyap Manjusha</first><last>R</last><affiliation>UIUC, USA</affiliation></author>
      <pages>117-121</pages>
      <abstract>Artificial Intelligence (AI) and Large Language Models (LLMs) are increasingly integrated into high-stakes applications, yet their susceptibility to adversarial prompts poses significant security risks. In this work, we introduce Mātṛkā, a framework for systematically evaluating jailbreak vulnerabilities in open-source multilingual LLMs. Using the open-source dataset across nine sensitive categories, we constructed adversarial prompt sets that combine translation, mixed-language encoding, homoglyph signatures, numeric enforcement, and structural variations. Experiments were conducted on state-of-the-art open-source models from Llama, Qwen, GPT-OSS, Mistral, and Gemma families. Our findings highlight transferability of jailbreaks across multiple languages with varying success rates depending on attack design. We provide empirical insights, a novel taxonomy of multilingual jailbreak strategies, and recommendations for enhancing robustness in safety-critical environments.</abstract>
      <url hash="0a36013d">2025.bhasha-1.10</url>
      <bibkey>emani-r-2025-matrka</bibkey>
    </paper>
    <paper id="11">
      <title>Accent Placement Models for Rigvedic <fixed-case>S</fixed-case>anskrit Text</title>
      <author><first>Akhil Rajeev</first><last>P</last><affiliation>CDAC, Bangalore, India</affiliation></author>
      <author><first>Annarao</first><last>Kulkarni</last><affiliation>CDAC, Bangalore, India</affiliation></author>
      <pages>122-126</pages>
      <abstract>The Rigveda, among the oldest Indian texts in Vedic Sanskrit, employs a distinctive pitchaccent system - udatta, anudatta, svarita whose marks encode melodic and interpretive cues but are often absent from moderne-texts. This work develops a parallel corpus of accented-unaccented ́slokas and conducts a controlled comparison of three strategies for automatic accent placement in Rigvedic verse: (i) full fine-tuning of ByT5, a byte-level Transformer that operates directly on Unicode combining marks, (ii) a from-scratch BiLSTM-CRF sequence-labeling baseline, and (iii) LoRA-based parameter-efficient fine-tuning atop ByT5. Evaluation uses Word Error Rate (WER) and Character Error Rate (CER) for orthographic fidelity, plus a task-specific Diacritic Error Rate (DER) that isolates accent edits. Full ByT5 fine-tuning attains the lowest error across all metrics; LoRA offers strong efficiencyaccuracy trade-offs, and BiLSTM-CRF serves as a transparent baseline. The study underscores practical requirements for accent restoration - Unicode-safe preprocessing, mark-aware tokenization, and evaluation that separates grapheme from accent errors - and positions heritage-language technology as an emerging NLP area connecting computational modeling with philological and pedagogical aims. Results establish reproducible baselines for Rigvedic accent restoration and provide guidance for downstream tasks such as accentaware OCR, ASR/chant synthesis, and digital scholarship.</abstract>
      <url hash="7b940467">2025.bhasha-1.11</url>
      <bibkey>p-kulkarni-2025-accent</bibkey>
    </paper>
    <paper id="12">
      <title>Findings of the <fixed-case>I</fixed-case>ndic<fixed-case>GEC</fixed-case> and <fixed-case>I</fixed-case>ndic<fixed-case>WG</fixed-case> Shared Task at <fixed-case>BHASHA</fixed-case> 2025</title>
      <author><first>Pramit</first><last>Bhattacharyya</last><affiliation>IIT Kanpur, India</affiliation></author>
      <author><first>Karthika</first><last>N J</last><affiliation>IIT Bombay, India</affiliation></author>
      <author><first>Hrishikesh</first><last>Terdalkar</last><affiliation>BITS Pilani, Hyderabad Campus, India</affiliation></author>
      <author><first>Manoj Balaji</first><last>Jagadeeshan</last><affiliation>IIT Kharagpur, India</affiliation></author>
      <author><first>Shubham Kumar</first><last>Nigam</last><affiliation>IIT Kanpur, India</affiliation></author>
      <author><first>Arvapalli Sai</first><last>Susmitha</last><affiliation>IIT Kanpur, India</affiliation></author>
      <author><first>Arnab</first><last>Bhattacharya</last><affiliation>IIT Kanpur, India</affiliation></author>
      <pages>127-134</pages>
      <abstract>This overview paper presents the findings of the two shared tasks organized as part of the 1st Workshop on Benchmarks, Harmonization, Annotation, and Standardization for Human-Centric AI in Indian Languages (BHASHA) co-located with IJCNLP-AACL 2025. The shared tasks are: (1) Indic Grammar Error Correction (IndicGEC) and (2) Indic Word Grouping (IndicWG). For GEC, participants were tasked with producing grammatically correct sentences based on given input sentences in five Indian languages. For WG, participants were required to generate a word-grouped variant of a provided sentence in Hindi. The evaluation metric used for GEC was GLEU, while Exact Matching was employed for WG. A total of 14 teams participated in the final phase of the Shared Task 1; 2 teams participated in the final phase of Shared Task 2. The maximum GLEU scores obtained for Hindi, Bangla, Telugu, Tamil and Malayalam languages are respectively 85.69, 95.79, 88.17, 91.57 and 96.02 for the IndicGEC shared task. The highest exact matching score obtained for IndicWG shared task is 45.13%.</abstract>
      <url hash="9157bab4">2025.bhasha-1.12</url>
      <bibkey>bhattacharyya-etal-2025-findings</bibkey>
    </paper>
    <paper id="13">
      <title>Niyamika at <fixed-case>BHASHA</fixed-case> Task 1: Word-Level Transliteration for <fixed-case>E</fixed-case>nglish-<fixed-case>H</fixed-case>indi Mixed Text in Grammar Correction Using <fixed-case>MT</fixed-case>5</title>
      <author><first>Rucha</first><last>Ambaliya</last><affiliation>VNSGU, India</affiliation></author>
      <author><first>Mahika</first><last>Dugar</last><affiliation>VNSGU, India</affiliation></author>
      <author><first>Pruthwik</first><last>Mishra</last><affiliation>SVNIT, India</affiliation></author>
      <pages>135-141</pages>
      <abstract>Grammar correction for Indian languages poses significant challenges due to complex morphology, non-standard spellings, and frequent script variations. In this work, we address grammar correction for English-mixed sentences in five Indic languages—Hindi, Bengali, Malayalam, Tamil, and Telugu—as part of the IndicGEC 2025 Bhasha Workshop. Our approach first applies word-level transliteration using IndicTrans (Bhat et al., 2014) to normalize Romanized and mixed-script tokens, followed by grammar correction using the mT5-small model (Xue et al., 2021). Although our experiments focus on these five languages, the methodology is generalizable to other Indian languages. Our implementation and code are publicly available at: https://github.com/Rucha-Ambaliya/bhasha-workshop</abstract>
      <url hash="e8f5add6">2025.bhasha-1.13</url>
      <bibkey>ambaliya-etal-2025-niyamika</bibkey>
    </paper>
    <paper id="14">
      <title>Team Horizon at <fixed-case>BHASHA</fixed-case> Task 1: Multilingual <fixed-case>I</fixed-case>ndic<fixed-case>GEC</fixed-case> with Transformer-based Grammatical Error Correction Models</title>
      <author><first>Manav</first><last>Dhamecha</last><affiliation>SVNIT, India</affiliation></author>
      <author><first>Sunil</first><last>Jaat</last><affiliation>SVNIT, India</affiliation></author>
      <author><first>Gaurav</first><last>Damor</last><affiliation>SVNIT, India</affiliation></author>
      <author><first>Pruthwik</first><last>Mishra</last><affiliation>SVNIT, India</affiliation></author>
      <pages>142-146</pages>
      <abstract>This paper presents Team Horizon’s approach to the BHASHA Shared Task 1: Indic Grammatical Error Correction (IndicGEC). We explore transformer-based multilingual models — mT5-small and IndicBART — to correct grammatical and semantic errors across five Indian languages: Bangla, Hindi, Tamil, Telugu, and Malayalam. Due to limited annotated data, we developed a synthetic data augmentation pipeline that introduces realistic linguistic errors under ten categories, simulating natural mistakes found in Indic scripts. Our fine-tuned models achieved competitive performance with GLEU scores of 86.03 (Tamil), 72.00 (Telugu), 82.69 (Bangla), 80.44 (Hindi), and 84.36 (Malayalam). We analyze the impact of dataset scaling, multilingual fine-tuning, and training epochs, showing that linguistically grounded augmentation can significantly improve grammatical correction accuracy in low-resource Indic languages.</abstract>
      <url hash="abfe2f0f">2025.bhasha-1.14</url>
      <bibkey>dhamecha-etal-2025-team</bibkey>
    </paper>
    <paper id="15">
      <title>A3-108 at <fixed-case>BHASHA</fixed-case> Task1: Asymmetric <fixed-case>BPE</fixed-case> configuration for Grammar Error Correction</title>
      <author><first>Saumitra</first><last>Yadav</last><affiliation>IIIT Hyderabad, India</affiliation></author>
      <author id="manish-shrivastava"><first>Manish</first><last>Shrivastava</last><affiliation>IIIT Hyderabad, India</affiliation></author>
      <pages>147-154</pages>
      <abstract>This paper presents our approach to Grammatical Error Correction (GEC) for five low-resource Indic languages, a task severely limited by a scarcity of annotated data. Our core methodology involves two stages: synthetic data generation and model optimization. First, we leverage the provided training data to build a Statistical Machine Translation (SMT) system, which is then used to generate large-scale synthetic noisy-to-clean parallel data from available monolingual text. This artificially corrupted data significantly enhances model robustness. Second, we train Transformer-based sequence-to-sequence models using an asymmetric and symmetric Byte Pair Encoding (BPE) configuration, where the number of merge operations differs between the source (erroneous) and target (corrected) sides to better capture language-specific characteristics. For instance, source BPE sizes 4000, 8000 and 16000, with target sizes at 500, 1000, 2000, 3000 and 4000. Our experiments demonstrated competitive performance across all five languages, with the best results achieving a GLUE score of 94.16 for Malayalam (Rank 4th) followed by Bangla at 92.44 (ranked 5th), Tamil at 85.52 (ranked 5th), Telugu at 81.9 (7th), and Hindi at 79.45(10th) in the shared task. These findings substantiate the effectiveness of combining SMT-based synthetic data generation with asymmetric BPE configurations for low-resource GEC.</abstract>
      <url hash="f365b075">2025.bhasha-1.15</url>
      <bibkey>yadav-shrivastava-2025-a3</bibkey>
    </paper>
    <paper id="16">
      <title><fixed-case>DLRG</fixed-case> at <fixed-case>BHASHA</fixed-case>: Task 1 (<fixed-case>I</fixed-case>ndic<fixed-case>GEC</fixed-case>): A Hybrid Neurosymbolic Approach for <fixed-case>T</fixed-case>amil and <fixed-case>M</fixed-case>alayalam Grammatical Error Correction</title>
      <author><first>Akshay</first><last>Ramesh</last><affiliation>VIT, Chennai, India</affiliation></author>
      <author><first>Ratnavel</first><last>Rajalakshmi</last><affiliation>VIT, Chennai, India</affiliation></author>
      <pages>155-163</pages>
      <abstract>Grammatical Error Correction (GEC) for low-resource Indic languages remains challenging due to limited annotated data and morphological complexity. We present a hybrid neurosymbolic GEC system that combines neural sequence-to-sequence models with explicit language-specific rule-based pattern matching. Our approach leverages parameter-efficient LoRA adaptation on aggressively augmented data to fine-tune pre-trained mT5 models, followed by learned correction rules through intelligent ensemble strategies. The proposed hybrid architecture achieved 85.34% GLEU for Tamil (Rank 8) and 95.06% GLEU for Malayalam (Rank 2) on the provided IndicGEC test sets, outperforming individual neural and rule-based approaches. The system incorporates conservative safety mechanisms to prevent catastrophic deletions and over-corrections, thus ensuring robustness and real-world applicability. Our work demonstrates that extremely low-resource GEC can be effectively addressed by combining neural generalization with symbolic precision.</abstract>
      <url hash="96b90cf8">2025.bhasha-1.16</url>
      <bibkey>ramesh-rajalakshmi-2025-dlrg</bibkey>
    </paper>
    <paper id="17">
      <title>akhilrajeevp at <fixed-case>BHASHA</fixed-case> Task 1: Minimal-Edit Instruction Tuning for Low-Resource <fixed-case>I</fixed-case>ndic <fixed-case>GEC</fixed-case></title>
      <author><first>Akhil Rajeev</first><last>P</last><affiliation>CDAC, Bangalore, India</affiliation></author>
      <pages>164-174</pages>
      <abstract>Grammatical error correction for Indic languages faces limited supervision, diverse scripts, and rich morphology. We propose an augmentation-free setup that uses instructiontuned large language models and conservative decoding. A 12B GEMMA 3 model is instruction-tuned in bnb 4 bit precision with Parameter efficient Finetuning and Alpaca-style formatting. Decoding follows a deterministic, constraint-aware procedure with a lightweight normaliser that encourages minimal, meaningpreserving edits. We operationalise inference, subsequent to instruction fine-tuning (IFT), via a fixed, language-specific prompt directly synthesised from a deterministic error classifier’s taxonomy, label distributions, and precedence ordering computed on the training corpus. Under the official untuned GLEU evaluation, the system scores 92.41 on Malayalam, sixth overall, and 81.44 on Hindi, third overall. These results indicate that classifier-informed prompt design, adapter-based instruction tuning, and deterministic decoding provide a reproducible and computationally efficient alternative to augmentation-centred pipelines for Indic GEC. The approach also motivates future work on stronger morphosyntactic constraints and human centered evaluation of conservative edits.</abstract>
      <url hash="74f49eb0">2025.bhasha-1.17</url>
      <bibkey>p-2025-akhilrajeevp</bibkey>
    </paper>
    <paper id="18">
      <title>Team Horizon at <fixed-case>BHASHA</fixed-case> Task 2: Fine-tuning Multilingual Transformers for <fixed-case>I</fixed-case>ndic Word Grouping</title>
      <author><first>Manav</first><last>Dhamecha</last><affiliation>SVNIT, India</affiliation></author>
      <author><first>Gaurav</first><last>Damor</last><affiliation>SVNIT, India</affiliation></author>
      <author><first>Sunil</first><last>Jaat</last><affiliation>SVNIT, India</affiliation></author>
      <author><first>Pruthwik</first><last>Mishra</last><affiliation>SVNIT, India</affiliation></author>
      <pages>175-179</pages>
      <abstract>We present Team Horizon’s approach to BHASHA Task 2: Indic Word Grouping. We model the word-grouping problem as token classification problem and fine-tune multilingual Transformer encoders for the task. We evaluated MuRIL, XLM-Roberta, and IndicBERT v2 and report Exact Match accuracy on the test data. Our best model (MuRIL) achieves 58.1818% exact match on the test set.</abstract>
      <url hash="b7fa312a">2025.bhasha-1.18</url>
      <bibkey>dhamecha-etal-2025-team-horizon</bibkey>
    </paper>
  </volume>
</collection>
